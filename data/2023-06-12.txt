------------------------------------------------------------------------------
------------------------------------------------------------------------------
Send any comments regarding submissions directly to submitter.
------------------------------------------------------------------------------
Archives at http://arxiv.org/
To unsubscribe, e-mail To: cs@arXiv.org, Subject: cancel
------------------------------------------------------------------------------
Submissions to:
Artificial Intelligence
Computer Vision and Pattern Recognition
Computer Science and Game Theory
Machine Learning
Multiagent Systems
Robotics
Systems and Control
received from  Thu  8 Jun 23 18:00:00 GMT  to  Fri  9 Jun 23 18:00:00 GMT
------------------------------------------------------------------------------
------------------------------------------------------------------------------
\\
arXiv:2306.05480
Date: Thu, 8 Jun 2023 18:04:13 GMT   (439kb,D)

Title: Artificial General Intelligence for Medical Imaging
Authors: Xiang Li, Lu Zhang, Zihao Wu, Zhengliang Liu, Lin Zhao, Yixuan Yuan,
 Jun Liu, Gang Li, Dajiang Zhu, Pingkuan Yan, Quanzheng Li, Wei Liu, Tianming
 Liu, and Dinggang Shen
Categories: cs.AI
\\
 In this review, we explore the potential applications of Artificial General
Intelligence (AGI) models in healthcare, focusing on foundational Large
Language Models (LLMs), Large Vision Models, and Large Multimodal Models. We
emphasize the importance of integrating clinical expertise, domain knowledge,
and multimodal capabilities into AGI models. In addition, we lay out key
roadmaps that guide the development and deployment of healthcare AGI models.
Throughout the review, we provide critical perspectives on the potential
challenges and pitfalls associated with deploying large-scale AGI models in the
medical field. This comprehensive review aims to offer insights into the future
implications of AGI in medical imaging, healthcare and beyond.
\\ ( https://arxiv.org/abs/2306.05480 ,  439kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05490
Date: Thu, 8 Jun 2023 18:22:46 GMT   (151kb)

Title: Learnability with PAC Semantics for Multi-agent Beliefs
Authors: Ionela G. Mocanu, Vaishak Belle and Brendan Juba
Categories: cs.AI cs.LO
\\
 The tension between deduction and induction is perhaps the most fundamental
issue in areas such as philosophy, cognition and artificial intelligence. In an
influential paper, Valiant recognised that the challenge of learning should be
integrated with deduction. In particular, he proposed a semantics to capture
the quality possessed by the output of Probably Approximately Correct (PAC)
learning algorithms when formulated in a logic. Although weaker than classical
entailment, it allows for a powerful model-theoretic framework for answering
queries. In this paper, we provide a new technical foundation to demonstrate
PAC learning with multi-agent epistemic logics. To circumvent the negative
results in the literature on the difficulty of robust learning with the PAC
semantics, we consider so-called implicit learning where we are able to
incorporate observations to the background theory in service of deciding the
entailment of an epistemic query. We prove correctness of the learning
procedure and discuss results on the sample complexity, that is how many
observations we will need to provably assert that the query is entailed given a
user-specified error bound. Finally, we investigate under what circumstances
this algorithm can be made efficient. On the last point, given that reasoning
in epistemic logics especially in multi-agent epistemic logics is
PSPACE-complete, it might seem like there is no hope for this problem. We
leverage some recent results on the so-called Representation Theorem explored
for single-agent and multi-agent epistemic logics with the only knowing
operator to reduce modal reasoning to propositional reasoning.
\\ ( https://arxiv.org/abs/2306.05490 ,  151kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05582
Date: Thu, 8 Jun 2023 22:46:31 GMT   (683kb)

Title: A newborn embodied Turing test for view-invariant object recognition
Authors: Denizhan Pak, Donsuk Lee, Samantha M. W. Wood, Justin N. Wood
Categories: cs.AI q-bio.NC
Comments: 7 Pages. 4 figures, 1 table. This paper was accepted to the CogSci
 2023 Conference. (https://cognitivesciencesociety.org/)
\\
 Recent progress in artificial intelligence has renewed interest in building
machines that learn like animals. Almost all of the work comparing learning
across biological and artificial systems comes from studies where animals and
machines received different training data, obscuring whether differences
between animals and machines emerged from differences in learning mechanisms
versus training data. We present an experimental approach-a "newborn embodied
Turing Test"-that allows newborn animals and machines to be raised in the same
environments and tested with the same tasks, permitting direct comparison of
their learning abilities. To make this platform, we first collected
controlled-rearing data from newborn chicks, then performed "digital twin"
experiments in which machines were raised in virtual environments that mimicked
the rearing conditions of the chicks. We found that (1) machines (deep
reinforcement learning agents with intrinsic motivation) can spontaneously
develop visually guided preference behavior, akin to imprinting in newborn
chicks, and (2) machines are still far from newborn-level performance on object
recognition tasks. Almost all of the chicks developed view-invariant object
recognition, whereas the machines tended to develop view-dependent recognition.
The learning outcomes were also far more constrained in the chicks versus
machines. Ultimately, we anticipate that this approach will help researchers
develop embodied AI systems that learn like newborn animals.
\\ ( https://arxiv.org/abs/2306.05582 ,  683kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05731
Date: Fri, 9 Jun 2023 07:51:50 GMT   (16141kb,D)

Title: Multimodal Explainable Artificial Intelligence: A Comprehensive Review
 of Methodological Advances and Future Research Directions
Authors: Nikolaos Rodis, Christos Sardianos, Georgios Th. Papadopoulos,
 Panagiotis Radoglou-Grammatikis, Panagiotis Sarigiannidis and Iraklis
 Varlamis
Categories: cs.AI
Comments: 26 pages, 11 figures
\\
 The current study focuses on systematically analyzing the recent advances in
the field of Multimodal eXplainable Artificial Intelligence (MXAI). In
particular, the relevant primary prediction tasks and publicly available
datasets are initially described. Subsequently, a structured presentation of
the MXAI methods of the literature is provided, taking into account the
following criteria: a) The number of the involved modalities, b) The stage at
which explanations are produced, and c) The type of the adopted methodology
(i.e. mathematical formalism). Then, the metrics used for MXAI evaluation are
discussed. Finally, a comprehensive analysis of current challenges and future
research directions is provided.
\\ ( https://arxiv.org/abs/2306.05731 ,  16141kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05747
Date: Fri, 9 Jun 2023 08:24:56 GMT   (4608kb,D)

Title: An End-to-End Reinforcement Learning Approach for Job-Shop Scheduling
 Problems Based on Constraint Programming
Authors: Pierre Tassel, Martin Gebser, Konstantin Schekotihin
Categories: cs.AI cs.LG
Comments: To be published at ICAPS 2023
\\
 Constraint Programming (CP) is a declarative programming paradigm that allows
for modeling and solving combinatorial optimization problems, such as the
Job-Shop Scheduling Problem (JSSP). While CP solvers manage to find optimal or
near-optimal solutions for small instances, they do not scale well to large
ones, i.e., they require long computation times or yield low-quality solutions.
Therefore, real-world scheduling applications often resort to fast,
handcrafted, priority-based dispatching heuristics to find a good initial
solution and then refine it using optimization methods.
 This paper proposes a novel end-to-end approach to solving scheduling
problems by means of CP and Reinforcement Learning (RL). In contrast to
previous RL methods, tailored for a given problem by including procedural
simulation algorithms, complex feature engineering, or handcrafted reward
functions, our neural-network architecture and training algorithm merely
require a generic CP encoding of some scheduling problem along with a set of
small instances. Our approach leverages existing CP solvers to train an agent
learning a Priority Dispatching Rule (PDR) that generalizes well to large
instances, even from separate datasets. We evaluate our method on seven JSSP
datasets from the literature, showing its ability to find higher-quality
solutions for very large instances than obtained by static PDRs and by a CP
solver within the same time limit.
\\ ( https://arxiv.org/abs/2306.05747 ,  4608kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05801
Date: Fri, 9 Jun 2023 10:38:26 GMT   (336kb,D)

Title: Strategies to exploit XAI to improve classification systems
Authors: Andrea Apicella, Luca Di Lorenzo, Francesco Isgr\`o, Andrea Pollastro,
 Roberto Prevete
Categories: cs.AI
Comments: This work has been accepted to be presented to The 1st World
 Conference on eXplainable Artificial Intelligence (xAI 2023), July 26-28,
 2023 - Lisboa, Portugal
\\
 Explainable Artificial Intelligence (XAI) aims to provide insights into the
decision-making process of AI models, allowing users to understand their
results beyond their decisions. A significant goal of XAI is to improve the
performance of AI models by providing explanations for their decision-making
processes. However, most XAI literature focuses on how to explain an AI system,
while less attention has been given to how XAI methods can be exploited to
improve an AI system. In this work, a set of well-known XAI methods typically
used with Machine Learning (ML) classification tasks are investigated to verify
if they can be exploited, not just to provide explanations but also to improve
the performance of the model itself. To this aim, two strategies to use the
explanation to improve a classification system are reported and empirically
evaluated on three datasets: Fashion-MNIST, CIFAR10, and STL10. Results suggest
that explanations built by Integrated Gradients highlight input features that
can be effectively used to improve classification performance.
\\ ( https://arxiv.org/abs/2306.05801 ,  336kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06036
Date: Fri, 9 Jun 2023 17:01:51 GMT   (1473kb,D)

Title: SNeL: A Structured Neuro-Symbolic Language for Entity-Based Multimodal
 Scene Understanding
Authors: Silvan Ferreira, Allan Martins, Ivanovitch Silva
Categories: cs.AI
\\
 In the evolving landscape of artificial intelligence, multimodal and
Neuro-Symbolic paradigms stand at the forefront, with a particular emphasis on
the identification and interaction with entities and their relations across
diverse modalities. Addressing the need for complex querying and interaction in
this context, we introduce SNeL (Structured Neuro-symbolic Language), a
versatile query language designed to facilitate nuanced interactions with
neural networks processing multimodal data. SNeL's expressive interface enables
the construction of intricate queries, supporting logical and arithmetic
operators, comparators, nesting, and more. This allows users to target specific
entities, specify their properties, and limit results, thereby efficiently
extracting information from a scene. By aligning high-level symbolic reasoning
with low-level neural processing, SNeL effectively bridges the Neuro-Symbolic
divide. The language's versatility extends to a variety of data types,
including images, audio, and text, making it a powerful tool for multimodal
scene understanding. Our evaluations demonstrate SNeL's potential to reshape
the way we interact with complex neural networks, underscoring its efficacy in
driving targeted information extraction and facilitating a deeper understanding
of the rich semantics encapsulated in multimodal AI models.
\\ ( https://arxiv.org/abs/2306.06036 ,  1473kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06067
Date: Fri, 9 Jun 2023 17:43:49 GMT   (954kb,D)

Title: Combining a Meta-Policy and Monte-Carlo Planning for Scalable Type-Based
 Reasoning in Partially Observable Environments
Authors: Jonathon Schwartz, Hanna Kurniawati, Marcus Hutter
Categories: cs.AI cs.MA
Comments: 24 pages
\\
 The design of autonomous agents that can interact effectively with other
agents without prior coordination is a core problem in multi-agent systems.
Type-based reasoning methods achieve this by maintaining a belief over a set of
potential behaviours for the other agents. However, current methods are limited
in that they assume full observability of the state and actions of the other
agent or do not scale efficiently to larger problems with longer planning
horizons. Addressing these limitations, we propose Partially Observable
Type-based Meta Monte-Carlo Planning (POTMMCP) - an online Monte-Carlo Tree
Search based planning method for type-based reasoning in large partially
observable environments. POTMMCP incorporates a novel meta-policy for guiding
search and evaluating beliefs, allowing it to search more effectively to longer
horizons using less planning time. We show that our method converges to the
optimal solution in the limit and empirically demonstrate that it effectively
adapts online to diverse sets of other agents across a range of environments.
Comparisons with the state-of-the art method on problems with up to $10^{14}$
states and $10^8$ observations indicate that POTMMCP is able to compute better
solutions significantly faster.
\\ ( https://arxiv.org/abs/2306.06067 ,  954kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05442
Date: Thu, 8 Jun 2023 12:24:04 GMT   (31508kb,D)

Title: FlowFormer: A Transformer Architecture and Its Masked Cost Volume
 Autoencoding for Optical Flow
Authors: Zhaoyang Huang, Xiaoyu Shi, Chao Zhang, Qiang Wang, Yijin Li, Hongwei
 Qin, Jifeng Dai, Xiaogang Wang, and Hongsheng Li
Categories: cs.CV
Comments: arXiv admin note: substantial text overlap with arXiv:2203.16194,
 arXiv:2303.01237
\\
 This paper introduces a novel transformer-based network architecture,
FlowFormer, along with the Masked Cost Volume AutoEncoding (MCVA) for
pretraining it to tackle the problem of optical flow estimation. FlowFormer
tokenizes the 4D cost-volume built from the source-target image pair and
iteratively refines flow estimation with a cost-volume encoder-decoder
architecture. The cost-volume encoder derives a cost memory with
alternate-group transformer~(AGT) layers in a latent space and the decoder
recurrently decodes flow from the cost memory with dynamic positional cost
queries. On the Sintel benchmark, FlowFormer architecture achieves 1.16 and
2.09 average end-point-error~(AEPE) on the clean and final pass, a 16.5\% and
15.5\% error reduction from the GMA~(1.388 and 2.47). MCVA enhances FlowFormer
by pretraining the cost-volume encoder with a masked autoencoding scheme, which
further unleashes the capability of FlowFormer with unlabeled data. This is
especially critical in optical flow estimation because ground truth flows are
more expensive to acquire than labels in other vision tasks. MCVA improves
FlowFormer all-sided and FlowFormer+MCVA ranks 1st among all published methods
on both Sintel and KITTI-2015 benchmarks and achieves the best generalization
performance. Specifically, FlowFormer+MCVA achieves 1.07 and 1.94 AEPE on the
Sintel benchmark, leading to 7.76\% and 7.18\% error reductions from
FlowFormer.
\\ ( https://arxiv.org/abs/2306.05442 ,  31508kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05476
Date: Thu, 8 Jun 2023 18:01:08 GMT   (1664kb,D)

Title: A Novel Confidence Induced Class Activation Mapping for MRI Brain Tumor
 Segmentation
Authors: Yu-Jen Chen, Yiyu Shi, Tsung-Yi Ho
Categories: cs.CV
\\
 Magnetic resonance imaging (MRI) is a commonly used technique for brain tumor
segmentation, which is critical for evaluating patients and planning treatment.
To make the labeling process less laborious and dependent on expertise,
weakly-supervised semantic segmentation (WSSS) methods using class activation
mapping (CAM) have been proposed. However, current CAM-based WSSS methods
generate the object localization map using internal neural network information,
such as gradient or trainable parameters, which can lead to suboptimal
solutions. To address these issues, we propose the confidence-induced CAM
(Cfd-CAM), which calculates the weight of each feature map by using the
confidence of the target class. Our experiments on two brain tumor datasets
show that Cfd-CAM outperforms existing state-of-the-art methods under the same
level of supervision. Overall, our proposed Cfd-CAM approach improves the
accuracy of brain tumor segmentation and may provide valuable insights for
developing better WSSS methods for other medical imaging tasks.
\\ ( https://arxiv.org/abs/2306.05476 ,  1664kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05493
Date: Thu, 8 Jun 2023 18:31:56 GMT   (12044kb,D)

Title: Multi-Modal Classifiers for Open-Vocabulary Object Detection
Authors: Prannay Kaul, Weidi Xie, Andrew Zisserman
Categories: cs.CV cs.AI cs.LG
Comments: ICML 2023, project page:
 https://www.robots.ox.ac.uk/vgg/research/mm-ovod/
ACM-class: I.4.6; I.4.8; I.4.9; I.2.10
\\
 The goal of this paper is open-vocabulary object detection (OVOD)
$\unicode{x2013}$ building a model that can detect objects beyond the set of
categories seen at training, thus enabling the user to specify categories of
interest at inference without the need for model retraining. We adopt a
standard two-stage object detector architecture, and explore three ways for
specifying novel categories: via language descriptions, via image exemplars, or
via a combination of the two. We make three contributions: first, we prompt a
large language model (LLM) to generate informative language descriptions for
object classes, and construct powerful text-based classifiers; second, we
employ a visual aggregator on image exemplars that can ingest any number of
images as input, forming vision-based classifiers; and third, we provide a
simple method to fuse information from language descriptions and image
exemplars, yielding a multi-modal classifier. When evaluating on the
challenging LVIS open-vocabulary benchmark we demonstrate that: (i) our
text-based classifiers outperform all previous OVOD works; (ii) our
vision-based classifiers perform as well as text-based classifiers in prior
work; (iii) using multi-modal classifiers perform better than either modality
alone; and finally, (iv) our text-based and multi-modal classifiers yield
better performance than a fully-supervised detector.
\\ ( https://arxiv.org/abs/2306.05493 ,  12044kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05495
Date: Thu, 8 Jun 2023 18:33:12 GMT   (3594kb,D)

Title: Is Attentional Channel Processing Design Required? Comprehensive
 Analysis Of Robustness Between Vision Transformers And Fully Attentional
 Networks
Authors: Abhishri Ajit Medewar, Swanand Ashokrao Kavitkar
Categories: cs.CV cs.LG
Comments: 4 pages, 12 figures
\\
 The robustness testing has been performed for standard CNN models and Vision
Transformers, however there is a lack of comprehensive study between the
robustness of traditional Vision Transformers without an extra attentional
channel design and the latest fully attentional network(FAN) models. So in this
paper, we use the ImageNet dataset to compare the robustness of fully
attentional network(FAN) models with traditional Vision Transformers to
understand the role of an attentional channel processing design using white box
attacks and also study the transferability between the same using black box
attacks.
\\ ( https://arxiv.org/abs/2306.05495 ,  3594kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05526
Date: Thu, 8 Jun 2023 19:54:08 GMT   (33924kb,D)

Title: Learning Fine-grained View-Invariant Representations from Unpaired
 Ego-Exo Videos via Temporal Alignment
Authors: Zihui Xue, Kristen Grauman
Categories: cs.CV
Comments: Project website: https://vision.cs.utexas.edu/projects/AlignEgoExo/
\\
 The egocentric and exocentric viewpoints of a human activity look
dramatically different, yet invariant representations to link them are
essential for many potential applications in robotics and augmented reality.
Prior work is limited to learning view-invariant features from paired
synchronized viewpoints. We relax that strong data assumption and propose to
learn fine-grained action features that are invariant to the viewpoints by
aligning egocentric and exocentric videos in time, even when not captured
simultaneously or in the same environment. To this end, we propose AE2, a
self-supervised embedding approach with two key designs: (1) an object-centric
encoder that explicitly focuses on regions corresponding to hands and active
objects; (2) a contrastive-based alignment objective that leverages temporally
reversed frames as negative samples. For evaluation, we establish a benchmark
for fine-grained video understanding in the ego-exo context, comprising four
datasets -- including an ego tennis forehand dataset we collected, along with
dense per-frame labels we annotated for each dataset. On the four datasets, our
AE2 method strongly outperforms prior work in a variety of fine-grained
downstream tasks, both in regular and cross-view settings.
\\ ( https://arxiv.org/abs/2306.05526 ,  33924kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05527
Date: Thu, 8 Jun 2023 19:55:44 GMT   (11388kb,D)

Title: Teaching AI to Teach: Leveraging Limited Human Salience Data Into
 Unlimited Saliency-Based Training
Authors: Colton R. Crum, Aidan Boyd, Kevin Bowyer, Adam Czajka
Categories: cs.CV
Comments: 12 pages, 8 figures
\\
 Machine learning models have shown increased accuracy in classification tasks
when the training process incorporates human perceptual information. However, a
challenge in training human-guided models is the cost associated with
collecting image annotations for human salience. Collecting annotation data for
all images in a large training set can be prohibitively expensive. In this
work, we utilize ''teacher'' models (trained on a small amount of
human-annotated data) to annotate additional data by means of teacher models'
saliency maps. Then, ''student'' models are trained using the larger amount of
annotated training data. This approach makes it possible to supplement a
limited number of human-supplied annotations with an arbitrarily large number
of model-generated image annotations. We compare the accuracy achieved by our
teacher-student training paradigm with (1) training using all available human
salience annotations, and (2) using all available training data without human
salience annotations. We use synthetic face detection and fake iris detection
as example challenging problems, and report results across four model
architectures (DenseNet, ResNet, Xception, and Inception), and two saliency
estimation methods (CAM and RISE). Results show that our teacher-student
training paradigm results in models that significantly exceed the performance
of both baselines, demonstrating that our approach can usefully leverage a
small amount of human annotations to generate salience maps for an arbitrary
amount of additional training data.
\\ ( https://arxiv.org/abs/2306.05527 ,  11388kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05544
Date: Thu, 8 Jun 2023 20:30:55 GMT   (47274kb,D)

Title: BOOT: Data-free Distillation of Denoising Diffusion Models with
 Bootstrapping
Authors: Jiatao Gu, Shuangfei Zhai, Yizhe Zhang, Lingjie Liu, Josh Susskind
Categories: cs.CV cs.LG
Comments: In progress
\\
 Diffusion models have demonstrated excellent potential for generating diverse
images. However, their performance often suffers from slow generation due to
iterative denoising. Knowledge distillation has been recently proposed as a
remedy that can reduce the number of inference steps to one or a few without
significant quality degradation. However, existing distillation methods either
require significant amounts of offline computation for generating synthetic
training data from the teacher model or need to perform expensive online
learning with the help of real data. In this work, we present a novel technique
called BOOT, that overcomes these limitations with an efficient data-free
distillation algorithm. The core idea is to learn a time-conditioned model that
predicts the output of a pre-trained diffusion model teacher given any time
step. Such a model can be efficiently trained based on bootstrapping from two
consecutive sampled steps. Furthermore, our method can be easily adapted to
large-scale text-to-image diffusion models, which are challenging for
conventional methods given the fact that the training sets are often large and
difficult to access. We demonstrate the effectiveness of our approach on
several benchmark datasets in the DDIM setting, achieving comparable generation
quality while being orders of magnitude faster than the diffusion teacher. The
text-to-image results show that the proposed approach is able to handle highly
complex distributions, shedding light on more efficient generative modeling.
\\ ( https://arxiv.org/abs/2306.05544 ,  47274kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05553
Date: Thu, 8 Jun 2023 20:52:01 GMT   (451kb,D)

Title: Equivariant vs. Invariant Layers: A Comparison of Backbone and Pooling
 for Point Cloud Classification
Authors: Ashkan Shahbazi, Abihith Kothapalli, Xinran Liu, Robert Sheng, Soheil
 Kolouri
Categories: cs.CV cs.LG
\\
 Learning from set-structured data, such as point clouds, has gained
significant attention from the community. Geometric deep learning provides a
blueprint for designing effective set neural networks by incorporating
permutation symmetry. Of our interest are permutation invariant networks, which
are composed of a permutation equivariant backbone, permutation invariant
global pooling, and regression/classification head. While existing literature
has focused on improving permutation equivariant backbones, the impact of
global pooling is often overlooked. In this paper, we examine the interplay
between permutation equivariant backbones and permutation invariant global
pooling on three benchmark point cloud classification datasets. Our findings
reveal that: 1) complex pooling methods, such as transport-based or
attention-based poolings, can significantly boost the performance of simple
backbones, but the benefits diminish for more complex backbones, 2) even
complex backbones can benefit from pooling layers in low data scenarios, 3)
surprisingly, the choice of pooling layers can have a more significant impact
on the model's performance than adjusting the width and depth of the backbone,
and 4) pairwise combination of pooling layers can significantly improve the
performance of a fixed backbone. Our comprehensive study provides insights for
practitioners to design better permutation invariant set neural networks.
\\ ( https://arxiv.org/abs/2306.05553 ,  451kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05572
Date: Thu, 8 Jun 2023 22:07:48 GMT   (2848kb,D)

Title: Merging Deep Learning with Expert Knowledge for Seizure Onset Zone
 localization from rs-fMRI in Pediatric Pharmaco Resistant Epilepsy
Authors: Payal Kamboj, Ayan Banerjee, Sandeep K. S. Gupta and Varina L.
 Boerwinkle
Categories: cs.CV
Comments: This paper is currently under review in IEEE Journal
Report-no: ILTR-2023-2
\\
 Surgical disconnection of Seizure Onset Zones (SOZs) at an early age is an
effective treatment for Pharmaco-Resistant Epilepsy (PRE). Pre-surgical
localization of SOZs with intra-cranial EEG (iEEG) requires safe and effective
depth electrode placement. Resting-state functional Magnetic Resonance Imaging
(rs-fMRI) combined with signal decoupling using independent component (IC)
analysis has shown promising SOZ localization capability that guides iEEG lead
placement. However, SOZ ICs identification requires manual expert sorting of
100s of ICs per patient by the surgical team which limits the reproducibility
and availability of this pre-surgical screening. Automated approaches for SOZ
IC identification using rs-fMRI may use deep learning (DL) that encodes
intricacies of brain networks from scarcely available pediatric data but has
low precision, or shallow learning (SL) expert rule-based inference approaches
that are incapable of encoding the full spectrum of spatial features. This
paper proposes DeepXSOZ that exploits the synergy between DL based spatial
feature and SL based expert knowledge encoding to overcome performance
drawbacks of these strategies applied in isolation. DeepXSOZ is an
expert-in-the-loop IC sorting technique that a) can be configured to either
significantly reduce expert sorting workload or operate with high sensitivity
based on expertise of the surgical team and b) can potentially enable the usage
of rs-fMRI as a low cost outpatient pre-surgical screening tool. Comparison
with state-of-art on 52 children with PRE shows that DeepXSOZ achieves
sensitivity of 89.79%, precision of 93.6% and accuracy of 84.6%, and reduces
sorting effort by 6.7-fold. Knowledge level ablation studies show a pathway
towards maximizing patient outcomes while optimizing the machine-expert
collaboration for various scenarios.
\\ ( https://arxiv.org/abs/2306.05572 ,  2848kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05584
Date: Thu, 8 Jun 2023 22:55:32 GMT   (1517kb,D)

Title: Multi-body SE(3) Equivariance for Unsupervised Rigid Segmentation and
 Motion Estimation
Authors: Jia-Xing Zhong, Ta-Ying Cheng, Yuhang He, Kai Lu, Kaichen Zhou, Andrew
 Markham, Niki Trigoni
Categories: cs.CV cs.AI cs.LG cs.MM
\\
 A truly generalizable approach to rigid segmentation and motion estimation is
fundamental to 3D understanding of articulated objects and moving scenes. In
view of the tightly coupled relationship between segmentation and motion
estimates, we present an SE(3) equivariant architecture and a training strategy
to tackle this task in an unsupervised manner. Our architecture comprises two
lightweight and inter-connected heads that predict segmentation masks using
point-level invariant features and motion estimates from SE(3) equivariant
features without the prerequisites of category information. Our unified
training strategy can be performed online while jointly optimizing the two
predictions by exploiting the interrelations among scene flow, segmentation
mask, and rigid transformations. We show experiments on four datasets as
evidence of the superiority of our method both in terms of model performance
and computational efficiency with only 0.25M parameters and 0.92G FLOPs. To the
best of our knowledge, this is the first work designed for category-agnostic
part-level SE(3) equivariance in dynamic point clouds.
\\ ( https://arxiv.org/abs/2306.05584 ,  1517kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05612
Date: Fri, 9 Jun 2023 01:11:50 GMT   (2462kb,D)

Title: Spatial Re-parameterization for N:M Sparsity
Authors: Yuxin Zhang, Mingbao Lin, Yunshan Zhong, Mengzhao Chen, Fei Chao,
 Rongrong Ji
Categories: cs.CV
Comments: 11 pages, 4 figures
\\
 This paper presents a Spatial Re-parameterization (SpRe) method for the N:M
sparsity in CNNs. SpRe is stemmed from an observation regarding the restricted
variety in spatial sparsity present in N:M sparsity compared with unstructured
sparsity. Particularly, N:M sparsity exhibits a fixed sparsity rate within the
spatial domains due to its distinctive pattern that mandates N non-zero
components among M successive weights in the input channel dimension of
convolution filters. On the contrary, we observe that unstructured sparsity
displays a substantial divergence in sparsity across the spatial domains, which
we experimentally verified to be very crucial for its robust performance
retention compared with N:M sparsity. Therefore, SpRe employs the
spatial-sparsity distribution of unstructured sparsity to assign an extra
branch in conjunction with the original N:M branch at training time, which
allows the N:M sparse network to sustain a similar distribution of spatial
sparsity with unstructured sparsity. During inference, the extra branch can be
further re-parameterized into the main N:M branch, without exerting any
distortion on the sparse pattern or additional computation costs. SpRe has
achieved a commendable feat by matching the performance of N:M sparsity methods
with state-of-the-art unstructured sparsity methods across various benchmarks.
Code and models are anonymously available at
\url{https://github.com/zyxxmu/SpRe}.
\\ ( https://arxiv.org/abs/2306.05612 ,  2462kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05623
Date: Fri, 9 Jun 2023 02:05:40 GMT   (15207kb)

Title: Reconstructing the somatotopic organization of the corticospinal tract
 remains a challenge for modern tractography methods
Authors: Jianzhong He, Fan Zhang, Yiang Pan, Yuanjing Feng, Jarrett Rushmore,
 Erickson Torio, Yogesh Rathi, Nikos Makris, Ron Kikinis, Alexandra J.Golby,
 Lauren J.ODonnell
Categories: cs.CV
Comments: 41 pages, 19 figures
\\
 The corticospinal tract (CST) is a critically important white matter fiber
tract in the human brain that enables control of voluntary movements of the
body. Diffusion MRI tractography is the only method that enables the study of
the anatomy and variability of the CST pathway in human health. In this work,
we explored the performance of six widely used tractography methods for
reconstructing the CST and its somatotopic organization. We perform experiments
using diffusion MRI data from the Human Connectome Project. Four quantitative
measurements including reconstruction rate, the WM-GM interface coverage,
anatomical distribution of streamlines, and correlation with cortical volumes
to assess the advantages and limitations of each method. Overall, we conclude
that while current tractography methods have made progress toward the
well-known challenge of improving the reconstruction of the lateral projections
of the CST, the overall problem of performing a comprehensive CST
reconstruction, including clinically important projections in the lateral (hand
and face area) and medial portions (leg area), remains an important challenge
for diffusion MRI tractography.
\\ ( https://arxiv.org/abs/2306.05623 ,  15207kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05642
Date: Fri, 9 Jun 2023 03:02:36 GMT   (1903kb,D)

Title: Customizing General-Purpose Foundation Models for Medical Report
 Generation
Authors: Bang Yang, Asif Raza, Yuexian Zou, Tong Zhang
Categories: cs.CV cs.AI cs.CL cs.IR
Comments: 14 pages, 3 figures
\\
 Medical caption prediction which can be regarded as a task of medical report
generation (MRG), requires the automatic generation of coherent and accurate
captions for the given medical images. However, the scarcity of labelled
medical image-report pairs presents great challenges in the development of deep
and large-scale neural networks capable of harnessing the potential artificial
general intelligence power like large language models (LLMs). In this work, we
propose customizing off-the-shelf general-purpose large-scale pre-trained
models, i.e., foundation models (FMs), in computer vision and natural language
processing with a specific focus on medical report generation. Specifically,
following BLIP-2, a state-of-the-art vision-language pre-training approach, we
introduce our encoder-decoder-based MRG model. This model utilizes a
lightweight query Transformer to connect two FMs: the giant vision Transformer
EVA-ViT-g and a bilingual LLM trained to align with human intentions (referred
to as ChatGLM-6B). Furthermore, we conduct ablative experiments on the
trainable components of the model to identify the crucial factors for effective
transfer learning. Our findings demonstrate that unfreezing EVA-ViT-g to learn
medical image representations, followed by parameter-efficient training of
ChatGLM-6B to capture the writing styles of medical reports, is essential for
achieving optimal results. Our best attempt (PCLmed Team) achieved the 4th and
the 2nd, respectively, out of 13 participating teams, based on the BERTScore
and ROUGE-1 metrics, in the ImageCLEFmedical Caption 2023 Caption Prediction
Task competition.
\\ ( https://arxiv.org/abs/2306.05642 ,  1903kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05658
Date: Fri, 9 Jun 2023 03:53:12 GMT   (4236kb,D)

Title: GMS-3DQA: Projection-based Grid Mini-patch Sampling for 3D Model Quality
 Assessment
Authors: Zicheng Zhang, Wei Sun, Houning Wu, Yingjie Zhou, Chunyi Li, Xiongkuo
 Min, Guangtao Zhai, Weisi Lin
Categories: cs.CV eess.IV
\\
 Nowadays, most 3D model quality assessment (3DQA) methods have been aimed at
improving performance. However, little attention has been paid to the
computational cost and inference time required for practical applications.
Model-based 3DQA methods extract features directly from the 3D models, which
are characterized by their high degree of complexity. As a result, many
researchers are inclined towards utilizing projection-based 3DQA methods.
Nevertheless, previous projection-based 3DQA methods directly extract features
from multi-projections to ensure quality prediction accuracy, which calls for
more resource consumption and inevitably leads to inefficiency. Thus in this
paper, we address this challenge by proposing a no-reference (NR)
projection-based \textit{\underline{G}rid \underline{M}ini-patch
\underline{S}ampling \underline{3D} Model \underline{Q}uality
\underline{A}ssessment (GMS-3DQA)} method. The projection images are rendered
from six perpendicular viewpoints of the 3D model to cover sufficient quality
information. To reduce redundancy and inference resources, we propose a
multi-projection grid mini-patch sampling strategy (MP-GMS), which samples grid
mini-patches from the multi-projections and forms the sampled grid mini-patches
into one quality mini-patch map (QMM). The Swin-Transformer tiny backbone is
then used to extract quality-aware features from the QMMs. The experimental
results show that the proposed GMS-3DQA outperforms existing state-of-the-art
NR-3DQA methods on the point cloud quality assessment databases. The efficiency
analysis reveals that the proposed GMS-3DQA requires far less computational
resources and inference time than other 3DQA competitors. The code will be
available at https://github.com/zzc-1998/GMS-3DQA.
\\ ( https://arxiv.org/abs/2306.05658 ,  4236kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05663
Date: Fri, 9 Jun 2023 04:11:43 GMT   (2721kb,D)

Title: Improving LiDAR 3D Object Detection via Range-based Point Cloud Density
 Optimization
Authors: Eduardo R. Corral-Soto, Alaap Grandhi, Yannis Y. He, Mrigank Rochan,
 Bingbing Liu
Categories: cs.CV
\\
 In recent years, much progress has been made in LiDAR-based 3D object
detection mainly due to advances in detector architecture designs and
availability of large-scale LiDAR datasets. Existing 3D object detectors tend
to perform well on the point cloud regions closer to the LiDAR sensor as
opposed to on regions that are farther away. In this paper, we investigate this
problem from the data perspective instead of detector architecture design. We
observe that there is a learning bias in detection models towards the dense
objects near the sensor and show that the detection performance can be improved
by simply manipulating the input point cloud density at different distance
ranges without modifying the detector architecture and without data
augmentation. We propose a model-free point cloud density adjustment
pre-processing mechanism that uses iterative MCMC optimization to estimate
optimal parameters for altering the point density at different distance ranges.
We conduct experiments using four state-of-the-art LiDAR 3D object detectors on
two public LiDAR datasets, namely Waymo and ONCE. Our results demonstrate that
our range-based point cloud density manipulation technique can improve the
performance of the existing detectors, which in turn could potentially inspire
future detector designs.
\\ ( https://arxiv.org/abs/2306.05663 ,  2721kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05668
Date: Fri, 9 Jun 2023 04:49:31 GMT   (13109kb,D)

Title: RePaint-NeRF: NeRF Editting via Semantic Masks and Diffusion Models
Authors: Xingchen Zhou, Ying He, F. Richard Yu, Jianqiang Li, You Li
Categories: cs.CV cs.AI cs.GR
Comments: IJCAI 2023 Accepted (Main Track)
\\
 The emergence of Neural Radiance Fields (NeRF) has promoted the development
of synthesized high-fidelity views of the intricate real world. However, it is
still a very demanding task to repaint the content in NeRF. In this paper, we
propose a novel framework that can take RGB images as input and alter the 3D
content in neural scenes. Our work leverages existing diffusion models to guide
changes in the designated 3D content. Specifically, we semantically select the
target object and a pre-trained diffusion model will guide the NeRF model to
generate new 3D objects, which can improve the editability, diversity, and
application range of NeRF. Experiment results show that our algorithm is
effective for editing 3D objects in NeRF under different text prompts,
including editing appearance, shape, and more. We validate our method on both
real-world datasets and synthetic-world datasets for these editing tasks.
Please visit https://repaintnerf.github.io for a better view of our results.
\\ ( https://arxiv.org/abs/2306.05668 ,  13109kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05671
Date: Fri, 9 Jun 2023 05:01:55 GMT   (20501kb,D)

Title: Topology-Aware Uncertainty for Image Segmentation
Authors: Saumya Gupta, Yikai Zhang, Xiaoling Hu, Prateek Prasanna and Chao Chen
Categories: cs.CV
Comments: 19 pages, 13 figures, 5 tables
\\
 Segmentation of curvilinear structures such as vasculature and road networks
is challenging due to relatively weak signals and complex geometry/topology. To
facilitate and accelerate large scale annotation, one has to adopt
semi-automatic approaches such as proofreading by experts. In this work, we
focus on uncertainty estimation for such tasks, so that highly uncertain, and
thus error-prone structures can be identified for human annotators to verify.
Unlike most existing works, which provide pixel-wise uncertainty maps, we
stipulate it is crucial to estimate uncertainty in the units of topological
structures, e.g., small pieces of connections and branches. To achieve this, we
leverage tools from topological data analysis, specifically discrete Morse
theory (DMT), to first capture the structures, and then reason about their
uncertainties. To model the uncertainty, we (1) propose a joint prediction
model that estimates the uncertainty of a structure while taking the
neighboring structures into consideration (inter-structural uncertainty); (2)
propose a novel Probabilistic DMT to model the inherent uncertainty within each
structure (intra-structural uncertainty) by sampling its representations via a
perturb-and-walk scheme. On various 2D and 3D datasets, our method produces
better structure-wise uncertainty maps compared to existing works.
\\ ( https://arxiv.org/abs/2306.05671 ,  20501kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05675
Date: Fri, 9 Jun 2023 05:19:51 GMT   (17992kb,D)

Title: Illumination Controllable Dehazing Network based on Unsupervised Retinex
 Embedding
Authors: Jie Gui, Xiaofeng Cong, Lei He, Yuan Yan Tang, James Tin-Yau Kwok
Categories: cs.CV
\\
 On the one hand, the dehazing task is an illposedness problem, which means
that no unique solution exists. On the other hand, the dehazing task should
take into account the subjective factor, which is to give the user selectable
dehazed images rather than a single result. Therefore, this paper proposes a
multi-output dehazing network by introducing illumination controllable ability,
called IC-Dehazing. The proposed IC-Dehazing can change the illumination
intensity by adjusting the factor of the illumination controllable module,
which is realized based on the interpretable Retinex theory. Moreover, the
backbone dehazing network of IC-Dehazing consists of a Transformer with double
decoders for high-quality image restoration. Further, the prior-based loss
function and unsupervised training strategy enable IC-Dehazing to complete the
parameter learning process without the need for paired data. To demonstrate the
effectiveness of the proposed IC-Dehazing, quantitative and qualitative
experiments are conducted on image dehazing, semantic segmentation, and object
detection tasks. Code is available at
https://github.com/Xiaofeng-life/ICDehazing.
\\ ( https://arxiv.org/abs/2306.05675 ,  17992kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05682
Date: Fri, 9 Jun 2023 05:51:40 GMT   (2686kb,D)

Title: Lightweight Monocular Depth Estimation via Token-Sharing Transformer
Authors: Dong-Jae Lee, Jae Young Lee, Hyounguk Shon, Eojindl Yi, Yeong-Hun
 Park, Sung-Sik Cho, Junmo Kim
Categories: cs.CV cs.AI cs.LG cs.RO eess.IV
Comments: ICRA 2023
\\
 Depth estimation is an important task in various robotics systems and
applications. In mobile robotics systems, monocular depth estimation is
desirable since a single RGB camera can be deployable at a low cost and compact
size. Due to its significant and growing needs, many lightweight monocular
depth estimation networks have been proposed for mobile robotics systems. While
most lightweight monocular depth estimation methods have been developed using
convolution neural networks, the Transformer has been gradually utilized in
monocular depth estimation recently. However, massive parameters and large
computational costs in the Transformer disturb the deployment to embedded
devices. In this paper, we present a Token-Sharing Transformer (TST), an
architecture using the Transformer for monocular depth estimation, optimized
especially in embedded devices. The proposed TST utilizes global token sharing,
which enables the model to obtain an accurate depth prediction with high
throughput in embedded devices. Experimental results show that TST outperforms
the existing lightweight monocular depth estimation methods. On the NYU Depth
v2 dataset, TST can deliver depth maps up to 63.4 FPS in NVIDIA Jetson nano and
142.6 FPS in NVIDIA Jetson TX2, with lower errors than the existing methods.
Furthermore, TST achieves real-time depth estimation of high-resolution images
on Jetson TX2 with competitive results.
\\ ( https://arxiv.org/abs/2306.05682 ,  2686kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05688
Date: Fri, 9 Jun 2023 06:00:05 GMT   (3307kb,D)

Title: ModeT: Learning Deformable Image Registration via Motion Decomposition
 Transformer
Authors: Haiqiao Wang, Dong Ni, and Yi Wang
Categories: cs.CV
Comments: Early accepted by MICCAI 2023
\\
 The Transformer structures have been widely used in computer vision and have
recently made an impact in the area of medical image registration. However, the
use of Transformer in most registration networks is straightforward. These
networks often merely use the attention mechanism to boost the feature learning
as the segmentation networks do, but do not sufficiently design to be adapted
for the registration task. In this paper, we propose a novel motion
decomposition Transformer (ModeT) to explicitly model multiple motion
modalities by fully exploiting the intrinsic capability of the Transformer
structure for deformation estimation. The proposed ModeT naturally transforms
the multi-head neighborhood attention relationship into the multi-coordinate
relationship to model multiple motion modes. Then the competitive weighting
module (CWM) fuses multiple deformation sub-fields to generate the resulting
deformation field. Extensive experiments on two public brain magnetic resonance
imaging (MRI) datasets show that our method outperforms current
state-of-the-art registration networks and Transformers, demonstrating the
potential of our ModeT for the challenging non-rigid deformation estimation
problem. The benchmarks and our code are publicly available at
https://github.com/ZAX130/SmileCode.
\\ ( https://arxiv.org/abs/2306.05688 ,  3307kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05689
Date: Fri, 9 Jun 2023 06:02:01 GMT   (1928kb,D)

Title: Single-Stage Visual Relationship Learning using Conditional Queries
Authors: Alakh Desai, Tz-Ying Wu, Subarna Tripathi, Nuno Vasconcelos
Categories: cs.CV
Comments: Accepted to NeurIPS 2022
\\
 Research in scene graph generation (SGG) usually considers two-stage models,
that is, detecting a set of entities, followed by combining them and labeling
all possible relationships. While showing promising results, the pipeline
structure induces large parameter and computation overhead, and typically
hinders end-to-end optimizations. To address this, recent research attempts to
train single-stage models that are computationally efficient. With the advent
of DETR, a set based detection model, one-stage models attempt to predict a set
of subject-predicate-object triplets directly in a single shot. However, SGG is
inherently a multi-task learning problem that requires modeling entity and
predicate distributions simultaneously. In this paper, we propose Transformers
with conditional queries for SGG, namely, TraCQ with a new formulation for SGG
that avoids the multi-task learning problem and the combinatorial entity pair
distribution. We employ a DETR-based encoder-decoder design and leverage
conditional queries to significantly reduce the entity label space as well,
which leads to 20% fewer parameters compared to state-of-the-art single-stage
models. Experimental results show that TraCQ not only outperforms existing
single-stage scene graph generation methods, it also beats many
state-of-the-art two-stage methods on the Visual Genome dataset, yet is capable
of end-to-end training and faster inference.
\\ ( https://arxiv.org/abs/2306.05689 ,  1928kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05691
Date: Fri, 9 Jun 2023 06:10:59 GMT   (4780kb,D)

Title: DIFT: Dynamic Iterative Field Transforms for Memory Efficient Optical
 Flow
Authors: Risheek Garrepalli, Jisoo Jeong, Rajeswaran C Ravindran, Jamie Menjay
 Lin and Fatih Porikli
Categories: cs.CV
Comments: CVPR MAI 2023 Accepted Paper
\\
 Recent advancements in neural network-based optical flow estimation often
come with prohibitively high computational and memory requirements, presenting
challenges in their model adaptation for mobile and low-power use cases. In
this paper, we introduce a lightweight low-latency and memory-efficient model,
Dynamic Iterative Field Transforms (DIFT), for optical flow estimation feasible
for edge applications such as mobile, XR, micro UAVs, robotics and cameras.
DIFT follows an iterative refinement framework leveraging variable resolution
of cost volumes for correspondence estimation. We propose a memory efficient
solution for cost volume processing to reduce peak memory. Also, we present a
novel dynamic coarse-to-fine cost volume processing during various stages of
refinement to avoid multiple levels of cost volumes. We demonstrate first
real-time cost-volume based optical flow DL architecture on Snapdragon 8 Gen 1
HTP efficient mobile AI accelerator with 32 inf/sec and 5.89 EPE (endpoint
error) on KITTI with manageable accuracy-performance tradeoffs.
\\ ( https://arxiv.org/abs/2306.05691 ,  4780kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05704
Date: Fri, 9 Jun 2023 06:50:20 GMT   (18148kb,D)

Title: Exploring Effective Mask Sampling Modeling for Neural Image Compression
Authors: Lin Liu, Mingming Zhao, Shanxin Yuan, Wenlong Lyu, Wengang Zhou,
 Houqiang Li, Yanfeng Wang, Qi Tian
Categories: cs.CV cs.MM eess.IV
Comments: 10 pages
\\
 Image compression aims to reduce the information redundancy in images. Most
existing neural image compression methods rely on side information from
hyperprior or context models to eliminate spatial redundancy, but rarely
address the channel redundancy. Inspired by the mask sampling modeling in
recent self-supervised learning methods for natural language processing and
high-level vision, we propose a novel pretraining strategy for neural image
compression. Specifically, Cube Mask Sampling Module (CMSM) is proposed to
apply both spatial and channel mask sampling modeling to image compression in
the pre-training stage. Moreover, to further reduce channel redundancy, we
propose the Learnable Channel Mask Module (LCMM) and the Learnable Channel
Completion Module (LCCM). Our plug-and-play CMSM, LCMM, LCCM modules can apply
to both CNN-based and Transformer-based architectures, significantly reduce the
computational cost, and improve the quality of images. Experiments on the
public Kodak and Tecnick datasets demonstrate that our method achieves
competitive performance with lower computational complexity compared to
state-of-the-art image compression methods.
\\ ( https://arxiv.org/abs/2306.05704 ,  18148kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05705
Date: Fri, 9 Jun 2023 06:54:58 GMT   (3230kb,D)

Title: On the Challenges and Perspectives of Foundation Models for Medical
 Image Analysis
Authors: Shaoting Zhang, Dimitris Metaxas
Categories: cs.CV
\\
 This article discusses the opportunities, applications and future directions
of large-scale pre-trained models, i.e., foundation models, for analyzing
medical images. Medical foundation models have immense potential in solving a
wide range of downstream tasks, as they can help to accelerate the development
of accurate and robust models, reduce the large amounts of required labeled
data, preserve the privacy and confidentiality of patient data. Specifically,
we illustrate the "spectrum" of medical foundation models, ranging from general
vision models, modality-specific models, to organ/task-specific models,
highlighting their challenges, opportunities and applications. We also discuss
how foundation models can be leveraged in downstream medical tasks to enhance
the accuracy and efficiency of medical image analysis, leading to more precise
diagnosis and treatment decisions.
\\ ( https://arxiv.org/abs/2306.05705 ,  3230kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05718
Date: Fri, 9 Jun 2023 07:30:10 GMT   (5359kb,D)

Title: Learning Domain-Aware Detection Head with Prompt Tuning
Authors: Haochen Li, Rui Zhang, Hantao Yao, Xinkai Song, Yifan Hao, Yongwei
 Zhao, Ling Li and Yunji Chen
Categories: cs.CV
\\
 Domain adaptive object detection (DAOD) aims to generalize detectors trained
on an annotated source domain to an unlabelled target domain. However, existing
methods focus on reducing the domain bias of the detection backbone by
inferring a discriminative visual encoder, while ignoring the domain bias in
the detection head. Inspired by the high generalization of vision-language
models (VLMs), applying a VLM as the robust detection backbone following a
domain-aware detection head is a reasonable way to learn the discriminative
detector for each domain, rather than reducing the domain bias in traditional
methods. To achieve the above issue, we thus propose a novel DAOD framework
named Domain-Aware detection head with Prompt tuning (DA-Pro), which applies
the learnable domain-adaptive prompt to generate the dynamic detection head for
each domain. Formally, the domain-adaptive prompt consists of the
domain-invariant tokens, domain-specific tokens, and the domain-related textual
description along with the class label. Furthermore, two constraints between
the source and target domains are applied to ensure that the domain-adaptive
prompt can capture the domains-shared and domain-specific knowledge. A prompt
ensemble strategy is also proposed to reduce the effect of prompt disturbance.
Comprehensive experiments over multiple cross-domain adaptation tasks
demonstrate that using the domain-adaptive prompt can produce an effectively
domain-related detection head for boosting domain-adaptive object detection.
\\ ( https://arxiv.org/abs/2306.05718 ,  5359kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05720
Date: Fri, 9 Jun 2023 07:34:34 GMT   (22386kb,D)

Title: Beyond Surface Statistics: Scene Representations in a Latent Diffusion
 Model
Authors: Yida Chen, Fernanda Vi\'egas, Martin Wattenberg
Categories: cs.CV cs.AI cs.LG
Comments: 17 pages, 13 figures
\\
 Latent diffusion models (LDMs) exhibit an impressive ability to produce
realistic images, yet the inner workings of these models remain mysterious.
Even when trained purely on images without explicit depth information, they
typically output coherent pictures of 3D scenes. In this work, we investigate a
basic interpretability question: does an LDM create and use an internal
representation of simple scene geometry? Using linear probes, we find evidence
that the internal activations of the LDM encode linear representations of both
3D depth data and a salient-object / background distinction. These
representations appear surprisingly early in the denoising process$-$well
before a human can easily make sense of the noisy images. Intervention
experiments further indicate these representations play a causal role in image
synthesis, and may be used for simple high-level editing of an LDM's output.
\\ ( https://arxiv.org/abs/2306.05720 ,  22386kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05749
Date: Fri, 9 Jun 2023 08:29:15 GMT   (37251kb,D)

Title: DocAligner: Annotating Real-world Photographic Document Images by Simply
 Taking Pictures
Authors: Jiaxin Zhang, Bangdong Chen, Hiuyi Cheng, Lianwen Jin, Fengjun Guo,
 Kai Ding
Categories: cs.CV
\\
 Recently, there has been a growing interest in research concerning document
image analysis and recognition in photographic scenarios. However, the lack of
labeled datasets for this emerging challenge poses a significant obstacle, as
manual annotation can be time-consuming and impractical. To tackle this issue,
we present DocAligner, a novel method that streamlines the manual annotation
process to a simple step of taking pictures. DocAligner achieves this by
establishing dense correspondence between photographic document images and
their clean counterparts. It enables the automatic transfer of existing
annotations in clean document images to photographic ones and helps to
automatically acquire labels that are unavailable through manual labeling.
Considering the distinctive characteristics of document images, DocAligner
incorporates several innovative features. First, we propose a non-rigid
pre-alignment technique based on the document's edges, which effectively
eliminates interference caused by significant global shifts and repetitive
patterns present in document images. Second, to handle large shifts and ensure
high accuracy, we introduce a hierarchical aligning approach that combines
global and local correlation layers. Furthermore, considering the importance of
fine-grained elements in document images, we present a details recurrent
refinement module to enhance the output in a high-resolution space. To train
DocAligner, we construct a synthetic dataset and introduce a self-supervised
learning approach to enhance its robustness for real-world data. Through
extensive experiments, we demonstrate the effectiveness of DocAligner and the
acquired dataset. Datasets and codes will be publicly available.
\\ ( https://arxiv.org/abs/2306.05749 ,  37251kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05772
Date: Fri, 9 Jun 2023 09:25:48 GMT   (207kb,D)

Title: A Boosted Model Ensembling Approach to Ball Action Spotting in Videos:
 The Runner-Up Solution to CVPR'23 SoccerNet Challenge
Authors: Luping Wang, Hao Guo, Bin Liu
Categories: cs.CV
Comments: 4 pages
\\
 This technical report presents our solution to Ball Action Spotting in
videos. Our method reached second place in the CVPR'23 SoccerNet Challenge.
Details of this challenge can be found at
https://www.soccer-net.org/tasks/ball-action-spotting. Our approach is
developed based on a baseline model termed E2E-Spot, which was provided by the
organizer of this competition. We first generated several variants of the
E2E-Spot model, resulting in a candidate model set. We then proposed a strategy
for selecting appropriate model members from this set and assigning an
appropriate weight to each model. The aim of this strategy is to boost the
performance of the resulting model ensemble. Therefore, we call our approach
Boosted Model Ensembling (BME). Our code is available at
https://github.com/ZJLAB-AMMI/E2E-Spot-MBS.
\\ ( https://arxiv.org/abs/2306.05772 ,  207kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05807
Date: Fri, 9 Jun 2023 10:44:44 GMT   (1020kb,D)

Title: A Dual-Source Attention Transformer for Multi-Person Pose Tracking
Authors: Andreas Doering and Juergen Gall
Categories: cs.CV
\\
 Multi-person pose tracking is an important element for many applications and
requires to estimate the human poses of all persons in a video and to track
them over time. The association of poses across frames remains an open research
problem, in particular for online tracking methods, due to motion blur, crowded
scenes and occlusions. To tackle the association challenge, we propose a
Dual-Source Attention Transformer that incorporates three core aspects: i) In
order to re-identify persons that have been occluded, we propose a
pose-conditioned re-identification network that provides an initial embedding
and allows to match persons even if the number of visible joints differs
between the frames. ii) We incorporate edge embeddings based on temporal pose
similarity and the impact of appearance and pose similarity is automatically
adapted. iii) We propose an attention based matching layer for pose-to-track
association and duplicate removal. We evaluate our approach on Market1501,
PoseTrack 2018 and PoseTrack21.
\\ ( https://arxiv.org/abs/2306.05807 ,  1020kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05832
Date: Fri, 9 Jun 2023 12:04:13 GMT   (6003kb,D)

Title: Sketch Beautification: Learning Part Beautification and Structure
 Refinement for Sketches of Man-made Objects
Authors: Deng Yu, Manfred Lau, Lin Gao, Hongbo Fu
Categories: cs.CV cs.GR
Comments: 13 figures
\\
 We present a novel freehand sketch beautification method, which takes as
input a freely drawn sketch of a man-made object and automatically beautifies
it both geometrically and structurally. Beautifying a sketch is challenging
because of its highly abstract and heavily diverse drawing manner. Existing
methods are usually confined to the distribution of their limited training
samples and thus cannot beautify freely drawn sketches with rich variations. To
address this challenge, we adopt a divide-and-combine strategy. Specifically,
we first parse an input sketch into semantic components, beautify individual
components by a learned part beautification module based on part-level implicit
manifolds, and then reassemble the beautified components through a structure
beautification module. With this strategy, our method can go beyond the
training samples and handle novel freehand sketches. We demonstrate the
effectiveness of our system with extensive experiments and a perceptive study.
\\ ( https://arxiv.org/abs/2306.05832 ,  6003kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05844
Date: Fri, 9 Jun 2023 12:18:14 GMT   (3723kb,D)

Title: How Object Information Improves Skeleton-based Human Action Recognition
 in Assembly Tasks
Authors: Dustin Aganian, Mona K\"ohler, Sebastian Baake, Markus Eisenbach, and
 Horst-Michael Gross
Categories: cs.CV cs.LG cs.RO
Comments: IEEE International Joint Conference on Neural Networks (IJCNN) 2023
\\
 As the use of collaborative robots (cobots) in industrial manufacturing
continues to grow, human action recognition for effective human-robot
collaboration becomes increasingly important. This ability is crucial for
cobots to act autonomously and assist in assembly tasks. Recently,
skeleton-based approaches are often used as they tend to generalize better to
different people and environments. However, when processing skeletons alone,
information about the objects a human interacts with is lost. Therefore, we
present a novel approach of integrating object information into skeleton-based
action recognition. We enhance two state-of-the-art methods by treating object
centers as further skeleton joints. Our experiments on the assembly dataset
IKEA ASM show that our approach improves the performance of these
state-of-the-art methods to a large extent when combining skeleton joints with
objects predicted by a state-of-the-art instance segmentation model. Our
research sheds light on the benefits of combining skeleton joints with object
information for human action recognition in assembly tasks. We analyze the
effect of the object detector on the combination for action classification and
discuss the important factors that must be taken into account.
\\ ( https://arxiv.org/abs/2306.05844 ,  3723kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05846
Date: Fri, 9 Jun 2023 12:18:48 GMT   (5400kb,D)

Title: Motion-DVAE: Unsupervised learning for fast human motion denoising
Authors: Gu\'enol\'e Fiche, Simon Leglaive, Xavier Alameda-Pineda, Renaud
 S\'eguier
Categories: cs.CV cs.AI
\\
 Pose and motion priors are crucial for recovering realistic and accurate
human motion from noisy observations. Substantial progress has been made on
pose and shape estimation from images, and recent works showed impressive
results using priors to refine frame-wise predictions. However, a lot of motion
priors only model transitions between consecutive poses and are used in
time-consuming optimization procedures, which is problematic for many
applications requiring real-time motion capture. We introduce Motion-DVAE, a
motion prior to capture the short-term dependencies of human motion. As part of
the dynamical variational autoencoder (DVAE) models family, Motion-DVAE
combines the generative capability of VAE models and the temporal modeling of
recurrent architectures. Together with Motion-DVAE, we introduce an
unsupervised learned denoising method unifying regression- and
optimization-based approaches in a single framework for real-time 3D human pose
estimation. Experiments show that the proposed approach reaches competitive
performance with state-of-the-art methods while being much faster.
\\ ( https://arxiv.org/abs/2306.05846 ,  5400kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05872
Date: Fri, 9 Jun 2023 13:08:34 GMT   (29537kb,D)

Title: Neural Haircut: Prior-Guided Strand-Based Hair Reconstruction
Authors: Vanessa Sklyarova (1), Jenya Chelishev (2), Andreea Dogaru (3), Igor
 Medvedev (1), Victor Lempitsky (4), Egor Zakharov (1) ((1) Samsung AI Center,
 (2) Rockstar Games, (3) FAU Erlangen-N\"urnberg, (4) Cinemersive Labs)
Categories: cs.CV cs.GR
\\
 Generating realistic human 3D reconstructions using image or video data is
essential for various communication and entertainment applications. While
existing methods achieved impressive results for body and facial regions,
realistic hair modeling still remains challenging due to its high mechanical
complexity. This work proposes an approach capable of accurate hair geometry
reconstruction at a strand level from a monocular video or multi-view images
captured in uncontrolled lighting conditions. Our method has two stages, with
the first stage performing joint reconstruction of coarse hair and bust shapes
and hair orientation using implicit volumetric representations. The second
stage then estimates a strand-level hair reconstruction by reconciling in a
single optimization process the coarse volumetric constraints with hair strand
and hairstyle priors learned from the synthetic data. To further increase the
reconstruction fidelity, we incorporate image-based losses into the fitting
process using a new differentiable renderer. The combined system, named Neural
Haircut, achieves high realism and personalization of the reconstructed
hairstyles.
\\ ( https://arxiv.org/abs/2306.05872 ,  29537kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05888
Date: Fri, 9 Jun 2023 13:31:50 GMT   (253kb,D)

Title: TrajectoryFormer: 3D Object Tracking Transformer with Predictive
 Trajectory Hypotheses
Authors: Xuesong Chen, Shaoshuai Shi, Chao Zhang, Benjin Zhu, Qiang Wang, Ka
 Chun Cheung, Simon See, Hongsheng Li
Categories: cs.CV
Comments: 10 pages, 3 figures
\\
 3D multi-object tracking (MOT) is vital for many applications including
autonomous driving vehicles and service robots. With the commonly used
tracking-by-detection paradigm, 3D MOT has made important progress in recent
years. However, these methods only use the detection boxes of the current frame
to obtain trajectory-box association results, which makes it impossible for the
tracker to recover objects missed by the detector. In this paper, we present
TrajectoryFormer, a novel point-cloud-based 3D MOT framework. To recover the
missed object by detector, we generates multiple trajectory hypotheses with
hybrid candidate boxes, including temporally predicted boxes and current-frame
detection boxes, for trajectory-box association. The predicted boxes can
propagate object's history trajectory information to the current frame and thus
the network can tolerate short-term miss detection of the tracked objects. We
combine long-term object motion feature and short-term object appearance
feature to create per-hypothesis feature embedding, which reduces the
computational overhead for spatial-temporal encoding. Additionally, we
introduce a Global-Local Interaction Module to conduct information interaction
among all hypotheses and models their spatial relations, leading to accurate
estimation of hypotheses. Our TrajectoryFormer achieves state-of-the-art
performance on the Waymo 3D MOT benchmarks.
\\ ( https://arxiv.org/abs/2306.05888 ,  253kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05911
Date: Fri, 9 Jun 2023 14:05:41 GMT   (21334kb,D)

Title: Sketch2Stress: Sketching with Structural Stress Awareness
Authors: Deng Yu, Chufeng Xiao, Manfred Lau, and Hongbo Fu
Categories: cs.CV cs.GR
Comments: 16 figures
\\
 In the process of product design and digital fabrication, the structural
analysis of a designed prototype is a fundamental and essential step. However,
such a step is usually invisible or inaccessible to designers at the early
sketching phase. This limits the user's ability to consider a shape's physical
properties and structural soundness. To bridge this gap, we introduce a novel
approach Sketch2Stress that allows users to perform structural analysis of
desired objects at the sketching stage. This method takes as input a 2D
freehand sketch and one or multiple locations of user-assigned external forces.
With the specially-designed two-branch generative-adversarial framework, it
automatically predicts a normal map and a corresponding structural stress map
distributed over the user-sketched underlying object. In this way, our method
empowers designers to easily examine the stress sustained everywhere and
identify potential problematic regions of their sketched object. Furthermore,
combined with the predicted normal map, users are able to conduct a region-wise
structural analysis efficiently by aggregating the stress effects of multiple
forces in the same direction. Finally, we demonstrate the effectiveness and
practicality of our system with extensive experiments and user studies.
\\ ( https://arxiv.org/abs/2306.05911 ,  21334kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05957
Date: Fri, 9 Jun 2023 15:17:13 GMT   (40250kb,D)

Title: DDLP: Unsupervised Object-Centric Video Prediction with Deep Dynamic
 Latent Particles
Authors: Tal Daniel, Aviv Tamar
Categories: cs.CV cs.LG
Comments: Project site: https://taldatech.github.io/ddlp-web
\\
 We propose a new object-centric video prediction algorithm based on the deep
latent particle (DLP) representation. In comparison to existing slot- or
patch-based representations, DLPs model the scene using a set of keypoints with
learned parameters for properties such as position and size, and are both
efficient and interpretable. Our method, deep dynamic latent particles (DDLP),
yields state-of-the-art object-centric video prediction results on several
challenging datasets. The interpretable nature of DDLP allows us to perform
``what-if'' generation -- predict the consequence of changing properties of
objects in the initial frames, and DLP's compact structure enables efficient
diffusion-based unconditional video generation. Videos, code and pre-trained
models are available: https://taldatech.github.io/ddlp-web
\\ ( https://arxiv.org/abs/2306.05957 ,  40250kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05963
Date: Fri, 9 Jun 2023 15:29:54 GMT   (4316kb,D)

Title: Adaptive Contextual Perception: How to Generalize to New Backgrounds and
 Ambiguous Objects
Authors: Zhuofan Ying, Peter Hase, Mohit Bansal
Categories: cs.CV cs.AI cs.LG
Comments: 21 pages, 12 figures. Our code is available at
 https://github.com/zfying/AdaptiveContext
\\
 Biological vision systems make adaptive use of context to recognize objects
in new settings with novel contexts as well as occluded or blurry objects in
familiar settings. In this paper, we investigate how vision models adaptively
use context for out-of-distribution (OOD) generalization and leverage our
analysis results to improve model OOD generalization. First, we formulate two
distinct OOD settings where the contexts are either irrelevant
(Background-Invariance) or beneficial (Object-Disambiguation), reflecting the
diverse contextual challenges faced in biological vision. We then analyze model
performance in these two different OOD settings and demonstrate that models
that excel in one setting tend to struggle in the other. Notably, prior works
on learning causal features improve on one setting but hurt in the other. This
underscores the importance of generalizing across both OOD settings, as this
ability is crucial for both human cognition and robust AI systems. Next, to
better understand the model properties contributing to OOD generalization, we
use representational geometry analysis and our own probing methods to examine a
population of models, and we discover that those with more factorized
representations and appropriate feature weighting are more successful in
handling Background-Invariance and Object-Disambiguation tests. We further
validate these findings through causal intervention on representation
factorization and feature weighting to demonstrate their causal effect on
performance. Lastly, we propose new augmentation methods to enhance model
generalization. These methods outperform strong baselines, yielding
improvements in both in-distribution and OOD tests. In conclusion, to replicate
the generalization abilities of biological vision, computer vision models must
have factorized object vs. background representations and appropriately weight
both kinds of features.
\\ ( https://arxiv.org/abs/2306.05963 ,  4316kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05978
Date: Fri, 9 Jun 2023 15:45:23 GMT   (1087kb)

Title: 3D objects and scenes classification, recognition, segmentation, and
 reconstruction using 3D point cloud data: A review
Authors: Omar Elharrouss, Kawther Hassine, Ayman Zayyan, Zakariyae Chatri, Noor
 almaadeed, Somaya Al-Maadeed and Khalid Abualsaud
Categories: cs.CV
\\
 Three-dimensional (3D) point cloud analysis has become one of the attractive
subjects in realistic imaging and machine visions due to its simplicity,
flexibility and powerful capacity of visualization. Actually, the
representation of scenes and buildings using 3D shapes and formats leveraged
many applications among which automatic driving, scenes and objects
reconstruction, etc. Nevertheless, working with this emerging type of data has
been a challenging task for objects representation, scenes recognition,
segmentation, and reconstruction. In this regard, a significant effort has
recently been devoted to developing novel strategies, using different
techniques such as deep learning models. To that end, we present in this paper
a comprehensive review of existing tasks on 3D point cloud: a well-defined
taxonomy of existing techniques is performed based on the nature of the adopted
algorithms, application scenarios, and main objectives. Various tasks performed
on 3D point could data are investigated, including objects and scenes
detection, recognition, segmentation and reconstruction. In addition, we
introduce a list of used datasets, we discuss respective evaluation metrics and
we compare the performance of existing solutions to better inform the
state-of-the-art and identify their limitations and strengths. Lastly, we
elaborate on current challenges facing the subject of technology and future
trends attracting considerable interest, which could be a starting point for
upcoming research studies
\\ ( https://arxiv.org/abs/2306.05978 ,  1087kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05980
Date: Fri, 9 Jun 2023 15:46:42 GMT   (944kb,D)

Title: Federated Learning for Medical Image Analysis: A Survey
Authors: Hao Guan, Mingxia Liu
Categories: cs.CV eess.IV
Comments: 19 pages, 6 figures
\\
 Machine learning in medical imaging often faces a fundamental dilemma, namely
the small sample size problem. Many recent studies suggest using multi-domain
data pooled from different acquisition sites/datasets to improve statistical
power. However, medical images from different sites cannot be easily shared to
build large datasets for model training due to privacy protection reasons. As a
promising solution, federated learning, which enables collaborative training of
machine learning models based on data from different sites without cross-site
data sharing, has attracted considerable attention recently. In this paper, we
conduct a comprehensive survey of the recent development of federated learning
methods in medical image analysis. We first introduce the background and
motivation of federated learning for dealing with privacy protection and
collaborative learning issues in medical imaging. We then present a
comprehensive review of recent advances in federated learning methods for
medical image analysis. Specifically, existing methods are categorized based on
three critical aspects of a federated learning system, including client end,
server end, and communication techniques. In each category, we summarize the
existing federated learning methods according to specific research problems in
medical image analysis and also provide insights into the motivations of
different approaches. In addition, we provide a review of existing benchmark
medical imaging datasets and software platforms for current federated learning
research. We also conduct an experimental study to empirically evaluate typical
federated learning methods for medical image analysis. This survey can help to
better understand the current research status, challenges and potential
research opportunities in this promising research field.
\\ ( https://arxiv.org/abs/2306.05980 ,  944kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05985
Date: Fri, 9 Jun 2023 15:53:01 GMT   (11412kb)

Title: Beyond Detection: Visual Realism Assessment of Deepfakes
Authors: Luka Dragar, Peter Peer, Vitomir \v{S}truc, Borut Batagelj
Categories: cs.CV
\\
 In the era of rapid digitalization and artificial intelligence advancements,
the development of DeepFake technology has posed significant security and
privacy concerns. This paper presents an effective measure to assess the visual
realism of DeepFake videos. We utilize an ensemble of two Convolutional Neural
Network (CNN) models: Eva and ConvNext. These models have been trained on the
DeepFake Game Competition (DFGC) 2022 dataset and aim to predict Mean Opinion
Scores (MOS) from DeepFake videos based on features extracted from sequences of
frames. Our method secured the third place in the recent DFGC on Visual Realism
Assessment held in conjunction with the 2023 International Joint Conference on
Biometrics (IJCB 2023). We provide an over\-view of the models, data
preprocessing, and training procedures. We also report the performance of our
models against the competition's baseline model and discuss the implications of
our findings.
\\ ( https://arxiv.org/abs/2306.05985 ,  11412kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06010
Date: Fri, 9 Jun 2023 16:27:14 GMT   (22453kb,D)

Title: Benchmarking self-supervised video representation learning
Authors: Akash Kumar, Ashlesha Kumar, Vibhav Vineet, Yogesh Singh Rawat
Categories: cs.CV
\\
 Self-supervised learning is an effective way for label-free model
pre-training, especially in the video domain where labeling is expensive.
Existing self-supervised works in the video domain use varying experimental
setups to demonstrate their effectiveness and comparison across approaches
becomes challenging with no standard benchmark. In this work, we first provide
a benchmark that enables a comparison of existing approaches on the same
ground. Next, we study five different aspects of self-supervised learning
important for videos; 1) dataset size, 2) complexity, 3) data distribution, 4)
data noise, and, 5)feature analysis. To facilitate this study, we focus on
seven different methods along with seven different network architectures and
perform an extensive set of experiments on 5 different datasets with an
evaluation of two different downstream tasks. We present several interesting
insights from this study which span across different properties of pretraining
and target datasets, pretext-tasks, and model architectures among others. We
further put some of these insights to the real test and propose an approach
that requires a limited amount of training data and outperforms existing
state-of-the-art approaches which use 10x pretraining data. We believe this
work will pave the way for researchers to a better understanding of
self-supervised pretext tasks in video representation learning.
\\ ( https://arxiv.org/abs/2306.06010 ,  22453kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06023
Date: Fri, 9 Jun 2023 16:42:00 GMT   (13688kb,D)

Title: DetZero: Rethinking Offboard 3D Object Detection with Long-term
 Sequential Point Clouds
Authors: Tao Ma, Xuemeng Yang, Hongbin Zhou, Xin Li, Botian Shi, Junjie Liu,
 Yuchen Yang, Zhizheng Liu, Liang He, Yu Qiao, Yikang Li, Hongsheng Li
Categories: cs.CV
Comments: 17 pages, 8 figures
\\
 Existing offboard 3D detectors always follow a modular pipeline design to
take advantage of unlimited sequential point clouds. We have found that the
full potential of offboard 3D detectors is not explored mainly due to two
reasons: (1) the onboard multi-object tracker cannot generate sufficient
complete object trajectories, and (2) the motion state of objects poses an
inevitable challenge for the object-centric refining stage in leveraging the
long-term temporal context representation. To tackle these problems, we propose
a novel paradigm of offboard 3D object detection, named DetZero. Concretely, an
offline tracker coupled with a multi-frame detector is proposed to focus on the
completeness of generated object tracks. An attention-mechanism refining module
is proposed to strengthen contextual information interaction across long-term
sequential point clouds for object refining with decomposed regression methods.
Extensive experiments on Waymo Open Dataset show our DetZero outperforms all
state-of-the-art onboard and offboard 3D detection methods. Notably, DetZero
ranks 1st place on Waymo 3D object detection leaderboard with 85.15 mAPH (L2)
detection performance. Further experiments validate the application of taking
the place of human labels with such high-quality results. Our empirical study
leads to rethinking conventions and interesting findings that can guide future
research on offboard 3D object detection.
\\ ( https://arxiv.org/abs/2306.06023 ,  13688kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06044
Date: Fri, 9 Jun 2023 17:12:35 GMT   (9610kb,D)

Title: GANeRF: Leveraging Discriminators to Optimize Neural Radiance Fields
Authors: Barbara Roessle, Norman M\"uller, Lorenzo Porzi, Samuel Rota Bul\`o,
 Peter Kontschieder, Matthias Nie{\ss}ner
Categories: cs.CV cs.GR eess.IV
Comments: Video: https://youtu.be/EUWW8nUxpl0
\\
 Neural Radiance Fields (NeRF) have shown impressive novel view synthesis
results; nonetheless, even thorough recordings yield imperfections in
reconstructions, for instance due to poorly observed areas or minor lighting
changes. Our goal is to mitigate these imperfections from various sources with
a joint solution: we take advantage of the ability of generative adversarial
networks (GANs) to produce realistic images and use them to enhance realism in
3D scene reconstruction with NeRFs. To this end, we learn the patch
distribution of a scene using an adversarial discriminator, which provides
feedback to the radiance field reconstruction, thus improving realism in a
3D-consistent fashion. Thereby, rendering artifacts are repaired directly in
the underlying 3D representation by imposing multi-view path rendering
constraints. In addition, we condition a generator with multi-resolution NeRF
renderings which is adversarially trained to further improve rendering quality.
We demonstrate that our approach significantly improves rendering quality,
e.g., nearly halving LPIPS scores compared to Nerfacto while at the same time
improving PSNR by 1.4dB on the advanced indoor scenes of Tanks and Temples.
\\ ( https://arxiv.org/abs/2306.06044 ,  9610kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06048
Date: Fri, 9 Jun 2023 17:16:50 GMT   (3737kb,D)

Title: How Does Fine-Tuning Impact Out-of-Distribution Detection for
 Vision-Language Models?
Authors: Yifei Ming, Yixuan Li
Categories: cs.CV cs.CY cs.LG
\\
 Recent large vision-language models such as CLIP have shown remarkable
out-of-distribution (OOD) detection and generalization performance. However,
their zero-shot in-distribution (ID) accuracy is often limited for downstream
datasets. Recent CLIP-based fine-tuning methods such as prompt learning have
demonstrated significant improvements in ID classification and OOD
generalization where OOD labels are available. Nonetheless, it remains unclear
whether the model is reliable to semantic shifts without OOD labels. In this
paper, we aim to bridge the gap and present a comprehensive study to understand
how fine-tuning impact OOD detection for few-shot downstream tasks. By framing
OOD detection as multi-modal concept matching, we establish a connection
between fine-tuning methods and various OOD scores. Our results suggest that a
proper choice of OOD scores is essential for CLIP-based fine-tuning. In
particular, the maximum concept matching (MCM) score provides a promising
solution consistently. We also show that prompt learning demonstrates the
state-of-the-art OOD detection performance over the zero-shot counterpart.
\\ ( https://arxiv.org/abs/2306.06048 ,  3737kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06051
Date: Fri, 9 Jun 2023 17:21:52 GMT   (6566kb,D)

Title: Exploring the Impact of Image Resolution on Chest X-ray Classification
 Performance
Authors: Alessandro Wollek, Sardi Hyska, Bastian Sabel, Michael Ingrisch,
 Tobias Lasser
Categories: cs.CV
\\
 Deep learning models for image classification have often used a resolution of
$224\times224$ pixels for computational reasons.
 This study investigates the effect of image resolution on chest X-ray
classification performance, using the ChestX-ray14 dataset.
 The results show that a higher image resolution, specifically
$1024\times1024$ pixels, has the best overall classification performance, with
a slight decline in performance between $256\times256$ to $512\times512$ pixels
for most of the pathological classes.
 Comparison of saliency map-generated bounding boxes revealed that commonly
used resolutions are insufficient for finding most pathologies.
\\ ( https://arxiv.org/abs/2306.06051 ,  6566kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06061
Date: Thu, 25 May 2023 14:13:29 GMT   (1140kb)

Title: clustering an african hairstyle dataset using pca and k-means
Authors: Teffo Phomolo Nicrocia, Owolawi Pius Adewale, Pholo Moanda Diana
Categories: cs.CV cs.LG
\\
 The adoption of digital transformation was not expressed in building an
African face shape classifier. In this paper, an approach is presented that
uses k-means to classify African women images. African women rely on beauty
standards recommendations, personal preference, or the newest trends in
hairstyles to decide on the appropriate hairstyle for them. In this paper, an
approach is presented that uses K-means clustering to classify African women's
images. In order to identify potential facial clusters, Haarcascade is used for
feature-based training, and K-means clustering is applied for image
classification.
\\ ( https://arxiv.org/abs/2306.06061 ,  1140kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06062
Date: Thu, 1 Jun 2023 17:36:13 GMT   (1401kb,D)

Title: Neural FIM for learning Fisher Information Metrics from point cloud data
Authors: Oluwadamilola Fasina, Guilluame Huguet, Alexander Tong, Yanlei Zhang,
 Guy Wolf, Maximilian Nickel, Ian Adelstein, Smita Krishnaswamy
Categories: cs.CV cs.LG
Comments: 13 pages, 11 figures, 1 table
\\
 Although data diffusion embeddings are ubiquitous in unsupervised learning
and have proven to be a viable technique for uncovering the underlying
intrinsic geometry of data, diffusion embeddings are inherently limited due to
their discrete nature. To this end, we propose neural FIM, a method for
computing the Fisher information metric (FIM) from point cloud data - allowing
for a continuous manifold model for the data. Neural FIM creates an extensible
metric space from discrete point cloud data such that information from the
metric can inform us of manifold characteristics such as volume and geodesics.
We demonstrate Neural FIM's utility in selecting parameters for the PHATE
visualization method as well as its ability to obtain information pertaining to
local volume illuminating branching points and cluster centers embeddings of a
toy dataset and two single-cell datasets of IPSC reprogramming and PBMCs
(immune cells).
\\ ( https://arxiv.org/abs/2306.06062 ,  1401kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06066
Date: Wed, 31 May 2023 10:00:45 GMT   (1835kb)

Title: Multi-level Cross-modal Feature Alignment via Contrastive Learning
 towards Zero-shot Classification of Remote Sensing Image Scenes
Authors: Chun Liu, Suqiang Ma, Zheng Li, Wei Yang and Zhigang Han
Categories: cs.CV cs.LG
\\
 Zero-shot classification of image scenes which can recognize the image scenes
that are not seen in the training stage holds great promise of lowering the
dependence on large numbers of labeled samples. To address the zero-shot image
scene classification, the cross-modal feature alignment methods have been
proposed in recent years. These methods mainly focus on matching the visual
features of each image scene with their corresponding semantic descriptors in
the latent space. Less attention has been paid to the contrastive relationships
between different image scenes and different semantic descriptors. In light of
the challenge of large intra-class difference and inter-class similarity among
image scenes and the potential noisy samples, these methods are susceptible to
the influence of the instances which are far from these of the same classes and
close to these of other classes. In this work, we propose a multi-level
cross-modal feature alignment method via contrastive learning for zero-shot
classification of remote sensing image scenes. While promoting the
single-instance level positive alignment between each image scene with their
corresponding semantic descriptors, the proposed method takes the
cross-instance contrastive relationships into consideration,and learns to keep
the visual and semantic features of different classes in the latent space apart
from each other. Extensive experiments have been done to evaluate the
performance of the proposed method. The results show that our proposed method
outperforms state of the art methods for zero-shot remote sensing image scene
classification. All the code and data are available at github
https://github.com/masuqiang/MCFA-Pytorch
\\ ( https://arxiv.org/abs/2306.06066 ,  1835kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06068
Date: Mon, 5 Jun 2023 11:16:47 GMT   (510kb,D)

Title: DeepStay: Stay Region Extraction from Location Trajectories using Weak
 Supervision
Authors: Christian L\"owens, Daniela Thyssens, Emma Andersson, Christina
 Jenkins, Lars Schmidt-Thieme
Categories: cs.CV cs.LG
Comments: Paper under peer review
\\
 Nowadays, mobile devices enable constant tracking of the user's position and
location trajectories can be used to infer personal points of interest (POIs)
like homes, workplaces, or stores. A common way to extract POIs is to first
identify spatio-temporal regions where a user spends a significant amount of
time, known as stay regions (SRs).
 Common approaches to SR extraction are evaluated either solely unsupervised
or on a small-scale private dataset, as popular public datasets are unlabeled.
Most of these methods rely on hand-crafted features or thresholds and do not
learn beyond hyperparameter optimization. Therefore, we propose a weakly and
self-supervised transformer-based model called DeepStay, which is trained on
location trajectories to predict stay regions. To the best of our knowledge,
this is the first approach based on deep learning and the first approach that
is evaluated on a public, labeled dataset. Our SR extraction method outperforms
state-of-the-art methods. In addition, we conducted a limited experiment on the
task of transportation mode detection from GPS trajectories using the same
architecture and achieved significantly higher scores than the
state-of-the-art. Our code is available at
https://github.com/christianll9/deepstay.
\\ ( https://arxiv.org/abs/2306.06068 ,  510kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06069
Date: Wed, 31 May 2023 14:35:02 GMT   (2001kb,D)

Title: Gemtelligence: Accelerating Gemstone classification with Deep Learning
Authors: Tommaso Bendinelli, Luca Biggio, Daniel Nyfeler, Abhigyan Ghosh, Peter
 Tollan, Moritz Alexander Kirschmann, Olga Fink
Categories: cs.CV
\\
 The value of luxury goods, particularly investment-grade gemstones, is
greatly influenced by their origin and authenticity, sometimes resulting in
differences worth millions of dollars. Traditionally, human experts have
determined the origin and detected treatments on gemstones through visual
inspections and a range of analytical methods. However, the interpretation of
the data can be subjective and time-consuming, resulting in inconsistencies. In
this study, we propose Gemtelligence, a novel approach based on deep learning
that enables accurate and consistent origin determination and treatment
detection. Gemtelligence comprises convolutional and attention-based neural
networks that process heterogeneous data types collected by multiple
instruments. Notably, the algorithm demonstrated comparable predictive
performance to expensive laser-ablation inductively-coupled-plasma
mass-spectrometry (ICP-MS) analysis and visual examination by human experts,
despite using input data from relatively inexpensive analytical methods. Our
innovative methodology represents a major breakthrough in the field of gemstone
analysis by significantly improving the automation and robustness of the entire
analytical process pipeline.
\\ ( https://arxiv.org/abs/2306.06069 ,  2001kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06071
Date: Sat, 27 May 2023 12:45:32 GMT   (412kb)

Title: Adversarial Attack On Yolov5 For Traffic And Road Sign Detection
Authors: Sanyam Jain
Categories: cs.CV cs.CR cs.LG
\\
 This paper implements and investigates popular adversarial attacks on the
YOLOv5 Object Detection algorithm. The paper explores the vulnerability of the
YOLOv5 to adversarial attacks in the context of traffic and road sign
detection. The paper investigates the impact of different types of attacks,
including the Limited memory Broyden Fletcher Goldfarb Shanno (L-BFGS), the
Fast Gradient Sign Method (FGSM) attack, the Carlini and Wagner (C&W) attack,
the Basic Iterative Method (BIM) attack, the Projected Gradient Descent (PGD)
attack, One Pixel Attack, and the Universal Adversarial Perturbations attack on
the accuracy of YOLOv5 in detecting traffic and road signs. The results show
that YOLOv5 is susceptible to these attacks, with misclassification rates
increasing as the magnitude of the perturbations increases. We also explain the
results using saliency maps. The findings of this paper have important
implications for the safety and reliability of object detection algorithms used
in traffic and transportation systems, highlighting the need for more robust
and secure models to ensure their effectiveness in real-world applications.
\\ ( https://arxiv.org/abs/2306.06071 ,  412kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06073
Date: Wed, 31 May 2023 20:27:10 GMT   (7206kb,D)

Title: Feature Selection on Sentinel-2 Multi-spectral Imagery for Efficient
 Tree Cover Estimation
Authors: Usman Nazir, Momin Uppal, Muhammad Tahir, Zubair Khalid
Categories: cs.CV cs.LG eess.IV
Comments: IEEE IGARSS 2023
\\
 This paper proposes a multi-spectral random forest classifier with suitable
feature selection and masking for tree cover estimation in urban areas. The key
feature of the proposed classifier is filtering out the built-up region using
spectral indices followed by random forest classification on the remaining mask
with carefully selected features. Using Sentinel-2 satellite imagery, we
evaluate the performance of the proposed technique on a specified area
(approximately 82 acres) of Lahore University of Management Sciences (LUMS) and
demonstrate that our method outperforms a conventional random forest classifier
as well as state-of-the-art methods such as European Space Agency (ESA)
WorldCover 10m 2020 product as well as a DeepLabv3 deep learning architecture.
\\ ( https://arxiv.org/abs/2306.06073 ,  7206kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06074
Date: Wed, 31 May 2023 20:46:06 GMT   (13632kb,D)

Title: Improved flood mapping for efficient policy design by fusion of
 Sentinel-1, Sentinel-2, and Landsat-9 imagery to identify population and
 infrastructure exposed to floods
Authors: Usman Nazir, Muhammad Ahmad Waseem, Falak Sher Khan, Rabia Saeed, Syed
 Muhammad Hasan, Momin Uppal, Zubair Khalid
Categories: cs.CV cs.AI
Comments: IEEE IGARSS 2023
\\
 A reliable yet inexpensive tool for the estimation of flood water spread is
conducive for efficient disaster management. The application of optical and SAR
imagery in tandem provides a means of extended availability and enhanced
reliability of flood mapping. We propose a methodology to merge these two types
of imagery into a common data space and demonstrate its use in the
identification of affected populations and infrastructure for the 2022 floods
in Pakistan. The merging of optical and SAR data provides us with improved
observations in cloud-prone regions; that is then used to gain additional
insights into flood mapping applications. The use of open source datasets from
WorldPop and OSM for population and roads respectively makes the exercise
globally replicable. The integration of flood maps with spatial data on
population and infrastructure facilitates informed policy design. We have shown
that within the top five flood-affected districts in Sindh province, Pakistan,
the affected population accounts for 31 %, while the length of affected roads
measures 1410.25 km out of a total of 7537.96 km.
\\ ( https://arxiv.org/abs/2306.06074 ,  13632kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06075
Date: Fri, 26 May 2023 13:41:35 GMT   (2215kb)

Title: DeepSeaNet: Improving Underwater Object Detection using EfficientDet
Authors: Sanyam Jain
Categories: cs.CV cs.LG
\\
 Marine animals and deep underwater objects are difficult to recognize and
monitor for safety of aquatic life. There is an increasing challenge when the
water is saline with granular particles and impurities. In such natural
adversarial environment, traditional approaches like CNN start to fail and are
expensive to compute. This project involves implementing and evaluating various
object detection models, including EfficientDet, YOLOv5, YOLOv8, and
Detectron2, on an existing annotated underwater dataset, called the
Brackish-Dataset. The dataset comprises annotated image sequences of fish,
crabs, starfish, and other aquatic animals captured in Limfjorden water with
limited visibility. The aim of this research project is to study the efficiency
of newer models on the same dataset and contrast them with the previous results
based on accuracy and inference time. Firstly, I compare the results of YOLOv3
(31.10% mean Average Precision (mAP)), YOLOv4 (83.72% mAP), YOLOv5 (97.6%),
YOLOv8 (98.20%), EfficientDet (98.56% mAP) and Detectron2 (95.20% mAP) on the
same dataset. Secondly, I provide a modified BiSkFPN mechanism (BiFPN neck with
skip connections) to perform complex feature fusion in adversarial noise which
makes modified EfficientDet robust to perturbations. Third, analyzed the effect
on accuracy of EfficientDet (98.63% mAP) and YOLOv5 by adversarial learning
(98.04% mAP). Last, I provide class activation map based explanations (CAM) for
the two models to promote Explainability in black box models. Overall, the
results indicate that modified EfficientDet achieved higher accuracy with
five-fold cross validation than the other models with 88.54% IoU of feature
maps.
\\ ( https://arxiv.org/abs/2306.06075 ,  2215kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06076
Date: Thu, 8 Jun 2023 04:14:32 GMT   (1240kb,D)

Title: Differentially Private Image Classification by Learning Priors from
 Random Processes
Authors: Xinyu Tang, Ashwinee Panda, Vikash Sehwag, Prateek Mittal
Categories: cs.CV cs.CR cs.LG stat.ML
\\
 In privacy-preserving machine learning, differentially private stochastic
gradient descent (DP-SGD) performs worse than SGD due to per-sample gradient
clipping and noise addition. A recent focus in private learning research is
improving the performance of DP-SGD on private data by incorporating priors
that are learned on real-world public data. In this work, we explore how we can
improve the privacy-utility tradeoff of DP-SGD by learning priors from images
generated by random processes and transferring these priors to private data. We
propose DP-RandP, a three-phase approach. We attain new state-of-the-art
accuracy when training from scratch on CIFAR10, CIFAR100, and MedMNIST for a
range of privacy budgets $\varepsilon \in [1, 8]$. In particular, we improve
the previous best reported accuracy on CIFAR10 from $60.6 \%$ to $72.3 \%$ for
$\varepsilon=1$. Our code is available at
https://github.com/inspire-group/DP-RandP.
\\ ( https://arxiv.org/abs/2306.06076 ,  1240kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06077
Date: Mon, 5 Jun 2023 17:22:54 GMT   (8717kb,D)

Title: Visually-Grounded Descriptions Improve Zero-Shot Image Classification
Authors: Michael Ogezi, Bradley Hauer, Grzegorz Kondrak
Categories: cs.CV cs.AI cs.CL
\\
 Language-vision models like CLIP have made significant progress in zero-shot
vision tasks, such as zero-shot image classification (ZSIC). However,
generating specific and expressive class descriptions remains a major
challenge. Existing approaches suffer from granularity and label ambiguity
issues. To tackle these challenges, we propose V-GLOSS: Visual Glosses, a novel
method leveraging modern language models and semantic knowledge bases to
produce visually-grounded class descriptions. We demonstrate V-GLOSS's
effectiveness by achieving state-of-the-art results on benchmark ZSIC datasets
including ImageNet and STL-10. In addition, we introduce a silver dataset with
class descriptions generated by V-GLOSS, and show its usefulness for vision
tasks. We make available our code and dataset.
\\ ( https://arxiv.org/abs/2306.06077 ,  8717kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06078
Date: Sat, 27 May 2023 04:03:15 GMT   (508kb,D)

Title: Cheating off your neighbors: Improving activity recognition through
 corroboration
Authors: Haoxiang Yu, Jingyi An, Evan King, Edison Thomaz, Christine Julien
Categories: cs.CV cs.HC cs.LG eess.SP
\\
 Understanding the complexity of human activities solely through an
individual's data can be challenging. However, in many situations, surrounding
individuals are likely performing similar activities, while existing human
activity recognition approaches focus almost exclusively on individual
measurements and largely ignore the context of the activity. Consider two
activities: attending a small group meeting and working at an office desk. From
solely an individual's perspective, it can be difficult to differentiate
between these activities as they may appear very similar, even though they are
markedly different. Yet, by observing others nearby, it can be possible to
distinguish between these activities. In this paper, we propose an approach to
enhance the prediction accuracy of an individual's activities by incorporating
insights from surrounding individuals. We have collected a real-world dataset
from 20 participants with over 58 hours of data including activities such as
attending lectures, having meetings, working in the office, and eating
together. Compared to observing a single person in isolation, our proposed
approach significantly improves accuracy. We regard this work as a first step
in collaborative activity recognition, opening new possibilities for
understanding human activity in group settings.
\\ ( https://arxiv.org/abs/2306.06078 ,  508kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06080
Date: Wed, 31 May 2023 06:16:40 GMT   (1435kb)

Title: Detection of Late Blight Disease in Tomato Leaf Using Image Processing
 Techniques
Authors: Muhammad Shoaib Farooq, Tabir Arif, Shamyla Riaz
Categories: cs.CV cs.LG
Comments: it is a review search that contains 17 pages and 8 figures
\\
 =One of the most frequently farmed crops is the tomato crop. Late blight is
the most prevalent tomato disease in the world, and often causes a significant
reduction in the production of tomato crops. The importance of tomatoes as an
agricultural product necessitates early detection of late blight. It is
produced by the fungus Phytophthora. The earliest signs of late blight on
tomatoes are unevenly formed, water-soaked lesions on the leaves located on the
plant canopy's younger leave White cottony growth may appear in humid
environments evident on the undersides of the leaves that have been impacted.
Lesions increase as the disease proceeds, turning the leaves brown to shrivel
up and die. Using picture segmentation and the Multi-class SVM technique, late
blight disorder is discovered in this work. Image segmentation is employed for
separating damaged areas on leaves, and the Multi-class SVM method is used for
reliable disease categorization. 30 reputable studies were chosen from a total
of 2770 recognized papers. The primary goal of this study is to compile
cutting-edge research that identifies current research trends, problems, and
prospects for late blight detection. It also looks at current approaches for
applying image processing to diagnose and detect late blight. A suggested
taxonomy for late blight detection has also been provided. In the same way, a
model for the development of the solutions to problems is also presented.
Finally, the research gaps have been presented in terms of open issues for the
provision of future directions in image processing for the researchers.
\\ ( https://arxiv.org/abs/2306.06080 ,  1435kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06081
Date: Thu, 25 May 2023 09:04:31 GMT   (635kb,D)

Title: CARSO: Counter-Adversarial Recall of Synthetic Observations
Authors: Emanuele Ballarin, Alessio Ansuini, Luca Bortolussi
Categories: cs.CV cs.AI cs.CR cs.LG
Comments: 20 pages, 5 figures, 10 tables
\\
 In this paper, we propose a novel adversarial defence mechanism for image
classification -- CARSO -- inspired by cues from cognitive neuroscience. The
method is synergistically complementary to adversarial training and relies on
knowledge of the internal representation of the attacked classifier. Exploiting
a generative model for adversarial purification, conditioned on such
representation, it samples reconstructions of inputs to be finally classified.
Experimental evaluation by a well-established benchmark of varied, strong
adaptive attacks, across diverse image datasets and classifier architectures,
shows that CARSO is able to defend the classifier significantly better than
state-of-the-art adversarial training alone -- with a tolerable clean accuracy
toll. Furthermore, the defensive architecture succeeds in effectively shielding
itself from unforeseen threats, and end-to-end attacks adapted to fool
stochastic defences. Code and pre-trained models are available at
https://github.com/emaballarin/CARSO .
\\ ( https://arxiv.org/abs/2306.06081 ,  635kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06082
Date: Wed, 31 May 2023 12:24:06 GMT   (5961kb,D)

Title: Augmentation-aware Self-supervised Learning with Guided Projector
Authors: Marcin Przewi\k{e}\'zlikowski, Mateusz Pyla, Bartosz Zieli\'nski,
 Bart{\l}omiej Twardowski, Jacek Tabor, Marek \'Smieja
Categories: cs.CV cs.LG
Comments: Prepint under review. Code: https://github.com/gmum/CASSLE
\\
 Self-supervised learning (SSL) is a powerful technique for learning robust
representations from unlabeled data. By learning to remain invariant to applied
data augmentations, methods such as SimCLR and MoCo are able to reach quality
on par with supervised approaches. However, this invariance may be harmful to
solving some downstream tasks which depend on traits affected by augmentations
used during pretraining, such as color. In this paper, we propose to foster
sensitivity to such characteristics in the representation space by modifying
the projector network, a common component of self-supervised architectures.
Specifically, we supplement the projector with information about augmentations
applied to images. In order for the projector to take advantage of this
auxiliary guidance when solving the SSL task, the feature extractor learns to
preserve the augmentation information in its representations. Our approach,
coined Conditional Augmentation-aware Selfsupervised Learning (CASSLE), is
directly applicable to typical joint-embedding SSL methods regardless of their
objective functions. Moreover, it does not require major changes in the network
architecture or prior knowledge of downstream tasks. In addition to an analysis
of sensitivity towards different data augmentations, we conduct a series of
experiments, which show that CASSLE improves over various SSL methods, reaching
state-of-the-art performance in multiple downstream tasks.
\\ ( https://arxiv.org/abs/2306.06082 ,  5961kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06084
Date: Fri, 12 May 2023 04:43:51 GMT   (1241kb)

Title: Machine Vision Using Cellphone Camera: A Comparison of deep networks for
 classifying three challenging denominations of Indian Coins
Authors: Keyur D. Joshi, Dhruv Shah, Varshil Shah, Nilay Gandhi, Sanket J.
 Shah, Sanket B. Shah
Categories: cs.CV cs.LG
Comments: 6 Pages, 4 Figures, 6 Tables, Conference paper
DOI: 10.1109/M2VIP55626.2022.10041089
\\
 Indian currency coins come in a variety of denominations. Off all the
varieties Rs.1, RS.2, and Rs.5 have similar diameters. Majority of the coin
styles in market circulation for denominations of Rs.1 and Rs.2 coins are
nearly the same except for numerals on its reverse side. If a coin is resting
on its obverse side, the correct denomination is not distinguishable by humans.
Therefore, it was hypothesized that a digital image of a coin resting on its
either size could be classified into its correct denomination by training a
deep neural network model. The digital images were generated by using cheap
cell phone cameras. To find the most suitable deep neural network architecture,
four were selected based on the preliminary analysis carried out for
comparison. The results confirm that two of the four deep neural network models
can classify the correct denomination from either side of a coin with an
accuracy of 97%.
\\ ( https://arxiv.org/abs/2306.06084 ,  1241kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06089
Date: Fri, 9 Jun 2023 17:51:20 GMT   (15107kb,D)

Title: Computational Flash Photography through Intrinsics
Authors: Sepideh Sarajian Maralan, Chris Careaga, Ya\u{g}{\i}z Aksoy
Categories: cs.CV
Comments: 9 pages, 15 figures. Accepted to CVPR 2023. Project page:
 http://yaksoy.github.io/intrinsicFlash/
\\
 Flash is an essential tool as it often serves as the sole controllable light
source in everyday photography. However, the use of flash is a binary decision
at the time a photograph is captured with limited control over its
characteristics such as strength or color. In this work, we study the
computational control of the flash light in photographs taken with or without
flash. We present a physically motivated intrinsic formulation for flash
photograph formation and develop flash decomposition and generation methods for
flash and no-flash photographs, respectively. We demonstrate that our intrinsic
formulation outperforms alternatives in the literature and allows us to
computationally control flash in in-the-wild images.
\\ ( https://arxiv.org/abs/2306.06089 ,  15107kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06092
Date: Fri, 9 Jun 2023 17:52:34 GMT   (13166kb,D)

Title: Realistic Saliency Guided Image Enhancement
Authors: S. Mahdi H. Miangoleh and Zoya Bylinskii and Eric Kee and Eli
 Shechtman and Ya\u{g}{\i}z Aksoy
Categories: cs.CV
Comments: For more info visit http://yaksoy.github.io/realisticEditing/
Journal-ref: Proc. CVPR (2023)
\\
 Common editing operations performed by professional photographers include the
cleanup operations: de-emphasizing distracting elements and enhancing subjects.
These edits are challenging, requiring a delicate balance between manipulating
the viewer's attention while maintaining photo realism. While recent approaches
can boast successful examples of attention attenuation or amplification, most
of them also suffer from frequent unrealistic edits. We propose a realism loss
for saliency-guided image enhancement to maintain high realism across varying
image types, while attenuating distractors and amplifying objects of interest.
Evaluations with professional photographers confirm that we achieve the dual
objective of realism and effectiveness, and outperform the recent approaches on
their own datasets, while requiring a smaller memory footprint and runtime. We
thus offer a viable solution for automating image enhancement and photo cleanup
operations.
\\ ( https://arxiv.org/abs/2306.06092 ,  13166kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06093
Date: Fri, 9 Jun 2023 17:56:07 GMT   (11019kb,D)

Title: HyP-NeRF: Learning Improved NeRF Priors using a HyperNetwork
Authors: Bipasha Sen, Gaurav Singh, Aditya Agarwal, Rohith Agaram, K Madhava
 Krishna, Srinath Sridhar
Categories: cs.CV
\\
 Neural Radiance Fields (NeRF) have become an increasingly popular
representation to capture high-quality appearance and shape of scenes and
objects. However, learning generalizable NeRF priors over categories of scenes
or objects has been challenging due to the high dimensionality of network
weight space. To address the limitations of existing work on generalization,
multi-view consistency and to improve quality, we propose HyP-NeRF, a latent
conditioning method for learning generalizable category-level NeRF priors using
hypernetworks. Rather than using hypernetworks to estimate only the weights of
a NeRF, we estimate both the weights and the multi-resolution hash encodings
resulting in significant quality gains. To improve quality even further, we
incorporate a denoise and finetune strategy that denoises images rendered from
NeRFs estimated by the hypernetwork and finetunes it while retaining multiview
consistency. These improvements enable us to use HyP-NeRF as a generalizable
prior for multiple downstream tasks including NeRF reconstruction from
single-view or cluttered scenes and text-to-NeRF. We provide qualitative
comparisons and evaluate HyP-NeRF on three tasks: generalization, compression,
and retrieval, demonstrating our state-of-the-art results.
\\ ( https://arxiv.org/abs/2306.06093 ,  11019kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06094
Date: Fri, 9 Jun 2023 17:57:01 GMT   (1193kb,D)

Title: Leveraging Large Language Models for Scalable Vector Graphics-Driven
 Image Understanding
Authors: Mu Cai, Zeyi Huang, Yuheng Li, Haohan Wang, Yong Jae Lee
Categories: cs.CV cs.AI cs.CL cs.LG
\\
 Recently, large language models (LLMs) have made significant advancements in
natural language understanding and generation. However, their potential in
computer vision remains largely unexplored. In this paper, we introduce a new,
exploratory approach that enables LLMs to process images using the Scalable
Vector Graphics (SVG) format. By leveraging the XML-based textual descriptions
of SVG representations instead of raster images, we aim to bridge the gap
between the visual and textual modalities, allowing LLMs to directly understand
and manipulate images without the need for parameterized visual components. Our
method facilitates simple image classification, generation, and in-context
learning using only LLM capabilities. We demonstrate the promise of our
approach across discriminative and generative tasks, highlighting its (i)
robustness against distribution shift, (ii) substantial improvements achieved
by tapping into the in-context learning abilities of LLMs, and (iii) image
understanding and generation capabilities with human guidance. Our code, data,
and models can be found here https://github.com/mu-cai/svg-llm.
\\ ( https://arxiv.org/abs/2306.06094 ,  1193kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05592
Date: Thu, 8 Jun 2023 23:38:25 GMT   (2972kb,D)

Title: Evaluating and Incentivizing Diverse Data Contributions in Collaborative
 Learning
Authors: Baihe Huang, Sai Praneeth Karimireddy, Michael I. Jordan
Categories: cs.GT cs.CY cs.DC cs.LG econ.TH
\\
 For a federated learning model to perform well, it is crucial to have a
diverse and representative dataset. However, the data contributors may only be
concerned with the performance on a specific subset of the population, which
may not reflect the diversity of the wider population. This creates a tension
between the principal (the FL platform designer) who cares about global
performance and the agents (the data collectors) who care about local
performance. In this work, we formulate this tension as a game between the
principal and multiple agents, and focus on the linear experiment design
problem to formally study their interaction. We show that the statistical
criterion used to quantify the diversity of the data, as well as the choice of
the federated learning algorithm used, has a significant effect on the
resulting equilibrium. We leverage this to design simple optimal federated
learning mechanisms that encourage data collectors to contribute data
representative of the global population, thereby maximizing global performance.
\\ ( https://arxiv.org/abs/2306.05592 ,  2972kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05732
Date: Fri, 9 Jun 2023 07:52:42 GMT   (455kb,D)

Title: Computing Algorithm for an Equilibrium of the Generalized Stackelberg
 Game
Authors: Jaeyeon Jo, Jihwan Yu, Jinkyoo Park
Categories: cs.GT math.OC
Comments: 37 pages, 10 figures
\\
 The $1-N$ generalized Stackelberg game (single-leader multi-follower game) is
intricately intertwined with the interaction between a leader and followers
(hierarchical interaction) and the interaction among followers (simultaneous
interaction). However, obtaining the optimal strategy of the leader is
generally challenging due to the complex interactions among the leader and
followers. Here, we propose a general methodology to find a generalized
Stackelberg equilibrium of a $1-N$ generalized Stackelberg game. Specifically,
we first provide the conditions where a generalized Stackelberg equilibrium
always exists using the variational equilibrium concept. Next, to find an
equilibrium in polynomial time, we transformed the $1-N$ generalized
Stackelberg game into a $1-1$ Stackelberg game whose Stackelberg equilibrium is
identical to that of the original. Finally, we propose an effective computation
procedure based on the projected implicit gradient descent algorithm to find a
Stackelberg equilibrium of the transformed $1-1$ Stackelberg game. We validate
the proposed approaches using the two problems of deriving operating strategies
for EV charging stations: (1) the first problem is optimizing the one-time
charging price for EV users, in which a platform operator determines the price
of electricity and EV users determine the optimal amount of charging for their
satisfaction; and (2) the second problem is to determine the spatially varying
charging price to optimally balance the demand and supply over every charging
station.
\\ ( https://arxiv.org/abs/2306.05732 ,  455kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05756
Date: Fri, 9 Jun 2023 08:38:12 GMT   (3262kb,D)

Title: The Potential of Self-Regulation for Front-Running Prevention on DEXes
Authors: Lioba Heimbach, Eric Schertenleib, Roger Wattenhofer
Categories: cs.GT
\\
 The transaction ordering dependency of the smart contracts building
decentralized exchanges (DEXes) allow for predatory trading strategies. In
particular, front-running attacks present a constant risk for traders on DEXes.
Whereas legal regulation outlaws most front-running practices in traditional
finance, such measures are ineffective in preventing front-running on DEXes due
to the absence of a central authority. While novel market designs hindering
front-running may emerge, it remains unclear whether the market's participants,
in particular liquidity providers, would be willing to adopt these new designs.
A misalignment of the participant's private incentives and the market's social
incentives can hinder the market from adopting an effective prevention
mechanism.
 We present a game-theoretic model to study the behavior of traders and
liquidity providers in DEXes. Our work finds that in most market
configurations, the private interests of traders and liquidity providers align
with the market's social incentives - eliminating front-running attacks.
However, even though liquidity providers generally benefit from embracing the
market that prevents front-running, the benefit is often small and may not
suffice to entice them to change strategy in reality. Thus, we find that inert
liquidity providers might require additional incentives to adopt innovative
market designs and permit the market's successful self-regulation.
\\ ( https://arxiv.org/abs/2306.05756 ,  3262kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05986
Date: Fri, 9 Jun 2023 15:54:20 GMT   (29kb)

Title: Fair Allocation with Binary Valuations for Mixed Divisible and
 Indivisible Goods
Authors: Yasushi Kawase, Koichi Nishimura, Hanna Sumita
Categories: cs.GT cs.DS
\\
 The fair allocation of mixed goods, consisting of both divisible and
indivisible goods, among agents with heterogeneous preferences, has been a
prominent topic of study in economics and computer science. In this paper, we
investigate the nature of fair allocations when agents have binary valuations.
We define an allocation as fair if its utility vector minimizes a symmetric
strictly convex function, which includes conventional fairness criteria such as
maximum egalitarian social welfare and maximum Nash social welfare. While a
good structure is known for the continuous case (where only divisible goods
exist) or the discrete case (where only indivisible goods exist), deriving such
a structure in the hybrid case remains challenging. Our contributions are
twofold. First, we demonstrate that the hybrid case does not inherit some of
the nice properties of continuous or discrete cases, while it does inherit the
proximity theorem. Second, we analyze the computational complexity of finding a
fair allocation of mixed goods based on the proximity theorem. In particular,
we provide a polynomial-time algorithm for the case when all divisible goods
are identical and homogeneous, and demonstrate that the problem is NP-hard in
general. Our results also contribute to a deeper understanding of the hybrid
convex analysis.
\\ ( https://arxiv.org/abs/2306.05986 ,  29kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05437
Date: Thu, 8 Jun 2023 02:52:24 GMT   (6967kb,D)

Title: One-step Multi-view Clustering with Diverse Representation
Authors: Xinhang Wan, Jiyuan Liu, Jue Wang, Xinwang Liu, Siwei Wang, Yi Wen,
 Tianjiao Wan, En Zhu
Categories: cs.LG cs.AI
\\
 Multi-view clustering has attracted broad attention due to its capacity to
utilize consistent and complementary information among views. Although
tremendous progress has been made recently, most existing methods undergo high
complexity, preventing them from being applied to large-scale tasks. Multi-view
clustering via matrix factorization is a representative to address this issue.
However, most of them map the data matrices into a fixed dimension, which
limits the expressiveness of the model. Moreover, a range of methods suffer
from a two-step process, i.e., multimodal learning and the subsequent
$k$-means, inevitably causing a sub-optimal clustering result. In light of
this, we propose a one-step multi-view clustering with diverse representation
method, which incorporates multi-view learning and $k$-means into a unified
framework. Specifically, we first project original data matrices into various
latent spaces to attain comprehensive information and auto-weight them in a
self-supervised manner. Then we directly use the information matrices under
diverse dimensions to obtain consensus discrete clustering labels. The unified
work of representation learning and clustering boosts the quality of the final
results. Furthermore, we develop an efficient optimization algorithm to solve
the resultant problem with proven convergence. Comprehensive experiments on
various datasets demonstrate the promising clustering performance of our
proposed method.
\\ ( https://arxiv.org/abs/2306.05437 ,  6967kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05438
Date: Thu, 8 Jun 2023 06:57:07 GMT   (3046kb,D)

Title: DynamoRep: Trajectory-Based Population Dynamics for Classification of
 Black-box Optimization Problems
Authors: Gjorgjina Cenikj, Ga\v{s}per Petelin, Carola Doerr, Peter Koro\v{s}ec,
 Tome Eftimov
Categories: cs.LG cs.NE
Comments: 9 pages, 5 figures
DOI: 10.1145/3583131.3590401
\\
 The application of machine learning (ML) models to the analysis of
optimization algorithms requires the representation of optimization problems
using numerical features. These features can be used as input for ML models
that are trained to select or to configure a suitable algorithm for the problem
at hand. Since in pure black-box optimization information about the problem
instance can only be obtained through function evaluation, a common approach is
to dedicate some function evaluations for feature extraction, e.g., using
random sampling. This approach has two key downsides: (1) It reduces the budget
left for the actual optimization phase, and (2) it neglects valuable
information that could be obtained from a problem-solver interaction.
 In this paper, we propose a feature extraction method that describes the
trajectories of optimization algorithms using simple descriptive statistics. We
evaluate the generated features for the task of classifying problem classes
from the Black Box Optimization Benchmarking (BBOB) suite. We demonstrate that
the proposed DynamoRep features capture enough information to identify the
problem class on which the optimization algorithm is running, achieving a mean
classification accuracy of 95% across all experiments.
\\ ( https://arxiv.org/abs/2306.05438 ,  3046kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05439
Date: Thu, 8 Jun 2023 07:15:13 GMT   (2690kb,D)

Title: CLC: Cluster Assignment via Contrastive Representation Learning
Authors: Fei Ding, Dan Zhang, Yin Yang, Venkat Krovi, Feng Luo
Categories: cs.LG cs.AI cs.CV cs.IR
Comments: 10 pages, 7 tables, 4 figures
\\
 Clustering remains an important and challenging task of grouping samples into
clusters without manual annotations. Recent works have achieved excellent
results on small datasets by performing clustering on feature representations
learned from self-supervised learning. However, for datasets with a large
number of clusters, such as ImageNet, current methods still can not achieve
high clustering performance. In this paper, we propose Contrastive
Learning-based Clustering (CLC), which uses contrastive learning to directly
learn cluster assignment. We decompose the representation into two parts: one
encodes the categorical information under an equipartition constraint, and the
other captures the instance-wise factors. We propose a contrastive loss using
both parts of the representation. We theoretically analyze the proposed
contrastive loss and reveal that CLC sets different weights for the negative
samples while learning cluster assignments. Further gradient analysis shows
that the larger weights tend to focus more on the hard negative samples.
Therefore, the proposed loss has high expressiveness that enables us to
efficiently learn cluster assignments. Experimental evaluation shows that CLC
achieves overall state-of-the-art or highly competitive clustering performance
on multiple benchmark datasets. In particular, we achieve 53.4% accuracy on the
full ImageNet dataset and outperform existing methods by large margins (+
10.2%).
\\ ( https://arxiv.org/abs/2306.05439 ,  2690kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05483
Date: Thu, 8 Jun 2023 18:07:02 GMT   (8985kb,D)

Title: On the Importance of Exploration for Generalization in Reinforcement
 Learning
Authors: Yiding Jiang, J. Zico Kolter, Roberta Raileanu
Categories: cs.LG
\\
 Existing approaches for improving generalization in deep reinforcement
learning (RL) have mostly focused on representation learning, neglecting
RL-specific aspects such as exploration. We hypothesize that the agent's
exploration strategy plays a key role in its ability to generalize to new
environments. Through a series of experiments in a tabular contextual MDP, we
show that exploration is helpful not only for efficiently finding the optimal
policy for the training environments but also for acquiring knowledge that
helps decision making in unseen environments. Based on these observations, we
propose EDE: Exploration via Distributional Ensemble, a method that encourages
exploration of states with high epistemic uncertainty through an ensemble of
Q-value distributions. Our algorithm is the first value-based approach to
achieve state-of-the-art on both Procgen and Crafter, two benchmarks for
generalization in RL with high-dimensional observations. The open-sourced
implementation can be found at https://github.com/facebookresearch/ede .
\\ ( https://arxiv.org/abs/2306.05483 ,  8985kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05487
Date: Thu, 8 Jun 2023 18:17:48 GMT   (13930kb)

Title: Boosting with Tempered Exponential Measures
Authors: Richard Nock, Ehsan Amid, Manfred K. Warmuth
Categories: cs.LG stat.ML
ACM-class: I.2.6
\\
 One of the most popular ML algorithms, AdaBoost, can be derived from the dual
of a relative entropy minimization problem subject to the fact that the
positive weights on the examples sum to one. Essentially, harder examples
receive higher probabilities. We generalize this setup to the recently
introduced {\it tempered exponential measure}s (TEMs) where normalization is
enforced on a specific power of the measure and not the measure itself. TEMs
are indexed by a parameter $t$ and generalize exponential families ($t=1$). Our
algorithm, $t$-AdaBoost, recovers AdaBoost~as a special case ($t=1$). We show
that $t$-AdaBoost retains AdaBoost's celebrated exponential convergence rate
when $t\in [0,1)$ while allowing a slight improvement of the rate's hidden
constant compared to $t=1$. $t$-AdaBoost partially computes on a generalization
of classical arithmetic over the reals and brings notable properties like
guaranteed bounded leveraging coefficients for $t\in [0,1)$. From the loss that
$t$-AdaBoost minimizes (a generalization of the exponential loss), we show how
to derive a new family of {\it tempered} losses for the induction of
domain-partitioning classifiers like decision trees. Crucially, strict
properness is ensured for all while their boosting rates span the full known
spectrum. Experiments using $t$-AdaBoost+trees display that significant
leverage can be achieved by tuning $t$.
\\ ( https://arxiv.org/abs/2306.05487 ,  13930kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05497
Date: Thu, 8 Jun 2023 18:38:55 GMT   (465kb,D)

Title: Reevaluating Loss Functions: Enhancing Robustness to Label Noise in Deep
 Learning Models
Authors: Max Staats, Matthias Thamm, Bernd Rosenow
Categories: cs.LG cond-mat.dis-nn cs.AI
Comments: 13 pages, 4 figures
\\
 Large annotated datasets inevitably contain incorrect labels, which poses a
major challenge for the training of deep neural networks as they easily fit the
labels. Only when training with a robust model that is not easily distracted by
the noise, a good generalization performance can be achieved. A simple yet
effective way to create a noise robust model is to use a noise robust loss
function. However, the number of proposed loss functions is large, they often
come with hyperparameters, and may learn slower than the widely used but noise
sensitive Cross Entropy loss. By heuristic considerations and extensive
numerical experiments, we study in which situations the proposed loss functions
are applicable and give suggestions on how to choose an appropriate loss.
Additionally, we propose a novel technique to enhance learning with bounded
loss functions: the inclusion of an output bias, i.e. a slight increase in the
neuron pre-activation corresponding to the correct label. Surprisingly, we find
that this not only significantly improves the learning of bounded losses, but
also leads to the Mean Absolute Error loss outperforming the Cross Entropy loss
on the Cifar-100 dataset - even in the absence of additional label noise. This
suggests that training with a bounded loss function can be advantageous even in
the presence of minimal label noise. To further strengthen our analysis of the
learning behavior of different loss functions, we additionally design and test
a novel loss function denoted as Bounded Cross Entropy.
\\ ( https://arxiv.org/abs/2306.05497 ,  465kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05501
Date: Thu, 8 Jun 2023 18:49:23 GMT   (6263kb,D)

Title: AMEE: A Robust Framework for Explanation Evaluation in Time Series
 Classification
Authors: Thu Trang Nguyen, Thach Le Nguyen, and Georgiana Ifrim
Categories: cs.LG
Comments: Pre-print
\\
 This paper aims to provide a framework to quantitatively evaluate and rank
explanation methods for the time series classification task, which deals with a
prevalent data type in critical domains such as healthcare and finance. The
recent surge of research interest in explanation methods for time series
classification has provided a great variety of explanation techniques.
Nevertheless, when these explanation techniques disagree on a specific problem,
it remains unclear which of them to use. Comparing the explanations to find the
right answer is non-trivial. Two key challenges remain: how to quantitatively
and robustly evaluate the informativeness (i.e., relevance for the
classification task) of a given explanation method, and how to compare
explanation methods side-by-side. We propose AMEE, a Model-Agnostic Explanation
Evaluation framework for quantifying and comparing multiple saliency-based
explanations for time series classification. Perturbation is added to the input
time series guided by the saliency maps (i.e., importance weights for each
point in the time series). The impact of perturbation on classification
accuracy is measured and used for explanation evaluation. The results show that
perturbing discriminative parts of the time series leads to significant changes
in classification accuracy. To be robust to different types of perturbations
and different types of classifiers, we aggregate the accuracy loss across
perturbations and classifiers. This allows us to objectively quantify and rank
different explanation methods. We provide a quantitative and qualitative
analysis for synthetic datasets, a variety of UCR benchmark datasets, as well
as a real-world dataset with known expert ground truth.
\\ ( https://arxiv.org/abs/2306.05501 ,  6263kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05515
Date: Thu, 8 Jun 2023 19:12:42 GMT   (84kb,D)

Title: PeFLL: A Lifelong Learning Approach to Personalized Federated Learning
Authors: Jonathan Scott, Hossein Zakerinia, Christoph H. Lampert
Categories: cs.LG
\\
 Personalized federated learning (pFL) has emerged as a popular approach to
dealing with the challenge of statistical heterogeneity between the data
distributions of the participating clients. Instead of learning a single global
model, pFL aims to learn an individual model for each client while still making
use of the data available at other clients. In this work, we present PeFLL, a
new pFL approach rooted in lifelong learning that performs well not only on
clients present during its training phase, but also on any that may emerge in
the future. PeFLL learns to output client specific models by jointly training
an embedding network and a hypernetwork. The embedding network learns to
represent clients in a latent descriptor space in a way that reflects their
similarity to each other. The hypernetwork learns a mapping from this latent
space to the space of possible client models. We demonstrate experimentally
that PeFLL produces models of superior accuracy compared to previous methods,
especially for clients not seen during training, and that it scales well to
large numbers of clients. Moreover, generating a personalized model for a new
client is efficient as no additional fine-tuning or optimization is required by
either the client or the server. We also present theoretical results supporting
PeFLL in the form of a new PAC-Bayesian generalization bound for lifelong
learning and we prove the convergence of our proposed optimization procedure.
\\ ( https://arxiv.org/abs/2306.05515 ,  84kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05567
Date: Thu, 8 Jun 2023 21:19:42 GMT   (1728kb)

Title: Intelligent Energy Management with IoT Framework in Smart Cities Using
 Intelligent Analysis: An Application of Machine Learning Methods for Complex
 Networks and Systems
Authors: Maryam Nikpour, Parisa Behvand Yousefi, Hadi Jafarzadeh, Kasra Danesh,
 Mohsen Ahmadi
Categories: cs.LG cs.CY cs.SY eess.SY
\\
 Smart buildings are increasingly using Internet of Things (IoT)-based
wireless sensing systems to reduce their energy consumption and environmental
impact. As a result of their compact size and ability to sense, measure, and
compute all electrical properties, Internet of Things devices have become
increasingly important in our society. A major contribution of this study is
the development of a comprehensive IoT-based framework for smart city energy
management, incorporating multiple components of IoT architecture and
framework. An IoT framework for intelligent energy management applications that
employ intelligent analysis is an essential system component that collects and
stores information. Additionally, it serves as a platform for the development
of applications by other companies. Furthermore, we have studied intelligent
energy management solutions based on intelligent mechanisms. The depletion of
energy resources and the increase in energy demand have led to an increase in
energy consumption and building maintenance. The data collected is used to
monitor, control, and enhance the efficiency of the system.
\\ ( https://arxiv.org/abs/2306.05567 ,  1728kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05579
Date: Thu, 8 Jun 2023 22:37:24 GMT   (65kb)

Title: Decentralized Randomly Distributed Multi-agent Multi-armed Bandit with
 Heterogeneous Rewards
Authors: Mengfan Xu and Diego Klabjan
Categories: cs.LG stat.ML
Comments: 14 pages, under review
\\
 We study a decentralized multi-agent multi-armed bandit problem in which
multiple clients are connected by time dependent random graphs provided by an
environment. The reward distributions of each arm vary across clients and
rewards are generated independently over time by an environment based on
distributions that include both sub-exponential and sub-gaussian distributions.
Each client pulls an arm and communicates with neighbors based on the graph
provided by the environment. The goal is to minimize the overall regret of the
entire system through collaborations. To this end, we introduce a novel
algorithmic framework, which first provides robust simulation methods for
generating random graphs using rapidly mixing Markov chains or the random graph
model, and then combines an averaging-based consensus approach with a newly
proposed weighting technique and the upper confidence bound to deliver a
UCB-type solution. Our algorithms account for the randomness in the graphs,
removing the conventional doubly stochasticity assumption, and only require the
knowledge of the number of clients at initialization. We derive optimal
instance-dependent regret upper bounds of order $\log{T}$ in both sub-gaussian
and sub-exponential environments, and a nearly optimal mean-gap independent
regret upper bound of order $\sqrt{T}\log T$ up to a $\log T$ factor.
Importantly, our regret bounds hold with high probability and capture graph
randomness, whereas prior works consider expected regret under assumptions and
require more stringent reward distributions.
\\ ( https://arxiv.org/abs/2306.05579 ,  65kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05583
Date: Thu, 8 Jun 2023 22:54:48 GMT   (1203kb,D)

Title: SGLD-Based Information Criteria and the Over-Parameterized Regime
Authors: Haobo Chen, Yuheng Bu and Gregory W. Wornell
Categories: cs.LG cs.IT math.IT
\\
 Double-descent refers to the unexpected drop in test loss of a learning
algorithm beyond an interpolating threshold with over-parameterization, which
is not predicted by information criteria in their classical forms due to the
limitations in the standard asymptotic approach. We update these analyses using
the information risk minimization framework and provide Akaike Information
Criterion (AIC) and Bayesian Information Criterion (BIC) for models learned by
stochastic gradient Langevin dynamics (SGLD). Notably, the AIC and BIC penalty
terms for SGLD correspond to specific information measures, i.e., symmetrized
KL information and KL divergence. We extend this information-theoretic analysis
to over-parameterized models by characterizing the SGLD-based BIC for the
random feature model in the regime where the number of parameters $p$ and the
number of samples $n$ tend to infinity, with $p/n$ fixed. Our experiments
demonstrate that the refined SGLD-based BIC can track the double-descent curve,
providing meaningful guidance for model selection and revealing new insights
into the behavior of SGLD learning algorithms in the over-parameterized regime.
\\ ( https://arxiv.org/abs/2306.05583 ,  1203kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05587
Date: Thu, 8 Jun 2023 23:14:39 GMT   (332kb,D)

Title: MC-NN: An End-to-End Multi-Channel Neural Network Approach for
 Predicting Influenza A Virus Hosts and Antigenic Types
Authors: Yanhua Xu and Dominik Wojtczak
Categories: cs.LG q-bio.QM
Comments: Accepted version submitted to the SN Computer Science; Published in
 the SN Computer Science 2023
DOI: 10.1007/s42979-023-01839-5
\\
 Influenza poses a significant threat to public health, particularly among the
elderly, young children, and people with underlying dis-eases. The
manifestation of severe conditions, such as pneumonia, highlights the
importance of preventing the spread of influenza. An accurate and
cost-effective prediction of the host and antigenic sub-types of influenza A
viruses is essential to addressing this issue, particularly in
resource-constrained regions. In this study, we propose a multi-channel neural
network model to predict the host and antigenic subtypes of influenza A viruses
from hemagglutinin and neuraminidase protein sequences. Our model was trained
on a comprehensive data set of complete protein sequences and evaluated on
various test data sets of complete and incomplete sequences. The results
demonstrate the potential and practicality of using multi-channel neural
networks in predicting the host and antigenic subtypes of influenza A viruses
from both full and partial protein sequences.
\\ ( https://arxiv.org/abs/2306.05587 ,  332kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05628
Date: Fri, 9 Jun 2023 02:23:37 GMT   (2721kb,D)

Title: Quantifying the Knowledge in GNNs for Reliable Distillation into MLPs
Authors: Lirong Wu, Haitao Lin, Yufei Huang, Stan Z. Li
Categories: cs.LG
\\
 To bridge the gaps between topology-aware Graph Neural Networks (GNNs) and
inference-efficient Multi-Layer Perceptron (MLPs), GLNN proposes to distill
knowledge from a well-trained teacher GNN into a student MLP. Despite their
great progress, comparatively little work has been done to explore the
reliability of different knowledge points (nodes) in GNNs, especially their
roles played during distillation. In this paper, we first quantify the
knowledge reliability in GNN by measuring the invariance of their information
entropy to noise perturbations, from which we observe that different knowledge
points (1) show different distillation speeds (temporally); (2) are
differentially distributed in the graph (spatially). To achieve reliable
distillation, we propose an effective approach, namely Knowledge-inspired
Reliable Distillation (KRD), that models the probability of each node being an
informative and reliable knowledge point, based on which we sample a set of
additional reliable knowledge points as supervision for training student MLPs.
Extensive experiments show that KRD improves over the vanilla MLPs by 12.62%
and outperforms its corresponding teacher GNNs by 2.16% averaged over 7
datasets and 3 GNN architectures.
\\ ( https://arxiv.org/abs/2306.05628 ,  2721kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05637
Date: Fri, 9 Jun 2023 02:47:21 GMT   (2621kb,D)

Title: On the Importance of Feature Decorrelation for Unsupervised
 Representation Learning in Reinforcement Learning
Authors: Hojoon Lee and Koanho Lee and Dongyoon Hwang and Hyunho Lee and
 Byungkun Lee and Jaegul Choo
Categories: cs.LG
Comments: Accepted to ICML 2023
\\
 Recently, unsupervised representation learning (URL) has improved the sample
efficiency of Reinforcement Learning (RL) by pretraining a model from a large
unlabeled dataset. The underlying principle of these methods is to learn
temporally predictive representations by predicting future states in the latent
space. However, an important challenge of this approach is the representational
collapse, where the subspace of the latent representations collapses into a
low-dimensional manifold. To address this issue, we propose a novel URL
framework that causally predicts future states while increasing the dimension
of the latent manifold by decorrelating the features in the latent space.
Through extensive empirical studies, we demonstrate that our framework
effectively learns predictive representations without collapse, which
significantly improves the sample efficiency of state-of-the-art URL methods on
the Atari 100k benchmark. The code is available at
https://github.com/dojeon-ai/SimTPR.
\\ ( https://arxiv.org/abs/2306.05637 ,  2621kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05641
Date: Fri, 9 Jun 2023 03:00:34 GMT   (3608kb,D)

Title: Revisiting Permutation Symmetry for Merging Models between Different
 Datasets
Authors: Masanori Yamada, Tomoya Yamashita, Shin'ya Yamaguchi, Daiki Chijiwa
Categories: cs.LG cs.AI
Comments: 18 pages; comments are welcome
\\
 Model merging is a new approach to creating a new model by combining the
weights of different trained models. Previous studies report that model merging
works well for models trained on a single dataset with different random seeds,
while model merging between different datasets is difficult. Merging knowledge
from different datasets has practical significance, but it has not been well
investigated. In this paper, we investigate the properties of merging models
between different datasets. Through theoretical and empirical analyses, we find
that the accuracy of the merged model decreases more significantly as the
datasets diverge more and that the different loss landscapes for each dataset
make model merging between different datasets difficult. We also show that
merged models require datasets for merging in order to achieve a high accuracy.
Furthermore, we show that condensed datasets created by dataset condensation
can be used as substitutes for the original datasets when merging models. We
conduct experiments for model merging between different datasets. When merging
between MNIST and Fashion- MNIST models, the accuracy significantly improves by
28% using the dataset and 25% using the condensed dataset compared with not
using the dataset.
\\ ( https://arxiv.org/abs/2306.05641 ,  3608kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05651
Date: Fri, 9 Jun 2023 03:37:27 GMT   (1143kb,D)

Title: Differentially Private Sharpness-Aware Training
Authors: Jinseong Park, Hoki Kim, Yujin Choi, Jaewook Lee
Categories: cs.LG cs.AI cs.CR
Comments: ICML 2023
\\
 Training deep learning models with differential privacy (DP) results in a
degradation of performance. The training dynamics of models with DP show a
significant difference from standard training, whereas understanding the
geometric properties of private learning remains largely unexplored. In this
paper, we investigate sharpness, a key factor in achieving better
generalization, in private learning. We show that flat minima can help reduce
the negative effects of per-example gradient clipping and the addition of
Gaussian noise. We then verify the effectiveness of Sharpness-Aware
Minimization (SAM) for seeking flat minima in private learning. However, we
also discover that SAM is detrimental to the privacy budget and computational
time due to its two-step optimization. Thus, we propose a new sharpness-aware
training method that mitigates the privacy-optimization trade-off. Our
experimental results demonstrate that the proposed method improves the
performance of deep learning models with DP from both scratch and fine-tuning.
Code is available at https://github.com/jinseongP/DPSAT.
\\ ( https://arxiv.org/abs/2306.05651 ,  1143kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05655
Date: Fri, 9 Jun 2023 03:51:45 GMT   (4018kb,D)

Title: Communication-Efficient Zeroth-Order Distributed Online Optimization:
 Algorithm, Theory, and Applications
Authors: Ege C. Kaya, M. Berk Sahin and Abolfazl Hashemi
Categories: cs.LG math.OC
Comments: 21 pages, 5 figures, and this paper has been accepted by IEEE Access
DOI: 10.1109/ACCESS.2023.3284891
\\
 This paper focuses on a multi-agent zeroth-order online optimization problem
in a federated learning setting for target tracking. The agents only sense
their current distances to their targets and aim to maintain a minimum safe
distance from each other to prevent collisions. The coordination among the
agents and dissemination of collision-prevention information is managed by a
central server using the federated learning paradigm. The proposed formulation
leads to an instance of distributed online nonconvex optimization problem that
is solved via a group of communication-constrained agents. To deal with the
communication limitations of the agents, an error feedback-based compression
scheme is utilized for agent-to-server communication. The proposed algorithm is
analyzed theoretically for the general class of distributed online nonconvex
optimization problems. We provide non-asymptotic convergence rates that show
the dominant term is independent of the characteristics of the compression
scheme. Our theoretical results feature a new approach that employs
significantly more relaxed assumptions in comparison to standard literature.
The performance of the proposed solution is further analyzed numerically in
terms of tracking errors and collisions between agents in two relevant
applications.
\\ ( https://arxiv.org/abs/2306.05655 ,  4018kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05670
Date: Fri, 9 Jun 2023 04:59:24 GMT   (2047kb,D)

Title: One-Shot Machine Unlearning with Mnemonic Code
Authors: Tomoya Yamashita and Masanori Yamada and Takashi Shibata
Categories: cs.LG cs.AI cs.CV
Comments: 14 pages, welcome coments
\\
 Deep learning has achieved significant improvements in accuracy and has been
applied to various fields. With the spread of deep learning, a new problem has
also emerged; deep learning models can sometimes have undesirable information
from an ethical standpoint. This problem must be resolved if deep learning is
to make sensitive decisions such as hiring and prison sentencing. Machine
unlearning (MU) is the research area that responds to such demands. MU aims at
forgetting about undesirable training data from a trained deep learning model.
A naive MU approach is to re-train the whole model with the training data from
which the undesirable data has been removed. However, re-training the whole
model can take a huge amount of time and consumes significant computer
resources. To make MU even more practical, a simple-yet-effective MU method is
required. In this paper, we propose a one-shot MU method, which does not need
additional training. To design one-shot MU, we add noise to the model
parameters that are sensitive to undesirable information. In our proposed
method, we use the Fisher information matrix (FIM) to estimate the sensitive
model parameters. Training data were usually used to evaluate the FIM in
existing methods. In contrast, we avoid the need to retain the training data
for calculating the FIM by using class-specific synthetic signals called
mnemonic code. Extensive experiments using artificial and natural datasets
demonstrate that our method outperforms the existing methods.
\\ ( https://arxiv.org/abs/2306.05670 ,  2047kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05697
Date: Fri, 9 Jun 2023 06:34:16 GMT   (8097kb,D)

Title: Group Equivariant Fourier Neural Operators for Partial Differential
 Equations
Authors: Jacob Helwig, Xuan Zhang, Cong Fu, Jerry Kurtin, Stephan Wojtowytsch,
 Shuiwang Ji
Categories: cs.LG cs.NA math.NA
Comments: Proceedings of the 40th International Conference on Machine Learning
 https://icml.cc/virtual/2023/poster/23875
\\
 We consider solving partial differential equations (PDEs) with Fourier neural
operators (FNOs), which operate in the frequency domain. Since the laws of
physics do not depend on the coordinate system used to describe them, it is
desirable to encode such symmetries in the neural operator architecture for
better performance and easier learning. While encoding symmetries in the
physical domain using group theory has been studied extensively, how to capture
symmetries in the frequency domain is under-explored. In this work, we extend
group convolutions to the frequency domain and design Fourier layers that are
equivariant to rotations, translations, and reflections by leveraging the
equivariance property of the Fourier transform. The resulting $G$-FNO
architecture generalizes well across input resolutions and performs well in
settings with varying levels of symmetry. Our code is publicly available as
part of the AIRS library (https://github.com/divelab/AIRS).
\\ ( https://arxiv.org/abs/2306.05697 ,  8097kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05706
Date: Fri, 9 Jun 2023 06:55:15 GMT   (532kb,D)

Title: Understanding How Consistency Works in Federated Learning via Stage-wise
 Relaxed Initialization
Authors: Yan Sun, Li Shen, Dacheng Tao
Categories: cs.LG cs.DC math.OC
Comments: 32 pages
\\
 Federated learning (FL) is a distributed paradigm that coordinates massive
local clients to collaboratively train a global model via stage-wise local
training processes on the heterogeneous dataset. Previous works have implicitly
studied that FL suffers from the ``client-drift'' problem, which is caused by
the inconsistent optimum across local clients. However, till now it still lacks
solid theoretical analysis to explain the impact of this local inconsistency.
To alleviate the negative impact of the ``client drift'' and explore its
substance in FL, in this paper, we first design an efficient FL algorithm
\textit{FedInit}, which allows employing the personalized relaxed
initialization state at the beginning of each local training stage.
Specifically, \textit{FedInit} initializes the local state by moving away from
the current global state towards the reverse direction of the latest local
state. This relaxed initialization helps to revise the local divergence and
enhance the local consistency level. Moreover, to further understand how
inconsistency disrupts performance in FL, we introduce the excess risk analysis
and study the divergence term to investigate the test error of the proposed
\textit{FedInit} method. Our studies show that optimization error is not
sensitive to this local inconsistency, while it mainly affects the
generalization error bound in \textit{FedInit}. Extensive experiments are
conducted to validate this conclusion. Our proposed \textit{FedInit} could
achieve state-of-the-art~(SOTA) results compared to several advanced benchmarks
without any additional costs. Meanwhile, stage-wise relaxed initialization
could also be incorporated into the current advanced algorithms to achieve
higher performance in the FL paradigm.
\\ ( https://arxiv.org/abs/2306.05706 ,  532kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05722
Date: Fri, 9 Jun 2023 07:38:38 GMT   (1054kb)

Title: Estimation of Ridge Using Nonlinear Transformation on Density Function
Authors: Zheng Zhai and Hengchao Chen and Zhigang Yao
Categories: cs.LG stat.ML
\\
 Ridges play a vital role in accurately approximating the underlying structure
of manifolds. In this paper, we explore the ridge's variation by applying a
concave nonlinear transformation to the density function. Through the
derivation of the Hessian matrix, we observe that nonlinear transformations
yield a rank-one modification of the Hessian matrix. Leveraging the variational
properties of eigenvalue problems, we establish a partial order inclusion
relationship among the corresponding ridges. We intuitively discover that the
transformation can lead to improved estimation of the tangent space via
rank-one modification of the Hessian matrix. To validate our theories, we
conduct extensive numerical experiments on synthetic and real-world datasets
that demonstrate the superiority of the ridges obtained from our transformed
approach in approximating the underlying truth manifold compared to other
manifold fitting algorithms.
\\ ( https://arxiv.org/abs/2306.05722 ,  1054kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05726
Date: Fri, 9 Jun 2023 07:46:24 GMT   (1607kb,D)

Title: In-Sample Policy Iteration for Offline Reinforcement Learning
Authors: Xiaohan Hu, Yi Ma, Chenjun Xiao, Yan Zheng, Zhaopeng Meng
Categories: cs.LG cs.AI
\\
 Offline reinforcement learning (RL) seeks to derive an effective control
policy from previously collected data. To circumvent errors due to inadequate
data coverage, behavior-regularized methods optimize the control policy while
concurrently minimizing deviation from the data collection policy.
Nevertheless, these methods often exhibit subpar practical performance,
particularly when the offline dataset is collected by sub-optimal policies. In
this paper, we propose a novel algorithm employing in-sample policy iteration
that substantially enhances behavior-regularized methods in offline RL. The
core insight is that by continuously refining the policy used for behavior
regularization, in-sample policy iteration gradually improves itself while
implicitly avoids querying out-of-sample actions to avert catastrophic learning
failures. Our theoretical analysis verifies its ability to learn the in-sample
optimal policy, exclusively utilizing actions well-covered by the dataset.
Moreover, we propose competitive policy improvement, a technique applying two
competitive policies, both of which are trained by iteratively improving over
the best competitor. We show that this simple yet potent technique
significantly enhances learning efficiency when function approximation is
applied. Lastly, experimental results on the D4RL benchmark indicate that our
algorithm outperforms previous state-of-the-art methods in most tasks.
\\ ( https://arxiv.org/abs/2306.05726 ,  1607kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05727
Date: Fri, 9 Jun 2023 07:48:36 GMT   (296kb,D)

Title: The Role of Diverse Replay for Generalisation in Reinforcement Learning
Authors: Max Weltevrede, Matthijs T.J. Spaan, Wendelin B\"ohmer
Categories: cs.LG
Comments: 14 pages, 8 figures
\\
 In reinforcement learning (RL), key components of many algorithms are the
exploration strategy and replay buffer. These strategies regulate what
environment data is collected and trained on and have been extensively studied
in the RL literature. In this paper, we investigate the impact of these
components in the context of generalisation in multi-task RL. We investigate
the hypothesis that collecting and training on more diverse data from the
training environment will improve zero-shot generalisation to new
environments/tasks. We motivate mathematically and show empirically that
generalisation to states that are "reachable" during training is improved by
increasing the diversity of transitions in the replay buffer. Furthermore, we
show empirically that this same strategy also shows improvement for
generalisation to similar but "unreachable" states and could be due to improved
generalisation of latent representations.
\\ ( https://arxiv.org/abs/2306.05727 ,  296kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05734
Date: Fri, 9 Jun 2023 07:55:46 GMT   (1580kb,D)

Title: DP-HyPO: An Adaptive Private Hyperparameter Optimization Framework
Authors: Hua Wang, Sheng Gao, Huanyu Zhang, Weijie J. Su, Milan Shen
Categories: cs.LG cs.CR cs.DS
\\
 Hyperparameter optimization, also known as hyperparameter tuning, is a widely
recognized technique for improving model performance. Regrettably, when
training private ML models, many practitioners often overlook the privacy risks
associated with hyperparameter optimization, which could potentially expose
sensitive information about the underlying dataset. Currently, the sole
existing approach to allow privacy-preserving hyperparameter optimization is to
uniformly and randomly select hyperparameters for a number of runs,
subsequently reporting the best-performing hyperparameter. In contrast, in
non-private settings, practitioners commonly utilize "adaptive" hyperparameter
optimization methods such as Gaussian process-based optimization, which select
the next candidate based on information gathered from previous outputs. This
substantial contrast between private and non-private hyperparameter
optimization underscores a critical concern. In our paper, we introduce
DP-HyPO, a pioneering framework for "adaptive" private hyperparameter
optimization, aiming to bridge the gap between private and non-private
hyperparameter optimization. To accomplish this, we provide a comprehensive
differential privacy analysis of our framework. Furthermore, we empirically
demonstrate the effectiveness of DP-HyPO on a diverse set of real-world and
synthetic datasets.
\\ ( https://arxiv.org/abs/2306.05734 ,  1580kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05751
Date: Fri, 9 Jun 2023 08:30:51 GMT   (1593kb,D)

Title: Advancing Counterfactual Inference through Quantile Regression
Authors: Shaoan Xie, Biwei Huang, Bin Gu, Tongliang Liu, Kun Zhang
Categories: cs.LG stat.ME
\\
 The capacity to address counterfactual "what if" inquiries is crucial for
understanding and making use of causal influences. Traditional counterfactual
inference usually assumes a structural causal model is available. However, in
practice, such a causal model is often unknown and may not be identifiable.
This paper aims to perform reliable counterfactual inference based on the
(learned) qualitative causal structure and observational data, without a given
causal model or even directly estimating conditional distributions. We re-cast
counterfactual reasoning as an extended quantile regression problem using
neural networks. The approach is statistically more efficient than existing
ones, and further makes it possible to develop the generalization ability of
the estimated counterfactual outcome to unseen data and provide an upper bound
on the generalization error. Experiment results on multiple datasets strongly
support our theoretical claims.
\\ ( https://arxiv.org/abs/2306.05751 ,  1593kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05760
Date: Fri, 9 Jun 2023 08:54:20 GMT   (735kb,D)

Title: Efficient GNN Explanation via Learning Removal-based Attribution
Authors: Yao Rong, Guanchu Wang, Qizhang Feng, Ninghao Liu, Zirui Liu,
 Enkelejda Kasneci, Xia Hu
Categories: cs.LG cs.AI
\\
 As Graph Neural Networks (GNNs) have been widely used in real-world
applications, model explanations are required not only by users but also by
legal regulations. However, simultaneously achieving high fidelity and low
computational costs in generating explanations has been a challenge for current
methods. In this work, we propose a framework of GNN explanation named LeArn
Removal-based Attribution (LARA) to address this problem. Specifically, we
introduce removal-based attribution and demonstrate its substantiated link to
interpretability fidelity theoretically and experimentally. The explainer in
LARA learns to generate removal-based attribution which enables providing
explanations with high fidelity. A strategy of subgraph sampling is designed in
LARA to improve the scalability of the training process. In the deployment,
LARA can efficiently generate the explanation through a feed-forward pass. We
benchmark our approach with other state-of-the-art GNN explanation methods on
six datasets. Results highlight the effectiveness of our framework regarding
both efficiency and fidelity. In particular, LARA is 3.5 times faster and
achieves higher fidelity than the state-of-the-art method on the large dataset
ogbn-arxiv (more than 160K nodes and 1M edges), showing its great potential in
real-world applications. Our source code is available at
https://anonymous.4open.science/r/LARA-10D8/README.md.
\\ ( https://arxiv.org/abs/2306.05760 ,  735kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05764
Date: Fri, 9 Jun 2023 08:57:14 GMT   (1156kb,D)

Title: Fair yet Asymptotically Equal Collaborative Learning
Authors: Xiaoqiang Lin, Xinyi Xu, See-Kiong Ng, Chuan-Sheng Foo, Bryan Kian
 Hsiang Low
Categories: cs.LG cs.AI cs.GT cs.MA
Comments: Accepted to 40th International Conference on Machine Learning (ICML
 2023), 37 pages
\\
 In collaborative learning with streaming data, nodes (e.g., organizations)
jointly and continuously learn a machine learning (ML) model by sharing the
latest model updates computed from their latest streaming data. For the more
resourceful nodes to be willing to share their model updates, they need to be
fairly incentivized. This paper explores an incentive design that guarantees
fairness so that nodes receive rewards commensurate to their contributions. Our
approach leverages an explore-then-exploit formulation to estimate the nodes'
contributions (i.e., exploration) for realizing our theoretically guaranteed
fair incentives (i.e., exploitation). However, we observe a "rich get richer"
phenomenon arising from the existing approaches to guarantee fairness and it
discourages the participation of the less resourceful nodes. To remedy this, we
additionally preserve asymptotic equality, i.e., less resourceful nodes achieve
equal performance eventually to the more resourceful/"rich" nodes. We
empirically demonstrate in two settings with real-world streaming data:
federated online incremental learning and federated reinforcement learning,
that our proposed approach outperforms existing baselines in fairness and
learning performance while remaining competitive in preserving equality.
\\ ( https://arxiv.org/abs/2306.05764 ,  1156kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05769
Date: Fri, 9 Jun 2023 09:17:51 GMT   (965kb,D)

Title: Self-Paced Absolute Learning Progress as a Regularized Approach to
 Curriculum Learning
Authors: Tobias Niehues, Ulla Scheler, Pascal Klink
Categories: cs.LG
Comments: 11 pages, 8 figures. The paper was a result from an Integrated
 Project at TU Darmstadt for which we received course credit (9 ECTS) and is
 not meant to be published elsewhere
\\
 The usability of Reinforcement Learning is restricted by the large
computation times it requires. Curriculum Reinforcement Learning speeds up
learning by defining a helpful order in which an agent encounters tasks, i.e.
from simple to hard. Curricula based on Absolute Learning Progress (ALP) have
proven successful in different environments, but waste computation on repeating
already learned behaviour in new tasks. We solve this problem by introducing a
new regularization method based on Self-Paced (Deep) Learning, called
Self-Paced Absolute Learning Progress (SPALP). We evaluate our method in three
different environments. Our method achieves performance comparable to original
ALP in all cases, and reaches it quicker than ALP in two of them. We illustrate
possibilities to further improve the efficiency and performance of SPALP.
\\ ( https://arxiv.org/abs/2306.05769 ,  965kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05775
Date: Fri, 9 Jun 2023 09:33:34 GMT   (4608kb,D)

Title: Weight Freezing: A Regularization Approach for Fully Connected Layers
 with an Application in EEG Classification
Authors: Zhengqing Miao and Meirong Zhao
Categories: cs.LG eess.SP
Comments: 16 pages, 5 figures
\\
 In the realm of EEG decoding, enhancing the performance of artificial neural
networks (ANNs) carries significant potential. This study introduces a novel
approach, termed "weight freezing", that is anchored on the principles of ANN
regularization and neuroscience prior knowledge. The concept of weight freezing
revolves around the idea of reducing certain neurons' influence on the
decision-making process for a specific EEG task by freezing specific weights in
the fully connected layer during the backpropagation process. This is
actualized through the use of a mask matrix and a threshold to determine the
proportion of weights to be frozen during backpropagation. Moreover, by setting
the masked weights to zero, weight freezing can not only realize sparse
connections in networks with a fully connected layer as the classifier but also
function as an efficacious regularization method for fully connected layers.
Through experiments involving three distinct ANN architectures and three widely
recognized EEG datasets, we validate the potency of weight freezing. Our method
significantly surpasses previous peak performances in classification accuracy
across all examined datasets. Supplementary control experiments offer insights
into performance differences pre and post weight freezing implementation and
scrutinize the influence of the threshold in the weight freezing process. Our
study underscores the superior efficacy of weight freezing compared to
traditional fully connected networks for EEG feature classification tasks. With
its proven effectiveness, this innovative approach holds substantial promise
for contributing to future strides in EEG decoding research.
\\ ( https://arxiv.org/abs/2306.05775 ,  4608kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05779
Date: Fri, 9 Jun 2023 09:46:38 GMT   (7457kb,D)

Title: Transformer-based Time-to-Event Prediction for Chronic Kidney Disease
 Deterioration
Authors: Moshe Zisser and Dvir Aran
Categories: cs.LG cs.CL
\\
 Deep-learning techniques, particularly the transformer model, have shown
great potential in enhancing the prediction performance of longitudinal health
records. While previous methods have mainly focused on fixed-time risk
prediction, time-to-event prediction (also known as survival analysis) is often
more appropriate for clinical scenarios. Here, we present a novel deep-learning
architecture we named STRAFE, a generalizable survival analysis
transformer-based architecture for electronic health records. The performance
of STRAFE was evaluated using a real-world claim dataset of over 130,000
individuals with stage 3 chronic kidney disease (CKD) and was found to
outperform other time-to-event prediction algorithms in predicting the exact
time of deterioration to stage 5. Additionally, STRAFE was found to outperform
binary outcome algorithms in predicting fixed-time risk, possibly due to its
ability to train on censored data. We show that STRAFE predictions can improve
the positive predictive value of high-risk patients by 3-fold, demonstrating
possible usage to improve targeting for intervention programs. Finally, we
suggest a novel visualization approach to predictions on a per-patient basis.
In conclusion, STRAFE is a cutting-edge time-to-event prediction algorithm that
has the potential to enhance risk predictions in large claims datasets.
\\ ( https://arxiv.org/abs/2306.05779 ,  7457kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05781
Date: Fri, 9 Jun 2023 09:49:16 GMT   (2543kb,D)

Title: Adaptivity Complexity for Causal Graph Discovery
Authors: Davin Choo, Kirankumar Shiragur
Categories: cs.LG cs.AI cs.DS stat.ME stat.ML
Comments: Accepted into UAI 2023
\\
 Causal discovery from interventional data is an important problem, where the
task is to design an interventional strategy that learns the hidden ground
truth causal graph $G(V,E)$ on $|V| = n$ nodes while minimizing the number of
performed interventions. Most prior interventional strategies broadly fall into
two categories: non-adaptive and adaptive. Non-adaptive strategies decide on a
single fixed set of interventions to be performed while adaptive strategies can
decide on which nodes to intervene on sequentially based on past interventions.
While adaptive algorithms may use exponentially fewer interventions than their
non-adaptive counterparts, there are practical concerns that constrain the
amount of adaptivity allowed. Motivated by this trade-off, we study the problem
of $r$-adaptivity, where the algorithm designer recovers the causal graph under
a total of $r$ sequential rounds whilst trying to minimize the total number of
interventions. For this problem, we provide a $r$-adaptive algorithm that
achieves $O(\min\{r,\log n\} \cdot n^{1/\min\{r,\log n\}})$ approximation with
respect to the verification number, a well-known lower bound for adaptive
algorithms. Furthermore, for every $r$, we show that our approximation is
tight. Our definition of $r$-adaptivity interpolates nicely between the
non-adaptive ($r=1$) and fully adaptive ($r=n$) settings where our
approximation simplifies to $O(n)$ and $O(\log n)$ respectively, matching the
best-known approximation guarantees for both extremes. Our results also extend
naturally to the bounded size interventions.
\\ ( https://arxiv.org/abs/2306.05781 ,  2543kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05784
Date: Fri, 9 Jun 2023 09:55:20 GMT   (1635kb,D)

Title: Quantitative Ink Analysis: Estimating the Number of Inks in Documents
 through Hyperspectral Imaging
Authors: Aneeqa Abrar, Hamza Iqbal
Categories: cs.LG eess.IV
\\
 In the field of document forensics, ink analysis plays a crucial role in
determining the authenticity of legal and historic documents and detecting
forgery. Visual examination alone is insufficient for distinguishing visually
similar inks, necessitating the use of advanced scientific techniques. This
paper proposes an ink analysis technique based on hyperspectral imaging, which
enables the examination of documents in hundreds of narrowly spaced spectral
bands, revealing hidden details. The main objective of this study is to
identify the number of distinct inks used in a document. Three clustering
algorithms, namely k-means, Agglomerative, and c-means, are employed to
estimate the number of inks present. The methodology involves data extraction,
ink pixel segmentation, and ink number determination. The results demonstrate
the effectiveness of the proposed technique in identifying ink clusters and
distinguishing between different inks. The analysis of a hyperspectral cube
dataset reveals variations in spectral reflectance across different bands and
distinct spectral responses among the 12 lines, indicating the presence of
multiple inks. The clustering algorithms successfully identify ink clusters,
with k-means clustering showing superior classification performance. These
findings contribute to the development of reliable methodologies for ink
analysis using hyperspectral imaging, enhancing the
\\ ( https://arxiv.org/abs/2306.05784 ,  1635kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05785
Date: Fri, 9 Jun 2023 09:57:17 GMT   (466kb,D)

Title: End-to-End Neural Network Compression via $\frac{\ell_1}{\ell_2}$
 Regularized Latency Surrogates
Authors: Anshul Nasery, Hardik Shah, Arun Sai Suggala, Prateek Jain
Categories: cs.LG
\\
 Neural network (NN) compression via techniques such as pruning, quantization
requires setting compression hyperparameters (e.g., number of channels to be
pruned, bitwidths for quantization) for each layer either manually or via
neural architecture search (NAS) which can be computationally expensive. We
address this problem by providing an end-to-end technique that optimizes for
model's Floating Point Operations (FLOPs) or for on-device latency via a novel
$\frac{\ell_1}{\ell_2}$ latency surrogate. Our algorithm is versatile and can
be used with many popular compression methods including pruning, low-rank
factorization, and quantization. Crucially, it is fast and runs in almost the
same amount of time as single model training; which is a significant training
speed-up over standard NAS methods. For BERT compression on GLUE fine-tuning
tasks, we achieve $50\%$ reduction in FLOPs with only $1\%$ drop in
performance. For compressing MobileNetV3 on ImageNet-1K, we achieve $15\%$
reduction in FLOPs, and $11\%$ reduction in on-device latency without drop in
accuracy, while still requiring $3\times$ less training compute than SOTA
compression techniques. Finally, for transfer learning on smaller datasets, our
technique identifies $1.2\times$-$1.4\times$ cheaper architectures than
standard MobileNetV3, EfficientNet suite of architectures at almost the same
training cost and accuracy.
\\ ( https://arxiv.org/abs/2306.05785 ,  466kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05786
Date: Fri, 9 Jun 2023 09:57:18 GMT   (1570kb,D)

Title: Two-level histograms for dealing with outliers and heavy tail
 distributions
Authors: Marc Boull\'e
Categories: cs.LG
Comments: 30 pages, 47 figures
\\
 Histograms are among the most popular methods used in exploratory analysis to
summarize univariate distributions. In particular, irregular histograms are
good non-parametric density estimators that require very few parameters: the
number of bins with their lengths and frequencies. Many approaches have been
proposed in the literature to infer these parameters, either assuming
hypotheses about the underlying data distributions or exploiting a model
selection approach. In this paper, we focus on the G-Enum histogram method,
which exploits the Minimum Description Length (MDL) principle to build
histograms without any user parameter and achieves state-of-the art performance
w.r.t accuracy; parsimony and computation time. We investigate on the limits of
this method in the case of outliers or heavy-tailed distributions. We suggest a
two-level heuristic to deal with such cases. The first level exploits a
logarithmic transformation of the data to split the data set into a list of
data subsets with a controlled range of values. The second level builds a
sub-histogram for each data subset and aggregates them to obtain a complete
histogram. Extensive experiments show the benefits of the approach.
\\ ( https://arxiv.org/abs/2306.05786 ,  1570kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05805
Date: Fri, 9 Jun 2023 10:42:32 GMT   (742kb,D)

Title: DynaBench: A benchmark dataset for learning dynamical systems from
 low-resolution data
Authors: Andrzej Dulny and Andreas Hotho and Anna Krause
Categories: cs.LG
\\
 Previous work on learning physical systems from data has focused on
high-resolution grid-structured measurements. However, real-world knowledge of
such systems (e.g. weather data) relies on sparsely scattered measuring
stations. In this paper, we introduce a novel simulated benchmark dataset,
DynaBench, for learning dynamical systems directly from sparsely scattered data
without prior knowledge of the equations. The dataset focuses on predicting the
evolution of a dynamical system from low-resolution, unstructured measurements.
We simulate six different partial differential equations covering a variety of
physical systems commonly used in the literature and evaluate several machine
learning models, including traditional graph neural networks and point cloud
processing models, with the task of predicting the evolution of the system. The
proposed benchmark dataset is expected to advance the state of art as an
out-of-the-box easy-to-use tool for evaluating models in a setting where only
unstructured low-resolution observations are available. The benchmark is
available at https://anonymous.4open.science/r/code-2022-dynabench/.
\\ ( https://arxiv.org/abs/2306.05805 ,  742kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05810
Date: Fri, 9 Jun 2023 10:52:39 GMT   (137kb,D)

Title: Explaining Reinforcement Learning with Shapley Values
Authors: Daniel Beechey, Thomas M. S. Smith, \"Ozg\"ur \c{S}im\c{s}ek
Categories: cs.LG
Comments: 12 pages, 9 figures. Accepted at ICML 2023
\\
 For reinforcement learning systems to be widely adopted, their users must
understand and trust them. We present a theoretical analysis of explaining
reinforcement learning using Shapley values, following a principled approach
from game theory for identifying the contribution of individual players to the
outcome of a cooperative game. We call this general framework Shapley Values
for Explaining Reinforcement Learning (SVERL). Our analysis exposes the
limitations of earlier uses of Shapley values in reinforcement learning. We
then develop an approach that uses Shapley values to explain agent performance.
In a variety of domains, SVERL produces meaningful explanations that match and
supplement human intuition.
\\ ( https://arxiv.org/abs/2306.05810 ,  137kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05813
Date: Fri, 9 Jun 2023 11:12:55 GMT   (12505kb,D)

Title: Incorporating Prior Knowledge in Deep Learning Models via Pathway
 Activity Autoencoders
Authors: Pedro Henrique da Costa Avelar, Min Wu, Sophia Tsoka
Categories: cs.LG cs.AI cs.NE
\\
 Motivation: Despite advances in the computational analysis of high-throughput
molecular profiling assays (e.g. transcriptomics), a dichotomy exists between
methods that are simple and interpretable, and ones that are complex but with
lower degree of interpretability. Furthermore, very few methods deal with
trying to translate interpretability in biologically relevant terms, such as
known pathway cascades. Biological pathways reflecting signalling events or
metabolic conversions are Small improvements or modifications of existing
algorithms will generally not be suitable, unless novel biological results have
been predicted and verified. Determining which pathways are implicated in
disease and incorporating such pathway data as prior knowledge may enhance
predictive modelling and personalised strategies for diagnosis, treatment and
prevention of disease.
 Results: We propose a novel prior-knowledge-based deep auto-encoding
framework, PAAE, together with its accompanying generative variant, PAVAE, for
RNA-seq data in cancer. Through comprehensive comparisons among various
learning models, we show that, despite having access to a smaller set of
features, our PAAE and PAVAE models achieve better out-of-set reconstruction
results compared to common methodologies. Furthermore, we compare our model
with equivalent baselines on a classification task and show that they achieve
better results than models which have access to the full input gene set.
Another result is that using vanilla variational frameworks might negatively
impact both reconstruction outputs as well as classification performance.
Finally, our work directly contributes by providing comprehensive
interpretability analyses on our models on top of improving prognostication for
translational medicine.
\\ ( https://arxiv.org/abs/2306.05813 ,  12505kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05815
Date: Fri, 9 Jun 2023 11:27:35 GMT   (289kb,D)

Title: Extending Kernel PCA through Dualization: Sparsity, Robustness and Fast
 Algorithms
Authors: Francesco Tonin, Alex Lambert, Panagiotis Patrinos, Johan A. K.
 Suykens
Categories: cs.LG stat.ML
Comments: 15 pages, ICML 2023
\\
 The goal of this paper is to revisit Kernel Principal Component Analysis
(KPCA) through dualization of a difference of convex functions. This allows to
naturally extend KPCA to multiple objective functions and leads to efficient
gradient-based algorithms avoiding the expensive SVD of the Gram matrix.
Particularly, we consider objective functions that can be written as Moreau
envelopes, demonstrating how to promote robustness and sparsity within the same
framework. The proposed method is evaluated on synthetic and real-world
benchmarks, showing significant speedup in KPCA training time as well as
highlighting the benefits in terms of robustness and sparsity.
\\ ( https://arxiv.org/abs/2306.05815 ,  289kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05838
Date: Fri, 9 Jun 2023 12:12:07 GMT   (29kb)

Title: Expectation-Complete Graph Representations with Homomorphisms
Authors: Pascal Welke, Maximilian Thiessen, Fabian Jogl, Thomas G\"artner
Categories: cs.LG cs.DS
Comments: accepted for publication at ICML 2023
\\
 We investigate novel random graph embeddings that can be computed in expected
polynomial time and that are able to distinguish all non-isomorphic graphs in
expectation. Previous graph embeddings have limited expressiveness and either
cannot distinguish all graphs or cannot be computed efficiently for every
graph. To be able to approximate arbitrary functions on graphs, we are
interested in efficient alternatives that become arbitrarily expressive with
increasing resources. Our approach is based on Lov\'asz' characterisation of
graph isomorphism through an infinite dimensional vector of homomorphism
counts. Our empirical evaluation shows competitive results on several benchmark
graph learning tasks.
\\ ( https://arxiv.org/abs/2306.05838 ,  29kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05843
Date: Fri, 9 Jun 2023 12:17:18 GMT   (5115kb,D)

Title: Domain-Agnostic Batch Bayesian Optimization with Diverse Constraints via
 Bayesian Quadrature
Authors: Masaki Adachi, Satoshi Hayakawa, Xingchen Wan, Martin J{\o}rgensen,
 Harald Oberhauser, Michael A. Osborne
Categories: cs.LG cs.AI cs.NA math.NA stat.CO stat.ML
Comments: 24 pages, 5 figures
MSC-class: 62C10, 62F15
\\
 Real-world optimisation problems often feature complex combinations of (1)
diverse constraints, (2) discrete and mixed spaces, and are (3) highly
parallelisable. (4) There are also cases where the objective function cannot be
queried if unknown constraints are not satisfied, e.g. in drug discovery,
safety on animal experiments (unknown constraints) must be established before
human clinical trials (querying objective function) may proceed. However, most
existing works target each of the above three problems in isolation and do not
consider (4) unknown constraints with query rejection. For problems with
diverse constraints and/or unconventional input spaces, it is difficult to
apply these techniques as they are often mutually incompatible. We propose
cSOBER, a domain-agnostic prudent parallel active sampler for Bayesian
optimisation, based on SOBER of Adachi et al. (2023). We consider infeasibility
under unknown constraints as a type of integration error that we can estimate.
We propose a theoretically-driven approach that propagates such error as a
tolerance in the quadrature precision that automatically balances exploitation
and exploration with the expected rejection rate. Moreover, our method flexibly
accommodates diverse constraints and/or discrete and mixed spaces via adaptive
tolerance, including conventional zero-risk cases. We show that cSOBER
outperforms competitive baselines on diverse real-world blackbox-constrained
problems, including safety-constrained drug discovery, and
human-relationship-aware team optimisation over graph-structured space.
\\ ( https://arxiv.org/abs/2306.05843 ,  5115kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05859
Date: Fri, 9 Jun 2023 12:45:41 GMT   (8348kb,D)

Title: Robust Reinforcement Learning via Adversarial Kernel Approximation
Authors: Kaixin Wang, Uri Gadot, Navdeep Kumar, Kfir Levy, Shie Mannor
Categories: cs.LG
\\
 Robust Markov Decision Processes (RMDPs) provide a framework for sequential
decision-making that is robust to perturbations on the transition kernel.
However, robust reinforcement learning (RL) approaches in RMDPs do not scale
well to realistic online settings with high-dimensional domains. By
characterizing the adversarial kernel in RMDPs, we propose a novel approach for
online robust RL that approximates the adversarial kernel and uses a standard
(non-robust) RL algorithm to learn a robust policy. Notably, our approach can
be applied on top of any underlying RL algorithm, enabling easy scaling to
high-dimensional domains. Experiments in classic control tasks, MinAtar and
DeepMind Control Suite demonstrate the effectiveness and the applicability of
our method.
\\ ( https://arxiv.org/abs/2306.05859 ,  8348kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05865
Date: Fri, 9 Jun 2023 12:58:47 GMT   (462kb,D)

Title: Faster Discrete Convex Function Minimization with Predictions: The
 M-Convex Case
Authors: Taihei Oki, Shinsaku Sakaue
Categories: cs.LG cs.DS
\\
 Recent years have seen a growing interest in accelerating optimization
algorithms with machine-learned predictions. Sakaue and Oki (NeurIPS 2022) have
developed a general framework that warm-starts the L-convex function
minimization method with predictions, revealing the idea's usefulness for
various discrete optimization problems. In this paper, we present a framework
for using predictions to accelerate M-convex function minimization, thus
complementing previous research and extending the range of discrete
optimization algorithms that can benefit from predictions. Our framework is
particularly effective for an important subclass called laminar convex
minimization, which appears in many operations research applications. Our
methods can improve time complexity bounds upon the best worst-case results by
using predictions and even have potential to go beyond a lower-bound result.
\\ ( https://arxiv.org/abs/2306.05865 ,  462kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05873
Date: Fri, 9 Jun 2023 13:11:05 GMT   (1614kb,D)

Title: Detecting Adversarial Directions in Deep Reinforcement Learning to Make
 Robust Decisions
Authors: Ezgi Korkmaz, Jonah Brown-Cohen
Categories: cs.LG cs.AI cs.CR stat.ML
Comments: Published in ICML 2023
\\
 Learning in MDPs with highly complex state representations is currently
possible due to multiple advancements in reinforcement learning algorithm
design. However, this incline in complexity, and furthermore the increase in
the dimensions of the observation came at the cost of volatility that can be
taken advantage of via adversarial attacks (i.e. moving along worst-case
directions in the observation space). To solve this policy instability problem
we propose a novel method to detect the presence of these non-robust directions
via local quadratic approximation of the deep neural policy loss. Our method
provides a theoretical basis for the fundamental cut-off between safe
observations and adversarial observations. Furthermore, our technique is
computationally efficient, and does not depend on the methods used to produce
the worst-case directions. We conduct extensive experiments in the Arcade
Learning Environment with several different adversarial attack techniques. Most
significantly, we demonstrate the effectiveness of our approach even in the
setting where non-robust directions are explicitly optimized to circumvent our
proposed method.
\\ ( https://arxiv.org/abs/2306.05873 ,  1614kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05879
Date: Fri, 9 Jun 2023 13:18:50 GMT   (6134kb,D)

Title: Is Normalization Indispensable for Multi-domain Federated Learning?
Authors: Weiming Zhuang, Lingjuan Lyu
Categories: cs.LG cs.AI cs.CV cs.DC
\\
 Federated learning (FL) enhances data privacy with collaborative in-situ
training on decentralized clients. Nevertheless, FL encounters challenges due
to non-independent and identically distributed (non-i.i.d) data, leading to
potential performance degradation and hindered convergence. While prior studies
predominantly addressed the issue of skewed label distribution, our research
addresses a crucial yet frequently overlooked problem known as multi-domain FL.
In this scenario, clients' data originate from diverse domains with distinct
feature distributions, as opposed to label distributions. To address the
multi-domain problem in FL, we propose a novel method called Federated learning
Without normalizations (FedWon). FedWon draws inspiration from the observation
that batch normalization (BN) faces challenges in effectively modeling the
statistics of multiple domains, while alternative normalization techniques
possess their own limitations. In order to address these issues, FedWon
eliminates all normalizations in FL and reparameterizes convolution layers with
scaled weight standardization. Through comprehensive experimentation on four
datasets and four models, our results demonstrate that FedWon surpasses both
FedAvg and the current state-of-the-art method (FedBN) across all experimental
setups, achieving notable improvements of over 10% in certain domains.
Furthermore, FedWon is versatile for both cross-silo and cross-device FL,
exhibiting strong performance even with a batch size as small as 1, thereby
catering to resource-constrained devices. Additionally, FedWon effectively
tackles the challenge of skewed label distribution.
\\ ( https://arxiv.org/abs/2306.05879 ,  6134kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05880
Date: Fri, 9 Jun 2023 13:20:04 GMT   (738kb,D)

Title: Time Series Continuous Modeling for Imputation and Forecasting with
 Implicit Neural Representations
Authors: Etienne Le Naour, Louis Serrano, L\'eon Migus, Yuan Yin, patrick
 gallinari, Ghislain Agoua, Nicolas Baskiotis, Vincent Guigue
Categories: cs.LG cs.AI
\\
 Although widely explored, time series modeling continues to encounter
significant challenges when confronted with real-world data. We propose a novel
modeling approach leveraging Implicit Neural Representations (INR). This
approach enables us to effectively capture the continuous aspect of time series
and provides a natural solution to recurring modeling issues such as handling
missing data, dealing with irregular sampling, or unaligned observations from
multiple sensors. By introducing conditional modulation of INR parameters and
leveraging meta-learning techniques, we address the issue of generalization to
both unseen samples and time window shifts. Through extensive experimentation,
our model demonstrates state-of-the-art performance in forecasting and
imputation tasks, while exhibiting flexibility in handling a wide range of
challenging scenarios that competing models cannot.
\\ ( https://arxiv.org/abs/2306.05880 ,  738kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05889
Date: Fri, 9 Jun 2023 13:35:04 GMT   (13195kb,D)

Title: C(NN)FD -- a deep learning framework for turbomachinery CFD analysis
Authors: Giuseppe Bruni, Sepehr Maleki, Senthil K. Krishnababu
Categories: cs.LG cs.CE physics.flu-dyn
\\
 Deep Learning methods have seen a wide range of successful applications
across different industries. Up until now, applications to physical simulations
such as CFD (Computational Fluid Dynamics), have been limited to simple
test-cases of minor industrial relevance. This paper demonstrates the
development of a novel deep learning framework for real-time predictions of the
impact of manufacturing and build variations on the overall performance of
axial compressors in gas turbines, with a focus on tip clearance variations.
The associated scatter in efficiency can significantly increase the $CO_2$
emissions, thus being of great industrial and environmental relevance. The
proposed \textit{C(NN)FD} architecture achieves in real-time accuracy
comparable to the CFD benchmark. Predicting the flow field and using it to
calculate the corresponding overall performance renders the methodology
generalisable, while filtering only relevant parts of the CFD solution makes
the methodology scalable to industrial applications.
\\ ( https://arxiv.org/abs/2306.05889 ,  13195kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05905
Date: Fri, 9 Jun 2023 14:01:26 GMT   (90kb,D)

Title: TreeDQN: Learning to minimize Branch-and-Bound tree
Authors: Dmitry Sorokin, Alexander Kostin
Categories: cs.LG math.OC
Comments: Submitted to NeurIPS 2023
\\
 Combinatorial optimization problems require an exhaustive search to find the
optimal solution. A convenient approach to solving combinatorial optimization
tasks in the form of Mixed Integer Linear Programs is Branch-and-Bound.
Branch-and-Bound solver splits a task into two parts dividing the domain of an
integer variable, then it solves them recursively, producing a tree of nested
sub-tasks. The efficiency of the solver depends on the branchning heuristic
used to select a variable for splitting. In the present work, we propose a
reinforcement learning method that can efficiently learn the branching
heuristic. We view the variable selection task as a tree Markov Decision
Process, prove that the Bellman operator adapted for the tree Markov Decision
Process is contracting in mean, and propose a modified learning objective for
the reinforcement learning agent. Our agent requires less training data and
produces smaller trees compared to previous reinforcement learning methods.
\\ ( https://arxiv.org/abs/2306.05905 ,  90kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05951
Date: Fri, 9 Jun 2023 15:05:40 GMT   (37838kb,D)

Title: Prediction of Transportation Index for Urban Patterns in Small and
 Medium-sized Indian Cities using Hybrid RidgeGAN Model
Authors: Rahisha Thottolil, Uttam Kumar, Tanujit Chakraborty
Categories: cs.LG physics.geo-ph stat.AP
\\
 The rapid urbanization trend in most developing countries including India is
creating a plethora of civic concerns such as loss of green space, degradation
of environmental health, clean water availability, air pollution, traffic
congestion leading to delays in vehicular transportation, etc. Transportation
and network modeling through transportation indices have been widely used to
understand transportation problems in the recent past. This necessitates
predicting transportation indices to facilitate sustainable urban planning and
traffic management. Recent advancements in deep learning research, in
particular, Generative Adversarial Networks (GANs), and their modifications in
spatial data analysis such as CityGAN, Conditional GAN, and MetroGAN have
enabled urban planners to simulate hyper-realistic urban patterns. These
synthetic urban universes mimic global urban patterns and evaluating their
landscape structures through spatial pattern analysis can aid in comprehending
landscape dynamics, thereby enhancing sustainable urban planning. This research
addresses several challenges in predicting the urban transportation index for
small and medium-sized Indian cities. A hybrid framework based on Kernel Ridge
Regression (KRR) and CityGAN is introduced to predict transportation index
using spatial indicators of human settlement patterns. This paper establishes a
relationship between the transportation index and human settlement indicators
and models it using KRR for the selected 503 Indian cities. The proposed hybrid
pipeline, we call it RidgeGAN model, can evaluate the sustainability of urban
sprawl associated with infrastructure development and transportation systems in
sprawling cities. Experimental results show that the two-step pipeline approach
outperforms existing benchmarks based on spatial and statistical measures.
\\ ( https://arxiv.org/abs/2306.05951 ,  37838kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05952
Date: Fri, 9 Jun 2023 15:09:16 GMT   (2854kb,D)

Title: Overcoming Adversarial Attacks for Human-in-the-Loop Applications
Authors: Ryan McCoppin, Marla Kennedy, Platon Lukyanenko, Sean Kennedy
Categories: cs.LG cs.CV
Comments: New Frontiers in Adversarial Machine Learning, ICML 2022
\\
 Including human analysis has the potential to positively affect the
robustness of Deep Neural Networks and is relatively unexplored in the
Adversarial Machine Learning literature. Neural network visual explanation maps
have been shown to be prone to adversarial attacks. Further research is needed
in order to select robust visualizations of explanations for the image analyst
to evaluate a given model. These factors greatly impact Human-In-The-Loop
(HITL) evaluation tools due to their reliance on adversarial images, including
explanation maps and measurements of robustness. We believe models of human
visual attention may improve interpretability and robustness of human-machine
imagery analysis systems. Our challenge remains, how can HITL evaluation be
robust in this adversarial landscape?
\\ ( https://arxiv.org/abs/2306.05952 ,  2854kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05955
Date: Fri, 9 Jun 2023 15:11:49 GMT   (718kb,D)

Title: Path Neural Networks: Expressive and Accurate Graph Neural Networks
Authors: Gaspard Michel, Giannis Nikolentzos, Johannes Lutzeyer, Michalis
 Vazirgiannis
Categories: cs.LG stat.ML
Comments: Accepted at ICML 2023
\\
 Graph neural networks (GNNs) have recently become the standard approach for
learning with graph-structured data. Prior work has shed light into their
potential, but also their limitations. Unfortunately, it was shown that
standard GNNs are limited in their expressive power. These models are no more
powerful than the 1-dimensional Weisfeiler-Leman (1-WL) algorithm in terms of
distinguishing non-isomorphic graphs. In this paper, we propose Path Neural
Networks (PathNNs), a model that updates node representations by aggregating
paths emanating from nodes. We derive three different variants of the PathNN
model that aggregate single shortest paths, all shortest paths and all simple
paths of length up to K. We prove that two of these variants are strictly more
powerful than the 1-WL algorithm, and we experimentally validate our
theoretical results. We find that PathNNs can distinguish pairs of
non-isomorphic graphs that are indistinguishable by 1-WL, while our most
expressive PathNN variant can even distinguish between 3-WL indistinguishable
graphs. The different PathNN variants are also evaluated on graph
classification and graph regression datasets, where in most cases, they
outperform the baseline methods.
\\ ( https://arxiv.org/abs/2306.05955 ,  718kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05965
Date: Fri, 9 Jun 2023 15:33:30 GMT   (956kb,D)

Title: Automating Model Comparison in Factor Graphs
Authors: Bart van Erp, Wouter W. L. Nuijten, Thijs van de Laar, Bert de Vries
Categories: cs.LG cs.AI stat.ML
\\
 Bayesian state and parameter estimation have been automated effectively in
the literature, however, this has not yet been the case for model comparison,
which therefore still requires error-prone and time-consuming manual
derivations. As a result, model comparison is often overlooked and ignored,
despite its importance. This paper efficiently automates Bayesian model
averaging, selection, and combination by message passing on a Forney-style
factor graph with a custom mixture node. Parameter and state inference, and
model comparison can then be executed simultaneously using message passing with
scale factors. This approach shortens the model design cycle and allows for the
straightforward extension to hierarchical and temporal model priors to
accommodate for modeling complicated time-varying processes.
\\ ( https://arxiv.org/abs/2306.05965 ,  956kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05989
Date: Fri, 9 Jun 2023 15:59:27 GMT   (4429kb,D)

Title: Quartile-Based Seasonality Decomposition for Time Series Forecasting and
 Anomaly Detection
Authors: Ebenezer RHP Isaac and Bulbul Singh
Categories: cs.LG stat.ML
\\
 The timely detection of anomalies is essential in the telecom domain as it
facilitates the identification and characterization of irregular patterns,
abnormal behaviors, and network anomalies, contributing to enhanced service
quality and operational efficiency. Precisely forecasting and eliminating
predictable time series patterns constitutes a vital component of time series
anomaly detection. While the state-of-the-art methods aim to maximize
forecasting accuracy, the computational performance takes a hit. In a system
composed of a large number of time series variables, e.g., cell Key Performance
Indicators (KPIs), the time and space complexity of the forecasting employed is
of crucial importance. Quartile-Based Seasonality Decomposition (QBSD) is a
live forecasting method proposed in this paper to make an optimal trade-off
between computational complexity and forecasting accuracy. This paper compares
the performance of QBSD to the state-of-the-art forecasting methods and their
applicability to practical anomaly detection. To demonstrate the efficacy of
the proposed solution, experimental evaluation was conducted using publicly
available datasets as well as a telecom KPI dataset.
\\ ( https://arxiv.org/abs/2306.05989 ,  4429kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05991
Date: Fri, 9 Jun 2023 15:59:39 GMT   (18047kb,D)

Title: Approximate information state based convergence analysis of recurrent
 Q-learning
Authors: Erfan Seyedsalehi, Nima Akbarzadeh, Amit Sinha, Aditya Mahajan
Categories: cs.LG
Comments: 25 pages, 6 figures
\\
 In spite of the large literature on reinforcement learning (RL) algorithms
for partially observable Markov decision processes (POMDPs), a complete
theoretical understanding is still lacking. In a partially observable setting,
the history of data available to the agent increases over time so most
practical algorithms either truncate the history to a finite window or compress
it using a recurrent neural network leading to an agent state that is
non-Markovian. In this paper, it is shown that in spite of the lack of the
Markov property, recurrent Q-learning (RQL) converges in the tabular setting.
Moreover, it is shown that the quality of the converged limit depends on the
quality of the representation which is quantified in terms of what is known as
an approximate information state (AIS). Based on this characterization of the
approximation error, a variant of RQL with AIS losses is presented. This
variant performs better than a strong baseline for RQL that does not use AIS
losses. It is demonstrated that there is a strong correlation between the
performance of RQL over time and the loss associated with the AIS
representation.
\\ ( https://arxiv.org/abs/2306.05991 ,  18047kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05998
Date: Fri, 9 Jun 2023 16:10:26 GMT   (1364kb,D)

Title: Distributed Consensus Algorithm for Decision-Making in Multi-agent
 Multi-armed Bandit
Authors: Xiaotong Cheng, Setareh Maghsudi
Categories: cs.LG cs.MA stat.ML
\\
 We study a structured multi-agent multi-armed bandit (MAMAB) problem in a
dynamic environment. A graph reflects the information-sharing structure among
agents, and the arms' reward distributions are piecewise-stationary with
several unknown change points. The agents face the identical
piecewise-stationary MAB problem. The goal is to develop a decision-making
policy for the agents that minimizes the regret, which is the expected total
loss of not playing the optimal arm at each time step. Our proposed solution,
Restarted Bayesian Online Change Point Detection in Cooperative Upper
Confidence Bound Algorithm (RBO-Coop-UCB), involves an efficient multi-agent
UCB algorithm as its core enhanced with a Bayesian change point detector. We
also develop a simple restart decision cooperation that improves
decision-making. Theoretically, we establish that the expected group regret of
RBO-Coop-UCB is upper bounded by $\mathcal{O}(KNM\log T + K\sqrt{MT\log T})$,
where K is the number of agents, M is the number of arms, and T is the number
of time steps. Numerical experiments on synthetic and real-world datasets
demonstrate that our proposed method outperforms the state-of-the-art
algorithms.
\\ ( https://arxiv.org/abs/2306.05998 ,  1364kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06024
Date: Fri, 9 Jun 2023 16:42:52 GMT   (451kb,D)

Title: Self-Interpretable Time Series Prediction with Counterfactual
 Explanations
Authors: Jingquan Yan, Hao Wang
Categories: cs.LG
\\
 Interpretable time series prediction is crucial for safety-critical areas
such as healthcare and autonomous driving. Most existing methods focus on
interpreting predictions by assigning important scores to segments of time
series. In this paper, we take a different and more challenging route and aim
at developing a self-interpretable model, dubbed Counterfactual Time Series
(CounTS), which generates counterfactual and actionable explanations for time
series predictions. Specifically, we formalize the problem of time series
counterfactual explanations, establish associated evaluation protocols, and
propose a variational Bayesian deep learning model equipped with counterfactual
inference capability of time series abduction, action, and prediction. Compared
with state-of-the-art baselines, our self-interpretable model can generate
better counterfactual explanations while maintaining comparable prediction
accuracy.
\\ ( https://arxiv.org/abs/2306.06024 ,  451kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06034
Date: Fri, 9 Jun 2023 16:55:49 GMT   (2968kb,D)

Title: RANS-PINN based Simulation Surrogates for Predicting Turbulent Flows
Authors: Shinjan Ghosh, Amit Chakraborty, Georgia Olympia Brikis, Biswadip Dey
Categories: cs.LG cs.NA math.NA physics.flu-dyn
\\
 Physics-informed neural networks (PINNs) provide a framework to build
surrogate models for dynamical systems governed by differential equations.
During the learning process, PINNs incorporate a physics-based regularization
term within the loss function to enhance generalization performance. Since
simulating dynamics controlled by partial differential equations (PDEs) can be
computationally expensive, PINNs have gained popularity in learning parametric
surrogates for fluid flow problems governed by Navier-Stokes equations. In this
work, we introduce RANS-PINN, a modified PINN framework, to predict flow fields
(i.e., velocity and pressure) in high Reynolds number turbulent flow regime. To
account for the additional complexity introduced by turbulence, RANS-PINN
employs a 2-equation eddy viscosity model based on a Reynolds-averaged
Navier-Stokes (RANS) formulation. Furthermore, we adopt a novel training
approach that ensures effective initialization and balance among the various
components of the loss function. The effectiveness of RANS-PINN framework is
then demonstrated using a parametric PINN.
\\ ( https://arxiv.org/abs/2306.06034 ,  2968kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06041
Date: Fri, 9 Jun 2023 17:07:04 GMT   (2275kb,D)

Title: A Dynamical Graph Prior for Relational Inference
Authors: Liming Pan, Cheng Shi, Ivan Dokmani\'c
Categories: cs.LG stat.ML
\\
 Relational inference aims to identify interactions between parts of a
dynamical system from the observed dynamics. Current state-of-the-art methods
fit a graph neural network (GNN) on a learnable graph to the dynamics. They use
one-step message-passing GNNs -- intuitively the right choice since
non-locality of multi-step or spectral GNNs may confuse direct and indirect
interactions. But the \textit{effective} interaction graph depends on the
sampling rate and it is rarely localized to direct neighbors, leading to local
minima for the one-step model. In this work, we propose a \textit{dynamical
graph prior} (DYGR) for relational inference. The reason we call it a prior is
that, contrary to established practice, it constructively uses error
amplification in high-degree non-local polynomial filters to generate good
gradients for graph learning. To deal with non-uniqueness, DYGR simultaneously
fits a ``shallow'' one-step model with shared graph topology. Experiments show
that DYGR reconstructs graphs far more accurately than earlier methods, with
remarkable robustness to under-sampling. Since appropriate sampling rates for
unknown dynamical systems are not known a priori, this robustness makes DYGR
suitable for real applications in scientific machine learning.
\\ ( https://arxiv.org/abs/2306.06041 ,  2275kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06063
Date: Fri, 9 Jun 2023 17:38:22 GMT   (1267kb,D)

Title: Virtual Node Tuning for Few-shot Node Classification
Authors: Zhen Tan, Ruocheng Guo, Kaize Ding, Huan Liu
Categories: cs.LG
Comments: Accepted to KDD 2023
\\
 Few-shot Node Classification (FSNC) is a challenge in graph representation
learning where only a few labeled nodes per class are available for training.
To tackle this issue, meta-learning has been proposed to transfer structural
knowledge from base classes with abundant labels to target novel classes.
However, existing solutions become ineffective or inapplicable when base
classes have no or limited labeled nodes. To address this challenge, we propose
an innovative method dubbed Virtual Node Tuning (VNT). Our approach utilizes a
pretrained graph transformer as the encoder and injects virtual nodes as soft
prompts in the embedding space, which can be optimized with few-shot labels in
novel classes to modulate node embeddings for each specific FSNC task. A unique
feature of VNT is that, by incorporating a Graph-based Pseudo Prompt Evolution
(GPPE) module, VNT-GPPE can handle scenarios with sparse labels in base
classes. Experimental results on four datasets demonstrate the superiority of
the proposed approach in addressing FSNC with unlabeled or sparsely labeled
base classes, outperforming existing state-of-the-art methods and even fully
supervised baselines.
\\ ( https://arxiv.org/abs/2306.06063 ,  1267kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06087
Date: Fri, 9 Jun 2023 17:49:56 GMT   (226kb,D)

Title: Learning Not to Spoof
Authors: David Byrd
Categories: cs.LG cs.AI cs.CE cs.MA q-fin.ST
DOI: 10.1145/3533271.3561767
\\
 As intelligent trading agents based on reinforcement learning (RL) gain
prevalence, it becomes more important to ensure that RL agents obey laws,
regulations, and human behavioral expectations. There is substantial literature
concerning the aversion of obvious catastrophes like crashing a helicopter or
bankrupting a trading account, but little around the avoidance of subtle
non-normative behavior for which there are examples, but no programmable
definition. Such behavior may violate legal or regulatory, rather than physical
or monetary, constraints.
 In this article, I consider a series of experiments in which an intelligent
stock trading agent maximizes profit but may also inadvertently learn to spoof
the market in which it participates. I first inject a hand-coded spoofing agent
to a multi-agent market simulation and learn to recognize spoofing activity
sequences. Then I replace the hand-coded spoofing trader with a simple
profit-maximizing RL agent and observe that it independently discovers spoofing
as the optimal strategy. Finally, I introduce a method to incorporate the
recognizer as normative guide, shaping the agent's perceived rewards and
altering its selected actions. The agent remains profitable while avoiding
spoofing behaviors that would result in even higher profit. After presenting
the empirical results, I conclude with some recommendations. The method should
generalize to the reduction of any unwanted behavior for which a recognizer can
be learned.
\\ ( https://arxiv.org/abs/2306.06087 ,  226kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06098
Date: Fri, 9 Jun 2023 17:58:47 GMT   (812kb,D)

Title: Error Feedback Can Accurately Compress Preconditioners
Authors: Ionut-Vlad Modoranu, Aleksei Kalinov, Eldar Kurtic, Dan Alistarh
Categories: cs.LG cs.NA math.NA math.OC
\\
 Leveraging second-order information at the scale of deep networks is one of
the main lines of approach for improving the performance of current optimizers
for deep learning. Yet, existing approaches for accurate full-matrix
preconditioning, such as Full-Matrix Adagrad (GGT) or Matrix-Free Approximate
Curvature (M-FAC) suffer from massive storage costs when applied even to
medium-scale models, as they must store a sliding window of gradients, whose
memory requirements are multiplicative in the model dimension. In this paper,
we address this issue via an efficient and simple-to-implement error-feedback
technique that can be applied to compress preconditioners by up to two orders
of magnitude in practice, without loss of convergence. Specifically, our
approach compresses the gradient information via sparsification or low-rank
compression \emph{before} it is fed into the preconditioner, feeding the
compression error back into future iterations. Extensive experiments on deep
neural networks for vision show that this approach can compress full-matrix
preconditioners by up to two orders of magnitude without impact on accuracy,
effectively removing the memory overhead of full-matrix preconditioning for
implementations of full-matrix Adagrad (GGT) and natural gradient (M-FAC). Our
code is available at https://github.com/IST-DASLab/EFCP.
\\ ( https://arxiv.org/abs/2306.06098 ,  812kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06101
Date: Fri, 9 Jun 2023 17:59:35 GMT   (3066kb,D)

Title: Prodigy: An Expeditiously Adaptive Parameter-Free Learner
Authors: Konstantin Mishchenko, Aaron Defazio
Categories: cs.LG cs.AI math.OC stat.ML
\\
 We consider the problem of estimating the learning rate in adaptive methods,
such as Adagrad and Adam. We describe two techniques, Prodigy and Resetting, to
provably estimate the distance to the solution $D$, which is needed to set the
learning rate optimally. Our techniques are modifications of the D-Adaptation
method for learning-rate-free learning. Our methods improve upon the
convergence rate of D-Adaptation by a factor of $O(\sqrt{\log(D/d_0)})$, where
$d_0$ is the initial estimate of $D$. We test our methods on 12 common
logistic-regression benchmark datasets, VGG11 and ResNet-50 training on
CIFAR10, ViT training on Imagenet, LSTM training on IWSLT14, DLRM training on
Criteo dataset, VarNet on Knee MRI dataset, as well as RoBERTa and GPT
transformer training on BookWiki. Our experimental results show that our
approaches consistently outperform D-Adaptation and reach test accuracy values
close to that of hand-tuned Adam.
\\ ( https://arxiv.org/abs/2306.06101 ,  3066kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05590
Date: Thu, 8 Jun 2023 23:28:41 GMT   (1757kb,D)

Title: The Viability of Domain Constrained Coalition Formation for Robotic
 Collectives
Authors: Grace Diehl and Julie A. Adams
Categories: cs.MA cs.AI
Comments: 46 pages, 9 figures, Swarm Intelligence (under review)
\\
 Applications, such as military and disaster response, can benefit from
robotic collectives' ability to perform multiple cooperative tasks (e.g.,
surveillance, damage assessments) efficiently across a large spatial area.
Coalition formation algorithms can potentially facilitate collective robots'
assignment to appropriate task teams; however, most coalition formation
algorithms were designed for smaller multiple robot systems (i.e., 2-50
robots). Collectives' scale and domain-relevant constraints (i.e.,
distribution, near real-time, minimal communication) make coalition formation
more challenging. This manuscript identifies the challenges inherent to
designing coalition formation algorithms for very large collectives (e.g., 1000
robots). A survey of multiple robot coalition formation algorithms finds that
most are unable to transfer directly to collectives, due to the identified
system differences; however, auctions and hedonic games may be the most
transferable. A simulation-based evaluation of three auction and hedonic game
algorithms, applied to homogeneous and heterogeneous collectives, demonstrates
that there are collective compositions for which no existing algorithm is
viable; however, the experimental results and literature survey suggest paths
forward.
\\ ( https://arxiv.org/abs/2306.05590 ,  1757kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05478
Date: Thu, 8 Jun 2023 18:03:48 GMT   (991kb,D)

Title: Trajectory Prediction with Observations of Variable-Length for Motion
 Planning in Highway Merging scenarios
Authors: Sajjad Mozaffari, Mreza Alipour Sormoli, Konstantinos Koufos, Graham
 Lee, and Mehrdad Dianati
Categories: cs.RO cs.LG
Comments: 8 page, 7 figures, submitted to IEEE ITSC 2023
\\
 Accurate trajectory prediction of nearby vehicles is crucial for the safe
motion planning of automated vehicles in dynamic driving scenarios such as
highway merging. Existing methods cannot initiate prediction for a vehicle
unless observed for a fixed duration of two or more seconds. This prevents a
fast reaction by the ego vehicle to vehicles that enter its perception range,
thus creating safety concerns. Therefore, this paper proposes a novel
transformer-based trajectory prediction approach, specifically trained to
handle any observation length larger than one frame. We perform a comprehensive
evaluation of the proposed method using two large-scale highway trajectory
datasets, namely the highD and exiD. In addition, we study the impact of the
proposed prediction approach on motion planning and control tasks using
extensive merging scenarios from the exiD dataset. To the best of our
knowledge, this marks the first instance where such a large-scale highway
merging dataset has been employed for this purpose. The results demonstrate
that the prediction model achieves state-of-the-art performance on highD
dataset and maintains lower prediction error w.r.t. the constant velocity
across all observation lengths in exiD. Moreover, it significantly enhances
safety, comfort, and efficiency in dense traffic scenarios, as compared to the
constant velocity model.
\\ ( https://arxiv.org/abs/2306.05478 ,  991kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05562
Date: Thu, 8 Jun 2023 21:07:15 GMT   (2755kb,D)

Title: AircraftVerse: A Large-Scale Multimodal Dataset of Aerial Vehicle
 Designs
Authors: Adam D. Cobb, Anirban Roy, Daniel Elenius, F. Michael Heim, Brian
 Swenson, Sydney Whittington, James D. Walker, Theodore Bapty, Joseph Hite,
 Karthik Ramani, Christopher McComb, Susmit Jha
Categories: cs.RO cs.AI cs.CE
Comments: The dataset is hosted at https://zenodo.org/record/6525446, baseline
 models and code at https://github.com/SRI-CSL/AircraftVerse, and the dataset
 description at https://aircraftverse.onrender.com/
\\
 We present AircraftVerse, a publicly available aerial vehicle design dataset.
Aircraft design encompasses different physics domains and, hence, multiple
modalities of representation. The evaluation of these cyber-physical system
(CPS) designs requires the use of scientific analytical and simulation models
ranging from computer-aided design tools for structural and manufacturing
analysis, computational fluid dynamics tools for drag and lift computation,
battery models for energy estimation, and simulation models for flight control
and dynamics. AircraftVerse contains 27,714 diverse air vehicle designs - the
largest corpus of engineering designs with this level of complexity. Each
design comprises the following artifacts: a symbolic design tree describing
topology, propulsion subsystem, battery subsystem, and other design details; a
STandard for the Exchange of Product (STEP) model data; a 3D CAD design using a
stereolithography (STL) file format; a 3D point cloud for the shape of the
design; and evaluation results from high fidelity state-of-the-art physics
models that characterize performance metrics such as maximum flight distance
and hover-time. We also present baseline surrogate models that use different
modalities of design representation to predict design performance metrics,
which we provide as part of our dataset release. Finally, we discuss the
potential impact of this dataset on the use of learning in aircraft design and,
more generally, in CPS. AircraftVerse is accompanied by a data card, and it is
released under Creative Commons Attribution-ShareAlike (CC BY-SA) license. The
dataset is hosted at https://zenodo.org/record/6525446, baseline models and
code at https://github.com/SRI-CSL/AircraftVerse, and the dataset description
at https://aircraftverse.onrender.com/.
\\ ( https://arxiv.org/abs/2306.05562 ,  2755kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05696
Date: Fri, 9 Jun 2023 06:34:09 GMT   (3723kb,D)

Title: Embodied Executable Policy Learning with Language-based Scene
 Summarization
Authors: Jielin Qiu, Mengdi Xu, William Han, Seungwhan Moon, Ding Zhao
Categories: cs.RO
Comments: 15 pages. arXiv admin note: text overlap with arXiv:2107.06912 by
 other authors
\\
 Large Language models (LLMs) have shown remarkable success in assisting robot
learning tasks, i.e., complex household planning. However, the performance of
pretrained LLMs heavily relies on domain-specific templated text data, which
may be infeasible in real-world robot learning tasks with image-based
observations. Moreover, existing LLMs with text inputs lack the capability to
evolve with non-expert interactions with environments. In this work, we
introduce a novel learning paradigm that generates robots' executable actions
in the form of text, derived solely from visual observations, using
language-based summarization of these observations as the connecting bridge
between both domains. Our proposed paradigm stands apart from previous works,
which utilized either language instructions or a combination of language and
visual data as inputs. Moreover, our method does not require oracle text
summarization of the scene, eliminating the need for human involvement in the
learning loop, which makes it more practical for real-world robot learning
tasks. Our proposed paradigm consists of two modules: the SUM module, which
interprets the environment using visual observations and produces a text
summary of the scene, and the APM module, which generates executable action
policies based on the natural language descriptions provided by the SUM module.
We demonstrate that our proposed method can employ two fine-tuning strategies,
including imitation learning and reinforcement learning approaches, to adapt to
the target test tasks effectively. We conduct extensive experiments involving
various SUM/APM model selections, environments, and tasks across 7 house
layouts in the VirtualHome environment. Our experimental results demonstrate
that our method surpasses existing baselines, confirming the effectiveness of
this novel learning paradigm.
\\ ( https://arxiv.org/abs/2306.05696 ,  3723kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05716
Date: Fri, 9 Jun 2023 07:22:12 GMT   (20135kb,D)

Title: Pave the Way to Grasp Anything: Transferring Foundation Models for
 Universal Pick-Place Robots
Authors: Jiange Yang, Wenhui Tan, Chuhao Jin, Bei Liu, Jianlong Fu, Ruihua
 Song, Limin Wang
Categories: cs.RO cs.AI
\\
 Improving the generalization capabilities of general-purpose robotic agents
has long been a significant challenge actively pursued by research communities.
Existing approaches often rely on collecting large-scale real-world robotic
data, such as the RT-1 dataset. However, these approaches typically suffer from
low efficiency, limiting their capability in open-domain scenarios with new
objects, and diverse backgrounds. In this paper, we propose a novel paradigm
that effectively leverages language-grounded segmentation masks generated by
state-of-the-art foundation models, to address a wide range of pick-and-place
robot manipulation tasks in everyday scenarios. By integrating precise
semantics and geometries conveyed from masks into our multi-view policy model,
our approach can perceive accurate object poses and enable sample-efficient
learning. Besides, such design facilitates effective generalization for
grasping new objects with similar shapes observed during training. Our approach
consists of two distinct steps. First, we introduce a series of foundation
models to accurately ground natural language demands across multiple tasks.
Second, we develop a Multi-modal Multi-view Policy Model that incorporates
inputs such as RGB images, semantic masks, and robot proprioception states to
jointly predict precise and executable robot actions. Extensive real-world
experiments conducted on a Franka Emika robot arm validate the effectiveness of
our proposed paradigm. Real-world demos are shown in YouTube
(https://www.youtube.com/watch?v=1m9wNzfp_4E ) and Bilibili
(https://www.bilibili.com/video/BV178411Z7H2/ ).
\\ ( https://arxiv.org/abs/2306.05716 ,  20135kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05766
Date: Fri, 9 Jun 2023 09:04:35 GMT   (594kb,D)

Title: Data-Link: High Fidelity Manufacturing Datasets for Model2Real Transfer
 under Industrial Settings
Authors: Sunny Katyara, Mohammad Mujtahid, Court Edmondson
Categories: cs.RO
Comments: RSS 2023
\\
 High-fidelity datasets play a pivotal role in imbuing simulators with
realism, enabling the benchmarking of various state-of-the-art deep inference
models. These models are particularly instrumental in tasks such as semantic
segmentation, classification, and localization. This study showcases the
efficacy of a customized manufacturing dataset comprising 60 classes in the
creation of a high-fidelity digital twin of a robotic manipulation environment.
By leveraging the concept of transfer learning, different 6D pose estimation
models are trained within the simulated environment using domain randomization
and subsequently tested on real-world objects to assess domain adaptation. To
ascertain the effectiveness and realism of the created data-set, pose accuracy
and mean absolute error (MAE) metrics are reported to quantify the model2real
gap.
\\ ( https://arxiv.org/abs/2306.05766 ,  594kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05791
Date: Fri, 9 Jun 2023 10:08:51 GMT   (10436kb,D)

Title: Enabling Robot Manipulation of Soft and Rigid Objects with Vision-based
 Tactile Sensors
Authors: Michael C. Welle, Martina Lippi, Haofei Lu, Jens Lundell, Andrea
 Gasparri, Danica Kragic
Categories: cs.RO
Comments: Published in IEEE International Conference on Automation Science and
 Engineering (CASE2023)
\\
 Endowing robots with tactile capabilities opens up new possibilities for
their interaction with the environment, including the ability to handle fragile
and/or soft objects. In this work, we equip the robot gripper with low-cost
vision-based tactile sensors and propose a manipulation algorithm that adapts
to both rigid and soft objects without requiring any knowledge of their
properties. The algorithm relies on a touch and slip detection method, which
considers the variation in the tactile images with respect to reference ones.
We validate the approach on seven different objects, with different properties
in terms of rigidity and fragility, to perform unplugging and lifting tasks.
Furthermore, to enhance applicability, we combine the manipulation algorithm
with a grasp sampler for the task of finding and picking a grape from a bunch
without damaging~it.
\\ ( https://arxiv.org/abs/2306.05791 ,  10436kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05869
Date: Fri, 9 Jun 2023 13:02:31 GMT   (9077kb,D)

Title: Leaving the Lines Behind: Vision-Based Crop Row Exit for Agricultural
 Robot Navigation
Authors: Rajitha de Silva, Grzegorz Cielniak, Junfeng Gao
Categories: cs.RO cs.CV
Comments: Best Paper Award at TIG-IV workshop at ICRA 2023
 https://sites.google.com/view/icra23tig4ws/call-for-contributions
\\
 Usage of purely vision based solutions for row switching is not well explored
in existing vision based crop row navigation frameworks. This method only uses
RGB images for local feature matching based visual feedback to exit crop row.
Depth images were used at crop row end to estimate the navigation distance
within headland. The algorithm was tested on diverse headland areas with soil
and vegetation. The proposed method could reach the end of the crop row and
then navigate into the headland completely leaving behind the crop row with an
error margin of 50 cm.
\\ ( https://arxiv.org/abs/2306.05869 ,  9077kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05902
Date: Fri, 9 Jun 2023 13:53:45 GMT   (5290kb,D)

Title: Augmenting Off-the-Shelf Grippers with Tactile Sensing
Authors: Remko Proesmans, Francis wyffels
Categories: cs.RO
Comments: Project repo:
 https://github.com/RemkoPr/icra-2023-workshop-tactile-fingertips
ACM-class: B.m
\\
 The development of tactile sensing and its fusion with computer vision is
expected to enhance robotic systems in handling complex tasks like deformable
object manipulation. However, readily available industrial grippers typically
lack tactile feedback, which has led researchers to develop and integrate their
own tactile sensors. This has resulted in a wide range of sensor hardware,
making it difficult to compare performance between different systems. We
highlight the value of accessible open-source sensors and present a set of
fingertips specifically designed for fine object manipulation, with readily
interpretable data outputs. The fingertips are validated through two difficult
tasks: cloth edge tracing and cable tracing. Videos of these demonstrations, as
well as design files and readout code can be found at
https://github.com/RemkoPr/icra-2023-workshop-tactile-fingertips.
\\ ( https://arxiv.org/abs/2306.05902 ,  5290kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05581
Date: Thu, 8 Jun 2023 22:45:39 GMT   (47515kb,D)

Title: Risk-aware Urban Air Mobility Network Design with Overflow Redundancy
Authors: Qinshuang Wei, Zhenyu Gao, John-Paul Clarke, Ufuk Topcu
Categories: eess.SY cs.SY math.OC
Comments: 43 pages, 10 figures
\\
 Urban Air Mobility (UAM), as envisioned by researchers and practitioners,
will be achieved through the use of highly automated aircraft that operate and
transport passengers and cargo at low altitudes within urban and suburban
areas. To operate in complex urban environment, precise air traffic management,
in particular the management of traffic overflows due to operational
disruptions will be critical to ensuring system safety and efficiency. To this
end, we propose a methodology for the design of UAM networks with reserve
capacity, i.e., a design where alternative landing options and flight corridors
are explicitly considered as a means of improving contingency management and
reducing risk. Similar redundancy considerations are incorporated in the design
of many critical infrastructures, yet remain unexploited in the air
transportation literature. In our methodology, we first model how disruptions
to a given on-demand UAM network might impact on the nominal traffic flow and
how this flow might be re-accommodated on an extended network with reserve
capacity. Then, through an optimization problem, we select the locations and
capacities for the backup vertiports with the maximal expected throughput of
the extended network over all possible disruption scenarios, while the
throughput is the maximal amount of flights that the network can accommodate
per unit of time. We show that we can obtain the solution for the corresponding
bi-level and bi-linear optimization problem by solving a mixed-integer linear
program. We demonstrate our methodology in the case study using networks from
Milwaukee, Atlanta, and Dallas--Fort Worth metropolitan areas and show how the
throughput and flexibility of the UAM networks with reserve capacity can
outcompete those without.
\\ ( https://arxiv.org/abs/2306.05581 ,  47515kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05686
Date: Fri, 9 Jun 2023 05:57:23 GMT   (4717kb,D)

Title: Encrypted Simultaneous Control of Joint Angle and Stiffness of
 Antagonistic Pneumatic Artificial Muscle Actuator by Polynomial Approximation
Authors: Yuta Takeda, Takaya Shin, Kaoru Teranishi, and Kimono Kogiso
Categories: eess.SY cs.SY
\\
 This study proposes an encrypted simultaneous control system for an
antagonistic pneumatic artificial muscle (PAM) actuator toward developing a
cybersecure and flexible actuator. First, a novel simultaneous control system
design is considered for the joint angle and stiffness of a PAM actuator in a
model-based design approach, facilitating the use of an encrypted control
method. The designed controller includes a contraction force model expressed as
rational polynomial functions, which makes it difficult to encrypt the
controller. To overcome this difficulty, a least absolute shrinkage and
selection operator (LASSO)-based polynomial approximation is employed for a
rational controller. The resulting polynomial controller is then transformed
into a matrix-vector product form, which enables the use of a specific
homomorphic encryption scheme to develop an encrypted simultaneous control
system for the PAM actuator. Finally, this study quantitatively evaluates the
tracking control performance of the original, approximated, and encrypted
controllers. The experimental results show that the proposed encrypted
controller achieves simultaneous tracking of the joint angle and stiffness with
a tracking error of less than 2.7 %.
\\ ( https://arxiv.org/abs/2306.05686 ,  4717kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05700
Date: Fri, 9 Jun 2023 06:39:37 GMT   (23kb)

Title: Finite-Time Analysis of Minimax Q-Learning for Two-Player Zero-Sum
 Markov Games: Switching System Approach
Authors: Donghwan Lee
Categories: eess.SY cs.GT cs.LG cs.SY
Comments: arXiv admin note: text overlap with arXiv:2205.05455
\\
 The objective of this paper is to investigate the finite-time analysis of a
Q-learning algorithm applied to two-player zero-sum Markov games. Specifically,
we establish a finite-time analysis of both the minimax Q-learning algorithm
and the corresponding value iteration method. To enhance the analysis of both
value iteration and Q-learning, we employ the switching system model of minimax
Q-learning and the associated value iteration. This approach provides further
insights into minimax Q-learning and facilitates a more straightforward and
insightful convergence analysis. We anticipate that the introduction of these
additional insights has the potential to uncover novel connections and foster
collaboration between concepts in the fields of control theory and
reinforcement learning communities.
\\ ( https://arxiv.org/abs/2306.05700 ,  23kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05881
Date: Fri, 9 Jun 2023 13:23:25 GMT   (723kb,D)

Title: Nonlinear Stability Assessment Of Type-4 Wind Turbines During Unbalanced
 Grid Faults Based On Reduced-Order Model
Authors: Sujay Ghosh, Mohammad Kazem Bakhshizadeh, {\L}ukasz Kocewiak and
 Guangya Yang
Categories: eess.SY cs.SY
\\
 As the number of converter-based renewable generations in the power system is
increasing, the inertia provided by the synchronous generators is reducing,
which in turn is reducing the stability margins of the power system. In order
to assess the large-signal stability, it is essential to model the wind power
plant connections accurately. However, the actual EMT models are often
unavailable, black-boxed, or computationally too heavy to model in detail.
Hence, simplified reduced-order models (ROMs) resembling the actual system
behaviour have gained prominence in stability studies. In this regard, an
improved WT ROM was proposed to investigate large signal stability during
unbalanced grid faults. The methodology presents a systematic way to model the
coupled sequence components of the WT ROM for various grid faults. Based on the
studies carried out in this paper, it is observed that post unbalanced grid
disturbances the proposed WT ROM correctly tracks the angle and frequency, and
its trajectory is a good match when compared to a detailed simulation model in
PSCAD.
\\ ( https://arxiv.org/abs/2306.05881 ,  723kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06096
Date: Fri, 9 Jun 2023 17:58:11 GMT   (2924kb,D)

Title: Model Predictive Control for Integrated Lateral Stability
Authors: Jad Yahya, Siddharth Saha, Haoru Xue, Allen Y. Yang
Categories: eess.SY cs.SY
Comments: 8 Pages, 10 figures
\\
 This paper studies the design of a Model Predictive Controller (MPC) for
integrated lateral stability, traction/braking control, and rollover prevention
of electric vehicles intended for very high speed (VHS) racing applications. We
first identify the advantages of a state-of-the-art dynamic model in that it
includes rollover prevention into the MPC (a total of 8 states) and also
linearizes the tire model prior to solving the MPC problem to save computation
time. Then the design of a novel model predictive controller for lateral
stability control is proposed aimed for achieving stable control at top speed
significantly greater than typical highway speed limits. We have tested the new
solution in simulation environments associated with the Indy Autonomous
Challenge, where its real-world racing conditions include significant road
banking angles, lateral position tracking, and a different suspension model of
its Dallara Indy Lights chassis. The results are very promising with a low
solver time in Python, as low as 50 Hz, and a lateral error of 30 cm at speeds
of 45 m/s. Our open source code is available at: https:
//github.com/jadyahya/Roll-Yaw-and-Lateral-Velocity-MPC/.
\\ ( https://arxiv.org/abs/2306.06096 ,  2924kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06102
Date: Fri, 9 Jun 2023 17:59:52 GMT   (1773kb,D)

Title: Backup Plan Constrained Model Predictive Control with Guaranteed
 Stability
Authors: Ran Tao, Hunmin Kim, Hyung-Jin Yoon, Wenbin Wan, Naira Hovakimyan, Lui
 Sha, Petros Voulgaris
Categories: eess.SY cs.SY
\\
 This article proposes and evaluates a new safety concept called backup plan
safety for path planning of autonomous vehicles under mission uncertainty.
Backup plan safety is defined as the ability to complete an alternative mission
when the primary mission is aborted. To include this new safety concept in
control problems, we formulate a feasibility maximization problem aiming to
maximize the feasibility of the primary and alternative missions. The
feasibility maximization problem is based on multi-objective model predictive
control (MPC), where each objective (cost function) is associated with a
different mission and balanced by a weight vector. Furthermore, the feasibility
maximization problem incorporates additional control input horizons toward the
alternative missions on top of the control input horizon toward the primary
mission, denoted as multi-horizon inputs, to evaluate the cost for each
mission. We develop the backup plan constrained MPC algorithm, which designs
the weight vector that ensures asymptotic stability of the closed-loop system,
and generates the optimal control input by solving the feasibility maximization
problem with computational efficiency. The performance of the proposed
algorithm is validated through simulations of a UAV path planning problem.
\\ ( https://arxiv.org/abs/2306.06102 ,  1773kb)
%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-
------------------------------------------------------------------------------
\\
arXiv:2306.05432 (*cross-listing*)
Date: Tue, 6 Jun 2023 15:22:16 GMT   (258kb)

Title: Towards End-to-end Speech-to-text Summarization
Authors: Raul Monteiro and Diogo Pernes
Categories: cs.CL cs.AI cs.LG eess.AS
Comments: Accepted to the 26th International Conference of Text, Speech and
 Dialogue (TSD2023)
\\
 Speech-to-text (S2T) summarization is a time-saving technique for filtering
and keeping up with the broadcast news uploaded online on a daily basis. The
rise of large language models from deep learning with impressive text
generation capabilities has placed the research focus on summarization systems
that produce paraphrased compact versions of the document content, also known
as abstractive summaries. End-to-end (E2E) modelling of S2T abstractive
summarization is a promising approach that offers the possibility of generating
rich latent representations that leverage non-verbal and acoustic information,
as opposed to the use of only linguistic information from automatically
generated transcripts in cascade systems. However, the few literature on E2E
modelling of this task fails on exploring different domains, namely broadcast
news, which is challenging domain where large and diversified volumes of data
are presented to the user every day. We model S2T summarization both with a
cascade and an E2E system for a corpus of broadcast news in French. Our novel
E2E model leverages external data by resorting to transfer learning from a
pre-trained T2T summarizer. Experiments show that both our cascade and E2E
abstractive summarizers are stronger than an extractive baseline. However, the
performance of the E2E model still lies behind the cascade one, which is object
of an extensive analysis that includes future directions to close that gap.
\\ ( https://arxiv.org/abs/2306.05432 ,  258kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05443 (*cross-listing*)
Date: Thu, 8 Jun 2023 14:20:29 GMT   (182kb,D)

Title: PIXIU: A Large Language Model, Instruction Data and Evaluation Benchmark
 for Finance
Authors: Qianqian Xie, Weiguang Han, Xiao Zhang, Yanzhao Lai, Min Peng,
 Alejandro Lopez-Lira, Jimin Huang
Categories: cs.CL cs.AI
Comments: 12 pages, 1 figures
\\
 Although large language models (LLMs) has shown great performance on natural
language processing (NLP) in the financial domain, there are no publicly
available financial tailtored LLMs, instruction tuning datasets, and evaluation
benchmarks, which is critical for continually pushing forward the open-source
development of financial artificial intelligence (AI). This paper introduces
PIXIU, a comprehensive framework including the first financial LLM based on
fine-tuning LLaMA with instruction data, the first instruction data with 136K
data samples to support the fine-tuning, and an evaluation benchmark with 5
tasks and 9 datasets. We first construct the large-scale multi-task instruction
data considering a variety of financial tasks, financial document types, and
financial data modalities. We then propose a financial LLM called FinMA by
fine-tuning LLaMA with the constructed dataset to be able to follow
instructions for various financial tasks. To support the evaluation of
financial LLMs, we propose a standardized benchmark that covers a set of
critical financial tasks, including five financial NLP tasks and one financial
prediction task. With this benchmark, we conduct a detailed analysis of FinMA
and several existing LLMs, uncovering their strengths and weaknesses in
handling critical financial tasks. The model, datasets, benchmark, and
experimental results are open-sourced to facilitate future research in
financial AI.
\\ ( https://arxiv.org/abs/2306.05443 ,  182kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05446 (*cross-listing*)
Date: Thu, 8 Jun 2023 17:28:28 GMT   (1456kb,D)

Title: Latent Phrase Matching for Dysarthric Speech
Authors: Colin Lea, Dianna Yee, Jaya Narain, Zifang Huang, Lauren Tooley,
 Jeffrey P. Bigham, Leah Findlater
Categories: eess.AS cs.AI cs.CL cs.LG
\\
 Many consumer speech recognition systems are not tuned for people with speech
disabilities, resulting in poor recognition and user experience, especially for
severe speech differences. Recent studies have emphasized interest in
personalized speech models from people with atypical speech patterns. We
propose a query-by-example-based personalized phrase recognition system that is
trained using small amounts of speech, is language agnostic, does not assume a
traditional pronunciation lexicon, and generalizes well across speech
difference severities. On an internal dataset collected from 32 people with
dysarthria, this approach works regardless of severity and shows a 60%
improvement in recall relative to a commercial speech recognition system. On
the public EasyCall dataset of dysarthric speech, our approach improves
accuracy by 30.5%. Performance degrades as the number of phrases increases, but
consistently outperforms ASR systems when trained with 50 unique phrases.
\\ ( https://arxiv.org/abs/2306.05446 ,  1456kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05499 (*cross-listing*)
Date: Thu, 8 Jun 2023 18:43:11 GMT   (729kb,D)

Title: Prompt Injection attack against LLM-integrated Applications
Authors: Yi Liu, Gelei Deng, Yuekang Li, Kailong Wang, Tianwei Zhang, Yepang
 Liu, Haoyu Wang, Yan Zheng and Yang Liu
Categories: cs.CR cs.AI cs.CL cs.SE
\\
 Large Language Models (LLMs), renowned for their superior proficiency in
language comprehension and generation, stimulate a vibrant ecosystem of
applications around them. However, their extensive assimilation into various
services introduces significant security risks. This study deconstructs the
complexities and implications of prompt injection attacks on actual
LLM-integrated applications. Initially, we conduct an exploratory analysis on
ten commercial applications, highlighting the constraints of current attack
strategies in practice. Prompted by these limitations, we subsequently
formulate HouYi, a novel black-box prompt injection attack technique, which
draws inspiration from traditional web injection attacks. HouYi is
compartmentalized into three crucial elements: a seamlessly-incorporated
pre-constructed prompt, an injection prompt inducing context partition, and a
malicious payload designed to fulfill the attack objectives. Leveraging HouYi,
we unveil previously unknown and severe attack outcomes, such as unrestricted
arbitrary LLM usage and uncomplicated application prompt theft. We deploy HouYi
on 36 actual LLM-integrated applications and discern 31 applications
susceptible to prompt injection. 10 vendors have validated our discoveries,
including Notion, which has the potential to impact millions of users. Our
investigation illuminates both the possible risks of prompt injection attacks
and the possible tactics for mitigation.
\\ ( https://arxiv.org/abs/2306.05499 ,  729kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05500 (*cross-listing*)
Date: Sat, 3 Jun 2023 21:39:07 GMT   (4270kb,D)

Title: Word-Level Explanations for Analyzing Bias in Text-to-Image Models
Authors: Alexander Lin, Lucas Monteiro Paes, Sree Harsha Tanneru, Suraj
 Srinivas, Himabindu Lakkaraju
Categories: cs.CL cs.AI cs.CV cs.LG
Comments: 5 main pages, 3 pages in appendix, and 3 figures
\\
 Text-to-image models take a sentence (i.e., prompt) and generate images
associated with this input prompt. These models have created award wining-art,
videos, and even synthetic datasets. However, text-to-image (T2I) models can
generate images that underrepresent minorities based on race and sex. This
paper investigates which word in the input prompt is responsible for bias in
generated images. We introduce a method for computing scores for each word in
the prompt; these scores represent its influence on biases in the model's
output. Our method follows the principle of \emph{explaining by removing},
leveraging masked language models to calculate the influence scores. We perform
experiments on Stable Diffusion to demonstrate that our method identifies the
replication of societal stereotypes in generated images.
\\ ( https://arxiv.org/abs/2306.05500 ,  4270kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05523 (*cross-listing*)
Date: Mon, 22 May 2023 08:29:47 GMT   (9592kb,D)

Title: FACTIFY3M: A Benchmark for Multimodal Fact Verification with
 Explainability through 5W Question-Answering
Authors: Megha Chakraborty, Khusbu Pahwa, Anku Rani, Adarsh Mahor, Aditya
 Pakala, Arghya Sarkar, Harshit Dave, Ishan Paul, Janvita Reddy, Preethi
 Gurumurthy, Ritvik G, Samahriti Mukherjee, Shreyas Chatterjee, Kinjal
 Sensharma, Dwip Dalal, Suryavardan S, Shreyash Mishra, Parth Patwa, Aman
 Chadha, Amit Sheth, Amitava Das
Categories: cs.CL cs.AI cs.CV cs.MM
Comments: arXiv admin note: text overlap with arXiv:2305.04329
\\
 Combating disinformation is one of the burning societal crises -- about 67%
of the American population believes that disinformation produces a lot of
uncertainty, and 10% of them knowingly propagate disinformation. Evidence shows
that disinformation can manipulate democratic processes and public opinion,
causing disruption in the share market, panic and anxiety in society, and even
death during crises. Therefore, disinformation should be identified promptly
and, if possible, mitigated. With approximately 3.2 billion images and 720,000
hours of video shared online daily on social media platforms, scalable
detection of multimodal disinformation requires efficient fact verification.
Despite progress in automatic text-based fact verification (e.g., FEVER, LIAR),
the research community lacks substantial effort in multimodal fact
verification. To address this gap, we introduce FACTIFY 3M, a dataset of 3
million samples that pushes the boundaries of the domain of fact verification
via a multimodal fake news dataset, in addition to offering explainability
through the concept of 5W question-answering. Salient features of the dataset
include: (i) textual claims, (ii) ChatGPT-generated paraphrased claims, (iii)
associated images, (iv) stable diffusion-generated additional images (i.e.,
visual paraphrases), (v) pixel-level image heatmap to foster image-text
explainability of the claim, (vi) 5W QA pairs, and (vii) adversarial fake news
stories.
\\ ( https://arxiv.org/abs/2306.05523 ,  9592kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05535 (*cross-listing*)
Date: Wed, 24 May 2023 12:09:42 GMT   (454kb,D)

Title: Detecting Check-Worthy Claims in Political Debates, Speeches, and
 Interviews Using Audio Data
Authors: Petar Ivanov, Ivan Koychev, Momchil Hardalov, Preslav Nakov
Categories: cs.CL cs.AI cs.IR cs.LG cs.SD eess.AS
Comments: check-worthy claims, fake news, political debates, audio
MSC-class: 68T50
ACM-class: F.2.2; I.2.7
\\
 A large portion of society united around the same vision and ideas carries
enormous energy. That is precisely what political figures would like to
accumulate for their cause. With this goal in mind, they can sometimes resort
to distorting or hiding the truth, unintentionally or on purpose, which opens
the door for misinformation and disinformation. Tools for automatic detection
of check-worthy claims would be of great help to moderators of debates,
journalists, and fact-checking organizations. While previous work on detecting
check-worthy claims has focused on text, here we explore the utility of the
audio signal as an additional information source. We create a new multimodal
dataset (text and audio in English) containing 48 hours of speech. Our
evaluation results show that the audio modality together with text yields
improvements over text alone in the case of multiple speakers. Moreover, an
audio-only model could outperform a text-only one for a single speaker.
\\ ( https://arxiv.org/abs/2306.05535 ,  454kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05540 (*cross-listing*)
Date: Tue, 23 May 2023 11:18:30 GMT   (6804kb,D)

Title: DetectLLM: Leveraging Log Rank Information for Zero-Shot Detection of
 Machine-Generated Text
Authors: Jinyan Su, Terry Yue Zhuo, Di Wang, Preslav Nakov
Categories: cs.CL cs.AI
Comments: machine-generated text, large language models, LLMs, zero-shot
MSC-class: 68T50
ACM-class: F.2.2; I.2.7
\\
 With the rapid progress of large language models (LLMs) and the huge amount
of text they generated, it becomes more and more impractical to manually
distinguish whether a text is machine-generated. Given the growing use of LLMs
in social media and education, it prompts us to develop methods to detect
machine-generated text, preventing malicious usage such as plagiarism,
misinformation, and propaganda. Previous work has studied several zero-shot
methods, which require no training data. These methods achieve good
performance, but there is still a lot of room for improvement. In this paper,
we introduce two novel zero-shot methods for detecting machine-generated text
by leveraging the log rank information. One is called DetectLLM-LRR, which is
fast and efficient, and the other is called DetectLLM-NPR, which is more
accurate, but slower due to the need for perturbations. Our experiments on
three datasets and seven language models show that our proposed methods improve
over the state of the art by 3.9 and 1.75 AUROC points absolute. Moreover,
DetectLLM-NPR needs fewer perturbations than previous work to achieve the same
level of performance, which makes it more practical for real-world use. We also
investigate the efficiency--performance trade-off based on users preference on
these two measures and we provide intuition for using them in practice
effectively. We release the data and the code of both methods in
https://github.com/mbzuai-nlp/DetectLLM
\\ ( https://arxiv.org/abs/2306.05540 ,  6804kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05550 (*cross-listing*)
Date: Thu, 8 Jun 2023 20:46:09 GMT   (1210kb,D)

Title: Bias Against 93 Stigmatized Groups in Masked Language Models and
 Downstream Sentiment Classification Tasks
Authors: Katelyn X. Mei, Sonia Fereidooni, Aylin Caliskan
Categories: cs.CY cs.AI cs.CL cs.LG
Comments: 20 pages,12 figures,2 tables; ACM FAccT 2023
ACM-class: K.4; I.2.7; I.2.0
DOI: 10.1145/3593013.3594109 10.1145/3593013.3594109 10.1145/3593013.3594109
\\
 The rapid deployment of artificial intelligence (AI) models demands a
thorough investigation of biases and risks inherent in these models to
understand their impact on individuals and society. This study extends the
focus of bias evaluation in extant work by examining bias against social
stigmas on a large scale. It focuses on 93 stigmatized groups in the United
States, including a wide range of conditions related to disease, disability,
drug use, mental illness, religion, sexuality, socioeconomic status, and other
relevant factors. We investigate bias against these groups in English
pre-trained Masked Language Models (MLMs) and their downstream sentiment
classification tasks. To evaluate the presence of bias against 93 stigmatized
conditions, we identify 29 non-stigmatized conditions to conduct a comparative
analysis. Building upon a psychology scale of social rejection, the Social
Distance Scale, we prompt six MLMs: RoBERTa-base, RoBERTa-large, XLNet-large,
BERTweet-base, BERTweet-large, and DistilBERT. We use human annotations to
analyze the predicted words from these models, with which we measure the extent
of bias against stigmatized groups. When prompts include stigmatized
conditions, the probability of MLMs predicting negative words is approximately
20 percent higher than when prompts have non-stigmatized conditions. In the
sentiment classification tasks, when sentences include stigmatized conditions
related to diseases, disability, education, and mental illness, they are more
likely to be classified as negative. We also observe a strong correlation
between bias in MLMs and their downstream sentiment classifiers (r =0.79). The
evidence indicates that MLMs and their downstream sentiment classification
tasks exhibit biases against socially stigmatized groups.
\\ ( https://arxiv.org/abs/2306.05550 ,  1210kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05554 (*cross-listing*)
Date: Sat, 6 May 2023 10:16:04 GMT   (1795kb)

Title: Simulation and Prediction of Countercurrent Spontaneous Imbibition at
 Early and Late Times Using Physics-Informed Neural Networks
Authors: Jassem Abbasi, P{\aa}l {\O}steb{\o} Andersen
Categories: physics.comp-ph cs.AI cs.LG
\\
 Countercurrent spontaneous imbibition (COUCSI) is a process in porous
materials in which a wetting phase displaces non-wetting phase. In this work,
we investigate for the first time the application of Physics-Informed Neural
Networks (PINNs) in solving the 1D COUCSI problem in both early (ET) and late
(LT) times. Also novel, we examine the Change-of-Variables technique for
improving the performance of PINNs. We formulated the COUCSI problem in three
equivalent forms by changing the independent variables: XT-, XY-, and
Z-formulations. The first describes saturation as function of normalized
position X and time T; the second as function of X and Y=T^0.5; and the third
as a sole function of Z=X/T^0.5 (valid only at ET). The PINN model was
generated using a feed-forward neural network and trained based on minimizing a
weighted loss function, including the physics-informed loss term and terms
corresponding to the initial and boundary conditions. No synthetical or
experimental data were involved in the training. All three formulations could
closely approximate the correct solutions (obtained by fine-grid numerical
simulations), with water saturation mean absolute errors (MAE) around 0.019 and
0.009 for XT and XY formulations and 0.012 for the Z formulation at ET. The Z
formulation perfectly captured the self-similarity of the system at ET. This
was less captured by XT and XY formulations. The total variation (TV) of
saturation was preserved in the Z formulation, and it was better preserved with
XY- than XT formulation. It was demonstrated that redefining the problem based
on physics-inspired variables reduced the non-linearity of the problem and
allowed higher solution accuracies, a higher degree of loss-landscape
convexity, a lower number of required collocation points, smaller network
sizes, and more computationally efficient solutions.
\\ ( https://arxiv.org/abs/2306.05554 ,  1795kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05605 (*cross-listing*)
Date: Fri, 9 Jun 2023 00:33:30 GMT   (6980kb,D)

Title: A Unified Generative Approach to Product Attribute-Value Identification
Authors: Keiji Shinzato, Naoki Yoshinaga, Yandi Xia and Wei-Te Chen
Categories: cs.CL cs.AI
Comments: Accepted to the Findings of ACL 2023
\\
 Product attribute-value identification (PAVI) has been studied to link
products on e-commerce sites with their attribute values (e.g., <Material,
Cotton>) using product text as clues. Technical demands from real-world
e-commerce platforms require PAVI methods to handle unseen values,
multi-attribute values, and canonicalized values, which are only partly
addressed in existing extraction- and classification-based approaches.
Motivated by this, we explore a generative approach to the PAVI task. We
finetune a pre-trained generative model, T5, to decode a set of attribute-value
pairs as a target sequence from the given product text. Since the attribute
value pairs are unordered set elements, how to linearize them will matter; we,
thus, explore methods of composing an attribute-value pair and ordering the
pairs for the task. Experimental results confirm that our generation-based
approach outperforms the existing extraction and classification-based methods
on large-scale real-world datasets meant for those methods.
\\ ( https://arxiv.org/abs/2306.05605 ,  6980kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05652 (*cross-listing*)
Date: Fri, 9 Jun 2023 03:37:49 GMT   (314kb,D)

Title: Privacy Aware Question-Answering System for Online Mental Health Risk
 Assessment
Authors: Prateek Chhikara, Ujjwal Pasupulety, John Marshall, Dhiraj Chaurasia,
 Shweta Kumari
Categories: cs.CL cs.AI cs.HC
Comments: 5 pages, 2 figures, 3 tables
\\
 Social media platforms have enabled individuals suffering from mental
illnesses to share their lived experiences and find the online support
necessary to cope. However, many users fail to receive genuine clinical
support, thus exacerbating their symptoms. Screening users based on what they
post online can aid providers in administering targeted healthcare and minimize
false positives. Pre-trained Language Models (LMs) can assess users' social
media data and classify them in terms of their mental health risk. We propose a
Question-Answering (QA) approach to assess mental health risk using the
Unified-QA model on two large mental health datasets. To protect user data, we
extend Unified-QA by anonymizing the model training process using differential
privacy. Our results demonstrate the effectiveness of modeling risk assessment
as a QA task, specifically for mental health use cases. Furthermore, the
model's performance decreases by less than 1% with the inclusion of
differential privacy. The proposed system's performance is indicative of a
promising research direction that will lead to the development of privacy-aware
diagnostic systems.
\\ ( https://arxiv.org/abs/2306.05652 ,  314kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05659 (*cross-listing*)
Date: Fri, 9 Jun 2023 03:53:42 GMT   (440kb)

Title: COVER: A Heuristic Greedy Adversarial Attack on Prompt-based Learning in
 Language Models
Authors: Zihao Tan, Qingliang Chen, Wenbin Zhu and Yongjian Huang
Categories: cs.CL cs.AI
\\
 Prompt-based learning has been proved to be an effective way in pre-trained
language models (PLMs), especially in low-resource scenarios like few-shot
settings. However, the trustworthiness of PLMs is of paramount significance and
potential vulnerabilities have been shown in prompt-based templates that could
mislead the predictions of language models, causing serious security concerns.
In this paper, we will shed light on some vulnerabilities of PLMs, by proposing
a prompt-based adversarial attack on manual templates in black box scenarios.
First of all, we design character-level and word-level heuristic approaches to
break manual templates separately. Then we present a greedy algorithm for the
attack based on the above heuristic destructive approaches. Finally, we
evaluate our approach with the classification tasks on three variants of BERT
series models and eight datasets. And comprehensive experimental results
justify the effectiveness of our approach in terms of attack success rate and
attack speed. Further experimental studies indicate that our proposed method
also displays good capabilities in scenarios with varying shot counts, template
lengths and query counts, exhibiting good generalizability.
\\ ( https://arxiv.org/abs/2306.05659 ,  440kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05685 (*cross-listing*)
Date: Fri, 9 Jun 2023 05:55:52 GMT   (1667kb,D)

Title: Judging LLM-as-a-judge with MT-Bench and Chatbot Arena
Authors: Lianmin Zheng, Wei-Lin Chiang, Ying Sheng, Siyuan Zhuang, Zhanghao Wu,
 Yonghao Zhuang, Zi Lin, Zhuohan Li, Dacheng Li, Eric. P Xing, Hao Zhang,
 Joseph E. Gonzalez, Ion Stoica
Categories: cs.CL cs.AI
\\
 Evaluating large language model (LLM) based chat assistants is challenging
due to their broad capabilities and the inadequacy of existing benchmarks in
measuring human preferences. To address this, we explore using strong LLMs as
judges to evaluate these models on more open-ended questions. We examine the
usage and limitations of LLM-as-a-judge, such as position and verbosity biases
and limited reasoning ability, and propose solutions to migrate some of them.
We then verify the agreement between LLM judges and human preferences by
introducing two benchmarks: MT-bench, a multi-turn question set; and Chatbot
Arena, a crowdsourced battle platform. Our results reveal that strong LLM
judges like GPT-4 can match both controlled and crowdsourced human preferences
well, achieving over 80\% agreement, the same level of agreement between
humans. Hence, LLM-as-a-judge is a scalable and explainable way to approximate
human preferences, which are otherwise very expensive to obtain. Additionally,
we show our benchmark and traditional benchmarks complement each other by
evaluating several variants of LLaMA/Vicuna. We will publicly release 80
MT-bench questions, 3K expert votes, and 30K conversations with human
preferences from Chatbot Arena.
\\ ( https://arxiv.org/abs/2306.05685 ,  1667kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05715 (*cross-listing*)
Date: Fri, 9 Jun 2023 07:19:43 GMT   (238kb)

Title: Exploring the Responses of Large Language Models to Beginner
 Programmers' Help Requests
Authors: Arto Hellas, Juho Leinonen, Sami Sarsa, Charles Koutcheme, Lilja
 Kujanp\"a\"a, Juha Sorva
Categories: cs.CY cs.AI cs.CL cs.HC cs.SE
Comments: 13 pages, 1 figure. To be published in Proceedings of the 2023 ACM
 Conference on International Computing Education Research V.1 (ICER '23 V1)
DOI: 10.1145/3568813.3600139
\\
 Background and Context: Over the past year, large language models (LLMs) have
taken the world by storm. In computing education, like in other walks of life,
many opportunities and threats have emerged as a consequence.
 Objectives: In this article, we explore such opportunities and threats in a
specific area: responding to student programmers' help requests. More
specifically, we assess how good LLMs are at identifying issues in problematic
code that students request help on.
 Method: We collected a sample of help requests and code from an online
programming course. We then prompted two different LLMs (OpenAI Codex and
GPT-3.5) to identify and explain the issues in the students' code and assessed
the LLM-generated answers both quantitatively and qualitatively.
 Findings: GPT-3.5 outperforms Codex in most respects. Both LLMs frequently
find at least one actual issue in each student program (GPT-3.5 in 90% of the
cases). Neither LLM excels at finding all the issues (GPT-3.5 finding them 57%
of the time). False positives are common (40% chance for GPT-3.5). The advice
that the LLMs provide on the issues is often sensible. The LLMs perform better
on issues involving program logic rather than on output formatting. Model
solutions are frequently provided even when the LLM is prompted not to. LLM
responses to prompts in a non-English language are only slightly worse than
responses to English prompts.
 Implications: Our results continue to highlight the utility of LLMs in
programming education. At the same time, the results highlight the
unreliability of LLMs: LLMs make some of the same mistakes that students do,
perhaps especially when formatting output as required by automated assessment
systems. Our study informs teachers interested in using LLMs as well as future
efforts to customize LLMs for the needs of programming education.
\\ ( https://arxiv.org/abs/2306.05715 ,  238kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05741 (*cross-listing*)
Date: Fri, 9 Jun 2023 08:18:58 GMT   (1051kb,D)

Title: Challenges and Opportunities for the Design of Smart Speakers
Authors: Tao Long, Lydia B. Chilton
Categories: cs.HC cs.AI cs.CL cs.CY cs.RO
Comments: 15 pages, 7 figures
\\
 Advances in voice technology and voice user interfaces (VUIs) -- such as
Alexa, Siri, and Google Home -- have opened up the potential for many new types
of interaction. However, despite the potential of these devices reflected by
the growing market and body of VUI research, there is a lingering sense that
the technology is still underused. In this paper, we conducted a systematic
literature review of 35 papers to identify and synthesize 127 VUI design
guidelines into five themes. Additionally, we conducted semi-structured
interviews with 15 smart speaker users to understand their use and non-use of
the technology. From the interviews, we distill four design challenges that
contribute the most to non-use. Based on their (non-)use, we identify four
opportunity spaces for designers to explore such as focusing on information
support while multitasking (cooking, driving, childcare, etc), incorporating
users' mental models for smart speakers, and integrating calm design
principles.
\\ ( https://arxiv.org/abs/2306.05741 ,  1051kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05752 (*cross-listing*)
Date: Fri, 9 Jun 2023 08:31:41 GMT   (319kb)

Title: From psychological traits to safety warnings: three studies on
 recommendations in a smart home environment
Authors: Federica Cena, Cristina Gena, Claudio Mattutino, Michele Mioli, and
 Fabiana Vernero
Categories: cs.HC cs.AI
\\
 In this paper, we report on three experiments we have carried out in the
context of the EMPATHY project, with the aim of helping users make better
configuration choices in a smart home environment, and discuss our results. We
found that there are psychological traits, such as Need for Cognition, which
influence the way individuals tend to use recommendations, that there are non
obvious relationships between the perceived usefulness of recommendations in
different domains and individuals' ability to exploit suggestions on
configuration choices, and that detailed, easy-to-understand security
explanations are more persuasive than simple security warnings, when it comes
to make decisions on the applicability of rules which might cause privacy and
security risks.
\\ ( https://arxiv.org/abs/2306.05752 ,  319kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05809 (*cross-listing*)
Date: Fri, 9 Jun 2023 10:48:04 GMT   (10082kb,D)

Title: Interactive Explanation with Varying Level of Details in an Explainable
 Scientific Literature Recommender System
Authors: Mouadh Guesmi and Mohamed Amine Chatti and Shoeb Joarder and Qurat Ul
 Ain and Rawaa Alatrash and Clara Siepmann and Tannaz Vahidi
Categories: cs.IR cs.AI cs.CY cs.HC
Comments: 23 pages
\\
 Explainable recommender systems (RS) have traditionally followed a
one-size-fits-all approach, delivering the same explanation level of detail to
each user, without considering their individual needs and goals. Further,
explanations in RS have so far been presented mostly in a static and
non-interactive manner. To fill these research gaps, we aim in this paper to
adopt a user-centered, interactive explanation model that provides explanations
with different levels of detail and empowers users to interact with, control,
and personalize the explanations based on their needs and preferences. We
followed a user-centered approach to design interactive explanations with three
levels of detail (basic, intermediate, and advanced) and implemented them in
the transparent Recommendation and Interest Modeling Application (RIMA). We
conducted a qualitative user study (N=14) to investigate the impact of
providing interactive explanations with varying level of details on the users'
perception of the explainable RS. Our study showed qualitative evidence that
fostering interaction and giving users control in deciding which explanation
they would like to see can meet the demands of users with different needs,
preferences, and goals, and consequently can have positive effects on different
crucial aspects in explainable recommendation, including transparency, trust,
satisfaction, and user experience.
\\ ( https://arxiv.org/abs/2306.05809 ,  10082kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05817 (*cross-listing*)
Date: Fri, 9 Jun 2023 11:31:50 GMT   (639kb,D)

Title: How Can Recommender Systems Benefit from Large Language Models: A Survey
Authors: Jianghao Lin, Xinyi Dai, Yunjia Xi, Weiwen Liu, Bo Chen, Xiangyang Li,
 Chenxu Zhu, Huifeng Guo, Yong Yu, Ruiming Tang, Weinan Zhang
Categories: cs.IR cs.AI
Comments: 15 pages; 3 figures; summarization table in appendix;
\\
 Recommender systems (RS) play important roles to match users' information
needs for Internet applications. In natural language processing (NLP) domains,
large language model (LLM) has shown astonishing emergent abilities (e.g.,
instruction following, reasoning), thus giving rise to the promising research
direction of adapting LLM to RS for performance enhancements and user
experience improvements. In this paper, we conduct a comprehensive survey on
this research direction from an application-oriented view. We first summarize
existing research works from two orthogonal perspectives: where and how to
adapt LLM to RS. For the "WHERE" question, we discuss the roles that LLM could
play in different stages of the recommendation pipeline, i.e., feature
engineering, feature encoder, scoring/ranking function, and pipeline
controller. For the "HOW" question, we investigate the training and inference
strategies, resulting in two fine-grained taxonomy criteria, i.e., whether to
tune LLMs or not, and whether to involve conventional recommendation model
(CRM) for inference. Detailed analysis and general development trajectories are
provided for both questions, respectively. Then, we highlight key challenges in
adapting LLM to RS from three aspects, i.e., efficiency, effectiveness, and
ethics. Finally, we summarize the survey and discuss the future prospects. We
also actively maintain a GitHub repository for papers and other related
resources in this rising direction:
$\href{https://github.com/CHIANGEL/Awesome-LLM-for-RecSys}{[GitHub\;Link]}$.
\\ ( https://arxiv.org/abs/2306.05817 ,  639kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05836 (*cross-listing*)
Date: Fri, 9 Jun 2023 12:09:15 GMT   (351kb,D)

Title: Can Large Language Models Infer Causation from Correlation?
Authors: Zhijing Jin, Jiarui Liu, Zhiheng Lyu, Spencer Poff, Mrinmaya Sachan,
 Rada Mihalcea, Mona Diab, Bernhard Sch\"olkopf
Categories: cs.CL cs.AI cs.LG
\\
 Causal inference is one of the hallmarks of human intelligence. While the
field of CausalNLP has attracted much interest in the recent years, existing
causal inference datasets in NLP primarily rely on discovering causality from
empirical knowledge (e.g., commonsense knowledge). In this work, we propose the
first benchmark dataset to test the pure causal inference skills of large
language models (LLMs). Specifically, we formulate a novel task Corr2Cause,
which takes a set of correlational statements and determines the causal
relationship between the variables. We curate a large-scale dataset of more
than 400K samples, on which we evaluate seventeen existing LLMs. Through our
experiments, we identify a key shortcoming of LLMs in terms of their causal
inference skills, and show that these models achieve almost close to random
performance on the task. This shortcoming is somewhat mitigated when we try to
re-purpose LLMs for this skill via finetuning, but we find that these models
still fail to generalize -- they can only perform causal inference in
in-distribution settings when variable names and textual expressions used in
the queries are similar to those in the training set, but fail in
out-of-distribution settings generated by perturbing these queries. Corr2Cause
is a challenging task for LLMs, and would be helpful in guiding future research
on improving LLMs' pure reasoning skills and generalizability. Our data is at
https://huggingface.co/datasets/causalnlp/corr2cause. Our code is at
https://github.com/causalNLP/corr2cause.
\\ ( https://arxiv.org/abs/2306.05836 ,  351kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05949 (*cross-listing*)
Date: Fri, 9 Jun 2023 15:05:13 GMT   (223kb,D)

Title: Evaluating the Social Impact of Generative AI Systems in Systems and
 Society
Authors: Irene Solaiman, Zeerak Talat, William Agnew, Lama Ahmad, Dylan Baker,
 Su Lin Blodgett, Hal Daum\'e III, Jesse Dodge, Ellie Evans, Sara Hooker,
 Yacine Jernite, Alexandra Sasha Luccioni, Alberto Lusoli, Margaret Mitchell,
 Jessica Newman, Marie-Therese Png, Andrew Strait, Apostol Vassilev
Categories: cs.CY cs.AI
\\
 Generative AI systems across modalities, ranging from text, image, audio, and
video, have broad social impacts, but there exists no official standard for
means of evaluating those impacts and which impacts should be evaluated. We
move toward a standard approach in evaluating a generative AI system for any
modality, in two overarching categories: what is able to be evaluated in a base
system that has no predetermined application and what is able to be evaluated
in society. We describe specific social impact categories and how to approach
and conduct evaluations in the base technical system, then in people and
society. Our framework for a base system defines seven categories of social
impact: bias, stereotypes, and representational harms; cultural values and
sensitive content; disparate performance; privacy and data protection;
financial costs; environmental costs; and data and content moderation labor
costs. Suggested methods for evaluation apply to all modalities and analyses of
the limitations of existing evaluations serve as a starting point for necessary
investment in future evaluations. We offer five overarching categories for what
is able to be evaluated in society, each with their own subcategories:
trustworthiness and autonomy; inequality, marginalization, and violence;
concentration of authority; labor and creativity; and ecosystem and
environment. Each subcategory includes recommendations for mitigating harm. We
are concurrently crafting an evaluation repository for the AI research
community to contribute existing evaluations along the given categories. This
version will be updated following a CRAFT session at ACM FAccT 2023.
\\ ( https://arxiv.org/abs/2306.05949 ,  223kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05973 (*cross-listing*)
Date: Fri, 9 Jun 2023 15:37:24 GMT   (84kb)

Title: Query Rewriting with Disjunctive Existential Rules and Mappings
Authors: Michel Lecl\`ere and Marie-Laure Mugnier and Guillaume
 P\'erution-Kihli
Categories: cs.DB cs.AI
Comments: This report contains the paper accepted at KR 2023 and an appendix
 with full proofs. 24 pages
\\
 We consider the issue of answering unions of conjunctive queries (UCQs) with
disjunctive existential rules and mappings. While this issue has already been
well studied from a chase perspective, query rewriting within UCQs has hardly
been addressed yet. We first propose a sound and complete query rewriting
operator, which has the advantage of establishing a tight relationship between
a chase step and a rewriting step. The associated breadth-first query rewriting
algorithm outputs a minimal UCQ-rewriting when one exists. Second, we show that
for any ``truly disjunctive'' nonrecursive rule, there exists a conjunctive
query that has no UCQ-rewriting. It follows that the notion of finite
unification sets (fus), which denotes sets of existential rules such that any
UCQ admits a UCQ-rewriting, seems to have little relevance in this setting.
Finally, turning our attention to mappings, we show that the problem of
determining whether a UCQ admits a UCQ-rewriting through a disjunctive mapping
is undecidable. We conclude with a number of open problems.
\\ ( https://arxiv.org/abs/2306.05973 ,  84kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06000 (*cross-listing*)
Date: Fri, 9 Jun 2023 16:13:43 GMT   (851kb,D)

Title: S$^{3}$: Increasing GPU Utilization during Generative Inference for
 Higher Throughput
Authors: Yunho Jin, Chun-Feng Wu, David Brooks, Gu-Yeon Wei
Categories: cs.AR cs.AI
\\
 Generating texts with a large language model (LLM) consumes massive amounts
of memory. Apart from the already-large model parameters, the key/value (KV)
cache that holds information about previous tokens in a sequence can grow to be
even larger than the model itself. This problem is exacerbated in one of the
current LLM serving frameworks which reserves the maximum sequence length of
memory for the KV cache to guarantee generating a complete sequence as they do
not know the output sequence length. This restricts us to use a smaller batch
size leading to lower GPU utilization and above all, lower throughput. We argue
that designing a system with a priori knowledge of the output sequence can
mitigate this problem. To this end, we propose S$^{3}$, which predicts the
output sequence length, schedules generation queries based on the prediction to
increase device resource utilization and throughput, and handle mispredictions.
Our proposed method achieves 6.49$\times$ throughput over those systems that
assume the worst case for the output sequence length.
\\ ( https://arxiv.org/abs/2306.06000 ,  851kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06002 (*cross-listing*)
Date: Fri, 9 Jun 2023 16:16:53 GMT   (71kb,D)

Title: Causal Effect Estimation from Observational and Interventional Data
 Through Matrix Weighted Linear Estimators
Authors: Klaus-Rudolf Kladny, Julius von K\"ugelgen, Bernhard Sch\"olkopf,
 Michael Muehlebach
Categories: stat.ME cs.AI
\\
 We study causal effect estimation from a mixture of observational and
interventional data in a confounded linear regression model with multivariate
treatments. We show that the statistical efficiency in terms of expected
squared error can be improved by combining estimators arising from both the
observational and interventional setting. To this end, we derive methods based
on matrix weighted linear estimators and prove that our methods are
asymptotically unbiased in the infinite sample limit. This is an important
improvement compared to the pooled estimator using the union of interventional
and observational data, for which the bias only vanishes if the ratio of
observational to interventional data tends to zero. Studies on synthetic data
confirm our theoretical findings. In settings where confounding is substantial
and the ratio of observational to interventional data is large, our estimators
outperform a Stein-type estimator and various other baselines.
\\ ( https://arxiv.org/abs/2306.06002 ,  71kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06022 (*cross-listing*)
Date: Fri, 9 Jun 2023 16:41:34 GMT   (1011kb)

Title: A Dynamic Partial Computation Offloading for the Metaverse in In-Network
 Computing
Authors: Ibrahim Aliyu, Namseok Ko, Tai-Won Um, Jinsul Kim
Categories: cs.DC cs.AI cs.GT
Comments: 14 pages, 9 figures
\\
 The In-Network Computing (COIN) paradigm is a promising solution that
leverages unused network resources to perform some tasks to meet up with
computation-demanding applications, such as metaverse. In this vein, we
consider the metaverse partial computation offloading problem for multiple
subtasks in a COIN environment to minimise energy consumption and delay while
dynamically adjusting the offloading policy based on the changing computation
resources status. We prove that the problem is NP and thus transformed it into
two subproblems: task splitting problem (TSP) on the user side and task
offloading problem (TOP) on the COIN side. We modelled the TSP as an ordinal
potential game (OPG) and proposed a decentralised algorithm to obtain its Nash
Equilibrium (NE). Then, we model the TOP as Markov Decision Process (MDP)
proposed double deep Q-network (DDQN) to solve for the optimal offloading
policy. Unlike the conventional DDQN algorithm, where intelligent agents sample
offloading decisions randomly within a certain probability, our COIN agent
explores the NE of the TSP and the deep neural network. Finally, simulation
results show that our proposed model approach allows the COIN agent to update
its policies and make more informed decisions, leading to improved performance
over time compared to the traditional baseline.
\\ ( https://arxiv.org/abs/2306.06022 ,  1011kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06029 (*cross-listing*)
Date: Fri, 9 Jun 2023 16:50:02 GMT   (2402kb,D)

Title: HiTZ@Antidote: Argumentation-driven Explainable Artificial Intelligence
 for Digital Medicine
Authors: Rodrigo Agerri, I\~nigo Alonso, Aitziber Atutxa, Ander Berrondo,
 Ainara Estarrona, Iker Garcia-Ferrero, Iakes Goenaga, Koldo Gojenola, Maite
 Oronoz, Igor Perez-Tejedor, German Rigau and Anar Yeginbergenova
Categories: cs.CL cs.AI
Comments: To appear: In SEPLN 2023: 39th International Conference of the
 Spanish Society for Natural Language Processing
\\
 Providing high quality explanations for AI predictions based on machine
learning is a challenging and complex task. To work well it requires, among
other factors: selecting a proper level of generality/specificity of the
explanation; considering assumptions about the familiarity of the explanation
beneficiary with the AI task under consideration; referring to specific
elements that have contributed to the decision; making use of additional
knowledge (e.g. expert evidence) which might not be part of the prediction
process; and providing evidence supporting negative hypothesis. Finally, the
system needs to formulate the explanation in a clearly interpretable, and
possibly convincing, way. Given these considerations, ANTIDOTE fosters an
integrated vision of explainable AI, where low-level characteristics of the
deep learning process are combined with higher level schemes proper of the
human argumentation capacity. ANTIDOTE will exploit cross-disciplinary
competences in deep learning and argumentation to support a broader and
innovative view of explainable AI, where the need for high-quality explanations
for clinical cases deliberation is critical. As a first result of the project,
we publish the Antidote CasiMedicos dataset to facilitate research on
explainable AI in general, and argumentation in the medical domain in
particular.
\\ ( https://arxiv.org/abs/2306.06029 ,  2402kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06085 (*cross-listing*)
Date: Fri, 9 Jun 2023 17:48:54 GMT   (128kb,D)

Title: Trapping LLM Hallucinations Using Tagged Context Prompts
Authors: Philip Feldman, James R. Foulds, Shimei Pan
Categories: cs.CL cs.AI
Comments: 13 pages, 3 Figures, 2 Tables
ACM-class: I.2.7; K.4.2
\\
 Recent advances in large language models (LLMs), such as ChatGPT, have led to
highly sophisticated conversation agents. However, these models suffer from
"hallucinations," where the model generates false or fabricated information.
Addressing this challenge is crucial, particularly with AI-driven platforms
being adopted across various sectors. In this paper, we propose a novel method
to recognize and flag instances when LLMs perform outside their domain
knowledge, and ensuring users receive accurate information.
 We find that the use of context combined with embedded tags can successfully
combat hallucinations within generative language models. To do this, we
baseline hallucination frequency in no-context prompt-response pairs using
generated URLs as easily-tested indicators of fabricated data. We observed a
significant reduction in overall hallucination when context was supplied along
with question prompts for tested generative engines. Lastly, we evaluated how
placing tags within contexts impacted model responses and were able to
eliminate hallucinations in responses with 98.88% effectiveness.
\\ ( https://arxiv.org/abs/2306.06085 ,  128kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05514 (*cross-listing*)
Date: Thu, 8 Jun 2023 19:07:22 GMT   (5720kb,D)

Title: Robust Brain Age Estimation via Regression Models and MRI-derived
 Features
Authors: Mansoor Ahmed, Usama Sardar, Sarwan Ali, Shafiq Alam, Murray
 Patterson, Imdad Ullah Khan
Categories: eess.IV cs.CV cs.LG q-bio.NC
Comments: Published at the 15th International Conference on Computational
 Collective Intelligence
\\
 The determination of biological brain age is a crucial biomarker in the
assessment of neurological disorders and understanding of the morphological
changes that occur during aging. Various machine learning models have been
proposed for estimating brain age through Magnetic Resonance Imaging (MRI) of
healthy controls. However, developing a robust brain age estimation (BAE)
framework has been challenging due to the selection of appropriate MRI-derived
features and the high cost of MRI acquisition. In this study, we present a
novel BAE framework using the Open Big Healthy Brain (OpenBHB) dataset, which
is a new multi-site and publicly available benchmark dataset that includes
region-wise feature metrics derived from T1-weighted (T1-w) brain MRI scans of
3965 healthy controls aged between 6 to 86 years. Our approach integrates three
different MRI-derived region-wise features and different regression models,
resulting in a highly accurate brain age estimation with a Mean Absolute Error
(MAE) of 3.25 years, demonstrating the framework's robustness. We also analyze
our model's regression-based performance on gender-wise (male and female)
healthy test groups. The proposed BAE framework provides a new approach for
estimating brain age, which has important implications for the understanding of
neurological disorders and age-related brain changes.
\\ ( https://arxiv.org/abs/2306.05514 ,  5720kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05745 (*cross-listing*)
Date: Fri, 9 Jun 2023 08:22:41 GMT   (1707kb,D)

Title: Two Independent Teachers are Better Role Model
Authors: Afifa Khaled, Ahmed A. Mubarak, Kun He
Categories: eess.IV cs.CV cs.LG
Comments: This manuscript contains 14 pages, 7 figures. We have submitted the
 manuscript to Journal of IEEE Transactions on Medical Imaging (TMI) in June
 2023
\\
 Recent deep learning models have attracted substantial attention in infant
brain analysis. These models have performed state-of-the-art performance, such
as semi-supervised techniques (e.g., Temporal Ensembling, mean teacher).
However, these models depend on an encoder-decoder structure with stacked local
operators to gather long-range information, and the local operators limit the
efficiency and effectiveness. Besides, the $MRI$ data contain different tissue
properties ($TPs$) such as $T1$ and $T2$. One major limitation of these models
is that they use both data as inputs to the segment process, i.e., the models
are trained on the dataset once, and it requires much computational and memory
requirements during inference. In this work, we address the above limitations
by designing a new deep-learning model, called 3D-DenseUNet, which works as
adaptable global aggregation blocks in down-sampling to solve the issue of
spatial information loss. The self-attention module connects the down-sampling
blocks to up-sampling blocks, and integrates the feature maps in three
dimensions of spatial and channel, effectively improving the representation
potential and discriminating ability of the model. Additionally, we propose a
new method called Two Independent Teachers ($2IT$), that summarizes the model
weights instead of label predictions. Each teacher model is trained on
different types of brain data, $T1$ and $T2$, respectively. Then, a fuse model
is added to improve test accuracy and enable training with fewer parameters and
labels compared to the Temporal Ensembling method without modifying the network
architecture. Empirical results demonstrate the effectiveness of the proposed
method.
\\ ( https://arxiv.org/abs/2306.05745 ,  1707kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05812 (*cross-listing*)
Date: Fri, 9 Jun 2023 11:05:09 GMT   (14649kb,D)

Title: HRTF upsampling with a generative adversarial network using a gnomonic
 equiangular projection
Authors: Aidan O. T. Hogg, Mads Jenkins, He Liu, Isaac Squires, Samuel J.
 Cooper and Lorenzo Picinali
Categories: eess.AS cs.CV cs.HC cs.LG cs.SD eess.SP
Comments: 13 pages, 9 figures, Preprint (Submitted to Transactions on Audio,
 Speech and Language Processing on the 24 Feb 2023)
\\
 An individualised head-related transfer function (HRTF) is essential for
creating realistic virtual reality (VR) and augmented reality (AR)
environments. However, acoustically measuring high-quality HRTFs requires
expensive equipment and an acoustic lab setting. To overcome these limitations
and to make this measurement more efficient HRTF upsampling has been exploited
in the past where a high-resolution HRTF is created from a low-resolution one.
This paper demonstrates how generative adversarial networks (GANs) can be
applied to HRTF upsampling. We propose a novel approach that transforms the
HRTF data for convenient use with a convolutional super-resolution generative
adversarial network (SRGAN). This new approach is benchmarked against two
baselines: barycentric upsampling and a HRTF selection approach. Experimental
results show that the proposed method outperforms both baselines in terms of
log-spectral distortion (LSD) and localisation performance using perceptual
models when the input HRTF is sparse.
\\ ( https://arxiv.org/abs/2306.05812 ,  14649kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05912 (*cross-listing*)
Date: Fri, 9 Jun 2023 14:06:26 GMT   (19591kb,D)

Title: Single-Image-Based Deep Learning for Segmentation of Early Esophageal
 Cancer Lesions
Authors: Haipeng Li, Dingrui Liu, Yu Zeng, Shuaicheng Liu, Tao Gan, Nini Rao,
 Jinlin Yang, Bing Zeng
Categories: eess.IV cs.CV
\\
 Accurate segmentation of lesions is crucial for diagnosis and treatment of
early esophageal cancer (EEC). However, neither traditional nor deep
learning-based methods up to today can meet the clinical requirements, with the
mean Dice score - the most important metric in medical image analysis - hardly
exceeding 0.75. In this paper, we present a novel deep learning approach for
segmenting EEC lesions. Our approach stands out for its uniqueness, as it
relies solely on a single image coming from one patient, forming the so-called
"You-Only-Have-One" (YOHO) framework. On one hand, this "one-image-one-network"
learning ensures complete patient privacy as it does not use any images from
other patients as the training data. On the other hand, it avoids nearly all
generalization-related problems since each trained network is applied only to
the input image itself. In particular, we can push the training to
"over-fitting" as much as possible to increase the segmentation accuracy. Our
technical details include an interaction with clinical physicians to utilize
their expertise, a geometry-based rendering of a single lesion image to
generate the training set (the \emph{biggest} novelty), and an edge-enhanced
UNet. We have evaluated YOHO over an EEC data-set created by ourselves and
achieved a mean Dice score of 0.888, which represents a significant advance
toward clinical applications.
\\ ( https://arxiv.org/abs/2306.05912 ,  19591kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06038 (*cross-listing*)
Date: Fri, 9 Jun 2023 17:02:26 GMT   (4659kb,D)

Title: WindowNet: Learnable Windows for Chest X-ray Classification
Authors: Alessandro Wollek, Sardi Hyska, Bastian Sabel, Michael Ingrisch,
 Tobias Lasser
Categories: eess.IV cs.CV
\\
 Chest X-ray (CXR) images are commonly compressed to a lower resolution and
bit depth to reduce their size, potentially altering subtle diagnostic
features.
 Radiologists use windowing operations to enhance image contrast, but the
impact of such operations on CXR classification performance is unclear.
 In this study, we show that windowing can improve CXR classification
performance, and propose WindowNet, a model that learns optimal window
settings.
 We first investigate the impact of bit-depth on classification performance
and find that a higher bit-depth (12-bit) leads to improved performance.
 We then evaluate different windowing settings and show that training with a
distinct window generally improves pathology-wise classification performance.
 Finally, we propose and evaluate WindowNet, a model that learns optimal
window settings, and show that it significantly improves performance compared
to the baseline model without windowing.
\\ ( https://arxiv.org/abs/2306.06038 ,  4659kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06088 (*cross-listing*)
Date: Fri, 9 Jun 2023 17:50:53 GMT   (41216kb,D)

Title: SENS: Sketch-based Implicit Neural Shape Modeling
Authors: Alexandre Binninger, Amir Hertz, Olga Sorkine-Hornung, Daniel
 Cohen-Or, Raja Giryes
Categories: cs.GR cs.CV cs.LG
Comments: 18 pages, 18 figures
\\
 We present SENS, a novel method for generating and editing 3D models from
hand-drawn sketches, including those of an abstract nature. Our method allows
users to quickly and easily sketch a shape, and then maps the sketch into the
latent space of a part-aware neural implicit shape architecture. SENS analyzes
the sketch and encodes its parts into ViT patch encoding, then feeds them into
a transformer decoder that converts them to shape embeddings, suitable for
editing 3D neural implicit shapes. SENS not only provides intuitive
sketch-based generation and editing, but also excels in capturing the intent of
the user's sketch to generate a variety of novel and expressive 3D shapes, even
from abstract sketches. We demonstrate the effectiveness of our model compared
to the state-of-the-art using objective metric evaluation criteria and a
decisive user study, both indicating strong performance on sketches with a
medium level of abstraction. Furthermore, we showcase its intuitive
sketch-based shape editing capabilities.
\\ ( https://arxiv.org/abs/2306.06088 ,  41216kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05597 (*cross-listing*)
Date: Thu, 8 Jun 2023 23:57:27 GMT   (67kb)

Title: Application of zero-determinant strategies to particle control in
 statistical physics
Authors: Masahiko Ueda
Categories: cond-mat.stat-mech cs.GT cs.SY eess.SY physics.soc-ph
Comments: 9 pages, 2 figures
\\
 Zero-determinant strategies are a class of strategies in repeated games which
unilaterally control payoffs. Zero-determinant strategies have attracted much
attention in studies of social dilemma, particularly in the context of
evolution of cooperation. So far, not only general properties of
zero-determinant strategies have been investigated, but zero-determinant
strategies have been applied to control in the fields of information and
communications technology and analysis of imitation. Here, we provide another
example of application of zero-determinant strategies: control of a particle on
a lattice. We first prove that zero-determinant strategies, if exist, can be
implemented by some one-dimensional transition probability. Next, we prove
that, if a two-player game has a non-trivial potential function, a
zero-determinant strategy exists in its repeated version. These two results
enable us to apply the concept of zero-determinant strategies to control the
expected potential energies of two coordinates of a particle on a
two-dimensional lattice.
\\ ( https://arxiv.org/abs/2306.05597 ,  67kb)
------------------------------------------------------------------------------
\\
arXiv:2305.16255 (*cross-listing*)
Date: Thu, 25 May 2023 17:10:54 GMT   (237kb,D)

Title: Hierarchical forecasting for aggregated curves with an application to
 day-ahead electricity price auctions
Authors: Paul Ghelasi, Florian Ziel
Categories: stat.AP cs.LG econ.EM q-fin.TR stat.ML
Comments: 34 pages, 6 figures. International Journal of Forecasting (2022)
DOI: 10.1016/j.ijforecast.2022.11.004
\\
 Aggregated curves are common structures in economics and finance, and the
most prominent examples are supply and demand curves. In this study, we exploit
the fact that all aggregated curves have an intrinsic hierarchical structure,
and thus hierarchical reconciliation methods can be used to improve the
forecast accuracy. We provide an in-depth theory on how aggregated curves can
be constructed or deconstructed, and conclude that these methods are equivalent
under weak assumptions. We consider multiple reconciliation methods for
aggregated curves, including previously established bottom-up, top-down, and
linear optimal reconciliation approaches. We also present a new benchmark
reconciliation method called 'aggregated-down' with similar complexity to
bottom-up and top-down approaches, but it tends to provide better accuracy in
this setup. We conducted an empirical forecasting study on the German day-ahead
power auction market by predicting the demand and supply curves, where their
equilibrium determines the electricity price for the next day. Our results
demonstrate that hierarchical reconciliation methods can be used to improve the
forecasting accuracy of aggregated curves.
\\ ( https://arxiv.org/abs/2305.16255 ,  237kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05445 (*cross-listing*)
Date: Thu, 8 Jun 2023 17:12:08 GMT   (10952kb,D)

Title: Towards Predicting Equilibrium Distributions for Molecular Systems with
 Deep Learning
Authors: Shuxin Zheng, Jiyan He, Chang Liu, Yu Shi, Ziheng Lu, Weitao Feng,
 Fusong Ju, Jiaxi Wang, Jianwei Zhu, Yaosen Min, He Zhang, Shidi Tang, Hongxia
 Hao, Peiran Jin, Chi Chen, Frank No\'e, Haiguang Liu, Tie-Yan Liu
Categories: physics.chem-ph cs.LG q-bio.BM
Comments: 80 pages, 11 figures
\\
 Advances in deep learning have greatly improved structure prediction of
molecules. However, many macroscopic observations that are important for
real-world applications are not functions of a single molecular structure, but
rather determined from the equilibrium distribution of structures. Traditional
methods for obtaining these distributions, such as molecular dynamics
simulation, are computationally expensive and often intractable. In this paper,
we introduce a novel deep learning framework, called Distributional Graphormer
(DiG), in an attempt to predict the equilibrium distribution of molecular
systems. Inspired by the annealing process in thermodynamics, DiG employs deep
neural networks to transform a simple distribution towards the equilibrium
distribution, conditioned on a descriptor of a molecular system, such as a
chemical graph or a protein sequence. This framework enables efficient
generation of diverse conformations and provides estimations of state
densities. We demonstrate the performance of DiG on several molecular tasks,
including protein conformation sampling, ligand structure sampling,
catalyst-adsorbate sampling, and property-guided structure generation. DiG
presents a significant advancement in methodology for statistically
understanding molecular systems, opening up new research opportunities in
molecular science.
\\ ( https://arxiv.org/abs/2306.05445 ,  10952kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05484 (*cross-listing*)
Date: Thu, 8 Jun 2023 18:10:37 GMT   (444kb,D)

Title: Task-specific experimental design for treatment effect estimation
Authors: Bethany Connolly, Kim Moore, Tobias Schwedes, Alexander Adam, Gary
 Willis, Ilya Feige, Christopher Frye
Categories: stat.ME cs.LG stat.ML
Comments: To appear in ICML 2023; 8 pages, 7 figures, 4 appendices
\\
 Understanding causality should be a core requirement of any attempt to build
real impact through AI. Due to the inherent unobservability of counterfactuals,
large randomised trials (RCTs) are the standard for causal inference. But large
experiments are generically expensive, and randomisation carries its own costs,
e.g. when suboptimal decisions are trialed. Recent work has proposed more
sample-efficient alternatives to RCTs, but these are not adaptable to the
downstream application for which the causal effect is sought. In this work, we
develop a task-specific approach to experimental design and derive sampling
strategies customised to particular downstream applications. Across a range of
important tasks, real-world datasets, and sample sizes, our method outperforms
other benchmarks, e.g. requiring an order-of-magnitude less data to match RCT
performance on targeted marketing tasks.
\\ ( https://arxiv.org/abs/2306.05484 ,  444kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05494 (*cross-listing*)
Date: Thu, 8 Jun 2023 18:32:08 GMT   (1921kb,D)

Title: Adversarial Evasion Attacks Practicality in Networks: Testing the Impact
 of Dynamic Learning
Authors: Mohamed el Shehaby and Ashraf Matrawy
Categories: cs.CR cs.LG cs.NI
\\
 Machine Learning (ML) has become ubiquitous, and its deployment in Network
Intrusion Detection Systems (NIDS) is inevitable due to its automated nature
and high accuracy in processing and classifying large volumes of data. However,
ML has been found to have several flaws, on top of them are adversarial
attacks, which aim to trick ML models into producing faulty predictions. While
most adversarial attack research focuses on computer vision datasets, recent
studies have explored the practicality of such attacks against ML-based network
security entities, especially NIDS.
 This paper presents two distinct contributions: a taxonomy of practicality
issues associated with adversarial attacks against ML-based NIDS and an
investigation of the impact of continuous training on adversarial attacks
against NIDS. Our experiments indicate that continuous re-training, even
without adversarial training, can reduce the effect of adversarial attacks.
While adversarial attacks can harm ML-based NIDSs, our aim is to highlight that
there is a significant gap between research and real-world practicality in this
domain which requires attention.
\\ ( https://arxiv.org/abs/2306.05494 ,  1921kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05524 (*cross-listing*)
Date: Wed, 7 Jun 2023 12:33:24 GMT   (9867kb,D)

Title: Check Me If You Can: Detecting ChatGPT-Generated Academic Writing using
 CheckGPT
Authors: Zeyan Liu, Zijun Yao, Fengjun Li, Bo Luo
Categories: cs.CL cs.CR cs.LG
\\
 With ChatGPT under the spotlight, utilizing large language models (LLMs) for
academic writing has drawn a significant amount of discussions and concerns in
the community. While substantial research efforts have been stimulated for
detecting LLM-Generated Content (LLM-content), most of the attempts are still
in the early stage of exploration. In this paper, we present a holistic
investigation of detecting LLM-generate academic writing, by providing a
dataset, evidence, and algorithms, in order to inspire more community effort to
address the concern of LLM academic misuse. We first present GPABenchmark, a
benchmarking dataset of 600,000 samples of human-written, GPT-written,
GPT-completed, and GPT-polished abstracts of research papers in CS, physics,
and humanities and social sciences (HSS). We show that existing open-source and
commercial GPT detectors provide unsatisfactory performance on GPABenchmark,
especially for GPT-polished text. Moreover, through a user study of 150+
participants, we show that it is highly challenging for human users, including
experienced faculty members and researchers, to identify GPT-generated
abstracts. We then present CheckGPT, a novel LLM-content detector consisting of
a general representation module and an attentive-BiLSTM classification module,
which is accurate, transferable, and interpretable. Experimental results show
that CheckGPT achieves an average classification accuracy of 98% to 99% for the
task-specific discipline-specific detectors and the unified detectors. CheckGPT
is also highly transferable that, without tuning, it achieves ~90% accuracy in
new domains, such as news articles, while a model tuned with approximately
2,000 samples in the target domain achieves ~98% accuracy. Finally, we
demonstrate the explainability insights obtained from CheckGPT to reveal the
key behaviors of how LLM generates texts.
\\ ( https://arxiv.org/abs/2306.05524 ,  9867kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05528 (*cross-listing*)
Date: Thu, 8 Jun 2023 19:56:32 GMT   (7704kb,D)

Title: A brief review of contrastive learning applied to astrophysics
Authors: Marc Huertas-Company, Regina Sarmiento, Johan Knapen
Categories: astro-ph.IM cs.LG
Comments: Invited review to be published in RASTI
\\
 Reliable tools to extract patterns from high-dimensionality spaces are
becoming more necessary as astronomical datasets increase both in volume and
complexity. Contrastive Learning is a self-supervised machine learning
algorithm that extracts informative measurements from multi-dimensional
datasets, which has become increasingly popular in the computer vision and
Machine Learning communities in recent years. To do so, it maximizes the
agreement between the information extracted from augmented versions of the same
input data, making the final representation invariant to the applied
transformations. Contrastive Learning is particularly useful in astronomy for
removing known instrumental effects and for performing supervised
classifications and regressions with a limited amount of available labels,
showing a promising avenue towards \emph{Foundation Models}. This short review
paper briefly summarizes the main concepts behind contrastive learning and
reviews the first promising applications to astronomy. We include some
practical recommendations on which applications are particularly attractive for
contrastive learning.
\\ ( https://arxiv.org/abs/2306.05528 ,  7704kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05545 (*cross-listing*)
Date: Thu, 8 Jun 2023 20:31:14 GMT   (824kb,D)

Title: AI Enhanced Control Engineering Methods
Authors: Ion Matei, Raj Minhas, Johan de Kleer and Alexander Felman
Categories: math.OC cs.LG
\\
 AI and machine learning based approaches are becoming ubiquitous in almost
all engineering fields. Control engineering cannot escape this trend. In this
paper, we explore how AI tools can be useful in control applications. The core
tool we focus on is automatic differentiation. Two immediate applications are
linearization of system dynamics for local stability analysis or for state
estimation using Kalman filters. We also explore other usages such as
conversion of differential algebraic equations to ordinary differential
equations for control design. In addition, we explore the use of machine
learning models for global parameterizations of state vectors and control
inputs in model predictive control applications. For each considered use case,
we give examples and results.
\\ ( https://arxiv.org/abs/2306.05545 ,  824kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05556 (*cross-listing*)
Date: Thu, 8 Jun 2023 20:59:40 GMT   (7548kb,D)

Title: Emotion and Sentiment Guided Paraphrasing
Authors: Justin J. Xie and Ameeta Agrawal
Categories: cs.CL cs.LG
Comments: 13th Workshop on Computational Approaches to Subjectivity, Sentiment
 & Social Media Analysis (WASSA) 2023 at The 61st Annual Meeting of the
 Association for Computational Linguistics (ACL) 2023. arXiv admin note:
 substantial text overlap with arXiv:2212.03297
\\
 Paraphrase generation, a.k.a. paraphrasing, is a common and important task in
natural language processing. Emotional paraphrasing, which changes the emotion
embodied in a piece of text while preserving its meaning, has many potential
applications, including moderating online dialogues and preventing
cyberbullying. We introduce a new task of fine-grained emotional paraphrasing
along emotion gradients, that is, altering the emotional intensities of the
paraphrases in fine-grained settings following smooth variations in affective
dimensions while preserving the meaning of the original text. We reconstruct
several widely used paraphrasing datasets by augmenting the input and target
texts with their fine-grained emotion labels. Then, we propose a framework for
emotion and sentiment guided paraphrasing by leveraging pre-trained language
models for conditioned text generation. Extensive evaluation of the fine-tuned
models suggests that including fine-grained emotion labels in the paraphrase
task significantly improves the likelihood of obtaining high-quality
paraphrases that reflect the desired emotions while achieving consistently
better scores in paraphrase metrics such as BLEU, ROUGE, and METEOR.
\\ ( https://arxiv.org/abs/2306.05556 ,  7548kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05557 (*cross-listing*)
Date: Thu, 8 Jun 2023 21:01:24 GMT   (1251kb,D)

Title: On Performance Discrepancies Across Local Homophily Levels in Graph
 Neural Networks
Authors: Donald Loveland, Jiong Zhu, Mark Heimann, Benjamin Fish, Michael T.
 Shaub, Danai Koutra
Categories: cs.SI cs.LG
\\
 Research on GNNs has highlighted a relationship between high homophily (i.e.,
the tendency for nodes of a similar class to connect) and strong predictive
performance in node classification. However, recent research has found the
relationship to be more nuanced, demonstrating that even simple GNNs can learn
in certain heterophilous settings. To bridge the gap between these findings, we
revisit the assumptions made in previous works and identify that datasets are
often treated as having a constant homophily level across nodes. To align
closer to real-world datasets, we theoretically and empirically study the
performance of GNNs when the local homophily level of a node deviates at
test-time from the global homophily level of its graph. To aid our theoretical
analysis, we introduce a new parameter to the preferential attachment model
commonly used in homophily analysis to enable the control of local homophily
levels in generated graphs, enabling a systematic empirical study on how local
homophily can impact performance. We additionally perform a granular analysis
on a number of real-world datasets with varying global homophily levels. Across
our theoretical and empirical results, we find that (a)~ GNNs can fail to
generalize to test nodes that deviate from the global homophily of a graph,
(b)~ high local homophily does not necessarily confer high performance for a
node, and (c)~ GNN models designed to handle heterophily are able to perform
better across varying heterophily ranges irrespective of the dataset's global
homophily. These findings point towards a GNN's over-reliance on the global
homophily used for training and motivates the need to design GNNs that can
better generalize across large local homophily ranges.
\\ ( https://arxiv.org/abs/2306.05557 ,  1251kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05566 (*cross-listing*)
Date: Thu, 8 Jun 2023 21:18:25 GMT   (708kb,D)

Title: Data-Adaptive Probabilistic Likelihood Approximation for Ordinary
 Differential Equations
Authors: Mohan Wu and Martin Lysy
Categories: stat.ML cs.LG
Comments: 9 pages, 5 figures, under review for neurips 2023
\\
 Parameter inference for ordinary differential equations (ODEs) is of
fundamental importance in many scientific applications. While ODE solutions are
typically approximated by deterministic algorithms, new research on
probabilistic solvers indicates that they produce more reliable parameter
estimates by better accounting for numerical errors. However, many ODE systems
are highly sensitive to their parameter values. This produces deep local minima
in the likelihood function -- a problem which existing probabilistic solvers
have yet to resolve. Here, we show that a Bayesian filtering paradigm for
probabilistic ODE solution can dramatically reduce sensitivity to parameters by
learning from the noisy ODE observations in a data-adaptive manner. Our method
is applicable to ODEs with partially unobserved components and with arbitrary
non-Gaussian noise. Several examples demonstrate that it is more accurate than
existing probabilistic ODE solvers, and even in some cases than the exact ODE
likelihood.
\\ ( https://arxiv.org/abs/2306.05566 ,  708kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05622 (*cross-listing*)
Date: Fri, 9 Jun 2023 01:53:56 GMT   (1669kb,D)

Title: Improving Quantum Circuit Synthesis with Machine Learning
Authors: Mathias Weiden, Ed Younis, Justin Kalloor, John Kubiatowicz, and
 Costin Iancu
Categories: quant-ph cs.LG
Comments: 11 pages, 10 figures
\\
 In the Noisy Intermediate Scale Quantum (NISQ) era, finding implementations
of quantum algorithms that minimize the number of expensive and error prone
multi-qubit gates is vital to ensure computations produce meaningful outputs.
Unitary synthesis, the process of finding a quantum circuit that implements
some target unitary matrix, is able to solve this problem optimally in many
cases. However, current bottom-up unitary synthesis algorithms are limited by
their exponentially growing run times. We show how applying machine learning to
unitary datasets permits drastic speedups for synthesis algorithms. This paper
presents QSeed, a seeded synthesis algorithm that employs a learned model to
quickly propose resource efficient circuit implementations of unitaries. QSeed
maintains low gate counts and offers a speedup of $3.7\times$ in synthesis time
over the state of the art for a 64 qubit modular exponentiation circuit, a core
component in Shor's factoring algorithm. QSeed's performance improvements also
generalize to families of circuits not seen during the training process.
\\ ( https://arxiv.org/abs/2306.05622 ,  1669kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05649 (*cross-listing*)
Date: Fri, 9 Jun 2023 03:35:33 GMT   (512kb,D)

Title: Specifying and Solving Robust Empirical Risk Minimization Problems Using
 CVXPY
Authors: Eric Luxenberg and Dhruv Malik and Yuanzhi Li and Aarti Singh and
 Stephen Boyd
Categories: math.OC cs.LG
\\
 We consider robust empirical risk minimization (ERM), where model parameters
are chosen to minimize the worst-case empirical loss when each data point
varies over a given convex uncertainty set. In some simple cases, such problems
can be expressed in an analytical form. In general the problem can be made
tractable via dualization, which turns a min-max problem into a min-min
problem. Dualization requires expertise and is tedious and error-prone. We
demonstrate how CVXPY can be used to automate this dualization procedure in a
user-friendly manner. Our framework allows practitioners to specify and solve
robust ERM problems with a general class of convex losses, capturing many
standard regression and classification problems. Users can easily specify any
complex uncertainty set that is representable via disciplined convex
programming (DCP) constraints.
\\ ( https://arxiv.org/abs/2306.05649 ,  512kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05666 (*cross-listing*)
Date: Fri, 9 Jun 2023 04:40:38 GMT   (27327kb,D)

Title: QuestEnvSim: Environment-Aware Simulated Motion Tracking from Sparse
 Sensors
Authors: Sunmin Lee, Sebastian Starke, Yuting Ye, Jungdam Won, and Alexander
 Winkler
Categories: cs.GR cs.LG cs.RO
ACM-class: I.3.6
Journal-ref: SIGGRAPH 23 Conference Proceedings, August 6-10, 2023, Los
 Angeles, CA, USA
DOI: 10.1145/3588432.3591504
\\
 Replicating a user's pose from only wearable sensors is important for many
AR/VR applications. Most existing methods for motion tracking avoid environment
interaction apart from foot-floor contact due to their complex dynamics and
hard constraints. However, in daily life people regularly interact with their
environment, e.g. by sitting on a couch or leaning on a desk. Using
Reinforcement Learning, we show that headset and controller pose, if combined
with physics simulation and environment observations can generate realistic
full-body poses even in highly constrained environments. The physics simulation
automatically enforces the various constraints necessary for realistic poses,
instead of manually specifying them as in many kinematic approaches. These hard
constraints allow us to achieve high-quality interaction motions without
typical artifacts such as penetration or contact sliding. We discuss three
features, the environment representation, the contact reward and scene
randomization, crucial to the performance of the method. We demonstrate the
generality of the approach through various examples, such as sitting on chairs,
a couch and boxes, stepping over boxes, rocking a chair and turning an office
chair. We believe these are some of the highest-quality results achieved for
motion tracking from sparse sensor with scene interaction.
\\ ( https://arxiv.org/abs/2306.05666 ,  27327kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05674 (*cross-listing*)
Date: Fri, 9 Jun 2023 05:15:53 GMT   (175kb,D)

Title: Efficient Uncertainty Quantification and Reduction for
 Over-Parameterized Neural Networks
Authors: Ziyi Huang, Henry Lam, Haofeng Zhang
Categories: stat.ML cs.LG
\\
 Uncertainty quantification (UQ) is important for reliability assessment and
enhancement of machine learning models. In deep learning, uncertainties arise
not only from data, but also from the training procedure that often injects
substantial noises and biases. These hinder the attainment of statistical
guarantees and, moreover, impose computational challenges on UQ due to the need
for repeated network retraining. Building upon the recent neural tangent kernel
theory, we create statistically guaranteed schemes to principally
\emph{quantify}, and \emph{remove}, the procedural uncertainty of
over-parameterized neural networks with very low computation effort. In
particular, our approach, based on what we call a procedural-noise-correcting
(PNC) predictor, removes the procedural uncertainty by using only \emph{one}
auxiliary network that is trained on a suitably labeled data set, instead of
many retrained networks employed in deep ensembles. Moreover, by combining our
PNC predictor with suitable light-computation resampling methods, we build
several approaches to construct asymptotically exact-coverage confidence
intervals using as low as four trained networks without additional overheads.
\\ ( https://arxiv.org/abs/2306.05674 ,  175kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05680 (*cross-listing*)
Date: Fri, 9 Jun 2023 05:43:06 GMT   (701kb,D)

Title: Emotion Detection from EEG using Transfer Learning
Authors: Sidharth Sidharth, Ashish Abraham Samuel, Ranjana H, Jerrin Thomas
 Panachakel, Sana Parveen K
Categories: eess.SP cs.LG
Comments: Preprint of the manuscript accepted for presentation in 45th Annual
 International Conference of the IEEE Engineering in Medicine and Biology
 Society. DOI will be updated soon
\\
 The detection of emotions using an Electroencephalogram (EEG) is a crucial
area in brain-computer interfaces and has valuable applications in fields such
as rehabilitation and medicine. In this study, we employed transfer learning to
overcome the challenge of limited data availability in EEG-based emotion
detection. The base model used in this study was Resnet50. Additionally, we
employed a novel feature combination in EEG-based emotion detection. The input
to the model was in the form of an image matrix, which comprised Mean Phase
Coherence (MPC) and Magnitude Squared Coherence (MSC) in the upper-triangular
and lower-triangular matrices, respectively. We further improved the technique
by incorporating features obtained from the Differential Entropy (DE) into the
diagonal, which previously held little to no useful information for classifying
emotions. The dataset used in this study, SEED EEG (62 channel EEG), comprises
three classes (Positive, Neutral, and Negative). We calculated both
subject-independent and subject-dependent accuracy. The subject-dependent
accuracy was obtained using a 10-fold cross-validation method and was 93.1%,
while the subject-independent classification was performed by employing the
leave-one-subject-out (LOSO) strategy. The accuracy obtained in
subject-independent classification was 71.6%. Both of these accuracies are at
least twice better than the chance accuracy of classifying 3 classes. The study
found the use of MSC and MPC in EEG-based emotion detection promising for
emotion classification. The future scope of this work includes the use of data
augmentation techniques, enhanced classifiers, and better features for emotion
classification.
\\ ( https://arxiv.org/abs/2306.05680 ,  701kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05694 (*cross-listing*)
Date: Fri, 9 Jun 2023 06:30:25 GMT   (4841kb,D)

Title: Explainable Representation Learning of Small Quantum States
Authors: Felix Frohnert and Evert van Nieuwenburg
Categories: quant-ph cs.LG
\\
 Unsupervised machine learning models build an internal representation of
their training data without the need for explicit human guidance or feature
engineering. This learned representation provides insights into which features
of the data are relevant for the task at hand. In the context of quantum
physics, training models to describe quantum states without human intervention
offers a promising approach to gaining insight into how machines represent
complex quantum states. The ability to interpret the learned representation may
offer a new perspective on non-trivial features of quantum systems and their
efficient representation. We train a generative model on two-qubit density
matrices generated by a parameterized quantum circuit. In a series of
computational experiments, we investigate the learned representation of the
model and its internal understanding of the data. We observe that the model
learns an interpretable representation which relates the quantum states to
their underlying entanglement characteristics. In particular, our results
demonstrate that the latent representation of the model is directly correlated
with the entanglement measure concurrence. The insights from this study
represent proof of concept towards interpretable machine learning of quantum
states. Our approach offers insight into how machines learn to represent
small-scale quantum systems autonomously.
\\ ( https://arxiv.org/abs/2306.05694 ,  4841kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05698 (*cross-listing*)
Date: Fri, 9 Jun 2023 06:35:14 GMT   (848kb,D)

Title: JABBERWOCK: A Tool for WebAssembly Dataset Generation and Its
 Application to Malicious Website Detection
Authors: Chika Komiya and Naoto Yanai and Kyosuke Yamashita and Shingo Okamura
Categories: cs.CR cs.LG
Comments: Accepted in DCDS 2023 (co-located in DSN 2023)
\\
 Machine learning is often used for malicious website detection, but an
approach incorporating WebAssembly as a feature has not been explored due to a
limited number of samples, to the best of our knowledge. In this paper, we
propose JABBERWOCK (JAvascript-Based Binary EncodeR by WebAssembly Optimization
paCKer), a tool to generate WebAssembly datasets in a pseudo fashion via
JavaScript. Loosely speaking, JABBERWOCK automatically gathers JavaScript code
in the real world, convert them into WebAssembly, and then outputs vectors of
the WebAssembly as samples for malicious website detection. We also conduct
experimental evaluations of JABBERWOCK in terms of the processing time for
dataset generation, comparison of the generated samples with actual WebAssembly
samples gathered from the Internet, and an application for malicious website
detection. Regarding the processing time, we show that JABBERWOCK can construct
a dataset in 4.5 seconds per sample for any number of samples. Next, comparing
10,000 samples output by JABBERWOCK with 168 gathered WebAssembly samples, we
believe that the generated samples by JABBERWOCK are similar to those in the
real world. We then show that JABBERWOCK can provide malicious website
detection with 99\% F1-score because JABBERWOCK makes a gap between benign and
malicious samples as the reason for the above high score. We also confirm that
JABBERWOCK can be combined with an existing malicious website detection tool to
improve F1-scores. JABBERWOCK is publicly available via GitHub
(https://github.com/c-chocolate/Jabberwock).
\\ ( https://arxiv.org/abs/2306.05698 ,  848kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05708 (*cross-listing*)
Date: Fri, 9 Jun 2023 07:02:43 GMT   (990kb,D)

Title: Boosting Fast and High-Quality Speech Synthesis with Linear Diffusion
Authors: Haogeng Liu, Tao Wang, Jie Cao, Ran He, Jianhua Tao
Categories: cs.SD cs.LG eess.AS
\\
 Denoising Diffusion Probabilistic Models have shown extraordinary ability on
various generative tasks. However, their slow inference speed renders them
impractical in speech synthesis. This paper proposes a linear diffusion model
(LinDiff) based on an ordinary differential equation to simultaneously reach
fast inference and high sample quality. Firstly, we employ linear interpolation
between the target and noise to design a diffusion sequence for training, while
previously the diffusion path that links the noise and target is a curved
segment. When decreasing the number of sampling steps (i.e., the number of line
segments used to fit the path), the ease of fitting straight lines compared to
curves allows us to generate higher quality samples from a random noise with
fewer iterations. Secondly, to reduce computational complexity and achieve
effective global modeling of noisy speech, LinDiff employs a patch-based
processing approach that partitions the input signal into small patches. The
patch-wise token leverages Transformer architecture for effective modeling of
global information. Adversarial training is used to further improve the sample
quality with decreased sampling steps. We test proposed method with speech
synthesis conditioned on acoustic feature (Mel-spectrograms). Experimental
results verify that our model can synthesize high-quality speech even with only
one diffusion step. Both subjective and objective evaluations demonstrate that
our model can synthesize speech of a quality comparable to that of
autoregressive models with faster synthesis speed (3 diffusion steps).
\\ ( https://arxiv.org/abs/2306.05708 ,  990kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05724 (*cross-listing*)
Date: Fri, 9 Jun 2023 07:43:46 GMT   (4647kb,D)

Title: Explaining Predictive Uncertainty with Information Theoretic Shapley
 Values
Authors: David S. Watson, Joshua O'Hara, Niek Tax, Richard Mudd, and Ido Guy
Categories: stat.ML cs.LG
\\
 Researchers in explainable artificial intelligence have developed numerous
methods for helping users understand the predictions of complex supervised
learning models. By contrast, explaining the $\textit{uncertainty}$ of model
outputs has received relatively little attention. We adapt the popular Shapley
value framework to explain various types of predictive uncertainty, quantifying
each feature's contribution to the conditional entropy of individual model
outputs. We consider games with modified characteristic functions and find deep
connections between the resulting Shapley values and fundamental quantities
from information theory and conditional independence testing. We outline
inference procedures for finite sample error rate control with provable
guarantees, and implement an efficient algorithm that performs well in a range
of experiments on real and simulated data. Our method has applications to
covariate shift detection, active learning, feature selection, and active
feature-value acquisition.
\\ ( https://arxiv.org/abs/2306.05724 ,  4647kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05739 (*cross-listing*)
Date: Fri, 9 Jun 2023 08:13:06 GMT   (1799kb,D)

Title: Leaping through tree space: continuous phylogenetic inference for rooted
 and unrooted trees
Authors: Matthew J Penn, Neil Scheidwasser, Joseph Penn, Christl A Donnelly,
 David A Duch\^ene, and Samir Bhatt
Categories: q-bio.PE cs.LG
Comments: 13 pages, 4 figures, 14 supplementary pages, 2 supplementary figures
\\
 Phylogenetics is now fundamental in life sciences, providing insights into
the earliest branches of life and the origins and spread of epidemics. However,
finding suitable phylogenies from the vast space of possible trees remains
challenging. To address this problem, for the first time, we perform both tree
exploration and inference in a continuous space where the computation of
gradients is possible. This continuous relaxation allows for major leaps across
tree space in both rooted and unrooted trees, and is less susceptible to
convergence to local minima. Our approach outperforms the current best methods
for inference on unrooted trees and, in simulation, accurately infers the tree
and root in ultrametric cases. The approach is effective in cases of empirical
data with negligible amounts of data, which we demonstrate on the phylogeny of
jawed vertebrates. Indeed, only a few genes with an ultrametric signal were
generally sufficient for resolving the major lineages of vertebrate. With
cubic-time complexity and efficient optimisation via automatic differentiation,
our method presents an effective way forwards for exploring the most difficult,
data-deficient phylogenetic questions.
\\ ( https://arxiv.org/abs/2306.05739 ,  1799kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05776 (*cross-listing*)
Date: Fri, 9 Jun 2023 09:42:21 GMT   (4603kb,D)

Title: Weight Re-Mapping for Variational Quantum Algorithms
Authors: Michael K\"olle, Alessandro Giovagnoli, Jonas Stein, Maximilian
 Balthasar Mansky, Julian Hager, Tobias Rohe, Robert M\"uller and Claudia
 Linnhoff-Popien
Categories: quant-ph cs.LG
\\
 Inspired by the remarkable success of artificial neural networks across a
broad spectrum of AI tasks, variational quantum circuits (VQCs) have recently
seen an upsurge in quantum machine learning applications. The promising
outcomes shown by VQCs, such as improved generalization and reduced parameter
training requirements, are attributed to the robust algorithmic capabilities of
quantum computing. However, the current gradient-based training approaches for
VQCs do not adequately accommodate the fact that trainable parameters (or
weights) are typically used as angles in rotational gates. To address this, we
extend the concept of weight re-mapping for VQCs, as introduced by K\"olle et
al. (2023). This approach unambiguously maps the weights to an interval of
length $2\pi$, mirroring data rescaling techniques in conventional machine
learning that have proven to be highly beneficial in numerous scenarios. In our
study, we employ seven distinct weight re-mapping functions to assess their
impact on eight classification datasets, using variational classifiers as a
representative example. Our results indicate that weight re-mapping can enhance
the convergence speed of the VQC. We assess the efficacy of various re-mapping
functions across all datasets and measure their influence on the VQC's average
performance. Our findings indicate that weight re-mapping not only consistently
accelerates the convergence of VQCs, regardless of the specific re-mapping
function employed, but also significantly increases accuracy in certain cases.
\\ ( https://arxiv.org/abs/2306.05776 ,  4603kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05803 (*cross-listing*)
Date: Fri, 9 Jun 2023 10:40:22 GMT   (1177kb,D)

Title: Causality between Sentiment and Cryptocurrency Prices
Authors: Lubdhak Mondal, Udeshya Raj, Abinandhan S, Began Gowsik S, Sarwesh P
 and Abhijeet Chandra
Categories: q-fin.CP cs.CL cs.LG
ACM-class: I.2.7
\\
 This study investigates the relationship between narratives conveyed through
microblogging platforms, namely Twitter, and the value of crypto assets. Our
study provides a unique technique to build narratives about cryptocurrency by
combining topic modelling of short texts with sentiment analysis. First, we
used an unsupervised machine learning algorithm to discover the latent topics
within the massive and noisy textual data from Twitter, and then we revealed
4-5 cryptocurrency-related narratives, including financial investment,
technological advancement related to crypto, financial and political
regulations, crypto assets, and media coverage. In a number of situations, we
noticed a strong link between our narratives and crypto prices. Our work
connects the most recent innovation in economics, Narrative Economics, to a new
area of study that combines topic modelling and sentiment analysis to relate
consumer behaviour to narratives.
\\ ( https://arxiv.org/abs/2306.05803 ,  1177kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05808 (*cross-listing*)
Date: Fri, 9 Jun 2023 10:47:06 GMT   (339kb,D)

Title: RankFormer: Listwise Learning-to-Rank Using Listwide Labels
Authors: Maarten Buyl, Paul Missault and Pierre-Antoine Sondag
Categories: cs.IR cs.LG
Comments: Accepted at KDD 2023
DOI: 10.1145/3580305.3599892
\\
 Web applications where users are presented with a limited selection of items
have long employed ranking models to put the most relevant results first. Any
feedback received from users is typically assumed to reflect a relative
judgement on the utility of items, e.g. a user clicking on an item only implies
it is better than items not clicked in the same ranked list. Hence, the
objectives optimized in Learning-to-Rank (LTR) tend to be pairwise or listwise.
 Yet, by only viewing feedback as relative, we neglect the user's absolute
feedback on the list's overall quality, e.g. when no items in the selection are
clicked. We thus reconsider the standard LTR paradigm and argue the benefits of
learning from this listwide signal. To this end, we propose the RankFormer as
an architecture that, with a Transformer at its core, can jointly optimize a
novel listwide assessment objective and a traditional listwise LTR objective.
 We simulate implicit feedback on public datasets and observe that the
RankFormer succeeds in benefitting from listwide signals. Additionally, we
conduct experiments in e-commerce on Amazon Search data and find the RankFormer
to be superior to all baselines offline. An online experiment shows that
knowledge distillation can be used to find immediate practical use for the
RankFormer.
\\ ( https://arxiv.org/abs/2306.05808 ,  339kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05857 (*cross-listing*)
Date: Fri, 9 Jun 2023 12:39:41 GMT   (3042kb,D)

Title: How Sparse Can We Prune A Deep Network: A Geometric Viewpoint
Authors: Qiaozhe Zhang, Ruijie Zhang, Jun Sun, Yingzhuang Liu
Categories: stat.ML cs.LG
\\
 Overparameterization constitutes one of the most significant hallmarks of
deep neural networks. Though it can offer the advantage of outstanding
generalization performance, it meanwhile imposes substantial storage burden,
thus necessitating the study of network pruning. A natural and fundamental
question is: How sparse can we prune a deep network (with almost no hurt on the
performance)? To address this problem, in this work we take a first principles
approach, specifically, by merely enforcing the sparsity constraint on the
original loss function, we're able to characterize the sharp phase transition
point of pruning ratio, which corresponds to the boundary between the feasible
and the infeasible, from the perspective of high-dimensional geometry. It turns
out that the phase transition point of pruning ratio equals the squared
Gaussian width of some convex body resulting from the $l_1$-regularized loss
function, normalized by the original dimension of parameters. As a byproduct,
we provide a novel network pruning algorithm which is essentially a global
one-shot pruning one. Furthermore, we provide efficient countermeasures to
address the challenges in computing the involved Gaussian width, including the
spectrum estimation of a large-scale Hessian matrix and dealing with the
non-definite positiveness of a Hessian matrix. It is demonstrated that the
predicted pruning ratio threshold coincides very well with the actual value
obtained from the experiments and our proposed pruning algorithm can achieve
competitive or even better performance than the existing pruning algorithms.
All codes are available at:
https://github.com/QiaozheZhang/Global-One-shot-Pruning
\\ ( https://arxiv.org/abs/2306.05857 ,  3042kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05862 (*cross-listing*)
Date: Fri, 9 Jun 2023 12:53:24 GMT   (806kb,D)

Title: Federated Learning You May Communicate Less Often!
Authors: Milad Sefidgaran, Romain Chor, Abdellatif Zaidi, Yijun Wan
Categories: stat.ML cs.IT cs.LG math.IT
\\
 We investigate the generalization error of statistical learning models in a
Federated Learning (FL) setting. Specifically, we study the evolution of the
generalization error with the number of communication rounds between the
clients and the parameter server, i.e., the effect on the generalization error
of how often the local models as computed by the clients are aggregated at the
parameter server. We establish PAC-Bayes and rate-distortion theoretic bounds
on the generalization error that account explicitly for the effect of the
number of rounds, say $ R \in \mathbb{N}$, in addition to the number of
participating devices $K$ and individual datasets size $n$. The bounds, which
apply in their generality for a large class of loss functions and learning
algorithms, appear to be the first of their kind for the FL setting.
Furthermore, we apply our bounds to FL-type Support Vector Machines (FSVM); and
we derive (more) explicit bounds on the generalization error in this case. In
particular, we show that the generalization error of FSVM increases with $R$,
suggesting that more frequent communication with the parameter server
diminishes the generalization power of such learning algorithms. Combined with
that the empirical risk generally decreases for larger values of $R$, this
indicates that $R$ might be a parameter to optimize in order to minimize the
population risk of FL algorithms. Moreover, specialized to the case $R=1$
(sometimes referred to as "one-shot" FL or distributed learning) our bounds
suggest that the generalization error of the FL setting decreases faster than
that of centralized learning by a factor of $\mathcal{O}(\sqrt{\log(K)/K})$,
thereby generalizing recent findings in this direction to arbitrary loss
functions and algorithms. The results of this paper are also validated on some
experiments.
\\ ( https://arxiv.org/abs/2306.05862 ,  806kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05907 (*cross-listing*)
Date: Fri, 9 Jun 2023 14:02:53 GMT   (4544kb,D)

Title: 2DeteCT -- A large 2D expandable, trainable, experimental Computed
 Tomography dataset for machine learning
Authors: Maximilian B. Kiss, Sophia B. Coban, K. Joost Batenburg, Tristan van
 Leeuwen, Felix Lucka
Categories: eess.IV cs.LG
\\
 Recent research in computational imaging largely focuses on developing
machine learning (ML) techniques for image reconstruction, which requires
large-scale training datasets consisting of measurement data and ground-truth
images. However, suitable experimental datasets for X-ray Computed Tomography
(CT) are scarce, and methods are often developed and evaluated only on
simulated data. We fill this gap by providing the community with a versatile,
open 2D fan-beam CT dataset suitable for developing ML techniques for a range
of image reconstruction tasks. To acquire it, we designed a sophisticated,
semi-automatic scan procedure that utilizes a highly-flexible laboratory X-ray
CT setup. A diverse mix of samples with high natural variability in shape and
density was scanned slice-by-slice (5000 slices in total) with high angular and
spatial resolution and three different beam characteristics: A high-fidelity, a
low-dose and a beam-hardening-inflicted mode. In addition, 750
out-of-distribution slices were scanned with sample and beam variations to
accommodate robustness and segmentation tasks. We provide raw projection data,
reference reconstructions and segmentations based on an open-source data
processing pipeline.
\\ ( https://arxiv.org/abs/2306.05907 ,  4544kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05915 (*cross-listing*)
Date: Fri, 9 Jun 2023 14:11:07 GMT   (1117kb,D)

Title: Speaker Embeddings as Individuality Proxy for Voice Stress Detection
Authors: Zihan Wu, Neil Scheidwasser-Clow, Karl El Hajal, Milos Cernak
Categories: eess.AS cs.LG
Comments: 5 pages, 2 figures. Accepted at Interspeech 2023
\\
 Since the mental states of the speaker modulate speech, stress introduced by
cognitive or physical loads could be detected in the voice. The existing voice
stress detection benchmark has shown that the audio embeddings extracted from
the Hybrid BYOL-S self-supervised model perform well. However, the benchmark
only evaluates performance separately on each dataset, but does not evaluate
performance across the different types of stress and different languages.
Moreover, previous studies found strong individual differences in stress
susceptibility. This paper presents the design and development of voice stress
detection, trained on more than 100 speakers from 9 language groups and five
different types of stress. We address individual variabilities in voice stress
analysis by adding speaker embeddings to the hybrid BYOL-S features. The
proposed method significantly improves voice stress detection performance with
an input audio length of only 3-5 seconds.
\\ ( https://arxiv.org/abs/2306.05915 ,  1117kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05937 (*cross-listing*)
Date: Fri, 9 Jun 2023 14:56:06 GMT   (96kb)

Title: Robust Data-driven Prescriptiveness Optimization
Authors: Mehran Poursoltani, Erick Delage, Angelos Georghiou
Categories: math.OC cs.LG stat.ME
\\
 The abundance of data has led to the emergence of a variety of optimization
techniques that attempt to leverage available side information to provide more
anticipative decisions. The wide range of methods and contexts of application
have motivated the design of a universal unitless measure of performance known
as the coefficient of prescriptiveness. This coefficient was designed to
quantify both the quality of contextual decisions compared to a reference one
and the prescriptive power of side information. To identify policies that
maximize the former in a data-driven context, this paper introduces a
distributionally robust contextual optimization model where the coefficient of
prescriptiveness substitutes for the classical empirical risk minimization
objective. We present a bisection algorithm to solve this model, which relies
on solving a series of linear programs when the distributional ambiguity set
has an appropriate nested form and polyhedral structure. Studying a contextual
shortest path problem, we evaluate the robustness of the resulting policies
against alternative methods when the out-of-sample dataset is subject to
varying amounts of distribution shift.
\\ ( https://arxiv.org/abs/2306.05937 ,  96kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05987 (*cross-listing*)
Date: Fri, 9 Jun 2023 15:56:06 GMT   (6531kb,D)

Title: Agent market orders representation through a contrastive learning
 approach
Authors: Ruihua Ruan, Emmanuel Bacry, Jean-Fran\c{c}ois Muzy
Categories: q-fin.ST cs.LG stat.ML
\\
 Due to the access to the labeled orders on the CAC40 data from Euronext, we
are able to analyse agents' behaviours in the market based on their placed
orders. In this study, we construct a self-supervised learning model using
triplet loss to effectively learn the representation of agent market orders. By
acquiring this learned representation, various downstream tasks become
feasible. In this work, we utilise the K-means clustering algorithm on the
learned representation vectors of agent orders to identify distinct behaviour
types within each cluster.
\\ ( https://arxiv.org/abs/2306.05987 ,  6531kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06031 (*cross-listing*)
Date: Fri, 9 Jun 2023 16:52:00 GMT   (1214kb,D)

Title: FinGPT: Open-Source Financial Large Language Models
Authors: Hongyang Yang, Xiao-Yang Liu, Christina Dan Wang
Categories: q-fin.ST cs.CL cs.LG q-fin.TR
\\
 Large language models (LLMs) have shown the potential of revolutionizing
natural language processing tasks in diverse domains, sparking great interest
in finance. Accessing high-quality financial data is the first challenge for
financial LLMs (FinLLMs). While proprietary models like BloombergGPT have taken
advantage of their unique data accumulation, such privileged access calls for
an open-source alternative to democratize Internet-scale financial data.
 In this paper, we present an open-source large language model, FinGPT, for
the finance sector. Unlike proprietary models, FinGPT takes a data-centric
approach, providing researchers and practitioners with accessible and
transparent resources to develop their FinLLMs. We highlight the importance of
an automatic data curation pipeline and the lightweight low-rank adaptation
technique in building FinGPT. Furthermore, we showcase several potential
applications as stepping stones for users, such as robo-advising, algorithmic
trading, and low-code development. Through collaborative efforts within the
open-source AI4Finance community, FinGPT aims to stimulate innovation,
democratize FinLLMs, and unlock new opportunities in open finance. Two
associated code repos are \url{https://github.com/AI4Finance-Foundation/FinGPT}
and \url{https://github.com/AI4Finance-Foundation/FinNLP}
\\ ( https://arxiv.org/abs/2306.06031 ,  1214kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06040 (*cross-listing*)
Date: Fri, 9 Jun 2023 17:05:53 GMT   (1211kb,D)

Title: Reconstructing Human Expressiveness in Piano Performances with a
 Transformer Network
Authors: Jingjing Tang, Geraint Wiggins, George Fazekas
Categories: cs.SD cs.LG eess.AS
Comments: 12 pages, 5 figures, submitted to CMMR 2023
\\
 Capturing intricate and subtle variations in human expressiveness in music
performance using computational approaches is challenging. In this paper, we
propose a novel approach for reconstructing human expressiveness in piano
performance with a multi-layer bi-directional Transformer encoder. To address
the needs for large amounts of accurately captured and score-aligned
performance data in training neural networks, we use transcribed scores
obtained from an existing transcription model to train our model. We integrate
pianist identities to control the sampling process and explore the ability of
our system to model variations in expressiveness for different pianists. The
system is evaluated through statistical analysis of generated expressive
performances and a listening test. Overall, the results suggest that our method
achieves state-of-the-art in generating human-like piano performances from
transcribed scores, while fully and consistently reconstructing human
expressiveness poses further challenges.
\\ ( https://arxiv.org/abs/2306.06040 ,  1211kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06064 (*cross-listing*)
Date: Thu, 18 May 2023 13:59:02 GMT   (461kb,D)

Title: Neural Algorithmic Reasoning for Combinatorial Optimisation
Authors: Dobrik Georgiev and Danilo Numeroso and Davide Bacciu and Pietro Li\`o
Categories: cs.NE cs.LG
\\
 Solving NP-hard/complete combinatorial problems with neural networks is a
challenging research area that aims to surpass classical approximate
algorithms. The long-term objective is to outperform hand-designed heuristics
for NP-hard/complete problems by learning to generate superior solutions solely
from training data. The Travelling Salesman Problem (TSP) is a prominent
combinatorial optimisation problem often targeted by such approaches. However,
current neural-based methods for solving TSP often overlook the inherent
"algorithmic" nature of the problem. In contrast, heuristics designed for TSP
frequently leverage well-established algorithms, such as those for finding the
minimum spanning tree. In this paper, we propose leveraging recent advancements
in neural algorithmic reasoning to improve the learning of TSP problems.
Specifically, we suggest pre-training our neural model on relevant algorithms
before training it on TSP instances. Our results demonstrate that, using this
learning setup, we achieve superior performance compared to non-algorithmically
informed deep learning models.
\\ ( https://arxiv.org/abs/2306.06064 ,  461kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06079 (*cross-listing*)
Date: Tue, 6 Jun 2023 07:07:54 GMT   (7414kb,D)

Title: Deep Learning for Day Forecasts from Sparse Observations
Authors: Marcin Andrychowicz, Lasse Espeholt, Di Li, Samier Merchant, Alex
 Merose, Fred Zyda, Shreya Agrawal, Nal Kalchbrenner
Categories: physics.ao-ph cs.LG
\\
 Deep neural networks offer an alternative paradigm for modeling weather
conditions. The ability of neural models to make a prediction in less than a
second once the data is available and to do so with very high temporal and
spatial resolution, and the ability to learn directly from atmospheric
observations, are just some of these models' unique advantages. Neural models
trained using atmospheric observations, the highest fidelity and lowest latency
data, have to date achieved good performance only up to twelve hours of lead
time when compared with state-of-the-art probabilistic Numerical Weather
Prediction models and only for the sole variable of precipitation. In this
paper, we present MetNet-3 that extends significantly both the lead time range
and the variables that an observation based neural model can predict well.
MetNet-3 learns from both dense and sparse data sensors and makes predictions
up to 24 hours ahead for precipitation, wind, temperature and dew point.
MetNet-3 introduces a key densification technique that implicitly captures data
assimilation and produces spatially dense forecasts in spite of the network
training on extremely sparse targets. MetNet-3 has a high temporal and spatial
resolution of, respectively, up to 2 minutes and 1 km as well as a low
operational latency. We find that MetNet-3 is able to outperform the best
single- and multi-member NWPs such as HRRR and ENS over the CONUS region for up
to 24 hours ahead setting a new performance milestone for observation based
neural models.
\\ ( https://arxiv.org/abs/2306.06079 ,  7414kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06083 (*cross-listing*)
Date: Tue, 6 Jun 2023 21:13:08 GMT   (4180kb,D)

Title: Improving Fairness and Robustness in End-to-End Speech Recognition
 through unsupervised clustering
Authors: Irina-Elena Veliche, Pascale Fung
Categories: cs.SD cs.CL cs.LG eess.AS
Journal-ref: ICASSP 2023
\\
 The challenge of fairness arises when Automatic Speech Recognition (ASR)
systems do not perform equally well for all sub-groups of the population. In
the past few years there have been many improvements in overall speech
recognition quality, but without any particular focus on advancing Equality and
Equity for all user groups for whom systems do not perform well. ASR fairness
is therefore also a robustness issue. Meanwhile, data privacy also takes
priority in production systems. In this paper, we present a privacy preserving
approach to improve fairness and robustness of end-to-end ASR without using
metadata, zip codes, or even speaker or utterance embeddings directly in
training. We extract utterance level embeddings using a speaker ID model
trained on a public dataset, which we then use in an unsupervised fashion to
create acoustic clusters. We use cluster IDs instead of speaker utterance
embeddings as extra features during model training, which shows improvements
for all demographic groups and in particular for different accents.
\\ ( https://arxiv.org/abs/2306.06083 ,  4180kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06099 (*cross-listing*)
Date: Fri, 9 Jun 2023 17:59:16 GMT   (186kb,D)

Title: NuCLR: Nuclear Co-Learned Representations
Authors: Ouail Kitouni, Niklas Nolte, Sokratis Trifinopoulos, Subhash
 Kantamneni, Mike Williams
Categories: nucl-th cs.LG nucl-ex
Comments: 5 pages, 3 figures
\\
 We introduce Nuclear Co-Learned Representations (NuCLR), a deep learning
model that predicts various nuclear observables, including binding and decay
energies, and nuclear charge radii. The model is trained using a multi-task
approach with shared representations and obtains state-of-the-art performance,
achieving levels of precision that are crucial for understanding fundamental
phenomena in nuclear (astro)physics. We also report an intriguing finding that
the learned representation of NuCLR exhibits the prominent emergence of crucial
aspects of the nuclear shell model, namely the shell structure, including the
well-known magic numbers, and the Pauli Exclusion Principle. This suggests that
the model is capable of capturing the underlying physical principles and that
our approach has the potential to offer valuable insights into nuclear theory.
\\ ( https://arxiv.org/abs/2306.06099 ,  186kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05482 (*cross-listing*)
Date: Thu, 8 Jun 2023 18:06:31 GMT   (694kb,D)

Title: Data-Driven Near-Optimal Control of Nonlinear Systems Over Finite
 Horizon
Authors: Vasanth Reddy, Hoda Eldardiry and Almuatazbellah Boker
Categories: math.OC cs.SY eess.SY
\\
 We examine the problem of two-point boundary optimal control of nonlinear
systems over finite-horizon time periods with unknown model dynamics by
employing reinforcement learning. We use techniques from singular perturbation
theory to decompose the control problem over the finite horizon into two
sub-problems, each solved over an infinite horizon. In the process, we avoid
the need to solve the time-varying Hamilton-Jacobi-Bellman equation. Using a
policy iteration method, which is made feasible as a result of this
decomposition, it is now possible to learn the controller gains of both
sub-problems. The overall control is then formed by piecing together the
solutions to the two sub-problems. We show that the performance of the proposed
closed-loop system approaches that of the model-based optimal performance as
the time horizon gets long. Finally, we provide three simulation scenarios to
support the paper's claims.
\\ ( https://arxiv.org/abs/2306.05482 ,  694kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05629 (*cross-listing*)
Date: Fri, 9 Jun 2023 02:28:55 GMT   (405kb,D)

Title: R-PMAC: A Robust Preamble Based MAC Mechanism Applied in Industrial
 Internet of Things
Authors: Kai Song, Biqian Feng, Yongpeng Wu, Zhen Gao and Wenjun Zhang
Categories: cs.IT cs.SY eess.SY math.IT
Comments: This paper has been accepted by IEEE Internet of Things Journal
\\
 This paper proposes a novel media access control (MAC) mechanism, called the
robust preamble-based MAC mechanism (R-PMAC), which can be applied to power
line communication (PLC) networks in the context of the Industrial Internet of
Things (IIoT). Compared with other MAC mechanisms such as P-MAC and the MAC
layer of IEEE1901.1, R-PMAC has higher networking speed. Besides, it supports
whitelist authentication and functions properly in the presence of data frame
loss. Firstly, we outline three basic mechanisms of R-PMAC, containing precise
time difference calculation, preambles generation and short ID allocation.
Secondly, we elaborate its networking process of single layer and multiple
layers. Thirdly, we illustrate its robust mechanisms, including collision
handling and data retransmission. Moreover, a low-cost hardware platform is
established to measure the time of connecting hundreds of PLC nodes for the
R-PMAC, P-MAC, and IEEE1901.1 mechanisms in a real power line environment. The
experiment results show that R-PMAC outperforms the other mechanisms by
achieving a 50% reduction in networking time. These findings indicate that the
R-PMAC mechanism holds great potential for quickly and effectively building a
PLC network in actual industrial scenarios.
\\ ( https://arxiv.org/abs/2306.05629 ,  405kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05677 (*cross-listing*)
Date: Fri, 9 Jun 2023 05:25:54 GMT   (3986kb,D)

Title: A fast reduced order method for linear parabolic inverse source problems
Authors: Yuxuan Huang, Yangwen Zhang
Categories: math.NA cs.NA cs.SY eess.SY
Comments: This is a placeholder. Unfinished Section 4 and Section 6
\\
 In this paper, we propose a novel, computationally efficient reduced order
method to solve linear parabolic inverse source problems. Our approach provides
accurate numerical solutions without relying on specific training data. The
forward solution is constructed using a Krylov sequence, while the source term
is recovered via the conjugate gradient (CG) method. Under a weak regularity
assumption on the solution of the parabolic partial differential equations
(PDEs), we establish convergence of the forward solution and provide a rigorous
error estimate for our method. Numerical results demonstrate that our approach
offers substantial computational savings compared to the traditional finite
element method (FEM) and retains equivalent accuracy.
\\ ( https://arxiv.org/abs/2306.05677 ,  3986kb)
%%--%%--%%--%%--%%--%%--%%--%%--%%--%%--%%--%%--%%--%%--%%--%%--%%--%%--%%--%%
------------------------------------------------------------------------------
\\
arXiv:2212.08230
replaced with revised version Fri, 9 Jun 2023 03:22:52 GMT   (15480kb,D)

Title: An Energy-aware and Fault-tolerant Deep Reinforcement Learning based
 approach for Multi-agent Patrolling Problems
Authors: Chenhao Tong, Aaron Harwood, Maria A. Rodriguez, Richard O. Sinnott
Categories: cs.AI cs.LG cs.MA cs.RO
\\ ( https://arxiv.org/abs/2212.08230 ,  15480kb)
------------------------------------------------------------------------------
\\
arXiv:2301.11765
replaced with revised version Thu, 8 Jun 2023 23:11:50 GMT   (1978kb,D)

Title: ExplainableFold: Understanding AlphaFold Prediction with Explainable AI
Authors: Juntao Tan, Yongfeng Zhang
Categories: cs.AI cs.LG
Comments: This work has been accepted for presentation at the 29th ACM SIGKDD
 Conference on Knowledge Discovery and Data Mining (KDD 2023)
\\ ( https://arxiv.org/abs/2301.11765 ,  1978kb)
------------------------------------------------------------------------------
\\
arXiv:2303.04091
replaced with revised version Fri, 9 Jun 2023 12:52:24 GMT   (266kb,D)

Title: Visual Abstraction and Reasoning through Language
Authors: Giacomo Camposampiero, Loic Houmard, Benjamin Estermann, Jo\"el
 Mathys, Roger Wattenhofer
Categories: cs.AI cs.CL cs.LG
Comments: The first two authors have contributed equally to this work. Accepted
 as regular paper at CVPR 2023 Workshop and Challenges for New Frontiers in
 Visual Language Reasoning: Compositionality, Prompts and Causality (NFVLR)
\\ ( https://arxiv.org/abs/2303.04091 ,  266kb)
------------------------------------------------------------------------------
\\
arXiv:2303.15022
replaced with revised version Fri, 9 Jun 2023 16:20:36 GMT   (1129kb,D)

Title: Interactive Explanations by Conflict Resolution via Argumentative
 Exchanges
Authors: Antonio Rago, Hengzhi Li and Francesca Toni
Categories: cs.AI cs.MA
Comments: 14 pages, 2 figures
ACM-class: I.2.4
\\ ( https://arxiv.org/abs/2303.15022 ,  1129kb)
------------------------------------------------------------------------------
\\
arXiv:2305.13459
replaced with revised version Fri, 9 Jun 2023 11:00:15 GMT   (806kb,D)

Title: The First Proven Performance Guarantees for the Non-Dominated Sorting
 Genetic Algorithm II (NSGA-II) on a Combinatorial Optimization Problem
Authors: Sacha Cerf, Benjamin Doerr, Benjamin Hebras, Yakob Kahane, Simon
 Wietheger
Categories: cs.AI cs.DS cs.NE math.OC
Comments: Author-generated version of a paper appearing in the proceedings of
 IJCAI 2023, with appendix
\\ ( https://arxiv.org/abs/2305.13459 ,  806kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02910
replaced with revised version Fri, 9 Jun 2023 09:36:22 GMT   (454kb,D)

Title: Action-Evolution Petri Nets: a Framework for Modeling and Solving
 Dynamic Task Assignment Problems
Authors: Riccardo Lo Bianco, Remco Dijkman, Wim Nuijten, Willem van Jaarsveld
Categories: cs.AI
\\ ( https://arxiv.org/abs/2306.02910 ,  454kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03293
replaced with revised version Thu, 8 Jun 2023 22:00:43 GMT   (2467kb,D)

Title: Towards Fairness in Personalized Ads Using Impression Variance Aware
 Reinforcement Learning
Authors: Aditya Srinivas Timmaraju, Mehdi Mashayekhi, Mingliang Chen, Qi Zeng,
 Quintin Fettes, Wesley Cheung, Yihan Xiao, Manojkumar Rangasamy Kannadasan,
 Pushkar Tripathi, Sean Gahagan, Miranda Bogen, Rob Roudani
Categories: cs.AI cs.CY
Comments: 11 pages, 7 figure, KDD 2023
DOI: 10.1145/3580305.3599916
\\ ( https://arxiv.org/abs/2306.03293 ,  2467kb)
------------------------------------------------------------------------------
\\
arXiv:2103.15812
replaced with revised version Thu, 8 Jun 2023 21:43:08 GMT   (33601kb,D)

Title: LatentKeypointGAN: Controlling GANs via Latent Keypoints
Authors: Xingzhe He, Bastian Wandt, Helge Rhodin
Categories: cs.CV
Journal-ref: CRV 2023
\\ ( https://arxiv.org/abs/2103.15812 ,  33601kb)
------------------------------------------------------------------------------
\\
arXiv:2202.06268
replaced with revised version Fri, 9 Jun 2023 06:08:37 GMT   (12567kb,D)

Title: BViT: Broad Attention based Vision Transformer
Authors: Nannan Li, Yaran Chen, Weifan Li, Zixiang Ding, Dongbin Zhao
Categories: cs.CV
\\ ( https://arxiv.org/abs/2202.06268 ,  12567kb)
------------------------------------------------------------------------------
\\
arXiv:2206.08657
replaced with revised version Fri, 9 Jun 2023 12:36:33 GMT   (1387kb,D)

Title: BridgeTower: Building Bridges Between Encoders in Vision-Language
 Representation Learning
Authors: Xiao Xu, Chenfei Wu, Shachar Rosenman, Vasudev Lal, Wanxiang Che, Nan
 Duan
Categories: cs.CV cs.CL cs.LG
Comments: Accepted by AAAI 2023, Oral
\\ ( https://arxiv.org/abs/2206.08657 ,  1387kb)
------------------------------------------------------------------------------
\\
arXiv:2207.11081
replaced with revised version Fri, 9 Jun 2023 09:12:18 GMT   (3366kb,D)

Title: Emotion Separation and Recognition from a Facial Expression by
 Generating the Poker Face with Vision Transformers
Authors: Jia Li, Jiantao Nie, Dan Guo, Richang Hong, Meng Wang
Categories: cs.CV
Comments: 11 pages, 7 figures
\\ ( https://arxiv.org/abs/2207.11081 ,  3366kb)
------------------------------------------------------------------------------
\\
arXiv:2208.07365
replaced with revised version Fri, 9 Jun 2023 15:06:02 GMT   (5768kb,D)

Title: Unsupervised Video Domain Adaptation for Action Recognition: A
 Disentanglement Perspective
Authors: Pengfei Wei, Lingdong Kong, Xinghua Qu, Yi Ren, Zhiqiang Xu, Jing
 Jiang, Xiang Yin
Categories: cs.CV cs.AI cs.LG
Comments: 18 pages, 9 figures, 7 tables. Code at
 https://github.com/ldkong1205/TranSVAE
\\ ( https://arxiv.org/abs/2208.07365 ,  5768kb)
------------------------------------------------------------------------------
\\
arXiv:2210.02871
replaced with revised version Fri, 9 Jun 2023 08:57:07 GMT   (619kb,D)

Title: Self-Distillation for Further Pre-training of Transformers
Authors: Seanie Lee, Minki Kang, Juho Lee, Sung Ju Hwang, Kenji Kawaguchi
Categories: cs.CV cs.LG
Comments: ICLR 2023
\\ ( https://arxiv.org/abs/2210.02871 ,  619kb)
------------------------------------------------------------------------------
\\
arXiv:2210.12513
replaced with revised version Fri, 9 Jun 2023 04:06:39 GMT   (7022kb,D)

Title: Learning Point-Language Hierarchical Alignment for 3D Visual Grounding
Authors: Jiaming Chen, Weixin Luo, Ran Song, Xiaolin Wei, Lin Ma, Wei Zhang
Categories: cs.CV
Comments: Champion on ECCV 2022 ScanRefer Challenge
\\ ( https://arxiv.org/abs/2210.12513 ,  7022kb)
------------------------------------------------------------------------------
\\
arXiv:2211.03064
replaced with revised version Fri, 9 Jun 2023 08:32:06 GMT   (5499kb,D)

Title: ViT-CX: Causal Explanation of Vision Transformers
Authors: Weiyan Xie, Xiao-Hui Li, Caleb Chen Cao, Nevin L.Zhang
Categories: cs.CV cs.AI
Comments: IJCAI2023 Camera-ready
\\ ( https://arxiv.org/abs/2211.03064 ,  5499kb)
------------------------------------------------------------------------------
\\
arXiv:2212.05400
replaced with revised version Fri, 9 Jun 2023 01:20:27 GMT   (37676kb,D)

Title: How to Backdoor Diffusion Models?
Authors: Sheng-Yen Chou, Pin-Yu Chen, Tsung-Yi Ho
Categories: cs.CV cs.CR cs.LG
Comments: Accepted by CVPR 2023
\\ ( https://arxiv.org/abs/2212.05400 ,  37676kb)
------------------------------------------------------------------------------
\\
arXiv:2212.09948
replaced with revised version Fri, 9 Jun 2023 11:59:32 GMT   (26638kb,D)

Title: MM-3DScene: 3D Scene Understanding by Customizing Masked Modeling with
 Informative-Preserved Reconstruction and Self-Distilled Consistency
Authors: Mingye Xu, Mutian Xu, Tong He, Wanli Ouyang, Yali Wang, Xiaoguang Han,
 Yu Qiao
Categories: cs.CV
\\ ( https://arxiv.org/abs/2212.09948 ,  26638kb)
------------------------------------------------------------------------------
\\
arXiv:2302.10697
replaced with revised version Fri, 9 Jun 2023 01:30:00 GMT   (5471kb,D)

Title: A Visual Representation-guided Framework with Global Affinity for Weakly
 Supervised Salient Object Detection
Authors: Binwei Xu, Haoran Liang, Weihua Gong, Ronghua Liang, Peng Chen
Categories: cs.CV
DOI: 10.1109/TCSVT.2023.3284076
\\ ( https://arxiv.org/abs/2302.10697 ,  5471kb)
------------------------------------------------------------------------------
\\
arXiv:2303.05470
replaced with revised version Thu, 8 Jun 2023 18:00:46 GMT   (26698kb,D)

Title: Spawrious: A Benchmark for Fine Control of Spurious Correlation Biases
Authors: Aengus Lynch, Gb\`etondji J-S Dovonon, Jean Kaddour, Ricardo Silva
Categories: cs.CV cs.LG
\\ ( https://arxiv.org/abs/2303.05470 ,  26698kb)
------------------------------------------------------------------------------
\\
arXiv:2304.00501
replaced with revised version Fri, 9 Jun 2023 05:02:31 GMT   (5856kb,D)

Title: A Comprehensive Review of YOLO: From YOLOv1 and Beyond
Authors: Juan Terven and Diana Cordova-Esparza
Categories: cs.CV
Comments: 33 pages, 18 figures, 4 tables, submitted to ACM Computing Surveys.
 This version adds detailed diagrams for YOLOv6, YOLOv7, and PP-YOLOE
\\ ( https://arxiv.org/abs/2304.00501 ,  5856kb)
------------------------------------------------------------------------------
\\
arXiv:2305.07829
replaced with revised version Fri, 9 Jun 2023 09:27:33 GMT   (6682kb,D)

Title: No-Reference Point Cloud Quality Assessment via Weighted Patch Quality
 Prediction
Authors: Jun Cheng, Honglei Su, Jari Korhonen
Categories: cs.CV cs.LG eess.IV
Comments: 6 pages, 5 figures, Accepted by International Conference on Software
 Engineering and Knowledge Engineering(SEKE2023)
DOI: 10.18293/SEKE2023-185
\\ ( https://arxiv.org/abs/2305.07829 ,  6682kb)
------------------------------------------------------------------------------
\\
arXiv:2305.11403
replaced with revised version Fri, 9 Jun 2023 03:40:55 GMT   (3859kb,D)

Title: Efficient Mixed Transformer for Single Image Super-Resolution
Authors: Ling Zheng, Jinchen Zhu, Jinpeng Shi, Shizhuang Weng
Categories: cs.CV
Comments: Super-resolution, Long-range attention, Transformer, Locality
\\ ( https://arxiv.org/abs/2305.11403 ,  3859kb)
------------------------------------------------------------------------------
\\
arXiv:2305.13501
replaced with revised version Fri, 9 Jun 2023 14:02:00 GMT   (4028kb,D)

Title: LaDI-VTON: Latent Diffusion Textual-Inversion Enhanced Virtual Try-On
Authors: Davide Morelli, Alberto Baldrati, Giuseppe Cartella, Marcella Cornia,
 Marco Bertini, Rita Cucchiara
Categories: cs.CV cs.AI cs.MM
\\ ( https://arxiv.org/abs/2305.13501 ,  4028kb)
------------------------------------------------------------------------------
\\
arXiv:2305.15213
replaced with revised version Fri, 9 Jun 2023 14:23:12 GMT   (1009kb,D)

Title: GTNet: Graph Transformer Network for 3D Point Cloud Classification and
 Semantic Segmentation
Authors: Wei Zhou, Qian Wang, Weiwei Jin, Xinzhe Shi, Ying He
Categories: cs.CV
\\ ( https://arxiv.org/abs/2305.15213 ,  1009kb)
------------------------------------------------------------------------------
\\
arXiv:2305.16321
replaced with revised version Thu, 8 Jun 2023 21:34:12 GMT   (4307kb,D)

Title: Eclipse: Disambiguating Illumination and Materials using Unintended
 Shadows
Authors: Dor Verbin, Ben Mildenhall, Peter Hedman, Jonathan T. Barron, Todd
 Zickler, Pratul P. Srinivasan
Categories: cs.CV cs.GR
Comments: Project page: https://dorverbin.github.io/eclipse/
\\ ( https://arxiv.org/abs/2305.16321 ,  4307kb)
------------------------------------------------------------------------------
\\
arXiv:2305.17235
replaced with revised version Fri, 9 Jun 2023 16:11:21 GMT   (32103kb,D)

Title: COMCAT: Towards Efficient Compression and Customization of
 Attention-Based Vision Models
Authors: Jinqi Xiao, Miao Yin, Yu Gong, Xiao Zang, Jian Ren, Bo Yuan
Categories: cs.CV cs.AI
Comments: ICML 2023 Poster
\\ ( https://arxiv.org/abs/2305.17235 ,  32103kb)
------------------------------------------------------------------------------
\\
arXiv:2305.18326
replaced with revised version Fri, 9 Jun 2023 07:03:06 GMT   (1464kb,D)

Title: BigVideo: A Large-scale Video Subtitle Translation Dataset for
 Multimodal Machine Translation
Authors: Liyan Kang, Luyang Huang, Ningxin Peng, Peihao Zhu, Zewei Sun, Shanbo
 Cheng, Mingxuan Wang, Degen Huang and Jinsong Su
Categories: cs.CV cs.AI
Comments: Accepted to ACL 2023 Findings
\\ ( https://arxiv.org/abs/2305.18326 ,  1464kb)
------------------------------------------------------------------------------
\\
arXiv:2305.18721
replaced with revised version Fri, 9 Jun 2023 03:29:43 GMT   (8264kb,D)

Title: LayoutMask: Enhance Text-Layout Interaction in Multi-modal Pre-training
 for Document Understanding
Authors: Yi Tu, Ya Guo, Huan Chen, Jinyang Tang
Categories: cs.CV
Comments: Accepted by ACL 2023 main conference
\\ ( https://arxiv.org/abs/2305.18721 ,  8264kb)
------------------------------------------------------------------------------
\\
arXiv:2305.19590
replaced with revised version Fri, 9 Jun 2023 09:55:13 GMT   (32714kb,D)

Title: Neural Kernel Surface Reconstruction
Authors: Jiahui Huang, Zan Gojcic, Matan Atzmon, Or Litany, Sanja Fidler,
 Francis Williams
Categories: cs.CV
Comments: CVPR 2023
\\ ( https://arxiv.org/abs/2305.19590 ,  32714kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03514
replaced with revised version Fri, 9 Jun 2023 15:21:06 GMT   (452kb,D)

Title: Recognize Anything: A Strong Image Tagging Model
Authors: Youcai Zhang, Xinyu Huang, Jinyu Ma, Zhaoyang Li, Zhaochuan Luo,
 Yanchun Xie, Yuzhuo Qin, Tong Luo, Yaqian Li, Shilong Liu, Yandong Guo, Lei
 Zhang
Categories: cs.CV
Comments: Homepage: https://recognize-anything.github.io/
\\ ( https://arxiv.org/abs/2306.03514 ,  452kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04607
replaced with revised version Fri, 9 Jun 2023 09:51:36 GMT   (8978kb,D)

Title: Integrating Geometric Control into Text-to-Image Diffusion Models for
 High-Quality Detection Data Generation via Text Prompt
Authors: Kai Chen, Enze Xie, Zhe Chen, Lanqing Hong, Zhenguo Li, Dit-Yan Yeung
Categories: cs.CV cs.AI
\\ ( https://arxiv.org/abs/2306.04607 ,  8978kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04641
replaced with revised version Fri, 9 Jun 2023 02:46:34 GMT   (6663kb,D)

Title: Generalizable Low-Resource Activity Recognition with Diverse and
 Discriminative Representation Learning
Authors: Xin Qin, Jindong Wang, Shuo Ma, Wang Lu, Yongchun Zhu, Xing Xie,
 Yiqiang Chen
Categories: cs.CV cs.AI cs.LG
Comments: Accepted by SIGKDD 2023 Research track; 12 pages; Code is available
 at: https://github.com/microsoft/robustlearn
\\ ( https://arxiv.org/abs/2306.04641 ,  6663kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04699
replaced with revised version Fri, 9 Jun 2023 17:14:02 GMT   (16612kb,D)

Title: DiViNeT: 3D Reconstruction from Disparate Views via Neural Template
 Regularization
Authors: Aditya Vora, Akshay Gadi Patil, Hao Zhang
Categories: cs.CV
\\ ( https://arxiv.org/abs/2306.04699 ,  16612kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04865
replaced with revised version Fri, 9 Jun 2023 01:59:48 GMT   (18546kb,D)

Title: MyStyle++: A Controllable Personalized Generative Prior
Authors: Libing Zeng, Lele Chen, Yi Xu, Nima Kalantari
Categories: cs.CV
\\ ( https://arxiv.org/abs/2306.04865 ,  18546kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05272
replaced with revised version Fri, 9 Jun 2023 06:16:30 GMT   (34750kb,D)

Title: Image Clustering via the Principle of Rate Reduction in the Age of
 Pretrained Models
Authors: Tianzhe Chu, Shengbang Tong, Tianjiao Ding, Xili Dai, Benjamin David
 Haeffele, Ren\'e Vidal, Yi Ma
Categories: cs.CV cs.LG
Comments: 21 pages, 13 figures
\\ ( https://arxiv.org/abs/2306.05272 ,  34750kb)
------------------------------------------------------------------------------
\\
arXiv:2102.07929
replaced with revised version Thu, 8 Jun 2023 21:34:21 GMT   (339kb)

Title: Near-Optimal Algorithms for Private Online Learning in a Stochastic
 Environment
Authors: Bingshan Hu and Zhiming Huang and Nishant A. Mehta
Categories: cs.LG
Comments: 34 pages. For full-information setting: (i) corrected a mistake in
 proof of regret upper bound for FTNL (new bound is larger); (ii) added lower
 bound for full-information setting
\\ ( https://arxiv.org/abs/2102.07929 ,  339kb)
------------------------------------------------------------------------------
\\
arXiv:2110.08627
replaced with revised version Fri, 9 Jun 2023 05:14:58 GMT   (3501kb,D)

Title: Achieving the Pareto Frontier of Regret Minimization and Best Arm
 Identification in Multi-Armed Bandits
Authors: Zixin Zhong, Wang Chi Cheung, Vincent Y. F. Tan
Categories: cs.LG cs.AI cs.IT math.IT stat.ML
Comments: 43 pages, 10 figures
\\ ( https://arxiv.org/abs/2110.08627 ,  3501kb)
------------------------------------------------------------------------------
\\
arXiv:2202.04820
replaced with revised version Fri, 9 Jun 2023 16:20:37 GMT   (58kb)

Title: L0Learn: A Scalable Package for Sparse Learning using L0 Regularization
Authors: Hussein Hazimeh, Rahul Mazumder, Tim Nonet
Categories: cs.LG cs.MS stat.CO stat.ML
Comments: Accepted to JMLR (MLOSS)
\\ ( https://arxiv.org/abs/2202.04820 ,  58kb)
------------------------------------------------------------------------------
\\
arXiv:2206.01298
replaced with revised version Fri, 9 Jun 2023 15:43:27 GMT   (1567kb,D)

Title: A memory-efficient neural ODE framework based on high-level adjoint
 differentiation
Authors: Hong Zhang, Wenjun Zhao
Categories: cs.LG
\\ ( https://arxiv.org/abs/2206.01298 ,  1567kb)
------------------------------------------------------------------------------
\\
arXiv:2206.03569
replaced with revised version Fri, 9 Jun 2023 08:38:39 GMT   (1785kb,D)

Title: Overcoming the Long Horizon Barrier for Sample-Efficient Reinforcement
 Learning with Latent Low-Rank Structure
Authors: Tyler Sam, Yudong Chen, and Christina Lee Yu
Categories: cs.LG
\\ ( https://arxiv.org/abs/2206.03569 ,  1785kb)
------------------------------------------------------------------------------
\\
arXiv:2206.06602
replaced with revised version Fri, 9 Jun 2023 01:19:55 GMT   (4952kb,D)

Title: Deep Isolation Forest for Anomaly Detection
Authors: Hongzuo Xu and Guansong Pang and Yijie Wang and Yongjun Wang
Categories: cs.LG
Comments: Accepted by IEEE Transactions on Knowledge and Data Engineering
 (TKDE)
DOI: 10.1109/TKDE.2023.3270293
\\ ( https://arxiv.org/abs/2206.06602 ,  4952kb)
------------------------------------------------------------------------------
\\
arXiv:2206.09280
replaced with revised version Thu, 8 Jun 2023 23:11:48 GMT   (768kb,D)

Title: MetaGL: Evaluation-Free Selection of Graph Learning Models via
 Meta-Learning
Authors: Namyong Park, Ryan Rossi, Nesreen Ahmed, Christos Faloutsos
Categories: cs.LG cs.SI
Comments: ICLR 2023
\\ ( https://arxiv.org/abs/2206.09280 ,  768kb)
------------------------------------------------------------------------------
\\
arXiv:2206.13378
replaced with revised version Fri, 9 Jun 2023 14:22:16 GMT   (1443kb,D)

Title: Guillotine Regularization: Why removing layers is needed to improve
 generalization in Self-Supervised Learning
Authors: Florian Bordes, Randall Balestriero, Quentin Garrido, Adrien Bardes,
 Pascal Vincent
Categories: cs.LG
Comments: Accepted at TMLR 2023
\\ ( https://arxiv.org/abs/2206.13378 ,  1443kb)
------------------------------------------------------------------------------
\\
arXiv:2207.04396
replaced with revised version Fri, 9 Jun 2023 11:52:42 GMT   (7719kb,D)

Title: Graph Generative Model for Benchmarking Graph Neural Networks
Authors: Minji Yoon, Yue Wu, John Palowitch, Bryan Perozzi, Ruslan
 Salakhutdinov
Categories: cs.LG cs.AI cs.CR
\\ ( https://arxiv.org/abs/2207.04396 ,  7719kb)
------------------------------------------------------------------------------
\\
arXiv:2207.12497
replaced with revised version Fri, 9 Jun 2023 00:06:23 GMT   (176kb,D)

Title: Estimating and Controlling for Equalized Odds via Sensitive Attribute
 Predictors
Authors: Beepul Bharti, Paul Yi, Jeremias Sulam
Categories: cs.LG cs.CY
\\ ( https://arxiv.org/abs/2207.12497 ,  176kb)
------------------------------------------------------------------------------
\\
arXiv:2208.02484
replaced with revised version Fri, 9 Jun 2023 02:31:22 GMT   (3365kb,D)

Title: Customs Import Declaration Datasets
Authors: Chaeyoon Jeong and Sundong Kim and Jaewoo Park and Yeonsoo Choi
Categories: cs.LG cs.AI stat.OT
Comments: Datasets: https://github.com/Seondong/Customs-Declaration-Datasets
\\ ( https://arxiv.org/abs/2208.02484 ,  3365kb)
------------------------------------------------------------------------------
\\
arXiv:2209.10866
replaced with revised version Fri, 9 Jun 2023 07:07:51 GMT   (373kb,D)

Title: A One-shot Framework for Distributed Clustered Learning in Heterogeneous
 Environments
Authors: Aleksandar Armacki, Dragana Bajovic, Dusan Jakovetic, Soummya Kar
Categories: cs.LG
\\ ( https://arxiv.org/abs/2209.10866 ,  373kb)
------------------------------------------------------------------------------
\\
arXiv:2210.00471
replaced with revised version Fri, 9 Jun 2023 04:55:02 GMT   (1435kb,D)

Title: OCD: Learning to Overfit with Conditional Diffusion Models
Authors: Shahar Lutati and Lior Wolf
Categories: cs.LG
Comments: Accepted to ICML 2023 (Oral & Poster)
\\ ( https://arxiv.org/abs/2210.00471 ,  1435kb)
------------------------------------------------------------------------------
\\
arXiv:2210.06662
replaced with revised version Thu, 8 Jun 2023 23:30:26 GMT   (4565kb,D)

Title: Action Matching: Learning Stochastic Dynamics from Samples
Authors: Kirill Neklyudov, Rob Brekelmans, Daniel Severo, Alireza Makhzani
Categories: cs.LG
Comments: Published in ICML 2023
\\ ( https://arxiv.org/abs/2210.06662 ,  4565kb)
------------------------------------------------------------------------------
\\
arXiv:2210.17357
replaced with revised version Fri, 9 Jun 2023 17:11:26 GMT   (3405kb,D)

Title: L-GreCo: Layerwise-Adaptive Gradient Compression for Efficient and
 Accurate Deep Learning
Authors: Mohammadreza Alimohammadi, Ilia Markov, Elias Frantar, Dan Alistarh
Categories: cs.LG cs.DC
\\ ( https://arxiv.org/abs/2210.17357 ,  3405kb)
------------------------------------------------------------------------------
\\
arXiv:2211.06530
replaced with revised version Thu, 8 Jun 2023 19:59:03 GMT   (6687kb,D)

Title: Multi-Epoch Matrix Factorization Mechanisms for Private Machine Learning
Authors: Christopher A. Choquette-Choo, H. Brendan McMahan, Keith Rush, and
 Abhradeep Thakurta
Categories: cs.LG cs.CR cs.DS stat.ML
Comments: 9 pages main-text, 3 figures. 40 pages with 13 figures total
\\ ( https://arxiv.org/abs/2211.06530 ,  6687kb)
------------------------------------------------------------------------------
\\
arXiv:2211.15355
replaced with revised version Fri, 9 Jun 2023 17:03:15 GMT   (895kb,D)

Title: Causal Deep Reinforcement Learning Using Observational Data
Authors: Wenxuan Zhu, Chao Yu, Qiang Zhang
Categories: cs.LG stat.ML
\\ ( https://arxiv.org/abs/2211.15355 ,  895kb)
------------------------------------------------------------------------------
\\
arXiv:2212.02191
replaced with revised version Fri, 9 Jun 2023 11:13:54 GMT   (662kb,D)

Title: On the effectiveness of partial variance reduction in federated learning
 with heterogeneous data
Authors: Bo Li, Mikkel N. Schmidt, Tommy S. Alstr{\o}m, Sebastian U. Stich
Categories: cs.LG cs.DC
Comments: Accepted to CVPR 2023
\\ ( https://arxiv.org/abs/2212.02191 ,  662kb)
------------------------------------------------------------------------------
\\
arXiv:2301.04404
replaced with revised version Thu, 8 Jun 2023 19:32:26 GMT   (3511kb,D)

Title: A prediction and behavioural analysis of machine learning methods for
 modelling travel mode choice
Authors: Jos\'e \'Angel Mart\'in-Baos, Julio Alberto L\'opez-G\'omez, Luis
 Rodriguez-Benitez, Tim Hillel and Ricardo Garc\'ia-R\'odenas
Categories: cs.LG
Comments: 44 pages and 13 figures
\\ ( https://arxiv.org/abs/2301.04404 ,  3511kb)
------------------------------------------------------------------------------
\\
arXiv:2301.11181
replaced with revised version Fri, 9 Jun 2023 16:33:08 GMT   (9956kb,D)

Title: Deep Laplacian-based Options for Temporally-Extended Exploration
Authors: Martin Klissarov and Marlos C. Machado
Categories: cs.LG cs.AI
\\ ( https://arxiv.org/abs/2301.11181 ,  9956kb)
------------------------------------------------------------------------------
\\
arXiv:2301.11956
replaced with revised version Fri, 9 Jun 2023 04:46:39 GMT   (197kb,D)

Title: On the Connection Between MPNN and Graph Transformer
Authors: Chen Cai, Truong Son Hy, Rose Yu, Yusu Wang
Categories: cs.LG
\\ ( https://arxiv.org/abs/2301.11956 ,  197kb)
------------------------------------------------------------------------------
\\
arXiv:2302.01255
replaced with revised version Fri, 9 Jun 2023 16:05:12 GMT   (5558kb,D)

Title: adSformers: Personalization from Short-Term Sequences and Diversity of
 Representations in Etsy Ads
Authors: Alaa Awad, Denisa Roberts, Eden Dolev, Andrea Heyman, Zahra
 Ebrahimzadeh, Zoe Weil, Marcin Mejran, Vaibhav Malpani, Mahir Yavuz
Categories: cs.LG
\\ ( https://arxiv.org/abs/2302.01255 ,  5558kb)
------------------------------------------------------------------------------
\\
arXiv:2302.01851
replaced with revised version Fri, 9 Jun 2023 17:05:09 GMT   (10070kb,D)

Title: Unsupervised hierarchical clustering using the learning dynamics of RBMs
Authors: Aur\'elien Decelle, Lorenzo Rosset, Beatriz Seoane
Categories: cs.LG cond-mat.dis-nn cond-mat.stat-mech
Comments: Version accepted in Physical Review E
\\ ( https://arxiv.org/abs/2302.01851 ,  10070kb)
------------------------------------------------------------------------------
\\
arXiv:2302.03806
replaced with revised version Thu, 8 Jun 2023 18:00:24 GMT   (13140kb,D)

Title: SLaM: Student-Label Mixing for Distillation with Unlabeled Examples
Authors: Vasilis Kontonis, Fotis Iliopoulos, Khoa Trinh, Cenk Baykal, Gaurav
 Menghani, Erik Vee
Categories: cs.LG
\\ ( https://arxiv.org/abs/2302.03806 ,  13140kb)
------------------------------------------------------------------------------
\\
arXiv:2302.04083
replaced with revised version Fri, 9 Jun 2023 12:20:45 GMT   (4096kb,D)

Title: Improving the Model Consistency of Decentralized Federated Learning
Authors: Yifan Shi, Li Shen, Kang Wei, Yan Sun, Bo Yuan, Xueqian Wang, Dacheng
 Tao
Categories: cs.LG cs.DC math.OC
Comments: ICML2023
\\ ( https://arxiv.org/abs/2302.04083 ,  4096kb)
------------------------------------------------------------------------------
\\
arXiv:2302.04336
replaced with revised version Thu, 8 Jun 2023 21:10:33 GMT   (15200kb,D)

Title: Performative Recommendation: Diversifying Content via Strategic
 Incentives
Authors: Itay Eilat, Nir Rosenfeld
Categories: cs.LG
\\ ( https://arxiv.org/abs/2302.04336 ,  15200kb)
------------------------------------------------------------------------------
\\
arXiv:2302.04972
replaced with revised version Fri, 9 Jun 2023 04:49:55 GMT   (35kb)

Title: Differentially Private Optimization for Smooth Nonconvex ERM
Authors: Changyu Gao and Stephen J. Wright
Categories: cs.LG cs.CR math.OC stat.ML
\\ ( https://arxiv.org/abs/2302.04972 ,  35kb)
------------------------------------------------------------------------------
\\
arXiv:2302.06064
replaced with revised version Thu, 8 Jun 2023 23:18:42 GMT   (761kb,D)

Title: Provably Safe Reinforcement Learning with Step-wise Violation
 Constraints
Authors: Nuoya Xiong, Yihan Du, Longbo Huang
Categories: cs.LG
\\ ( https://arxiv.org/abs/2302.06064 ,  761kb)
------------------------------------------------------------------------------
\\
arXiv:2302.06280
replaced with revised version Fri, 9 Jun 2023 13:27:31 GMT   (4656kb,D)

Title: Causal Strategic Classification: A Tale of Two Shifts
Authors: Guy Horowitz, Nir Rosenfeld
Categories: cs.LG
\\ ( https://arxiv.org/abs/2302.06280 ,  4656kb)
------------------------------------------------------------------------------
\\
arXiv:2302.10911
replaced with revised version Fri, 9 Jun 2023 14:49:41 GMT   (2838kb,D)

Title: Revisiting Weighted Aggregation in Federated Learning with Neural
 Networks
Authors: Zexi Li, Tao Lin, Xinyi Shang, Chao Wu
Categories: cs.LG
Comments: Accepted by ICML 2023
\\ ( https://arxiv.org/abs/2302.10911 ,  2838kb)
------------------------------------------------------------------------------
\\
arXiv:2303.07160
replaced with revised version Fri, 9 Jun 2023 08:30:56 GMT   (79kb)

Title: Tighter Lower Bounds for Shuffling SGD: Random Permutations and Beyond
Authors: Jaeyoung Cha, Jaewook Lee, Chulhee Yun
Categories: cs.LG math.OC stat.ML
Comments: 58 pages
\\ ( https://arxiv.org/abs/2303.07160 ,  79kb)
------------------------------------------------------------------------------
\\
arXiv:2304.07896
replaced with revised version Fri, 9 Jun 2023 10:00:05 GMT   (72kb,D)

Title: Out-of-Variable Generalization for Discriminative Models
Authors: Siyuan Guo, Jonas Wildberger, Bernhard Sch\"olkopf
Categories: cs.LG cs.AI stat.ML
\\ ( https://arxiv.org/abs/2304.07896 ,  72kb)
------------------------------------------------------------------------------
\\
arXiv:2304.10613
replaced with revised version Fri, 9 Jun 2023 09:59:27 GMT   (1160kb,D)

Title: Debiasing Conditional Stochastic Optimization
Authors: Lie He and Shiva Prasad Kasiviswanathan
Categories: cs.LG stat.ML
\\ ( https://arxiv.org/abs/2304.10613 ,  1160kb)
------------------------------------------------------------------------------
\\
arXiv:2305.02252
replaced with revised version Thu, 8 Jun 2023 18:34:56 GMT   (31kb)

Title: An Adaptive Algorithm for Learning with Unknown Distribution Drift
Authors: Alessio Mazzetto, Eli Upfal
Categories: cs.LG
Comments: Fixed typos and references. Updated conclusion
\\ ( https://arxiv.org/abs/2305.02252 ,  31kb)
------------------------------------------------------------------------------
\\
arXiv:2305.02776
replaced with revised version Fri, 9 Jun 2023 07:33:29 GMT   (3536kb,D)

Title: Efficient Personalized Federated Learning via Sparse Model-Adaptation
Authors: Daoyuan Chen, Liuyi Yao, Dawei Gao, Bolin Ding, Yaliang Li
Categories: cs.LG
Comments: Accepted to ICML 2023
\\ ( https://arxiv.org/abs/2305.02776 ,  3536kb)
------------------------------------------------------------------------------
\\
arXiv:2305.04501
replaced with revised version Fri, 9 Jun 2023 08:57:49 GMT   (560kb,D)

Title: SEGA: Structural Entropy Guided Anchor View for Graph Contrastive
 Learning
Authors: Junran Wu, Xueyuan Chen, Bowen Shi, Shangzhe Li, Ke Xu
Categories: cs.LG cs.AI
Comments: ICML'23
\\ ( https://arxiv.org/abs/2305.04501 ,  560kb)
------------------------------------------------------------------------------
\\
arXiv:2305.09943
replaced with revised version Fri, 9 Jun 2023 01:36:18 GMT   (7278kb,D)

Title: Demonstration-free Autonomous Reinforcement Learning via Implicit and
 Bidirectional Curriculum
Authors: Jigang Kim, Daesol Cho, H. Jin Kim
Categories: cs.LG cs.AI cs.RO
Comments: ICML 2023, first two authors contributed equally
\\ ( https://arxiv.org/abs/2305.09943 ,  7278kb)
------------------------------------------------------------------------------
\\
arXiv:2305.15817
replaced with revised version Fri, 9 Jun 2023 07:58:13 GMT   (569kb,D)

Title: Sharpness-Aware Minimization Revisited: Weighted Sharpness as a
 Regularization Term
Authors: Yun Yue, Jiadi Jiang, Zhiling Ye, Ning Gao, Yongchao Liu, Ke Zhang
Categories: cs.LG
Comments: 10 pages. Accepted as a conference paper at KDD '23
\\ ( https://arxiv.org/abs/2305.15817 ,  569kb)
------------------------------------------------------------------------------
\\
arXiv:2305.16217
replaced with revised version Fri, 9 Jun 2023 07:48:49 GMT   (13014kb,D)

Title: Beyond Reward: Offline Preference-guided Policy Optimization
Authors: Yachen Kang, Diyuan Shi, Jinxin Liu, Li He, Donglin Wang
Categories: cs.LG
\\ ( https://arxiv.org/abs/2305.16217 ,  13014kb)
------------------------------------------------------------------------------
\\
arXiv:2305.17535
replaced with revised version Fri, 9 Jun 2023 13:09:16 GMT   (11408kb,D)

Title: PFNs4BO: In-Context Learning for Bayesian Optimization
Authors: Samuel M\"uller, Matthias Feurer, Noah Hollmann, Frank Hutter
Categories: cs.LG stat.ML
Comments: Accepted at ICML 2023
\\ ( https://arxiv.org/abs/2305.17535 ,  11408kb)
------------------------------------------------------------------------------
\\
arXiv:2305.18777
replaced with revised version Thu, 8 Jun 2023 21:02:20 GMT   (4687kb,D)

Title: Adaptive Conditional Quantile Neural Processes
Authors: Peiman Mohseni, Nick Duffield, Bani Mallick, Arman Hasanzadeh
Categories: cs.LG stat.ML
\\ ( https://arxiv.org/abs/2305.18777 ,  4687kb)
------------------------------------------------------------------------------
\\
arXiv:2305.19452
replaced with revised version Fri, 9 Jun 2023 05:17:43 GMT   (750kb,D)

Title: Bigger, Better, Faster: Human-level Atari with human-level efficiency
Authors: Max Schwarzer, Johan Obando-Ceron, Aaron Courville, Marc Bellemare,
 Rishabh Agarwal, Pablo Samuel Castro
Categories: cs.LG cs.AI
Comments: ICML 2023 Camera Ready
\\ ( https://arxiv.org/abs/2305.19452 ,  750kb)
------------------------------------------------------------------------------
\\
arXiv:2306.01986
replaced with revised version Fri, 9 Jun 2023 13:46:50 GMT   (2777kb)

Title: A Novel Correlation-optimized Deep Learning Method for Wind Speed
 Forecast
Authors: Yang Yang, Jin Lang, Jian Wu, Yanyan Zhang, Xiang Zhao
Categories: cs.LG cs.AI cs.SY eess.SY math.OC
\\ ( https://arxiv.org/abs/2306.01986 ,  2777kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03042
replaced with revised version Fri, 9 Jun 2023 08:26:57 GMT   (1177kb,D)

Title: SERT: A Transfomer Based Model for Spatio-Temporal Sensor Data with
 Missing Values for Environmental Monitoring
Authors: Amin Shoari Nejad, Roc\'io Alaiz-Rodr\'iguez, Gerard D. McCarthy,
 Brian Kelleher, Anthony Grey, Andrew Parnell
Categories: cs.LG cs.AI
Comments: 11 pages, 7 figures
\\ ( https://arxiv.org/abs/2306.03042 ,  1177kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04026
replaced with revised version Thu, 8 Jun 2023 22:53:10 GMT   (1642kb,D)

Title: Value Functions are Control Barrier Functions: Verification of Safe
 Policies using Control Theory
Authors: Daniel C.H. Tan and Fernando Acero and Robert McCarthy and Dimitrios
 Kanoulas and Zhibin Li
Categories: cs.LG cs.AI cs.RO
\\ ( https://arxiv.org/abs/2306.04026 ,  1642kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04634
replaced with revised version Fri, 9 Jun 2023 17:58:04 GMT   (14993kb,D)

Title: On the Reliability of Watermarks for Large Language Models
Authors: John Kirchenbauer, Jonas Geiping, Yuxin Wen, Manli Shu, Khalid
 Saifullah, Kezhi Kong, Kasun Fernando, Aniruddha Saha, Micah Goldblum and Tom
 Goldstein
Categories: cs.LG cs.CL cs.CR
Comments: 14 pages in the main body. Code is available at
 https://github.com/jwkirchenbauer/lm-watermarking
\\ ( https://arxiv.org/abs/2306.04634 ,  14993kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04795
replaced with revised version Fri, 9 Jun 2023 03:56:10 GMT   (1777kb,D)

Title: Feature Selection using Sparse Adaptive Bottleneck Centroid-Encoder
Authors: Tomojit Ghosh, Michael Kirby
Categories: cs.LG
Comments: A novel nonlinear feature selection technique with new state of the
 art result. 22 pages (including references), 13 figures. The article is in
 review
\\ ( https://arxiv.org/abs/2306.04795 ,  1777kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04824
replaced with revised version Fri, 9 Jun 2023 04:06:36 GMT   (1614kb,D)

Title: Sparse Linear Centroid-Encoder: A Convex Method for Feature Selection
Authors: Tomojit Ghosh, Michael Kirby, Karim Karimov
Categories: cs.LG
Comments: A novel linear feature selection technique using convex optimization.
 Total 13 pages including references, 7 figures. The article is under review
\\ ( https://arxiv.org/abs/2306.04824 ,  1614kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04873
replaced with revised version Fri, 9 Jun 2023 02:10:26 GMT   (10340kb,D)

Title: Complexity-aware Large Scale Origin-Destination Network Generation via
 Diffusion Model
Authors: Can Rong, Jingtao Ding, Zhicheng Liu, Yong Li
Categories: cs.LG
Comments: 11 pagers, 5 figures
\\ ( https://arxiv.org/abs/2306.04873 ,  10340kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04901
replaced with revised version Fri, 9 Jun 2023 00:45:06 GMT   (323kb)

Title: Generalization Performance of Transfer Learning: Overparameterized and
 Underparameterized Regimes
Authors: Peizhong Ju, Sen Lin, Mark S. Squillante, Yingbin Liang, Ness B.
 Shroff
Categories: cs.LG
\\ ( https://arxiv.org/abs/2306.04901 ,  323kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05275
replaced with revised version Fri, 9 Jun 2023 11:32:04 GMT   (96kb)

Title: Federated Linear Contextual Bandits with User-level Differential Privacy
Authors: Ruiquan Huang, Huanyu Zhang, Luca Melis, Milan Shen, Meisam Hajzinia,
 Jing Yang
Categories: cs.LG cs.CR stat.ML
Comments: Accepted by ICML 2023
\\ ( https://arxiv.org/abs/2306.05275 ,  96kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05344
replaced with revised version Fri, 9 Jun 2023 08:27:55 GMT   (2320kb,D)

Title: A Crystal-Specific Pre-Training Framework for Crystal Material Property
 Prediction
Authors: Haomin Yu, Yanru Song, Jilin Hu, Chenjuan Guo, Bin Yang
Categories: cs.LG cond-mat.mtrl-sci
\\ ( https://arxiv.org/abs/2306.05344 ,  2320kb)
------------------------------------------------------------------------------
\\
arXiv:2203.14572
replaced with revised version Fri, 9 Jun 2023 15:15:14 GMT   (1112kb)

Title: Distributed Task Management in Fog Computing: A Socially Concave Bandit
 Game
Authors: Xiaotong Cheng and Setareh Maghsudi
Categories: cs.MA cs.GT cs.LG
DOI: 10.1109/TGCN.2023.3276415
\\ ( https://arxiv.org/abs/2203.14572 ,  1112kb)
------------------------------------------------------------------------------
\\
arXiv:2211.05189
replaced with revised version Fri, 9 Jun 2023 04:00:12 GMT   (2154kb,D)

Title: Deterministic Random Walk Model in NetLogo and the Identification of
 Asymmetric Saturation Time in Random Graph
Authors: Ayan Chatterjee, Qingtao Cao, Amirhossein Sajadi, Babak Ravandi
Categories: cs.MA stat.AP
\\ ( https://arxiv.org/abs/2211.05189 ,  2154kb)
------------------------------------------------------------------------------
\\
arXiv:2303.09734
replaced with revised version Fri, 9 Jun 2023 15:21:02 GMT   (4067kb,D)

Title: The Moderating Effect of Instant Runoff Voting
Authors: Kiran Tomlinson, Johan Ugander, Jon Kleinberg
Categories: cs.MA cs.GT econ.TH
Comments: 42 pages; updated intro and title, added GitHub link
\\ ( https://arxiv.org/abs/2303.09734 ,  4067kb)
------------------------------------------------------------------------------
\\
arXiv:2111.12793
replaced with revised version Thu, 8 Jun 2023 21:43:03 GMT   (6564kb,D)

Title: Bacteria-inspired robotic propulsion from bundling of soft helical
 filaments at low Reynolds number
Authors: Sangmin Lim, Achyuta Yadunandan, Mohammad Khalid Jawed
Categories: cs.RO
Comments: Soft Matter (2023). Supplementary Video: https://youtu.be/qevN1NovCZs
DOI: 10.1039/D2SM01398C
\\ ( https://arxiv.org/abs/2111.12793 ,  6564kb)
------------------------------------------------------------------------------
\\
arXiv:2212.12724
replaced with revised version Thu, 8 Jun 2023 22:42:59 GMT   (2415kb,D)

Title: Certification of Bottleneck Task Assignment with Shortest Path Criteria
Authors: Tony A. Wood and Maryam Kamgarpour
Categories: cs.RO cs.SY eess.SY math.OC
\\ ( https://arxiv.org/abs/2212.12724 ,  2415kb)
------------------------------------------------------------------------------
\\
arXiv:2301.02297
replaced with revised version Fri, 9 Jun 2023 15:49:03 GMT   (10143kb,D)

Title: Improving Self-Consistency in Underwater Mapping Through Laser-Based
 Loop Closure (Extended)
Authors: Thomas Hitchcox and James Richard Forbes
Categories: cs.RO
Comments: 26 pages, 18 figures. V2 correct Table III x2 parameter values, Table
 VIII 'INS' values, and equation A.28
Journal-ref: IEEE Transactions on Robotics, vol. 39, no. 3, pp. 1873-1892, 2023
DOI: 10.1109/TRO.2022.3229842
\\ ( https://arxiv.org/abs/2301.02297 ,  10143kb)
------------------------------------------------------------------------------
\\
arXiv:2303.10231
replaced with revised version Fri, 9 Jun 2023 01:17:00 GMT   (2360kb,D)

Title: An Input-to-State Stability Perspective on Robust Locomotion
Authors: Maegan Tucker and Aaron D. Ames
Categories: cs.RO cs.SY eess.SY
Comments: 6 pages
\\ ( https://arxiv.org/abs/2303.10231 ,  2360kb)
------------------------------------------------------------------------------
\\
arXiv:2305.16744
replaced with revised version Thu, 8 Jun 2023 18:39:08 GMT   (46087kb,D)

Title: Demo2Code: From Summarizing Demonstrations to Synthesizing Code via
 Extended Chain-of-Thought
Authors: Huaxiaoyue Wang, Gonzalo Gonzalez-Pumariega, Yash Sharma, Sanjiban
 Choudhury
Categories: cs.RO
Comments: 10 pages (not including references and appendix), 14 figures (7 in
 main paper, 7 in appendix); (v2) added additional references to section 2 and
 9, added acknowledgement section
\\ ( https://arxiv.org/abs/2305.16744 ,  46087kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05340
replaced with revised version Fri, 9 Jun 2023 02:41:06 GMT   (553kb)

Title: Research Impact of Solar Panel Cleaning Robot on Photovoltaic Panel's
 Deflection
Authors: Trung Dat Phan, Minh Duc Nguyen, Maxence Auffray, Nhut Thang Le, Cong
 Toai Truong, Van Tu Duong, Huy Hung Nguyen, Tan Tien Nguyen
Categories: cs.RO
Comments: 8 pages, 8 figures, The 4th International Conference on Applied
 Convergence Engineering (ICACE 2023)
\\ ( https://arxiv.org/abs/2306.05340 ,  553kb)
------------------------------------------------------------------------------
\\
arXiv:2107.04094
replaced with revised version Fri, 9 Jun 2023 00:37:46 GMT   (3012kb,D)

Title: Robust Control Barrier Functions under High Relative Degree and Input
 Constraints for Satellite Trajectories
Authors: Joseph Breeden and Dimitra Panagou
Categories: eess.SY cs.SY math.OC
Comments: 21 pages, extended version contains additional simulations and
 proofs. Accepted to Automatica
\\ ( https://arxiv.org/abs/2107.04094 ,  3012kb)
------------------------------------------------------------------------------
\\
arXiv:2206.07425
replaced with revised version Fri, 9 Jun 2023 08:04:06 GMT   (1803kb,D)

Title: Discrete-time Layered-network Epidemics Model with Time-varying
 Transition Rates and Multiple Resources
Authors: Shaoxuan Cui, Fangzhou Liu, Hildeberto Jard\'on-Kojakhmetov and Ming
 Cao
Categories: eess.SY cs.SY
MSC-class: 93A15 37N25 92F05
\\ ( https://arxiv.org/abs/2206.07425 ,  1803kb)
------------------------------------------------------------------------------
\\
arXiv:2211.04854
replaced with revised version Fri, 9 Jun 2023 07:47:59 GMT   (1561kb,D)

Title: 6G Mobile-Edge Empowered Metaverse: Requirements, Technologies,
 Challenges and Research Directions
Authors: Jiadong Yu, Ahmad Alhilal, Pan Hui, Danny H.K. Tsang
Categories: eess.SY cs.SY
\\ ( https://arxiv.org/abs/2211.04854 ,  1561kb)
------------------------------------------------------------------------------
\\
arXiv:2212.02111
replaced with revised version Fri, 9 Jun 2023 12:58:03 GMT   (218kb,D)

Title: Predictive safety filter using system level synthesis
Authors: Antoine P. Leeman and Johannes K\"ohler and Samir Benanni and Melanie
 N. Zeilinger
Categories: eess.SY cs.SY
Comments: https://gitlab.ethz.ch/ics/SLS_safety_filter/
Journal-ref: Proceedings of The 5th Annual Learning for Dynamics and Control
 Conference, PMLR 211:1180-1192 (2023)
DOI: 10.3929/ethz-b-000615512
\\ ( https://arxiv.org/abs/2212.02111 ,  218kb)
------------------------------------------------------------------------------
\\
arXiv:2008.10522
replaced with revised version Fri, 9 Jun 2023 08:27:03 GMT   (28kb)

Title: Machine Semiotics
Authors: Peter beim Graben, Markus Huber-Liebl, Peter Klimczak, and G\"unther
 Wirsching
Categories: cs.CL cs.AI
Comments: 48 pages, 4 tables
\\ ( https://arxiv.org/abs/2008.10522 ,  28kb)
------------------------------------------------------------------------------
\\
arXiv:2205.05359 (*cross-listing*)
replaced with revised version Fri, 9 Jun 2023 16:44:52 GMT   (5843kb,D)

Title: Exploring Local Explanations of Nonlinear Models Using Animated Linear
 Projections
Authors: Nicholas Spyrison, Dianne Cook, Przemyslaw Biecek
Categories: stat.ML cs.AI cs.LG
Comments: 26 pages, 10 figures, 0 tables
\\ ( https://arxiv.org/abs/2205.05359 ,  5843kb)
------------------------------------------------------------------------------
\\
arXiv:2205.15239 (*cross-listing*)
replaced with revised version Fri, 9 Jun 2023 13:30:44 GMT   (1896kb,D)

Title: Conformal Credal Self-Supervised Learning
Authors: Julian Lienen, Caglar Demir, Eyke H\"ullermeier
Categories: stat.ML cs.AI cs.CV cs.LG
Comments: 26 pages, 5 figures, 10 tables, to be published at the 12th Symposium
 on Conformal and Probabilistic Prediction with Applications (COPA 2023)
\\ ( https://arxiv.org/abs/2205.15239 ,  1896kb)
------------------------------------------------------------------------------
\\
arXiv:2207.03579
replaced with revised version Fri, 9 Jun 2023 11:37:55 GMT   (525kb,D)

Title: DGraph: A Large-Scale Financial Dataset for Graph Anomaly Detection
Authors: Xuanwen Huang, Yang Yang, Yang Wang, Chunping Wang, Zhisheng Zhang,
 Jiarong Xu, Lei Chen, Michalis Vazirgiannis
Categories: cs.SI cs.AI
Comments: Accepted to NeurIPS 2022. Dataset Url: https://dgraph.xinye.com/
\\ ( https://arxiv.org/abs/2207.03579 ,  525kb)
------------------------------------------------------------------------------
\\
arXiv:2212.08162 (*cross-listing*)
replaced with revised version Fri, 9 Jun 2023 08:53:56 GMT   (1567kb,D)

Title: Huber-energy measure quantization
Authors: Gabriel Turinici
Categories: stat.ML cs.AI cs.LG cs.NA math.NA math.PR math.ST stat.TH
\\ ( https://arxiv.org/abs/2212.08162 ,  1567kb)
------------------------------------------------------------------------------
\\
arXiv:2303.16972
replaced with revised version Thu, 8 Jun 2023 18:08:24 GMT   (3103kb,D)

Title: Queer In AI: A Case Study in Community-Led Participatory AI
Authors: Organizers Of QueerInAI: Anaelia Ovalle, Arjun Subramonian, Ashwin
 Singh, Claas Voelcker, Danica J. Sutherland, Davide Locatelli, Eva Breznik,
 Filip Klubi\v{c}ka, Hang Yuan, Hetvi J, Huan Zhang, Jaidev Shriram, Kruno
 Lehman, Luca Soldaini, Maarten Sap, Marc Peter Deisenroth, Maria Leonor
 Pacheco, Maria Ryskina, Martin Mundt, Milind Agarwal, Nyx McLean, Pan Xu, A
 Pranav, Raj Korpan, Ruchira Ray, Sarah Mathew, Sarthak Arora, ST John, Tanvi
 Anand, Vishakha Agrawal, William Agnew, Yanan Long, Zijie J. Wang, Zeerak
 Talat, Avijit Ghosh, Nathaniel Dennler, Michael Noseworthy, Sharvani Jha, Emi
 Baylor, Aditya Joshi, Natalia Y. Bilenko, Andrew McNamara, Raphael
 Gontijo-Lopes, Alex Markham, Evyn D\v{o}ng, Jackie Kay, Manu Saraswat, Nikhil
 Vytla, Luke Stark
Categories: cs.CY cs.AI
Comments: To appear at FAccT 2023
Journal-ref: 2023 ACM Conference on Fairness, Accountability, and Transparency
DOI: 10.1145/3593013.3594134
\\ ( https://arxiv.org/abs/2303.16972 ,  3103kb)
------------------------------------------------------------------------------
\\
arXiv:2305.01555
replaced with revised version Fri, 9 Jun 2023 15:59:18 GMT   (7414kb,D)

Title: How to Unleash the Power of Large Language Models for Few-shot Relation
 Extraction?
Authors: Xin Xu, Yuqi Zhu, Xiaohan Wang, Ningyu Zhang
Categories: cs.CL cs.AI cs.DB cs.IR cs.LG
Comments: SustaiNLP Workshop@ACL 2023
\\ ( https://arxiv.org/abs/2305.01555 ,  7414kb)
------------------------------------------------------------------------------
\\
arXiv:2305.01904
replaced with revised version Fri, 9 Jun 2023 07:17:14 GMT   (604kb,D)

Title: Robust Multi-bit Natural Language Watermarking through Invariant
 Features
Authors: KiYoon Yoo, Wonhyuk Ahn, Jiho Jang, Nojun Kwak
Categories: cs.CL cs.AI
Comments: ACL 2023 long
\\ ( https://arxiv.org/abs/2305.01904 ,  604kb)
------------------------------------------------------------------------------
\\
arXiv:2305.04835
replaced with revised version Fri, 9 Jun 2023 02:25:29 GMT   (7842kb,D)

Title: How Do In-Context Examples Affect Compositional Generalization?
Authors: Shengnan An, Zeqi Lin, Qiang Fu, Bei Chen, Nanning Zheng, Jian-Guang
 Lou and Dongmei Zhang
Categories: cs.CL cs.AI
Comments: ACL 2023 main conference, long paper
\\ ( https://arxiv.org/abs/2305.04835 ,  7842kb)
------------------------------------------------------------------------------
\\
arXiv:2305.11579
replaced with revised version Fri, 9 Jun 2023 03:48:42 GMT   (25241kb,D)

Title: Speech-Text Dialog Pre-training for Spoken Dialog Understanding with
 Explicit Cross-Modal Alignment
Authors: Tianshu Yu, Haoyu Gao, Ting-En Lin, Min Yang, Yuchuan Wu, Wentao Ma,
 Chao Wang, Fei Huang, Yongbin Li
Categories: cs.CL cs.AI
Comments: Accepted at ACL 2023 main conference
\\ ( https://arxiv.org/abs/2305.11579 ,  25241kb)
------------------------------------------------------------------------------
\\
arXiv:2305.15945
replaced with revised version Thu, 8 Jun 2023 18:26:36 GMT   (6648kb,D)

Title: Learning to Act through Evolution of Neural Diversity in Random Neural
 Networks
Authors: Joachim Winther Pedersen and Sebastian Risi
Categories: cs.NE cs.AI
Comments: Linebreaks in abstract fixed
DOI: 10.1145/3583131.3590460
\\ ( https://arxiv.org/abs/2305.15945 ,  6648kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05153
replaced with revised version Fri, 9 Jun 2023 01:08:40 GMT   (124kb,D)

Title: Is AI the better programming partner? Human-Human Pair Programming vs.
 Human-AI pAIr Programming
Authors: Qianou Ma, Tongshuang Wu, Kenneth Koedinger
Categories: cs.HC cs.AI
Comments: 8 pages (without references), 2 tables
\\ ( https://arxiv.org/abs/2306.05153 ,  124kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05176
replaced with revised version Fri, 9 Jun 2023 02:56:20 GMT   (41kb,D)

Title: RRWKV: Capturing Long-range Dependencies in RWKV
Authors: Leilei Wang
Categories: cs.CL cs.AI
\\ ( https://arxiv.org/abs/2306.05176 ,  41kb)
------------------------------------------------------------------------------
\\
arXiv:2305.07894
replaced with revised version Fri, 9 Jun 2023 06:28:52 GMT   (2034kb,D)

Title: Voxel-wise classification for porosity investigation of additive
 manufactured parts with 3D unsupervised and (deeply) supervised neural
 networks
Authors: Domenico Iuso, Soumick Chatterjee, Sven Cornelissen, Dries Verhees,
 Jan De Beenhouwer, Jan Sijbers
Categories: cs.CE cs.CV cs.LG
\\ ( https://arxiv.org/abs/2305.07894 ,  2034kb)
------------------------------------------------------------------------------
\\
arXiv:2212.14449 (*cross-listing*)
replaced with revised version Fri, 9 Jun 2023 12:06:32 GMT   (86kb)

Title: Policy Mirror Ascent for Efficient and Independent Learning in Mean
 Field Games
Authors: Batuhan Yardim, Semih Cayci, Matthieu Geist, Niao He
Categories: math.OC cs.GT cs.LG stat.ML
Comments: Accepted for publication at ICML 2023
\\ ( https://arxiv.org/abs/2212.14449 ,  86kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05359
replaced with revised version Fri, 9 Jun 2023 08:52:24 GMT   (606kb,D)

Title: Safeguarding Physical Sneaker Sale Through a Decentralized Medium
Authors: Marwan Zeggari and Aydin Abadi and Renaud Lambiotte and Mohamad Kassab
Categories: cs.CR cs.GT
Comments: 27 pages, 6 figures, 7 tables
DOI: 10.13140/RG.2.2.32852.58247
\\ ( https://arxiv.org/abs/2306.05359 ,  606kb)
------------------------------------------------------------------------------
\\
arXiv:2009.07514 (*cross-listing*)
replaced with revised version Fri, 9 Jun 2023 03:07:57 GMT   (1379kb,D)

Title: A Unified Approach to Synchronization Problems over Subgroups of the
 Orthogonal Group
Authors: Huikang Liu, Man-Chung Yue, Anthony Man-Cho So
Categories: math.OC cs.LG eess.SP
\\ ( https://arxiv.org/abs/2009.07514 ,  1379kb)
------------------------------------------------------------------------------
\\
arXiv:2108.09646
replaced with revised version Thu, 8 Jun 2023 22:10:08 GMT   (4957kb,D)

Title: A Systematic Review of Automated Query Reformulations in Source Code
 Search
Authors: Mohammad Masudur Rahman and Chanchal K. Roy
Categories: cs.SE cs.IR cs.LG cs.NE
Comments: 81 pages, accepted at TOSEM
ACM-class: D.2.5; D.2.1; D.2.7; D.2.13
\\ ( https://arxiv.org/abs/2108.09646 ,  4957kb)
------------------------------------------------------------------------------
\\
arXiv:2109.08079
replaced with revised version Thu, 8 Jun 2023 18:33:01 GMT   (659kb,D)

Title: Context-NER : Contextual Phrase Generation at Scale
Authors: Himanshu Gupta, Shreyas Verma, Santosh Mashetty, Swaroop Mishra
Categories: cs.IR cs.CL cs.LG
Comments: 29 pages, 5 Figures, 2 AlgorithmS, 17 Tables. Accepted in NeurIPS
 2022 - Efficient Natural Language and Speech Processing (ENLSP) Workshop
\\ ( https://arxiv.org/abs/2109.08079 ,  659kb)
------------------------------------------------------------------------------
\\
arXiv:2110.15444
replaced with revised version Fri, 9 Jun 2023 15:53:54 GMT   (97kb,D)

Title: 10 Security and Privacy Problems in Large Foundation Models
Authors: Jinyuan Jia, Hongbin Liu, Neil Zhenqiang Gong
Categories: cs.CR cs.LG
Comments: A book chapter
\\ ( https://arxiv.org/abs/2110.15444 ,  97kb)
------------------------------------------------------------------------------
\\
arXiv:2112.03419 (*cross-listing*)
replaced with revised version Fri, 9 Jun 2023 03:29:05 GMT   (3164kb,D)

Title: Using Image Transformations to Learn Network Structure
Authors: Brayan Ortiz and Amitabh Sinha
Categories: stat.ML cs.LG stat.AP
Comments: 11 pages, 6 figures, 5 tables, In Submission with Springer Nature,
 Computer Science Journal
MSC-class: 62P99 (Primary), 68T05 (Primary), 90B99 (Secondary)
ACM-class: G.3; I.4; I.2
\\ ( https://arxiv.org/abs/2112.03419 ,  3164kb)
------------------------------------------------------------------------------
\\
arXiv:2112.12909 (*cross-listing*)
replaced with revised version Fri, 9 Jun 2023 01:51:29 GMT   (477kb,D)

Title: Optimal Variable Clustering for High-Dimensional Matrix Valued Data
Authors: Inbeom Lee, Siyi Deng, Yang Ning
Categories: stat.ML cs.LG math.ST stat.ME stat.TH
Comments: 25 pages and 2 figures in the main paper; 43 pages and 10 figures in
 the supplementary material
\\ ( https://arxiv.org/abs/2112.12909 ,  477kb)
------------------------------------------------------------------------------
\\
arXiv:2203.13617 (*cross-listing*)
replaced with revised version Fri, 9 Jun 2023 14:45:18 GMT   (611kb,D)

Title: EmotionNAS: Two-stream Neural Architecture Search for Speech Emotion
 Recognition
Authors: Haiyang Sun, Zheng Lian, Bin Liu, Ying Li, Licai Sun, Cong Cai,
 Jianhua Tao, Meng Wang, Yuan Cheng
Categories: eess.AS cs.LG cs.SD
Comments: Accepted to Interspeech 2023
\\ ( https://arxiv.org/abs/2203.13617 ,  611kb)
------------------------------------------------------------------------------
\\
arXiv:2204.08335 (*cross-listing*)
replaced with revised version Fri, 9 Jun 2023 13:51:13 GMT   (2036kb,D)

Title: Active Learning with Weak Supervision for Gaussian Processes
Authors: Amanda Olmin and Jakob Lindqvist and Lennart Svensson and Fredrik
 Lindsten
Categories: stat.ML cs.LG
Journal-ref: In: ICONIP. Communications in Computer and Information Science,
 vol 1792. Springer, Singapore (2023)
DOI: 10.1007/978-981-99-1642-9_17
\\ ( https://arxiv.org/abs/2204.08335 ,  2036kb)
------------------------------------------------------------------------------
\\
arXiv:2210.14306
replaced with revised version Fri, 9 Jun 2023 15:03:06 GMT   (3940kb,D)

Title: Reading Between the Lines: Modeling User Behavior and Costs in
 AI-Assisted Programming
Authors: Hussein Mozannar, Gagan Bansal, Adam Fourney, Eric Horvitz
Categories: cs.SE cs.HC cs.LG
\\ ( https://arxiv.org/abs/2210.14306 ,  3940kb)
------------------------------------------------------------------------------
\\
arXiv:2210.15471 (*cross-listing*)
replaced with revised version Thu, 8 Jun 2023 22:23:46 GMT   (267kb,D)

Title: Adaptive Estimation of Graphical Models under Total Positivity
Authors: Jiaxi Ying, Jos\'e Vin\'icius de M. Cardoso, Daniel P. Palomar
Categories: stat.ML cs.LG eess.SP
Comments: 26 pages
\\ ( https://arxiv.org/abs/2210.15471 ,  267kb)
------------------------------------------------------------------------------
\\
arXiv:2210.16458 (*cross-listing*)
replaced with revised version Thu, 8 Jun 2023 22:30:58 GMT   (3383kb,D)

Title: Reformulating van Rijsbergen's $F_{\beta}$ metric for weighted binary
 cross-entropy
Authors: Satesh Ramdhani
Categories: stat.ML cs.LG
\\ ( https://arxiv.org/abs/2210.16458 ,  3383kb)
------------------------------------------------------------------------------
\\
arXiv:2211.03860 (*cross-listing*)
replaced with revised version Fri, 9 Jun 2023 15:55:11 GMT   (2159kb)

Title: Automatic Change-Point Detection in Time Series via Deep Learning
Authors: Jie Li, Paul Fearnhead, Piotr Fryzlewicz, Tengyao Wang
Categories: stat.ML cs.LG stat.ME
Comments: 33 pages, 15 figures and 3 tables
\\ ( https://arxiv.org/abs/2211.03860 ,  2159kb)
------------------------------------------------------------------------------
\\
arXiv:2212.12978 (*cross-listing*)
replaced with revised version Fri, 9 Jun 2023 06:34:33 GMT   (736kb,D)

Title: Doubly Smoothed GDA for Constrained Nonconvex-Nonconcave Minimax
 Optimization
Authors: Taoli Zheng, Linglingzhi Zhu, Anthony Man-Cho So, Jose Blanchet,
 Jiajin Li
Categories: math.OC cs.LG stat.ML
\\ ( https://arxiv.org/abs/2212.12978 ,  736kb)
------------------------------------------------------------------------------
\\
arXiv:2301.01642 (*cross-listing*)
replaced with revised version Fri, 9 Jun 2023 13:32:29 GMT   (8442kb,D)

Title: CI-GNN: A Granger Causality-Inspired Graph Neural Network for
 Interpretable Brain Network-Based Psychiatric Diagnosis
Authors: Kaizhong Zheng, Shujian Yu, Badong Chen
Categories: stat.ML cs.LG q-bio.NC
Comments: 45 pages, 13 figures
\\ ( https://arxiv.org/abs/2301.01642 ,  8442kb)
------------------------------------------------------------------------------
\\
arXiv:2301.05537 (*cross-listing*)
replaced with revised version Fri, 9 Jun 2023 03:33:00 GMT   (2261kb,D)

Title: Almost Surely $\sqrt{T}$ Regret Bound for Adaptive LQR
Authors: Yiwen Lu and Yilin Mo
Categories: math.OC cs.LG cs.SY eess.SY
\\ ( https://arxiv.org/abs/2301.05537 ,  2261kb)
------------------------------------------------------------------------------
\\
arXiv:2301.08173 (*cross-listing*)
replaced with revised version Fri, 9 Jun 2023 08:40:45 GMT   (7379kb,D)

Title: Time-Warping Invariant Quantum Recurrent Neural Networks via
 Quantum-Classical Adaptive Gating
Authors: Ivana Nikoloska, Osvaldo Simeone, Leonardo Banchi, and Petar
 Veli\v{c}kovi\'c
Categories: quant-ph cs.IT cs.LG math.IT
Comments: Submitted for publication
\\ ( https://arxiv.org/abs/2301.08173 ,  7379kb)
------------------------------------------------------------------------------
\\
arXiv:2302.00163
replaced with revised version Fri, 9 Jun 2023 14:26:29 GMT   (5728kb)

Title: FLSTRA: Federated Learning in Stratosphere
Authors: Amin Farajzadeh, Animesh Yadav, Omid Abbasi, Wael Jaafar, Halim
 Yanikomeroglu
Categories: cs.NI cs.LG eess.SP math.OC
Comments: Accepted to IEEE Transactions on Wireless Communications
\\ ( https://arxiv.org/abs/2302.00163 ,  5728kb)
------------------------------------------------------------------------------
\\
arXiv:2302.01075 (*cross-listing*)
replaced with revised version Fri, 9 Jun 2023 10:23:28 GMT   (3483kb,D)

Title: MonoFlow: Rethinking Divergence GANs via the Perspective of Wasserstein
 Gradient Flows
Authors: Mingxuan Yi, Zhanxing Zhu, Song Liu
Categories: stat.ML cs.LG
\\ ( https://arxiv.org/abs/2302.01075 ,  3483kb)
------------------------------------------------------------------------------
\\
arXiv:2303.14822
replaced with revised version Fri, 9 Jun 2023 06:50:57 GMT   (1523kb,D)

Title: MGTBench: Benchmarking Machine-Generated Text Detection
Authors: Xinlei He and Xinyue Shen and Zeyuan Chen and Michael Backes and Yang
 Zhang
Categories: cs.CR cs.LG
\\ ( https://arxiv.org/abs/2303.14822 ,  1523kb)
------------------------------------------------------------------------------
\\
arXiv:2303.14878
replaced with revised version Thu, 8 Jun 2023 19:56:08 GMT   (6959kb,D)

Title: GPT-PINN: Generative Pre-Trained Physics-Informed Neural Networks toward
 non-intrusive Meta-learning of parametric PDEs
Authors: Yanlai Chen and Shawn Koohy
Categories: math.NA cs.LG cs.NA
\\ ( https://arxiv.org/abs/2303.14878 ,  6959kb)
------------------------------------------------------------------------------
\\
arXiv:2304.04740 (*cross-listing*)
replaced with revised version Thu, 8 Jun 2023 21:56:08 GMT   (6407kb,D)

Title: Reflected Diffusion Models
Authors: Aaron Lou and Stefano Ermon
Categories: stat.ML cs.LG
Comments: ICML 2023 Camera Ready. Code available at
 https://github.com/louaaron/Reflected-Diffusion
\\ ( https://arxiv.org/abs/2304.04740 ,  6407kb)
------------------------------------------------------------------------------
\\
arXiv:2304.13835
replaced with revised version Thu, 8 Jun 2023 21:45:46 GMT   (1464kb,D)

Title: Multi-Party Chat: Conversational Agents in Group Settings with Humans
 and Models
Authors: Jimmy Wei, Kurt Shuster, Arthur Szlam, Jason Weston, Jack Urbanek,
 Mojtaba Komeili
Categories: cs.CL cs.LG
\\ ( https://arxiv.org/abs/2304.13835 ,  1464kb)
------------------------------------------------------------------------------
\\
arXiv:2305.03827
replaced with revised version Thu, 8 Jun 2023 22:22:24 GMT   (7204kb,D)

Title: Uncertainty-Aware Bootstrap Learning for Joint Extraction on
 Distantly-Supervised Data
Authors: Yufei Li, Xiao Yu, Yanchi Liu, Haifeng Chen, Cong Liu
Categories: cs.CL cs.LG
Comments: ACL 2023 main conference short paper
\\ ( https://arxiv.org/abs/2305.03827 ,  7204kb)
------------------------------------------------------------------------------
\\
arXiv:2305.06348 (*cross-listing*)
replaced with revised version Fri, 9 Jun 2023 09:20:17 GMT   (48kb)

Title: Supervised learning with probabilistic morphisms and kernel mean
 embeddings
Authors: H\^ong V\^an L\^e
Categories: math.ST cs.LG math.CT math.FA math.PR stat.TH
Comments: V4: 50 p., minor corrections and presentation improvement, in
 particular in Lemma 6.8, Corollary 6.13, Example 6.14
MSC-class: 46N30, 60B10, 62G05, 18N99
\\ ( https://arxiv.org/abs/2305.06348 ,  48kb)
------------------------------------------------------------------------------
\\
arXiv:2305.08637 (*cross-listing*)
replaced with revised version Fri, 9 Jun 2023 10:48:45 GMT   (371kb)

Title: Double-Weighting for Covariate Shift Adaptation
Authors: Jos\'e I. Segovia-Mart\'in, Santiago Mazuelas, and Anqi Liu
Categories: stat.ML cs.LG
\\ ( https://arxiv.org/abs/2305.08637 ,  371kb)
------------------------------------------------------------------------------
\\
arXiv:2305.15871 (*cross-listing*)
replaced with revised version Fri, 9 Jun 2023 08:01:00 GMT   (4270kb,D)

Title: Learning Robust Statistics for Simulation-based Inference under Model
 Misspecification
Authors: Daolang Huang, Ayush Bharti, Amauri Souza, Luigi Acerbi, Samuel Kaski
Categories: stat.ML cs.LG stat.CO
\\ ( https://arxiv.org/abs/2305.15871 ,  4270kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03984
replaced with revised version Fri, 9 Jun 2023 01:17:39 GMT   (7560kb,D)

Title: Toward More Accurate and Generalizable Evaluation Metrics for
 Task-Oriented Dialogs
Authors: Abishek Komma, Nagesh Panyam Chandrasekarasastry, Timothy Leffel, Anuj
 Goyal, Angeliki Metallinou, Spyros Matsoukas, Aram Galstyan
Categories: cs.CL cs.LG
\\ ( https://arxiv.org/abs/2306.03984 ,  7560kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04810
replaced with revised version Fri, 9 Jun 2023 11:40:26 GMT   (8678kb,D)

Title: Correlative Information Maximization: A Biologically Plausible Approach
 to Supervised Deep Neural Networks without Weight Symmetry
Authors: Bariscan Bozkurt, Cengiz Pehlevan, Alper T Erdogan
Categories: cs.NE cs.IT cs.LG math.IT q-bio.NC
Comments: Preprint, 31 pages
\\ ( https://arxiv.org/abs/2306.04810 ,  8678kb)
------------------------------------------------------------------------------
\\
arXiv:2105.09884 (*cross-listing*)
replaced with revised version Fri, 9 Jun 2023 15:47:55 GMT   (571kb,D)

Title: A Stochastic Operator Framework for Optimization and Learning with
 Sub-Weibull Errors
Authors: Nicola Bastianello, Liam Madden, Ruggero Carli, Emiliano Dall'Anese
Categories: math.OC cs.SY eess.SY
\\ ( https://arxiv.org/abs/2105.09884 ,  571kb)
%%%---%%%---%%%---%%%---%%%---%%%---%%%---%%%---%%%---%%%---%%%---%%%---%%%---
