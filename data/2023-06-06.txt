------------------------------------------------------------------------------
------------------------------------------------------------------------------
Send any comments regarding submissions directly to submitter.
------------------------------------------------------------------------------
Archives at http://arxiv.org/
To unsubscribe, e-mail To: cs@arXiv.org, Subject: cancel
------------------------------------------------------------------------------
Submissions to:
Artificial Intelligence
Computer Vision and Pattern Recognition
Computer Science and Game Theory
Machine Learning
Multiagent Systems
Robotics
Systems and Control
received from  Mon  5 Jun 23 18:00:00 GMT  to  Tue  6 Jun 23 18:00:00 GMT
------------------------------------------------------------------------------
------------------------------------------------------------------------------
\\
arXiv:2306.03110
Date: Mon, 5 Jun 2023 05:11:03 GMT   (6157kb,D)

Title: SwinRDM: Integrate SwinRNN with Diffusion Model towards High-Resolution
 and High-Quality Weather Forecasting
Authors: Lei Chen, Fei Du, Yuan Hu, Fan Wang, Zhibin Wang
Categories: cs.AI cs.CV physics.ao-ph
DOI: 10.48448/zn7f-fc64
\\
 Data-driven medium-range weather forecasting has attracted much attention in
recent years. However, the forecasting accuracy at high resolution is
unsatisfactory currently. Pursuing high-resolution and high-quality weather
forecasting, we develop a data-driven model SwinRDM which integrates an
improved version of SwinRNN with a diffusion model. SwinRDM performs
predictions at 0.25-degree resolution and achieves superior forecasting
accuracy to IFS (Integrated Forecast System), the state-of-the-art operational
NWP model, on representative atmospheric variables including 500 hPa
geopotential (Z500), 850 hPa temperature (T850), 2-m temperature (T2M), and
total precipitation (TP), at lead times of up to 5 days. We propose to leverage
a two-step strategy to achieve high-resolution predictions at 0.25-degree
considering the trade-off between computation memory and forecasting accuracy.
Recurrent predictions for future atmospheric fields are firstly performed at
1.40625-degree resolution, and then a diffusion-based super-resolution model is
leveraged to recover the high spatial resolution and finer-scale atmospheric
details. SwinRDM pushes forward the performance and potential of data-driven
models for a large margin towards operational applications.
\\ ( https://arxiv.org/abs/2306.03110 ,  6157kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03175
Date: Mon, 5 Jun 2023 18:32:53 GMT   (4993kb,D)

Title: Infusing Lattice Symmetry Priors in Attention Mechanisms for
 Sample-Efficient Abstract Geometric Reasoning
Authors: Mattia Atzeni, Mrinmaya Sachan, Andreas Loukas
Categories: cs.AI cs.LG stat.ML
Comments: Accepted for publication at the International Conference on Machine
 Learning, ICML 2023
\\
 The Abstraction and Reasoning Corpus (ARC) (Chollet, 2019) and its most
recent language-complete instantiation (LARC) has been postulated as an
important step towards general AI. Yet, even state-of-the-art machine learning
models struggle to achieve meaningful performance on these problems, falling
behind non-learning based approaches. We argue that solving these tasks
requires extreme generalization that can only be achieved by proper accounting
for core knowledge priors. As a step towards this goal, we focus on geometry
priors and introduce LatFormer, a model that incorporates lattice symmetry
priors in attention masks. We show that, for any transformation of the
hypercubic lattice, there exists a binary attention mask that implements that
group action. Hence, our study motivates a modification to the standard
attention mechanism, where attention weights are scaled using soft masks
generated by a convolutional network. Experiments on synthetic geometric
reasoning show that LatFormer requires 2 orders of magnitude fewer data than
standard attention and transformers. Moreover, our results on ARC and LARC
tasks that incorporate geometric priors provide preliminary evidence that these
complex datasets do not lie out of the reach of deep learning models.
\\ ( https://arxiv.org/abs/2306.03175 ,  4993kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03197
Date: Mon, 5 Jun 2023 19:16:37 GMT   (340kb,D)

Title: AutoScrum: Automating Project Planning Using Large Language Models
Authors: Martin Schroder
Categories: cs.AI cs.CL
Comments: 25 pages, 3 figures, demo: https://github.com/autoscrum/autoscrum
\\
 Recent advancements in the field of large language models have made it
possible to use language models for advanced reasoning. In this paper we
leverage this ability for designing complex project plans based only on knowing
the current state and the desired state. Two approaches are demonstrated - a
scrum based approach and a shortcut plan approach. The scrum based approach
executes an automated process of requirements gathering, user story mapping,
feature identification, task decomposition and finally generates questions and
search terms for seeking out domain specific information to assist with task
completion. The shortcut approach looks at most recent snapshot of the current
and desired state and generates the next most reasonable task to do in order to
get to the desired state as quickly as possible. In this paper we automate
everything using a novel concept of "Language Programs". These are programs
written in natural language designed to process input data through the language
model. Guidance language is used for all LLM programs. All demo source code for
this paper is available at https://github.com/autoscrum/autoscrum
\\ ( https://arxiv.org/abs/2306.03197 ,  340kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03236
Date: Mon, 5 Jun 2023 20:45:30 GMT   (1454kb,D)

Title: A Study of Global and Episodic Bonuses for Exploration in Contextual
 MDPs
Authors: Mikael Henaff, Minqi Jiang, Roberta Raileanu
Categories: cs.AI
\\
 Exploration in environments which differ across episodes has received
increasing attention in recent years. Current methods use some combination of
global novelty bonuses, computed using the agent's entire training experience,
and \textit{episodic novelty bonuses}, computed using only experience from the
current episode. However, the use of these two types of bonuses has been ad-hoc
and poorly understood. In this work, we shed light on the behavior of these two
types of bonuses through controlled experiments on easily interpretable tasks
as well as challenging pixel-based settings. We find that the two types of
bonuses succeed in different settings, with episodic bonuses being most
effective when there is little shared structure across episodes and global
bonuses being effective when more structure is shared. We develop a conceptual
framework which makes this notion of shared structure precise by considering
the variance of the value function across contexts, and which provides a
unifying explanation of our empirical results. We furthermore find that
combining the two bonuses can lead to more robust performance across different
degrees of shared structure, and investigate different algorithmic choices for
defining and combining global and episodic bonuses based on function
approximation. This results in an algorithm which sets a new state of the art
across 16 tasks from the MiniHack suite used in prior work, and also performs
robustly on Habitat and Montezuma's Revenge.
\\ ( https://arxiv.org/abs/2306.03236 ,  1454kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03293
Date: Mon, 5 Jun 2023 22:38:21 GMT   (2467kb,D)

Title: Towards Fairness in Personalized Ads Using Impression Variance Aware
 Reinforcement Learning
Authors: Aditya Srinivas Timmaraju, Mehdi Mashayekhi, Mingliang Chen, Qi Zeng,
 Quintin Fettes, Wesley Cheung, Yihan Xiao, Manojkumar Rangasamy Kannadasan,
 Pushkar Tripathi, Sean Gahagan, Miranda Boge, Rob Roudani
Categories: cs.AI cs.CY
Comments: 11 pages, 7 figure, KDD 2023
DOI: 10.1145/3580305.3599916
\\
 Variances in ad impression outcomes across demographic groups are
increasingly considered to be potentially indicative of algorithmic bias in
personalized ads systems. While there are many definitions of fairness that
could be applicable in the context of personalized systems, we present a
framework which we call the Variance Reduction System (VRS) for achieving more
equitable outcomes in Meta's ads systems. VRS seeks to achieve a distribution
of impressions with respect to selected protected class (PC) attributes that
more closely aligns the demographics of an ad's eligible audience (a function
of advertiser targeting criteria) with the audience who sees that ad, in a
privacy-preserving manner. We first define metrics to quantify fairness gaps in
terms of ad impression variances with respect to PC attributes including gender
and estimated race. We then present the VRS for re-ranking ads in an impression
variance-aware manner. We evaluate VRS via extensive simulations over different
parameter choices and study the effect of the VRS on the chosen fairness
metric. We finally present online A/B testing results from applying VRS to
Meta's ads systems, concluding with a discussion of future work. We have
deployed the VRS to all users in the US for housing ads, resulting in
significant improvement in our fairness metric. VRS is the first large-scale
deployed framework for pursuing fairness for multiple PC attributes in online
advertising.
\\ ( https://arxiv.org/abs/2306.03293 ,  2467kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03310
Date: Mon, 5 Jun 2023 23:32:26 GMT   (43470kb,D)

Title: LIBERO: Benchmarking Knowledge Transfer for Lifelong Robot Learning
Authors: Bo Liu, Yifeng Zhu, Chongkai Gao, Yihao Feng, Qiang Liu, Yuke Zhu,
 Peter Stone
Categories: cs.AI
\\
 Lifelong learning offers a promising paradigm of building a generalist agent
that learns and adapts over its lifespan. Unlike traditional lifelong learning
problems in image and text domains, which primarily involve the transfer of
declarative knowledge of entities and concepts, lifelong learning in
decision-making (LLDM) also necessitates the transfer of procedural knowledge,
such as actions and behaviors. To advance research in LLDM, we introduce
LIBERO, a novel benchmark of lifelong learning for robot manipulation.
Specifically, LIBERO highlights five key research topics in LLDM: 1) how to
efficiently transfer declarative knowledge, procedural knowledge, or the
mixture of both; 2) how to design effective policy architectures and 3)
effective algorithms for LLDM; 4) the robustness of a lifelong learner with
respect to task ordering; and 5) the effect of model pretraining for LLDM. We
develop an extendible procedural generation pipeline that can in principle
generate infinitely many tasks. For benchmarking purpose, we create four task
suites (130 tasks in total) that we use to investigate the above-mentioned
research topics. To support sample-efficient learning, we provide high-quality
human-teleoperated demonstration data for all tasks. Our extensive experiments
present several insightful or even unexpected discoveries: sequential
finetuning outperforms existing lifelong learning methods in forward transfer,
no single visual encoder architecture excels at all types of knowledge
transfer, and naive supervised pretraining can hinder agents' performance in
the subsequent LLDM. Check the website at https://libero-project.github.io for
the code and the datasets.
\\ ( https://arxiv.org/abs/2306.03310 ,  43470kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03314
Date: Mon, 5 Jun 2023 23:55:37 GMT   (35kb,D)

Title: Multi-Agent Collaboration: Harnessing the Power of Intelligent LLM
 Agents
Authors: Yashar Talebirad and Amirhossein Nadiri
Categories: cs.AI cs.LG cs.MA
\\
 In this paper, we present a novel framework for enhancing the capabilities of
large language models (LLMs) by leveraging the power of multi-agent systems.
Our framework introduces a collaborative environment where multiple intelligent
agent components, each with distinctive attributes and roles, work together to
handle complex tasks more efficiently and effectively. We demonstrate the
practicality and versatility of our framework through case studies in
artificial general intelligence (AGI), specifically focusing on the Auto-GPT
and BabyAGI models. We also examine the "Gorilla" model, which integrates
external APIs into the LLM. Our framework addresses limitations and challenges
such as looping issues, security risks, scalability, system evaluation, and
ethical considerations. By modeling various domains such as courtroom
simulations and software development scenarios, we showcase the potential
applications and benefits of our proposed multi-agent system. Our framework
provides an avenue for advancing the capabilities and performance of LLMs
through collaboration and knowledge exchange among intelligent agents.
\\ ( https://arxiv.org/abs/2306.03314 ,  35kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03375
Date: Tue, 6 Jun 2023 03:29:47 GMT   (42610kb,D)

Title: Identifying Shared Decodable Concepts in the Human Brain Using
 Image-Language Foundation Models
Authors: Cory Efird, Alex Murphy, Joel Zylberberg, Alona Fyshe
Categories: cs.AI cs.CV
Comments: Under review
\\
 We introduce a method that takes advantage of high-quality pretrained
multimodal representations to explore fine-grained semantic networks in the
human brain. Previous studies have documented evidence of functional
localization in the brain, with different anatomical regions preferentially
activating for different types of sensory input. Many such localized structures
are known, including the fusiform face area and parahippocampal place area.
This raises the question of whether additional brain regions (or conjunctions
of brain regions) are also specialized for other important semantic concepts.
To identify such brain regions, we developed a data-driven approach to uncover
visual concepts that are decodable from a massive functional magnetic resonance
imaging (fMRI) dataset. Our analysis is broadly split into three sections.
First, a fully connected neural network is trained to map brain responses to
the outputs of an image-language foundation model, CLIP (Radford et al., 2021).
Subsequently, a contrastive-learning dimensionality reduction method reveals
the brain-decodable components of CLIP space. In the final section of our
analysis, we localize shared decodable concepts in the brain using a
voxel-masking optimization method to produce a shared decodable concept (SDC)
space. The accuracy of our procedure is validated by comparing it to previous
localization experiments that identify regions for faces, bodies, and places.
In addition to these concepts, whose corresponding brain regions were already
known, we localize novel concept representations which are shared across
participants to other areas of the human brain. We also demonstrate how this
method can be used to inspect fine-grained semantic networks for individual
participants. We envisage that this extensible method can also be adapted to
explore other questions at the intersection of AI and neuroscience.
\\ ( https://arxiv.org/abs/2306.03375 ,  42610kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03381
Date: Tue, 6 Jun 2023 03:43:11 GMT   (1021kb,D)

Title: VR.net: A Real-world Dataset for Virtual Reality Motion Sickness
 Research
Authors: Elliott Wen, Chitralekha Gupta, Prasanth Sasikumar, Mark Billinghurst,
 James Wilmott, Emily Skow, Arindam Dey, Suranga Nanayakkara
Categories: cs.AI
\\
 Researchers have used machine learning approaches to identify motion sickness
in VR experience. These approaches demand an accurately-labeled, real-world,
and diverse dataset for high accuracy and generalizability. As a starting point
to address this need, we introduce `VR.net', a dataset offering approximately
12-hour gameplay videos from ten real-world games in 10 diverse genres. For
each video frame, a rich set of motion sickness-related labels, such as
camera/object movement, depth field, and motion flow, are accurately assigned.
Building such a dataset is challenging since manual labeling would require an
infeasible amount of time. Instead, we utilize a tool to automatically and
precisely extract ground truth data from 3D engines' rendering pipelines
without accessing VR games' source code. We illustrate the utility of VR.net
through several applications, such as risk factor detection and sickness level
prediction. We continuously expand VR.net and envision its next version
offering 10X more data than the current form. We believe that the scale,
accuracy, and diversity of VR.net can offer unparalleled opportunities for VR
motion sickness research and beyond.
\\ ( https://arxiv.org/abs/2306.03381 ,  1021kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03387
Date: Tue, 6 Jun 2023 04:04:12 GMT   (7151kb,D)

Title: ColdNAS: Search to Modulate for User Cold-Start Recommendation
Authors: Shiguang Wu, Yaqing Wang, Qinghe Jing, Daxiang Dong, Dejing Dou,
 Quanming Yao
Categories: cs.AI
\\
 Making personalized recommendation for cold-start users, who only have a few
interaction histories, is a challenging problem in recommendation systems.
Recent works leverage hypernetworks to directly map user interaction histories
to user-specific parameters, which are then used to modulate predictor by
feature-wise linear modulation function. These works obtain the
state-of-the-art performance. However, the physical meaning of scaling and
shifting in recommendation data is unclear. Instead of using a fixed modulation
function and deciding modulation position by expertise, we propose a modulation
framework called ColdNAS for user cold-start problem, where we look for proper
modulation structure, including function and position, via neural architecture
search. We design a search space which covers broad models and theoretically
prove that this search space can be transformed to a much smaller space,
enabling an efficient and robust one-shot search algorithm. Extensive
experimental results on benchmark datasets show that ColdNAS consistently
performs the best. We observe that different modulation functions lead to the
best performance on different datasets, which validates the necessity of
designing a searching-based method.
\\ ( https://arxiv.org/abs/2306.03387 ,  7151kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03408
Date: Tue, 6 Jun 2023 05:11:58 GMT   (781kb,D)

Title: Agents Explore the Environment Beyond Good Actions to Improve Their
 Model for Better Decisions
Authors: Matthias Unverzagt
Categories: cs.AI cs.LG
Comments: Submitted to NeurIPS 2023
\\
 Improving the decision-making capabilities of agents is a key challenge on
the road to artificial intelligence. To improve the planning skills needed to
make good decisions, MuZero's agent combines prediction by a network model and
planning by a tree search using the predictions. MuZero's learning process can
fail when predictions are poor but planning requires them. We use this as an
impetus to get the agent to explore parts of the decision tree in the
environment that it otherwise would not explore. The agent achieves this, first
by normal planning to come up with an improved policy. Second, it randomly
deviates from this policy at the beginning of each training episode. And third,
it switches back to the improved policy at a random time step to experience the
rewards from the environment associated with the improved policy, which is the
basis for learning the correct value expectation. The simple board game
Tic-Tac-Toe is used to illustrate how this approach can improve the agent's
decision-making ability. The source code, written entirely in Java, is
available at https://github.com/enpasos/muzero.
\\ ( https://arxiv.org/abs/2306.03408 ,  781kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03409
Date: Tue, 6 Jun 2023 05:13:29 GMT   (35kb)

Title: Rigorous Runtime Analysis of MOEA/D for Solving Multi-Objective Minimum
 Weight Base Problems
Authors: Anh Viet Do, Aneta Neumann, Frank Neumann, Andrew M. Sutton
Categories: cs.AI cs.DS cs.NE
Comments: 12 pages
\\
 We study the multi-objective minimum weight base problem, an abstraction of
classical NP-hard combinatorial problems such as the multi-objective minimum
spanning tree problem. We prove some important properties of the convex hull of
the non-dominated front, such as its approximation quality and an upper bound
on the number of extreme points. Using these properties, we give the first
run-time analysis of the MOEA/D algorithm for this problem, an evolutionary
algorithm that effectively optimizes by decomposing the objectives into
single-objective components. We show that the MOEA/D, given an appropriate
decomposition setting, finds all extreme points within expected fixed-parameter
polynomial time in the oracle model, the parameter being the number of
objectives. Experiments are conducted on random bi-objective minimum spanning
tree instances, and the results agree with our theoretical findings.
Furthermore, compared with a previously studied evolutionary algorithm for the
problem GSEMO, MOEA/D finds all extreme points much faster across all
instances.
\\ ( https://arxiv.org/abs/2306.03409 ,  35kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03423
Date: Tue, 6 Jun 2023 05:50:58 GMT   (1443kb,D)

Title: I'm Afraid I Can't Do That: Predicting Prompt Refusal in Black-Box
 Generative Language Models
Authors: Max Reuter, William Schulze
Categories: cs.AI
Comments: Submitted for review to KDD 2023 via the workshop "Foundations and
 Applications in Large-scale AI Models: Pre-training, Fine-tuning, and
 Prompt-based Learning"
\\
 Since the release of OpenAI's ChatGPT, generative language models have
attracted extensive public attention. The increased usage has highlighted
generative models' broad utility, but also revealed several forms of embedded
bias. Some is induced by the pre-training corpus; but additional bias specific
to generative models arises from the use of subjective fine-tuning to avoid
generating harmful content. Fine-tuning bias may come from individual engineers
and company policies, and affects which prompts the model chooses to refuse. In
this experiment, we characterize ChatGPT's refusal behavior using a black-box
attack. We first query ChatGPT with a variety of offensive and benign prompts
(n=1,730), then manually label each response as compliance or refusal. Manual
examination of responses reveals that refusal is not cleanly binary, and lies
on a continuum; as such, we map several different kinds of responses to a
binary of compliance or refusal. The small manually-labeled dataset is used to
train a refusal classifier, which achieves an accuracy of 92%. Second, we use
this refusal classifier to bootstrap a larger (n=10,000) dataset adapted from
the Quora Insincere Questions dataset. With this machine-labeled data, we train
a prompt classifier to predict whether ChatGPT will refuse a given question,
without seeing ChatGPT's response. This prompt classifier achieves 76% accuracy
on a test set of manually labeled questions (n=1,009). We examine our
classifiers and the prompt n-grams that are most predictive of either
compliance or refusal. Datasets and code are available at
https://github.com/maxwellreuter/chatgpt-refusals.
\\ ( https://arxiv.org/abs/2306.03423 ,  1443kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03532
Date: Tue, 6 Jun 2023 09:30:48 GMT   (41kb)

Title: A Belief Model for Conflicting and Uncertain Evidence -- Connecting
 Dempster-Shafer Theory and the Topology of Evidence
Authors: Daira Pinto Prieto, Ronald de Haan, Ayb\"uke \"Ozg\"un
Categories: cs.AI cs.MA
Comments: To appear in the proceedings of KR 2023
\\
 One problem to solve in the context of information fusion, decision-making,
and other artificial intelligence challenges is to compute justified beliefs
based on evidence. In real-life examples, this evidence may be inconsistent,
incomplete, or uncertain, making the problem of evidence fusion highly
non-trivial. In this paper, we propose a new model for measuring degrees of
beliefs based on possibly inconsistent, incomplete, and uncertain evidence, by
combining tools from Dempster-Shafer Theory and Topological Models of Evidence.
Our belief model is more general than the aforementioned approaches in two
important ways: (1) it can reproduce them when appropriate constraints are
imposed, and, more notably, (2) it is flexible enough to compute beliefs
according to various standards that represent agents' evidential demands. The
latter novelty allows the users of our model to employ it to compute an agent's
(possibly) distinct degrees of belief, based on the same evidence, in
situations when, e.g, the agent prioritizes avoiding false negatives and when
it prioritizes avoiding false positives. Finally, we show that computing
degrees of belief with this model is #P-complete in general.
\\ ( https://arxiv.org/abs/2306.03532 ,  41kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03551
Date: Tue, 6 Jun 2023 09:57:04 GMT   (25966kb,D)

Title: Scalable Concept Extraction in Industry 4.0
Authors: Andr\'es Felipe Posada-Moreno, Kai M\"uller, Florian Brillowski,
 Friedrich Solowjow, Thomas Gries, Sebastian Trimpe
Categories: cs.AI cs.CV cs.LG
\\
 The industry 4.0 is leveraging digital technologies and machine learning
techniques to connect and optimize manufacturing processes. Central to this
idea is the ability to transform raw data into human understandable knowledge
for reliable data-driven decision-making. Convolutional Neural Networks (CNNs)
have been instrumental in processing image data, yet, their ``black box''
nature complicates the understanding of their prediction process. In this
context, recent advances in the field of eXplainable Artificial Intelligence
(XAI) have proposed the extraction and localization of concepts, or which
visual cues intervene on the prediction process of CNNs. This paper tackles the
application of concept extraction (CE) methods to industry 4.0 scenarios. To
this end, we modify a recently developed technique, ``Extracting Concepts with
Local Aggregated Descriptors'' (ECLAD), improving its scalability.
Specifically, we propose a novel procedure for calculating concept importance,
utilizing a wrapper function designed for CNNs. This process is aimed at
decreasing the number of times each image needs to be evaluated. Subsequently,
we demonstrate the potential of CE methods, by applying them in three
industrial use cases. We selected three representative use cases in the context
of quality control for material design (tailored textiles), manufacturing
(carbon fiber reinforcement), and maintenance (photovoltaic module inspection).
In these examples, CE was able to successfully extract and locate concepts
directly related to each task. This is, the visual cues related to each
concept, coincided with what human experts would use to perform the task
themselves, even when the visual cues were entangled between multiple classes.
Through empirical results, we show that CE can be applied for understanding
CNNs in an industrial context, giving useful insights that can relate to domain
knowledge.
\\ ( https://arxiv.org/abs/2306.03551 ,  25966kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03553
Date: Tue, 6 Jun 2023 10:08:12 GMT   (835kb,D)

Title: An Approach to Solving the Abstraction and Reasoning Corpus (ARC)
 Challenge
Authors: Tan John Chong Min
Categories: cs.AI
Comments: 14 pages
\\
 We utilise the power of Large Language Models (LLMs), in particular GPT4, to
be prompt engineered into performing an arbitrary task. Here, we give the model
some human priors via text, along with some typical procedures for solving the
ARC tasks, and ask it to generate the i) broad description of the input-output
relation, ii) detailed steps of the input-output mapping, iii) use the detailed
steps to perform manipulation on the test input and derive the test output. The
current GPT3.5/GPT4 prompt solves 2 out of 4 tested small ARC challenges (those
with small grids of 8x8 and below). With tweaks to the prompt to make it more
specific for the use case, it can solve more. We posit that when scaled to a
multi-agent system with usage of past memory and equipped with an image
interpretation tool via Visual Question Answering, we may actually be able to
solve the majority of the ARC challenge
\\ ( https://arxiv.org/abs/2306.03553 ,  835kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03601
Date: Tue, 6 Jun 2023 11:44:57 GMT   (13kb)

Title: The Creative Frontier of Generative AI: Managing the Novelty-Usefulness
 Tradeoff
Authors: Anirban Mukherjee and Hannah Chang
Categories: cs.AI
\\
 In this paper, drawing inspiration from the human creativity literature, we
explore the optimal balance between novelty and usefulness in generative
Artificial Intelligence (AI) systems. We posit that overemphasizing either
aspect can lead to limitations such as hallucinations and memorization.
Hallucinations, characterized by AI responses containing random inaccuracies or
falsehoods, emerge when models prioritize novelty over usefulness.
Memorization, where AI models reproduce content from their training data,
results from an excessive focus on usefulness, potentially limiting creativity.
To address these challenges, we propose a framework that includes
domain-specific analysis, data and transfer learning, user preferences and
customization, custom evaluation metrics, and collaboration mechanisms. Our
approach aims to generate content that is both novel and useful within specific
domains, while considering the unique requirements of various contexts.
\\ ( https://arxiv.org/abs/2306.03601 ,  13kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03604
Date: Tue, 6 Jun 2023 11:49:09 GMT   (588kb,D)

Title: Enabling Efficient Interaction between an Algorithm Agent and an LLM: A
 Reinforcement Learning Approach
Authors: Bin Hu, Chenyang Zhao, Pu Zhang, Zihao Zhou, Yuanhang Yang, Zenglin
 Xu, Bin Liu
Categories: cs.AI
Comments: 10 pages
\\
 Large language models (LLMs) encode a vast amount of world knowledge acquired
from massive text datasets. Recent studies have demonstrated that LLMs can
assist an algorithm agent in solving complex sequential decision making tasks
in embodied environments by providing high-level instructions. However,
interacting with LLMs can be time-consuming, as in many practical scenarios,
they require a significant amount of storage space that can only be deployed on
remote cloud server nodes. Additionally, using commercial LLMs can be costly
since they may charge based on usage frequency. In this paper, we explore how
to enable efficient and cost-effective interactions between the agent and an
LLM. We propose a reinforcement learning based mediator model that determines
when it is necessary to consult LLMs for high-level instructions to accomplish
a target task. Experiments on 4 MiniGrid environments that entail planning
sub-goals demonstrate that our method can learn to solve target tasks with only
a few necessary interactions with an LLM, significantly reducing interaction
costs in testing environments, compared with baseline methods. Experimental
results also suggest that by learning a mediator model to interact with the
LLM, the agent's performance becomes more robust against both exploratory and
stochastic environments.
\\ ( https://arxiv.org/abs/2306.03604 ,  588kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03606
Date: Tue, 6 Jun 2023 11:49:38 GMT   (299kb,D)

Title: BioBLP: A Modular Framework for Learning on Multimodal Biomedical
 Knowledge Graphs
Authors: Daniel Daza, Dimitrios Alivanistos, Payal Mitra, Thom Pijnenburg,
 Michael Cochez, Paul Groth
Categories: cs.AI
\\
 Knowledge graphs (KGs) are an important tool for representing complex
relationships between entities in the biomedical domain. Several methods have
been proposed for learning embeddings that can be used to predict new links in
such graphs. Some methods ignore valuable attribute data associated with
entities in biomedical KGs, such as protein sequences, or molecular graphs.
Other works incorporate such data, but assume that entities can be represented
with the same data modality. This is not always the case for biomedical KGs,
where entities exhibit heterogeneous modalities that are central to their
representation in the subject domain.
 We propose a modular framework for learning embeddings in KGs with entity
attributes, that allows encoding attribute data of different modalities while
also supporting entities with missing attributes. We additionally propose an
efficient pretraining strategy for reducing the required training runtime. We
train models using a biomedical KG containing approximately 2 million triples,
and evaluate the performance of the resulting entity embeddings on the tasks of
link prediction, and drug-protein interaction prediction, comparing against
methods that do not take attribute data into account. In the standard link
prediction evaluation, the proposed method results in competitive, yet lower
performance than baselines that do not use attribute data. When evaluated in
the task of drug-protein interaction prediction, the method compares favorably
with the baselines. We find settings involving low degree entities, which make
up for a substantial amount of the set of entities in the KG, where our method
outperforms the baselines. Our proposed pretraining strategy yields
significantly higher performance while reducing the required training runtime.
 Our implementation is available at https://github.com/elsevier-AI-Lab/BioBLP .
\\ ( https://arxiv.org/abs/2306.03606 ,  299kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03659
Date: Tue, 6 Jun 2023 13:22:54 GMT   (1312kb,D)

Title: Schema First! Learn Versatile Knowledge Graph Embeddings by Capturing
 Semantics with MASCHInE
Authors: Nicolas Hubert, Heiko Paulheim, Pierre Monnin, Armelle Brun, Davy
 Monticolo
Categories: cs.AI cs.LG
\\
 Knowledge graph embedding models (KGEMs) have gained considerable traction in
recent years. These models learn a vector representation of knowledge graph
entities and relations, a.k.a. knowledge graph embeddings (KGEs). Learning
versatile KGEs is desirable as it makes them useful for a broad range of tasks.
However, KGEMs are usually trained for a specific task, which makes their
embeddings task-dependent. In parallel, the widespread assumption that KGEMs
actually create a semantic representation of the underlying entities and
relations (e.g., project similar entities closer than dissimilar ones) has been
challenged. In this work, we design heuristics for generating protographs --
small, modified versions of a KG that leverage schema-based information. The
learnt protograph-based embeddings are meant to encapsulate the semantics of a
KG, and can be leveraged in learning KGEs that, in turn, also better capture
semantics. Extensive experiments on various evaluation benchmarks demonstrate
the soundness of this approach, which we call Modular and Agnostic SCHema-based
Integration of protograph Embeddings (MASCHInE). In particular, MASCHInE helps
produce more versatile KGEs that yield substantially better performance for
entity clustering and node classification tasks. For link prediction, using
MASCHInE has little impact on rank-based performance but increases the number
of semantically valid predictions.
\\ ( https://arxiv.org/abs/2306.03659 ,  1312kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03717
Date: Tue, 6 Jun 2023 14:27:03 GMT   (1187kb,D)

Title: Description Logics with Abstraction and Refinement
Authors: Carsten Lutz, Lukas Schulze
Categories: cs.AI cs.LO
Comments: 25 pages, Long version of paper accepted at KR 2023
\\
 Ontologies often require knowledge representation on multiple levels of
abstraction, but description logics (DLs) are not well-equipped for supporting
this. We propose an extension of DLs in which abstraction levels are
first-class citizens and which provides explicit operators for the abstraction
and refinement of concepts and roles across multiple abstraction levels, based
on conjunctive queries. We prove that reasoning in the resulting family of DLs
is decidable while several seemingly harmless variations turn out to be
undecidable. We also pinpoint the precise complexity of our logics and several
relevant fragments.
\\ ( https://arxiv.org/abs/2306.03717 ,  1187kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03753
Date: Tue, 6 Jun 2023 15:13:58 GMT   (414kb)

Title: Newly Formed Cities: an AI Curation
Authors: Dario Negueruela del Castillo, Ludovica Schaerf, Pepe Ballesteros,
 Iacopo Neri, Valentine Bernasconi
Categories: cs.AI cs.CV
\\
 Art curatorial processes are characterized by the presentation of a
collection of artworks in a knowledgeable way. Machine processes are
characterized by their capacity to manage and analyze large amounts of data.
This paper envisages machine curation and audience interaction as a means to
explore the implications of contemporary AI models for the curatorial world.
This project was developed for the occasion of the 2023 Helsinki Art Biennial,
entitled New Directions May Emerge. We use the Helsinki Art Museum (HAM)
collection to re-imagine the city of Helsinki through the lens of machine
perception. We use visual-textual models to place artworks currently hosted
inside the museum in outdoor public spaces of the city, assigning fictional
coordinates based on similarity scores. Synthetic 360{\deg} art panoramas are
generated using diffusion-based models to propose a machinic visual style
guided by the artworks. The result of this project will be virtually presented
as a web-based installation, where such a re-contextualization allows the
navigation of an alternative version of the city while exploring its artistic
heritage. Finally, we discuss our contributions to machine curation and the
ethical implications that such a process entails. The web-based installation is
available at this link: http://newlyformedcity.com/.
\\ ( https://arxiv.org/abs/2306.03753 ,  414kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03795
Date: Tue, 6 Jun 2023 15:40:27 GMT   (276kb,D)

Title: AI-Supported Assessment of Load Safety
Authors: Julius Sch\"oning and Niklas Kruse
Categories: cs.AI cs.HC cs.LG
Comments: 9 pages, 4 figures, 2 tables
\\
 Load safety assessment and compliance is an essential step in the corporate
process of every logistics service provider. In 2020, a total of 11,371 police
checks of trucks were carried out, during which 9.6% (1091) violations against
the load safety regulations were detected. For a logistic service provider,
every load safety violation results in height fines and damage to reputation.
An assessment of load safety supported by artificial intelligence (AI) will
reduce the risk of accidents by unsecured loads and fines during safety
assessments. This work shows how photos of the load, taken by the truck driver
or the loadmaster after the loading process, can be used to assess load safety.
By a trained two-stage artificial neural network (ANN), these photos are
classified into three different classes I) cargo loaded safely, II) cargo
loaded unsafely, and III) unusable image. By applying several architectures of
convolutional neural networks (CNN), it can be shown that it is possible to
distinguish between unusable and usable images for cargo safety assessment.
This distinction is quite crucial since the truck driver and the loadmaster
sometimes provide photos without the essential image features like the case
structure of the truck and the whole cargo. A human operator or another ANN
will then assess the load safety within the second stage.
\\ ( https://arxiv.org/abs/2306.03795 ,  276kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03842
Date: Tue, 6 Jun 2023 16:29:31 GMT   (7kb)

Title: Remarks on Utility in Repeated Bets
Authors: Nimrod Megiddo
Categories: cs.AI math.PR
\\
 The use of von Neumann -- Morgenstern utility is examined in the context of
multiple choices between lotteries. Different conclusions are reached if the
choices are simultaneous or sequential. It is demonstrated that utility cannot
be additive.
\\ ( https://arxiv.org/abs/2306.03842 ,  7kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03849
Date: Tue, 6 Jun 2023 16:39:58 GMT   (978kb,D)

Title: Considering Human Factors in Risk Maps for Robust and Foresighted Driver
 Warning
Authors: Tim Puphal, Ryohei Hirano, Malte Probst, Raphael Wenzel and Akihito
 Kimata
Categories: cs.AI cs.HC
Report-no: Accepted at IEEE ROMAN 2023
\\
 Driver support systems that include human states in the support process is an
active research field. Many recent approaches allow, for example, to sense the
driver's drowsiness or awareness of the driving situation. However, so far,
this rich information has not been utilized much for improving the
effectiveness of support systems. In this paper, we therefore propose a warning
system that uses human states in the form of driver errors and can warn users
in some cases of upcoming risks several seconds earlier than the state of the
art systems not considering human factors. The system consists of a behavior
planner Risk Maps which directly changes its prediction of the surrounding
driving situation based on the sensed driver errors. By checking if this
driver's behavior plan is objectively safe, a more robust and foresighted
driver warning is achieved. In different simulations of a dynamic lane change
and intersection scenarios, we show how the driver's behavior plan can become
unsafe, given the estimate of driver errors, and experimentally validate the
advantages of considering human factors.
\\ ( https://arxiv.org/abs/2306.03849 ,  978kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03874
Date: Tue, 6 Jun 2023 17:21:21 GMT   (41kb)

Title: Embracing Background Knowledge in the Analysis of Actual Causality: An
 Answer Set Programming Approach
Authors: Michael Gelfond, Jorge Fandinno and Evgenii Balai
Categories: cs.AI cs.LO
Comments: Under consideration for publication in Theory and Practice of Logic
 Programming
\\
 This paper presents a rich knowledge representation language aimed at
formalizing causal knowledge. This language is used for accurately and directly
formalizing common benchmark examples from the literature of actual causality.
A definition of cause is presented and used to analyze the actual causes of
changes with respect to sequences of actions representing those examples.
\\ ( https://arxiv.org/abs/2306.03874 ,  41kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03901
Date: Tue, 6 Jun 2023 17:58:24 GMT   (297kb,D)

Title: ChatDB: Augmenting LLMs with Databases as Their Symbolic Memory
Authors: Chenxu Hu, Jie Fu, Chenzhuang Du, Simian Luo, Junbo Zhao, Hang Zhao
Categories: cs.AI cs.CL cs.DB cs.LG
\\
 Large language models (LLMs) with memory are computationally universal.
However, mainstream LLMs are not taking full advantage of memory, and the
designs are heavily influenced by biological brains. Due to their approximate
nature and proneness to the accumulation of errors, conventional neural memory
mechanisms cannot support LLMs to simulate complex reasoning. In this paper, we
seek inspiration from modern computer architectures to augment LLMs with
symbolic memory for complex multi-hop reasoning. Such a symbolic memory
framework is instantiated as an LLM and a set of SQL databases, where the LLM
generates SQL instructions to manipulate the SQL databases. We validate the
effectiveness of the proposed memory framework on a synthetic dataset requiring
complex reasoning. The project website is available at
https://chatdatabase.github.io/ .
\\ ( https://arxiv.org/abs/2306.03901 ,  297kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03151
Date: Mon, 5 Jun 2023 18:04:57 GMT   (1685kb,D)

Title: DISCount: Counting in Large Image Collections with Detector-Based
 Importance Sampling
Authors: Gustavo Perez, Subhransu Maji, Daniel Sheldon
Categories: cs.CV cs.LG
\\
 Many modern applications use computer vision to detect and count objects in
massive image collections. However, when the detection task is very difficult
or in the presence of domain shifts, the counts may be inaccurate even with
significant investments in training data and model development. We propose
DISCount -- a detector-based importance sampling framework for counting in
large image collections that integrates an imperfect detector with
human-in-the-loop screening to produce unbiased estimates of counts. We propose
techniques for solving counting problems over multiple spatial or temporal
regions using a small number of screened samples and estimate confidence
intervals. This enables end-users to stop screening when estimates are
sufficiently accurate, which is often the goal in a scientific study. On the
technical side we develop variance reduction techniques based on control
variates and prove the (conditional) unbiasedness of the estimators. DISCount
leads to a 9-12x reduction in the labeling costs over naive screening for tasks
we consider, such as counting birds in radar imagery or estimating damaged
buildings in satellite imagery, and also surpasses alternative covariate-based
screening approaches in efficiency.
\\ ( https://arxiv.org/abs/2306.03151 ,  1685kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03206
Date: Mon, 5 Jun 2023 19:28:19 GMT   (1947kb,D)

Title: MoDAR: Using Motion Forecasting for 3D Object Detection in Point Cloud
 Sequences
Authors: Yingwei Li, Charles R. Qi, Yin Zhou, Chenxi Liu, Dragomir Anguelov
Categories: cs.CV
Comments: CVPR 2023
\\
 Occluded and long-range objects are ubiquitous and challenging for 3D object
detection. Point cloud sequence data provide unique opportunities to improve
such cases, as an occluded or distant object can be observed from different
viewpoints or gets better visibility over time. However, the efficiency and
effectiveness in encoding long-term sequence data can still be improved. In
this work, we propose MoDAR, using motion forecasting outputs as a type of
virtual modality, to augment LiDAR point clouds. The MoDAR modality propagates
object information from temporal contexts to a target frame, represented as a
set of virtual points, one for each object from a waypoint on a forecasted
trajectory. A fused point cloud of both raw sensor points and the virtual
points can then be fed to any off-the-shelf point-cloud based 3D object
detector. Evaluated on the Waymo Open Dataset, our method significantly
improves prior art detectors by using motion forecasting from extra-long
sequences (e.g. 18 seconds), achieving new state of the arts, while not adding
much computation overhead.
\\ ( https://arxiv.org/abs/2306.03206 ,  1947kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03222
Date: Mon, 5 Jun 2023 20:16:19 GMT   (178kb,D)

Title: Confidence-based federated distillation for vision-based lane-centering
Authors: Yitao Chen, Dawei Chen, Haoxin Wang, Kyungtae Han, Ming Zhao
Categories: cs.CV
Comments: 5 pages, 5 figures
\\
 A fundamental challenge of autonomous driving is maintaining the vehicle in
the center of the lane by adjusting the steering angle. Recent advances
leverage deep neural networks to predict steering decisions directly from
images captured by the car cameras. Machine learning-based steering angle
prediction needs to consider the vehicle's limitation in uploading large
amounts of potentially private data for model training. Federated learning can
address these constraints by enabling multiple vehicles to collaboratively
train a global model without sharing their private data, but it is difficult to
achieve good accuracy as the data distribution is often non-i.i.d. across the
vehicles. This paper presents a new confidence-based federated distillation
method to improve the performance of federated learning for steering angle
prediction. Specifically, it proposes the novel use of entropy to determine the
predictive confidence of each local model, and then selects the most confident
local model as the teacher to guide the learning of the global model. A
comprehensive evaluation of vision-based lane centering shows that the proposed
approach can outperform FedAvg and FedDF by 11.3% and 9%, respectively.
\\ ( https://arxiv.org/abs/2306.03222 ,  178kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03229
Date: Mon, 5 Jun 2023 20:26:17 GMT   (31513kb,D)

Title: Adversarial alignment: Breaking the trade-off between the strength of an
 attack and its relevance to human perception
Authors: Drew Linsley, Pinyuan Feng, Thibaut Boissin, Alekh Karkada Ashok,
 Thomas Fel, Stephanie Olaiya, Thomas Serre
Categories: cs.CV cs.AI
\\
 Deep neural networks (DNNs) are known to have a fundamental sensitivity to
adversarial attacks, perturbations of the input that are imperceptible to
humans yet powerful enough to change the visual decision of a model.
Adversarial attacks have long been considered the "Achilles' heel" of deep
learning, which may eventually force a shift in modeling paradigms.
Nevertheless, the formidable capabilities of modern large-scale DNNs have
somewhat eclipsed these early concerns. Do adversarial attacks continue to pose
a threat to DNNs?
 Here, we investigate how the robustness of DNNs to adversarial attacks has
evolved as their accuracy on ImageNet has continued to improve. We measure
adversarial robustness in two different ways: First, we measure the smallest
adversarial attack needed to cause a model to change its object categorization
decision. Second, we measure how aligned successful attacks are with the
features that humans find diagnostic for object recognition. We find that
adversarial attacks are inducing bigger and more easily detectable changes to
image pixels as DNNs grow better on ImageNet, but these attacks are also
becoming less aligned with features that humans find diagnostic for
recognition. To better understand the source of this trade-off, we turn to the
neural harmonizer, a DNN training routine that encourages models to leverage
the same features as humans to solve tasks. Harmonized DNNs achieve the best of
both worlds and experience attacks that are detectable and affect features that
humans find diagnostic for recognition, meaning that attacks on these models
are more likely to be rendered ineffective by inducing similar effects on human
perception. Our findings suggest that the sensitivity of DNNs to adversarial
attacks can be mitigated by DNN scale, data scale, and training routines that
align models with biological intelligence.
\\ ( https://arxiv.org/abs/2306.03229 ,  31513kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03253
Date: Mon, 5 Jun 2023 21:14:23 GMT   (29979kb,D)

Title: Zero-Shot 3D Shape Correspondence
Authors: Ahmed Abdelreheem, Abdelrahman Eldesokey, Maks Ovsjanikov, Peter Wonka
Categories: cs.CV
\\
 We propose a novel zero-shot approach to computing correspondences between 3D
shapes. Existing approaches mainly focus on isometric and near-isometric shape
pairs (e.g., human vs. human), but less attention has been given to strongly
non-isometric and inter-class shape matching (e.g., human vs. cow). To this
end, we introduce a fully automatic method that exploits the exceptional
reasoning capabilities of recent foundation models in language and vision to
tackle difficult shape correspondence problems. Our approach comprises multiple
stages. First, we classify the 3D shapes in a zero-shot manner by feeding
rendered shape views to a language-vision model (e.g., BLIP2) to generate a
list of class proposals per shape. These proposals are unified into a single
class per shape by employing the reasoning capabilities of ChatGPT. Second, we
attempt to segment the two shapes in a zero-shot manner, but in contrast to the
co-segmentation problem, we do not require a mutual set of semantic regions.
Instead, we propose to exploit the in-context learning capabilities of ChatGPT
to generate two different sets of semantic regions for each shape and a
semantic mapping between them. This enables our approach to match strongly
non-isometric shapes with significant differences in geometric structure.
Finally, we employ the generated semantic mapping to produce coarse
correspondences that can further be refined by the functional maps framework to
produce dense point-to-point maps. Our approach, despite its simplicity,
produces highly plausible results in a zero-shot manner, especially between
strongly non-isometric shapes.
\\ ( https://arxiv.org/abs/2306.03253 ,  29979kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03287
Date: Mon, 5 Jun 2023 22:20:52 GMT   (1532kb,D)

Title: ICDAR 2023 Competition on Structured Text Extraction from Visually-Rich
 Document Images
Authors: Wenwen Yu, Chengquan Zhang, Haoyu Cao, Wei Hua, Bohan Li, Huang Chen,
 Mingyu Liu, Mingrui Chen, Jianfeng Kuang, Mengjun Cheng, Yuning Du, Shikun
 Feng, Xiaoguang Hu, Pengyuan Lyu, Kun Yao, Yuechen Yu, Yuliang Liu, Wanxiang
 Che, Errui Ding, Cheng-Lin Liu, Jiebo Luo, Shuicheng Yan, Min Zhang,
 Dimosthenis Karatzas, Xing Sun, Jingdong Wang, and Xiang Bai
Categories: cs.CV
Comments: ICDAR 2023 Competition on SVRD report (To be appear in ICDAR 2023)
\\
 Structured text extraction is one of the most valuable and challenging
application directions in the field of Document AI. However, the scenarios of
past benchmarks are limited, and the corresponding evaluation protocols usually
focus on the submodules of the structured text extraction scheme. In order to
eliminate these problems, we organized the ICDAR 2023 competition on Structured
text extraction from Visually-Rich Document images (SVRD). We set up two tracks
for SVRD including Track 1: HUST-CELL and Track 2: Baidu-FEST, where HUST-CELL
aims to evaluate the end-to-end performance of Complex Entity Linking and
Labeling, and Baidu-FEST focuses on evaluating the performance and
generalization of Zero-shot / Few-shot Structured Text extraction from an
end-to-end perspective. Compared to the current document benchmarks, our two
tracks of competition benchmark enriches the scenarios greatly and contains
more than 50 types of visually-rich document images (mainly from the actual
enterprise applications). The competition opened on 30th December, 2022 and
closed on 24th March, 2023. There are 35 participants and 91 valid submissions
received for Track 1, and 15 participants and 26 valid submissions received for
Track 2. In this report we will presents the motivation, competition datasets,
task definition, evaluation protocol, and submission summaries. According to
the performance of the submissions, we believe there is still a large gap on
the expected information extraction performance for complex and zero-shot
scenarios. It is hoped that this competition will attract many researchers in
the field of CV and NLP, and bring some new thoughts to the field of Document
AI.
\\ ( https://arxiv.org/abs/2306.03287 ,  1532kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03318
Date: Tue, 6 Jun 2023 00:01:40 GMT   (7729kb,D)

Title: Student Classroom Behavior Detection based on Improved YOLOv7
Authors: Fan Yang
Categories: cs.CV
Comments: arXiv admin note: text overlap with arXiv:2305.07825
\\
 Accurately detecting student behavior in classroom videos can aid in
analyzing their classroom performance and improving teaching effectiveness.
However, the current accuracy rate in behavior detection is low. To address
this challenge, we propose the Student Classroom Behavior Detection method,
based on improved YOLOv7. First, we created the Student Classroom Behavior
dataset (SCB-Dataset), which includes 18.4k labels and 4.2k images, covering
three behaviors: hand raising, reading, and writing. To improve detection
accuracy in crowded scenes, we integrated the biformer attention module and
Wise-IoU into the YOLOv7 network. Finally, experiments were conducted on the
SCB-Dataset, and the model achieved an mAP@0.5 of 79%, resulting in a 1.8%
improvement over previous results. The SCB-Dataset and code are available for
download at: https://github.com/Whiffe/SCB-dataset.
\\ ( https://arxiv.org/abs/2306.03318 ,  7729kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03331
Date: Tue, 6 Jun 2023 01:02:31 GMT   (3279kb)

Title: A Robust Likelihood Model for Novelty Detection
Authors: Ranya Almohsen, Shivang Patel, Donald A. Adjeroh, Gianfranco Doretto
Categories: cs.CV cs.LG
Comments: CVPR Workshop on Computer Vision in the Wild, 2023
\\
 Current approaches to novelty or anomaly detection are based on deep neural
networks. Despite their effectiveness, neural networks are also vulnerable to
imperceptible deformations of the input data. This is a serious issue in
critical applications, or when data alterations are generated by an adversarial
attack. While this is a known problem that has been studied in recent years for
the case of supervised learning, the case of novelty detection has received
very limited attention. Indeed, in this latter setting the learning is
typically unsupervised because outlier data is not available during training,
and new approaches for this case need to be investigated. We propose a new
prior that aims at learning a robust likelihood for the novelty test, as a
defense against attacks. We also integrate the same prior with a
state-of-the-art novelty detection approach. Because of the geometric
properties of that approach, the resulting robust training is computationally
very efficient. An initial evaluation of the method indicates that it is
effective at improving performance with respect to the standard models in the
absence and presence of attacks.
\\ ( https://arxiv.org/abs/2306.03331 ,  3279kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03374
Date: Tue, 6 Jun 2023 03:25:09 GMT   (17710kb,D)

Title: PGformer: Proxy-Bridged Game Transformer for Multi-Person Extremely
 Interactive Motion Prediction
Authors: Yanwen Fang, Chao Li, Jintai Chen, Pengtao Jiang, Yifeng Geng,
 Xuansong Xie, Eddy K.F. LAM, Guodong Li
Categories: cs.CV
\\
 Multi-person motion prediction is a challenging task, especially for
real-world scenarios of densely interacted persons. Most previous works have
been devoted to studying the case of weak interactions (e.g., hand-shaking),
which typically forecast each human pose in isolation. In this paper, we focus
on motion prediction for multiple persons with extreme collaborations and
attempt to explore the relationships between the highly interactive persons'
motion trajectories. Specifically, a novel cross-query attention (XQA) module
is proposed to bilaterally learn the cross-dependencies between the two pose
sequences tailored for this situation. Additionally, we introduce and build a
proxy entity to bridge the involved persons, which cooperates with our proposed
XQA module and subtly controls the bidirectional information flows, acting as a
motion intermediary. We then adapt these designs to a Transformer-based
architecture and devise a simple yet effective end-to-end framework called
proxy-bridged game Transformer (PGformer) for multi-person interactive motion
prediction. The effectiveness of our method has been evaluated on the
challenging ExPI dataset, which involves highly interactive actions. We show
that our PGformer consistently outperforms the state-of-the-art methods in both
short- and long-term predictions by a large margin. Besides, our approach can
also be compatible with the weakly interacted CMU-Mocap and MuPoTS-3D datasets
and achieve encouraging results. Our code will become publicly available upon
acceptance.
\\ ( https://arxiv.org/abs/2306.03374 ,  17710kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03377
Date: Tue, 6 Jun 2023 03:37:41 GMT   (5430kb,D)

Title: TextFormer: A Query-based End-to-End Text Spotter with Mixed Supervision
Authors: Yukun Zhai, Xiaoqiang Zhang, Xiameng Qin, Sanyuan Zhao, Xingping Dong,
 Jianbing Shen
Categories: cs.CV cs.CL
Comments: MIR 2023, 15 pages
\\
 End-to-end text spotting is a vital computer vision task that aims to
integrate scene text detection and recognition into a unified framework.
Typical methods heavily rely on Region-of-Interest (RoI) operations to extract
local features and complex post-processing steps to produce final predictions.
To address these limitations, we propose TextFormer, a query-based end-to-end
text spotter with Transformer architecture. Specifically, using query embedding
per text instance, TextFormer builds upon an image encoder and a text decoder
to learn a joint semantic understanding for multi-task modeling. It allows for
mutual training and optimization of classification, segmentation, and
recognition branches, resulting in deeper feature sharing without sacrificing
flexibility or simplicity. Additionally, we design an Adaptive Global
aGgregation (AGG) module to transfer global features into sequential features
for reading arbitrarily-shaped texts, which overcomes the sub-optimization
problem of RoI operations. Furthermore, potential corpus information is
utilized from weak annotations to full labels through mixed supervision,
further improving text detection and end-to-end text spotting results.
Extensive experiments on various bilingual (i.e., English and Chinese)
benchmarks demonstrate the superiority of our method. Especially on TDA-ReCTS
dataset, TextFormer surpasses the state-of-the-art method in terms of 1-NED by
13.2%.
\\ ( https://arxiv.org/abs/2306.03377 ,  5430kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03380
Date: Tue, 6 Jun 2023 03:40:29 GMT   (6189kb,D)

Title: A Unified Framework to Super-Resolve Face Images of Varied Low
 Resolutions
Authors: Qiuyu Peng, Zifei Jiang, Yan Huang and Jingliang Peng
Categories: cs.CV
\\
 The existing face image super-resolution (FSR) algorithms usually train a
specific model for a specific low input resolution for optimal results. By
contrast, we explore in this work a unified framework that is trained once and
then used to super-resolve input face images of varied low resolutions. For
that purpose, we propose a novel neural network architecture that is composed
of three anchor auto-encoders, one feature weight regressor and a final image
decoder. The three anchor auto-encoders are meant for optimal FSR for three
pre-defined low input resolutions, or named anchor resolutions, respectively.
An input face image of an arbitrary low resolution is firstly up-scaled to the
target resolution by bi-cubic interpolation and then fed to the three
auto-encoders in parallel. The three encoded anchor features are then fused
with weights determined by the feature weight regressor. At last, the fused
feature is sent to the final image decoder to derive the super-resolution
result. As shown by experiments, the proposed algorithm achieves robust and
state-of-the-art performance over a wide range of low input resolutions by a
single framework. Code and models will be made available after the publication
of this work.
\\ ( https://arxiv.org/abs/2306.03380 ,  6189kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03400
Date: Tue, 6 Jun 2023 04:30:18 GMT   (2304kb,D)

Title: G-CAME: Gaussian-Class Activation Mapping Explainer for Object Detectors
Authors: Quoc Khanh Nguyen, Truong Thanh Hung Nguyen, Vo Thanh Khang Nguyen,
 Van Binh Truong, Quoc Hung Cao
Categories: cs.CV cs.AI cs.LG
Comments: 10 figures
\\
 Nowadays, deep neural networks for object detection in images are very
prevalent. However, due to the complexity of these networks, users find it hard
to understand why these objects are detected by models. We proposed Gaussian
Class Activation Mapping Explainer (G-CAME), which generates a saliency map as
the explanation for object detection models. G-CAME can be considered a
CAM-based method that uses the activation maps of selected layers combined with
the Gaussian kernel to highlight the important regions in the image for the
predicted box. Compared with other Region-based methods, G-CAME can transcend
time constraints as it takes a very short time to explain an object. We also
evaluated our method qualitatively and quantitatively with YOLOX on the MS-COCO
2017 dataset and guided to apply G-CAME into the two-stage Faster-RCNN model.
\\ ( https://arxiv.org/abs/2306.03400 ,  2304kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03403
Date: Tue, 6 Jun 2023 04:49:51 GMT   (19721kb,D)

Title: SGAT4PASS: Spherical Geometry-Aware Transformer for PAnoramic Semantic
 Segmentation
Authors: Xuewei Li, Tao Wu, Zhongang Qi, Gaoang Wang, Ying Shan, Xi Li
Categories: cs.CV cs.AI cs.LG cs.MM
Comments: Accepted by IJCAI 2023
\\
 As an important and challenging problem in computer vision, PAnoramic
Semantic Segmentation (PASS) gives complete scene perception based on an
ultra-wide angle of view. Usually, prevalent PASS methods with 2D panoramic
image input focus on solving image distortions but lack consideration of the 3D
properties of original $360^{\circ}$ data. Therefore, their performance will
drop a lot when inputting panoramic images with the 3D disturbance. To be more
robust to 3D disturbance, we propose our Spherical Geometry-Aware Transformer
for PAnoramic Semantic Segmentation (SGAT4PASS), considering 3D spherical
geometry knowledge. Specifically, a spherical geometry-aware framework is
proposed for PASS. It includes three modules, i.e., spherical geometry-aware
image projection, spherical deformable patch embedding, and a panorama-aware
loss, which takes input images with 3D disturbance into account, adds a
spherical geometry-aware constraint on the existing deformable patch embedding,
and indicates the pixel density of original $360^{\circ}$ data, respectively.
Experimental results on Stanford2D3D Panoramic datasets show that SGAT4PASS
significantly improves performance and robustness, with approximately a 2%
increase in mIoU, and when small 3D disturbances occur in the data, the
stability of our performance is improved by an order of magnitude. Our code and
supplementary material are available at
https://github.com/TencentARC/SGAT4PASS.
\\ ( https://arxiv.org/abs/2306.03403 ,  19721kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03413
Date: Tue, 6 Jun 2023 05:24:15 GMT   (20244kb,D)

Title: DVIS: Decoupled Video Instance Segmentation Framework
Authors: Tao Zhang, Xingye Tian, Yu Wu, Shunping Ji, Xuebo Wang, Yuan Zhang,
 Pengfei Wan
Categories: cs.CV
\\
 Video instance segmentation (VIS) is a critical task with diverse
applications, including autonomous driving and video editing. Existing methods
often underperform on complex and long videos in real world, primarily due to
two factors. Firstly, offline methods are limited by the tightly-coupled
modeling paradigm, which treats all frames equally and disregards the
interdependencies between adjacent frames. Consequently, this leads to the
introduction of excessive noise during long-term temporal alignment. Secondly,
online methods suffer from inadequate utilization of temporal information. To
tackle these challenges, we propose a decoupling strategy for VIS by dividing
it into three independent sub-tasks: segmentation, tracking, and refinement.
The efficacy of the decoupling strategy relies on two crucial elements: 1)
attaining precise long-term alignment outcomes via frame-by-frame association
during tracking, and 2) the effective utilization of temporal information
predicated on the aforementioned accurate alignment outcomes during refinement.
We introduce a novel referring tracker and temporal refiner to construct the
\textbf{D}ecoupled \textbf{VIS} framework (\textbf{DVIS}). DVIS achieves new
SOTA performance in both VIS and VPS, surpassing the current SOTA methods by
7.3 AP and 9.6 VPQ on the OVIS and VIPSeg datasets, which are the most
challenging and realistic benchmarks. Moreover, thanks to the decoupling
strategy, the referring tracker and temporal refiner are super light-weight
(only 1.69\% of the segmenter FLOPs), allowing for efficient training and
inference on a single GPU with 11G memory. The code is available at
\href{https://github.com/zhang-tao-whu/DVIS}{https://github.com/zhang-tao-whu/DVIS}.
\\ ( https://arxiv.org/abs/2306.03413 ,  20244kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03414
Date: Tue, 6 Jun 2023 05:26:26 GMT   (19585kb,D)

Title: DreamSparse: Escaping from Plato's Cave with 2D Diffusion Model Given
 Sparse Views
Authors: Paul Yoo, Jiaxian Guo, Yutaka Matsuo, Shixiang Shane Gu
Categories: cs.CV cs.AI cs.GR
\\
 Synthesizing novel view images from a few views is a challenging but
practical problem. Existing methods often struggle with producing high-quality
results or necessitate per-object optimization in such few-view settings due to
the insufficient information provided. In this work, we explore leveraging the
strong 2D priors in pre-trained diffusion models for synthesizing novel view
images. 2D diffusion models, nevertheless, lack 3D awareness, leading to
distorted image synthesis and compromising the identity. To address these
problems, we propose DreamSparse, a framework that enables the frozen
pre-trained diffusion model to generate geometry and identity-consistent novel
view image. Specifically, DreamSparse incorporates a geometry module designed
to capture 3D features from sparse views as a 3D prior. Subsequently, a spatial
guidance model is introduced to convert these 3D feature maps into spatial
information for the generative process. This information is then used to guide
the pre-trained diffusion model, enabling it to generate geometrically
consistent images without tuning it. Leveraging the strong image priors in the
pre-trained diffusion models, DreamSparse is capable of synthesizing
high-quality novel views for both object and scene-level images and
generalising to open-set images. Experimental results demonstrate that our
framework can effectively synthesize novel view images from sparse views and
outperforms baselines in both trained and open-set category images. More
results can be found on our project page:
https://sites.google.com/view/dreamsparse-webpage.
\\ ( https://arxiv.org/abs/2306.03414 ,  19585kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03421
Date: Tue, 6 Jun 2023 05:41:42 GMT   (1338kb,D)

Title: Diversifying Joint Vision-Language Tokenization Learning
Authors: Vardaan Pahuja, AJ Piergiovanni, Anelia Angelova
Categories: cs.CV
Comments: Accepted to Transformers for Vision (T4V) workshop, CVPR 2023; 7
 pages, 5 figures
\\
 Building joint representations across images and text is an essential step
for tasks such as Visual Question Answering and Video Question Answering. In
this work, we find that the representations must not only jointly capture
features from both modalities but should also be diverse for better
generalization performance. To this end, we propose joint vision-language
representation learning by diversifying the tokenization learning process,
enabling tokens that are sufficiently disentangled from each other to be
learned from both modalities. We observe that our approach outperforms the
baseline models in a majority of settings and is competitive with
state-of-the-art methods.
\\ ( https://arxiv.org/abs/2306.03421 ,  1338kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03422
Date: Tue, 6 Jun 2023 05:48:09 GMT   (247kb,D)

Title: Prompting Large Language Models to Reformulate Queries for Moment
 Localization
Authors: Wenfeng Yan, Shaoxiang Chen, Zuxuan Wu, Yu-Gang Jiang
Categories: cs.CV
Comments: 4 pages, 2 figures
\\
 The task of moment localization is to localize a temporal moment in an
untrimmed video for a given natural language query. Since untrimmed video
contains highly redundant contents, the quality of the query is crucial for
accurately localizing moments, i.e., the query should provide precise
information about the target moment so that the localization model can
understand what to look for in the videos. However, the natural language
queries in current datasets may not be easy to understand for existing models.
For example, the Ego4D dataset uses question sentences as the query to describe
relatively complex moments. While being natural and straightforward for humans,
understanding such question sentences are challenging for mainstream moment
localization models like 2D-TAN. Inspired by the recent success of large
language models, especially their ability of understanding and generating
complex natural language contents, in this extended abstract, we make early
attempts at reformulating the moment queries into a set of instructions using
large language models and making them more friendly to the localization models.
\\ ( https://arxiv.org/abs/2306.03422 ,  247kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03424
Date: Tue, 6 Jun 2023 05:51:50 GMT   (8763kb,D)

Title: Change Diffusion: Change Detection Map Generation Based on
 Difference-Feature Guided DDPM
Authors: Yihan Wen, Jialu Sui, Xianping Ma, Wendi Liang, Xiaokang Zhang, Man-On
 Pun
Categories: cs.CV
\\
 Deep learning (DL) approaches based on CNN-purely or Transformer networks
have demonstrated promising results in bitemporal change detection (CD).
However, their performance is limited by insufficient contextual information
aggregation, as they struggle to fully capture the implicit contextual
dependency relationships among feature maps at different levels. Additionally,
researchers have utilized pre-trained denoising diffusion probabilistic models
(DDPMs) for training lightweight CD classifiers. Nevertheless, training a DDPM
to generate intricately detailed, multi-channel remote sensing images requires
months of training time and a substantial volume of unlabeled remote sensing
datasets, making it significantly more complex than generating a single-channel
change map. To overcome these challenges, we propose a novel end-to-end
DDPM-based model architecture called change-aware diffusion model (CADM), which
can be trained using a limited annotated dataset quickly. Furthermore, we
introduce dynamic difference conditional encoding to enhance step-wise regional
attention in DDPM for bitemporal images in CD datasets. This method establishes
state-adaptive conditions for each sampling step, emphasizing two main
innovative points of our model: 1) its end-to-end nature and 2) difference
conditional encoding. We evaluate CADM on four remote sensing CD tasks with
different ground scenarios, including CDD, WHU, Levier, and GVLM. Experimental
results demonstrate that CADM significantly outperforms state-of-the-art
methods, indicating the generalization and effectiveness of the proposed model.
\\ ( https://arxiv.org/abs/2306.03424 ,  8763kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03428
Date: Tue, 6 Jun 2023 05:59:23 GMT   (596kb,D)

Title: GaitGCI: Generative Counterfactual Intervention for Gait Recognition
Authors: Huanzhang Dou, Pengyi Zhang, Wei Su, Yunlong Yu, Yining Lin, and Xi Li
Categories: cs.CV
Comments: Accepted by CVPR2023
\\
 Gait is one of the most promising biometrics that aims to identify
pedestrians from their walking patterns. However, prevailing methods are
susceptible to confounders, resulting in the networks hardly focusing on the
regions that reflect effective walking patterns. To address this fundamental
problem in gait recognition, we propose a Generative Counterfactual
Intervention framework, dubbed GaitGCI, consisting of Counterfactual
Intervention Learning (CIL) and Diversity-Constrained Dynamic Convolution
(DCDC). CIL eliminates the impacts of confounders by maximizing the likelihood
difference between factual/counterfactual attention while DCDC adaptively
generates sample-wise factual/counterfactual attention to efficiently perceive
the sample-wise properties. With matrix decomposition and diversity constraint,
DCDC guarantees the model to be efficient and effective. Extensive experiments
indicate that proposed GaitGCI: 1) could effectively focus on the
discriminative and interpretable regions that reflect gait pattern; 2) is
model-agnostic and could be plugged into existing models to improve performance
with nearly no extra cost; 3) efficiently achieves state-of-the-art performance
on arbitrary scenarios (in-the-lab and in-the-wild).
\\ ( https://arxiv.org/abs/2306.03428 ,  596kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03430
Date: Tue, 6 Jun 2023 06:09:11 GMT   (1779kb,D)

Title: Revisiting the Trade-off between Accuracy and Robustness via Weight
 Distribution of Filters
Authors: Xingxing Wei, and Shiji Zhao
Categories: cs.CV
\\
 Adversarial attacks have been proven to be potential threats to Deep Neural
Networks (DNNs), and many methods are proposed to defend against adversarial
attacks. However, while enhancing the robustness, the clean accuracy will
decline to a certain extent, implying a trade-off existed between the accuracy
and robustness. In this paper, we firstly empirically find an obvious
distinction between standard and robust models in the filters' weight
distribution of the same architecture, and then theoretically explain this
phenomenon in terms of the gradient regularization, which shows this difference
is an intrinsic property for DNNs, and thus a static network architecture is
difficult to improve the accuracy and robustness at the same time. Secondly,
based on this observation, we propose a sample-wise dynamic network
architecture named Adversarial Weight-Varied Network (AW-Net), which focuses on
dealing with clean and adversarial examples with a ``divide and rule" weight
strategy. The AW-Net dynamically adjusts network's weights based on regulation
signals generated by an adversarial detector, which is directly influenced by
the input sample. Benefiting from the dynamic network architecture, clean and
adversarial examples can be processed with different network weights, which
provides the potentiality to enhance the accuracy and robustness
simultaneously. A series of experiments demonstrate that our AW-Net is
architecture-friendly to handle both clean and adversarial examples and can
achieve better trade-off performance than state-of-the-art robust models.
\\ ( https://arxiv.org/abs/2306.03430 ,  1779kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03437
Date: Tue, 6 Jun 2023 06:33:32 GMT   (9047kb,D)

Title: DFormer: Diffusion-guided Transformer for Universal Image Segmentation
Authors: Hefeng Wang, Jiale Cao, Rao Muhammad Anwer, Jin Xie, Fahad Shahbaz
 Khan, Yanwei Pang
Categories: cs.CV
\\
 This paper introduces an approach, named DFormer, for universal image
segmentation. The proposed DFormer views universal image segmentation task as a
denoising process using a diffusion model. DFormer first adds various levels of
Gaussian noise to ground-truth masks, and then learns a model to predict
denoising masks from corrupted masks. Specifically, we take deep pixel-level
features along with the noisy masks as inputs to generate mask features and
attention masks, employing diffusion-based decoder to perform mask prediction
gradually. At inference, our DFormer directly predicts the masks and
corresponding categories from a set of randomly-generated masks. Extensive
experiments reveal the merits of our proposed contributions on different image
segmentation tasks: panoptic segmentation, instance segmentation, and semantic
segmentation. Our DFormer outperforms the recent diffusion-based panoptic
segmentation method Pix2Seq-D with a gain of 3.6% on MS COCO val2017 set.
Further, DFormer achieves promising semantic segmentation performance
outperforming the recent diffusion-based method by 2.2% on ADE20K val set. Our
source code and models will be publicly on https://github.com/cp3wan/DFormer
\\ ( https://arxiv.org/abs/2306.03437 ,  9047kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03445
Date: Tue, 6 Jun 2023 06:53:05 GMT   (2976kb,D)

Title: MetaGait: Learning to Learn an Omni Sample Adaptive Representation for
 Gait Recognition
Authors: Huanzhang Dou, Pengyi Zhang, Wei Su, Yunlong Yu, and Xi Li
Categories: cs.CV cs.AI
Comments: Accepted by ECCV2022
\\
 Gait recognition, which aims at identifying individuals by their walking
patterns, has recently drawn increasing research attention. However, gait
recognition still suffers from the conflicts between the limited binary visual
clues of the silhouette and numerous covariates with diverse scales, which
brings challenges to the model's adaptiveness. In this paper, we address this
conflict by developing a novel MetaGait that learns to learn an omni sample
adaptive representation. Towards this goal, MetaGait injects meta-knowledge,
which could guide the model to perceive sample-specific properties, into the
calibration network of the attention mechanism to improve the adaptiveness from
the omni-scale, omni-dimension, and omni-process perspectives. Specifically, we
leverage the meta-knowledge across the entire process, where Meta Triple
Attention and Meta Temporal Pooling are presented respectively to adaptively
capture omni-scale dependency from spatial/channel/temporal dimensions
simultaneously and to adaptively aggregate temporal information through
integrating the merits of three complementary temporal aggregation methods.
Extensive experiments demonstrate the state-of-the-art performance of the
proposed MetaGait. On CASIA-B, we achieve rank-1 accuracy of 98.7%, 96.0%, and
89.3% under three conditions, respectively. On OU-MVLP, we achieve rank-1
accuracy of 92.4%.
\\ ( https://arxiv.org/abs/2306.03445 ,  2976kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03482
Date: Tue, 6 Jun 2023 08:08:18 GMT   (893kb,D)

Title: Looking and Listening: Audio Guided Text Recognition
Authors: Wenwen Yu, Mingyu Liu, Biao Yang, Enming Zhang, Deqiang Jiang, Xing
 Sun, Yuliang Liu, Xiang Bai
Categories: cs.CV
\\
 Text recognition in the wild is a long-standing problem in computer vision.
Driven by end-to-end deep learning, recent studies suggest vision and language
processing are effective for scene text recognition. Yet, solving edit errors
such as add, delete, or replace is still the main challenge for existing
approaches. In fact, the content of the text and its audio are naturally
corresponding to each other, i.e., a single character error may result in a
clear different pronunciation. In this paper, we propose the AudioOCR, a simple
yet effective probabilistic audio decoder for mel spectrogram sequence
prediction to guide the scene text recognition, which only participates in the
training phase and brings no extra cost during the inference stage. The
underlying principle of AudioOCR can be easily applied to the existing
approaches. Experiments using 7 previous scene text recognition methods on 12
existing regular, irregular, and occluded benchmarks demonstrate our proposed
method can bring consistent improvement. More importantly, through our
experimentation, we show that AudioOCR possesses a generalizability that
extends to more challenging scenarios, including recognizing non-English text,
out-of-vocabulary words, and text with various accents. Code will be available
at https://github.com/wenwenyu/AudioOCR.
\\ ( https://arxiv.org/abs/2306.03482 ,  893kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03491
Date: Tue, 6 Jun 2023 08:16:16 GMT   (1339kb,D)

Title: SciCap+: A Knowledge Augmented Dataset to Study the Challenges of
 Scientific Figure Captioning
Authors: Zhishen Yang, Raj Dabre, Hideki Tanaka, Naoaki Okazaki
Categories: cs.CV cs.CL
Comments: Published in SDU workshop at AAAI23
\\
 In scholarly documents, figures provide a straightforward way of
communicating scientific findings to readers. Automating figure caption
generation helps move model understandings of scientific documents beyond text
and will help authors write informative captions that facilitate communicating
scientific findings. Unlike previous studies, we reframe scientific figure
captioning as a knowledge-augmented image captioning task that models need to
utilize knowledge embedded across modalities for caption generation. To this
end, we extended the large-scale SciCap
dataset~\cite{hsu-etal-2021-scicap-generating} to SciCap+ which includes
mention-paragraphs (paragraphs mentioning figures) and OCR tokens. Then, we
conduct experiments with the M4C-Captioner (a multimodal transformer-based
model with a pointer network) as a baseline for our study. Our results indicate
that mention-paragraphs serves as additional context knowledge, which
significantly boosts the automatic standard image caption evaluation scores
compared to the figure-only baselines. Human evaluations further reveal the
challenges of generating figure captions that are informative to readers. The
code and SciCap+ dataset will be publicly available at
https://github.com/ZhishenYang/scientific_figure_captioning_dataset
\\ ( https://arxiv.org/abs/2306.03491 ,  1339kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03492
Date: Tue, 6 Jun 2023 08:19:30 GMT   (10836kb,D)

Title: Efficient Anomaly Detection with Budget Annotation Using Semi-Supervised
 Residual Transformer
Authors: Hanxi Li, Jingqi Wu, Hao Chen, Mingwen Wang, Chunhua Shen
Categories: cs.CV
Comments: 20 pages,6 figures
\\
 Anomaly Detection is challenging as usually only the normal samples are seen
during training and the detector needs to discover anomalies on-the-fly. The
recently proposed deep-learning-based approaches could somehow alleviate the
problem but there is still a long way to go in obtaining an industrial-class
anomaly detector for real-world applications. On the other hand, in some
particular AD tasks, a few anomalous samples are labeled manually for achieving
higher accuracy. However, this performance gain is at the cost of considerable
annotation efforts, which can be intractable in many practical scenarios.
 In this work, the above two problems are addressed in a unified framework.
Firstly, inspired by the success of the patch-matching-based AD algorithms, we
train a sliding vision transformer over the residuals generated by a novel
position-constrained patch-matching. Secondly, the conventional pixel-wise
segmentation problem is cast into a block-wise classification problem. Thus the
sliding transformer can attain even higher accuracy with much less annotation
labor. Thirdly, to further reduce the labeling cost, we propose to label the
anomalous regions using only bounding boxes. The unlabeled regions caused by
the weak labels are effectively exploited using a highly-customized
semi-supervised learning scheme equipped with two novel data augmentation
methods. The proposed method outperforms all the state-of-the-art approaches
using all the evaluation metrics in both the unsupervised and supervised
scenarios. On the popular MVTec-AD dataset, our SemiREST algorithm obtains the
Average Precision (AP) of 81.2% in the unsupervised condition and 84.4% AP for
supervised anomaly detection. Surprisingly, with the bounding-box-based
semi-supervisions, SemiREST still outperforms the SOTA methods with full
supervision (83.8% AP) on MVTec-AD.
\\ ( https://arxiv.org/abs/2306.03492 ,  10836kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03497
Date: Tue, 6 Jun 2023 08:28:55 GMT   (6804kb,D)

Title: Instructive Feature Enhancement for Dichotomous Medical Image
 Segmentation
Authors: Lian Liu, Han Zhou, Jiongquan Chen, Sijing Liu, Wenlong Shi, Dong Ni,
 Deng-Ping Fan, Xin Yang
Categories: cs.CV
Comments: Accepted by MICCAI 2023
\\
 Deep neural networks have been widely applied in dichotomous medical image
segmentation (DMIS) of many anatomical structures in several modalities,
achieving promising performance. However, existing networks tend to struggle
with task-specific, heavy and complex designs to improve accuracy. They made
little instructions to which feature channels would be more beneficial for
segmentation, and that may be why the performance and universality of these
segmentation models are hindered. In this study, we propose an instructive
feature enhancement approach, namely IFE, to adaptively select feature channels
with rich texture cues and strong discriminability to enhance raw features
based on local curvature or global information entropy criteria. Being
plug-and-play and applicable for diverse DMIS tasks, IFE encourages the model
to focus on texture-rich features which are especially important for the
ambiguous and challenging boundary identification, simultaneously achieving
simplicity, universality, and certain interpretability. To evaluate the
proposed IFE, we constructed the first large-scale DMIS dataset Cosmos55k,
which contains 55,023 images from 7 modalities and 26 anatomical structures.
Extensive experiments show that IFE can improve the performance of classic
segmentation networks across different anatomies and modalities with only
slight modifications. Code is available at https://github.com/yezi-66/IFE
\\ ( https://arxiv.org/abs/2306.03497 ,  6804kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03504
Date: Tue, 6 Jun 2023 08:50:13 GMT   (1112kb,D)

Title: Ada-TTA: Towards Adaptive High-Quality Text-to-Talking Avatar Synthesis
Authors: Zhenhui Ye, Ziyue Jiang, Yi Ren, Jinglin Liu, Chen Zhang, Xiang Yin,
 Zejun Ma, Zhou Zhao
Categories: cs.CV cs.SD eess.AS
Comments: 6 pages, 3 figures
\\
 We are interested in a novel task, namely low-resource text-to-talking
avatar. Given only a few-minute-long talking person video with the audio track
as the training data and arbitrary texts as the driving input, we aim to
synthesize high-quality talking portrait videos corresponding to the input
text. This task has broad application prospects in the digital human industry
but has not been technically achieved yet due to two challenges: (1) It is
challenging to mimic the timbre from out-of-domain audio for a traditional
multi-speaker Text-to-Speech system. (2) It is hard to render high-fidelity and
lip-synchronized talking avatars with limited training data. In this paper, we
introduce Adaptive Text-to-Talking Avatar (Ada-TTA), which (1) designs a
generic zero-shot multi-speaker TTS model that well disentangles the text
content, timbre, and prosody; and (2) embraces recent advances in neural
rendering to achieve realistic audio-driven talking face video generation. With
these designs, our method overcomes the aforementioned two challenges and
achieves to generate identity-preserving speech and realistic talking person
video. Experiments demonstrate that our method could synthesize realistic,
identity-preserving, and audio-visual synchronized talking avatar videos.
\\ ( https://arxiv.org/abs/2306.03504 ,  1112kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03508
Date: Tue, 6 Jun 2023 08:53:53 GMT   (20kb,D)

Title: Semantic Segmentation on VSPW Dataset through Contrastive Loss and
 Multi-dataset Training Approach
Authors: Min Yan, Qianxiong Ning, Qian Wang
Categories: cs.CV
Comments: 1st Place Solution for CVPR 2023 PVUW VSS Track
\\
 Video scene parsing incorporates temporal information, which can enhance the
consistency and accuracy of predictions compared to image scene parsing. The
added temporal dimension enables a more comprehensive understanding of the
scene, leading to more reliable results. This paper presents the winning
solution of the CVPR2023 workshop for video semantic segmentation, focusing on
enhancing Spatial-Temporal correlations with contrastive loss. We also explore
the influence of multi-dataset training by utilizing a label-mapping technique.
And the final result is aggregating the output of the above two models. Our
approach achieves 65.95% mIoU performance on the VSPW dataset, ranked 1st place
on the VSPW challenge at CVPR 2023.
\\ ( https://arxiv.org/abs/2306.03508 ,  20kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03514
Date: Tue, 6 Jun 2023 09:00:10 GMT   (442kb,D)

Title: Recognize Anything: A Strong Image Tagging Model
Authors: Youcai Zhang, Xinyu Huang, Jinyu Ma, Zhaoyang Li, Zhaochuan Luo,
 Yanchun Xie, Yuzhuo Qin, Tong Luo, Yaqian Li, Shilong Liu, Yandong Guo, Lei
 Zhang
Categories: cs.CV
\\
 We present the Recognize Anything Model (RAM): a strong foundation model for
image tagging. RAM can recognize any common category with high accuracy. RAM
introduces a new paradigm for image tagging, leveraging large-scale image-text
pairs for training instead of manual annotations. The development of RAM
comprises four key steps. Firstly, annotation-free image tags are obtained at
scale through automatic text semantic parsing. Subsequently, a preliminary
model is trained for automatic annotation by unifying the caption and tagging
tasks, supervised by the original texts and parsed tags, respectively. Thirdly,
a data engine is employed to generate additional annotations and clean
incorrect ones. Lastly, the model is retrained with the processed data and
fine-tuned using a smaller but higher-quality dataset. We evaluate the tagging
capabilities of RAM on numerous benchmarks and observe impressive zero-shot
performance, significantly outperforming CLIP and BLIP. Remarkably, RAM even
surpasses the fully supervised manners and exhibits competitive performance
with the Google API. We are releasing the RAM at
\url{https://recognize-anything.github.io/} to foster the advancements of large
models in computer vision.
\\ ( https://arxiv.org/abs/2306.03514 ,  442kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03531
Date: Tue, 6 Jun 2023 09:28:37 GMT   (18854kb,D)

Title: Expanding Explainability Horizons: A Unified Concept-Based System for
 Local, Global, and Misclassification Explanations
Authors: Fatemeh Aghaeipoor, Dorsa Asgarian, Mohammad Sabokrou
Categories: cs.CV cs.AI
ACM-class: I.2
\\
 Explainability of intelligent models has been garnering increasing attention
in recent years. Of the various explainability approaches, concept-based
techniques are notable for utilizing a set of human-meaningful concepts instead
of focusing on individual pixels. However, there is a scarcity of methods that
consistently provide both local and global explanations. Moreover, most of the
methods have no offer to explain misclassification cases. To address these
challenges, our study follows a straightforward yet effective approach. We
propose a unified concept-based system, which inputs a number of
super-pixelated images into the networks, allowing them to learn better
representations of the target's objects as well as the target's concepts. This
method automatically learns, scores, and extracts local and global concepts.
Our experiments revealed that, in addition to enhancing performance, the models
could provide deeper insights into predictions and elucidate false
classifications.
\\ ( https://arxiv.org/abs/2306.03531 ,  18854kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03537
Date: Tue, 6 Jun 2023 09:35:45 GMT   (12560kb,D)

Title: Real-Time Onboard Object Detection for Augmented Reality: Enhancing
 Head-Mounted Display with YOLOv8
Authors: Miko{\l}aj {\L}ysakowski, Kamil \.Zywanowski, Adam Banaszczyk,
 Micha{\l} R. Nowicki, Piotr Skrzypczy\'nski, S{\l}awomir K. Tadeja
Categories: cs.CV cs.HC
\\
 This paper introduces a software architecture for real-time object detection
using machine learning (ML) in an augmented reality (AR) environment. Our
approach uses the recent state-of-the-art YOLOv8 network that runs onboard on
the Microsoft HoloLens 2 head-mounted display (HMD). The primary motivation
behind this research is to enable the application of advanced ML models for
enhanced perception and situational awareness with a wearable, hands-free AR
platform. We show the image processing pipeline for the YOLOv8 model and the
techniques used to make it real-time on the resource-limited edge computing
platform of the headset. The experimental results demonstrate that our solution
achieves real-time processing without needing offloading tasks to the cloud or
any other external servers while retaining satisfactory accuracy regarding the
usual mAP metric and measured qualitative performance
\\ ( https://arxiv.org/abs/2306.03537 ,  12560kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03538
Date: Tue, 6 Jun 2023 09:35:56 GMT   (1534kb)

Title: SDR-GAIN: A High Real-Time Occluded Pedestrian Pose Completion Method
 for Autonomous Driving
Authors: Honghao Fu
Categories: cs.CV cs.AI
\\
 To mitigate the challenges arising from partial occlusion in human pose
keypoint based pedestrian detection methods , we present a novel pedestrian
pose keypoint completion method called the separation and dimensionality
reduction-based generative adversarial imputation networks (SDR-GAIN) .
Firstly, we utilize OpenPose to estimate pedestrian poses in images. Then, we
isolate the head and torso keypoints of pedestrians with incomplete keypoints
due to occlusion or other factors and perform dimensionality reduction to
enhance features and further unify feature distribution. Finally, we introduce
two generative models based on the generative adversarial networks (GAN)
framework, which incorporate Huber loss, residual structure, and L1
regularization to generate missing parts of the incomplete head and torso pose
keypoints of partially occluded pedestrians, resulting in pose completion. Our
experiments on MS COCO and JAAD datasets demonstrate that SDR-GAIN outperforms
basic GAIN framework, interpolation methods PCHIP and MAkima, machine learning
methods k-NN and MissForest in terms of pose completion task. In addition, the
runtime of SDR-GAIN is approximately 0.4ms, displaying high real-time
performance and significant application value in the field of autonomous
driving.
\\ ( https://arxiv.org/abs/2306.03538 ,  1534kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03576
Date: Tue, 6 Jun 2023 10:51:05 GMT   (1101kb,D)

Title: Human 3D Avatar Modeling with Implicit Neural Representation: A Brief
 Survey
Authors: Mingyang Sun, Dingkang Yang, Dongliang Kou, Yang Jiang, Weihua Shan,
 Zhe Yan, Lihua Zhang
Categories: cs.CV
Comments: A Brief Survey
\\
 A human 3D avatar is one of the important elements in the metaverse, and the
modeling effect directly affects people's visual experience. However, the human
body has a complex topology and diverse details, so it is often expensive,
time-consuming, and laborious to build a satisfactory model. Recent studies
have proposed a novel method, implicit neural representation, which is a
continuous representation method and can describe objects with arbitrary
topology at arbitrary resolution. Researchers have applied implicit neural
representation to human 3D avatar modeling and obtained more excellent results
than traditional methods. This paper comprehensively reviews the application of
implicit neural representation in human body modeling. First, we introduce
three implicit representations of occupancy field, SDF, and NeRF, and make a
classification of the literature investigated in this paper. Then the
application of implicit modeling methods in the body, hand, and head are
compared and analyzed respectively. Finally, we point out the shortcomings of
current work and provide available suggestions for researchers.
\\ ( https://arxiv.org/abs/2306.03576 ,  1101kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03577
Date: Tue, 6 Jun 2023 10:52:06 GMT   (2014kb,D)

Title: An Open Patch Generator based Fingerprint Presentation Attack Detection
 using Generative Adversarial Network
Authors: Anuj Rai, Ashutosh Anshul, Ashwini Jha, Prayag Jain, Ramprakash
 Sharma, Somnath Dey
Categories: cs.CV
\\
 The low-cost, user-friendly, and convenient nature of Automatic Fingerprint
Recognition Systems (AFRS) makes them suitable for a wide range of
applications. This spreading use of AFRS also makes them vulnerable to various
security threats. Presentation Attack (PA) or spoofing is one of the threats
which is caused by presenting a spoof of a genuine fingerprint to the sensor of
AFRS. Fingerprint Presentation Attack Detection (FPAD) is a countermeasure
intended to protect AFRS against fake or spoof fingerprints created using
various fabrication materials. In this paper, we have proposed a Convolutional
Neural Network (CNN) based technique that uses a Generative Adversarial Network
(GAN) to augment the dataset with spoof samples generated from the proposed
Open Patch Generator (OPG). This OPG is capable of generating realistic
fingerprint samples which have no resemblance to the existing spoof fingerprint
samples generated with other materials. The augmented dataset is fed to the
DenseNet classifier which helps in increasing the performance of the
Presentation Attack Detection (PAD) module for the various real-world attacks
possible with unknown spoof materials. Experimental evaluations of the proposed
approach are carried out on the Liveness Detection (LivDet) 2015, 2017, and
2019 competition databases. An overall accuracy of 96.20\%, 94.97\%, and
92.90\% has been achieved on the LivDet 2015, 2017, and 2019 databases,
respectively under the LivDet protocol scenarios. The performance of the
proposed PAD model is also validated in the cross-material and cross-sensor
attack paradigm which further exhibits its capability to be used under
real-world attack scenarios.
\\ ( https://arxiv.org/abs/2306.03577 ,  2014kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03584
Date: Tue, 6 Jun 2023 11:03:05 GMT   (5160kb,D)

Title: RDFC-GAN: RGB-Depth Fusion CycleGAN for Indoor Depth Completion
Authors: Haowen Wang, Zhengping Che, Mingyuan Wang, Zhiyuan Xu, Xiuquan Qiao,
 Mengshi Qi, Feifei Feng, Jian Tang
Categories: cs.CV cs.AI
Comments: Haowen Wang and Zhengping Che are with equal contributions. Under
 review. An earlier version has been accepted by CVPR 2022 (arXiv:2203.10856)
\\
 The raw depth image captured by indoor depth sensors usually has an extensive
range of missing depth values due to inherent limitations such as the inability
to perceive transparent objects and the limited distance range. The incomplete
depth map with missing values burdens many downstream vision tasks, and a
rising number of depth completion methods have been proposed to alleviate this
issue. While most existing methods can generate accurate dense depth maps from
sparse and uniformly sampled depth maps, they are not suitable for
complementing large contiguous regions of missing depth values, which is common
and critical in images captured in indoor environments. To overcome these
challenges, we design a novel two-branch end-to-end fusion network named
RDFC-GAN, which takes a pair of RGB and incomplete depth images as input to
predict a dense and completed depth map. The first branch employs an
encoder-decoder structure, by adhering to the Manhattan world assumption and
utilizing normal maps from RGB-D information as guidance, to regress the local
dense depth values from the raw depth map. In the other branch, we propose an
RGB-depth fusion CycleGAN to transfer the RGB image to the fine-grained
textured depth map. We adopt adaptive fusion modules named W-AdaIN to propagate
the features across the two branches, and we append a confidence fusion head to
fuse the two outputs of the branches for the final depth map. Extensive
experiments on NYU-Depth V2 and SUN RGB-D demonstrate that our proposed method
clearly improves the depth completion performance, especially in a more
realistic setting of indoor environments, with the help of our proposed pseudo
depth maps in training.
\\ ( https://arxiv.org/abs/2306.03584 ,  5160kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03594
Date: Tue, 6 Jun 2023 11:31:29 GMT   (3496kb,D)

Title: Emotional Talking Head Generation based on Memory-Sharing and
 Attention-Augmented Networks
Authors: Jianrong Wang, Yaxin Zhao, Li Liu, Tianyi Xu, Qi Li, Sen Li
Categories: cs.CV
\\
 Given an audio clip and a reference face image, the goal of the talking head
generation is to generate a high-fidelity talking head video. Although some
audio-driven methods of generating talking head videos have made some
achievements in the past, most of them only focused on lip and audio
synchronization and lack the ability to reproduce the facial expressions of the
target person. To this end, we propose a talking head generation model
consisting of a Memory-Sharing Emotion Feature extractor (MSEF) and an
Attention-Augmented Translator based on U-net (AATU). Firstly, MSEF can extract
implicit emotional auxiliary features from audio to estimate more accurate
emotional face landmarks.~Secondly, AATU acts as a translator between the
estimated landmarks and the photo-realistic video frames. Extensive qualitative
and quantitative experiments have shown the superiority of the proposed method
to the previous works. Codes will be made publicly available.
\\ ( https://arxiv.org/abs/2306.03594 ,  3496kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03597
Date: Tue, 6 Jun 2023 11:36:14 GMT   (6537kb,D)

Title: Human-Object Interaction Prediction in Videos through Gaze Following
Authors: Zhifan Ni, Esteve Valls Mascar\'o, Hyemin Ahn, Dongheui Lee
Categories: cs.CV
Comments: Accepted by CVIU https://doi.org/10.1016/j.cviu.2023.103741
DOI: 10.1016/j.cviu.2023.103741
\\
 Understanding the human-object interactions (HOIs) from a video is essential
to fully comprehend a visual scene. This line of research has been addressed by
detecting HOIs from images and lately from videos. However, the video-based HOI
anticipation task in the third-person view remains understudied. In this paper,
we design a framework to detect current HOIs and anticipate future HOIs in
videos. We propose to leverage human gaze information since people often fixate
on an object before interacting with it. These gaze features together with the
scene contexts and the visual appearances of human-object pairs are fused
through a spatio-temporal transformer. To evaluate the model in the HOI
anticipation task in a multi-person scenario, we propose a set of person-wise
multi-label metrics. Our model is trained and validated on the VidHOI dataset,
which contains videos capturing daily life and is currently the largest video
HOI dataset. Experimental results in the HOI detection task show that our
approach improves the baseline by a great margin of 36.3% relatively. Moreover,
we conduct an extensive ablation study to demonstrate the effectiveness of our
modifications and extensions to the spatio-temporal transformer. Our code is
publicly available on https://github.com/nizhf/hoi-prediction-gaze-transformer.
\\ ( https://arxiv.org/abs/2306.03597 ,  6537kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03630
Date: Tue, 6 Jun 2023 12:36:57 GMT   (20777kb,D)

Title: Mutual Information Regularization for Weakly-supervised RGB-D Salient
 Object Detection
Authors: Aixuan Li, Yuxin Mao, Jing Zhang, Yuchao Dai
Categories: cs.CV
Comments: IEEE Transactions on Circuits and Systems for Video Technology 2023
\\
 In this paper, we present a weakly-supervised RGB-D salient object detection
model via scribble supervision. Specifically, as a multimodal learning task, we
focus on effective multimodal representation learning via inter-modal mutual
information regularization. In particular, following the principle of
disentangled representation learning, we introduce a mutual information upper
bound with a mutual information minimization regularizer to encourage the
disentangled representation of each modality for salient object detection.
Based on our multimodal representation learning framework, we introduce an
asymmetric feature extractor for our multimodal data, which is proven more
effective than the conventional symmetric backbone setting. We also introduce
multimodal variational auto-encoder as stochastic prediction refinement
techniques, which takes pseudo labels from the first training stage as
supervision and generates refined prediction. Experimental results on benchmark
RGB-D salient object detection datasets verify both effectiveness of our
explicit multimodal disentangled representation learning method and the
stochastic prediction refinement strategy, achieving comparable performance
with the state-of-the-art fully supervised models. Our code and data are
available at: https://github.com/baneitixiaomai/MIRV.
\\ ( https://arxiv.org/abs/2306.03630 ,  20777kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03660
Date: Tue, 6 Jun 2023 13:23:42 GMT   (36828kb,D)

Title: PQM: A Point Quality Evaluation Metric for Dense Maps
Authors: Yash Turkar, Pranay Meshram, Charuvahan Adhivarahan, Karthik Dantu
Categories: cs.CV eess.IV
\\
 LiDAR-based mapping/reconstruction are important for various applications,
but evaluating the quality of the dense maps they produce is challenging. The
current methods have limitations, including the inability to capture
completeness, structural information, and local variations in error. In this
paper, we propose a novel point quality evaluation metric (PQM) that consists
of four sub-metrics to provide a more comprehensive evaluation of point cloud
quality. The completeness sub-metric evaluates the proportion of missing data,
the artifact score sub-metric recognizes and characterizes artifacts, the
accuracy sub-metric measures registration accuracy, and the resolution
sub-metric quantifies point cloud density. Through an ablation study using a
prototype dataset, we demonstrate the effectiveness of each of the sub-metrics
and compare them to popular point cloud distance measures. Using three LiDAR
SLAM systems to generate maps, we evaluate their output map quality and
demonstrate the metrics robustness to noise and artifacts. Our implementation
of PQM, datasets and detailed documentation on how to integrate with your
custom dense mapping pipeline can be found at github.com/droneslab/pqm
\\ ( https://arxiv.org/abs/2306.03660 ,  36828kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03679
Date: Tue, 6 Jun 2023 13:41:37 GMT   (9514kb,D)

Title: Human-imperceptible, Machine-recognizable Images
Authors: Fusheng Hao, Fengxiang He, Yikai Wang, Fuxiang Wu, Jing Zhang, Jun
 Cheng, Dacheng Tao
Categories: cs.CV cs.AI cs.CR cs.LG stat.ML
\\
 Massive human-related data is collected to train neural networks for computer
vision tasks. A major conflict is exposed relating to software engineers
between better developing AI systems and distancing from the sensitive training
data. To reconcile this conflict, this paper proposes an efficient
privacy-preserving learning paradigm, where images are first encrypted to
become ``human-imperceptible, machine-recognizable'' via one of the two
encryption strategies: (1) random shuffling to a set of equally-sized patches
and (2) mixing-up sub-patches of the images. Then, minimal adaptations are made
to vision transformer to enable it to learn on the encrypted images for vision
tasks, including image classification and object detection. Extensive
experiments on ImageNet and COCO show that the proposed paradigm achieves
comparable accuracy with the competitive methods. Decrypting the encrypted
images requires solving an NP-hard jigsaw puzzle or an ill-posed inverse
problem, which is empirically shown intractable to be recovered by various
attackers, including the powerful vision transformer-based attacker. We thus
show that the proposed paradigm can ensure the encrypted images have become
human-imperceptible while preserving machine-recognizable information. The code
is available at \url{https://github.com/FushengHao/PrivacyPreservingML.}
\\ ( https://arxiv.org/abs/2306.03679 ,  9514kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03686
Date: Tue, 6 Jun 2023 13:53:15 GMT   (12377kb,D)

Title: YONA: You Only Need One Adjacent Reference-frame for Accurate and Fast
 Video Polyp Detection
Authors: Yuncheng Jiang, Zixun Zhang, Ruimao Zhang, Guanbin Li, Shuguang Cui,
 Zhen Li
Categories: cs.CV
Comments: 11 pages, 3 figures, Accepted by MICCAI2023
\\
 Accurate polyp detection is essential for assisting clinical rectal cancer
diagnoses. Colonoscopy videos contain richer information than still images,
making them a valuable resource for deep learning methods. Great efforts have
been made to conduct video polyp detection through multi-frame temporal/spatial
aggregation. However, unlike common fixed-camera video, the camera-moving scene
in colonoscopy videos can cause rapid video jitters, leading to unstable
training for existing video detection models. Additionally, the concealed
nature of some polyps and the complex background environment further hinder the
performance of existing video detectors. In this paper, we propose the
\textbf{YONA} (\textbf{Y}ou \textbf{O}nly \textbf{N}eed one \textbf{A}djacent
Reference-frame) method, an efficient end-to-end training framework for video
polyp detection. YONA fully exploits the information of one previous adjacent
frame and conducts polyp detection on the current frame without multi-frame
collaborations. Specifically, for the foreground, YONA adaptively aligns the
current frame's channel activation patterns with its adjacent reference frames
according to their foreground similarity. For the background, YONA conducts
background dynamic alignment guided by inter-frame difference to eliminate the
invalid features produced by drastic spatial jitters. Moreover, YONA applies
cross-frame contrastive learning during training, leveraging the ground truth
bounding box to improve the model's perception of polyp and background.
Quantitative and qualitative experiments on three public challenging benchmarks
demonstrate that our proposed YONA outperforms previous state-of-the-art
competitors by a large margin in both accuracy and speed.
\\ ( https://arxiv.org/abs/2306.03686 ,  12377kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03711
Date: Tue, 6 Jun 2023 14:21:22 GMT   (8412kb,D)

Title: Deep Learning-Enabled Sleep Staging From Vital Signs and Activity
 Measured Using a Near-Infrared Video Camera
Authors: Jonathan Carter, Jo\~ao Jorge, Bindia Venugopal, Oliver Gibson, Lionel
 Tarassenko
Categories: cs.CV
Comments: Accepted to the 6th International Workshop on Computer Vision for
 Physiological Measurement (CVPM) at CVPR 2023. 10 pages, 12 figures, 5 tables
\\
 Conventional sleep monitoring is time-consuming, expensive and uncomfortable,
requiring a large number of contact sensors to be attached to the patient.
Video data is commonly recorded as part of a sleep laboratory assessment. If
accurate sleep staging could be achieved solely from video, this would overcome
many of the problems of traditional methods. In this work we use heart rate,
breathing rate and activity measures, all derived from a near-infrared video
camera, to perform sleep stage classification. We use a deep transfer learning
approach to overcome data scarcity, by using an existing contact-sensor dataset
to learn effective representations from the heart and breathing rate time
series. Using a dataset of 50 healthy volunteers, we achieve an accuracy of
73.4\% and a Cohen's kappa of 0.61 in four-class sleep stage classification,
establishing a new state-of-the-art for video-based sleep staging.
\\ ( https://arxiv.org/abs/2306.03711 ,  8412kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03727
Date: Tue, 6 Jun 2023 14:45:44 GMT   (10141kb,D)

Title: Towards Visual Foundational Models of Physical Scenes
Authors: Chethan Parameshwara, Alessandro Achille, Matthew Trager, Xiaolong Li,
 Jiawei Mo, Matthew Trager, Ashwin Swaminathan, CJ Taylor, Dheera Venkatraman,
 Xiaohan Fei, Stefano Soatto
Categories: cs.CV cs.AI cs.LG cs.RO
Comments: TLDR: Physical scenes are equivalence classes of sufficient
 statistics, and can be inferred uniquely by any agent measuring the same
 finite data; We formalize and implement an approach to representation
 learning that overturns "naive realism" in favor of an analytical approach of
 Russell and Koenderink. NeRFs cannot capture the physical scenes, but
 combined with Diffusion Models they can
\\
 We describe a first step towards learning general-purpose visual
representations of physical scenes using only image prediction as a training
criterion. To do so, we first define "physical scene" and show that, even
though different agents may maintain different representations of the same
scene, the underlying physical scene that can be inferred is unique. Then, we
show that NeRFs cannot represent the physical scene, as they lack extrapolation
mechanisms. Those, however, could be provided by Diffusion Models, at least in
theory. To test this hypothesis empirically, NeRFs can be combined with
Diffusion Models, a process we refer to as NeRF Diffusion, used as unsupervised
representations of the physical scene. Our analysis is limited to visual data,
without external grounding mechanisms that can be provided by independent
sensory modalities.
\\ ( https://arxiv.org/abs/2306.03727 ,  10141kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03747
Date: Tue, 6 Jun 2023 15:07:39 GMT   (24999kb,D)

Title: Towards Scalable Multi-View Reconstruction of Geometry and Materials
Authors: Carolin Schmitt and Bo\v{z}idar Anti\'c and Andrei Neculai and Joo Ho
 Lee and Andreas Geiger
Categories: cs.CV
\\
 In this paper, we propose a novel method for joint recovery of camera pose,
object geometry and spatially-varying Bidirectional Reflectance Distribution
Function (svBRDF) of 3D scenes that exceed object-scale and hence cannot be
captured with stationary light stages. The input are high-resolution RGB-D
images captured by a mobile, hand-held capture system with point lights for
active illumination. Compared to previous works that jointly estimate geometry
and materials from a hand-held scanner, we formulate this problem using a
single objective function that can be minimized using off-the-shelf
gradient-based solvers. To facilitate scalability to large numbers of
observation views and optimization variables, we introduce a distributed
optimization algorithm that reconstructs 2.5D keyframe-based representations of
the scene. A novel multi-view consistency regularizer effectively synchronizes
neighboring keyframes such that the local optimization results allow for
seamless integration into a globally consistent 3D model. We provide a study on
the importance of each component in our formulation and show that our method
compares favorably to baselines. We further demonstrate that our method
accurately reconstructs various objects and materials and allows for expansion
to spatially larger scenes. We believe that this work represents a significant
step towards making geometry and material estimation from hand-held scanners
scalable.
\\ ( https://arxiv.org/abs/2306.03747 ,  24999kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03779
Date: Tue, 6 Jun 2023 15:34:45 GMT   (32157kb,D)

Title: Performance-optimized deep neural networks are evolving into worse
 models of inferotemporal visual cortex
Authors: Drew Linsley, Ivan F. Rodriguez, Thomas Fel, Michael Arcaro, Saloni
 Sharma, Margaret Livingstone, Thomas Serre
Categories: cs.CV cs.AI
\\
 One of the most impactful findings in computational neuroscience over the
past decade is that the object recognition accuracy of deep neural networks
(DNNs) correlates with their ability to predict neural responses to natural
images in the inferotemporal (IT) cortex. This discovery supported the
long-held theory that object recognition is a core objective of the visual
cortex, and suggested that more accurate DNNs would serve as better models of
IT neuron responses to images. Since then, deep learning has undergone a
revolution of scale: billion parameter-scale DNNs trained on billions of images
are rivaling or outperforming humans at visual tasks including object
recognition. Have today's DNNs become more accurate at predicting IT neuron
responses to images as they have grown more accurate at object recognition?
 Surprisingly, across three independent experiments, we find this is not the
case. DNNs have become progressively worse models of IT as their accuracy has
increased on ImageNet. To understand why DNNs experience this trade-off and
evaluate if they are still an appropriate paradigm for modeling the visual
system, we turn to recordings of IT that capture spatially resolved maps of
neuronal activity elicited by natural images. These neuronal activity maps
reveal that DNNs trained on ImageNet learn to rely on different visual features
than those encoded by IT and that this problem worsens as their accuracy
increases. We successfully resolved this issue with the neural harmonizer, a
plug-and-play training routine for DNNs that aligns their learned
representations with humans. Our results suggest that harmonized DNNs break the
trade-off between ImageNet accuracy and neural prediction accuracy that assails
current DNNs and offer a path to more accurate models of biological vision.
\\ ( https://arxiv.org/abs/2306.03779 ,  32157kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03802
Date: Tue, 6 Jun 2023 15:45:53 GMT   (14785kb,D)

Title: Learning to Ground Instructional Articles in Videos through Narrations
Authors: Effrosyni Mavroudi, Triantafyllos Afouras, Lorenzo Torresani
Categories: cs.CV cs.AI
Comments: 17 pages, 4 figures and 10 tables
\\
 In this paper we present an approach for localizing steps of procedural
activities in narrated how-to videos. To deal with the scarcity of labeled data
at scale, we source the step descriptions from a language knowledge base
(wikiHow) containing instructional articles for a large variety of procedural
tasks. Without any form of manual supervision, our model learns to temporally
ground the steps of procedural articles in how-to videos by matching three
modalities: frames, narrations, and step descriptions. Specifically, our method
aligns steps to video by fusing information from two distinct pathways: i) {\em
direct} alignment of step descriptions to frames, ii) {\em indirect} alignment
obtained by composing steps-to-narrations with narrations-to-video
correspondences. Notably, our approach performs global temporal grounding of
all steps in an article at once by exploiting order information, and is trained
with step pseudo-labels which are iteratively refined and aggressively
filtered. In order to validate our model we introduce a new evaluation
benchmark -- HT-Step -- obtained by manually annotating a 124-hour subset of
HowTo100M\footnote{A test server is accessible at
\url{https://eval.ai/web/challenges/challenge-page/2082}.} with steps sourced
from wikiHow articles. Experiments on this benchmark as well as zero-shot
evaluations on CrossTask demonstrate that our multi-modality alignment yields
dramatic gains over several baselines and prior works. Finally, we show that
our inner module for matching narration-to-video outperforms by a large margin
the state of the art on the HTM-Align narration-video alignment benchmark.
\\ ( https://arxiv.org/abs/2306.03802 ,  14785kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03810
Date: Tue, 6 Jun 2023 15:52:55 GMT   (15303kb,D)

Title: X-Align++: cross-modal cross-view alignment for Bird's-eye-view
 segmentation
Authors: Shubhankar Borse, Senthil Yogamani, Marvin Klingner, Varun Ravi, Hong
 Cai, Abdulaziz Almuzairee and Fatih Porikli
Categories: cs.CV cs.RO
Comments: Accepted for publication at Springer Machine Vision and Applications
 Journal. The Version of Record of this article is published in Machine Vision
 and Applications Journal, and is available online at
 https://doi.org/10.1007/s00138-023-01400-7. arXiv admin note: substantial
 text overlap with arXiv:2210.06778
\\
 Bird's-eye-view (BEV) grid is a typical representation of the perception of
road components, e.g., drivable area, in autonomous driving. Most existing
approaches rely on cameras only to perform segmentation in BEV space, which is
fundamentally constrained by the absence of reliable depth information. The
latest works leverage both camera and LiDAR modalities but suboptimally fuse
their features using simple, concatenation-based mechanisms. In this paper, we
address these problems by enhancing the alignment of the unimodal features in
order to aid feature fusion, as well as enhancing the alignment between the
cameras' perspective view (PV) and BEV representations. We propose X-Align, a
novel end-to-end cross-modal and cross-view learning framework for BEV
segmentation consisting of the following components: (i) a novel Cross-Modal
Feature Alignment (X-FA) loss, (ii) an attention-based Cross-Modal Feature
Fusion (X-FF) module to align multi-modal BEV features implicitly, and (iii) an
auxiliary PV segmentation branch with Cross-View Segmentation Alignment (X-SA)
losses to improve the PV-to-BEV transformation. We evaluate our proposed method
across two commonly used benchmark datasets, i.e., nuScenes and KITTI-360.
Notably, X-Align significantly outperforms the state-of-the-art by 3 absolute
mIoU points on nuScenes. We also provide extensive ablation studies to
demonstrate the effectiveness of the individual components.
\\ ( https://arxiv.org/abs/2306.03810 ,  15303kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03847
Date: Tue, 6 Jun 2023 16:35:45 GMT   (2493kb,D)

Title: Learning Human Mesh Recovery in 3D Scenes
Authors: Zehong Shen, Zhi Cen, Sida Peng, Qing Shuai, Hujun Bao, Xiaowei Zhou
Categories: cs.CV
Comments: Accepted to CVPR 2023. Project page: https://zju3dv.github.io/sahmr/
\\
 We present a novel method for recovering the absolute pose and shape of a
human in a pre-scanned scene given a single image. Unlike previous methods that
perform sceneaware mesh optimization, we propose to first estimate absolute
position and dense scene contacts with a sparse 3D CNN, and later enhance a
pretrained human mesh recovery network by cross-attention with the derived 3D
scene cues. Joint learning on images and scene geometry enables our method to
reduce the ambiguity caused by depth and occlusion, resulting in more
reasonable global postures and contacts. Encoding scene-aware cues in the
network also allows the proposed method to be optimization-free, and opens up
the opportunity for real-time applications. The experiments show that the
proposed network is capable of recovering accurate and physically-plausible
meshes by a single forward pass and outperforms state-of-the-art methods in
terms of both accuracy and speed.
\\ ( https://arxiv.org/abs/2306.03847 ,  2493kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03878
Date: Tue, 6 Jun 2023 17:29:26 GMT   (834kb,D)

Title: Conditional Diffusion Models for Weakly Supervised Medical Image
 Segmentation
Authors: Xinrong Hu, Yu-Jen Chen, Tsung-Yi Ho, and Yiyu Shi
Categories: cs.CV
\\
 Recent advances in denoising diffusion probabilistic models have shown great
success in image synthesis tasks. While there are already works exploring the
potential of this powerful tool in image semantic segmentation, its application
in weakly supervised semantic segmentation (WSSS) remains relatively
under-explored. Observing that conditional diffusion models (CDM) is capable of
generating images subject to specific distributions, in this work, we utilize
category-aware semantic information underlied in CDM to get the prediction mask
of the target object with only image-level annotations. More specifically, we
locate the desired class by approximating the derivative of the output of CDM
w.r.t the input condition. Our method is different from previous diffusion
model methods with guidance from an external classifier, which accumulates
noises in the background during the reconstruction process. Our method
outperforms state-of-the-art CAM and diffusion model methods on two public
medical image segmentation datasets, which demonstrates that CDM is a promising
tool in WSSS. Also, experiment shows our method is more time-efficient than
existing diffusion model methods, making it practical for wider applications.
\\ ( https://arxiv.org/abs/2306.03878 ,  834kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03881
Date: Tue, 6 Jun 2023 17:33:19 GMT   (18581kb,D)

Title: Emergent Correspondence from Image Diffusion
Authors: Luming Tang, Menglin Jia, Qianqian Wang, Cheng Perng Phoo, Bharath
 Hariharan
Categories: cs.CV
Comments: Project page: https://diffusionfeatures.github.io
\\
 Finding correspondences between images is a fundamental problem in computer
vision. In this paper, we show that correspondence emerges in image diffusion
models without any explicit supervision. We propose a simple strategy to
extract this implicit knowledge out of diffusion networks as image features,
namely DIffusion FeaTures (DIFT), and use them to establish correspondences
between real images. Without any additional fine-tuning or supervision on the
task-specific data or annotations, DIFT is able to outperform both
weakly-supervised methods and competitive off-the-shelf features in identifying
semantic, geometric, and temporal correspondences. Particularly for semantic
correspondence, DIFT from Stable Diffusion is able to outperform DINO and
OpenCLIP by 19 and 14 accuracy points respectively on the challenging SPair-71k
benchmark. It even outperforms the state-of-the-art supervised methods on 9 out
of 18 categories while remaining on par for the overall performance. Project
page: https://diffusionfeatures.github.io
\\ ( https://arxiv.org/abs/2306.03881 ,  18581kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03899
Date: Tue, 6 Jun 2023 17:57:49 GMT   (49504kb,D)

Title: Towards Label-free Scene Understanding by Vision Foundation Models
Authors: Runnan Chen, Youquan Liu, Lingdong Kong, Nenglun Chen, Xinge Zhu,
 Yuexin Ma, Tongliang Liu, Wenping Wang
Categories: cs.CV
\\
 Vision foundation models such as Contrastive Vision-Language Pre-training
(CLIP) and Segment Anything (SAM) have demonstrated impressive zero-shot
performance on image classification and segmentation tasks. However, the
incorporation of CLIP and SAM for label-free scene understanding has yet to be
explored. In this paper, we investigate the potential of vision foundation
models in enabling networks to comprehend 2D and 3D worlds without labelled
data. The primary challenge lies in effectively supervising networks under
extremely noisy pseudo labels, which are generated by CLIP and further
exacerbated during the propagation from the 2D to the 3D domain. To tackle
these challenges, we propose a novel Cross-modality Noisy Supervision (CNS)
method that leverages the strengths of CLIP and SAM to supervise 2D and 3D
networks simultaneously. In particular, we introduce a prediction consistency
regularization to co-train 2D and 3D networks, then further impose the
networks' latent space consistency using the SAM's robust feature
representation. Experiments conducted on diverse indoor and outdoor datasets
demonstrate the superior performance of our method in understanding 2D and 3D
open environments. Our 2D and 3D network achieves label-free semantic
segmentation with 28.4% and 33.5% mIoU on ScanNet, improving 4.7% and 7.9%,
respectively. And for nuScenes dataset, our performance is 26.8% with an
improvement of 6%. Code will be released
(https://github.com/runnanchen/Label-Free-Scene-Understanding).
\\ ( https://arxiv.org/abs/2306.03899 ,  49504kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03908
Date: Tue, 6 Jun 2023 17:59:51 GMT   (1778kb,D)

Title: SAM3D: Segment Anything in 3D Scenes
Authors: Yunhan Yang, Xiaoyang Wu, Tong He, Hengshuang Zhao, Xihui Liu
Categories: cs.CV
Comments: Technical Report. The code is released at
 https://github.com/Pointcept/SegmentAnything3D
\\
 In this work, we propose SAM3D, a novel framework that is able to predict
masks in 3D point clouds by leveraging the Segment-Anything Model (SAM) in RGB
images without further training or finetuning. For a point cloud of a 3D scene
with posed RGB images, we first predict segmentation masks of RGB images with
SAM, and then project the 2D masks into the 3D points. Later, we merge the 3D
masks iteratively with a bottom-up merging approach. At each step, we merge the
point cloud masks of two adjacent frames with the bidirectional merging
approach. In this way, the 3D masks predicted from different frames are
gradually merged into the 3D masks of the whole 3D scene. Finally, we can
optionally ensemble the result from our SAM3D with the over-segmentation
results based on the geometric information of the 3D scenes. Our approach is
experimented with ScanNet dataset and qualitative results demonstrate that our
SAM3D achieves reasonable and fine-grained 3D segmentation results without any
training or finetuning of SAM.
\\ ( https://arxiv.org/abs/2306.03908 ,  1778kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03832
Date: Tue, 6 Jun 2023 16:20:44 GMT   (21kb,D)

Title: Sequential Principal-Agent Problems with Communication: Efficient
 Computation and Learning
Authors: Jiarui Gan, Rupak Majumdar, Debmalya Mandal, Goran Radanovic
Categories: cs.GT cs.LG cs.MA
\\
 We study a sequential decision making problem between a principal and an
agent with incomplete information on both sides. In this model, the principal
and the agent interact in a stochastic environment, and each is privy to
observations about the state not available to the other. The principal has the
power of commitment, both to elicit information from the agent and to provide
signals about her own information. The principal and the agent communicate
their signals to each other, and select their actions independently based on
this communication. Each player receives a payoff based on the state and their
joint actions, and the environment moves to a new state. The interaction
continues over a finite time horizon, and both players act to optimize their
own total payoffs over the horizon. Our model encompasses as special cases
stochastic games of incomplete information and POMDPs, as well as sequential
Bayesian persuasion and mechanism design problems. We study both computation of
optimal policies and learning in our setting. While the general problems are
computationally intractable, we study algorithmic solutions under a conditional
independence assumption on the underlying state-observation distributions. We
present an polynomial-time algorithm to compute the principal's optimal policy
up to an additive approximation. Additionally, we show an efficient learning
algorithm in the case where the transition probabilities are not known
beforehand. The algorithm guarantees sublinear regret for both players.
\\ ( https://arxiv.org/abs/2306.03832 ,  21kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03163
Date: Mon, 5 Jun 2023 18:17:37 GMT   (909kb,D)

Title: How Can We Train Deep Learning Models Across Clouds and Continents? An
 Experimental Study
Authors: Alexander Isenko, Ruben Mayer, Hans-Arno Jacobsen
Categories: cs.LG cs.DC cs.NI cs.PF
Comments: Currently in review. Artifacts and Code:
 https://github.com/cirquit/hivemind-multi-cloud
ACM-class: I.2.11; C.2.4; C.4; D.2.8
\\
 Training deep learning models in the cloud or on dedicated hardware is
expensive. A more cost-efficient option are hyperscale clouds offering spot
instances, a cheap but ephemeral alternative to on-demand resources. As spot
instance availability can change depending on the time of day, continent, and
cloud provider, it could be more cost-efficient to distribute resources over
the world. Still, it has not been investigated whether geo-distributed,
data-parallel spot deep learning training could be a more cost-efficient
alternative to centralized training.
 This paper aims to answer the question: Can deep learning models be
cost-efficiently trained on a global market of spot VMs spanning different data
centers and cloud providers? To provide guidance, we extensively evaluate the
cost and throughput implications of training in different zones, continents,
and clouds for representative CV and NLP models. To expand the current training
options further, we compare the scalability potential for hybrid-cloud
scenarios by adding cloud resources to on-premise hardware to improve training
throughput. Finally, we show how leveraging spot instance pricing enables a new
cost-efficient way to train models with multiple cheap VMs, trumping both more
centralized and powerful hardware and even on-demand cloud offerings at
competitive prices.
\\ ( https://arxiv.org/abs/2306.03163 ,  909kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03173
Date: Mon, 5 Jun 2023 18:29:00 GMT   (1508kb,D)

Title: Linear Distance Metric Learning
Authors: Meysam Alishahi, Anna Little, and Jeff M. Phillips
Categories: cs.LG
Comments: 45 pages
\\
 In linear distance metric learning, we are given data in one Euclidean metric
space and the goal is to find an appropriate linear map to another Euclidean
metric space which respects certain distance conditions as much as possible. In
this paper, we formalize a simple and elegant method which reduces to a general
continuous convex loss optimization problem, and for different noise models we
derive the corresponding loss functions. We show that even if the data is
noisy, the ground truth linear metric can be learned with any precision
provided access to enough samples, and we provide a corresponding sample
complexity bound. Moreover, we present an effective way to truncate the learned
model to a low-rank model that can provably maintain the accuracy in loss
function and in parameters -- the first such results of this type. Several
experimental observations on synthetic and real data sets support and inform
our theoretical results.
\\ ( https://arxiv.org/abs/2306.03173 ,  1508kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03179
Date: Mon, 5 Jun 2023 18:40:35 GMT   (744kb)

Title: Fair Patient Model: Mitigating Bias in the Patient Representation
 Learned from the Electronic Health Records
Authors: Sonish Sivarajkumar, Yufei Huang, Yanshan Wang
Categories: cs.LG cs.AI cs.CY
\\
 Objective: To pre-train fair and unbiased patient representations from
Electronic Health Records (EHRs) using a novel weighted loss function that
reduces bias and improves fairness in deep representation learning models.
 Methods: We defined a new loss function, called weighted loss function, in
the deep representation learning model to balance the importance of different
groups of patients and features. We applied the proposed model, called Fair
Patient Model (FPM), to a sample of 34,739 patients from the MIMIC-III dataset
and learned patient representations for four clinical outcome prediction tasks.
 Results: FPM outperformed the baseline models in terms of three fairness
metrics: demographic parity, equality of opportunity difference, and equalized
odds ratio. FPM also achieved comparable predictive performance with the
baselines, with an average accuracy of 0.7912. Feature analysis revealed that
FPM captured more information from clinical features than the baselines.
 Conclusion: FPM is a novel method to pre-train fair and unbiased patient
representations from EHR data using a weighted loss function. The learned
representations can be used for various downstream tasks in healthcare and can
be extended to other domains where bias and fairness are important.
\\ ( https://arxiv.org/abs/2306.03179 ,  744kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03186
Date: Mon, 5 Jun 2023 18:56:48 GMT   (3462kb,D)

Title: Flipping Coins to Estimate Pseudocounts for Exploration in Reinforcement
 Learning
Authors: Sam Lobel and Akhil Bagaria and George Konidaris
Categories: cs.LG cs.AI
Comments: 11 pages (+9 appendix). Published as a conference paper at ICML 2023.
 Code available at https://github.com/samlobel/CFN/
\\
 We propose a new method for count-based exploration in high-dimensional state
spaces. Unlike previous work which relies on density models, we show that
counts can be derived by averaging samples from the Rademacher distribution (or
coin flips). This insight is used to set up a simple supervised learning
objective which, when optimized, yields a state's visitation count. We show
that our method is significantly more effective at deducing ground-truth
visitation counts than previous work; when used as an exploration bonus for a
model-free reinforcement learning algorithm, it outperforms existing approaches
on most of 9 challenging exploration tasks, including the Atari game
Montezuma's Revenge.
\\ ( https://arxiv.org/abs/2306.03186 ,  3462kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03209
Date: Mon, 5 Jun 2023 19:34:36 GMT   (3557kb,D)

Title: End-to-end Differentiable Clustering with Associative Memories
Authors: Bishwajit Saha, Dmitry Krotov, Mohammed J. Zaki, Parikshit Ram
Categories: cs.LG
Comments: Accepted to ICML 2023
\\
 Clustering is a widely used unsupervised learning technique involving an
intensive discrete optimization problem. Associative Memory models or AMs are
differentiable neural networks defining a recursive dynamical system, which
have been integrated with various deep learning architectures. We uncover a
novel connection between the AM dynamics and the inherent discrete assignment
necessary in clustering to propose a novel unconstrained continuous relaxation
of the discrete clustering problem, enabling end-to-end differentiable
clustering with AM, dubbed ClAM. Leveraging the pattern completion ability of
AMs, we further develop a novel self-supervised clustering loss. Our
evaluations on varied datasets demonstrate that ClAM benefits from the
self-supervision, and significantly improves upon both the traditional Lloyd's
k-means algorithm, and more recent continuous clustering relaxations (by upto
60% in terms of the Silhouette Coefficient).
\\ ( https://arxiv.org/abs/2306.03209 ,  3557kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03221
Date: Mon, 5 Jun 2023 20:11:30 GMT   (248kb,D)

Title: Structural Re-weighting Improves Graph Domain Adaptation
Authors: Shikun Liu, Tianchun Li, Yongbin Feng, Nhan Tran, Han Zhao, Qiu Qiang,
 Pan Li
Categories: cs.LG cs.AI cs.SI
Comments: ICML 2023, Codes: https://github.com/Graph-COM/StruRW
\\
 In many real-world applications, graph-structured data used for training and
testing have differences in distribution, such as in high energy physics (HEP)
where simulation data used for training may not match real experiments. Graph
domain adaptation (GDA) is a method used to address these differences. However,
current GDA primarily works by aligning the distributions of node
representations output by a single graph neural network encoder shared across
the training and testing domains, which may often yield sub-optimal solutions.
This work examines different impacts of distribution shifts caused by either
graph structure or node attributes and identifies a new type of shift, named
conditional structure shift (CSS), which current GDA approaches are provably
sub-optimal to deal with. A novel approach, called structural reweighting
(StruRW), is proposed to address this issue and is tested on synthetic graphs,
four benchmark datasets, and a new application in HEP. StruRW has shown
significant performance improvement over the baselines in the settings with
large graph structure shifts, and reasonable performance improvement when node
attribute shift dominates.
\\ ( https://arxiv.org/abs/2306.03221 ,  248kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03228
Date: Mon, 5 Jun 2023 20:22:05 GMT   (17372kb,D)

Title: Discovering Novel Biological Traits From Images Using Phylogeny-Guided
 Neural Networks
Authors: Mohannad Elhamod, Mridul Khurana, Harish Babu Manogaran, Josef C.
 Uyeda, Meghan A. Balk, Wasila Dahdul, Yasin Bak{\i}\c{s}, Henry L. Bart Jr.,
 Paula M. Mabee, Hilmar Lapp, James P. Balhoff, Caleb Charpentier, David
 Carlyn, Wei-Lun Chao, Charles V. Stewart, Daniel I. Rubenstein, Tanya
 Berger-Wolf, Anuj Karpatne
Categories: cs.LG cs.CV eess.IV
\\
 Discovering evolutionary traits that are heritable across species on the tree
of life (also referred to as a phylogenetic tree) is of great interest to
biologists to understand how organisms diversify and evolve. However, the
measurement of traits is often a subjective and labor-intensive process, making
trait discovery a highly label-scarce problem. We present a novel approach for
discovering evolutionary traits directly from images without relying on trait
labels. Our proposed approach, Phylo-NN, encodes the image of an organism into
a sequence of quantized feature vectors -- or codes -- where different segments
of the sequence capture evolutionary signals at varying ancestry levels in the
phylogeny. We demonstrate the effectiveness of our approach in producing
biologically meaningful results in a number of downstream tasks including
species image generation and species-to-species image translation, using fish
species as a target example.
\\ ( https://arxiv.org/abs/2306.03228 ,  17372kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03235
Date: Mon, 5 Jun 2023 20:40:05 GMT   (494kb,D)

Title: Information Flow Control in Machine Learning through Modular Model
 Architecture
Authors: Trishita Tiwari, Suchin Gururangan, Chuan Guo, Weizhe Hua, Sanjay
 Kariyappa, Udit Gupta, Wenjie Xiong, Kiwan Maeng, Hsien-Hsin S. Lee, G.
 Edward Suh
Categories: cs.LG cs.CR
\\
 In today's machine learning (ML) models, any part of the training data can
affect its output. This lack of control for information flow from training data
to model output is a major obstacle in training models on sensitive data when
access control only allows individual users to access a subset of data. To
enable secure machine learning for access controlled data, we propose the
notion of information flow control for machine learning, and develop a secure
Transformer-based language model based on the Mixture-of-Experts (MoE)
architecture. The secure MoE architecture controls information flow by limiting
the influence of training data from each security domain to a single expert
module, and only enabling a subset of experts at inference time based on an
access control policy. The evaluation using a large corpus of text data shows
that the proposed MoE architecture has minimal (1.9%) performance overhead and
can significantly improve model accuracy (up to 37%) by enabling training on
access-controlled data.
\\ ( https://arxiv.org/abs/2306.03235 ,  494kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03240
Date: Mon, 5 Jun 2023 20:50:36 GMT   (799kb,D)

Title: Improving Accelerated Federated Learning with Compression and Importance
 Sampling
Authors: Micha{\l} Grudzie\'n, Grigory Malinovsky, Peter Richt\'arik
Categories: cs.LG
Comments: 33 pages, 3 algorithms, 1 figure
\\
 Federated Learning is a collaborative training framework that leverages
heterogeneous data distributed across a vast number of clients. Since it is
practically infeasible to request and process all clients during the
aggregation step, partial participation must be supported. In this setting, the
communication between the server and clients poses a major bottleneck. To
reduce communication loads, there are two main approaches: compression and
local steps. Recent work by Mishchenko et al. [2022] introduced the new
ProxSkip method, which achieves an accelerated rate using the local steps
technique. Follow-up works successfully combined local steps acceleration with
partial participation [Grudzie\'n et al., 2023, Condat et al. 2023] and
gradient compression [Condat et al. [2022]. In this paper, we finally present a
complete method for Federated Learning that incorporates all necessary
ingredients: Local Training, Compression, and Partial Participation. We obtain
state-of-the-art convergence guarantees in the considered setting. Moreover, we
analyze the general sampling framework for partial participation and derive an
importance sampling scheme, which leads to even better performance. We
experimentally demonstrate the advantages of the proposed method in practice.
\\ ( https://arxiv.org/abs/2306.03240 ,  799kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03241
Date: Mon, 5 Jun 2023 20:51:44 GMT   (2559kb,D)

Title: Understanding the Effectiveness of Early Weight Averaging for Training
 Large Language Models
Authors: Sunny Sanyal, Jean Kaddour, Abhishek Kumar and Sujay Sanghavi
Categories: cs.LG cs.AI cs.CL
Comments: 17 pages, 12 figures, under review
\\
 Training LLMs is expensive, and recent evidence indicates training all the
way to convergence is inefficient. In this paper, we investigate the ability of
a simple idea, checkpoint averaging along the trajectory of a training run to
improve the quality of models before they have converged. This approach incurs
no extra cost during training or inference. Specifically, we analyze the
training trajectories of Pythia LLMs with 1 to 12 billion parameters and
demonstrate that, particularly during the early to mid stages of training, this
idea accelerates convergence and improves both test and zero-shot
generalization. Loss spikes are a well recognized problem in LLM training; in
our analysis we encountered two instances of this in the underlying
trajectories, and both instances were mitigated by our averaging.
 For a 6.9B parameter LLM, for example, our early weight averaging recipe can
save upto 4200 hours of GPU time, which corresponds to significant savings in
cloud compute costs.
\\ ( https://arxiv.org/abs/2306.03241 ,  2559kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03249
Date: Mon, 5 Jun 2023 21:08:34 GMT   (955kb,D)

Title: Probabilistic Unrolling: Scalable, Inverse-Free Maximum Likelihood
 Estimation for Latent Gaussian Models
Authors: Alexander Lin, Bahareh Tolooshams, Yves Atchad\'e, Demba Ba
Categories: cs.LG eess.SP stat.CO
Comments: 29 pages, 4 figures
Journal-ref: International Conference on Machine Learning, 2023
\\
 Latent Gaussian models have a rich history in statistics and machine
learning, with applications ranging from factor analysis to compressed sensing
to time series analysis. The classical method for maximizing the likelihood of
these models is the expectation-maximization (EM) algorithm. For problems with
high-dimensional latent variables and large datasets, EM scales poorly because
it needs to invert as many large covariance matrices as the number of data
points. We introduce probabilistic unrolling, a method that combines Monte
Carlo sampling with iterative linear solvers to circumvent matrix inversion.
Our theoretical analyses reveal that unrolling and backpropagation through the
iterations of the solver can accelerate gradient estimation for maximum
likelihood estimation. In experiments on simulated and real data, we
demonstrate that probabilistic unrolling learns latent Gaussian models up to an
order of magnitude faster than gradient EM, with minimal losses in model
performance.
\\ ( https://arxiv.org/abs/2306.03249 ,  955kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03256
Date: Mon, 5 Jun 2023 21:17:48 GMT   (1730kb,D)

Title: Explaining and Adapting Graph Conditional Shift
Authors: Qi Zhu, Yizhu Jiao, Natalia Ponomareva, Jiawei Han, Bryan Perozzi
Categories: cs.LG stat.ML
\\
 Graph Neural Networks (GNNs) have shown remarkable performance on
graph-structured data. However, recent empirical studies suggest that GNNs are
very susceptible to distribution shift. There is still significant ambiguity
about why graph-based models seem more vulnerable to these shifts. In this work
we provide a thorough theoretical analysis on it by quantifying the magnitude
of conditional shift between the input features and the output label. Our
findings show that both graph heterophily and model architecture exacerbate
conditional shifts, leading to performance degradation. To address this, we
propose an approach that involves estimating and minimizing the conditional
shift for unsupervised domain adaptation on graphs. In our controlled synthetic
experiments, our algorithm demonstrates robustness towards distribution shift,
resulting in up to 10% absolute ROC AUC improvement versus the second-best
algorithm. Furthermore, comprehensive experiments on both node classification
and graph classification show its robust performance under various distribution
shifts.
\\ ( https://arxiv.org/abs/2306.03256 ,  1730kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03262
Date: Mon, 5 Jun 2023 21:26:12 GMT   (1073kb,D)

Title: Has the Machine Learning Review Process Become More Arbitrary as the
 Field Has Grown? The NeurIPS 2021 Consistency Experiment
Authors: Alina Beygelzimer, Yann N. Dauphin, Percy Liang, Jennifer Wortman
 Vaughan
Categories: cs.LG cs.DL
\\
 We present the NeurIPS 2021 consistency experiment, a larger-scale variant of
the 2014 NeurIPS experiment in which 10% of conference submissions were
reviewed by two independent committees to quantify the randomness in the review
process. We observe that the two committees disagree on their accept/reject
recommendations for 23% of the papers and that, consistent with the results
from 2014, approximately half of the list of accepted papers would change if
the review process were randomly rerun. Our analysis suggests that making the
conference more selective would increase the arbitrariness of the process.
Taken together with previous research, our results highlight the inherent
difficulty of objectively measuring the quality of research, and suggest that
authors should not be excessively discouraged by rejected work.
\\ ( https://arxiv.org/abs/2306.03262 ,  1073kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03266
Date: Mon, 5 Jun 2023 21:35:32 GMT   (120kb,D)

Title: Towards Arbitrarily Expressive GNNs in $O(n^2)$ Space by Rethinking
 Folklore Weisfeiler-Lehman
Authors: Jiarui Feng, Lecheng Kong, Hao Liu, Dacheng Tao, Fuhai Li, Muhan
 Zhang, Yixin Chen
Categories: cs.LG stat.ML
\\
 Message passing neural networks (MPNNs) have emerged as the most popular
framework of graph neural networks (GNNs) in recent years. However, their
expressive power is limited by the 1-dimensional Weisfeiler-Lehman (1-WL) test.
Some works are inspired by $k$-WL/FWL (Folklore WL) and design the
corresponding neural versions. Despite the high expressive power, there are
serious limitations in this line of research. In particular, (1) $k$-WL/FWL
requires at least $O(n^k)$ space complexity, which is impractical for large
graphs even when $k=3$; (2) The design space of $k$-WL/FWL is rigid, with the
only adjustable hyper-parameter being $k$. To tackle the first limitation, we
propose an extension, $(k, t)$-FWL. We theoretically prove that even if we fix
the space complexity to $O(n^2)$ in $(k, t)$-FWL, we can construct an
expressiveness hierarchy up to solving the graph isomorphism problem. To tackle
the second problem, we propose $k$-FWL+, which considers any equivariant set as
neighbors instead of all nodes, thereby greatly expanding the design space of
$k$-FWL. Combining these two modifications results in a flexible and powerful
framework $(k, t)$-FWL+. We demonstrate $(k, t)$-FWL+ can implement most
existing models with matching expressiveness. We then introduce an instance of
$(k,t)$-FWL+ called Neighborhood$^2$-FWL (N$^2$-FWL), which is practically and
theoretically sound. We prove that N$^2$-FWL is no less powerful than 3-WL, can
encode many substructures while only requiring $O(n^2)$ space. Finally, we
design its neural version named N$^2$-GNN and evaluate its performance on
various tasks. N$^2$-GNN achieves superior performance on almost all tasks,
with record-breaking results on ZINC-Subset (0.059) and ZINC-Full (0.013),
outperforming previous state-of-the-art results by 10.6% and 40.9%,
respectively.
\\ ( https://arxiv.org/abs/2306.03266 ,  120kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03273
Date: Mon, 5 Jun 2023 21:45:23 GMT   (1161kb)

Title: Under-Counted Tensor Completion with Neural Incorporation of Attributes
Authors: Shahana Ibrahim, Xiao Fu, Rebecca Hutchinson, Eugene Seo
Categories: cs.LG eess.SP
Comments: 33 pages, 5 figures, ICML 2023
\\
 Systematic under-counting effects are observed in data collected across many
disciplines, e.g., epidemiology and ecology. Under-counted tensor completion
(UC-TC) is well-motivated for many data analytics tasks, e.g., inferring the
case numbers of infectious diseases at unobserved locations from under-counted
case numbers in neighboring regions. However, existing methods for similar
problems often lack supports in theory, making it hard to understand the
underlying principles and conditions beyond empirical successes. In this work,
a low-rank Poisson tensor model with an expressive unknown nonlinear side
information extractor is proposed for under-counted multi-aspect data. A joint
low-rank tensor completion and neural network learning algorithm is designed to
recover the model. Moreover, the UC-TC formulation is supported by theoretical
analysis showing that the fully counted entries of the tensor and each entry's
under-counting probability can be provably recovered from partial observations
-- under reasonable conditions. To our best knowledge, the result is the first
to offer theoretical supports for under-counted multi-aspect data completion.
Simulations and real-data experiments corroborate the theoretical claims.
\\ ( https://arxiv.org/abs/2306.03273 ,  1161kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03284
Date: Mon, 5 Jun 2023 22:09:06 GMT   (5324kb,D)

Title: Optimizing Sampling Patterns for Compressed Sensing MRI with Diffusion
 Generative Models
Authors: Sriram Ravula, Brett Levac, Ajil Jalal, Jonathan I. Tamir, Alexandros
 G. Dimakis
Categories: cs.LG eess.IV
\\
 Diffusion-based generative models have been used as powerful priors for
magnetic resonance imaging (MRI) reconstruction. We present a learning method
to optimize sub-sampling patterns for compressed sensing multi-coil MRI that
leverages pre-trained diffusion generative models. Crucially, during training
we use a single-step reconstruction based on the posterior mean estimate given
by the diffusion model and the MRI measurement process. Experiments across
varying anatomies, acceleration factors, and pattern types show that sampling
operators learned with our method lead to competitive, and in the case of 2D
patterns, improved reconstructions compared to baseline patterns. Our method
requires as few as five training images to learn effective sampling patterns.
\\ ( https://arxiv.org/abs/2306.03284 ,  5324kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03286
Date: Mon, 5 Jun 2023 22:15:39 GMT   (13103kb,D)

Title: Survival Instinct in Offline Reinforcement Learning
Authors: Anqi Li, Dipendra Misra, Andrey Kolobov, Ching-An Cheng
Categories: cs.LG cs.AI
\\
 We present a novel observation about the behavior of offline reinforcement
learning (RL) algorithms: on many benchmark datasets, offline RL can produce
well-performing and safe policies even when trained with "wrong" reward labels,
such as those that are zero everywhere or are negatives of the true rewards.
This phenomenon cannot be easily explained by offline RL's return maximization
objective. Moreover, it gives offline RL a degree of robustness that is
uncharacteristic of its online RL counterparts, which are known to be sensitive
to reward design. We demonstrate that this surprising robustness property is
attributable to an interplay between the notion of pessimism in offline RL
algorithms and a certain bias implicit in common data collection practices. As
we prove in this work, pessimism endows the agent with a "survival instinct",
i.e., an incentive to stay within the data support in the long term, while the
limited and biased data coverage further constrains the set of survival
policies. Formally, given a reward class -- which may not even contain the true
reward -- we identify conditions on the training data distribution that enable
offline RL to learn a near-optimal and safe policy from any reward within the
class. We argue that the survival instinct should be taken into account when
interpreting results from existing offline RL benchmarks and when creating
future ones. Our empirical and theoretical results suggest a new paradigm for
RL, whereby an agent is "nudged" to learn a desirable behavior with imperfect
reward but purposely biased data coverage.
\\ ( https://arxiv.org/abs/2306.03286 ,  13103kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03288
Date: Mon, 5 Jun 2023 22:21:26 GMT   (971kb,D)

Title: Deep Learning From Crowdsourced Labels: Coupled Cross-entropy
 Minimization, Identifiability, and Regularization
Authors: Shahana Ibrahim, Tri Nguyen, Xiao Fu
Categories: cs.LG eess.SP stat.ML
Comments: 39 pages, 5 figures, ICLR 2023
\\
 Using noisy crowdsourced labels from multiple annotators, a deep
learning-based end-to-end (E2E) system aims to learn the label correction
mechanism and the neural classifier simultaneously. To this end, many E2E
systems concatenate the neural classifier with multiple annotator-specific
``label confusion'' layers and co-train the two parts in a parameter-coupled
manner. The formulated coupled cross-entropy minimization (CCEM)-type criteria
are intuitive and work well in practice. Nonetheless, theoretical understanding
of the CCEM criterion has been limited. The contribution of this work is
twofold: First, performance guarantees of the CCEM criterion are presented. Our
analysis reveals for the first time that the CCEM can indeed correctly identify
the annotators' confusion characteristics and the desired ``ground-truth''
neural classifier under realistic conditions, e.g., when only incomplete
annotator labeling and finite samples are available. Second, based on the
insights learned from our analysis, two regularized variants of the CCEM are
proposed. The regularization terms provably enhance the identifiability of the
target model parameters in various more challenging cases. A series of
synthetic and real data experiments are presented to showcase the effectiveness
of our approach.
\\ ( https://arxiv.org/abs/2306.03288 ,  971kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03291
Date: Mon, 5 Jun 2023 22:25:28 GMT   (7070kb,D)

Title: Switching Autoregressive Low-rank Tensor Models
Authors: Hyun Dong Lee, Andrew Warrington, Joshua I. Glaser, Scott W. Linderman
Categories: cs.LG stat.ME stat.ML
\\
 An important problem in time-series analysis is modeling systems with
time-varying dynamics. Probabilistic models with joint continuous and discrete
latent states offer interpretable, efficient, and experimentally useful
descriptions of such data. Commonly used models include autoregressive hidden
Markov models (ARHMMs) and switching linear dynamical systems (SLDSs), each
with its own advantages and disadvantages. ARHMMs permit exact inference and
easy parameter estimation, but are parameter intensive when modeling long
dependencies, and hence are prone to overfitting. In contrast, SLDSs can
capture long-range dependencies in a parameter efficient way through Markovian
latent dynamics, but present an intractable likelihood and a challenging
parameter estimation task. In this paper, we propose switching autoregressive
low-rank tensor (SALT) models, which retain the advantages of both approaches
while ameliorating the weaknesses. SALT parameterizes the tensor of an ARHMM
with a low-rank factorization to control the number of parameters and allow
longer range dependencies without overfitting. We prove theoretical and discuss
practical connections between SALT, linear dynamical systems, and SLDSs. We
empirically demonstrate quantitative advantages of SALT models on a range of
simulated and real prediction tasks, including behavioral and neural datasets.
Furthermore, the learned low-rank tensor provides novel insights into temporal
dependencies within each discrete state.
\\ ( https://arxiv.org/abs/2306.03291 ,  7070kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03301
Date: Mon, 5 Jun 2023 23:03:03 GMT   (936kb,D)

Title: Estimating Conditional Mutual Information for Dynamic Feature Selection
Authors: Soham Gadgil, Ian Covert, Su-In Lee
Categories: cs.LG cs.IT math.IT
\\
 Dynamic feature selection, where we sequentially query features to make
accurate predictions with a minimal budget, is a promising paradigm to reduce
feature acquisition costs and provide transparency into the prediction process.
The problem is challenging, however, as it requires both making predictions
with arbitrary feature sets and learning a policy to identify the most valuable
selections. Here, we take an information-theoretic perspective and prioritize
features based on their mutual information with the response variable. The main
challenge is learning this selection policy, and we design a straightforward
new modeling approach that estimates the mutual information in a discriminative
rather than generative fashion. Building on our learning approach, we introduce
several further improvements: allowing variable feature budgets across samples,
enabling non-uniform costs between features, incorporating prior information,
and exploring modern architectures to handle partial input information. We find
that our method provides consistent gains over recent state-of-the-art methods
across a variety of datasets.
\\ ( https://arxiv.org/abs/2306.03301 ,  936kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03311
Date: Mon, 5 Jun 2023 23:38:31 GMT   (5181kb,D)

Title: Learning Embeddings for Sequential Tasks Using Population of Agents
Authors: Mridul Mahajan, Georgios Tzannetos, Goran Radanovic, Adish Singla
Categories: cs.LG cs.AI
\\
 We present an information-theoretic framework to learn fixed-dimensional
embeddings for tasks in reinforcement learning. We leverage the idea that two
tasks are similar to each other if observing an agent's performance on one task
reduces our uncertainty about its performance on the other. This intuition is
captured by our information-theoretic criterion which uses a diverse population
of agents to measure similarity between tasks in sequential decision-making
settings. In addition to qualitative assessment, we empirically demonstrate the
effectiveness of our techniques based on task embeddings by quantitative
comparisons against strong baselines on two application scenarios: predicting
an agent's performance on a test task by observing its performance on a small
quiz of tasks, and selecting tasks with desired characteristics from a given
set of options.
\\ ( https://arxiv.org/abs/2306.03311 ,  5181kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03322
Date: Tue, 6 Jun 2023 00:23:28 GMT   (63kb,D)

Title: Stochastic Multi-Level Compositional Optimization Algorithms over
 Networks with Level-Independent Convergence Rate
Authors: Hongchang Gao
Categories: cs.LG
\\
 Stochastic multi-level compositional optimization problems cover many new
machine learning paradigms, e.g., multi-step model-agnostic meta-learning,
which require efficient optimization algorithms for large-scale applications.
This paper studies the decentralized stochastic multi-level optimization
algorithm, which is challenging because the multi-level structure and
decentralized communication scheme may make the number of levels affect the
order of the convergence rate. To this end, we develop two novel decentralized
optimization algorithms to deal with the multi-level function and its gradient.
Our theoretical results show that both algorithms can achieve the
level-independent convergence rate for nonconvex problems under much milder
conditions compared with existing single-machine algorithms. To the best of our
knowledge, this is the first work that achieves the level-independent
convergence rate under the decentralized setting. Moreover, extensive
experiments confirm the efficacy of our proposed algorithms.
\\ ( https://arxiv.org/abs/2306.03322 ,  63kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03329
Date: Tue, 6 Jun 2023 00:42:36 GMT   (7884kb,D)

Title: AVIDa-hIL6: A Large-Scale VHH Dataset Produced from an Immunized Alpaca
 for Predicting Antigen-Antibody Interactions
Authors: Hirofumi Tsuruta, Hiroyuki Yamazaki, Ryota Maeda, Ryotaro Tamura,
 Jennifer N. Wei, Zelda Mariet, Poomarin Phloyphisut, Hidetoshi Shimokawa,
 Joseph R. Ledsam, Lucy Colwell, Akihiro Imura
Categories: cs.LG q-bio.QM
\\
 Antibodies have become an important class of therapeutic agents to treat
human diseases. To accelerate therapeutic antibody discovery, computational
methods, especially machine learning, have attracted considerable interest for
predicting specific interactions between antibody candidates and target
antigens such as viruses and bacteria. However, the publicly available datasets
in existing works have notable limitations, such as small sizes and the lack of
non-binding samples and exact amino acid sequences. To overcome these
limitations, we have developed AVIDa-hIL6, a large-scale dataset for predicting
antigen-antibody interactions in the variable domain of heavy chain of heavy
chain antibodies (VHHs), produced from an alpaca immunized with the human
interleukin-6 (IL-6) protein, as antigens. By leveraging the simple structure
of VHHs, which facilitates identification of full-length amino acid sequences
by DNA sequencing technology, AVIDa-hIL6 contains 573,891 antigen-VHH pairs
with amino acid sequences. All the antigen-VHH pairs have reliable labels for
binding or non-binding, as generated by a novel labeling method. Furthermore,
via introduction of artificial mutations, AVIDa-hIL6 contains 30 different
mutants in addition to wild-type IL-6 protein. This characteristic provides
opportunities to develop machine learning models for predicting changes in
antibody binding by antigen mutations. We report experimental benchmark results
on AVIDa-hIL6 by using neural network-based baseline models. The results
indicate that the existing models have potential, but further research is
needed to generalize them to predict effective antibodies against unknown
mutants. The dataset is available at https://avida-hil6.cognanous.com.
\\ ( https://arxiv.org/abs/2306.03329 ,  7884kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03341
Date: Tue, 6 Jun 2023 01:26:53 GMT   (1677kb,D)

Title: Inference-Time Intervention: Eliciting Truthful Answers from a Language
 Model
Authors: Kenneth Li, Oam Patel, Fernanda Vi\'egas, Hanspeter Pfister, Martin
 Wattenberg
Categories: cs.LG cs.AI cs.CL
Comments: code: https://github.com/likenneth/honest_llama
\\
 We introduce Inference-Time Intervention (ITI), a technique designed to
enhance the truthfulness of large language models (LLMs). ITI operates by
shifting model activations during inference, following a set of directions
across a limited number of attention heads. This intervention significantly
improves the performance of LLaMA models on the TruthfulQA benchmark. On an
instruction-finetuned LLaMA called Alpaca, ITI improves its truthfulness from
32.5% to 65.1%. We identify a tradeoff between truthfulness and helpfulness and
demonstrate how to balance it by tuning the intervention strength. ITI is
minimally invasive and computationally inexpensive. Moreover, the technique is
data efficient: while approaches like RLHF require extensive annotations, ITI
locates truthful directions using only few hundred examples. Our findings
suggest that LLMs may have an internal representation of the likelihood of
something being true, even as they produce falsehoods on the surface.
\\ ( https://arxiv.org/abs/2306.03341 ,  1677kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03346
Date: Tue, 6 Jun 2023 01:36:56 GMT   (7828kb,D)

Title: Stabilizing Contrastive RL: Techniques for Offline Goal Reaching
Authors: Chongyi Zheng, Benjamin Eysenbach, Homer Walke, Patrick Yin, Kuan
 Fang, Ruslan Salakhutdinov, Sergey Levine
Categories: cs.LG cs.AI
\\
 In the same way that the computer vision (CV) and natural language processing
(NLP) communities have developed self-supervised methods, reinforcement
learning (RL) can be cast as a self-supervised problem: learning to reach any
goal, without requiring human-specified rewards or labels. However, actually
building a self-supervised foundation for RL faces some important challenges.
Building on prior contrastive approaches to this RL problem, we conduct careful
ablation experiments and discover that a shallow and wide architecture,
combined with careful weight initialization and data augmentation, can
significantly boost the performance of these contrastive RL approaches on
challenging simulated benchmarks. Additionally, we demonstrate that, with these
design decisions, contrastive approaches can solve real-world robotic
manipulation tasks, with tasks being specified by a single goal image provided
after training.
\\ ( https://arxiv.org/abs/2306.03346 ,  7828kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03355
Date: Tue, 6 Jun 2023 02:13:27 GMT   (12053kb,D)

Title: BatchSampler: Sampling Mini-Batches for Contrastive Learning in Vision,
 Language, and Graphs
Authors: Zhen Yang, Tinglin Huang, Ming Ding, Yuxiao Dong, Rex Ying, Yukuo Cen,
 Yangliao Geng, and Jie Tang
Categories: cs.LG cs.CL cs.CV
Comments: 17 pages, 16 figures
Journal-ref: KDD2023
\\
 In-Batch contrastive learning is a state-of-the-art self-supervised method
that brings semantically-similar instances close while pushing dissimilar
instances apart within a mini-batch. Its key to success is the negative sharing
strategy, in which every instance serves as a negative for the others within
the mini-batch. Recent studies aim to improve performance by sampling hard
negatives \textit{within the current mini-batch}, whose quality is bounded by
the mini-batch itself. In this work, we propose to improve contrastive learning
by sampling mini-batches from the input data. We present
BatchSampler\footnote{The code is available at
\url{https://github.com/THUDM/BatchSampler}} to sample mini-batches of
hard-to-distinguish (i.e., hard and true negatives to each other) instances. To
make each mini-batch have fewer false negatives, we design the proximity graph
of randomly-selected instances. To form the mini-batch, we leverage random walk
with restart on the proximity graph to help sample hard-to-distinguish
instances. BatchSampler is a simple and general technique that can be directly
plugged into existing contrastive learning models in vision, language, and
graphs. Extensive experiments on datasets of three modalities show that
BatchSampler can consistently improve the performance of powerful contrastive
models, as shown by significant improvements of SimCLR on ImageNet-100, SimCSE
on STS (language), and GraphCL and MVGRL on graph datasets.
\\ ( https://arxiv.org/abs/2306.03355 ,  12053kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03356
Date: Tue, 6 Jun 2023 02:14:20 GMT   (318kb,D)

Title: Query Complexity of Active Learning for Function Family With Nearly
 Orthogonal Basis
Authors: Xiang Chen, Zhao Song, Baocheng Sun, Junze Yin, Danyang Zhuo
Categories: cs.LG
\\
 Many machine learning algorithms require large numbers of labeled data to
deliver state-of-the-art results. In applications such as medical diagnosis and
fraud detection, though there is an abundance of unlabeled data, it is costly
to label the data by experts, experiments, or simulations. Active learning
algorithms aim to reduce the number of required labeled data points while
preserving performance. For many convex optimization problems such as linear
regression and $p$-norm regression, there are theoretical bounds on the number
of required labels to achieve a certain accuracy. We call this the query
complexity of active learning. However, today's active learning algorithms
require the underlying learned function to have an orthogonal basis. For
example, when applying active learning to linear regression, the requirement is
the target function is a linear composition of a set of orthogonal linear
functions, and active learning can find the coefficients of these linear
functions. We present a theoretical result to show that active learning does
not need an orthogonal basis but rather only requires a nearly orthogonal
basis. We provide the corresponding theoretical proofs for the function family
of nearly orthogonal basis, and its applications associated with the
algorithmically efficient active learning framework.
\\ ( https://arxiv.org/abs/2306.03356 ,  318kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03360
Date: Tue, 6 Jun 2023 02:24:41 GMT   (2765kb,D)

Title: Vid2Act: Activate Offline Videos for Visual RL
Authors: Pan Minting, Zheng Yitao, Wang Yunbo, Yang Xiaokang
Categories: cs.LG cs.AI cs.RO
\\
 Pretraining RL models on offline video datasets is a promising way to improve
their training efficiency in online tasks, but challenging due to the inherent
mismatch in tasks, dynamics, and behaviors across domains. A recent model, APV,
sidesteps the accompanied action records in offline datasets and instead
focuses on pretraining a task-irrelevant, action-free world model within the
source domains. We present Vid2Act, a model-based RL method that learns to
transfer valuable action-conditioned dynamics and potentially useful action
demonstrations from offline to online settings. The main idea is to use the
world models not only as simulators for behavior learning but also as tools to
measure the domain relevance for both dynamics representation transfer and
policy transfer. Specifically, we train the world models to generate a set of
time-varying task similarities using a domain-selective knowledge distillation
loss. These similarities serve two purposes: (i) adaptively transferring the
most useful source knowledge to facilitate dynamics learning, and (ii) learning
to replay the most relevant source actions to guide the target policy. We
demonstrate the advantages of Vid2Act over the action-free visual RL
pretraining method in both Meta-World and DeepMind Control Suite.
\\ ( https://arxiv.org/abs/2306.03360 ,  2765kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03362
Date: Tue, 6 Jun 2023 02:29:40 GMT   (2070kb,D)

Title: Boosting Offline Reinforcement Learning with Action Preference Query
Authors: Qisen Yang, Shenzhi Wang, Matthieu Gaetan Lin, Shiji Song, Gao Huang
Categories: cs.LG cs.AI
Comments: International Conference on Machine Learning 2023
\\
 Training practical agents usually involve offline and online reinforcement
learning (RL) to balance the policy's performance and interaction costs. In
particular, online fine-tuning has become a commonly used method to correct the
erroneous estimates of out-of-distribution data learned in the offline training
phase. However, even limited online interactions can be inaccessible or
catastrophic for high-stake scenarios like healthcare and autonomous driving.
In this work, we introduce an interaction-free training scheme dubbed
Offline-with-Action-Preferences (OAP). The main insight is that, compared to
online fine-tuning, querying the preferences between pre-collected and learned
actions can be equally or even more helpful to the erroneous estimate problem.
By adaptively encouraging or suppressing policy constraint according to action
preferences, OAP could distinguish overestimation from beneficial policy
improvement and thus attains a more accurate evaluation of unseen data.
Theoretically, we prove a lower bound of the behavior policy's performance
improvement brought by OAP. Moreover, comprehensive experiments on the D4RL
benchmark and state-of-the-art algorithms demonstrate that OAP yields higher
(29% on average) scores, especially on challenging AntMaze tasks (98% higher).
\\ ( https://arxiv.org/abs/2306.03362 ,  2070kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03364
Date: Tue, 6 Jun 2023 02:38:01 GMT   (2165kb,D)

Title: Learning Representations on the Unit Sphere: Application to Online
 Continual Learning
Authors: Nicolas Michel, Giovanni Chierchia, Romain Negrel, Jean-Fran\c{c}ois
 Bercher
Categories: cs.LG cs.CV
Comments: 16 pages, 4 figures, under review
\\
 We use the maximum a posteriori estimation principle for learning
representations distributed on the unit sphere. We derive loss functions for
the von Mises-Fisher distribution and the angular Gaussian distribution, both
designed for modeling symmetric directional data. A noteworthy feature of our
approach is that the learned representations are pushed toward fixed
directions, allowing for a learning strategy that is resilient to data drift.
This makes it suitable for online continual learning, which is the problem of
training neural networks on a continuous data stream, where multiple
classification tasks are presented sequentially so that data from past tasks
are no longer accessible, and data from the current task can be seen only once.
To address this challenging scenario, we propose a memory-based representation
learning technique equipped with our new loss functions. Our approach does not
require negative data or knowledge of task boundaries and performs well with
smaller batch sizes while being computationally efficient. We demonstrate with
extensive experiments that the proposed method outperforms the current
state-of-the-art methods on both standard evaluation scenarios and realistic
scenarios with blurry task boundaries. For reproducibility, we use the same
training pipeline for every compared method and share the code at
https://t.ly/SQTj.
\\ ( https://arxiv.org/abs/2306.03364 ,  2165kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03390
Date: Tue, 6 Jun 2023 04:07:21 GMT   (3249kb,D)

Title: Origin-Destination Network Generation via Gravity-Guided GAN
Authors: Can Rong, Huandong Wang, Yong Li
Categories: cs.LG
Comments: 10 pages, 8 figures
\\
 Origin-destination (OD) flow, which contains valuable population mobility
information including direction and volume, is critical in many urban
applications, such as urban planning, transportation management, etc. However,
OD data is not always easy to access due to high costs or privacy concerns.
Therefore, we must consider generating OD through mathematical models. Existing
works utilize physics laws or machine learning (ML) models to build the
association between urban structures and OD flows while these two kinds of
methods suffer from the limitation of over-simplicity and poor generalization
ability, respectively. In this paper, we propose to adopt physics-informed ML
paradigm, which couple the physics scientific knowledge and data-driven ML
methods, to construct a model named Origin-Destination Generation Networks
(ODGN) for better population mobility modeling by leveraging the complementary
strengths of combining physics and ML methods. Specifically, we first build a
Multi-view Graph Attention Networks (MGAT) to capture the urban features of
every region and then use a gravity-guided predictor to obtain OD flow between
every two regions. Furthermore, we use a conditional GAN training strategy and
design a sequence-based discriminator to consider the overall topological
features of OD as a network. Extensive experiments on real-world datasets have
been done to demonstrate the superiority of our proposed method compared with
baselines.
\\ ( https://arxiv.org/abs/2306.03390 ,  3249kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03401
Date: Tue, 6 Jun 2023 04:32:10 GMT   (1903kb,D)

Title: A Lightweight Method for Tackling Unknown Participation Probabilities in
 Federated Averaging
Authors: Shiqiang Wang, Mingyue Ji
Categories: cs.LG cs.DC cs.IT math.IT math.OC stat.ML
\\
 In federated learning (FL), clients usually have diverse participation
probabilities that are unknown a priori, which can significantly harm the
performance of FL if not handled properly. Existing works aiming at addressing
this problem are usually based on global variance reduction, which requires a
substantial amount of additional memory in a multiplicative factor equal to the
total number of clients. An important open problem is to find a lightweight
method for FL in the presence of clients with unknown participation rates. In
this paper, we address this problem by adapting the aggregation weights in
federated averaging (FedAvg) based on the participation history of each client.
We first show that, with heterogeneous participation probabilities, FedAvg with
non-optimal aggregation weights can diverge from the optimal solution of the
original FL objective, indicating the need of finding optimal aggregation
weights. However, it is difficult to compute the optimal weights when the
participation probabilities are unknown. To address this problem, we present a
new algorithm called FedAU, which improves FedAvg by adaptively weighting the
client updates based on online estimates of the optimal weights without knowing
the probabilities of client participation. We provide a theoretical convergence
analysis of FedAU using a novel methodology to connect the estimation error and
convergence. Our theoretical results reveal important and interesting insights,
while showing that FedAU converges to an optimal solution of the original
objective and has desirable properties such as linear speedup. Our experimental
results also verify the advantage of FedAU over baseline methods.
\\ ( https://arxiv.org/abs/2306.03401 ,  1903kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03406
Date: Tue, 6 Jun 2023 04:57:39 GMT   (4933kb)

Title: Deep neural networks architectures from the perspective of manifold
 learning
Authors: German Magai
Categories: cs.LG cs.AI cs.CV math.AT
Comments: 11 pages, 12 figures, PRAI2023. arXiv admin note: substantial text
 overlap with arXiv:2204.08624
\\
 Despite significant advances in the field of deep learning in ap-plications
to various areas, an explanation of the learning pro-cess of neural network
models remains an important open ques-tion. The purpose of this paper is a
comprehensive comparison and description of neural network architectures in
terms of ge-ometry and topology. We focus on the internal representation of
neural networks and on the dynamics of changes in the topology and geometry of
a data manifold on different layers. In this paper, we use the concepts of
topological data analysis (TDA) and persistent homological fractal dimension.
We present a wide range of experiments with various datasets and configurations
of convolutional neural network (CNNs) architectures and Transformers in CV and
NLP tasks. Our work is a contribution to the development of the important field
of explainable and interpretable AI within the framework of geometrical deep
learning.
\\ ( https://arxiv.org/abs/2306.03406 ,  4933kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03412
Date: Tue, 6 Jun 2023 05:20:53 GMT   (1670kb,D)

Title: DEK-Forecaster: A Novel Deep Learning Model Integrated with EMD-KNN for
 Traffic Prediction
Authors: Sajal Saha, Sudipto Baral, and Anwar Haque
Categories: cs.LG
Comments: 13 pages, 9 figures
\\
 Internet traffic volume estimation has a significant impact on the business
policies of the ISP (Internet Service Provider) industry and business
successions. Forecasting the internet traffic demand helps to shed light on the
future traffic trend, which is often helpful for ISPs decision-making in
network planning activities and investments. Besides, the capability to
understand future trend contributes to managing regular and long-term
operations. This study aims to predict the network traffic volume demand using
deep sequence methods that incorporate Empirical Mode Decomposition (EMD) based
noise reduction, Empirical rule based outlier detection, and $K$-Nearest
Neighbour (KNN) based outlier mitigation. In contrast to the former studies,
the proposed model does not rely on a particular EMD decomposed component
called Intrinsic Mode Function (IMF) for signal denoising. In our proposed
traffic prediction model, we used an average of all IMFs components for signal
denoising. Moreover, the abnormal data points are replaced by $K$ nearest data
points average, and the value for $K$ has been optimized based on the KNN
regressor prediction error measured in Root Mean Squared Error (RMSE). Finally,
we selected the best time-lagged feature subset for our prediction model based
on AutoRegressive Integrated Moving Average (ARIMA) and Akaike Information
Criterion (AIC) value. Our experiments are conducted on real-world internet
traffic datasets from industry, and the proposed method is compared with
various traditional deep sequence baseline models. Our results show that the
proposed EMD-KNN integrated prediction models outperform comparative models.
\\ ( https://arxiv.org/abs/2306.03412 ,  1670kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03434
Date: Tue, 6 Jun 2023 06:22:42 GMT   (166kb,D)

Title: Learning-Based Heuristic for Combinatorial Optimization of the Minimum
 Dominating Set Problem using Graph Convolutional Networks
Authors: Abihith Kothapalli, Mudassir Shabbir, Xenofon Koutsoukos
Categories: cs.LG cs.DM
\\
 A dominating set of a graph $\mathcal{G=(V, E)}$ is a subset of vertices
$S\subseteq\mathcal{V}$ such that every vertex $v\in \mathcal{V} \setminus S$
outside the dominating set is adjacent to a vertex $u\in S$ within the set. The
minimum dominating set problem seeks to find a dominating set of minimum
cardinality and is a well-established NP-hard combinatorial optimization
problem. We propose a novel learning-based heuristic approach to compute
solutions for the minimum dominating set problem using graph convolutional
networks. We conduct an extensive experimental evaluation of the proposed
method on a combination of randomly generated graphs and real-world graph
datasets. Our results indicate that the proposed learning-based approach can
outperform a classical greedy approximation algorithm. Furthermore, we
demonstrate the generalization capability of the graph convolutional network
across datasets and its ability to scale to graphs of higher order than those
on which it was trained. Finally, we utilize the proposed learning-based
heuristic in an iterative greedy algorithm, achieving state-of-the-art
performance in the computation of dominating sets.
\\ ( https://arxiv.org/abs/2306.03434 ,  166kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03435
Date: Tue, 6 Jun 2023 06:23:38 GMT   (1337kb,D)

Title: On the Role of Attention in Prompt-tuning
Authors: Samet Oymak, Ankit Singh Rawat, Mahdi Soltanolkotabi, Christos
 Thrampoulidis
Categories: cs.LG cs.CL stat.ML
Comments: Published at ICML 2023
\\
 Prompt-tuning is an emerging strategy to adapt large language models (LLM) to
downstream tasks by learning a (soft-)prompt parameter from data. Despite its
success in LLMs, there is limited theoretical understanding of the power of
prompt-tuning and the role of the attention mechanism in prompting. In this
work, we explore prompt-tuning for one-layer attention architectures and study
contextual mixture-models where each input token belongs to a context-relevant
or -irrelevant set. We isolate the role of prompt-tuning through a
self-contained prompt-attention model. Our contributions are as follows: (1) We
show that softmax-prompt-attention is provably more expressive than
softmax-self-attention and linear-prompt-attention under our contextual data
model. (2) We analyze the initial trajectory of gradient descent and show that
it learns the prompt and prediction head with near-optimal sample complexity
and demonstrate how prompt can provably attend to sparse context-relevant
tokens. (3) Assuming a known prompt but an unknown prediction head, we
characterize the exact finite sample performance of prompt-attention which
reveals the fundamental performance limits and the precise benefit of the
context information. We also provide experiments that verify our theoretical
insights on real datasets and demonstrate how prompt-tuning enables the model
to attend to context-relevant information.
\\ ( https://arxiv.org/abs/2306.03435 ,  1337kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03438
Date: Tue, 6 Jun 2023 06:35:27 GMT   (1330kb,D)

Title: Large Language Models of Code Fail at Completing Code with Potential
 Bugs
Authors: Tuan Dinh, Jinman Zhao, Samson Tan, Renato Negrinho, Leonard Lausen,
 Sheng Zha, George Karypis
Categories: cs.LG cs.AI cs.CL cs.SE
Comments: 25 pages
\\
 Large language models of code (Code-LLMs) have recently brought tremendous
advances to code completion, a fundamental feature of programming assistance
and code intelligence. However, most existing works ignore the possible
presence of bugs in the code context for generation, which are inevitable in
software development. Therefore, we introduce and study the buggy-code
completion problem, inspired by the realistic scenario of real-time code
suggestion where the code context contains potential bugs -- anti-patterns that
can become bugs in the completed program. To systematically study the task, we
introduce two datasets: one with synthetic bugs derived from semantics-altering
operator changes (buggy-HumanEval) and one with realistic bugs derived from
user submissions to coding problems (buggy-FixEval). We find that the presence
of potential bugs significantly degrades the generation performance of the
high-performing Code-LLMs. For instance, the passing rates of CodeGen-2B-mono
on test cases of buggy-HumanEval drop more than 50% given a single potential
bug in the context. Finally, we investigate several post-hoc methods for
mitigating the adverse effect of potential bugs and find that there remains a
large gap in post-mitigation performance.
\\ ( https://arxiv.org/abs/2306.03438 ,  1330kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03440
Date: Tue, 6 Jun 2023 06:37:07 GMT   (361kb,D)

Title: Quantifying the Variability Collapse of Neural Networks
Authors: Jing Xu, Haoxiong Liu
Categories: cs.LG
\\
 Recent studies empirically demonstrate the positive relationship between the
transferability of neural networks and the within-class variation of the last
layer features. The recently discovered Neural Collapse (NC) phenomenon
provides a new perspective of understanding such last layer geometry of neural
networks. In this paper, we propose a novel metric, named Variability Collapse
Index (VCI), to quantify the variability collapse phenomenon in the NC
paradigm. The VCI metric is well-motivated and intrinsically related to the
linear probing loss on the last layer features. Moreover, it enjoys desired
theoretical and empirical properties, including invariance under invertible
linear transformations and numerical stability, that distinguishes it from
previous metrics. Our experiments verify that VCI is indicative of the
variability collapse and the transferability of pretrained neural networks.
\\ ( https://arxiv.org/abs/2306.03440 ,  361kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03447
Date: Tue, 6 Jun 2023 07:00:24 GMT   (2610kb,D)

Title: GRAFENNE: Learning on Graphs with Heterogeneous and Dynamic Feature Sets
Authors: Shubham Gupta, Sahil Manchanda, Sayan Ranu, Srikanta Bedathur
Categories: cs.LG cs.AI
Comments: 17 pages, 4 figures and 9 tables. Accepted in ICML 2023, DOI will be
 updated once it is available
\\
 Graph neural networks (GNNs), in general, are built on the assumption of a
static set of features characterizing each node in a graph. This assumption is
often violated in practice. Existing methods partly address this issue through
feature imputation. However, these techniques (i) assume uniformity of feature
set across nodes, (ii) are transductive by nature, and (iii) fail to work when
features are added or removed over time. In this work, we address these
limitations through a novel GNN framework called GRAFENNE. GRAFENNE performs a
novel allotropic transformation on the original graph, wherein the nodes and
features are decoupled through a bipartite encoding. Through a carefully chosen
message passing framework on the allotropic transformation, we make the model
parameter size independent of the number of features and thereby inductive to
both unseen nodes and features. We prove that GRAFENNE is at least as
expressive as any of the existing message-passing GNNs in terms of
Weisfeiler-Leman tests, and therefore, the additional inductivity to unseen
features does not come at the cost of expressivity. In addition, as
demonstrated over four real-world graphs, GRAFENNE empowers the underlying GNN
with high empirical efficacy and the ability to learn in continual fashion over
streaming feature sets.
\\ ( https://arxiv.org/abs/2306.03447 ,  2610kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03460
Date: Tue, 6 Jun 2023 07:28:49 GMT   (1438kb,D)

Title: Natural Language Commanding via Program Synthesis
Authors: Apurva Gandhi, Thong Q. Nguyen, Huitian Jiao, Robert Steen, Ameya
 Bhatawdekar
Categories: cs.LG cs.CL cs.HC
\\
 We present Semantic Interpreter, a natural language-friendly AI system for
productivity software such as Microsoft Office that leverages large language
models (LLMs) to execute user intent across application features. While LLMs
are excellent at understanding user intent expressed as natural language, they
are not sufficient for fulfilling application-specific user intent that
requires more than text-to-text transformations. We therefore introduce the
Office Domain Specific Language (ODSL), a concise, high-level language
specialized for performing actions in and interacting with entities in Office
applications. Semantic Interpreter leverages an Analysis-Retrieval prompt
construction method with LLMs for program synthesis, translating natural
language user utterances to ODSL programs that can be transpiled to application
APIs and then executed. We focus our discussion primarily on a research
exploration for Microsoft PowerPoint.
\\ ( https://arxiv.org/abs/2306.03460 ,  1438kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03480
Date: Tue, 6 Jun 2023 08:03:18 GMT   (2449kb,D)

Title: GSHOT: Few-shot Generative Modeling of Labeled Graphs
Authors: Sahil Manchanda, Shubham Gupta, Sayan Ranu, Srikanta Bedathur
Categories: cs.LG cs.AI
\\
 Deep graph generative modeling has gained enormous attraction in recent years
due to its impressive ability to directly learn the underlying hidden graph
distribution. Despite their initial success, these techniques, like much of the
existing deep generative methods, require a large number of training samples to
learn a good model. Unfortunately, large number of training samples may not
always be available in scenarios such as drug discovery for rare diseases. At
the same time, recent advances in few-shot learning have opened door to
applications where available training data is limited. In this work, we
introduce the hitherto unexplored paradigm of few-shot graph generative
modeling. Towards this, we develop GSHOT, a meta-learning based framework for
few-shot labeled graph generative modeling. GSHOT learns to transfer
meta-knowledge from similar auxiliary graph datasets. Utilizing these prior
experiences, GSHOT quickly adapts to an unseen graph dataset through self-paced
fine-tuning. Through extensive experiments on datasets from diverse domains
having limited training samples, we establish that GSHOT generates graphs of
superior fidelity compared to existing baselines.
\\ ( https://arxiv.org/abs/2306.03480 ,  2449kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03506
Date: Tue, 6 Jun 2023 08:52:44 GMT   (3942kb,D)

Title: Subgraph Networks Based Contrastive Learning
Authors: Jinhuan Wang, Jiafei Shao, Zeyu Wang, Shanqing Yu, Qi Xuan, Xiaoniu
 Yang
Categories: cs.LG cs.AI
Comments: 12 pages, 6 figures
\\
 Graph contrastive learning (GCL), as a self-supervised learning method, can
solve the problem of annotated data scarcity. It mines explicit features in
unannotated graphs to generate favorable graph representations for downstream
tasks. Most existing GCL methods focus on the design of graph augmentation
strategies and mutual information estimation operations. Graph augmentation
produces augmented views by graph perturbations. These views preserve a locally
similar structure and exploit explicit features. However, these methods have
not considered the interaction existing in subgraphs. To explore the impact of
substructure interactions on graph representations, we propose a novel
framework called subgraph network-based contrastive learning (SGNCL). SGNCL
applies a subgraph network generation strategy to produce augmented views. This
strategy converts the original graph into an Edge-to-Node mapping network with
both topological and attribute features. The single-shot augmented view is a
first-order subgraph network that mines the interaction between nodes,
node-edge, and edges. In addition, we also investigate the impact of the
second-order subgraph augmentation on mining graph structure interactions, and
further, propose a contrastive objective that fuses the first-order and
second-order subgraph information. We compare SGNCL with classical and
state-of-the-art graph contrastive learning methods on multiple benchmark
datasets of different domains. Extensive experiments show that SGNCL achieves
competitive or better performance (top three) on all datasets in unsupervised
learning settings. Furthermore, SGNCL achieves the best average gain of 6.9\%
in transfer learning compared to the best method. Finally, experiments also
demonstrate that mining substructure interactions have positive implications
for graph contrastive learning.
\\ ( https://arxiv.org/abs/2306.03506 ,  3942kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03515
Date: Tue, 6 Jun 2023 09:01:17 GMT   (4236kb,D)

Title: Logic Diffusion for Knowledge Graph Reasoning
Authors: Xiaoying Xie, Biao Gong, Yiliang Lv, Zhen Han, Guoshuai Zhao, Xueming
 Qian
Categories: cs.LG cs.AI cs.LO
Comments: 10 pages, 6 figures
\\
 Most recent works focus on answering first order logical queries to explore
the knowledge graph reasoning via multi-hop logic predictions. However,
existing reasoning models are limited by the circumscribed logical paradigms of
training samples, which leads to a weak generalization of unseen logic. To
address these issues, we propose a plug-in module called Logic Diffusion (LoD)
to discover unseen queries from surroundings and achieves dynamical equilibrium
between different kinds of patterns. The basic idea of LoD is relation
diffusion and sampling sub-logic by random walking as well as a special
training mechanism called gradient adaption. Besides, LoD is accompanied by a
novel loss function to further achieve the robust logical diffusion when facing
noisy data in training or testing sets. Extensive experiments on four public
datasets demonstrate the superiority of mainstream knowledge graph reasoning
models with LoD over state-of-the-art. Moreover, our ablation study proves the
general effectiveness of LoD on the noise-rich knowledge graph.
\\ ( https://arxiv.org/abs/2306.03515 ,  4236kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03521
Date: Tue, 6 Jun 2023 09:12:49 GMT   (1039kb,D)

Title: Machine learning in and out of equilibrium
Authors: Shishir Adhikari, Alkan Kabak\c{c}{\i}o\u{g}lu, Alexander Strang,
 Deniz Yuret, Michael Hinczewski
Categories: cs.LG cond-mat.stat-mech
Comments: 24 pages, 6 figures
\\
 The algorithms used to train neural networks, like stochastic gradient
descent (SGD), have close parallels to natural processes that navigate a
high-dimensional parameter space -- for example protein folding or evolution.
Our study uses a Fokker-Planck approach, adapted from statistical physics, to
explore these parallels in a single, unified framework. We focus in particular
on the stationary state of the system in the long-time limit, which in
conventional SGD is out of equilibrium, exhibiting persistent currents in the
space of network parameters. As in its physical analogues, the current is
associated with an entropy production rate for any given training trajectory.
The stationary distribution of these rates obeys the integral and detailed
fluctuation theorems -- nonequilibrium generalizations of the second law of
thermodynamics. We validate these relations in two numerical examples, a
nonlinear regression network and MNIST digit classification. While the
fluctuation theorems are universal, there are other aspects of the stationary
state that are highly sensitive to the training details. Surprisingly, the
effective loss landscape and diffusion matrix that determine the shape of the
stationary distribution vary depending on the simple choice of minibatching
done with or without replacement. We can take advantage of this nonequilibrium
sensitivity to engineer an equilibrium stationary state for a particular
application: sampling from a posterior distribution of network weights in
Bayesian machine learning. We propose a new variation of stochastic gradient
Langevin dynamics (SGLD) that harnesses without replacement minibatching. In an
example system where the posterior is exactly known, this SGWORLD algorithm
outperforms SGLD, converging to the posterior orders of magnitude faster as a
function of the learning rate.
\\ ( https://arxiv.org/abs/2306.03521 ,  1039kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03522
Date: Tue, 6 Jun 2023 09:14:05 GMT   (10143kb,D)

Title: A Functional Data Perspective and Baseline On Multi-Layer
 Out-of-Distribution Detection
Authors: Eduardo Dadalto, Pierre Colombo, Guillaume Staerman, Nathan Noiry, and
 Pablo Piantanida
Categories: cs.LG cs.CV stat.ML
\\
 A key feature of out-of-distribution (OOD) detection is to exploit a trained
neural network by extracting statistical patterns and relationships through the
multi-layer classifier to detect shifts in the expected input data
distribution. Despite achieving solid results, several state-of-the-art methods
rely on the penultimate or last layer outputs only, leaving behind valuable
information for OOD detection. Methods that explore the multiple layers either
require a special architecture or a supervised objective to do so. This work
adopts an original approach based on a functional view of the network that
exploits the sample's trajectories through the various layers and their
statistical dependencies. It goes beyond multivariate features aggregation and
introduces a baseline rooted in functional anomaly detection. In this new
framework, OOD detection translates into detecting samples whose trajectories
differ from the typical behavior characterized by the training set. We validate
our method and empirically demonstrate its effectiveness in OOD detection
compared to strong state-of-the-art baselines on computer vision benchmarks.
\\ ( https://arxiv.org/abs/2306.03522 ,  10143kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03530
Date: Tue, 6 Jun 2023 09:26:43 GMT   (1597kb,D)

Title: BackpropTools: A Fast, Portable Deep Reinforcement Learning Library for
 Continuous Control
Authors: Jonas Eschmann, Dario Albani, Giuseppe Loianno
Categories: cs.LG cs.AI cs.RO
Comments: Project page: https://backprop.tools
\\
 Deep Reinforcement Learning (RL) has been demonstrated to yield capable
agents and control policies in several domains but is commonly plagued by
prohibitively long training times. Additionally, in the case of continuous
control problems, the applicability of learned policies on real-world embedded
devices is limited due to the lack of real-time guarantees and portability of
existing deep learning libraries. To address these challenges, we present
BackpropTools, a dependency-free, header-only, pure C++ library for deep
supervised and reinforcement learning. Leveraging the template meta-programming
capabilities of recent C++ standards, we provide composable components that can
be tightly integrated by the compiler. Its novel architecture allows
BackpropTools to be used seamlessly on a heterogeneous set of platforms, from
HPC clusters over workstations and laptops to smartphones, smartwatches, and
microcontrollers. Specifically, due to the tight integration of the RL
algorithms with simulation environments, BackpropTools can solve popular RL
problems like the Pendulum-v1 swing-up about 7 to 15 times faster in terms of
wall-clock training time compared to other popular RL frameworks when using
TD3. We also provide a low-overhead and parallelized interface to the MuJoCo
simulator, showing that our PPO implementation achieves state of the art
returns in the Ant-v4 environment while achieving a 25 to 30 percent faster
wall-clock training time. Finally, we also benchmark the policy inference on a
diverse set of microcontrollers and show that in most cases our optimized
inference implementation is much faster than even the manufacturer's DSP
libraries. To the best of our knowledge, BackpropTools enables the first-ever
demonstration of training a deep RL algorithm directly on a microcontroller,
giving rise to the field of Tiny Reinforcement Learning (TinyRL). Project page:
https://backprop.tools
\\ ( https://arxiv.org/abs/2306.03530 ,  1597kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03534
Date: Tue, 6 Jun 2023 09:34:11 GMT   (639kb,D)

Title: Continual Learning in Linear Classification on Separable Data
Authors: Itay Evron, Edward Moroshko, Gon Buzaglo, Maroun Khriesh, Badea
 Marjieh, Nathan Srebro, Daniel Soudry
Categories: cs.LG cs.NA math.NA
\\
 We analyze continual learning on a sequence of separable linear
classification tasks with binary labels. We show theoretically that learning
with weak regularization reduces to solving a sequential max-margin problem,
corresponding to a special case of the Projection Onto Convex Sets (POCS)
framework. We then develop upper bounds on the forgetting and other quantities
of interest under various settings with recurring tasks, including cyclic and
random orderings of tasks. We discuss several practical implications to popular
training practices like regularization scheduling and weighting. We point out
several theoretical differences between our continual classification setting
and a recently studied continual regression setting.
\\ ( https://arxiv.org/abs/2306.03534 ,  639kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03536
Date: Tue, 6 Jun 2023 09:35:29 GMT   (7746kb,D)

Title: On Pitfalls of Test-Time Adaptation
Authors: Hao Zhao, Yuejiang Liu, Alexandre Alahi, Tao Lin
Categories: cs.LG cs.AI
Comments: Accepted at ICML 2023
\\
 Test-Time Adaptation (TTA) has recently emerged as a promising approach for
tackling the robustness challenge under distribution shifts. However, the lack
of consistent settings and systematic studies in prior literature hinders
thorough assessments of existing methods. To address this issue, we present
TTAB, a test-time adaptation benchmark that encompasses ten state-of-the-art
algorithms, a diverse array of distribution shifts, and two evaluation
protocols. Through extensive experiments, our benchmark reveals three common
pitfalls in prior efforts. First, selecting appropriate hyper-parameters,
especially for model selection, is exceedingly difficult due to online batch
dependency. Second, the effectiveness of TTA varies greatly depending on the
quality and properties of the model being adapted. Third, even under optimal
algorithmic conditions, none of the existing methods are capable of addressing
all common types of distribution shifts. Our findings underscore the need for
future research in the field to conduct rigorous evaluations on a broader set
of models and shifts, and to re-examine the assumptions behind the empirical
success of TTA. Our code is available at
\url{https://github.com/lins-lab/ttab}.
\\ ( https://arxiv.org/abs/2306.03536 ,  7746kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03542
Date: Tue, 6 Jun 2023 09:38:57 GMT   (327kb,D)

Title: Masked Autoencoders are Efficient Continual Federated Learners
Authors: Subarnaduti Paul, Lars-Joel Frey, Roshni Kamath, Kristian Kersting,
 Martin Mundt
Categories: cs.LG
\\
 Machine learning is typically framed from a perspective of i.i.d., and more
importantly, isolated data. In parts, federated learning lifts this assumption,
as it sets out to solve the real-world challenge of collaboratively learning a
shared model from data distributed across clients. However, motivated primarily
by privacy and computational constraints, the fact that data may change,
distributions drift, or even tasks advance individually on clients, is seldom
taken into account. The field of continual learning addresses this separate
challenge and first steps have recently been taken to leverage synergies in
distributed supervised settings, in which several clients learn to solve
changing classification tasks over time without forgetting previously seen
ones. Motivated by these prior works, we posit that such federated continual
learning should be grounded in unsupervised learning of representations that
are shared across clients; in the loose spirit of how humans can indirectly
leverage others' experience without exposure to a specific task. For this
purpose, we demonstrate that masked autoencoders for distribution estimation
are particularly amenable to this setup. Specifically, their masking strategy
can be seamlessly integrated with task attention mechanisms to enable selective
knowledge transfer between clients. We empirically corroborate the latter
statement through several continual federated scenarios on both image and
binary datasets.
\\ ( https://arxiv.org/abs/2306.03542 ,  327kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03543
Date: Tue, 6 Jun 2023 09:44:56 GMT   (1300kb,D)

Title: How to Select Which Active Learning Strategy is Best Suited for Your
 Specific Problem and Budget
Authors: Guy Hacohen, Daphna Weinshall
Categories: cs.LG
\\
 In Active Learning (AL), a learner actively chooses which unlabeled examples
to query for labels from an oracle, under some budget constraints. Different AL
query strategies are more suited to different problems and budgets. Therefore,
in practice, knowing in advance which AL strategy is most suited for the
problem at hand remains an open problem. To tackle this challenge, we propose a
practical derivative-based method that dynamically identifies the best strategy
for each budget. We provide theoretical analysis of a simplified case to
motivate our approach and build intuition. We then introduce a method to
dynamically select an AL strategy based on the specific problem and budget.
Empirical results showcase the effectiveness of our approach across diverse
budgets and computer vision tasks.
\\ ( https://arxiv.org/abs/2306.03543 ,  1300kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03548
Date: Tue, 6 Jun 2023 09:50:38 GMT   (2655kb,D)

Title: Learning Dynamical Systems from Noisy Data with Inverse-Explicit
 Integrators
Authors: H\r{a}kon Noren, S{\o}lve Eidnes and Elena Celledoni
Categories: cs.LG cs.NA math.NA
Comments: 23 pages, 10 figures
\\
 We introduce the mean inverse integrator (MII), a novel approach to increase
the accuracy when training neural networks to approximate vector fields of
dynamical systems from noisy data. This method can be used to average multiple
trajectories obtained by numerical integrators such as Runge-Kutta methods. We
show that the class of mono-implicit Runge-Kutta methods (MIRK) has particular
advantages when used in connection with MII. When training vector field
approximations, explicit expressions for the loss functions are obtained when
inserting the training data in the MIRK formulae, unlocking symmetric and
high-order integrators that would otherwise be implicit for initial value
problems. The combined approach of applying MIRK within MII yields a
significantly lower error compared to the plain use of the numerical integrator
without averaging the trajectories. This is demonstrated with experiments using
data from several (chaotic) Hamiltonian systems. Additionally, we perform a
sensitivity analysis of the loss functions under normally distributed
perturbations, supporting the favorable performance of MII.
\\ ( https://arxiv.org/abs/2306.03548 ,  2655kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03552
Date: Tue, 6 Jun 2023 10:06:09 GMT   (2299kb,D)

Title: State Regularized Policy Optimization on Data with Dynamics Shift
Authors: Zhenghai Xue, Qingpeng Cai, Shuchang Liu, Dong Zheng, Peng Jiang, Kun
 Gai, Bo An
Categories: cs.LG cs.AI
Comments: Preprint. Under Review
\\
 In many real-world scenarios, Reinforcement Learning (RL) algorithms are
trained on data with dynamics shift, i.e., with different underlying
environment dynamics. A majority of current methods address such issue by
training context encoders to identify environment parameters. Data with
dynamics shift are separated according to their environment parameters to train
the corresponding policy. However, these methods can be sample inefficient as
data are used \textit{ad hoc}, and policies trained for one dynamics cannot
benefit from data collected in all other environments with different dynamics.
In this paper, we find that in many environments with similar structures and
different dynamics, optimal policies have similar stationary state
distributions. We exploit such property and learn the stationary state
distribution from data with dynamics shift for efficient data reuse. Such
distribution is used to regularize the policy trained in a new environment,
leading to the SRPO (\textbf{S}tate \textbf{R}egularized \textbf{P}olicy
\textbf{O}ptimization) algorithm. To conduct theoretical analyses, the
intuition of similar environment structures is characterized by the notion of
homomorphous MDPs. We then demonstrate a lower-bound performance guarantee on
policies regularized by the stationary state distribution. In practice, SRPO
can be an add-on module to context-based algorithms in both online and offline
RL settings. Experimental results show that SRPO can make several context-based
algorithms far more data efficient and significantly improve their overall
performance.
\\ ( https://arxiv.org/abs/2306.03552 ,  2299kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03561
Date: Tue, 6 Jun 2023 10:25:10 GMT   (1710kb,D)

Title: CIN++: Enhancing Topological Message Passing
Authors: Lorenzo Giusti, Teodora Reu, Francesco Ceccarelli, Cristian Bodnar,
 Pietro Li\`o
Categories: cs.LG cs.AI
Comments: 21 pages, 9 figures
\\
 Graph Neural Networks (GNNs) have demonstrated remarkable success in learning
from graph-structured data. However, they face significant limitations in
expressive power, struggling with long-range interactions and lacking a
principled approach to modeling higher-order structures and group interactions.
Cellular Isomorphism Networks (CINs) recently addressed most of these
challenges with a message passing scheme based on cell complexes. Despite their
advantages, CINs make use only of boundary and upper messages which do not
consider a direct interaction between the rings present in the underlying
complex. Accounting for these interactions might be crucial for learning
representations of many real-world complex phenomena such as the dynamics of
supramolecular assemblies, neural activity within the brain, and gene
regulation processes. In this work, we propose CIN++, an enhancement of the
topological message passing scheme introduced in CINs. Our message passing
scheme accounts for the aforementioned limitations by letting the cells to
receive also lower messages within each layer. By providing a more
comprehensive representation of higher-order and long-range interactions, our
enhanced topological message passing scheme achieves state-of-the-art results
on large-scale and long-range chemistry benchmarks.
\\ ( https://arxiv.org/abs/2306.03561 ,  1710kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03566
Date: Tue, 6 Jun 2023 10:34:03 GMT   (11634kb,D)

Title: Memory-Based Dual Gaussian Processes for Sequential Learning
Authors: Paul E. Chang, Prakhar Verma, S.T. John, Arno Solin, Mohammad Emtiyaz
 Khan
Categories: cs.LG stat.ML
Comments: International Conference on Machine Learning (ICML) 2023
\\
 Sequential learning with Gaussian processes (GPs) is challenging when access
to past data is limited, for example, in continual and active learning. In such
cases, errors can accumulate over time due to inaccuracies in the posterior,
hyperparameters, and inducing points, making accurate learning challenging.
Here, we present a method to keep all such errors in check using the recently
proposed dual sparse variational GP. Our method enables accurate inference for
generic likelihoods and improves learning by actively building and updating a
memory of past data. We demonstrate its effectiveness in several applications
involving Bayesian optimization, active learning, and continual learning.
\\ ( https://arxiv.org/abs/2306.03566 ,  11634kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03570
Date: Tue, 6 Jun 2023 10:37:11 GMT   (27462kb,D)

Title: Personalization Disentanglement for Federated Learning
Authors: Peng Yan, Guodong Long
Categories: cs.LG
\\
 Personalized federated learning (PFL) jointly trains a variety of local
models through balancing between knowledge sharing across clients and model
personalization per client. This paper addresses PFL via explicit disentangling
latent representations into two parts to capture the shared knowledge and
client-specific personalization, which leads to more reliable and effective
PFL. The disentanglement is achieved by a novel Federated Dual Variational
Autoencoder (FedDVA), which employs two encoders to infer the two types of
representations. FedDVA can produce a better understanding of the trade-off
between global knowledge sharing and local personalization in PFL. Moreover, it
can be integrated with existing FL methods and turn them into personalized
models for heterogeneous downstream tasks. Extensive experiments validate the
advantages caused by disentanglement and show that models trained with
disentangled representations substantially outperform those vanilla methods.
\\ ( https://arxiv.org/abs/2306.03570 ,  27462kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03589
Date: Tue, 6 Jun 2023 11:15:53 GMT   (862kb,D)

Title: How does over-squashing affect the power of GNNs?
Authors: Francesco Di Giovanni, T. Konstantin Rusch, Michael M. Bronstein,
 Andreea Deac, Marc Lackenby, Siddhartha Mishra, Petar Veli\v{c}kovi\'c
Categories: cs.LG stat.ML
\\
 Graph Neural Networks (GNNs) are the state-of-the-art model for machine
learning on graph-structured data. The most popular class of GNNs operate by
exchanging information between adjacent nodes, and are known as Message Passing
Neural Networks (MPNNs). Given their widespread use, understanding the
expressive power of MPNNs is a key question. However, existing results
typically consider settings with uninformative node features. In this paper, we
provide a rigorous analysis to determine which function classes of node
features can be learned by an MPNN of a given capacity. We do so by measuring
the level of pairwise interactions between nodes that MPNNs allow for. This
measure provides a novel quantitative characterization of the so-called
over-squashing effect, which is observed to occur when a large volume of
messages is aggregated into fixed-size vectors. Using our measure, we prove
that, to guarantee sufficient communication between pairs of nodes, the
capacity of the MPNN must be large enough, depending on properties of the input
graph structure, such as commute times. For many relevant scenarios, our
analysis results in impossibility statements in practice, showing that
over-squashing hinders the expressive power of MPNNs. We validate our
theoretical findings through extensive controlled experiments and ablation
studies.
\\ ( https://arxiv.org/abs/2306.03589 ,  862kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03600
Date: Tue, 6 Jun 2023 11:44:42 GMT   (1290kb,D)

Title: Avoid Adversarial Adaption in Federated Learning by Multi-Metric
 Investigations
Authors: Torsten Krau{\ss} (1) and Alexandra Dmitrienko (1) ((1) University of
 W\"urzburg)
Categories: cs.LG
Comments: 23 pages, 12 figures, 27 tables, 11 equations
\\
 Federated Learning (FL) trains machine learning models on data distributed
across multiple devices, avoiding data transfer to a central location. This
improves privacy, reduces communication costs, and enhances model performance.
However, FL is prone to poisoning attacks, which can be untargeted aiming to
reduce the model performance, or targeted, so-called backdoors, which add
adversarial behavior that can be triggered with appropriately crafted inputs.
Striving for stealthiness, backdoor attacks are harder to deal with.
 Mitigation techniques against poisoning attacks rely on monitoring certain
metrics and filtering malicious model updates. However, previous works didn't
consider real-world adversaries and data distributions. To support our
statement, we define a new notion of strong adaptive adversaries that can
simultaneously adapt to multiple objectives and demonstrate through extensive
tests, that existing defense methods can be circumvented in this adversary
model. We also demonstrate, that existing defenses have limited effectiveness
when no assumptions are made about underlying data distributions.
 To address realistic scenarios and adversary models, we propose
Metric-Cascades (MESAS) a new defense that leverages multiple detection metrics
simultaneously for the filtering of poisoned model updates. This approach
forces adaptive attackers into a heavy multi-objective optimization problem,
and our evaluation with nine backdoors and three datasets shows that even our
strong adaptive attacker cannot evade MESAS's detection. We show that MESAS
outperforms existing defenses in distinguishing backdoors from distortions
originating from different data distributions within and across the clients.
Overall, MESAS is the first defense that is robust against strong adaptive
adversaries and is effective in real-world data scenarios while introducing a
low overhead of 24.37s on average.
\\ ( https://arxiv.org/abs/2306.03600 ,  1290kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03615
Date: Tue, 6 Jun 2023 12:07:50 GMT   (3826kb,D)

Title: Zero-shot Preference Learning for Offline RL via Optimal Transport
Authors: Runze Liu, Yali Du, Fengshuo Bai, Jiafei Lyu, Xiu Li
Categories: cs.LG
\\
 Preference-based Reinforcement Learning (PbRL) has demonstrated remarkable
efficacy in aligning rewards with human intentions. However, a significant
challenge lies in the need of substantial human labels, which is costly and
time-consuming. Additionally, the expensive preference data obtained from prior
tasks is not typically reusable for subsequent task learning, leading to
extensive labeling for each new task. In this paper, we propose a novel
zero-shot preference-based RL algorithm that leverages labeled preference data
from source tasks to infer labels for target tasks, eliminating the requirement
for human queries. Our approach utilizes Gromov-Wasserstein distance to align
trajectory distributions between source and target tasks. The solved optimal
transport matrix serves as a correspondence between trajectories of two tasks,
making it possible to identify corresponding trajectory pairs between tasks and
transfer the preference labels. However, learning directly from inferred labels
that contains a fraction of noisy labels will result in an inaccurate reward
function, subsequently affecting policy performance. To this end, we introduce
Robust Preference Transformer, which models the rewards as Gaussian
distributions and incorporates reward uncertainty in addition to reward mean.
The empirical results on robotic manipulation tasks of Meta-World and Robomimic
show that our method has strong capabilities of transferring preferences
between tasks and learns reward functions from noisy labels robustly.
Furthermore, we reveal that our method attains near-oracle performance with a
small proportion of scripted labels.
\\ ( https://arxiv.org/abs/2306.03615 ,  3826kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03626
Date: Tue, 6 Jun 2023 12:27:54 GMT   (473kb,D)

Title: Understanding Progressive Training Through the Framework of Randomized
 Coordinate Descent
Authors: Rafa{\l} Szlendak, Elnur Gasanov, Peter Richt\'arik
Categories: cs.LG math.OC
\\
 We propose a Randomized Progressive Training algorithm (RPT) -- a stochastic
proxy for the well-known Progressive Training method (PT) (Karras et al.,
2017). Originally designed to train GANs (Goodfellow et al., 2014), PT was
proposed as a heuristic, with no convergence analysis even for the simplest
objective functions. On the contrary, to the best of our knowledge, RPT is the
first PT-type algorithm with rigorous and sound theoretical guarantees for
general smooth objective functions. We cast our method into the established
framework of Randomized Coordinate Descent (RCD) (Nesterov, 2012; Richt\'arik &
Tak\'a\v{c}, 2014), for which (as a by-product of our investigations) we also
propose a novel, simple and general convergence analysis encapsulating
strongly-convex, convex and nonconvex objectives. We then use this framework to
establish a convergence theory for RPT. Finally, we validate the effectiveness
of our method through extensive computational experiments.
\\ ( https://arxiv.org/abs/2306.03626 ,  473kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03638
Date: Sun, 4 Jun 2023 11:31:41 GMT   (517kb)

Title: Provable convergence guarantees for black-box variational inference
Authors: Justin Domke, Guillaume Garrigos and Robert Gower
Categories: cs.LG math.OC stat.ML
Comments: 32 pages
\\
 While black-box variational inference is widely used, there is no proof that
its stochastic optimization succeeds. We suggest this is due to a theoretical
gap in existing stochastic optimization proofs-namely the challenge of gradient
estimators with unusual noise bounds, and a composite non-smooth objective. For
dense Gaussian variational families, we observe that existing gradient
estimators based on reparameterization satisfy a quadratic noise bound and give
novel convergence guarantees for proximal and projected stochastic gradient
descent using this bound. This provides the first rigorous guarantee that
black-box variational inference converges for realistic inference problems.
\\ ( https://arxiv.org/abs/2306.03638 ,  517kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03646
Date: Tue, 6 Jun 2023 13:00:47 GMT   (6694kb,D)

Title: Dance Generation by Sound Symbolic Words
Authors: Miki Okamura, Naruya Kondo, Tatsuki Fushimi Maki Sakamoto and Yoichi
 Ochiai
Categories: cs.LG cs.HC cs.SD eess.AS
\\
 This study introduces a novel approach to generate dance motions using
onomatopoeia as input, with the aim of enhancing creativity and diversity in
dance generation. Unlike text and music, onomatopoeia conveys rhythm and
meaning through abstract word expressions without constraints on expression and
without need for specialized knowledge. We adapt the AI Choreographer framework
and employ the Sakamoto system, a feature extraction method for onomatopoeia
focusing on phonemes and syllables. Additionally, we present a new dataset of
40 onomatopoeia-dance motion pairs collected through a user survey. Our results
demonstrate that the proposed method enables more intuitive dance generation
and can create dance motions using sound-symbolic words from a variety of
languages, including those without onomatopoeia. This highlights the potential
for diverse dance creation across different languages and cultures, accessible
to a wider audience. Qualitative samples from our model can be found at:
https://sites.google.com/view/onomatopoeia-dance/home/.
\\ ( https://arxiv.org/abs/2306.03646 ,  6694kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03647
Date: Tue, 6 Jun 2023 13:03:24 GMT   (513kb)

Title: Proximal Symmetric Non-negative Latent Factor Analysis: A Novel Approach
 to Highly-Accurate Representation of Undirected Weighted Networks
Authors: Yurong Zhong, Zhe Xie, Weiling Li, and Xin Luo
Categories: cs.LG
\\
 An Undirected Weighted Network (UWN) is commonly found in big data-related
applications. Note that such a network's information connected with its nodes,
and edges can be expressed as a Symmetric, High-Dimensional and Incomplete
(SHDI) matrix. However, existing models fail in either modeling its intrinsic
symmetry or low-data density, resulting in low model scalability or
representation learning ability. For addressing this issue, a Proximal
Symmetric Nonnegative Latent-factor-analysis (PSNL) model is proposed. It
incorporates a proximal term into symmetry-aware and data density-oriented
objective function for high representation accuracy. Then an adaptive
Alternating Direction Method of Multipliers (ADMM)-based learning scheme is
implemented through a Tree-structured of Parzen Estimators (TPE) method for
high computational efficiency. Empirical studies on four UWNs demonstrate that
PSNL achieves higher accuracy gain than state-of-the-art models, as well as
highly competitive computational efficiency.
\\ ( https://arxiv.org/abs/2306.03647 ,  513kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03648
Date: Tue, 6 Jun 2023 13:04:05 GMT   (2412kb,D)

Title: Supervised Knowledge May Hurt Novel Class Discovery Performance
Authors: Ziyun Li, Jona Otholt, Ben Dai, Di Hu, Christoph Meinel, Haojin Yang
Categories: cs.LG cs.CV
Comments: TMLR 2023 accepted paper. arXiv admin note: substantial text overlap
 with arXiv:2209.09120
\\
 Novel class discovery (NCD) aims to infer novel categories in an unlabeled
dataset by leveraging prior knowledge of a labeled set comprising disjoint but
related classes. Given that most existing literature focuses primarily on
utilizing supervised knowledge from a labeled set at the methodology level,
this paper considers the question: Is supervised knowledge always helpful at
different levels of semantic relevance? To proceed, we first establish a novel
metric, so-called transfer flow, to measure the semantic similarity between
labeled/unlabeled datasets. To show the validity of the proposed metric, we
build up a large-scale benchmark with various degrees of semantic similarities
between labeled/unlabeled datasets on ImageNet by leveraging its hierarchical
class structure. The results based on the proposed benchmark show that the
proposed transfer flow is in line with the hierarchical class structure; and
that NCD performance is consistent with the semantic similarities (measured by
the proposed metric). Next, by using the proposed transfer flow, we conduct
various empirical experiments with different levels of semantic similarity,
yielding that supervised knowledge may hurt NCD performance. Specifically,
using supervised information from a low-similarity labeled set may lead to a
suboptimal result as compared to using pure self-supervised knowledge. These
results reveal the inadequacy of the existing NCD literature which usually
assumes that supervised knowledge is beneficial. Finally, we develop a
pseudo-version of the transfer flow as a practical reference to decide if
supervised knowledge should be used in NCD. Its effectiveness is supported by
our empirical studies, which show that the pseudo transfer flow (with or
without supervised knowledge) is consistent with the corresponding accuracy
based on various datasets. Code is released at
https://github.com/J-L-O/SK-Hurt-NCD
\\ ( https://arxiv.org/abs/2306.03648 ,  2412kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03655
Date: Tue, 6 Jun 2023 13:15:01 GMT   (207kb,D)

Title: Online Learning under Adversarial Nonlinear Constraints
Authors: Pavel Kolev, Georg Martius, Michael Muehlebach
Categories: cs.LG math.OC
\\
 In many applications, learning systems are required to process continuous
non-stationary data streams. We study this problem in an online learning
framework and propose an algorithm that can deal with adversarial time-varying
and nonlinear constraints. As we show in our work, the algorithm called
Constraint Violation Velocity Projection (CVV-Pro) achieves $\sqrt{T}$ regret
and converges to the feasible set at a rate of $1/\sqrt{T}$, despite the fact
that the feasible set is slowly time-varying and a priori unknown to the
learner. CVV-Pro only relies on local sparse linear approximations of the
feasible set and therefore avoids optimizing over the entire set at each
iteration, which is in sharp contrast to projected gradients or Frank-Wolfe
methods. We also empirically evaluate our algorithm on two-player games, where
the players are subjected to a shared constraint.
\\ ( https://arxiv.org/abs/2306.03655 ,  207kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03680
Date: Tue, 6 Jun 2023 13:43:09 GMT   (6527kb,D)

Title: Mildly Constrained Evaluation Policy for Offline Reinforcement Learning
Authors: Linjie Xu, Zhengyao Jiang, Jinyu Wang, Lei Song, Jiang Bian
Categories: cs.LG
\\
 Offline reinforcement learning (RL) methodologies enforce constraints on the
policy to adhere closely to the behavior policy, thereby stabilizing value
learning and mitigating the selection of out-of-distribution (OOD) actions
during test time. Conventional approaches apply identical constraints for both
value learning and test time inference. However, our findings indicate that the
constraints suitable for value estimation may in fact be excessively
restrictive for action selection during test time. To address this issue, we
propose a Mildly Constrained Evaluation Policy (MCEP) for test time inference
with a more constrained target policy for value estimation. Since the target
policy has been adopted in various prior approaches, MCEP can be seamlessly
integrated with them as a plug-in. We instantiate MCEP based on TD3-BC
[Fujimoto and Gu, 2021] and AWAC [Nair et al., 2020] algorithms. The empirical
results on MuJoCo locomotion tasks show that the MCEP significantly outperforms
the target policy and achieves competitive results to state-of-the-art offline
RL methods. The codes are open-sourced at https://github.com/egg-west/MCEP.git.
\\ ( https://arxiv.org/abs/2306.03680 ,  6527kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03698
Date: Tue, 6 Jun 2023 14:12:23 GMT   (854kb,D)

Title: Fine-grained Expressivity of Graph Neural Networks
Authors: Jan B\"oker, Ron Levie, Ningyuan Huang, Soledad Villar, Christopher
 Morris
Categories: cs.LG cs.DM cs.NE
\\
 Numerous recent works have analyzed the expressive power of message-passing
graph neural networks (MPNNs), primarily utilizing combinatorial techniques
such as the $1$-dimensional Weisfeiler-Leman test ($1$-WL) for the graph
isomorphism problem. However, the graph isomorphism objective is inherently
binary, not giving insights into the degree of similarity between two given
graphs. This work resolves this issue by considering continuous extensions of
both $1$-WL and MPNNs to graphons. Concretely, we show that the continuous
variant of $1$-WL delivers an accurate topological characterization of the
expressive power of MPNNs on graphons, revealing which graphs these networks
can distinguish and the level of difficulty in separating them. We identify the
finest topology where MPNNs separate points and prove a universal approximation
theorem. Consequently, we provide a theoretical framework for graph and graphon
similarity combining various topological variants of classical
characterizations of the $1$-WL. In particular, we characterize the expressive
power of MPNNs in terms of the tree distance, which is a graph distance based
on the concepts of fractional isomorphisms, and substructure counts via tree
homomorphisms, showing that these concepts have the same expressive power as
the $1$-WL and MPNNs on graphons. Empirically, we validate our theoretical
findings by showing that randomly initialized MPNNs, without training, exhibit
competitive performance compared to their trained counterparts. Moreover, we
evaluate different MPNN architectures based on their ability to preserve graph
distances, highlighting the significance of our continuous $1$-WL test in
understanding MPNNs' expressivity.
\\ ( https://arxiv.org/abs/2306.03698 ,  854kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03702
Date: Tue, 6 Jun 2023 14:15:29 GMT   (2680kb,D)

Title: Bayesian post-hoc regularization of random forests
Authors: Bastian Pfeifer
Categories: cs.LG cs.AI
\\
 Random Forests are powerful ensemble learning algorithms widely used in
various machine learning tasks. However, they have a tendency to overfit noisy
or irrelevant features, which can result in decreased generalization
performance. Post-hoc regularization techniques aim to mitigate this issue by
modifying the structure of the learned ensemble after its training. Here, we
propose Bayesian post-hoc regularization to leverage the reliable patterns
captured by leaf nodes closer to the root, while potentially reducing the
impact of more specific and potentially noisy leaf nodes deeper in the tree.
This approach allows for a form of pruning that does not alter the general
structure of the trees but rather adjusts the influence of leaf nodes based on
their proximity to the root node. We have evaluated the performance of our
method on various machine learning data sets. Our approach demonstrates
competitive performance with the state-of-the-art methods and, in certain
cases, surpasses them in terms of predictive accuracy and generalization.
\\ ( https://arxiv.org/abs/2306.03702 ,  2680kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03715
Date: Tue, 6 Jun 2023 14:23:34 GMT   (42475kb,D)

Title: Unleashing Mask: Explore the Intrinsic Out-of-Distribution Detection
 Capability
Authors: Jianing Zhu, Hengzhuang Li, Jiangchao Yao, Tongliang Liu, Jianliang
 Xu, Bo Han
Categories: cs.LG
Comments: accepted by ICML 2023
\\
 Out-of-distribution (OOD) detection is an indispensable aspect of secure AI
when deploying machine learning models in real-world applications. Previous
paradigms either explore better scoring functions or utilize the knowledge of
outliers to equip the models with the ability of OOD detection. However, few of
them pay attention to the intrinsic OOD detection capability of the given
model. In this work, we generally discover the existence of an intermediate
stage of a model trained on in-distribution (ID) data having higher OOD
detection performance than that of its final stage across different settings,
and further identify one critical data-level attribution to be learning with
the atypical samples. Based on such insights, we propose a novel method,
Unleashing Mask, which aims to restore the OOD discriminative capabilities of
the well-trained model with ID data. Our method utilizes a mask to figure out
the memorized atypical samples, and then finetune the model or prune it with
the introduced mask to forget them. Extensive experiments and analysis
demonstrate the effectiveness of our method. The code is available at:
https://github.com/tmlr-group/Unleashing-Mask.
\\ ( https://arxiv.org/abs/2306.03715 ,  42475kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03725
Date: Tue, 6 Jun 2023 14:44:52 GMT   (58kb)

Title: Towards Memory-Efficient Training for Extremely Large Output Spaces --
 Learning with 500k Labels on a Single Commodity GPU
Authors: Erik Schultheis, Rohit Babbar
Categories: cs.LG cs.AI cs.DC
\\
 In classification problems with large output spaces (up to millions of
labels), the last layer can require an enormous amount of memory. Using sparse
connectivity would drastically reduce the memory requirements, but as we show
below, it can result in much diminished predictive performance of the model.
Fortunately, we found that this can be mitigated by introducing a penultimate
layer of intermediate size. We further demonstrate that one can constrain the
connectivity of the sparse layer to be uniform, in the sense that each output
neuron will have the exact same number of incoming connections. This allows for
efficient implementations of sparse matrix multiplication and connection
redistribution on GPU hardware. Via a custom CUDA implementation, we show that
the proposed approach can scale to datasets with 670,000 labels on a single
commodity GPU with only 4GB memory.
\\ ( https://arxiv.org/abs/2306.03725 ,  58kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03726
Date: Tue, 6 Jun 2023 14:45:24 GMT   (2890kb,D)

Title: Exploring Model Dynamics for Accumulative Poisoning Discovery
Authors: Jianing Zhu, Xiawei Guo, Jiangchao Yao, Chao Du, Li He, Shuo Yuan,
 Tongliang Liu, Liang Wang, Bo Han
Categories: cs.LG cs.CR
Comments: accepted by ICML 2023
\\
 Adversarial poisoning attacks pose huge threats to various machine learning
applications. Especially, the recent accumulative poisoning attacks show that
it is possible to achieve irreparable harm on models via a sequence of
imperceptible attacks followed by a trigger batch. Due to the limited
data-level discrepancy in real-time data streaming, current defensive methods
are indiscriminate in handling the poison and clean samples. In this paper, we
dive into the perspective of model dynamics and propose a novel information
measure, namely, Memorization Discrepancy, to explore the defense via the
model-level information. By implicitly transferring the changes in the data
manipulation to that in the model outputs, Memorization Discrepancy can
discover the imperceptible poison samples based on their distinct dynamics from
the clean samples. We thoroughly explore its properties and propose
Discrepancy-aware Sample Correction (DSC) to defend against accumulative
poisoning attacks. Extensive experiments comprehensively characterized
Memorization Discrepancy and verified its effectiveness. The code is publicly
available at: https://github.com/tmlr-group/Memorization-Discrepancy.
\\ ( https://arxiv.org/abs/2306.03726 ,  2890kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03739
Date: Tue, 6 Jun 2023 14:56:47 GMT   (2581kb,D)

Title: Learning to Do or Learning While Doing: Reinforcement Learning and
 Bayesian Optimisation for Online Continuous Tuning
Authors: Jan Kaiser, Chenran Xu, Annika Eichler, Andrea Santamaria Garcia,
 Oliver Stein, Erik Br\"undermann, Willi Kuropka, Hannes Dinter, Frank Mayet,
 Thomas Vinatier, Florian Burkart, Holger Schlarb
Categories: cs.LG cs.AI physics.acc-ph
Comments: 17 pages, 8 figures, 2 tables
\\
 Online tuning of real-world plants is a complex optimisation problem that
continues to require manual intervention by experienced human operators.
Autonomous tuning is a rapidly expanding field of research, where
learning-based methods, such as Reinforcement Learning-trained Optimisation
(RLO) and Bayesian optimisation (BO), hold great promise for achieving
outstanding plant performance and reducing tuning times. Which algorithm to
choose in different scenarios, however, remains an open question. Here we
present a comparative study using a routine task in a real particle accelerator
as an example, showing that RLO generally outperforms BO, but is not always the
best choice. Based on the study's results, we provide a clear set of criteria
to guide the choice of algorithm for a given tuning task. These can ease the
adoption of learning-based autonomous tuning solutions to the operation of
complex real-world plants, ultimately improving the availability and pushing
the limits of operability of these facilities, thereby enabling scientific and
engineering advancements.
\\ ( https://arxiv.org/abs/2306.03739 ,  2581kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03745
Date: Tue, 6 Jun 2023 15:04:31 GMT   (235kb,D)

Title: Soft Merging of Experts with Adaptive Routing
Authors: Mohammed Muqeeth, Haokun Liu, Colin Raffel
Categories: cs.LG
\\
 Sparsely activated neural networks with conditional computation learn to
route their inputs through different "expert" subnetworks, providing a form of
modularity that densely activated models lack. Despite their possible benefits,
models with learned routing often underperform their parameter-matched densely
activated counterparts as well as models that use non-learned heuristic routing
strategies. In this paper, we hypothesize that these shortcomings stem from the
gradient estimation techniques used to train sparsely activated models that use
non-differentiable discrete routing decisions. To address this issue, we
introduce Soft Merging of Experts with Adaptive Routing (SMEAR), which avoids
discrete routing by using a single "merged" expert constructed via a weighted
average of all of the experts' parameters. By routing activations through a
single merged expert, SMEAR does not incur a significant increase in
computational costs and enables standard gradient-based training. We
empirically validate that models using SMEAR outperform models that route based
on metadata or learn sparse routing through gradient estimation. Furthermore,
we provide qualitative analysis demonstrating that the experts learned via
SMEAR exhibit a significant amount of specialization. All of the code used in
our experiments is publicly available.
\\ ( https://arxiv.org/abs/2306.03745 ,  235kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03770
Date: Tue, 6 Jun 2023 15:31:05 GMT   (658kb,D)

Title: Graph Classification Gaussian Processes via Spectral Features
Authors: Felix L. Opolka, Yin-Cong Zhi, Pietro Li\`o, Xiaowen Dong
Categories: cs.LG stat.ML
\\
 Graph classification aims to categorise graphs based on their structure and
node attributes. In this work, we propose to tackle this task using tools from
graph signal processing by deriving spectral features, which we then use to
design two variants of Gaussian process models for graph classification. The
first variant uses spectral features based on the distribution of energy of a
node feature signal over the spectrum of the graph. We show that even such a
simple approach, having no learned parameters, can yield competitive
performance compared to strong neural network and graph kernel baselines. A
second, more sophisticated variant is designed to capture multi-scale and
localised patterns in the graph by learning spectral graph wavelet filters,
obtaining improved performance on synthetic and real-world data sets. Finally,
we show that both models produce well calibrated uncertainty estimates,
enabling reliable decision making based on the model predictions.
\\ ( https://arxiv.org/abs/2306.03770 ,  658kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03775
Date: Tue, 6 Jun 2023 15:32:30 GMT   (723kb,AD)

Title: Matched Pair Calibration for Ranking Fairness
Authors: Hannah Korevaar, Chris McConnell, Edmund Tong, Erik Brinkman, Alana
 Shine, Misam Abbas, Blossom Metevier, Sam Corbett-Davies, Khalid El-Arini
Categories: cs.LG
Comments: 19 pages, 8 figures
ACM-class: K.4.1; K.4.2
\\
 We propose a test of fairness in score-based ranking systems called matched
pair calibration. Our approach constructs a set of matched item pairs with
minimal confounding differences between subgroups before computing an
appropriate measure of ranking error over the set. The matching step ensures
that we compare subgroup outcomes between identically scored items so that
measured performance differences directly imply unfairness in subgroup-level
exposures. We show how our approach generalizes the fairness intuitions of
calibration from a binary classification setting to ranking and connect our
approach to other proposals for ranking fairness measures. Moreover, our
strategy shows how the logic of marginal outcome tests extends to cases where
the analyst has access to model scores. Lastly, we provide an example of
applying matched pair calibration to a real-word ranking data set to
demonstrate its efficacy in detecting ranking bias.
\\ ( https://arxiv.org/abs/2306.03775 ,  723kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03782
Date: Mon, 5 Jun 2023 02:24:59 GMT   (1114kb)

Title: Non-parametric Probabilistic Time Series Forecasting via Innovations
 Representation
Authors: Xinyi Wang, Meijen Lee, Qing Zhao, Lang Tong
Categories: cs.LG
\\
 Probabilistic time series forecasting predicts the conditional probability
distributions of the time series at a future time given past realizations. Such
techniques are critical in risk-based decision-making and planning under
uncertainties. Existing approaches are primarily based on parametric or
semi-parametric time-series models that are restrictive, difficult to validate,
and challenging to adapt to varying conditions. This paper proposes a
nonparametric method based on the classic notion of {\em innovations} pioneered
by Norbert Wiener and Gopinath Kallianpur that causally transforms a
nonparametric random process to an independent and identical uniformly
distributed {\em innovations process}. We present a machine-learning
architecture and a learning algorithm that circumvent two limitations of the
original Wiener-Kallianpur innovations representation: (i) the need for known
probability distributions of the time series and (ii) the existence of a causal
decoder that reproduces the original time series from the innovations
representation. We develop a deep-learning approach and a Monte Carlo sampling
technique to obtain a generative model for the predicted conditional
probability distribution of the time series based on a weak notion of
Wiener-Kallianpur innovations representation. The efficacy of the proposed
probabilistic forecasting technique is demonstrated on a variety of electricity
price datasets, showing marked improvement over leading benchmarks of
probabilistic forecasting techniques.
\\ ( https://arxiv.org/abs/2306.03782 ,  1114kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03792
Date: Tue, 6 Jun 2023 15:39:54 GMT   (2460kb,D)

Title: FAMO: Fast Adaptive Multitask Optimization
Authors: Bo Liu, Yihao Feng, Peter Stone, Qiang Liu
Categories: cs.LG
\\
 One of the grand enduring goals of AI is to create generalist agents that can
learn multiple different tasks from diverse data via multitask learning (MTL).
However, gradient descent (GD) on the average loss across all tasks may yield
poor multitask performance due to severe under-optimization of certain tasks.
Previous approaches that manipulate task gradients for a more balanced loss
decrease require storing and computing all task gradients (O(K) space and time
where K is the number of tasks), limiting their use in large-scale scenarios.
In this work, we introduce Fast Adaptive Multitask Optimization (FAMO), a
dynamic weighting method that decreases task losses in a balanced way using
O(1) space and time. We conduct an extensive set of experiments covering
multi-task supervised and reinforcement learning problems. Our results indicate
that FAMO achieves comparable or superior performance to state-of-the-art
gradient manipulation techniques while offering significant improvements in
space and computational efficiency. Code is available at
https://github.com/Cranial-XIX/FAMO.
\\ ( https://arxiv.org/abs/2306.03792 ,  2460kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03801
Date: Tue, 6 Jun 2023 15:45:07 GMT   (481kb)

Title: Stable Vectorization of Multiparameter Persistent Homology using Signed
 Barcodes as Measures
Authors: David Loiseaux, Luis Scoccola, Mathieu Carri\`ere, Magnus Bakke
 Botnan, Steve Oudot
Categories: cs.LG cs.CG math.AT stat.ML
Comments: 23 pages, 3 figures, 8 tables
\\
 Persistent homology (PH) provides topological descriptors for geometric data,
such as weighted graphs, which are interpretable, stable to perturbations, and
invariant under, e.g., relabeling. Most applications of PH focus on the
one-parameter case -- where the descriptors summarize the changes in topology
of data as it is filtered by a single quantity of interest -- and there is now
a wide array of methods enabling the use of one-parameter PH descriptors in
data science, which rely on the stable vectorization of these descriptors as
elements of a Hilbert space. Although the multiparameter PH (MPH) of data that
is filtered by several quantities of interest encodes much richer information
than its one-parameter counterpart, the scarceness of stability results for MPH
descriptors has so far limited the available options for the stable
vectorization of MPH. In this paper, we aim to bring together the best of both
worlds by showing how the interpretation of signed barcodes -- a recent family
of MPH descriptors -- as signed measures leads to natural extensions of
vectorization strategies from one parameter to multiple parameters. The
resulting feature vectors are easy to define and to compute, and provably
stable. While, as a proof of concept, we focus on simple choices of signed
barcodes and vectorizations, we already see notable performance improvements
when comparing our feature vectors to state-of-the-art topology-based methods
on various types of data.
\\ ( https://arxiv.org/abs/2306.03801 ,  481kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03805
Date: Tue, 6 Jun 2023 15:49:09 GMT   (994kb,D)

Title: The Emergence of Essential Sparsity in Large Pre-trained Models: The
 Weights that Matter
Authors: Ajay Jaiswal, Shiwei Liu, Tianlong Chen, Zhangyang Wang
Categories: cs.LG
\\
 Large pre-trained transformers are show-stealer in modern-day deep learning,
and it becomes crucial to comprehend the parsimonious patterns that exist
within them as they grow in scale. With exploding parameter counts, Lottery
Ticket Hypothesis (LTH) and its variants, have lost their pragmatism in
sparsifying them due to high computation and memory bottleneck of the
repetitive train-prune-retrain routine of iterative magnitude pruning (IMP)
which worsens with increasing model size. In this paper, we comprehensively
study induced sparse patterns across multiple large pre-trained vision and
language transformers. We propose the existence of -- essential sparsity
defined with a sharp dropping point beyond which the performance declines much
faster w.r.t the rise of sparsity level, when we directly remove weights with
the smallest magnitudes in one-shot. In the sparsity-performance curve We also
present an intriguing emerging phenomenon of abrupt sparsification during the
pre-training of BERT, i.e., BERT suddenly becomes heavily sparse in
pre-training after certain iterations. Moreover, our observations also indicate
a counter-intuitive finding that BERT trained with a larger amount of
pre-training data tends to have a better ability to condense knowledge in
comparatively relatively fewer parameters. Lastly, we investigate the effect of
the pre-training loss on essential sparsity and discover that self-supervised
learning (SSL) objectives trigger stronger emergent sparsification properties
than supervised learning (SL). Our codes are available at
\url{https://github.com/VITA-Group/essential\_sparsity}.
\\ ( https://arxiv.org/abs/2306.03805 ,  994kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03819
Date: Tue, 6 Jun 2023 16:07:24 GMT   (92kb,D)

Title: LEACE: Perfect linear concept erasure in closed form
Authors: Nora Belrose, David Schneider-Joseph, Shauli Ravfogel, Ryan Cotterell,
 Edward Raff, Stella Biderman
Categories: cs.LG cs.CL cs.CY
\\
 Concept erasure aims to remove specified features from a representation. It
can be used to improve fairness (e.g. preventing a classifier from using gender
or race) and interpretability (e.g. removing a concept to observe changes in
model behavior). In this paper, we introduce LEAst-squares Concept Erasure
(LEACE), a closed-form method which provably prevents all linear classifiers
from detecting a concept while inflicting the least possible damage to the
representation. We apply LEACE to large language models with a novel procedure
called "concept scrubbing," which erases target concept information from every
layer in the network. We demonstrate the usefulness of our method on two tasks:
measuring the reliance of language models on part-of-speech information, and
reducing gender bias in BERT embeddings. Code is available at
https://github.com/EleutherAI/concept-erasure.
\\ ( https://arxiv.org/abs/2306.03819 ,  92kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03824
Date: Tue, 6 Jun 2023 16:12:35 GMT   (62kb,D)

Title: Understanding Generalization of Federated Learning via Stability:
 Heterogeneity Matters
Authors: Zhenyu Sun, Xiaochun Niu, Ermin Wei
Categories: cs.LG
Comments: Submitted to NeurIPS 2023
\\
 Generalization performance is a key metric in evaluating machine learning
models when applied to real-world applications. Good generalization indicates
the model can predict unseen data correctly when trained under a limited number
of data. Federated learning (FL), which has emerged as a popular distributed
learning framework, allows multiple devices or clients to train a shared model
without violating privacy requirements. While the existing literature has
studied extensively the generalization performances of centralized machine
learning algorithms, similar analysis in the federated settings is either
absent or with very restrictive assumptions on the loss functions. In this
paper, we aim to analyze the generalization performances of federated learning
by means of algorithmic stability, which measures the change of the output
model of an algorithm when perturbing one data point. Three widely-used
algorithms are studied, including FedAvg, SCAFFOLD, and FedProx, under convex
and non-convex loss functions. Our analysis shows that the generalization
performances of models trained by these three algorithms are closely related to
the heterogeneity of clients' datasets as well as the convergence behaviors of
the algorithms. Particularly, in the i.i.d. setting, our results recover the
classical results of stochastic gradient descent (SGD).
\\ ( https://arxiv.org/abs/2306.03824 ,  62kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03828
Date: Tue, 6 Jun 2023 16:15:26 GMT   (23616kb,D)

Title: Quick-Tune: Quickly Learning Which Pretrained Model to Finetune and How
Authors: Sebastian Pineda Arango, Fabio Ferreira, Arlind Kadra, Frank Hutter
 Josif Grabocka
Categories: cs.LG
\\
 With the ever-increasing number of pretrained models, machine learning
practitioners are continuously faced with which pretrained model to use, and
how to finetune it for a new dataset. In this paper, we propose a methodology
that jointly searches for the optimal pretrained model and the hyperparameters
for finetuning it. Our method transfers knowledge about the performance of many
pretrained models with multiple hyperparameter configurations on a series of
datasets. To this aim, we evaluated over 20k hyperparameter configurations for
finetuning 24 pretrained image classification models on 87 datasets to generate
a large-scale meta-dataset. We meta-learn a multi-fidelity performance
predictor on the learning curves of this meta-dataset and use it for fast
hyperparameter optimization on new datasets. We empirically demonstrate that
our resulting approach can quickly select an accurate pretrained model for a
new dataset together with its optimal hyperparameters.
\\ ( https://arxiv.org/abs/2306.03828 ,  23616kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03830
Date: Tue, 6 Jun 2023 16:15:56 GMT   (812kb,D)

Title: Inductive Bias for Emergent Communication in a Continuous Setting
Authors: John Isak Fjellvang Villanger and Troels Arnfred Bojesen
Categories: cs.LG cs.AI cs.MA
Comments: NIPS 2023 Preprint. 12 pages, 5 figures, 3 tables
ACM-class: I.2.11
\\
 We study emergent communication in a multi-agent reinforcement learning
setting, where the agents solve cooperative tasks and have access to a
communication channel. The communication channel may consist of either discrete
symbols or continuous variables. We introduce an inductive bias to aid with the
emergence of good communication protocols for continuous messages, and we look
at the effect this type of inductive bias has for continuous and discrete
messages in itself or when used in combination with reinforcement learning. We
demonstrate that this type of inductive bias has a beneficial effect on the
communication protocols learnt in two toy environments, Negotiation and
Sequence Guess.
\\ ( https://arxiv.org/abs/2306.03830 ,  812kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03831
Date: Tue, 6 Jun 2023 16:16:05 GMT   (6212kb,D)

Title: GEO-Bench: Toward Foundation Models for Earth Monitoring
Authors: Alexandre Lacoste, Nils Lehmann, Pau Rodriguez, Evan David Sherwin,
 Hannah Kerner, Bj\"orn L\"utjens, Jeremy Andrew Irvin, David Dao, Hamed
 Alemohammad, Alexandre Drouin, Mehmet Gunturkun, Gabriel Huang, David
 Vazquez, Dava Newman, Yoshua Bengio, Stefano Ermon, Xiao Xiang Zhu
Categories: cs.LG cs.CV
\\
 Recent progress in self-supervision has shown that pre-training large neural
networks on vast amounts of unsupervised data can lead to substantial increases
in generalization to downstream tasks. Such models, recently coined foundation
models, have been transformational to the field of natural language processing.
Variants have also been proposed for image data, but their applicability to
remote sensing tasks is limited. To stimulate the development of foundation
models for Earth monitoring, we propose a benchmark comprised of six
classification and six segmentation tasks, which were carefully curated and
adapted to be both relevant to the field and well-suited for model evaluation.
We accompany this benchmark with a robust methodology for evaluating models and
reporting aggregated results to enable a reliable assessment of progress.
Finally, we report results for 20 baselines to gain information about the
performance of existing models. We believe that this benchmark will be a driver
of progress across a variety of Earth monitoring tasks.
\\ ( https://arxiv.org/abs/2306.03831 ,  6212kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03833
Date: Tue, 6 Jun 2023 16:23:00 GMT   (2417kb)

Title: Patient Dropout Prediction in Virtual Health: A Multimodal Dynamic
 Knowledge Graph and Text Mining Approach
Authors: Shuang Geng, Wenli Zhang, Jiaheng Xie, Gemin Liang, Ben Niu
Categories: cs.LG
MSC-class: K.5
ACM-class: H.4.m
\\
 Virtual health has been acclaimed as a transformative force in healthcare
delivery. Yet, its dropout issue is critical that leads to poor health
outcomes, increased health, societal, and economic costs. Timely prediction of
patient dropout enables stakeholders to take proactive steps to address
patients' concerns, potentially improving retention rates. In virtual health,
the information asymmetries inherent in its delivery format, between different
stakeholders, and across different healthcare delivery systems hinder the
performance of existing predictive methods. To resolve those information
asymmetries, we propose a Multimodal Dynamic Knowledge-driven Dropout
Prediction (MDKDP) framework that learns implicit and explicit knowledge from
doctor-patient dialogues and the dynamic and complex networks of various
stakeholders in both online and offline healthcare delivery systems. We
evaluate MDKDP by partnering with one of the largest virtual health platforms
in China. MDKDP improves the F1-score by 3.26 percentage points relative to the
best benchmark. Comprehensive robustness analyses show that integrating
stakeholder attributes, knowledge dynamics, and compact bilinear pooling
significantly improves the performance. Our work provides significant
implications for healthcare IT by revealing the value of mining relations and
knowledge across different service modalities. Practically, MDKDP offers a
novel design artifact for virtual health platforms in patient dropout
management.
\\ ( https://arxiv.org/abs/2306.03833 ,  2417kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03834
Date: Tue, 6 Jun 2023 16:24:27 GMT   (2156kb,D)

Title: MTS2Graph: Interpretable Multivariate Time Series Classification with
 Temporal Evolving Graphs
Authors: Raneen Younis, Abdul Hakmeh, and Zahra Ahmadi
Categories: cs.LG cs.AI
\\
 Conventional time series classification approaches based on bags of patterns
or shapelets face significant challenges in dealing with a vast amount of
feature candidates from high-dimensional multivariate data. In contrast, deep
neural networks can learn low-dimensional features efficiently, and in
particular, Convolutional Neural Networks (CNN) have shown promising results in
classifying Multivariate Time Series (MTS) data. A key factor in the success of
deep neural networks is this astonishing expressive power. However, this power
comes at the cost of complex, black-boxed models, conflicting with the goals of
building reliable and human-understandable models. An essential criterion in
understanding such predictive deep models involves quantifying the contribution
of time-varying input variables to the classification. Hence, in this work, we
introduce a new framework for interpreting multivariate time series data by
extracting and clustering the input representative patterns that highly
activate CNN neurons. This way, we identify each signal's role and
dependencies, considering all possible combinations of signals in the MTS
input. Then, we construct a graph that captures the temporal relationship
between the extracted patterns for each layer. An effective graph merging
strategy finds the connection of each node to the previous layer's nodes.
Finally, a graph embedding algorithm generates new representations of the
created interpretable time-series features. To evaluate the performance of our
proposed framework, we run extensive experiments on eight datasets of the
UCR/UEA archive, along with HAR and PAM datasets. The experiments indicate the
benefit of our time-aware graph-based representation in MTS classification
while enriching them with more interpretability.
\\ ( https://arxiv.org/abs/2306.03834 ,  2156kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03838
Date: Tue, 6 Jun 2023 16:27:17 GMT   (35560kb,D)

Title: Spherical Fourier Neural Operators: Learning Stable Dynamics on the
 Sphere
Authors: Boris Bonev, Thorsten Kurth, Christian Hundt, Jaideep Pathak,
 Maximilian Baust, Karthik Kashinath, Anima Anandkumar
Categories: cs.LG cs.NA math.NA physics.ao-ph physics.comp-ph
\\
 Fourier Neural Operators (FNOs) have proven to be an efficient and effective
method for resolution-independent operator learning in a broad variety of
application areas across scientific machine learning. A key reason for their
success is their ability to accurately model long-range dependencies in
spatio-temporal data by learning global convolutions in a computationally
efficient manner. To this end, FNOs rely on the discrete Fourier transform
(DFT), however, DFTs cause visual and spectral artifacts as well as pronounced
dissipation when learning operators in spherical coordinates since they
incorrectly assume a flat geometry. To overcome this limitation, we generalize
FNOs on the sphere, introducing Spherical FNOs (SFNOs) for learning operators
on spherical geometries. We apply SFNOs to forecasting atmospheric dynamics,
and demonstrate stable auto\-regressive rollouts for a year of simulated time
(1,460 steps), while retaining physically plausible dynamics. The SFNO has
important implications for machine learning-based simulation of climate
dynamics that could eventually help accelerate our response to climate change.
\\ ( https://arxiv.org/abs/2306.03838 ,  35560kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03885
Date: Fri, 19 May 2023 06:38:29 GMT   (435kb,D)

Title: Three-way Imbalanced Learning based on Fuzzy Twin SVM
Authors: Wanting Cai, Mingjie Cai, Qingguo Li, Qiong Liu
Categories: cs.LG cs.IT math.IT
\\
 Three-way decision (3WD) is a powerful tool for granular computing to deal
with uncertain data, commonly used in information systems, decision-making, and
medical care. Three-way decision gets much research in traditional rough set
models. However, three-way decision is rarely combined with the currently
popular field of machine learning to expand its research. In this paper,
three-way decision is connected with SVM, a standard binary classification
model in machine learning, for solving imbalanced classification problems that
SVM needs to improve. A new three-way fuzzy membership function and a new fuzzy
twin support vector machine with three-way membership (TWFTSVM) are proposed.
The new three-way fuzzy membership function is defined to increase the
certainty of uncertain data in both input space and feature space, which
assigns higher fuzzy membership to minority samples compared with majority
samples. To evaluate the effectiveness of the proposed model, comparative
experiments are designed for forty-seven different datasets with varying
imbalance ratios. In addition, datasets with different imbalance ratios are
derived from the same dataset to further assess the proposed model's
performance. The results show that the proposed model significantly outperforms
other traditional SVM-based methods.
\\ ( https://arxiv.org/abs/2306.03885 ,  435kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03900
Date: Tue, 6 Jun 2023 17:58:12 GMT   (3963kb,D)

Title: Model Spider: Learning to Rank Pre-Trained Models Efficiently
Authors: Yi-Kai Zhang, Ting-Ji Huang, Yao-Xiang Ding, De-Chuan Zhan, Han-Jia Ye
Categories: cs.LG
\\
 Figuring out which Pre-Trained Model (PTM) from a model zoo fits the target
task is essential to take advantage of plentiful model resources. With the
availability of numerous heterogeneous PTMs from diverse fields, efficiently
selecting the most suitable PTM is challenging due to the time-consuming costs
of carrying out forward or backward passes over all PTMs. In this paper, we
propose Model Spider, which tokenizes both PTMs and tasks by summarizing their
characteristics into vectors to enable efficient PTM selection. By leveraging
the approximated performance of PTMs on a separate set of training tasks, Model
Spider learns to construct tokens and measure the fitness score between a
model-task pair via their tokens. The ability to rank relevant PTMs higher than
others generalizes to new tasks. With the top-ranked PTM candidates, we further
learn to enrich task tokens with their PTM-specific semantics to re-rank the
PTMs for better selection. Model Spider balances efficiency and selection
ability, making PTM selection like a spider preying on a web. Model Spider
demonstrates promising performance in various configurations of model zoos.
\\ ( https://arxiv.org/abs/2306.03900 ,  3963kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03505
Date: Tue, 6 Jun 2023 08:52:42 GMT   (1563kb,D)

Title: Distributed Flocking Control of Aerial Vehicles Based on a Markov Random
 Field
Authors: Guobin Zhu, Shanwei Fan, Qingrui Zhang
Categories: cs.MA
Comments: 6 Pages
\\
 The distributed flocking control of collective aerial vehicles has
extraordinary advantages in scalability and reliability, \emph{etc.} However,
it is still challenging to design a reliable, efficient, and responsive
flocking algorithm. In this paper, a distributed predictive flocking framework
is presented based on a Markov random field (MRF). The MRF is used to
characterize the optimization problem that is eventually resolved by
discretizing the input space. Potential functions are employed to describe the
interactions between aerial vehicles and as indicators of flight performance.
The dynamic constraints are taken into account in the candidate feasible
trajectories which correspond to random variables. Numerical simulation shows
that compared with some existing latest methods, the proposed algorithm has
better-flocking cohesion and control efficiency performances. Experiments are
also conducted to demonstrate the feasibility of the proposed algorithm.
\\ ( https://arxiv.org/abs/2306.03505 ,  1563kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03207
Date: Mon, 5 Jun 2023 19:28:34 GMT   (8551kb,D)

Title: H2-Mapping: Real-time Dense Mapping Using Hierarchical Hybrid
 Representation
Authors: Chenxing Jiang, Hanwen Zhang, Peize Liu, Zehuan Yu, Hui Cheng, Boyu
 Zhou, Shaojie Shen
Categories: cs.RO
Comments: Submitted to IEEE Robotics and Automation Letters
\\
 Constructing a high-quality dense map in real-time is essential for robotics,
AR/VR, and digital twins applications. As Neural Radiance Field (NeRF) greatly
improves the mapping performance, in this paper, we propose a NeRF-based
mapping method that enables higher-quality reconstruction and real-time
capability even on edge computers. Specifically, we propose a novel
hierarchical hybrid representation that leverages implicit multiresolution hash
encoding aided by explicit octree SDF priors, describing the scene at different
levels of detail. This representation allows for fast scene geometry
initialization and makes scene geometry easier to learn. Besides, we present a
coverage-maximizing keyframe selection strategy to address the forgetting issue
and enhance mapping quality, particularly in marginal areas. To the best of our
knowledge, our method is the first to achieve high-quality NeRF-based mapping
on edge computers of handheld devices and quadrotors in real-time. Experiments
demonstrate that our method outperforms existing NeRF-based mapping methods in
geometry accuracy, texture realism, and time consumption. The code will be
released at: https://github.com/SYSU-STAR/H2-Mapping
\\ ( https://arxiv.org/abs/2306.03207 ,  8551kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03220
Date: Mon, 5 Jun 2023 20:10:36 GMT   (526kb)

Title: Risk-Aware Reward Shaping of Reinforcement Learning Agents for
 Autonomous Driving
Authors: Lin-Chi Wu, Zengjie Zhang, Sofie Haesaert, Zhiqiang Ma, and Zhiyong
 Sun
Categories: cs.RO cs.AI
\\
 Reinforcement learning (RL) is an effective approach to motion planning in
autonomous driving, where an optimal driving policy can be automatically
learned using the interaction data with the environment. Nevertheless, the
reward function for an RL agent, which is significant to its performance, is
challenging to be determined. The conventional work mainly focuses on rewarding
safe driving states but does not incorporate the awareness of risky driving
behaviors of the vehicles. In this paper, we investigate how to use risk-aware
reward shaping to leverage the training and test performance of RL agents in
autonomous driving. Based on the essential requirements that prescribe the
safety specifications for general autonomous driving in practice, we propose
additional reshaped reward terms that encourage exploration and penalize risky
driving behaviors. A simulation study in OpenAI Gym indicates the advantage of
risk-aware reward shaping for various RL agents. Also, we point out that
proximal policy optimization (PPO) is likely to be the best RL method that
works with risk-aware reward shaping.
\\ ( https://arxiv.org/abs/2306.03220 ,  526kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03252
Date: Mon, 5 Jun 2023 21:13:46 GMT   (20141kb,D)

Title: RACECAR -- The Dataset for High-Speed Autonomous Racing
Authors: Amar Kulkarni, John Chrosniak, Emory Ducote, Florian Sauerbeck, Andrew
 Saba, Utkarsh Chirimar, John Link, Marcello Cellina, Madhur Behl
Categories: cs.RO
Comments: 9 pages, 10 figures. For links to data and reference material go to
 https://github.com/linklab-uva/RACECAR_DATA
\\
 This paper describes the first open dataset for full-scale and high-speed
autonomous racing. Multi-modal sensor data has been collected from fully
autonomous Indy race cars operating at speeds of up to 170 mph (273 kph). Six
teams who raced in the Indy Autonomous Challenge have contributed to this
dataset. The dataset spans 11 interesting racing scenarios across two race
tracks which include solo laps, multi-agent laps, overtaking situations,
high-accelerations, banked tracks, obstacle avoidance, pit entry and exit at
different speeds. The dataset contains data from 27 racing sessions across the
11 scenarios with over 6.5 hours of sensor data recorded from the track. The
data is organized and released in both ROS2 and nuScenes format. We have also
developed the ROS2-to-nuScenes conversion library to achieve this. The RACECAR
data is unique because of the high-speed environment of autonomous racing. We
present several benchmark problems on localization, object detection and
tracking (LiDAR, Radar, and Camera), and mapping using the RACECAR data to
explore issues that arise at the limits of operation of the vehicle.
\\ ( https://arxiv.org/abs/2306.03252 ,  20141kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03263
Date: Mon, 5 Jun 2023 21:30:52 GMT   (23303kb)

Title: Efficient automatic design of robots
Authors: David Matthews, Andrew Spielberg, Daniela Rus, Sam Kriegman, Josh
 Bongard
Categories: cs.RO cs.AI
\\
 Robots are notoriously difficult to design because of complex
interdependencies between their physical structure, sensory and motor layouts,
and behavior. Despite this, almost every detail of every robot built to date
has been manually determined by a human designer after several months or years
of iterative ideation, prototyping, and testing. Inspired by evolutionary
design in nature, the automated design of robots using evolutionary algorithms
has been attempted for two decades, but it too remains inefficient: days of
supercomputing are required to design robots in simulation that, when
manufactured, exhibit desired behavior. Here we show for the first time de-novo
optimization of a robot's structure to exhibit a desired behavior, within
seconds on a single consumer-grade computer, and the manufactured robot's
retention of that behavior. Unlike other gradient-based robot design methods,
this algorithm does not presuppose any particular anatomical form; starting
instead from a randomly-generated apodous body plan, it consistently discovers
legged locomotion, the most efficient known form of terrestrial movement. If
combined with automated fabrication and scaled up to more challenging tasks,
this advance promises near instantaneous design, manufacture, and deployment of
unique and useful machines for medical, environmental, vehicular, and
space-based tasks.
\\ ( https://arxiv.org/abs/2306.03263 ,  23303kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03354
Date: Tue, 6 Jun 2023 02:10:20 GMT   (1472kb,D)

Title: Simulation-Based Counterfactual Causal Discovery on Real World Driver
 Behaviour
Authors: Rhys Howard, Lars Kunze
Categories: cs.RO cs.AI
Comments: 8 Pages, 4 Figures, To be published in the Proceedings of the 2023
 IEEE Intelligent Vehicles Symposium, Final submission version
ACM-class: I.2.9; I.2.6; I.6.0
\\
 Being able to reason about how one's behaviour can affect the behaviour of
others is a core skill required of intelligent driving agents. Despite this,
the state of the art struggles to meet the need of agents to discover causal
links between themselves and others. Observational approaches struggle because
of the non-stationarity of causal links in dynamic environments, and the
sparsity of causal interactions while requiring the approaches to work in an
online fashion. Meanwhile interventional approaches are impractical as a
vehicle cannot experiment with its actions on a public road. To counter the
issue of non-stationarity we reformulate the problem in terms of extracted
events, while the previously mentioned restriction upon interventions can be
overcome with the use of counterfactual simulation. We present three variants
of the proposed counterfactual causal discovery method and evaluate these
against state of the art observational temporal causal discovery methods across
3396 causal scenes extracted from a real world driving dataset. We find that
the proposed method significantly outperforms the state of the art on the
proposed task quantitatively and can offer additional insights by comparing the
outcome of an alternate series of decisions in a way that observational and
interventional approaches cannot.
\\ ( https://arxiv.org/abs/2306.03354 ,  1472kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03367
Date: Tue, 6 Jun 2023 02:46:28 GMT   (4709kb,D)

Title: Bridging the Gap Between Multi-Step and One-Shot Trajectory Prediction
 via Self-Supervision
Authors: Faris Janjo\v{s}, Max Keller, Maxim Dolgov, J. Marius Z\"ollner
Categories: cs.RO cs.AI
Comments: 8 pages, 6 figures, to be published in 34th IEEE Intelligent Vehicles
 Symposium (IV)
ACM-class: I.1.2
\\
 Accurate vehicle trajectory prediction is an unsolved problem in autonomous
driving with various open research questions. State-of-the-art approaches
regress trajectories either in a one-shot or step-wise manner. Although
one-shot approaches are usually preferred for their simplicity, they relinquish
powerful self-supervision schemes that can be constructed by chaining multiple
time-steps. We address this issue by proposing a middle-ground where multiple
trajectory segments are chained together. Our proposed Multi-Branch
Self-Supervised Predictor receives additional training on new predictions
starting at intermediate future segments. In addition, the model 'imagines' the
latent context and 'predicts the past' while combining multi-modal trajectories
in a tree-like manner. We deliberately keep aspects such as interaction and
environment modeling simplistic and nevertheless achieve competitive results on
the INTERACTION dataset. Furthermore, we investigate the sparsely explored
uncertainty estimation of deterministic predictors. We find positive
correlations between the prediction error and two proposed metrics, which might
pave way for determining prediction confidence.
\\ ( https://arxiv.org/abs/2306.03367 ,  4709kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03405
Date: Tue, 6 Jun 2023 04:53:06 GMT   (10208kb,D)

Title: Vehicle Dynamics Modeling for Autonomous Racing Using Gaussian Processes
Authors: Jingyun Ning and Madhur Behl
Categories: cs.RO cs.LG
Comments: 12 pages, 6 figures, 10 tables
\\
 Autonomous racing is increasingly becoming a proving ground for autonomous
vehicle technology at the limits of its current capabilities. The most
prominent examples include the F1Tenth racing series, Formula Student
Driverless (FSD), Roborace, and the Indy Autonomous Challenge (IAC). Especially
necessary, in high speed autonomous racing, is the knowledge of accurate
racecar vehicle dynamics. The choice of the vehicle dynamics model has to be
made by balancing the increasing computational demands in contrast to improved
accuracy of more complex models. Recent studies have explored learning-based
methods, such as Gaussian Process (GP) regression for approximating the vehicle
dynamics model. However, these efforts focus on higher level constructs such as
motion planning, or predictive control and lack both in realism and rigor of
the GP modeling process, which is often over-simplified. This paper presents
the most detailed analysis of the applicability of GP models for approximating
vehicle dynamics for autonomous racing. In particular we construct dynamic, and
extended kinematic models for the popular F1TENTH racing platform. We
investigate the effect of kernel choices, sample sizes, racetrack layout,
racing lines, and velocity profiles on the efficacy and generalizability of the
learned dynamics. We conduct 400+ simulations on real F1 track layouts to
provide comprehensive recommendations to the research community for training
accurate GP regression for single-track vehicle dynamics of a racecar.
\\ ( https://arxiv.org/abs/2306.03405 ,  10208kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03410
Date: Tue, 6 Jun 2023 05:17:02 GMT   (16992kb,D)

Title: Learning to Simulate Tree-Branch Dynamics for Manipulation
Authors: Jayadeep Jacob, Tirthankar Bandyopadhyay, Jason Williams, Paulo Borges
 and Fabio Ramos
Categories: cs.RO cs.LG
Comments: 8 pages, 9 figures
\\
 We propose to use a simulation driven inverse inference approach to model the
joint dynamics of tree branches under manipulation. Learning branch dynamics
and gaining the ability to manipulate deformable vegetation can help with
occlusion-prone tasks, such as fruit picking in dense foliage, as well as
moving overhanging vines and branches for navigation in dense vegetation. The
underlying deformable tree geometry is encapsulated as coarse spring
abstractions executed on parallel, non-differentiable simulators. The implicit
statistical model defined by the simulator, reference trajectories obtained by
actively probing the ground truth, and the Bayesian formalism, together guide
the spring parameter posterior density estimation. Our non-parametric inference
algorithm, based on Stein Variational Gradient Descent, incorporates
biologically motivated assumptions into the inference process as neural network
driven learnt joint priors; moreover, it leverages the finite difference scheme
for gradient approximations. Real and simulated experiments confirm that our
model can predict deformation trajectories, quantify the estimation
uncertainty, and it can perform better when base-lined against other inference
algorithms, particularly from the Monte Carlo family. The model displays strong
robustness properties in the presence of heteroscedastic sensor noise;
furthermore, it can generalise to unseen grasp locations.
\\ ( https://arxiv.org/abs/2306.03410 ,  16992kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03484
Date: Tue, 6 Jun 2023 08:09:17 GMT   (6596kb,D)

Title: A Grasp Pose is All You Need: Learning Multi-fingered Grasping with Deep
 Reinforcement Learning from Vision and Touch
Authors: Federico Ceola, Elisa Maiettini, Lorenzo Rosasco and Lorenzo Natale
Categories: cs.RO
Comments: Submitted to IROS 2023
\\
 Multi-fingered robotic hands could enable robots to perform sophisticated
manipulation tasks. However, teaching a robot to grasp objects with an
anthropomorphic hand is an arduous problem due to the high dimensionality of
state and action spaces. Deep Reinforcement Learning (DRL) offers techniques to
design control policies for this kind of problems without explicit environment
or hand modeling. However, training these policies with state-of-the-art
model-free algorithms is greatly challenging for multi-fingered hands. The main
problem is that an efficient exploration of the environment is not possible for
such high-dimensional problems, thus causing issues in the initial phases of
policy optimization. One possibility to address this is to rely on off-line
task demonstrations. However, oftentimes this is incredibly demanding in terms
of time and computational resources. In this work, we overcome these
requirements and propose the A Grasp Pose is All You Need (G-PAYN) method for
the anthropomorphic hand of the iCub humanoid. We develop an approach to
automatically collect task demonstrations to initialize the training of the
policy. The proposed grasping pipeline starts from a grasp pose generated by an
external algorithm, used to initiate the movement. Then a control policy
(previously trained with the proposed G-PAYN) is used to reach and grab the
object. We deployed the iCub into the MuJoCo simulator and use it to test our
approach with objects from the YCB-Video dataset. The results show that G-PAYN
outperforms current DRL techniques in the considered setting, in terms of
success rate and execution time with respect to the baselines. The code to
reproduce the experiments will be released upon acceptance.
\\ ( https://arxiv.org/abs/2306.03484 ,  6596kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03616
Date: Tue, 6 Jun 2023 12:10:04 GMT   (16723kb,D)

Title: Online Estimation of Self-Body Deflection With Various Sensor Data Based
 on Directional Statistics
Authors: Hiroya Sato, Kento Kawaharazuka, Tasuku Makabe, Kei Okada, Masayuki
 Inaba
Categories: cs.RO
Comments: This work has been submitted to the IEEE for possible publication.
 Copyright may be transferred without notice, after which this version may no
 longer be accessible
DOI: 10.1109/SII55687.2023.10039450
\\
 In this paper, we propose a method for online estimation of the robot's
posture. Our method uses von Mises and Bingham distributions as probability
distributions of joint angles and 3D orientation, which are used in directional
statistics. We constructed a particle filter using these distributions and
configured a system to estimate the robot's posture from various sensor
information (e.g., joint encoders, IMU sensors, and cameras). Furthermore,
unlike tangent space approximations, these distributions can handle global
features and represent sensor characteristics as observation noises. As an
application, we show that the yaw drift of a 6-axis IMU sensor can be
represented probabilistically to prevent adverse effects on attitude
estimation. For the estimation, we used an approximate model that assumes the
actual robot posture can be reproduced by correcting the joint angles of a
rigid body model. In the experiment part, we tested the estimator's
effectiveness by examining that the joint angles generated with the approximate
model can be estimated using the link pose of the same model. We then applied
the estimator to the actual robot and confirmed that the gripper position could
be estimated, thereby verifying the validity of the approximate model in our
situation.
\\ ( https://arxiv.org/abs/2306.03616 ,  16723kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03617
Date: Tue, 6 Jun 2023 12:12:25 GMT   (30631kb,D)

Title: A Data-Efficient Approach for Long-Term Human Motion Prediction Using
 Maps of Dynamics
Authors: Yufei Zhu, Andrey Rudenko, Tomasz P. Kucner, Achim J. Lilienthal,
 Martin Magnusson
Categories: cs.RO
Comments: in 5th LHMP Workshop held in conjunction with 40th IEEE International
 Conference on Robotics and Automation (ICRA), 29/05 - 02/06 2023, London
\\
 Human motion prediction is essential for the safe and smooth operation of
mobile service robots and intelligent vehicles around people. Commonly used
neural network-based approaches often require large amounts of complete
trajectories to represent motion dynamics in complex semantically-rich spaces.
This requirement may complicate deployment of physical systems in new
environments, especially when the data is being collected online from onboard
sensors. In this paper we explore a data-efficient alternative using maps of
dynamics (MoD) to represent place-dependent multi-modal spatial motion
patterns, learned from prior observations. Our approach can perform efficient
human motion prediction in the long-term perspective of up to 60 seconds. We
quantitatively evaluate its accuracy with limited amount of training data in
comparison to an LSTM-based baseline, and qualitatively show that the predicted
trajectories reflect the natural semantic properties of the environment, e.g.
the locations of short- and long-term goals, navigation in narrow passages,
around obstacles, etc.
\\ ( https://arxiv.org/abs/2306.03617 ,  30631kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03641
Date: Tue, 6 Jun 2023 12:52:07 GMT   (1116kb,D)

Title: Single-Shot Global Localization via Graph-Theoretic Correspondence
 Matching
Authors: Shigemichi Matsuzaki, Kenji Koide, Shuji Oishi, Masashi Yokozuka,
 Atsuhiko Banno
Categories: cs.RO cs.CV
\\
 This paper describes a method of global localization based on graph-theoretic
association of instances between a query and the prior map. The proposed
framework employs correspondence matching based on the maximum clique problem
(MCP). The framework is potentially applicable to other map and/or query
modalities thanks to the graph-based abstraction of the problem, while many of
existing global localization methods rely on a query and the dataset in the
same modality. We implement it with a semantically labeled 3D point cloud map,
and a semantic segmentation image as a query. Leveraging the graph-theoretic
framework, the proposed method realizes global localization exploiting only the
map and the query. The method shows promising results on multiple large-scale
simulated maps of urban scenes.
\\ ( https://arxiv.org/abs/2306.03641 ,  1116kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03740
Date: Tue, 6 Jun 2023 14:57:49 GMT   (3058kb,D)

Title: GMMap: Memory-Efficient Continuous Occupancy Map Using Gaussian Mixture
 Model
Authors: Peter Zhi Xuan Li, Sertac Karaman, Vivienne Sze
Categories: cs.RO
Comments: 15 pages, 9 figures
\\
 Energy consumption of memory accesses dominates the compute energy in
energy-constrained robots which require a compact 3D map of the environment to
achieve autonomy. Recent mapping frameworks only focused on reducing the map
size while incurring significant memory usage during map construction due to
multi-pass processing of each depth image. In this work, we present a
memory-efficient continuous occupancy map, named GMMap, that accurately models
the 3D environment using a Gaussian Mixture Model (GMM). Memory-efficient GMMap
construction is enabled by the single-pass compression of depth images into
local GMMs which are directly fused together into a globally-consistent map. By
extending Gaussian Mixture Regression to model unexplored regions, occupancy
probability is directly computed from Gaussians. Using a low-power ARM Cortex
A57 CPU, GMMap can be constructed in real-time at up to 60 images per second.
Compared with prior works, GMMap maintains high accuracy while reducing the map
size by at least 56%, memory overhead by at least 88%, DRAM access by at least
78%, and energy consumption by at least 69%. Thus, GMMap enables real-time 3D
mapping on energy-constrained robots.
\\ ( https://arxiv.org/abs/2306.03740 ,  3058kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03757
Date: Tue, 6 Jun 2023 15:17:34 GMT   (24704kb,D)

Title: Exploring the effects of robotic design on learning and neural control
Authors: Joshua Paul Powers
Categories: cs.RO cs.AI cs.LG cs.NE
Comments: arXiv admin note: text overlap with arXiv:2008.06397
\\
 The ongoing deep learning revolution has allowed computers to outclass humans
in various games and perceive features imperceptible to humans during
classification tasks. Current machine learning techniques have clearly
distinguished themselves in specialized tasks. However, we have yet to see
robots capable of performing multiple tasks at an expert level. Most work in
this field is focused on the development of more sophisticated learning
algorithms for a robot's controller given a largely static and presupposed
robotic design. By focusing on the development of robotic bodies, rather than
neural controllers, I have discovered that robots can be designed such that
they overcome many of the current pitfalls encountered by neural controllers in
multitask settings. Through this discovery, I also present novel metrics to
explicitly measure the learning ability of a robotic design and its resistance
to common problems such as catastrophic interference.
 Traditionally, the physical robot design requires human engineers to plan
every aspect of the system, which is expensive and often relies on human
intuition. In contrast, within the field of evolutionary robotics, evolutionary
algorithms are used to automatically create optimized designs, however, such
designs are often still limited in their ability to perform in a multitask
setting. The metrics created and presented here give a novel path to automated
design that allow evolved robots to synergize with their controller to improve
the computational efficiency of their learning while overcoming catastrophic
interference.
 Overall, this dissertation intimates the ability to automatically design
robots that are more general purpose than current robots and that can perform
various tasks while requiring less computation.
\\ ( https://arxiv.org/abs/2306.03757 ,  24704kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03785
Date: Sat, 3 Jun 2023 20:07:27 GMT   (8917kb,D)

Title: Development of On-Ground Hardware In Loop Simulation Facility for Space
 Robotics
Authors: Roshan Sah, Raunak Srivastava, Kaushik Das
Categories: cs.RO astro-ph.EP cs.SY eess.SY math.OC physics.space-ph
Comments: 11 pages, 15 figures, Accepted at Small Satellite Conference 2023;
 Weekday Sessions: Orbital Debris, SSA & STM; Tuesday, 8th Aug 2023
\\
 Over a couple of decades, space junk has increased rapidly, which has caused
significant threats to the LEO operation satellites. An Active Debris Removal
$(ADR)$ concept continuously evolves for space junk removal. One of the ADR
methods is Space Robotics, whose function is to chase, capture and de-orbit the
space junk. This paper presents the development of an on-ground space robotics
facility in the TCS Research for on-orbit servicing $(OOS)$ like refueling and
debris capture experiments. A Hardware in Loop Simulation (HILS) system will be
used for integrated system development, testing, and demonstration of on-orbit
docking mechanisms. The HiLS test facility of TCS Research Lab will use two URs
in which one UR is attached to the RG2 gripper, and the other is attached to a
force-torque sensor and with a scaled mock-up model. The first UR5 will be
mounted on a 7-axis linear rail and contain the docking probe. First, UR5 with
a suitable gripper has to interface its control boxes. The grasping algorithm
was run through the ROS interface line to demonstrate and validate the on-orbit
operations. The manipulator will be mounted with LIDAR and a camera to
visualize the mock-up model, find the target model's pose and rotational
velocity estimation, and a gripper that will move relative to the target model.
The other manipulator has the UR10 control, providing rotational and random
motion to the mockup, enabling a dynamic simulator fed by force-torque data.
The dynamic simulator is fed up with the orbit propagator, which will provide
the orbiting environment to the target model. For the simulation of the docking
and grasping of the target model, a linear rail of a 6m setup is still in the
procurement process. Once reaching proximity, the grasping algorithm will be
launched to capture the target model after reading the random motion of the
mock-up model.
\\ ( https://arxiv.org/abs/2306.03785 ,  8917kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03857
Date: Tue, 6 Jun 2023 16:51:43 GMT   (3172kb,D)

Title: Learning with a Mole: Transferable latent spatial representations for
 navigation without reconstruction
Authors: Guillaume Bono, Leonid Antsfeld, Assem Sadek, Gianluca Monaci,
 Christian Wolf
Categories: cs.RO cs.CV
\\
 Agents navigating in 3D environments require some form of memory, which
should hold a compact and actionable representation of the history of
observations useful for decision taking and planning. In most end-to-end
learning approaches the representation is latent and usually does not have a
clearly defined interpretation, whereas classical robotics addresses this with
scene reconstruction resulting in some form of map, usually estimated with
geometry and sensor models and/or learning. In this work we propose to learn an
actionable representation of the scene independently of the targeted downstream
task and without explicitly optimizing reconstruction. The learned
representation is optimized by a blind auxiliary agent trained to navigate with
it on multiple short sub episodes branching out from a waypoint and, most
importantly, without any direct visual observation. We argue and show that the
blindness property is important and forces the (trained) latent representation
to be the only means for planning. With probing experiments we show that the
learned representation optimizes navigability and not reconstruction. On
downstream tasks we show that it is robust to changes in distribution, in
particular the sim2real gap, which we evaluate with a real physical robot in a
real office building, significantly improving performance.
\\ ( https://arxiv.org/abs/2306.03857 ,  3172kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03865
Date: Tue, 6 Jun 2023 17:06:55 GMT   (6964kb,D)

Title: Simultaneous Position-and-Stiffness Control of Underactuated
 Antagonistic Tendon-Driven Continuum Robots
Authors: Bowen Yi, Yeman Fan, Dikai Liu, Jose Guadalupe Romero
Categories: cs.RO cs.SY eess.SY
\\
 Continuum robots have gained widespread popularity due to their inherent
compliance and flexibility, particularly their adjustable levels of stiffness
for various application scenarios. Despite efforts to dynamic modeling and
control synthesis over the past decade, few studies have focused on
incorporating stiffness regulation in their feedback control design; however,
this is one of the initial motivations to develop continuum robots. This paper
aims to address the crucial challenge of controlling both the position and
stiffness of a class of highly underactuated continuum robots that are actuated
by antagonistic tendons. To this end, the first step involves presenting a
high-dimensional rigid-link dynamical model that can analyze the open-loop
stiffening of tendon-driven continuum robots. Based on this model, we propose a
novel passivity-based position-and-stiffness controller adheres to the
non-negative tension constraint. To demonstrate the effectiveness of our
approach, we tested the theoretical results on our continuum robot, and the
experimental results show the efficacy and precise performance of the proposed
methodology.
\\ ( https://arxiv.org/abs/2306.03865 ,  6964kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03906
Date: Tue, 6 Jun 2023 17:59:29 GMT   (4186kb)

Title: Biological Organisms as End Effectors
Authors: Josephine Galipon, Shoya Shimizu, Kenjiro Tadakuma
Categories: cs.RO
Comments: 11 pages, 8 figures
\\
 In robotics, an end effector is a device at the end of a robotic arm designed
to interact with the environment. Effectively, it serves as the hand of the
robot, carrying out tasks on behalf of humans. But could we turn this concept
on its head and consider using living organisms themselves as end-effectors?
This paper introduces a novel idea of using whole living organisms as end
effectors for robotics. We showcase this by demonstrating that pill bugs and
chitons -- types of small, harmless creatures -- can be utilized as functional
grippers. Crucially, this method does not harm these creatures, enabling their
release back into nature after use. How this concept may be expanded to other
organisms and applications is also discussed.
\\ ( https://arxiv.org/abs/2306.03906 ,  4186kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03254
Date: Mon, 5 Jun 2023 21:15:02 GMT   (357kb)

Title: Characterizing the Effects of Single Bus Perturbation on Power Systems
 Graph Signals
Authors: Md Abul Hasnat and Mia Naeini
Categories: eess.SY cs.SY eess.SP
\\
 This article explores the effects of a single bus perturbation in the
electrical grid using a Graph Signal Processing (GSP) perspective. The
perturbation is characterized by a sudden change in real-power load demand or
generation. The study focuses on analyzing the spread of the perturbation
throughout the grid and proposes a measure of spreadability based on GSP.
Moreover, the global and local smoothness properties of the difference bus
voltage angle graph signals are evaluated for understanding their embedded
patterns of spreadability property. It is demonstrated that the global
smoothness of the bus voltage angle graph signal follows a quadratic
relationship with the perturbation strength, which helps in characterizing the
critical perturbation strength after which the power flow diverges indicating a
stressed system. The impact of a single bus perturbation on power system graph
signals has been investigated through both analytical derivations using the DC
power flow model and simulation using the AC power flow model. The results
reveal that the proposed measure of spreadability as well as local and global
smoothness properties of the graph signals are independent of the perturbation
strength and instead mainly depend on the perturbation's location.
\\ ( https://arxiv.org/abs/2306.03254 ,  357kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03325
Date: Tue, 6 Jun 2023 00:34:05 GMT   (1077kb,D)

Title: Managing Wildfire Risk and Promoting Equity through Optimal
 Configuration of Networked Microgrids
Authors: Sofia Taylor, Gabriela Setyawan, Bai Cui, Ahmed Zamzam, Line A. Roald
Categories: eess.SY cs.SY
Comments: 11 pages, 6 figures. Accepted to ACM e-Energy 2023
DOI: 10.1145/3575813.3595196
\\
 As climate change increases the risk of large-scale wildfires, wildfire
ignitions from electric power lines are a growing concern. To mitigate the
wildfire ignition risk, many electric utilities de-energize power lines to
prevent electric faults and failures. These preemptive power shutoffs are
effective in reducing ignitions, but they could result in wide-scale power
outages. Advanced technology, such as networked microgrids, can help reduce the
size of the resulting power outages; however, even microgrid technology might
not be sufficient to supply power to everyone, thus forcing hard questions
about how to prioritize the provision of power among customers. In this paper,
we present an optimization problem that configures networked microgrids to
manage wildfire risk while maximizing the power served to customers; however,
rather than simply maximizing the amount of power served in kilowatts, our
formulation also considers the ability of customers to cope with power outages,
as measured by social vulnerability, and it discourages the disconnection of
particularly vulnerable customer groups. To test our model, we leverage a
synthetic but realistic distribution feeder, along with publicly available
social vulnerability indices and satellite-based wildfire risk map data, to
quantify the parameters in our optimal decision-making model. Our case study
results demonstrate the benefits of networked microgrids in limiting load shed
and promoting equity during scenarios with high wildfire risk.
\\ ( https://arxiv.org/abs/2306.03325 ,  1077kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03458
Date: Tue, 6 Jun 2023 07:23:57 GMT   (3487kb,D)

Title: The Unscented Kalman Filter for Nonlinear Parameter Identification of
 Adaptive Cruise Control Systems
Authors: Konstantinos Ampountolas
Categories: eess.SY cs.SY math.OC
Comments: 11 papes, 3 Figures
Journal-ref: IEEE Transactions on Intelligent Vehicles (2023)
DOI: 10.1109/TIV.2023.3272660
\\
 This paper develops and investigates a dual unscented Kalman filter (DUKF)
for the joint nonlinear state and parameter identification of commercial
adaptive cruise control (ACC) systems. Although the core functionality of stock
ACC systems, including their proprietary control logic and parameters, is not
publicly available, this work considers a car-following scenario with a
human-driven vehicle (leader) and an ACC engaged ego vehicle (follower) that
employs a constant time-headway policy (CTHP). The objective of the DUKF is to
determine the CTHP parameters of the ACC by using real-time observations of
space-gap and relative velocity from the vehicle's onboard sensors. Real-time
parameter identification of stock ACC systems is essential for assessing their
string stability, large-scale deployment on motorways, and impact on traffic
flow and throughput. In this regard, $L_2$ and $L_\infty$ string stability
conditions are considered. The observability rank condition for nonlinear
systems is adopted to evaluate the ability of the proposed estimation scheme to
estimate stock ACC system parameters using empirical data. The proposed filter
is evaluated using empirical data collected from the onboard sensors of two
2019 SUV vehicles, namely Hyundai Nexo and SsangYong Rexton, equipped with
stock ACC systems; and is compared with batch and recursive least-squares
optimization. The set of ACC model parameters obtained from the proposed filter
revealed that the commercially implemented ACC system of the considered vehicle
(Hyundai Nexo) is neither $L_2$ nor $L_\infty$ string stable.
\\ ( https://arxiv.org/abs/2306.03458 ,  3487kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03581
Date: Tue, 6 Jun 2023 10:53:40 GMT   (1802kb)

Title: Optimal sizing of solar photovoltaic and lithium battery storage to
 reduce grid electricity reliance in buildings
Authors: Han Kun Ren, Malcolm McCulloch, David Wallom
Categories: eess.SY cs.SY
Comments: 10 pages, 8 figures, published in the conference of ECEEE 2022 Summer
 Study on energy efficiency: agents of change
Report-no: 8-096-22
Journal-ref: ECEEE 2022 Summer Study on energy efficiency: agents of change,
 (2022), 1199-1208, ECEEE
\\
 In alignment with the Paris Agreement, the city of Oxford in the UK aims to
become carbon neutral by 2040. Renewable energy help achieve this target by
reducing the reliance on carbon-intensive grid electricity. This research seeks
to optimally size solar photovoltaic and lithium battery storage systems,
reducing Oxford's grid electricity reliance in buildings. The analysis starts
with modeling the electricity demand. The model uses Elexon electricity
settlement profiles, and assembles them into the demand profile according to
the quantity and types of buildings in Oxford. Then, solar generation is
modeled using Pfenninger and Staffell's method. Solar photovoltaic and lithium
storage systems are sized using a hybridized analytical and iterative method.
First, the method calculates the solar system size search range, then iterates
through the range. At each solar size, the method calculates and iterates
through the storage system size search range. Within each iteration, the
renewable system is simulated using demand and generation data with a
simplified system set-up and the conventional operation strategy. The method
outputs combinations of solar system capacity, storage system capacity, and
grid electricity import. Each combination's levelized cost of electricity is
calculated, and the lowest cost combination is the optimal sizing. Solar and
storage system costs are projected from 2019 to 2100, and the optimal sizing is
calculated for each year. The result shows that solar photovoltaic is
economically competitive, but lithium storage cost is still too high. As solar
and storage prices continue to drop, they will take up greater portions of the
energy system. However, there will always be a need for the grid, as it
provides flexibility and can meet demands that are too costly for solar and
storage
\\ ( https://arxiv.org/abs/2306.03581 ,  1802kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03859
Date: Tue, 6 Jun 2023 16:55:18 GMT   (235kb,D)

Title: Parameter Estimation in Electrical Distribution Systems with limited
 Measurements using Regression Methods
Authors: Steven de Jongh and Felicitas Mueller and Claudio Canizares and Thomas
 Leibfried and Kankar Bhattacharya
Categories: eess.SY cs.SY
\\
 This paper presents novel methods for parameter identification in electrical
grids with small numbers of spatially distributed measuring devices, which is
an issue for distribution system operators managing aged and not properly
mapped underground Low Voltage (LV) grids, especially in Germany. For this
purpose, the total impedance of individual branches of the overall system is
estimated by measuring currents and voltages at a subset of all system nodes
over time. It is shown that, under common assumptions for electrical
distsribution systems, an estimate of the total impedance can be made using
readily computable proxies. Different regression methods are then used and
compared to estimate the total impedance of the respective branches, with
varying weights of the input data. The results on realistic LV feeders with
different branch lengths and number of unmeasured segments are discussed and
multiple influencing factors are investigated through simulations. It is shown
that estimates of the total impedances can be obtained with acceptable quality
under realistic assumptions.
\\ ( https://arxiv.org/abs/2306.03859 ,  235kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03871
Date: Tue, 6 Jun 2023 17:17:45 GMT   (287kb,D)

Title: Probabilistic Planning for Maritime Search and Rescue
Authors: Lu\'is Marques, Jose Javier Escribano Macias, Panagiotis Angeloudis
Categories: eess.SY cs.SY
Comments: 4 pages. 3 figures. To appear in 6th International Conference on
 Dynamics of Disasters (DOD 2023)
\\
 Maritime accidents cause thousands of disappearances every year, with migrant
crossings being particularly dangerous and under-reported. Current coastal and
NGO search and rescue services are unable to provide a timely response, so new
technologies such as autonomous UAVs are needed. We present a thorough
formalization of the maritime search and rescue problem considering its
time-critical and probabilistic nature. Further, we introduce a method for
determining the optimal search altitude for any aerial thermal-based detection
system, so as to maximize overall mission success.
\\ ( https://arxiv.org/abs/2306.03871 ,  287kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03877
Date: Tue, 6 Jun 2023 17:26:28 GMT   (855kb,D)

Title: The Eater and the Mover Game
Authors: Violetta Rostobaya, Yue Guan, James Berneburg, Michael Dorothy and
 Daigo Shishika
Categories: eess.SY cs.SY
Comments: Submitted to the IEEE Control Systems Letters (L-CSS), 2023
\\
 This paper studies the idea of ``deception by motion'' through a two-player
dynamic game played between a Mover who must retrieve resources at a goal
location, and an Eater who can consume resources at two candidate goals. The
Mover seeks to minimize the resource consumption at the true goal, and the
Eater tries to maximize it. While the Mover has the knowledge about the true
goal, the Eater cannot differentiate between the two candidates. Unlike
existing works on deceptive motion control that measures the deceptiveness
through the quality of inference made by a distant observer (an estimator), we
incorporate their actions to directly measure the efficacy of deception through
the outcome of the game. An equilibrium concept is then proposed without the
notion of an estimator. We further identify a pair of equilibrium strategies
and demonstrate that if the Eater optimizes for the worst-case scenario, hiding
the intention (deception by ambiguity) is still effective, whereas trying to
fake the true goal (deception by exaggeration) is not.
\\ ( https://arxiv.org/abs/2306.03877 ,  855kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03897
Date: Sun, 4 Jun 2023 15:03:39 GMT   (5507kb)

Title: DANSE: Data-driven Non-linear State Estimation of Model-free Process in
 Unsupervised Learning Setup
Authors: Anubhab Ghosh, Antoine Honor\'e and Saikat Chatterjee
Categories: eess.SY cs.LG cs.SY eess.SP
Comments: 12 pages, The paper is under review
\\
 We address the tasks of Bayesian state estimation and forecasting for a
model-free process in an unsupervised learning setup. In the article, we
propose DANSE -- a Data-driven Nonlinear State Estimation method. DANSE
provides a closed-form posterior of the state of the model-free process, given
linear measurements of the state. In addition, it provides a closed-form
posterior for forecasting. A data-driven recurrent neural network (RNN) is used
in DANSE to provide the parameters of a prior of the state. The prior depends
on the past measurements as input, and then we find the closed-form posterior
of the state using the current measurement as input. The data-driven RNN
captures the underlying non-linear dynamics of the model-free process. The
training of DANSE, mainly learning the parameters of the RNN, is executed using
an unsupervised learning approach. In unsupervised learning, we have access to
a training dataset comprising only a set of measurement data trajectories, but
we do not have any access to the state trajectories. Therefore, DANSE does not
have access to state information in the training data and can not use
supervised learning. Using simulated linear and non-linear process models
(Lorenz attractor and Chen attractor), we evaluate the unsupervised
learning-based DANSE. We show that the proposed DANSE, without knowledge of the
process model and without supervised learning, provides a competitive
performance against model-driven methods, such as the Kalman filter (KF),
extended KF (EKF), unscented KF (UKF), and a recently proposed hybrid method
called KalmanNet.
\\ ( https://arxiv.org/abs/2306.03897 ,  5507kb)
%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-
------------------------------------------------------------------------------
\\
arXiv:2306.03097 (*cross-listing*)
Date: Tue, 30 May 2023 21:52:33 GMT   (7743kb,D)

Title: Seeing Seeds Beyond Weeds: Green Teaming Generative AI for Beneficial
 Uses
Authors: Logan Stapleton, Jordan Taylor, Sarah Fox, Tongshuang Wu, Haiyi Zhu
Categories: cs.HC cs.AI
\\
 Large generative AI models (GMs) like GPT and DALL-E are trained to generate
content for general, wide-ranging purposes. GM content filters are generalized
to filter out content which has a risk of harm in many cases, e.g., hate
speech. However, prohibited content is not always harmful -- there are
instances where generating prohibited content can be beneficial. So, when GMs
filter out content, they preclude beneficial use cases along with harmful ones.
Which use cases are precluded reflects the values embedded in GM content
filtering. Recent work on red teaming proposes methods to bypass GM content
filters to generate harmful content. We coin the term green teaming to describe
methods of bypassing GM content filters to design for beneficial use cases. We
showcase green teaming by: 1) Using ChatGPT as a virtual patient to simulate a
person experiencing suicidal ideation, for suicide support training; 2) Using
Codex to intentionally generate buggy solutions to train students on debugging;
and 3) Examining an Instagram page using Midjourney to generate images of
anti-LGBTQ+ politicians in drag. Finally, we discuss how our use cases
demonstrate green teaming as both a practical design method and a mode of
critique, which problematizes and subverts current understandings of harms and
values in generative AI.
\\ ( https://arxiv.org/abs/2306.03097 ,  7743kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03100 (*cross-listing*)
Date: Thu, 1 Jun 2023 00:01:43 GMT   (308kb,D)

Title: Rethinking Model Evaluation as Narrowing the Socio-Technical Gap
Authors: Q. Vera Liao, Ziang Xiao
Categories: cs.HC cs.AI
\\
 The recent development of generative and large language models (LLMs) poses
new challenges for model evaluation that the research community and industry
are grappling with. While the versatile capabilities of these models ignite
excitement, they also inevitably make a leap toward homogenization: powering a
wide range of applications with a single, often referred to as
``general-purpose'', model. In this position paper, we argue that model
evaluation practices must take on a critical task to cope with the challenges
and responsibilities brought by this homogenization: providing valid
assessments for whether and how much human needs in downstream use cases can be
satisfied by the given model (\textit{socio-technical gap}). By drawing on
lessons from the social sciences, human-computer interaction (HCI), and the
interdisciplinary field of explainable AI (XAI), we urge the community to
develop evaluation methods based on real-world socio-requirements and embrace
diverse evaluation methods with an acknowledgment of trade-offs between realism
to socio-requirements and pragmatic costs. By mapping HCI and current NLG
evaluation methods, we identify opportunities for new evaluation methods for
LLMs to narrow the socio-technical gap and pose open questions.
\\ ( https://arxiv.org/abs/2306.03100 ,  308kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03102 (*cross-listing*)
Date: Fri, 2 Jun 2023 06:28:21 GMT   (1582kb,D)

Title: ChatGPT is a Remarkable Tool -- For Experts
Authors: Amos Azaria, Rina Azoulay, Shulamit Reches
Categories: cs.HC cs.AI cs.CL cs.CY
\\
 This paper investigates the capabilities of ChatGPT as an automated assistant
in diverse domains, including scientific writing, mathematics, education,
programming, and healthcare. We explore the potential of ChatGPT to enhance
productivity, streamline problem-solving processes, and improve writing style.
Furthermore, we highlight the potential risks associated with excessive
reliance on ChatGPT in these fields. These limitations encompass factors like
incorrect and fictitious responses, inaccuracies in code, limited logical
reasoning abilities, overconfidence, and critical ethical concerns of
copyrights and privacy violation. We outline areas and objectives where ChatGPT
proves beneficial, applications where it should be used judiciously, and
scenarios where its reliability may be limited. In light of observed
limitations, and given that the tool's fundamental errors may pose a special
challenge for non-experts, ChatGPT should be used with a strategic methodology.
By drawing from comprehensive experimental studies, we offer methods and flow
charts for effectively using ChatGPT. Our recommendations emphasize iterative
interaction with ChatGPT and independent verification of its outputs.
Considering the importance of utilizing ChatGPT judiciously and with expertise,
we recommend its usage for experts who are well-versed in the respective
domains.
\\ ( https://arxiv.org/abs/2306.03102 ,  1582kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03104 (*cross-listing*)
Date: Sat, 3 Jun 2023 00:56:34 GMT   (886kb,D)

Title: Guided scenarios with simulated expert personae: a remarkable strategy
 to perform cognitive work
Authors: David Van Buren
Categories: cs.HC cs.AI quant-ph
Comments: 11 pages, 3 figures, 1 listing
MSC-class: 68T01, 68T20, 68T35, 68T37, 81V80
ACM-class: I.2.0; I.2.1; I.2.3; I.2.8
\\
 Large language models (LLMs) trained on a substantial corpus of human
knowledge and literature productively work with a large array of facts from
that corpus. Surprisingly, they are also able to re-create the behaviors of
personae that are captured within the corpus. By forming teams of simulated
personae, supplying contexts that set the stage, and providing gentle prompts,
one can move through scenarios that elicit expert behavior to perform
meaningful cognitive work. The power of this strategy is demonstrated with two
examples, one attacking factuality of LLM responses and the other reproducing a
very recently published result in quantum optics.
\\ ( https://arxiv.org/abs/2306.03104 ,  886kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03112 (*cross-listing*)
Date: Mon, 5 Jun 2023 08:38:30 GMT   (250kb,D)

Title: Synthesizing Affective Neurophysiological Signals Using Generative
 Models: A Review Paper
Authors: Alireza F. Nia, Vanessa Tang, Gonzalo Maso Talou, Mark Billinghurst
Categories: cs.HC cs.AI cs.LG q-bio.NC
\\
 The integration of emotional intelligence in machines is an important step in
advancing human-computer interaction. This demands the development of reliable
end-to-end emotion recognition systems. However, the scarcity of public
affective datasets presents a challenge. In this literature review, we
emphasize the use of generative models to address this issue in
neurophysiological signals, particularly Electroencephalogram (EEG) and
Functional Near-Infrared Spectroscopy (fNIRS). We provide a comprehensive
analysis of different generative models used in the field, examining their
input formulation, deployment strategies, and methodologies for evaluating the
quality of synthesized data. This review serves as a comprehensive overview,
offering insights into the advantages, challenges, and promising future
directions in the application of generative models in emotion recognition
systems. Through this review, we aim to facilitate the progression of
neurophysiological data augmentation, thereby supporting the development of
more efficient and reliable emotion recognition systems.
\\ ( https://arxiv.org/abs/2306.03112 ,  250kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03115 (*cross-listing*)
Date: Mon, 5 Jun 2023 13:13:19 GMT   (3788kb,D)

Title: AutoExp: A multidisciplinary, multi-sensor framework to evaluate human
 activities in self-driving cars
Authors: Carlos Crispim-Junior, Romain Guesdon, Christophe Jallais, Florent
 Laroche, Stephanie Souche-Le Corvec, Laure Tougne Rodet
Categories: cs.HC cs.AI cs.LG
Comments: This paper is currently under review by the 26th IEEE International
 Conference on Intelligent Transportation Systems (ITSC 2023)
\\
 The adoption of self-driving cars will certainly revolutionize our lives,
even though they may take more time to become fully autonomous than initially
predicted. The first vehicles are already present in certain cities of the
world, as part of experimental robot-taxi services. However, most existing
studies focus on the navigation part of such vehicles. We currently miss
methods, datasets, and studies to assess the in-cabin human component of the
adoption of such technology in real-world conditions. This paper proposes an
experimental framework to study the activities of occupants of self-driving
cars using a multidisciplinary approach (computer vision associated with human
and social sciences), particularly non-driving related activities. The
framework is composed of an experimentation scenario, and a data acquisition
module. We seek firstly to capture real-world data about the usage of the
vehicle in the nearest possible, real-world conditions, and secondly to create
a dataset containing in-cabin human activities to foster the development and
evaluation of computer vision algorithms. The acquisition module records
multiple views of the front seats of the vehicle (Intel RGB-D and GoPro
cameras); in addition to survey data about the internal states and attitudes of
participants towards this type of vehicle before, during, and after the
experimentation. We evaluated the proposed framework with the realization of
real-world experimentation with 30 participants (1 hour each) to study the
acceptance of SDCs of SAE level 4.
\\ ( https://arxiv.org/abs/2306.03115 ,  3788kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03116 (*cross-listing*)
Date: Mon, 5 Jun 2023 13:43:29 GMT   (4206kb,D)

Title: Transferring Annotator- and Instance-dependent Transition Matrix for
 Learning from Crowds
Authors: Shikun Li, Xiaobo Xia, Jiankang Deng, Shiming Ge, Tongliang Liu
Categories: cs.HC cs.AI cs.LG
\\
 Learning from crowds describes that the annotations of training data are
obtained with crowd-sourcing services. Multiple annotators each complete their
own small part of the annotations, where labeling mistakes that depend on
annotators occur frequently. Modeling the label-noise generation process by the
noise transition matrix is a power tool to tackle the label noise. In
real-world crowd-sourcing scenarios, noise transition matrices are both
annotator- and instance-dependent. However, due to the high complexity of
annotator- and instance-dependent transition matrices (AIDTM),
\textit{annotation sparsity}, which means each annotator only labels a little
part of instances, makes modeling AIDTM very challenging. Prior works simplify
the problem by assuming the transition matrix is instance-independent or using
simple parametric way, while lose modeling generality. Motivated by this, we
target a more realistic problem, estimating general AIDTM in practice. Without
losing modeling generality, we parameterize AIDTM with deep neural networks. To
alleviate the modeling challenge, we suppose every annotator shares its noise
pattern with similar annotators, and estimate AIDTM via \textit{knowledge
transfer}. We hence first model the mixture of noise patterns by all
annotators, and then transfer this modeling to individual annotators.
Furthermore, considering that the transfer from the mixture of noise patterns
to individuals may cause two annotators with highly different noise generations
to perturb each other, we employ the knowledge transfer between identified
neighboring annotators to calibrate the modeling. Experiments confirm the
superiority of the proposed approach on synthetic and real-world crowd-sourcing
data. Source codes will be released.
\\ ( https://arxiv.org/abs/2306.03116 ,  4206kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03147 (*cross-listing*)
Date: Mon, 5 Jun 2023 18:00:24 GMT   (562kb,D)

Title: Decoding Nature with Nature's Tools: Heterotic Line Bundle Models of
 Particle Physics with Genetic Algorithms and Quantum Annealing
Authors: Steve Abel, Andrei Constantin, Thomas R. Harvey, Andre Lukas and Luca
 A. Nutricati
Categories: hep-th cs.AI
Comments: 11 pages, 4 figures
\\
 The string theory landscape may include a multitude of ultraviolet embeddings
of the Standard Model, but identifying these has proven difficult due to the
enormous number of available string compactifications. Genetic Algorithms (GAs)
represent a powerful class of discrete optimisation techniques that can
efficiently deal with the immensity of the string landscape, especially when
enhanced with input from quantum annealers. In this letter we focus on
geometric compactifications of the $E_8\times E_8$ heterotic string theory
compactified on smooth Calabi-Yau threefolds with Abelian bundles. We make use
of analytic formulae for bundle-valued cohomology to impose the entire range of
spectrum requirements, something that has not been possible so far. For
manifolds with a relatively low number of Kahler parameters we compare the GA
search results with results from previous systematic scans, showing that GAs
can find nearly all the viable solutions while visiting only a tiny fraction of
the solution space. Moreover, we carry out GA searches on manifolds with a
larger numbers of Kahler parameters where systematic searches are not feasible.
\\ ( https://arxiv.org/abs/2306.03147 ,  562kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03195 (*cross-listing*)
Date: Mon, 5 Jun 2023 19:13:44 GMT   (2296kb,D)

Title: Lumos in the Night Sky: AI-enabled Visual Tool for Exploring Night-Time
 Light Patterns
Authors: Jakob Hederich, Shreya Ghosh, Zeyu He and Prasenjit Mitra
Categories: cs.HC cs.AI cs.IR cs.LG
Comments: 5 pages, 3 figures. Accepted in ECML PKDD Demo track
\\
 We introduce NightPulse, an interactive tool for Night-time light (NTL) data
visualization and analytics, which enables researchers and stakeholders to
explore and analyze NTL data with a user-friendly platform. Powered by
efficient system architecture, NightPulse supports image segmentation,
clustering, and change pattern detection to identify urban development and
sprawl patterns. It captures temporal trends of NTL and semantics of cities,
answering questions about demographic factors, city boundaries, and unusual
differences.
\\ ( https://arxiv.org/abs/2306.03195 ,  2296kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03208 (*cross-listing*)
Date: Mon, 5 Jun 2023 19:30:41 GMT   (7878kb,D)

Title: NLU on Data Diets: Dynamic Data Subset Selection for NLP Classification
 Tasks
Authors: Jean-Michel Attendu and Jean-Philippe Corbeil
Categories: cs.CL cs.AI
\\
 Finetuning large language models inflates the costs of NLU applications and
remains the bottleneck of development cycles. Recent works in computer vision
use data pruning to reduce training time. Pruned data selection with static
methods is based on a score calculated for each training example prior to
finetuning, which involves important computational overhead. Moreover, the
score may not necessarily be representative of sample importance throughout the
entire training duration. We propose to address these issues with a refined
version of dynamic data pruning, a curriculum which periodically scores and
discards unimportant examples during finetuning. Our method leverages an EL2N
metric that we extend to the joint intent and slot classification task, and an
initial finetuning phase on the full train set. Our results on the GLUE
benchmark and four joint NLU datasets show a better time-accuracy trade-off
compared to static methods. Our method preserves full accuracy while training
on 50% of the data points and reduces computational times by up to 41%. If we
tolerate instead a minor drop of accuracy of 1%, we can prune 80% of the
training examples for a reduction in finetuning time reaching 66%.
\\ ( https://arxiv.org/abs/2306.03208 ,  7878kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03233 (*cross-listing*)
Date: Tue, 30 May 2023 17:04:39 GMT   (4059kb)

Title: Unified Information Dynamic Analysis of Quantum Decision-Making and
 Search Algorithms: Computational Intelligence Measure
Authors: Sergey V. Ulyanov, Fabio Ghisi, Ichiro Kurawaki and Viktor S. Ulyanov
Categories: quant-ph cs.AI cs.RO
Comments: arXiv admin note: substantial text overlap with
 arXiv:quant-ph/0102094 by other authors; text overlap with
 arXiv:quant-ph/0112105, arXiv:quant-ph/9802065 by other authors
MSC-class: 81-08, 81-05, 68T40, 93C85
\\
 There are important algorithms built upon a mixture of basic techniques
described; for example, the Fast Fourier Transform (FFT) employs both
Divide-and-Conquer and Transform-and-Conquer techniques. In this article, the
evolution of a quantum algorithm (QA) is examined from an information theory
viewpoint. The complex vector entering the quantum algorithmic gate - QAG is
considered as an information source both from the classical and the quantum
level. The analysis of the classical and quantum information flow in
Deutsch-Jozsa, Shor and Grover algorithms is used. It is shown that QAG, based
on superposition of states, quantum entanglement and interference, when acting
on the input vector, stores information into the system state, minimizing the
gap between classical Shannon entropy and quantum von Neumann entropy.
Minimizing of the gap between Shannon and von Neumann entropies is considered
as a termination criterion of QA computational intelligence measure.
\\ ( https://arxiv.org/abs/2306.03233 ,  4059kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03313 (*cross-listing*)
Date: Mon, 5 Jun 2023 23:55:09 GMT   (480kb,D)

Title: A Scalable and Adaptive System to Infer the Industry Sectors of
 Companies: Prompt + Model Tuning of Generative Language Models
Authors: Lele Cao, Vilhelm von Ehrenheim, Astrid Berghult, Cecilia Henje,
 Richard Anselmo Stahl, Joar Wandborg, Sebastian Stan, Armin Catovic, Erik
 Ferm, Hannes Ingelhag
Categories: cs.CL cs.AI
Comments: Accepted by FinNLP (Financial Technology and Natural Language
 Processing) @ IJCAI2023 as long paper (8 pages and 8 figures)
MSC-class: 68T50, 68T05
ACM-class: I.2.7; I.2.1
\\
 The Private Equity (PE) firms operate investment funds by acquiring and
managing companies to achieve a high return upon selling. Many PE funds are
thematic, meaning investment professionals aim to identify trends by covering
as many industry sectors as possible, and picking promising companies within
these sectors. So, inferring sectors for companies is critical to the success
of thematic PE funds. In this work, we standardize the sector framework and
discuss the typical challenges; we then introduce our sector inference system
addressing these challenges. Specifically, our system is built on a
medium-sized generative language model, finetuned with a prompt + model tuning
procedure. The deployed model demonstrates a superior performance than the
common baselines. The system has been serving many PE professionals for over a
year, showing great scalability to data volume and adaptability to any change
in sector framework and/or annotation.
\\ ( https://arxiv.org/abs/2306.03313 ,  480kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03315 (*cross-listing*)
Date: Mon, 5 Jun 2023 23:57:52 GMT   (2060kb,D)

Title: Few Shot Rationale Generation using Self-Training with Dual Teachers
Authors: Aditya Srikanth Veerubhotla, Lahari Poddar, Jun Yin, Gy\"orgy Szarvas,
 Sharanya Eswaran
Categories: cs.CL cs.AI
Comments: ACL Findings 2023
\\
 Self-rationalizing models that also generate a free-text explanation for
their predicted labels are an important tool to build trustworthy AI
applications. Since generating explanations for annotated labels is a laborious
and costly pro cess, recent models rely on large pretrained language models
(PLMs) as their backbone and few-shot learning. In this work we explore a
self-training approach leveraging both labeled and unlabeled data to further
improve few-shot models, under the assumption that neither human written
rationales nor annotated task labels are available at scale. We introduce a
novel dual-teacher learning framework, which learns two specialized teacher
models for task prediction and rationalization using self-training and distills
their knowledge into a multi-tasking student model that can jointly generate
the task label and rationale. Furthermore, we formulate a new loss function,
Masked Label Regularization (MLR) which promotes explanations to be strongly
conditioned on predicted labels. Evaluation on three public datasets
demonstrate that the proposed methods are effective in modeling task labels and
generating faithful rationales.
\\ ( https://arxiv.org/abs/2306.03315 ,  2060kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03358 (*cross-listing*)
Date: Tue, 6 Jun 2023 02:22:08 GMT   (1102kb)

Title: Is AI Changing the Rules of Academic Misconduct? An In-depth Look at
 Students' Perceptions of 'AI-giarism'
Authors: Cecilia Ka Yuk Chan
Categories: cs.CY cs.AI
\\
 This pioneering study explores students' perceptions of AI-giarism, an
emergent form of academic dishonesty involving AI and plagiarism, within the
higher education context. A survey, undertaken by 393 undergraduate and
postgraduate students from a variety of disciplines, investigated their
perceptions of diverse AI-giarism scenarios. The findings portray a complex
landscape of understanding, with clear disapproval for direct AI content
generation, yet more ambivalent attitudes towards subtler uses of AI. The study
introduces a novel instrument, as an initial conceptualization of AI-giarism,
offering a significant tool for educators and policy-makers. This scale
facilitates understanding and discussions around AI-related academic
misconduct, aiding in pedagogical design and assessment in an era of AI
integration. Moreover, it challenges traditional definitions of academic
misconduct, emphasizing the need to adapt in response to evolving AI
technology. Despite limitations, such as the rapidly changing nature of AI and
the use of convenience sampling, the study provides pivotal insights for
academia, policy-making, and the broader integration of AI technology in
education.
\\ ( https://arxiv.org/abs/2306.03358 ,  1102kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03361 (*cross-listing*)
Date: Tue, 6 Jun 2023 02:28:38 GMT   (10003kb,D)

Title: $\textit{WHAT}$, $\textit{WHEN}$, and $\textit{HOW}$ to Ground:
 Designing User Persona-Aware Conversational Agents for Engaging Dialogue
Authors: Deuksin Kwon, Sunwoo Lee, Ki Hyun Kim, Seojin Lee, Taeyoon Kim, Eric
 Davis
Categories: cs.CL cs.AI
Comments: Accepted in ACL 2023 Industry Track
MSC-class: I.2.1, I.2.7
\\
 This paper presents a method for building a personalized open-domain dialogue
system to address the $\textit{WWH}$ ($\textit{WHAT}$, $\textit{WHEN}$, and
$\textit{HOW}$) problem for natural response generation in a commercial
setting, where personalized dialogue responses are heavily interleaved with
casual response turns. The proposed approach involves weighted dataset
blending, negative persona information augmentation methods, and the design of
personalized conversation datasets to address the challenges of $\textit{WWH}$
in personalized, open-domain dialogue systems. Our work effectively balances
dialogue fluency and tendency to ground, while also introducing a response-type
label to improve the controllability and explainability of the grounded
responses. The combination of these methods leads to more fluent conversations,
as evidenced by subjective human evaluations as well as objective evaluations.
\\ ( https://arxiv.org/abs/2306.03361 ,  10003kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03411 (*cross-listing*)
Date: Tue, 6 Jun 2023 05:18:21 GMT   (6979kb,D)

Title: Generate-then-Retrieve: Intent-Aware FAQ Retrieval in Product Search
Authors: Zhiyu Chen, Jason Choi, Besnik Fetahu, Oleg Rokhlenko, Shervin Malmasi
Categories: cs.CL cs.AI cs.IR
Comments: ACL 2023 Industry Track
\\
 Customers interacting with product search engines are increasingly
formulating information-seeking queries. Frequently Asked Question (FAQ)
retrieval aims to retrieve common question-answer pairs for a user query with
question intent. Integrating FAQ retrieval in product search can not only
empower users to make more informed purchase decisions, but also enhance user
retention through efficient post-purchase support. Determining when an FAQ
entry can satisfy a user's information need within product search, without
disrupting their shopping experience, represents an important challenge. We
propose an intent-aware FAQ retrieval system consisting of (1) an intent
classifier that predicts when a user's information need can be answered by an
FAQ; (2) a reformulation model that rewrites a query into a natural question.
Offline evaluation demonstrates that our approach improves Hit@1 by 13% on
retrieving ground-truth FAQs, while reducing latency by 95% compared to
baseline systems. These improvements are further validated by real user
feedback, where 71% of displayed FAQs on top of product search results received
explicit positive user feedback. Overall, our findings show promising
directions for integrating FAQ retrieval into product search at scale.
\\ ( https://arxiv.org/abs/2306.03411 ,  6979kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03457 (*cross-listing*)
Date: Tue, 6 Jun 2023 07:20:51 GMT   (793kb,D)

Title: Phonetically-Grounded Language Generation: The Case of Tongue Twisters
Authors: Tyler Loakman, Chen Tang and Chenghua Lin
Categories: cs.CL cs.AI
Journal-ref: ACL 2023
\\
 Previous work in phonetically-grounded language generation has mainly focused
on domains such as lyrics and poetry. In this paper, we present work on the
generation of tongue twisters - a form of language that is required to be
phonetically conditioned to maximise sound overlap, whilst maintaining semantic
consistency with an input topic, and still being grammatically correct. We
present \textbf{TwistList}, a large annotated dataset of tongue twisters,
consisting of 2.1K+ human-authored examples. We additionally present several
benchmark systems (referred to as TwisterMisters) for the proposed task of
tongue twister generation, including models that both do and do not require
training on in-domain data. We present the results of automatic and human
evaluation to demonstrate the performance of existing mainstream pre-trained
models in this task with limited (or no) task specific training and data, and
no explicit phonetic knowledge. We find that the task of tongue twister
generation is challenging for models under these conditions, yet some models
are still capable of generating acceptable examples of this language type.
\\ ( https://arxiv.org/abs/2306.03457 ,  793kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03481 (*cross-listing*)
Date: Tue, 6 Jun 2023 08:06:43 GMT   (1249kb,D)

Title: Transition role of entangled data in quantum machine learning
Authors: Xinbiao Wang, Yuxuan Du, Zhuozhuo Tu, Yong Luo, Xiao Yuan, Dacheng Tao
Categories: quant-ph cs.AI cs.IT cs.LG math.IT
\\
 Entanglement serves as the resource to empower quantum computing. Recent
progress has highlighted its positive impact on learning quantum dynamics,
wherein the integration of entanglement into quantum operations or measurements
of quantum machine learning (QML) models leads to substantial reductions in
training data size, surpassing a specified prediction error threshold. However,
an analytical understanding of how the entanglement degree in data affects
model performance remains elusive. In this study, we address this knowledge gap
by establishing a quantum no-free-lunch (NFL) theorem for learning quantum
dynamics using entangled data. Contrary to previous findings, we prove that the
impact of entangled data on prediction error exhibits a dual effect, depending
on the number of permitted measurements. With a sufficient number of
measurements, increasing the entanglement of training data consistently reduces
the prediction error or decreases the required size of the training data to
achieve the same prediction error. Conversely, when few measurements are
allowed, employing highly entangled data could lead to an increased prediction
error. The achieved results provide critical guidance for designing advanced
QML protocols, especially for those tailored for execution on early-stage
quantum computers with limited access to quantum resources.
\\ ( https://arxiv.org/abs/2306.03481 ,  1249kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03502 (*cross-listing*)
Date: Tue, 6 Jun 2023 08:41:02 GMT   (2688kb,D)

Title: Russo-Ukrainian War: Prediction and explanation of Twitter suspension
Authors: Alexander Shevtsov, Despoina Antonakaki, Ioannis Lamprou, Ioannis
 Kontogiorgakis, Polyvios Pratikakis, Sotiris Ioannidis
Categories: cs.SI cs.AI cs.LG
\\
 On 24 February 2022, Russia invaded Ukraine, starting what is now known as
the Russo-Ukrainian War, initiating an online discourse on social media.
Twitter as one of the most popular SNs, with an open and democratic character,
enables a transparent discussion among its large user base. Unfortunately, this
often leads to Twitter's policy violations, propaganda, abusive actions, civil
integrity violation, and consequently to user accounts' suspension and
deletion. This study focuses on the Twitter suspension mechanism and the
analysis of shared content and features of the user accounts that may lead to
this. Toward this goal, we have obtained a dataset containing 107.7M tweets,
originating from 9.8 million users, using Twitter API. We extract the
categories of shared content of the suspended accounts and explain their
characteristics, through the extraction of text embeddings in junction with
cosine similarity clustering. Our results reveal scam campaigns taking
advantage of trending topics regarding the Russia-Ukrainian conflict for
Bitcoin and Ethereum fraud, spam, and advertisement campaigns. Additionally, we
apply a machine learning methodology including a SHapley Additive
explainability model to understand and explain how user accounts get suspended.
\\ ( https://arxiv.org/abs/2306.03502 ,  2688kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03503 (*cross-listing*)
Date: Tue, 6 Jun 2023 08:47:42 GMT   (710kb)

Title: Applying Standards to Advance Upstream & Downstream Ethics in Large
 Language Models
Authors: Jose Berengueres and Marybeth Sandell
Categories: cs.CY cs.AI cs.CL
Comments: 8 pages, 4 tables, 2 figures
ACM-class: K.4.1; I.2.0
\\
 This paper explores how AI-owners can develop safeguards for AI-generated
content by drawing from established codes of conduct and ethical standards in
other content-creation industries. It delves into the current state of ethical
awareness on Large Language Models (LLMs). By dissecting the mechanism of
content generation by LLMs, four key areas (upstream/downstream and at user
prompt/answer), where safeguards could be effectively applied, are identified.
A comparative analysis of these four areas follows and includes an evaluation
of the existing ethical safeguards in terms of cost, effectiveness, and
alignment with established industry practices. The paper's key argument is that
existing IT-related ethical codes, while adequate for traditional IT
engineering, are inadequate for the challenges posed by LLM-based content
generation. Drawing from established practices within journalism, we propose
potential standards for businesses involved in distributing and selling
LLM-generated content. Finally, potential conflicts of interest between dataset
curation at upstream and ethical benchmarking downstream are highlighted to
underscore the need for a broader evaluation beyond mere output. This study
prompts a nuanced conversation around ethical implications in this rapidly
evolving field of content generation.
\\ ( https://arxiv.org/abs/2306.03503 ,  710kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03509 (*cross-listing*)
Date: Tue, 6 Jun 2023 08:54:49 GMT   (1500kb,D)

Title: Mega-TTS: Zero-Shot Text-to-Speech at Scale with Intrinsic Inductive
 Bias
Authors: Ziyue Jiang, Yi Ren, Zhenhui Ye, Jinglin Liu, Chen Zhang, Qian Yang,
 Shengpeng Ji, Rongjie Huang, Chunfeng Wang, Xiang Yin, Zejun Ma, Zhou Zhao
Categories: eess.AS cs.AI cs.SD
\\
 Scaling text-to-speech to a large and wild dataset has been proven to be
highly effective in achieving timbre and speech style generalization,
particularly in zero-shot TTS. However, previous works usually encode speech
into latent using audio codec and use autoregressive language models or
diffusion models to generate it, which ignores the intrinsic nature of speech
and may lead to inferior or uncontrollable results. We argue that speech can be
decomposed into several attributes (e.g., content, timbre, prosody, and phase)
and each of them should be modeled using a module with appropriate inductive
biases. From this perspective, we carefully design a novel and large zero-shot
TTS system called Mega-TTS, which is trained with large-scale wild data and
models different attributes in different ways: 1) Instead of using latent
encoded by audio codec as the intermediate feature, we still choose spectrogram
as it separates the phase and other attributes very well. Phase can be
appropriately constructed by the GAN-based vocoder and does not need to be
modeled by the language model. 2) We model the timbre using global vectors
since timbre is a global attribute that changes slowly over time. 3) We further
use a VQGAN-based acoustic model to generate the spectrogram and a latent code
language model to fit the distribution of prosody, since prosody changes
quickly over time in a sentence, and language models can capture both local and
long-range dependencies. We scale Mega-TTS to multi-domain datasets with 20K
hours of speech and evaluate its performance on unseen speakers. Experimental
results demonstrate that Mega-TTS surpasses state-of-the-art TTS systems on
zero-shot TTS, speech editing, and cross-lingual TTS tasks, with superior
naturalness, robustness, and speaker similarity due to the proper inductive
bias of each module. Audio samples are available at
https://mega-tts.github.io/demo-page.
\\ ( https://arxiv.org/abs/2306.03509 ,  1500kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03523 (*cross-listing*)
Date: Tue, 6 Jun 2023 09:17:56 GMT   (64kb)

Title: Inconsistency Handling in Prioritized Databases with Universal
 Constraints: Complexity Analysis and Links with Active Integrity Constraints
Authors: Meghyn Bienvenu and Camille Bourgaux
Categories: cs.DB cs.AI cs.LO
Comments: This is an extended version of a paper appearing at the 20th
 International Conference on Principles of Knowledge Representation and
 Reasoning (KR 2023). 28 pages
\\
 This paper revisits the problem of repairing and querying inconsistent
databases equipped with universal constraints. We adopt symmetric difference
repairs, in which both deletions and additions of facts can be used to restore
consistency, and suppose that preferred repair actions are specified via a
binary priority relation over (negated) facts. Our first contribution is to
show how existing notions of optimal repairs, defined for simpler denial
constraints and repairs solely based on fact deletion, can be suitably extended
to our richer setting. We next study the computational properties of the
resulting repair notions, in particular, the data complexity of repair checking
and inconsistency-tolerant query answering. Finally, we clarify the
relationship between optimal repairs of prioritized databases and repair
notions introduced in the framework of active integrity constraints. In
particular, we show that Pareto-optimal repairs in our setting correspond to
founded, grounded and justified repairs w.r.t. the active integrity constraints
obtained by translating the prioritized database. Our study also yields useful
insights into the behavior of active integrity constraints.
\\ ( https://arxiv.org/abs/2306.03523 ,  64kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03528 (*cross-listing*)
Date: Tue, 6 Jun 2023 09:24:06 GMT   (2043kb,D)

Title: Adversarial Attacks and Defenses for Semantic Communication in Vehicular
 Metaverses
Authors: Jiawen Kang, Jiayi He, Hongyang Du, Zehui Xiong, Zhaohui Yang, Xumin
 Huang, Shengli Xie
Categories: cs.CR cs.AI
\\
 For vehicular metaverses, one of the ultimate user-centric goals is to
optimize the immersive experience and Quality of Service (QoS) for users on
board. Semantic Communication (SemCom) has been introduced as a revolutionary
paradigm that significantly eases communication resource pressure for vehicular
metaverse applications to achieve this goal. SemCom enables high-quality and
ultra-efficient vehicular communication, even with explosively increasing data
traffic among vehicles. In this article, we propose a hierarchical
SemCom-enabled vehicular metaverses framework consisting of the global
metaverse, local metaverses, SemCom module, and resource pool. The global and
local metaverses are brand-new concepts from the metaverse's distribution
standpoint. Considering the QoS of users, this article explores the potential
security vulnerabilities of the proposed framework. To that purpose, this study
highlights a specific security risk to the framework's SemCom module and offers
a viable defense solution, so encouraging community researchers to focus more
on vehicular metaverse security. Finally, we provide an overview of the open
issues of secure SemCom in the vehicular metaverses, notably pointing out
potential future research directions.
\\ ( https://arxiv.org/abs/2306.03528 ,  2043kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03557 (*cross-listing*)
Date: Tue, 6 Jun 2023 10:18:17 GMT   (28kb)

Title: Take the Hint: Improving Arabic Diacritization with
 Partially-Diacritized Text
Authors: Parnia Bahar, Mattia Di Gangi, Nick Rossenbach, Mohammad Zeineldeen
Categories: cs.CL cs.AI
Comments: Arabic text diacritization, partially-diacritized text, Arabic
 natural language processing
\\
 Automatic Arabic diacritization is useful in many applications, ranging from
reading support for language learners to accurate pronunciation predictor for
downstream tasks like speech synthesis. While most of the previous works
focused on models that operate on raw non-diacritized text, production systems
can gain accuracy by first letting humans partly annotate ambiguous words. In
this paper, we propose 2SDiac, a multi-source model that can effectively
support optional diacritics in input to inform all predictions. We also
introduce Guided Learning, a training scheme to leverage given diacritics in
input with different levels of random masking. We show that the provided hints
during test affect more output positions than those annotated. Moreover,
experiments on two common benchmarks show that our approach i) greatly
outperforms the baseline also when evaluated on non-diacritized text; and ii)
achieves state-of-the-art results while reducing the parameter count by over
60%.
\\ ( https://arxiv.org/abs/2306.03557 ,  28kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03572 (*cross-listing*)
Date: Tue, 6 Jun 2023 10:42:40 GMT   (50kb,D)

Title: Range-Restricted Interpolation through Clausal Tableaux
Authors: Christoph Wernhard
Categories: cs.LO cs.AI cs.DB
\\
 We show how variations of range-restriction and also the Horn property can be
passed from inputs to outputs of Craig interpolation in first-order logic. The
proof system is clausal tableaux, which stems from first-order ATP. Our results
are induced by a restriction of the clausal tableau structure, which can be
achieved in general by a proof transformation, also if the source proof is by
resolution/paramodulation. Primarily addressed applications are query synthesis
and reformulation with interpolation. Our methodical approach combines
operations on proof structures with the immediate perspective of feasible
implementation through incorporating highly optimized first-order provers.
\\ ( https://arxiv.org/abs/2306.03572 ,  50kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03580 (*cross-listing*)
Date: Tue, 6 Jun 2023 10:53:26 GMT   (1396kb,D)

Title: L-C2ST: Local Diagnostics for Posterior Approximations in
 Simulation-Based Inference
Authors: Julia Linhart, Alexandre Gramfort, Pedro L. C. Rodrigues
Categories: stat.ML cs.AI cs.LG q-bio.NC
Comments: 20 pages, 4 figures, 7 appendices, in proceedings
\\
 Many recent works in simulation-based inference (SBI) rely on deep generative
models to approximate complex, high-dimensional posterior distributions.
However, evaluating whether or not these approximations can be trusted remains
a challenge. Most approaches evaluate the posterior estimator only in
expectation over the observation space. This limits their interpretability and
is not sufficient to identify for which observations the approximation can be
trusted or should be improved. Building upon the well-known classifier
two-sample test (C2ST), we introduce L-C2ST, a new method that allows for a
local evaluation of the posterior estimator at any given observation. It offers
theoretically grounded and easy to interpret - e.g. graphical - diagnostics,
and unlike C2ST, does not require access to samples from the true posterior. In
the case of normalizing flow-based posterior estimators, L-C2ST can be
specialized to offer better statistical power, while being computationally more
efficient. On standard SBI benchmarks, L-C2ST provides comparable results to
C2ST and outperforms alternative local approaches such as coverage tests based
on highest predictive density (HPD). We further highlight the importance of
local evaluation and the benefit of interpretability of L-C2ST on a challenging
application from computational neuroscience.
\\ ( https://arxiv.org/abs/2306.03580 ,  1396kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03586 (*cross-listing*)
Date: Tue, 6 Jun 2023 11:08:20 GMT   (8415kb,D)

Title: Language acquisition: do children and language models follow similar
 learning stages?
Authors: Linnea Evanson, Yair Lakretz, Jean-R\'emi King
Categories: cs.CL cs.AI
Comments: Accepted to ACL 2023. *Equal Contribution
\\
 During language acquisition, children follow a typical sequence of learning
stages, whereby they first learn to categorize phonemes before they develop
their lexicon and eventually master increasingly complex syntactic structures.
However, the computational principles that lead to this learning trajectory
remain largely unknown. To investigate this, we here compare the learning
trajectories of deep language models to those of children. Specifically, we
test whether, during its training, GPT-2 exhibits stages of language
acquisition comparable to those observed in children aged between 18 months and
6 years. For this, we train 48 GPT-2 models from scratch and evaluate their
syntactic and semantic abilities at each training step, using 96 probes curated
from the BLiMP, Zorro and BIG-Bench benchmarks. We then compare these
evaluations with the behavior of 54 children during language production. Our
analyses reveal three main findings. First, similarly to children, the language
models tend to learn linguistic skills in a systematic order. Second, this
learning scheme is parallel: the language tasks that are learned last improve
from the very first training steps. Third, some - but not all - learning stages
are shared between children and these language models. Overall, these results
shed new light on the principles of language acquisition, and highlight
important divergences in how humans and modern algorithms learn to process
natural language.
\\ ( https://arxiv.org/abs/2306.03586 ,  8415kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03602 (*cross-listing*)
Date: Tue, 6 Jun 2023 11:45:22 GMT   (320kb,D)

Title: TestLab: An Intelligent Automated Software Testing Framework
Authors: Tiago Dias, Arthur Batista, Eva Maia and Isabel Pra\c{c}a
Categories: cs.SE cs.AI
Comments: 10 pages, 5 figures, 1 table, accepted for DCAI2023
\\
 The prevalence of software systems has become an integral part of modern-day
living. Software usage has increased significantly, leading to its growth in
both size and complexity. Consequently, software development is becoming a more
time-consuming process. In an attempt to accelerate the development cycle, the
testing phase is often neglected, leading to the deployment of flawed systems
that can have significant implications on the users daily activities. This work
presents TestLab, an intelligent automated software testing framework that
attempts to gather a set of testing methods and automate them using Artificial
Intelligence to allow continuous testing of software systems at multiple levels
from different scopes, ranging from developers to end-users. The tool consists
of three modules, each serving a distinct purpose. The first two modules aim to
identify vulnerabilities from different perspectives, while the third module
enhances traditional automated software testing by automatically generating
test cases through source code analysis.
\\ ( https://arxiv.org/abs/2306.03602 ,  320kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03608 (*cross-listing*)
Date: Tue, 6 Jun 2023 11:54:48 GMT   (6785kb,D)

Title: A Survey of Quantum-Cognitively Inspired Sentiment Analysis Models
Authors: Yaochen Liu, Qiuchi Li, Benyou Wang, Yazhou Zhang, Dawei Song
Categories: cs.CL cs.AI
\\
 Quantum theory, originally proposed as a physical theory to describe the
motions of microscopic particles, has been applied to various non-physics
domains involving human cognition and decision-making that are inherently
uncertain and exhibit certain non-classical, quantum-like characteristics.
Sentiment analysis is a typical example of such domains. In the last few years,
by leveraging the modeling power of quantum probability (a non-classical
probability stemming from quantum mechanics methodology) and deep neural
networks, a range of novel quantum-cognitively inspired models for sentiment
analysis have emerged and performed well. This survey presents a timely
overview of the latest developments in this fascinating cross-disciplinary
area. We first provide a background of quantum probability and quantum
cognition at a theoretical level, analyzing their advantages over classical
theories in modeling the cognitive aspects of sentiment analysis. Then, recent
quantum-cognitively inspired models are introduced and discussed in detail,
focusing on how they approach the key challenges of the sentiment analysis
task. Finally, we discuss the limitations of the current research and highlight
future research directions.
\\ ( https://arxiv.org/abs/2306.03608 ,  6785kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03624 (*cross-listing*)
Date: Tue, 6 Jun 2023 12:22:09 GMT   (1779kb,D)

Title: On Manipulating Signals of User-Item Graph: A Jacobi Polynomial-based
 Graph Collaborative Filtering
Authors: Jiayan Guo and Lun Du and Xu Chen and Xiaojun Ma and Qiang Fu and Shi
 Han and Dongmei Zhang and Yan Zhang
Categories: cs.IR cs.AI
\\
 Collaborative filtering (CF) is an important research direction in
recommender systems that aims to make recommendations given the information on
user-item interactions. Graph CF has attracted more and more attention in
recent years due to its effectiveness in leveraging high-order information in
the user-item bipartite graph for better recommendations. Specifically, recent
studies show the success of graph neural networks (GNN) for CF is attributed to
its low-pass filtering effects. However, current researches lack a study of how
different signal components contributes to recommendations, and how to design
strategies to properly use them well. To this end, from the view of spectral
transformation, we analyze the important factors that a graph filter should
consider to achieve better performance. Based on the discoveries, we design
JGCF, an efficient and effective method for CF based on Jacobi polynomial bases
and frequency decomposition strategies. Extensive experiments on four widely
used public datasets show the effectiveness and efficiency of the proposed
methods, which brings at most 27.06% performance gain on Alibaba-iFashion.
Besides, the experimental results also show that JGCF is better at handling
sparse datasets, which shows potential in making recommendations for cold-start
users.
\\ ( https://arxiv.org/abs/2306.03624 ,  1779kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03650 (*cross-listing*)
Date: Tue, 6 Jun 2023 13:08:22 GMT   (4994kb,D)

Title: A Quantum Probability Driven Framework for Joint Multi-Modal Sarcasm,
 Sentiment and Emotion Analysis
Authors: Yaochen Liu, Yazhou Zhang, Dawei Song
Categories: cs.CL cs.AI
\\
 Sarcasm, sentiment, and emotion are three typical kinds of spontaneous
affective responses of humans to external events and they are tightly
intertwined with each other. Such events may be expressed in multiple
modalities (e.g., linguistic, visual and acoustic), e.g., multi-modal
conversations. Joint analysis of humans' multi-modal sarcasm, sentiment, and
emotion is an important yet challenging topic, as it is a complex cognitive
process involving both cross-modality interaction and cross-affection
correlation. From the probability theory perspective, cross-affection
correlation also means that the judgments on sarcasm, sentiment, and emotion
are incompatible. However, this exposed phenomenon cannot be sufficiently
modelled by classical probability theory due to its assumption of
compatibility. Neither do the existing approaches take it into consideration.
In view of the recent success of quantum probability (QP) in modeling human
cognition, particularly contextual incompatible decision making, we take the
first step towards introducing QP into joint multi-modal sarcasm, sentiment,
and emotion analysis. Specifically, we propose a QUantum probabIlity driven
multi-modal sarcasm, sEntiment and emoTion analysis framework, termed QUIET.
Extensive experiments on two datasets and the results show that the
effectiveness and advantages of QUIET in comparison with a wide range of the
state-of-the-art baselines. We also show the great potential of QP in
multi-affect analysis.
\\ ( https://arxiv.org/abs/2306.03650 ,  4994kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03693 (*cross-listing*)
Date: Tue, 6 Jun 2023 14:06:11 GMT   (332kb,D)

Title: ESL-SNNs: An Evolutionary Structure Learning Strategy for Spiking Neural
 Networks
Authors: Jiangrong Shen, Qi Xu, Jian K. Liu, Yueming Wang, Gang Pan, Huajin
 Tang
Categories: cs.NE cs.AI
\\
 Spiking neural networks (SNNs) have manifested remarkable advantages in power
consumption and event-driven property during the inference process. To take
full advantage of low power consumption and improve the efficiency of these
models further, the pruning methods have been explored to find sparse SNNs
without redundancy connections after training. However, parameter redundancy
still hinders the efficiency of SNNs during training. In the human brain, the
rewiring process of neural networks is highly dynamic, while synaptic
connections maintain relatively sparse during brain development. Inspired by
this, here we propose an efficient evolutionary structure learning (ESL)
framework for SNNs, named ESL-SNNs, to implement the sparse SNN training from
scratch. The pruning and regeneration of synaptic connections in SNNs evolve
dynamically during learning, yet keep the structural sparsity at a certain
level. As a result, the ESL-SNNs can search for optimal sparse connectivity by
exploring all possible parameters across time. Our experiments show that the
proposed ESL-SNNs framework is able to learn SNNs with sparse structures
effectively while reducing the limited accuracy. The ESL-SNNs achieve merely
0.28% accuracy loss with 10% connection density on the DVS-Cifar10 dataset. Our
work presents a brand-new approach for sparse training of SNNs from scratch
with biologically plausible evolutionary mechanisms, closing the gap in the
expressibility between sparse training and dense training. Hence, it has great
potential for SNN lightweight training and inference with low power consumption
and small memory usage.
\\ ( https://arxiv.org/abs/2306.03693 ,  332kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03707 (*cross-listing*)
Date: Tue, 6 Jun 2023 14:19:23 GMT   (243kb,D)

Title: Effective Intrusion Detection in Highly Imbalanced IoT Networks with
 Lightweight S2CGAN-IDS
Authors: Caihong Wang, Du Xu, Zonghang Li, Dusit Niyato
Categories: cs.CR cs.AI
\\
 Since the advent of the Internet of Things (IoT), exchanging vast amounts of
information has increased the number of security threats in networks. As a
result, intrusion detection based on deep learning (DL) has been developed to
achieve high throughput and high precision. Unlike general deep learning-based
scenarios, IoT networks contain benign traffic far more than abnormal traffic,
with some rare attacks. However, most existing studies have been focused on
sacrificing the detection rate of the majority class in order to improve the
detection rate of the minority class in class-imbalanced IoT networks. Although
this way can reduce the false negative rate of minority classes, it both wastes
resources and reduces the credibility of the intrusion detection systems. To
address this issue, we propose a lightweight framework named S2CGAN-IDS. The
proposed framework leverages the distribution characteristics of network
traffic to expand the number of minority categories in both data space and
feature space, resulting in a substantial increase in the detection rate of
minority categories while simultaneously ensuring the detection precision of
majority categories. To reduce the impact of sparsity on the experiments, the
CICIDS2017 numeric dataset is utilized to demonstrate the effectiveness of the
proposed method. The experimental results indicate that our proposed approach
outperforms the superior method in both Precision and Recall, particularly with
a 10.2% improvement in the F1-score.
\\ ( https://arxiv.org/abs/2306.03707 ,  243kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03723 (*cross-listing*)
Date: Tue, 6 Jun 2023 14:41:30 GMT   (823kb,D)

Title: Financial Numeric Extreme Labelling: A Dataset and Benchmarking for XBRL
 Tagging
Authors: Soumya Sharma, Subhendu Khatuya, Manjunath Hegde, Afreen Shaikh.
 Koustuv Dasgupta, Pawan Goyal, Niloy Ganguly
Categories: cs.CL cs.AI cs.CE
Comments: Accepted to ACL'23 Findings Paper
\\
 The U.S. Securities and Exchange Commission (SEC) mandates all public
companies to file periodic financial statements that should contain numerals
annotated with a particular label from a taxonomy. In this paper, we formulate
the task of automating the assignment of a label to a particular numeral span
in a sentence from an extremely large label set. Towards this task, we release
a dataset, Financial Numeric Extreme Labelling (FNXL), annotated with 2,794
labels. We benchmark the performance of the FNXL dataset by formulating the
task as (a) a sequence labelling problem and (b) a pipeline with span
extraction followed by Extreme Classification. Although the two approaches
perform comparably, the pipeline solution provides a slight edge for the least
frequent labels.
\\ ( https://arxiv.org/abs/2306.03723 ,  823kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03763 (*cross-listing*)
Date: Sun, 28 May 2023 21:11:59 GMT   (241kb,D)

Title: ChatGPT Informed Graph Neural Network for Stock Movement Prediction
Authors: Zihan Chen, Lei Nico Zheng, Cheng Lu, Jialu Yuan, Di Zhu
Categories: q-fin.ST cs.AI cs.CL cs.LG q-fin.CP
Comments: Under Review. 10 pages, 2 figures
ACM-class: I.2.7; J.1
\\
 ChatGPT has demonstrated remarkable capabilities across various natural
language processing (NLP) tasks. However, its potential for inferring dynamic
network structures from temporal textual data, specifically financial news,
remains an unexplored frontier. In this research, we introduce a novel
framework that leverages ChatGPT's graph inference capabilities to enhance
Graph Neural Networks (GNN). Our framework adeptly extracts evolving network
structures from textual data, and incorporates these networks into graph neural
networks for subsequent predictive tasks. The experimental results from stock
movement forecasting indicate our model has consistently outperformed the
state-of-the-art Deep Learning-based benchmarks. Furthermore, the portfolios
constructed based on our model's outputs demonstrate higher annualized
cumulative returns, alongside reduced volatility and maximum drawdown. This
superior performance highlights the potential of ChatGPT for text-based network
inferences and underscores its promising implications for the financial sector.
\\ ( https://arxiv.org/abs/2306.03763 ,  241kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03809 (*cross-listing*)
Date: Tue, 6 Jun 2023 15:52:05 GMT   (157kb)

Title: Can large language models democratize access to dual-use biotechnology?
Authors: Emily H. Soice, Rafael Rocha, Kimberlee Cordova, Michael Specter, and
 Kevin M. Esvelt
Categories: cs.CY cs.AI
Comments: 6 pages, 0 figures
\\
 Large language models (LLMs) such as those embedded in 'chatbots' are
accelerating and democratizing research by providing comprehensible information
and expertise from many different fields. However, these models may also confer
easy access to dual-use technologies capable of inflicting great harm. To
evaluate this risk, the 'Safeguarding the Future' course at MIT tasked
non-scientist students with investigating whether LLM chatbots could be
prompted to assist non-experts in causing a pandemic. In one hour, the chatbots
suggested four potential pandemic pathogens, explained how they can be
generated from synthetic DNA using reverse genetics, supplied the names of DNA
synthesis companies unlikely to screen orders, identified detailed protocols
and how to troubleshoot them, and recommended that anyone lacking the skills to
perform reverse genetics engage a core facility or contract research
organization. Collectively, these results suggest that LLMs will make
pandemic-class agents widely accessible as soon as they are credibly
identified, even to people with little or no laboratory training. Promising
nonproliferation measures include pre-release evaluations of LLMs by third
parties, curating training datasets to remove harmful concepts, and verifiably
screening all DNA generated by synthesis providers or used by contract research
organizations and robotic cloud laboratories to engineer organisms or viruses.
\\ ( https://arxiv.org/abs/2306.03809 ,  157kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03812 (*cross-listing*)
Date: Tue, 6 Jun 2023 15:58:09 GMT   (1276kb,D)

Title: Computation with Sequences in the Brain
Authors: Max Dabagia, Christos H. Papadimitriou, Santosh S. Vempala
Categories: cs.NE cs.AI cs.LG q-bio.NC
Comments: 24 pages, 12 figures
\\
 Even as machine learning exceeds human-level performance on many
applications, the generality, robustness, and rapidity of the brain's learning
capabilities remain unmatched. How cognition arises from neural activity is a
central open question in neuroscience, inextricable from the study of
intelligence itself. A simple formal model of neural activity was proposed in
Papadimitriou [2020] and has been subsequently shown, through both mathematical
proofs and simulations, to be capable of implementing certain simple cognitive
operations via the creation and manipulation of assemblies of neurons. However,
many intelligent behaviors rely on the ability to recognize, store, and
manipulate temporal sequences of stimuli (planning, language, navigation, to
list a few). Here we show that, in the same model, time can be captured
naturally as precedence through synaptic weights and plasticity, and, as a
result, a range of computations on sequences of assemblies can be carried out.
In particular, repeated presentation of a sequence of stimuli leads to the
memorization of the sequence through corresponding neural assemblies: upon
future presentation of any stimulus in the sequence, the corresponding assembly
and its subsequent ones will be activated, one after the other, until the end
of the sequence. Finally, we show that any finite state machine can be learned
in a similar way, through the presentation of appropriate patterns of
sequences. Through an extension of this mechanism, the model can be shown to be
capable of universal computation. We support our analysis with a number of
experiments to probe the limits of learning in this model in key ways. Taken
together, these results provide a concrete hypothesis for the basis of the
brain's remarkable abilities to compute and learn, with sequences playing a
vital role.
\\ ( https://arxiv.org/abs/2306.03812 ,  1276kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03823 (*cross-listing*)
Date: Thu, 25 May 2023 17:35:57 GMT   (350kb)

Title: Transformative Effects of ChatGPT on Modern Education: Emerging Era of
 AI Chatbots
Authors: Sukhpal Singh Gill, Minxian Xu, Panos Patros, Huaming Wu, Rupinder
 Kaur, Kamalpreet Kaur, Stephanie Fuller, Manmeet Singh, Priyansh Arora, Ajith
 Kumar Parlikad, Vlado Stankovski, Ajith Abraham, Soumya K. Ghosh, Hanan
 Lutfiyya, Salil S. Kanhere, Rami Bahsoon, Omer Rana, Schahram Dustdar, Rizos
 Sakellariou, Steve Uhlig, Rajkumar Buyya
Categories: cs.CY cs.AI cs.CL
Comments: Preprint submitted to IoTCPS Elsevier (2023)
\\
 ChatGPT, an AI-based chatbot, was released to provide coherent and useful
replies based on analysis of large volumes of data. In this article, leading
scientists, researchers and engineers discuss the transformative effects of
ChatGPT on modern education. This research seeks to improve our knowledge of
ChatGPT capabilities and its use in the education sector, identifying potential
concerns and challenges. Our preliminary evaluation concludes that ChatGPT
performed differently in each subject area including finance, coding and maths.
While ChatGPT has the ability to help educators by creating instructional
content, offering suggestions and acting as an online educator to learners by
answering questions and promoting group work, there are clear drawbacks in its
use, such as the possibility of producing inaccurate or false data and
circumventing duplicate content (plagiarism) detectors where originality is
essential. The often reported hallucinations within Generative AI in general,
and also relevant for ChatGPT, can render its use of limited benefit where
accuracy is essential. What ChatGPT lacks is a stochastic measure to help
provide sincere and sensitive communication with its users. Academic
regulations and evaluation practices used in educational institutions need to
be updated, should ChatGPT be used as a tool in education. To address the
transformative effects of ChatGPT on the learning environment, educating
teachers and students alike about its capabilities and limitations will be
crucial.
\\ ( https://arxiv.org/abs/2306.03823 ,  350kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03856 (*cross-listing*)
Date: Tue, 6 Jun 2023 16:51:03 GMT   (46kb,D)

Title: Iterative Translation Refinement with Large Language Models
Authors: Pinzhen Chen, Zhicheng Guo, Barry Haddow, Kenneth Heafield
Categories: cs.CL cs.AI
\\
 Large language models have shown surprising performances in understanding
instructions and performing natural language tasks. In this paper, we propose
iterative translation refinement to leverage the power of large language models
for more natural translation and post-editing. We show that by simply involving
a large language model in an iterative process, the output quality improves
beyond mere translation. Extensive test scenarios with GPT-3.5 reveal that
although iterations reduce string-based metric scores, neural metrics indicate
comparable if not improved translation quality. Further, human evaluations
demonstrate that our method effectively reduces translationese compared to
initial GPT translations and even human references, especially for into-English
directions. Ablation studies underscore the importance of anchoring the
refinement process to the source input and a reasonable initial translation.
\\ ( https://arxiv.org/abs/2306.03856 ,  46kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03866 (*cross-listing*)
Date: Tue, 6 Jun 2023 17:09:29 GMT   (387kb,D)

Title: Correction of Errors in Preference Ratings from Automated Metrics for
 Text Generation
Authors: Jan Deriu, Pius von D\"aniken, Don Tuggener, Mark Cieliebak
Categories: cs.CL cs.AI
\\
 A major challenge in the field of Text Generation is evaluation: Human
evaluations are cost-intensive, and automated metrics often display
considerable disagreement with human judgments. In this paper, we propose a
statistical model of Text Generation evaluation that accounts for the
error-proneness of automated metrics when used to generate preference rankings
between system outputs. We show that existing automated metrics are generally
over-confident in assigning significant differences between systems in this
setting. However, our model enables an efficient combination of human and
automated ratings to remedy the error-proneness of the automated metrics. We
show that using this combination, we only require about 50% of the human
annotations typically used in evaluations to arrive at robust and statistically
significant results while yielding the same evaluation outcome as the pure
human evaluation in 95% of cases. We showcase the benefits of approach for
three text generation tasks: dialogue systems, machine translation, and text
summarization.
\\ ( https://arxiv.org/abs/2306.03866 ,  387kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03872 (*cross-listing*)
Date: Tue, 6 Jun 2023 17:18:56 GMT   (313kb,D)

Title: Deductive Verification of Chain-of-Thought Reasoning
Authors: Zhan Ling, Yunhao Fang, Xuanlin Li, Zhiao Huang, Mingu Lee, Roland
 Memisevic and Hao Su
Categories: cs.CL cs.AI cs.LG
\\
 Large Language Models (LLMs) significantly benefit from Chain-of-Thought
(CoT) prompting in performing various reasoning tasks. While CoT allows models
to produce more comprehensive reasoning processes, its emphasis on intermediate
reasoning steps can inadvertently introduce hallucinations and accumulated
errors, thereby limiting models' ability to solve complex reasoning tasks.
Inspired by how humans engage in careful and meticulous deductive logical
reasoning processes to solve tasks, we seek to enable language models to
perform explicit and rigorous deductive reasoning, and also ensure the
trustworthiness of their reasoning process through self-verification. However,
directly verifying the validity of an entire deductive reasoning process is
challenging, even with advanced models like ChatGPT. In light of this, we
propose to decompose a reasoning verification process into a series of
step-by-step subprocesses, each only receiving their necessary context and
premises. To facilitate this procedure, we propose Natural Program, a natural
language-based deductive reasoning format. Our approach enables models to
generate precise reasoning steps where subsequent steps are more rigorously
grounded on prior steps. It also empowers language models to carry out
reasoning self-verification in a step-by-step manner. By integrating this
verification process into each deductive reasoning stage, we significantly
enhance the rigor and trustfulness of generated reasoning steps. Along this
process, we also improve the answer correctness on complex reasoning tasks.
Code will be released at https://github.com/lz1oceani/verify_cot.
\\ ( https://arxiv.org/abs/2306.03872 ,  313kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03902 (*cross-listing*)
Date: Tue, 6 Jun 2023 17:58:44 GMT   (2008kb,D)

Title: Utterance Classification with Logical Neural Network: Explainable AI for
 Mental Disorder Diagnosis
Authors: Yeldar Toleubay, Don Joven Agravante, Daiki Kimura, Baihan Lin,
 Djallel Bouneffouf, Michiaki Tatsubori
Categories: cs.CL cs.AI cs.LO q-bio.NC
Comments: ACL 2023
\\
 In response to the global challenge of mental health problems, we proposes a
Logical Neural Network (LNN) based Neuro-Symbolic AI method for the diagnosis
of mental disorders. Due to the lack of effective therapy coverage for mental
disorders, there is a need for an AI solution that can assist therapists with
the diagnosis. However, current Neural Network models lack explainability and
may not be trusted by therapists. The LNN is a Recurrent Neural Network
architecture that combines the learning capabilities of neural networks with
the reasoning capabilities of classical logic-based AI. The proposed system
uses input predicates from clinical interviews to output a mental disorder
class, and different predicate pruning techniques are used to achieve
scalability and higher scores. In addition, we provide an insight extraction
method to aid therapists with their diagnosis. The proposed system addresses
the lack of explainability of current Neural Network models and provides a more
trustworthy solution for mental disorder diagnosis.
\\ ( https://arxiv.org/abs/2306.03902 ,  2008kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03168 (*cross-listing*)
Date: Mon, 5 Jun 2023 18:22:23 GMT   (4845kb,D)

Title: Composition and Deformance: Measuring Imageability with a Text-to-Image
 Model
Authors: Si Wu, David A. Smith
Categories: cs.CL cs.CV
\\
 Although psycholinguists and psychologists have long studied the tendency of
linguistic strings to evoke mental images in hearers or readers, most
computational studies have applied this concept of imageability only to
isolated words. Using recent developments in text-to-image generation models,
such as DALLE mini, we propose computational methods that use generated images
to measure the imageability of both single English words and connected text. We
sample text prompts for image generation from three corpora: human-generated
image captions, news article sentences, and poem lines. We subject these
prompts to different deformances to examine the model's ability to detect
changes in imageability caused by compositional change. We find high
correlation between the proposed computational measures of imageability and
human judgments of individual words. We also find the proposed measures more
consistently respond to changes in compositionality than baseline approaches.
We discuss possible effects of model training and implications for the study of
compositionality in text-to-image models.
\\ ( https://arxiv.org/abs/2306.03168 ,  4845kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03177 (*cross-listing*)
Date: Mon, 5 Jun 2023 18:37:05 GMT   (2188kb,D)

Title: DeepVQE: Real Time Deep Voice Quality Enhancement for Joint Acoustic
 Echo Cancellation, Noise Suppression and Dereverberation
Authors: Evgenii Indenbom, Nicolae-Catalin Ristea, Ando Saabas, Tanel Parnamaa,
 Jegor Guzvin, Ross Cutler
Categories: cs.SD cs.CV eess.AS
\\
 Acoustic echo cancellation (AEC), noise suppression (NS) and dereverberation
(DR) are an integral part of modern full-duplex communication systems. As the
demand for teleconferencing systems increases, addressing these tasks is
required for an effective and efficient online meeting experience. Most prior
research proposes solutions for these tasks separately, combining them with
digital signal processing (DSP) based components, resulting in complex
pipelines that are often impractical to deploy in real-world applications. This
paper proposes a real-time cross-attention deep model, named DeepVQE, based on
residual convolutional neural networks (CNNs) and recurrent neural networks
(RNNs) to simultaneously address AEC, NS, and DR. We conduct several ablation
studies to analyze the contributions of different components of our model to
the overall performance. DeepVQE achieves state-of-the-art performance on
non-personalized tracks from the ICASSP 2023 Acoustic Echo Cancellation
Challenge and ICASSP 2023 Deep Noise Suppression Challenge test sets, showing
that a single model can handle multiple tasks with excellent performance.
Moreover, the model runs in real-time and has been successfully tested for the
Microsoft Teams platform.
\\ ( https://arxiv.org/abs/2306.03177 ,  2188kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03204 (*cross-listing*)
Date: Mon, 5 Jun 2023 19:26:21 GMT   (5328kb,D)

Title: ChatGPT as a mapping assistant: A novel method to enrich maps with
 generative AI and content derived from street-level photographs
Authors: Levente Juh\'asz and Peter Mooney and Hartwig H. Hochmair and Boyuan
 Guan
Categories: cs.CY cs.CV
Comments: Submitted to The Fourth Spatial Data Science Symposium
\\
 This paper explores the concept of leveraging generative AI as a mapping
assistant for enhancing the efficiency of collaborative mapping. We present
results of an experiment that combines multiple sources of volunteered
geographic information (VGI) and large language models (LLMs). Three analysts
described the content of crowdsourced Mapillary street-level photographs taken
along roads in a small test area in Miami, Florida. GPT-3.5-turbo was
instructed to suggest the most appropriate tagging for each road in
OpenStreetMap (OSM). The study also explores the utilization of BLIP-2, a
state-of-the-art multimodal pre-training method as an artificial analyst of
street-level photographs in addition to human analysts. Results demonstrate two
ways to effectively increase the accuracy of mapping suggestions without
modifying the underlying AI models: by (1) providing a more detailed
description of source photographs, and (2) combining prompt engineering with
additional context (e.g. location and objects detected along a road). The first
approach increases the suggestion accuracy by up to 29%, and the second one by
up to 20%.
\\ ( https://arxiv.org/abs/2306.03204 ,  5328kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03270 (*cross-listing*)
Date: Mon, 5 Jun 2023 21:39:11 GMT   (820kb)

Title: Brain Tumor Recurrence vs. Radiation Necrosis Classification and Patient
 Survivability Prediction
Authors: M. S. Sadique, W. Farzana, A. Temtam, E. Lappinen, A. Vossough, K. M.
 Iftekharuddin
Categories: eess.IV cs.CV cs.LG
\\
 GBM (Glioblastoma multiforme) is the most aggressive type of brain tumor in
adults that has a short survival rate even after aggressive treatment with
surgery and radiation therapy. The changes on magnetic resonance imaging (MRI)
for patients with GBM after radiotherapy are indicative of either
radiation-induced necrosis (RN) or recurrent brain tumor (rBT). Screening for
rBT and RN at an early stage is crucial for facilitating faster treatment and
better outcomes for the patients. Differentiating rBT from RN is challenging as
both may present with similar radiological and clinical characteristics on MRI.
Moreover, learning-based rBT versus RN classification using MRI may suffer from
class imbalance due to lack of patient data. While synthetic data generation
using generative models has shown promise to address class imbalance, the
underlying data representation may be different in synthetic or augmented data.
This study proposes computational modeling with statistically rigorous repeated
random sub-sampling to balance the subset sample size for rBT and RN
classification. The proposed pipeline includes multiresolution radiomic feature
(MRF) extraction followed by feature selection with statistical significance
testing (p<0.05). The five-fold cross validation results show the proposed
model with MRF features classifies rBT from RN with an area under the curve
(AUC) of 0.8920+-.055. Moreover, considering the dependence between survival
time and censor time (where patients are not followed up until death), we
demonstrate the feasibility of using MRF radiomic features as a non-invasive
biomarker to identify patients who are at higher risk of recurrence or
radiation necrosis. The cross-validated results show that the MRF model
provides the best overall performance with an AUC of 0.770+-.032.
\\ ( https://arxiv.org/abs/2306.03270 ,  820kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03271 (*cross-listing*)
Date: Mon, 5 Jun 2023 21:41:00 GMT   (43392kb,D)

Title: Dual self-distillation of U-shaped networks for 3D medical image
 segmentation
Authors: Soumyanil Banerjee, Ming Dong, Carri Glide-Hurst
Categories: eess.IV cs.CV
Comments: 12 pages, 5 figures, 3 tables
\\
 U-shaped networks and its variants have demonstrated exceptional results for
medical image segmentation. In this paper, we propose a novel dual
self-distillation (DSD) framework for U-shaped networks for 3D medical image
segmentation. DSD distills knowledge from the ground-truth segmentation labels
to the decoder layers and also between the encoder and decoder layers of a
single U-shaped network. DSD is a generalized training strategy that could be
attached to the backbone architecture of any U-shaped network to further
improve its segmentation performance. We attached DSD on two state-of-the-art
U-shaped backbones, and extensive experiments on two public 3D medical image
segmentation datasets (cardiac substructure and brain tumor) demonstrated
significant improvement over those backbones. On average, after attaching DSD
to the U-shaped backbones, we observed an improvement of 4.25% and 3.15% in
Dice similarity score for cardiac substructure and brain tumor segmentation
respectively.
\\ ( https://arxiv.org/abs/2306.03271 ,  43392kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03373 (*cross-listing*)
Date: Tue, 6 Jun 2023 03:22:22 GMT   (3309kb,D)

Title: CiT-Net: Convolutional Neural Networks Hand in Hand with Vision
 Transformers for Medical Image Segmentation
Authors: Tao Lei, Rui Sun, Xuan Wang, Yingbo Wang, Xi He, Asoke Nandi
Categories: eess.IV cs.CV
\\
 The hybrid architecture of convolutional neural networks (CNNs) and
Transformer are very popular for medical image segmentation. However, it
suffers from two challenges. First, although a CNNs branch can capture the
local image features using vanilla convolution, it cannot achieve adaptive
feature learning. Second, although a Transformer branch can capture the global
features, it ignores the channel and cross-dimensional self-attention,
resulting in a low segmentation accuracy on complex-content images. To address
these challenges, we propose a novel hybrid architecture of convolutional
neural networks hand in hand with vision Transformers (CiT-Net) for medical
image segmentation. Our network has two advantages. First, we design a dynamic
deformable convolution and apply it to the CNNs branch, which overcomes the
weak feature extraction ability due to fixed-size convolution kernels and the
stiff design of sharing kernel parameters among different inputs. Second, we
design a shifted-window adaptive complementary attention module and a compact
convolutional projection. We apply them to the Transformer branch to learn the
cross-dimensional long-term dependency for medical images. Experimental results
show that our CiT-Net provides better medical image segmentation results than
popular SOTA methods. Besides, our CiT-Net requires lower parameters and less
computational costs and does not rely on pre-training. The code is publicly
available at https://github.com/SR0920/CiT-Net.
\\ ( https://arxiv.org/abs/2306.03373 ,  3309kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03407 (*cross-listing*)
Date: Tue, 6 Jun 2023 05:09:20 GMT   (3035kb,D)

Title: Clinical-Inspired Cytological Whole Slide Image Screening with Just
 Slide-Level Labels
Authors: Beidi Zhao, Wenlong Deng, Zi Han (Henry) Li, Chen Zhou, Zuhua Gao,
 Gang Wang and Xiaoxiao Li
Categories: eess.IV cs.CV
Comments: This paper was submitted to IEEE Transaction on Medical Imaging. It
 is under review
\\
 Cytology test is effective, non-invasive, convenient, and inexpensive for
clinical cancer screening. ThinPrep, a commonly used liquid-based specimen, can
be scanned to generate digital whole slide images (WSIs) for cytology testing.
However, WSIs classification with gigapixel resolutions is highly
resource-intensive, posing significant challenges for automated medical image
analysis. In order to circumvent this computational impasse, existing methods
emphasize learning features at the cell or patch level, typically requiring
labor-intensive and detailed manual annotations, such as labels at the cell or
patch level. Here we propose a novel automated Label-Efficient WSI Screening
method, dubbed LESS, for cytology-based diagnosis with only slide-level labels.
Firstly, in order to achieve label efficiency, we suggest employing variational
positive-unlabeled (VPU) learning, enhancing patch-level feature learning using
WSI-level labels. Subsequently, guided by the clinical approach of scrutinizing
WSIs at varying fields of view and scales, we employ a cross-attention vision
transformer (CrossViT) to fuse multi-scale patch-level data and execute
WSI-level classification. We validate the proposed label-efficient method on a
urine cytology WSI dataset encompassing 130 samples (13,000 patches) and FNAC
2019 dataset with 212 samples (21,200 patches). The experiment shows that the
proposed LESS reaches 84.79%, 85.43%, 91.79% and 78.30% on a urine cytology WSI
dataset, and 96.53%, 96.37%, 99.31%, 94.95% on FNAC 2019 dataset in terms of
accuracy, AUC, sensitivity and specificity. It outperforms state-of-the-art
methods and realizes automatic cytology-based bladder cancer screening.
\\ ( https://arxiv.org/abs/2306.03407 ,  3035kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03454 (*cross-listing*)
Date: Tue, 6 Jun 2023 07:17:56 GMT   (6340kb,D)

Title: Benchmarking Robustness of AI-enabled Multi-sensor Fusion Systems:
 Challenges and Opportunities
Authors: Xinyu Gao, Zhijie Wang, Yang Feng, Lei Ma, Zhenyu Chen, Baowen Xu
Categories: cs.SE cs.CV cs.LG
Comments: Accepted by ESEC/FSE 2023
\\
 Multi-Sensor Fusion (MSF) based perception systems have been the foundation
in supporting many industrial applications and domains, such as self-driving
cars, robotic arms, and unmanned aerial vehicles. Over the past few years, the
fast progress in data-driven artificial intelligence (AI) has brought a
fast-increasing trend to empower MSF systems by deep learning techniques to
further improve performance, especially on intelligent systems and their
perception systems. Although quite a few AI-enabled MSF perception systems and
techniques have been proposed, up to the present, limited benchmarks that focus
on MSF perception are publicly available. Given that many intelligent systems
such as self-driving cars are operated in safety-critical contexts where
perception systems play an important role, there comes an urgent need for a
more in-depth understanding of the performance and reliability of these MSF
systems. To bridge this gap, we initiate an early step in this direction and
construct a public benchmark of AI-enabled MSF-based perception systems
including three commonly adopted tasks (i.e., object detection, object
tracking, and depth completion). Based on this, to comprehensively understand
MSF systems' robustness and reliability, we design 14 common and realistic
corruption patterns to synthesize large-scale corrupted datasets. We further
perform a systematic evaluation of these systems through our large-scale
evaluation. Our results reveal the vulnerability of the current AI-enabled MSF
perception systems, calling for researchers and practitioners to take
robustness and reliability into account when designing AI-enabled MSF.
\\ ( https://arxiv.org/abs/2306.03454 ,  6340kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03476 (*cross-listing*)
Date: Tue, 6 Jun 2023 07:50:46 GMT   (9169kb,D)

Title: Putting Humans in the Image Captioning Loop
Authors: Aliki Anagnostopoulou and Mareike Hartmann and Daniel Sonntag
Categories: cs.CL cs.CV
\\
 Image Captioning (IC) models can highly benefit from human feedback in the
training process, especially in cases where data is limited. We present
work-in-progress on adapting an IC system to integrate human feedback, with the
goal to make it easily adaptable to user-specific data. Our approach builds on
a base IC model pre-trained on the MS COCO dataset, which generates captions
for unseen images. The user will then be able to offer feedback on the image
and the generated/predicted caption, which will be augmented to create
additional training instances for the adaptation of the model. The additional
instances are integrated into the model using step-wise updates, and a sparse
memory replay component is used to avoid catastrophic forgetting. We hope that
this approach, while leading to improved results, will also result in
customizable IC models.
\\ ( https://arxiv.org/abs/2306.03476 ,  9169kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03494 (*cross-listing*)
Date: Tue, 6 Jun 2023 08:22:47 GMT   (24914kb,D)

Title: LegoNet: Alternating Model Blocks for Medical Image Segmentation
Authors: Ikboljon Sobirov, Cheng Xie, Muhammad Siddique, Parijat Patel, Kenneth
 Chan, Thomas Halborg, Christos Kotanidis, Zarqiash Fatima, Henry West, Keith
 Channon, Stefan Neubauer, Charalambos Antoniades, and Mohammad Yaqub
Categories: eess.IV cs.CV
Comments: 12 pages, 5 figures, 4 tables
\\
 Since the emergence of convolutional neural networks (CNNs), and later vision
transformers (ViTs), the common paradigm for model development has always been
using a set of identical block types with varying parameters/hyper-parameters.
To leverage the benefits of different architectural designs (e.g. CNNs and
ViTs), we propose to alternate structurally different types of blocks to
generate a new architecture, mimicking how Lego blocks can be assembled
together. Using two CNN-based and one SwinViT-based blocks, we investigate
three variations to the so-called LegoNet that applies the new concept of block
alternation for the segmentation task in medical imaging. We also study a new
clinical problem which has not been investigated before, namely the right
internal mammary artery (RIMA) and perivascular space segmentation from
computed tomography angiography (CTA) which has demonstrated a prognostic value
to major cardiovascular outcomes. We compare the model performance against
popular CNN and ViT architectures using two large datasets (e.g. achieving
0.749 dice similarity coefficient (DSC) on the larger dataset). We evaluate the
performance of the model on three external testing cohorts as well, where an
expert clinician made corrections to the model segmented results (DSC>0.90 for
the three cohorts). To assess our proposed model for suitability in clinical
use, we perform intra- and inter-observer variability analysis. Finally, we
investigate a joint self-supervised learning approach to assess its impact on
model performance. The code and the pretrained model weights will be available
upon acceptance.
\\ ( https://arxiv.org/abs/2306.03494 ,  24914kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03500 (*cross-listing*)
Date: Tue, 6 Jun 2023 08:38:10 GMT   (2369kb,D)

Title: Towards Adaptable and Interactive Image Captioning with Data
 Augmentation and Episodic Memory
Authors: Aliki Anagnostopoulou and Mareike Hartmann and Daniel Sonntag
Categories: cs.CL cs.CV
\\
 Interactive machine learning (IML) is a beneficial learning paradigm in cases
of limited data availability, as human feedback is incrementally integrated
into the training process. In this paper, we present an IML pipeline for image
captioning which allows us to incrementally adapt a pre-trained image
captioning model to a new data distribution based on user input. In order to
incorporate user input into the model, we explore the use of a combination of
simple data augmentation methods to obtain larger data batches for each newly
annotated data instance and implement continual learning methods to prevent
catastrophic forgetting from repeated updates. For our experiments, we split a
domain-specific image captioning dataset, namely VizWiz, into non-overlapping
parts to simulate an incremental input flow for continually adapting the model
to new data. We find that, while data augmentation worsens results, even when
relatively small amounts of data are available, episodic memory is an effective
strategy to retain knowledge from previously seen clusters.
\\ ( https://arxiv.org/abs/2306.03500 ,  2369kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03511 (*cross-listing*)
Date: Tue, 6 Jun 2023 08:56:58 GMT   (1629kb,D)

Title: Curriculum-Based Augmented Fourier Domain Adaptation for Robust Medical
 Image Segmentation
Authors: An Wang, Mobarakol Islam, Mengya Xu, Hongliang Ren
Categories: eess.IV cs.CV
Comments: Work under review. First three authors contributed equally
\\
 Accurate and robust medical image segmentation is fundamental and crucial for
enhancing the autonomy of computer-aided diagnosis and intervention systems.
Medical data collection normally involves different scanners, protocols, and
populations, making domain adaptation (DA) a highly demanding research field to
alleviate model degradation in the deployment site. To preserve the model
performance across multiple testing domains, this work proposes the
Curriculum-based Augmented Fourier Domain Adaptation (Curri-AFDA) for robust
medical image segmentation. In particular, our curriculum learning strategy is
based on the causal relationship of a model under different levels of data
shift in the deployment phase, where the higher the shift is, the harder to
recognize the variance. Considering this, we progressively introduce more
amplitude information from the target domain to the source domain in the
frequency space during the curriculum-style training to smoothly schedule the
semantic knowledge transfer in an easier-to-harder manner. Besides, we
incorporate the training-time chained augmentation mixing to help expand the
data distributions while preserving the domain-invariant semantics, which is
beneficial for the acquired model to be more robust and generalize better to
unseen domains. Extensive experiments on two segmentation tasks of Retina and
Nuclei collected from multiple sites and scanners suggest that our proposed
method yields superior adaptation and generalization performance. Meanwhile,
our approach proves to be more robust under various corruption types and
increasing severity levels. In addition, we show our method is also beneficial
in the domain-adaptive classification task with skin lesion datasets. The code
is available at https://github.com/lofrienger/Curri-AFDA.
\\ ( https://arxiv.org/abs/2306.03511 ,  1629kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03619 (*cross-listing*)
Date: Tue, 6 Jun 2023 12:12:59 GMT   (613kb,D)

Title: Digitization of Pathology Labs: A Review of Lessons Learned
Authors: Lars Ole Schwen, Tim-Rasmus Kiehl, Rita Cavalho, Norman Zerbe, Andr\'e
 Homeyer
Categories: cs.HC cs.CV eess.IV
Comments: 22 pages, 1 figure
\\
 Pathology laboratories are increasingly using digital workflows. This has the
potential of increasing lab efficiency, but the digitization process also
involves major challenges. Several reports have been published describing the
individual experiences of specific laboratories with the digitization process.
However, a comprehensive overview of the lessons learned is still lacking. We
provide an overview of the lessons learned for different aspects of the
digitization process, including digital case management, digital slide reading,
and computer-aided slide reading. We also cover metrics used for monitoring
performance and pitfalls and corresponding values observed in practice. The
overview is intended to help pathologists, IT decision-makers, and
administrators to benefit from the experiences of others and to implement the
digitization process in an optimal way to make their own laboratory
future-proof.
\\ ( https://arxiv.org/abs/2306.03619 ,  613kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03730 (*cross-listing*)
Date: Tue, 6 Jun 2023 14:48:50 GMT   (3136kb,D)

Title: Modality-Agnostic Learning for Medical Image Segmentation Using
 Multi-modality Self-distillation
Authors: Qisheng He, Nicholas Summerfield, Ming Dong, Carri Glide-Hurst
Categories: eess.IV cs.CV
\\
 Medical image segmentation of tumors and organs at risk is a time-consuming
yet critical process in the clinic that utilizes multi-modality imaging (e.g,
different acquisitions, data types, and sequences) to increase segmentation
precision. In this paper, we propose a novel framework, Modality-Agnostic
learning through Multi-modality Self-dist-illation (MAG-MS), to investigate the
impact of input modalities on medical image segmentation. MAG-MS distills
knowledge from the fusion of multiple modalities and applies it to enhance
representation learning for individual modalities. Thus, it provides a
versatile and efficient approach to handle limited modalities during testing.
Our extensive experiments on benchmark datasets demonstrate the high efficiency
of MAG-MS and its superior segmentation performance than current
state-of-the-art methods. Furthermore, using MAG-MS, we provide valuable
insight and guidance on selecting input modalities for medical image
segmentation tasks.
\\ ( https://arxiv.org/abs/2306.03730 ,  3136kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03835 (*cross-listing*)
Date: Tue, 6 Jun 2023 16:25:29 GMT   (831kb,D)

Title: Atrial Septal Defect Detection in Children Based on Ultrasound Video
 Using Multiple Instances Learning
Authors: Yiman Liu and Qiming Huang and Xiaoxiang Han and Tongtong Liang and
 Zhifang Zhang and Lijun Chen and Jinfeng Wang and Angelos Stefanidis and
 Jionglong Su and Jiangang Chen and Qingli Li and Yuqi Zhang
Categories: eess.IV cs.CV cs.LG
\\
 Purpose: Congenital heart defect (CHD) is the most common birth defect.
Thoracic echocardiography (TTE) can provide sufficient cardiac structure
information, evaluate hemodynamics and cardiac function, and is an effective
method for atrial septal defect (ASD) examination. This paper aims to study a
deep learning method based on cardiac ultrasound video to assist in ASD
diagnosis. Materials and methods: We select two standard views of the atrial
septum (subAS) and low parasternal four-compartment view (LPS4C) as the two
views to identify ASD. We enlist data from 300 children patients as part of a
double-blind experiment for five-fold cross-validation to verify the
performance of our model. In addition, data from 30 children patients (15
positives and 15 negatives) are collected for clinician testing and compared to
our model test results (these 30 samples do not participate in model training).
We propose an echocardiography video-based atrial septal defect diagnosis
system. In our model, we present a block random selection, maximal agreement
decision and frame sampling strategy for training and testing respectively,
resNet18 and r3D networks are used to extract the frame features and aggregate
them to build a rich video-level representation. Results: We validate our model
using our private dataset by five-cross validation. For ASD detection, we
achieve 89.33 AUC, 84.95 accuracy, 85.70 sensitivity, 81.51 specificity and
81.99 F1 score. Conclusion: The proposed model is multiple instances
learning-based deep learning model for video atrial septal defect detection
which effectively improves ASD detection accuracy when compared to the
performances of previous networks and clinical doctors.
\\ ( https://arxiv.org/abs/2306.03835 ,  831kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03540 (*cross-listing*)
Date: Tue, 6 Jun 2023 09:37:22 GMT   (560kb)

Title: Greedy-Mine: A Profitable Mining Attack Strategy in Bitcoin-NG
Authors: Junjie Hu, Zhe Jiang, Chunxiang Xu
Categories: cs.CR cs.CE cs.GT
Comments: 20 pages, 12 figurs
\\
 Bitcoin-NG is an extensible blockchain protocol based on the same trust model
as Bitcoin. It divides each epoch into one Key-Block and multiple Micro-Blocks,
effectively improving transaction processing capacity. Bitcoin-NG adopts a
special incentive mechanism (i.e., the transaction fees in each epoch are split
to the current and next leader) to maintain its security. However, there are
some limitations to the existing incentive analysis of Bitcoin-NG in recent
works. First, the incentive division method of Bitcoin-NG only includes some
specific mining attack strategies of adversary, while ignoring more stubborn
attack strategies. Second, once adversaries find a whale transaction, they will
deviate from honest mining strategy to obtain extra reward. In this paper, we
are committed to solving these two limitations. First, we propose a novel
mining strategy named Greedy-Mine attack. Then, we formulate a Markov Decision
Process (MDP) model to analyze the competition of honest miners and
adversaries. Furthermore, we analysis the extra reward of adversaries and
summarize the mining power proportion range required for malicious adversaries
to launch Greedy-Mine to obtain extra returns. Finally, we make a
backward-compatibility progressive modification to Bitcoin-NG protocol that
would raise the threshold of propagation factor from 0 to 1. Meanwhile, we get
the winning condition of adversaries when adopting Greedy-Mine, compared with
honest mining. Simulation and experimental results indicate that Bitcoin-NG is
not incentive compatible, which is vulnerable to Greedy-Mine attack.
\\ ( https://arxiv.org/abs/2306.03540 ,  560kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03099 (*cross-listing*)
Date: Wed, 31 May 2023 12:34:16 GMT   (9733kb,D)

Title: CrystalGPT: Enhancing system-to-system transferability in
 crystallization prediction and control using time-series-transformers
Authors: Niranjan Sitapure, Joseph S. Kwon
Categories: cond-mat.mtrl-sci cs.LG
Comments: 21 Pages, 11 Figures. Submitted to Computers and Chemical Engineering
 Journal
ACM-class: J.2; I.6.5; I.2.6
\\
 For prediction and real-time control tasks, machine-learning (ML)-based
digital twins are frequently employed. However, while these models are
typically accurate, they are custom-designed for individual systems, making
system-to-system (S2S) transferability difficult. This occurs even when
substantial similarities exist in the process dynamics across different
chemical systems. To address this challenge, we developed a novel
time-series-transformer (TST) framework that exploits the powerful transfer
learning capabilities inherent in transformer algorithms. This was demonstrated
using readily available process data obtained from different crystallizers
operating under various operational scenarios. Using this extensive dataset, we
trained a TST model (CrystalGPT) to exhibit remarkable S2S transferability not
only across all pre-established systems, but also to an unencountered system.
CrystalGPT achieved a cumulative error across all systems, which is eight times
superior to that of existing ML models. Additionally, we coupled CrystalGPT
with a predictive controller to reduce the variance in setpoint tracking to
just 1%.
\\ ( https://arxiv.org/abs/2306.03099 ,  9733kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03105 (*cross-listing*)
Date: Sat, 3 Jun 2023 06:06:27 GMT   (248kb,D)

Title: Data driven localized wave solution of the Fokas-Lenells equation using
 modified PINN
Authors: Gautam Kumar Saharia, Sagardeep Talukdar, Riki Dutta and Sudipta Nandy
Categories: nlin.PS cs.LG nlin.SI
Comments: 14 pages
\\
 We investigate data driven localized wave solutions of the Fokas-Lenells
equation by using physics informed neural network(PINN). We improve basic PINN
by incorporating control parameters into the residual loss function. We also
add conserve quantity as another loss term to modify the PINN. Using modified
PINN we obtain the data driven bright soliton and dark soliton solutions of
Fokas-Lenells equation. Conserved quantities informed loss function achieve
more accuracy in terms of relative L2 error between predicted and exact soliton
solutions. We hope that the present investigation would be useful to study the
applications of deep learning in nonlinear optics and other branches of
nonlinear physics. Source codes are available at
https://github.com/gautamksaharia/Fokas-Lenells
\\ ( https://arxiv.org/abs/2306.03105 ,  248kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03109 (*cross-listing*)
Date: Mon, 5 Jun 2023 04:34:54 GMT   (7982kb,D)

Title: Machine Learning Force Fields with Data Cost Aware Training
Authors: Alexander Bukharin, Tianyi Liu, Shengjie Wang, Simiao Zuo, Weihao Gao,
 Wen Yan, Tuo Zhao
Categories: q-bio.QM cs.LG physics.chem-ph
\\
 Machine learning force fields (MLFF) have been proposed to accelerate
molecular dynamics (MD) simulation, which finds widespread applications in
chemistry and biomedical research. Even for the most data-efficient MLFFs,
reaching chemical accuracy can require hundreds of frames of force and energy
labels generated by expensive quantum mechanical algorithms, which may scale as
$O(n^3)$ to $O(n^7)$, with $n$ proportional to the number of basis functions.
To address this issue, we propose a multi-stage computational framework --
ASTEROID, which lowers the data cost of MLFFs by leveraging a combination of
cheap inaccurate data and expensive accurate data. The motivation behind
ASTEROID is that inaccurate data, though incurring large bias, can help capture
the sophisticated structures of the underlying force field. Therefore, we first
train a MLFF model on a large amount of inaccurate training data, employing a
bias-aware loss function to prevent the model from overfitting tahe potential
bias of this data. We then fine-tune the obtained model using a small amount of
accurate training data, which preserves the knowledge learned from the
inaccurate training data while significantly improving the model's accuracy.
Moreover, we propose a variant of ASTEROID based on score matching for the
setting where the inaccurate training data are unlabeled. Extensive experiments
on MD datasets and downstream tasks validate the efficacy of ASTEROID. Our code
and data are available at https://github.com/abukharin3/asteroid.
\\ ( https://arxiv.org/abs/2306.03109 ,  7982kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03111 (*cross-listing*)
Date: Mon, 5 Jun 2023 08:23:46 GMT   (6791kb,D)

Title: Bootstrapped Training of Score-Conditioned Generator for Offline Design
 of Biological Sequences
Authors: Minsu Kim, Federico Berto, Sungsoo Ahn, Jinkyoo Park
Categories: q-bio.QM cs.LG stat.ML
Comments: 18 pages, 5 figures
\\
 We study the problem of optimizing biological sequences, e.g., proteins, DNA,
and RNA, to maximize a black-box score function that is only evaluated in an
offline dataset. We propose a novel solution, bootstrapped training of
score-conditioned generator (BootGen) algorithm. Our algorithm repeats a
two-stage process. In the first stage, our algorithm trains the biological
sequence generator with rank-based weights to enhance the accuracy of sequence
generation based on high scores. The subsequent stage involves bootstrapping,
which augments the training dataset with self-generated data labeled by a proxy
score function. Our key idea is to align the score-based generation with a
proxy score function, which distills the knowledge of the proxy score function
to the generator. After training, we aggregate samples from multiple
bootstrapped generators and proxies to produce a diverse design. Extensive
experiments show that our method outperforms competitive baselines on
biological sequential design tasks. We provide reproducible source code:
\href{https://github.com/kaist-silab/bootgen}{https://github.com/kaist-silab/bootgen}.
\\ ( https://arxiv.org/abs/2306.03111 ,  6791kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03117 (*cross-listing*)
Date: Mon, 5 Jun 2023 15:19:06 GMT   (9882kb,D)

Title: Score-based Enhanced Sampling for Protein Molecular Dynamics
Authors: Jiarui Lu, Bozitao Zhong, Jian Tang
Categories: q-bio.QM cs.LG q-bio.BM
Comments: Under review
\\
 The dynamic nature of proteins is crucial for determining their biological
functions and properties, and molecular dynamics (MD) simulations stand as a
predominant tool to study such phenomena. By utilizing empirically derived
force fields, MD simulations explore the conformational space through
numerically evolving the system along MD trajectories. However, the high-energy
barrier of the force fields can hamper the exploration of MD, resulting in
inadequately sampled ensemble. In this paper, we propose leveraging score-based
generative models (SGMs) trained on general protein structures to perform
protein conformational sampling to complement traditional MD simulations. We
argue that SGMs can provide a novel framework as an alternative to traditional
enhanced sampling methods by learning multi-level score functions, which
directly sample a diversity-controllable ensemble of conformations. We
demonstrate the effectiveness of our approach on several benchmark systems by
comparing the results with long MD trajectories and state-of-the-art generative
structure prediction models. Our framework provides new insights that SGMs have
the potential to serve as an efficient and simulation-free methods to study
protein dynamics.
\\ ( https://arxiv.org/abs/2306.03117 ,  9882kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03143 (*cross-listing*)
Date: Mon, 5 Jun 2023 18:00:07 GMT   (8279kb,D)

Title: Machine learning feature discovery of spinon Fermi surface
Authors: Kevin Zhang, Shi Feng, Yuri D. Lensky, Nandini Trivedi, Eun-Ah Kim
Categories: cond-mat.str-el cond-mat.dis-nn cs.LG quant-ph
Comments: 8 pages + 8 pages supplemental
\\
 With rapid progress in simulation of strongly interacting quantum
Hamiltonians, the challenge in characterizing unknown phases becomes a
bottleneck for scientific progress. We demonstrate that a Quantum-Classical
hybrid approach (QuCl) of mining the projective snapshots with interpretable
classical machine learning, can unveil new signatures of seemingly featureless
quantum states. The Kitaev-Heisenberg model on a honeycomb lattice with
bond-dependent frustrated interactions presents an ideal system to test QuCl.
The model hosts a wealth of quantum spin liquid states: gapped and gapless
$\mathbb{Z}_2$ spin liquids, and a chiral spin liquid (CSL) phase in a small
external magnetic field. Recently, various simulations have found a new
intermediate gapless phase (IGP), sandwiched between the CSL and a partially
polarized phase, launching a debate over its elusive nature. We reveal
signatures of phases in the model by contrasting two phases pairwise using an
interpretable neural network, the correlator convolutional neural network
(CCNN). We train the CCNN with a labeled collection of sampled projective
measurements and reveal signatures of each phase through regularization path
analysis. We show that QuCl reproduces known features of established spin
liquid phases and ordered phases. Most significantly, we identify a signature
motif of the field-induced IGP in the spin channel perpendicular to the field
direction, which we interpret as a signature of Friedel oscillations of gapless
spinons forming a Fermi surface. Our predictions can guide future experimental
searches for $U(1)$ spin liquids.
\\ ( https://arxiv.org/abs/2306.03143 ,  8279kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03161 (*cross-listing*)
Date: Mon, 5 Jun 2023 18:16:03 GMT   (62kb)

Title: On the Role of Entanglement and Statistics in Learning
Authors: Srinivasan Arunachalam, Vojtech Havlicek, Louis Schatzki
Categories: quant-ph cs.CC cs.LG
Comments: 43 pages, 3 pages of appendix
\\
 In this work we make progress in understanding the relationship between
learning models with access to entangled, separable and statistical
measurements in the quantum statistical query (QSQ) model. To this end, we show
the following results.
 $\textbf{Entangled versus separable measurements.}$ The goal here is to learn
an unknown $f$ from the concept class $C\subseteq \{f:\{0,1\}^n\rightarrow
[k]\}$ given copies of $\frac{1}{\sqrt{2^n}}\sum_x \vert x,f(x)\rangle$. We
show that, if $T$ copies suffice to learn $f$ using entangled measurements,
then $O(nT^2)$ copies suffice to learn $f$ using just separable measurements.
 $\textbf{Entangled versus statistical measurements}$ The goal here is to
learn a function $f \in C$ given access to separable measurements and
statistical measurements. We exhibit a class $C$ that gives an exponential
separation between QSQ learning and quantum learning with entangled
measurements (even in the presence of noise). This proves the "quantum
analogue" of the seminal result of Blum et al. [BKW'03]. that separates
classical SQ and PAC learning with classification noise.
 $\textbf{QSQ lower bounds for learning states.}$ We introduce a quantum
statistical query dimension (QSD), which we use to give lower bounds on the QSQ
learning. With this we prove superpolynomial QSQ lower bounds for testing
purity, shadow tomography, Abelian hidden subgroup problem, degree-$2$
functions, planted bi-clique states and output states of Clifford circuits of
depth $\textsf{polylog}(n)$.
 $\textbf{Further applications.}$ We give and $\textit{unconditional}$
separation between weak and strong error mitigation and prove lower bounds for
learning distributions in the QSQ model. Prior works by Quek et al. [QFK+'22],
Hinsche et al. [HIN+'22], and Nietner et al. [NIS+'23] proved the analogous
results $\textit{assuming}$ diagonal measurements and our work removes this
assumption.
\\ ( https://arxiv.org/abs/2306.03161 ,  62kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03191 (*cross-listing*)
Date: Mon, 5 Jun 2023 19:06:18 GMT   (2173kb,D)

Title: Personalized Federated Domain Adaptation for Item-to-Item Recommendation
Authors: Ziwei Fan, Hao Ding, Anoop Deoras, and Trong Nghia Hoang
Categories: cs.IR cs.LG
Comments: 14 pages, Accepted by UAI 2023
\\
 Item-to-Item (I2I) recommendation is an important function in most
recommendation systems, which generates replacement or complement suggestions
for a particular item based on its semantic similarities to other cataloged
items. Given that subsets of items in a recommendation system might be
co-interacted with by the same set of customers, graph-based models, such as
graph neural networks (GNNs), provide a natural framework to combine, ingest
and extract valuable insights from such high-order relational interactions
between cataloged items, as well as their metadata features, as has been shown
in many recent studies. However, learning GNNs effectively for I2I requires
ingesting a large amount of relational data, which might not always be
available, especially in new, emerging market segments. To mitigate this data
bottleneck, we postulate that recommendation patterns learned from existing
mature market segments (with private data) could be adapted to build effective
warm-start models for emerging ones. To achieve this, we propose and
investigate a personalized federated modeling framework based on GNNs to
summarize, assemble and adapt recommendation patterns across market segments
with heterogeneous customer behaviors into effective local models. Our key
contribution is a personalized graph adaptation model that bridges the gap
between recent literature on federated GNNs and (non-graph) personalized
federated learning, which either does not optimize for the adaptability of the
federated model or is restricted to local models with homogeneous
parameterization, excluding GNNs with heterogeneous local graphs.
\\ ( https://arxiv.org/abs/2306.03191 ,  2173kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03202 (*cross-listing*)
Date: Mon, 5 Jun 2023 19:22:02 GMT   (762kb,D)

Title: Nonlinear Distributionally Robust Optimization
Authors: Mohammed Rayyan Sheriff and Peyman Mohajerin Esfahani
Categories: stat.ML cs.LG math.OC
\\
 This article focuses on a class of distributionally robust optimization (DRO)
problems where, unlike the growing body of the literature, the objective
function is potentially non-linear in the distribution. Existing methods to
optimize nonlinear functions in probability space use the Frechet derivatives,
which present both theoretical and computational challenges. Motivated by this,
we propose an alternative notion for the derivative and corresponding
smoothness based on Gateaux (G)-derivative for generic risk measures. These
concepts are explained via three running risk measure examples of variance,
entropic risk, and risk on finite support sets. We then propose a G-derivative
based Frank-Wolfe~(FW) algorithm for generic non-linear optimization problems
in probability spaces and establish its convergence under the proposed notion
of smoothness in a completely norm-independent manner. We use the set-up of the
FW algorithm to devise a methodology to compute a saddle point of the
non-linear DRO problem. Finally, for the minimum variance portfolio selection
problem we analyze the regularity conditions and compute the FW-oracle in
various settings, and validate the theoretical results numerically.
\\ ( https://arxiv.org/abs/2306.03202 ,  762kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03218 (*cross-listing*)
Date: Mon, 5 Jun 2023 20:08:19 GMT   (8323kb,D)

Title: Optimal transport for automatic alignment of untargeted metabolomic data
Authors: Marie Breeur, George Stepaniants, Pekka Keski-Rahkonen, Philippe
 Rigollet, and Vivian Viallon
Categories: q-bio.QM cs.LG
Comments: 41 pages, 11 figures
MSC-class: 49Q22, 92C40
ACM-class: G.3; J.3
\\
 Untargeted metabolomic profiling through liquid chromatography-mass
spectrometry (LC-MS) measures a vast array of metabolites within biospecimens,
advancing drug development, disease diagnosis, and risk prediction. However,
the low throughput of LC-MS poses a major challenge for biomarker discovery,
annotation, and experimental comparison, necessitating the merging of multiple
datasets. Current data pooling methods encounter practical limitations due to
their vulnerability to data variations and hyperparameter dependence. Here we
introduce GromovMatcher, a flexible and user-friendly algorithm that
automatically combines LC-MS datasets using optimal transport. By capitalizing
on feature intensity correlation structures, GromovMatcher delivers superior
alignment accuracy and robustness compared to existing approaches. This
algorithm scales to thousands of features requiring minimal hyperparameter
tuning. Applying our method to experimental patient studies of liver and
pancreatic cancer, we discover shared metabolic features related to patient
alcohol intake, demonstrating how GromovMatcher facilitates the search for
biomarkers associated with lifestyle risk factors linked to several cancer
types.
\\ ( https://arxiv.org/abs/2306.03218 ,  8323kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03257 (*cross-listing*)
Date: Mon, 5 Jun 2023 21:19:37 GMT   (4029kb,D)

Title: Generating Private Synthetic Data with Genetic Algorithms
Authors: Terrance Liu, Jingwu Tang, Giuseppe Vietri, Zhiwei Steven Wu
Categories: cs.OH cs.CR cs.LG cs.NE
\\
 We study the problem of efficiently generating differentially private
synthetic data that approximate the statistical properties of an underlying
sensitive dataset. In recent years, there has been a growing line of work that
approaches this problem using first-order optimization techniques. However,
such techniques are restricted to optimizing differentiable objectives only,
severely limiting the types of analyses that can be conducted. For example,
first-order mechanisms have been primarily successful in approximating
statistical queries only in the form of marginals for discrete data domains. In
some cases, one can circumvent such issues by relaxing the task's objective to
maintain differentiability. However, even when possible, these approaches
impose a fundamental limitation in which modifications to the minimization
problem become additional sources of error. Therefore, we propose Private-GSD,
a private genetic algorithm based on zeroth-order optimization heuristics that
do not require modifying the original objective. As a result, it avoids the
aforementioned limitations of first-order optimization. We empirically evaluate
Private-GSD against baseline algorithms on data derived from the American
Community Survey across a variety of statistics--otherwise known as statistical
queries--both for discrete and real-valued attributes. We show that Private-GSD
outperforms the state-of-the-art methods on non-differential queries while
matching accuracy in approximating differentiable ones.
\\ ( https://arxiv.org/abs/2306.03257 ,  4029kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03303 (*cross-listing*)
Date: Mon, 5 Jun 2023 23:06:32 GMT   (1420kb,D)

Title: Global universal approximation of functional input maps on weighted
 spaces
Authors: Christa Cuchiero, Philipp Schmocker, Josef Teichmann
Categories: stat.ML cs.LG math.FA math.PR q-fin.MF
Comments: 57 pages, 4 figures
MSC-class: 26A16, 26E20, 41A65, 41A81, 46E40, 60L10, 68T07
\\
 We introduce so-called functional input neural networks defined on a possibly
infinite dimensional weighted space with values also in a possibly infinite
dimensional output space. To this end, we use an additive family as hidden
layer maps and a non-linear activation function applied to each hidden layer.
Relying on Stone-Weierstrass theorems on weighted spaces, we can prove a global
universal approximation result for generalizations of continuous functions
going beyond the usual approximation on compact sets. This then applies in
particular to approximation of (non-anticipative) path space functionals via
functional input neural networks. As a further application of the weighted
Stone-Weierstrass theorem we prove a global universal approximation result for
linear functions of the signature. We also introduce the viewpoint of Gaussian
process regression in this setting and show that the reproducing kernel Hilbert
space of the signature kernels are Cameron-Martin spaces of certain Gaussian
processes. This paves the way towards uncertainty quantification for signature
kernel regression.
\\ ( https://arxiv.org/abs/2306.03303 ,  1420kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03335 (*cross-listing*)
Date: Tue, 6 Jun 2023 01:13:18 GMT   (12490kb,D)

Title: Unraveling Projection Heads in Contrastive Learning: Insights from
 Expansion and Shrinkage
Authors: Yu Gui, Cong Ma, Yiqiao Zhong
Categories: stat.ML cs.LG math.ST stat.TH
\\
 We investigate the role of projection heads, also known as projectors, within
the encoder-projector framework (e.g., SimCLR) used in contrastive learning. We
aim to demystify the observed phenomenon where representations learned before
projectors outperform those learned after -- measured using the downstream
linear classification accuracy, even when the projectors themselves are linear.
 In this paper, we make two significant contributions towards this aim.
Firstly, through empirical and theoretical analysis, we identify two crucial
effects -- expansion and shrinkage -- induced by the contrastive loss on the
projectors. In essence, contrastive loss either expands or shrinks the signal
direction in the representations learned by an encoder, depending on factors
such as the augmentation strength, the temperature used in contrastive loss,
etc. Secondly, drawing inspiration from the expansion and shrinkage phenomenon,
we propose a family of linear transformations to accurately model the
projector's behavior. This enables us to precisely characterize the downstream
linear classification accuracy in the high-dimensional asymptotic limit. Our
findings reveal that linear projectors operating in the shrinkage (or
expansion) regime hinder (or improve) the downstream classification accuracy.
This provides the first theoretical explanation as to why (linear) projectors
impact the downstream performance of learned representations. Our theoretical
findings are further corroborated by extensive experiments on both synthetic
data and real image data.
\\ ( https://arxiv.org/abs/2306.03335 ,  12490kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03372 (*cross-listing*)
Date: Tue, 6 Jun 2023 03:21:28 GMT   (1821kb)

Title: Online Tensor Learning: Computational and Statistical Trade-offs,
 Adaptivity and Optimal Regret
Authors: Jian-Feng Cai, Jingyang Li and Dong Xia
Categories: stat.ML cs.LG
\\
 We investigate a generalized framework for estimating latent low-rank tensors
in an online setting, encompassing both linear and generalized linear models.
This framework offers a flexible approach for handling continuous or
categorical variables. Additionally, we investigate two specific applications:
online tensor completion and online binary tensor learning. To address these
challenges, we propose the online Riemannian gradient descent algorithm, which
demonstrates linear convergence and the ability to recover the low-rank
component under appropriate conditions in all applications. Furthermore, we
establish a precise entry-wise error bound for online tensor completion.
Notably, our work represents the first attempt to incorporate noise in the
online low-rank tensor recovery task. Intriguingly, we observe a surprising
trade-off between computational and statistical aspects in the presence of
noise. Increasing the step size accelerates convergence but leads to higher
statistical error, whereas a smaller step size yields a statistically optimal
estimator at the expense of slower convergence. Moreover, we conduct regret
analysis for online tensor regression. Under the fixed step size regime, a
fascinating trilemma concerning the convergence rate, statistical error rate,
and regret is observed. With an optimal choice of step size we achieve an
optimal regret of $O(\sqrt{T})$. Furthermore, we extend our analysis to the
adaptive setting where the horizon T is unknown. In this case, we demonstrate
that by employing different step sizes, we can attain a statistically optimal
error rate along with a regret of $O(\log T)$. To validate our theoretical
claims, we provide numerical results that corroborate our findings and support
our assertions.
\\ ( https://arxiv.org/abs/2306.03372 ,  1821kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03398 (*cross-listing*)
Date: Tue, 6 Jun 2023 04:28:12 GMT   (46kb)

Title: Minimum intrinsic dimension scaling for entropic optimal transport
Authors: Austin J. Stromme
Categories: math.ST cs.LG math.PR stat.TH
Comments: 53 pages
\\
 Motivated by the manifold hypothesis, which states that data with a high
extrinsic dimension may yet have a low intrinsic dimension, we develop refined
statistical bounds for entropic optimal transport that are sensitive to the
intrinsic dimension of the data. Our bounds involve a robust notion of
intrinsic dimension, measured at only a single distance scale depending on the
regularization parameter, and show that it is only the minimum of these
single-scale intrinsic dimensions which governs the rate of convergence. We
call this the Minimum Intrinsic Dimension scaling (MID scaling) phenomenon, and
establish MID scaling with no assumptions on the data distributions so long as
the cost is bounded and Lipschitz, and for various entropic optimal transport
quantities beyond just values, with stronger analogs when one distribution is
supported on a manifold. Our results significantly advance the theoretical
state of the art by showing that MID scaling is a generic phenomenon, and
provide the first rigorous interpretation of the statistical effect of entropic
regularization as a distance scale.
\\ ( https://arxiv.org/abs/2306.03398 ,  46kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03402 (*cross-listing*)
Date: Tue, 6 Jun 2023 04:47:44 GMT   (602kb,D)

Title: Binary Classification with Instance and Label Dependent Label Noise
Authors: Hyungki Im and Paul Grigas
Categories: stat.ML cs.LG
\\
 Learning with label dependent label noise has been extensively explored in
both theory and practice; however, dealing with instance (i.e., feature) and
label dependent label noise continues to be a challenging task. The difficulty
arises from the fact that the noise rate varies for each instance, making it
challenging to estimate accurately. The question of whether it is possible to
learn a reliable model using only noisy samples remains unresolved. We answer
this question with a theoretical analysis that provides matching upper and
lower bounds. Surprisingly, our results show that, without any additional
assumptions, empirical risk minimization achieves the optimal excess risk
bound. Specifically, we derive a novel excess risk bound proportional to the
noise level, which holds in very general settings, by comparing the empirical
risk minimizers obtained from clean samples and noisy samples. Second, we show
that the minimax lower bound for the 0-1 loss is a constant proportional to the
average noise rate. Our findings suggest that learning solely with noisy
samples is impossible without access to clean samples or strong assumptions on
the distribution of the data.
\\ ( https://arxiv.org/abs/2306.03402 ,  602kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03436 (*cross-listing*)
Date: Tue, 6 Jun 2023 06:31:07 GMT   (291kb,D)

Title: Protecting the Intellectual Property of Diffusion Models by the
 Watermark Diffusion Process
Authors: Sen Peng, Yufei Chen, Cong Wang, Xiaohua Jia
Categories: cs.CR cs.LG
\\
 Diffusion models have emerged as state-of-the-art deep generative
architectures with the increasing demands for generation tasks. Training large
diffusion models for good performance requires high resource costs, making them
valuable intellectual properties to protect. While most of the existing
ownership solutions, including watermarking, mainly focus on discriminative
models. This paper proposes WDM, a novel watermarking method for diffusion
models, including watermark embedding, extraction, and verification. WDM embeds
the watermark data through training or fine-tuning the diffusion model to learn
a Watermark Diffusion Process (WDP), different from the standard diffusion
process for the task data. The embedded watermark can be extracted by sampling
using the shared reverse noise from the learned WDP without degrading
performance on the original task. We also provide theoretical foundations and
analysis of the proposed method by connecting the WDP to the diffusion process
with a modified Gaussian kernel. Extensive experiments are conducted to
demonstrate its effectiveness and robustness against various attacks.
\\ ( https://arxiv.org/abs/2306.03436 ,  291kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03466 (*cross-listing*)
Date: Tue, 6 Jun 2023 07:36:47 GMT   (2609kb,D)

Title: Convergent Bregman Plug-and-Play Image Restoration for Poisson Inverse
 Problems
Authors: Samuel Hurault, Ulugbek Kamilov, Arthur Leclaire, Nicolas Papadakis
Categories: eess.IV cs.LG math.OC
\\
 Plug-and-Play (PnP) methods are efficient iterative algorithms for solving
ill-posed image inverse problems. PnP methods are obtained by using deep
Gaussian denoisers instead of the proximal operator or the gradient-descent
step within proximal algorithms. Current PnP schemes rely on data-fidelity
terms that have either Lipschitz gradients or closed-form proximal operators,
which is not applicable to Poisson inverse problems. Based on the observation
that the Gaussian noise is not the adequate noise model in this setting, we
propose to generalize PnP using theBregman Proximal Gradient (BPG) method. BPG
replaces the Euclidean distance with a Bregman divergence that can better
capture the smoothness properties of the problem. We introduce the Bregman
Score Denoiser specifically parametrized and trained for the new Bregman
geometry and prove that it corresponds to the proximal operator of a nonconvex
potential. We propose two PnP algorithms based on the Bregman Score Denoiser
for solving Poisson inverse problems. Extending the convergence results of BPG
in the nonconvex settings, we show that the proposed methods converge,
targeting stationary points of an explicit global functional. Experimental
evaluations conducted on various Poisson inverse problems validate the
convergence results and showcase effective restoration performance.
\\ ( https://arxiv.org/abs/2306.03466 ,  2609kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03516 (*cross-listing*)
Date: Tue, 6 Jun 2023 09:08:40 GMT   (661kb,D)

Title: COPR: Consistency-Oriented Pre-Ranking for Online Advertising
Authors: Zhishan Zhao, Jingyue Gao, Yu Zhang, Shuguang Han, Siyuan Lou,
 Xiang-Rong Sheng, Zhe Wang, Han Zhu, Yuning Jiang, Jian Xu, Bo Zheng
Categories: cs.IR cs.LG
\\
 Cascading architecture has been widely adopted in large-scale advertising
systems to balance efficiency and effectiveness. In this architecture, the
pre-ranking model is expected to be a lightweight approximation of the ranking
model, which handles more candidates with strict latency requirements. Due to
the gap in model capacity, the pre-ranking and ranking models usually generate
inconsistent ranked results, thus hurting the overall system effectiveness. The
paradigm of score alignment is proposed to regularize their raw scores to be
consistent. However, it suffers from inevitable alignment errors and error
amplification by bids when applied in online advertising. To this end, we
introduce a consistency-oriented pre-ranking framework for online advertising,
which employs a chunk-based sampling module and a plug-and-play rank alignment
module to explicitly optimize consistency of ECPM-ranked results. A $\Delta
NDCG$-based weighting mechanism is adopted to better distinguish the importance
of inter-chunk samples in optimization. Both online and offline experiments
have validated the superiority of our framework. When deployed in Taobao
display advertising system, it achieves an improvement of up to +12.3\% CTR and
+5.6\% RPM.
\\ ( https://arxiv.org/abs/2306.03516 ,  661kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03527 (*cross-listing*)
Date: Tue, 6 Jun 2023 09:22:52 GMT   (2249kb,D)

Title: Rec4Ad: A Free Lunch to Mitigate Sample Selection Bias for Ads CTR
 Prediction in Taobao
Authors: Jingyue Gao, Shuguang Han, Han Zhu, Siran Yang, Yuning Jiang, Jian Xu,
 Bo Zheng
Categories: cs.IR cs.LG
\\
 Click-Through Rate (CTR) prediction serves as a fundamental component in
online advertising. A common practice is to train a CTR model on advertisement
(ad) impressions with user feedback. Since ad impressions are purposely
selected by the model itself, their distribution differs from the inference
distribution and thus exhibits sample selection bias (SSB) that affects model
performance. Existing studies on SSB mainly employ sample re-weighting
techniques which suffer from high variance and poor model calibration. Another
line of work relies on costly uniform data that is inadequate to train
industrial models. Thus mitigating SSB in industrial models with a
uniform-data-free framework is worth exploring. Fortunately, many platforms
display mixed results of organic items (i.e., recommendations) and sponsored
items (i.e., ads) to users, where impressions of ads and recommendations are
selected by different systems but share the same user decision rationales.
Based on the above characteristics, we propose to leverage recommendations
samples as a free lunch to mitigate SSB for ads CTR model (Rec4Ad). After
elaborating data augmentation, Rec4Ad learns disentangled representations with
alignment and decorrelation modules for enhancement. When deployed in Taobao
display advertising system, Rec4Ad achieves substantial gains in key business
metrics, with a lift of up to +6.6\% CTR and +2.9\% RPM.
\\ ( https://arxiv.org/abs/2306.03527 ,  2249kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03558 (*cross-listing*)
Date: Tue, 6 Jun 2023 10:18:36 GMT   (646kb,D)

Title: Machine Unlearning: A Survey
Authors: Heng Xu, Tianqing Zhu, Lefeng Zhang, Wanlei Zhou, Philip S. Yu
Categories: cs.CR cs.LG
\\
 Machine learning has attracted widespread attention and evolved into an
enabling technology for a wide range of highly successful applications, such as
intelligent computer vision, speech recognition, medical diagnosis, and more.
Yet a special need has arisen where, due to privacy, usability, and/or the
right to be forgotten, information about some specific samples needs to be
removed from a model, called machine unlearning. This emerging technology has
drawn significant interest from both academics and industry due to its
innovation and practicality. At the same time, this ambitious problem has led
to numerous research efforts aimed at confronting its challenges. To the best
of our knowledge, no study has analyzed this complex topic or compared the
feasibility of existing unlearning solutions in different kinds of scenarios.
Accordingly, with this survey, we aim to capture the key concepts of unlearning
techniques. The existing solutions are classified and summarized based on their
characteristics within an up-to-date and comprehensive review of each
category's advantages and limitations. The survey concludes by highlighting
some of the outstanding issues with unlearning techniques, along with some
feasible directions for new research opportunities.
\\ ( https://arxiv.org/abs/2306.03558 ,  646kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03607 (*cross-listing*)
Date: Tue, 6 Jun 2023 11:50:09 GMT   (52kb)

Title: Buying Information for Stochastic Optimization
Authors: Mingchen Ma and Christos Tzamos
Categories: cs.DS cs.LG
Comments: To appear in ICML 2023
\\
 Stochastic optimization is one of the central problems in Machine Learning
and Theoretical Computer Science. In the standard model, the algorithm is given
a fixed distribution known in advance. In practice though, one may acquire at a
cost extra information to make better decisions. In this paper, we study how to
buy information for stochastic optimization and formulate this question as an
online learning problem. Assuming the learner has an oracle for the original
optimization problem, we design a $2$-competitive deterministic algorithm and a
$e/(e-1)$-competitive randomized algorithm for buying information. We show that
this ratio is tight as the problem is equivalent to a robust generalization of
the ski-rental problem, which we call super-martingale stopping.
 We also consider an adaptive setting where the learner can choose to buy
information after taking some actions for the underlying optimization problem.
We focus on the classic optimization problem, Min-Sum Set Cover, where the goal
is to quickly find an action that covers a given request drawn from a known
distribution. We provide an $8$-competitive algorithm running in polynomial
time that chooses actions and decides when to buy information about the
underlying request.
\\ ( https://arxiv.org/abs/2306.03607 ,  52kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03623 (*cross-listing*)
Date: Tue, 6 Jun 2023 12:19:12 GMT   (2114kb,D)

Title: Spike-based computation using classical recurrent neural networks
Authors: Florent De Geeter (1), Damien Ernst (1), Guillaume Drion (1) ((1)
 Montefiore Institute, University of Li\`ege, Li\`ege, Belgium)
Categories: cs.NE cs.LG
Comments: 12 pages, 3 figures
\\
 Spiking neural networks are a type of artificial neural networks in which
communication between neurons is only made of events, also called spikes. This
property allows neural networks to make asynchronous and sparse computations
and therefore to drastically decrease energy consumption when run on
specialized hardware. However, training such networks is known to be difficult,
mainly due to the non-differentiability of the spike activation, which prevents
the use of classical backpropagation. This is because state-of-the-art spiking
neural networks are usually derived from biologically-inspired neuron models,
to which are applied machine learning methods for training. Nowadays, research
about spiking neural networks focuses on the design of training algorithms
whose goal is to obtain networks that compete with their non-spiking version on
specific tasks. In this paper, we attempt the symmetrical approach: we modify
the dynamics of a well-known, easily trainable type of recurrent neural network
to make it event-based. This new RNN cell, called the Spiking Recurrent Cell,
therefore communicates using events, i.e. spikes, while being completely
differentiable. Vanilla backpropagation can thus be used to train any network
made of such RNN cell. We show that this new network can achieve performance
comparable to other types of spiking networks in the MNIST benchmark and its
variants, the Fashion-MNIST and the Neuromorphic-MNIST. Moreover, we show that
this new cell makes the training of deep spiking networks achievable.
\\ ( https://arxiv.org/abs/2306.03623 ,  2114kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03625 (*cross-listing*)
Date: Tue, 6 Jun 2023 12:22:20 GMT   (780kb,D)

Title: Fair and Robust Estimation of Heterogeneous Treatment Effects for Policy
 Learning
Authors: Kwangho Kim and Jos\'e R. Zubizarreta
Categories: stat.ME cs.LG stat.ML
Journal-ref: Proceedings of the 40 th International Conference on Machine
 Learning, Honolulu, Hawaii, USA. PMLR 202, 2023
\\
 We propose a simple and general framework for nonparametric estimation of
heterogeneous treatment effects under fairness constraints. Under standard
regularity conditions, we show that the resulting estimators possess the double
robustness property. We use this framework to characterize the trade-off
between fairness and the maximum welfare achievable by the optimal policy. We
evaluate the methods in a simulation study and illustrate them in a real-world
case study.
\\ ( https://arxiv.org/abs/2306.03625 ,  780kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03718 (*cross-listing*)
Date: Tue, 6 Jun 2023 14:28:57 GMT   (2203kb,D)

Title: Emotion-Conditioned Melody Harmonization with Hierarchical Variational
 Autoencoder
Authors: Shulei Ji and Xinyu Yang
Categories: cs.SD cs.LG cs.MM eess.AS
Comments: Accepted by IEEE SMC 2023
\\
 Existing melody harmonization models have made great progress in improving
the quality of generated harmonies, but most of them ignored the emotions
beneath the music. Meanwhile, the variability of harmonies generated by
previous methods is insufficient. To solve these problems, we propose a novel
LSTM-based Hierarchical Variational Auto-Encoder (LHVAE) to investigate the
influence of emotional conditions on melody harmonization, while improving the
quality of generated harmonies and capturing the abundant variability of chord
progressions. Specifically, LHVAE incorporates latent variables and emotional
conditions at different levels (piece- and bar-level) to model the global and
local music properties. Additionally, we introduce an attention-based melody
context vector at each step to better learn the correspondence between melodies
and harmonies. Experimental results of the objective evaluation show that our
proposed model outperforms other LSTM-based models. Through subjective
evaluation, we conclude that only altering the chords hardly changes the
overall emotion of the music. The qualitative analysis demonstrates the ability
of our model to generate variable harmonies.
\\ ( https://arxiv.org/abs/2306.03718 ,  2203kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03741 (*cross-listing*)
Date: Thu, 18 May 2023 03:08:18 GMT   (1254kb,D)

Title: Pre-training Tensor-Train Networks Facilitates Machine Learning with
 Variational Quantum Circuits
Authors: Jun Qi, Chao-Han Huck Yang, Pin-Yu Chen, Min-Hsiu Hsieh
Categories: quant-ph cs.LG
Comments: 17 pages, 6 figures. In submission
\\
 Variational quantum circuit (VQC) is a promising approach for implementing
quantum neural networks on noisy intermediate-scale quantum (NISQ) devices.
Recent studies have shown that a tensor-train network (TTN) for VQC, namely
TTN-VQC, can improve the representation and generalization powers of VQC.
However, the Barren Plateau problem leads to the gradients of the cost function
vanishing exponentially small as the number of qubits increases, making it
difficult to find the optimal parameters for the VQC. To address this issue, we
put forth a new learning approach called Pre+TTN-VQC that builds upon the
TTN-VQC architecture by incorporating a pre-trained TTN to alleviate the Barren
Plateau problem. The pre-trained TTN allows for efficient fine-tuning of target
data, which reduces the depth of the VQC required to achieve good empirical
performance and potentially alleviates the training obstacles posed by the
Barren Plateau landscape. Furthermore, we highlight the advantages of
Pre+TTN-VQC in terms of representation and generalization powers by exploiting
the error performance analysis. Moreover, we characterize the optimization
performance of Pre+TTN-VQC without the need for the Polyak-Lojasiewicz
condition, thereby enhancing the practicality of implementing quantum neural
networks on NISQ devices. We conduct experiments on a handwritten digit
classification dataset to corroborate our proposed methods and theorems.
\\ ( https://arxiv.org/abs/2306.03741 ,  1254kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03773 (*cross-listing*)
Date: Thu, 1 Jun 2023 11:42:34 GMT   (309kb,D)

Title: Some voices are too common: Building fair speech recognition systems
 using the Common Voice dataset
Authors: Lucas Maison, Yannick Est\`eve
Categories: eess.AS cs.CL cs.LG cs.SD
Comments: 5 pages, 3 figures. Accepted to Interspeech 2023
\\
 Automatic speech recognition (ASR) systems become increasingly efficient
thanks to new advances in neural network training like self-supervised
learning. However, they are known to be unfair toward certain groups, for
instance, people speaking with an accent. In this work, we use the French
Common Voice dataset to quantify the biases of a pre-trained wav2vec~2.0 model
toward several demographic groups. By fine-tuning the pre-trained model on a
variety of fixed-size, carefully crafted training sets, we demonstrate the
importance of speaker diversity. We also run an in-depth analysis of the Common
Voice corpus and identify important shortcomings that should be taken into
account by users of this dataset.
\\ ( https://arxiv.org/abs/2306.03773 ,  309kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03783 (*cross-listing*)
Date: Tue, 6 Jun 2023 15:36:15 GMT   (186kb,D)

Title: Asymptotics of Bayesian Uncertainty Estimation in Random Features
 Regression
Authors: Youngsoo Baek, Samuel I. Berchuck, Sayan Mukherjee
Categories: stat.ML cs.LG
Comments: 11 pages, 3 figures
\\
 In this paper we compare and contrast the behavior of the posterior
predictive distribution to the risk of the maximum a posteriori estimator for
the random features regression model in the overparameterized regime. We will
focus on the variance of the posterior predictive distribution (Bayesian model
average) and compare its asymptotics to that of the risk of the MAP estimator.
In the regime where the model dimensions grow faster than any constant multiple
of the number of samples, asymptotic agreement between these two quantities is
governed by the phase transition in the signal-to-noise ratio. They also
asymptotically agree with each other when the number of samples grow faster
than any constant multiple of model dimensions. Numerical simulations
illustrate finer distributional properties of the two quantities for finite
dimensions. We conjecture they have Gaussian fluctuations and exhibit similar
properties as found by previous authors in a Gaussian sequence model, which is
of independent theoretical interest.
\\ ( https://arxiv.org/abs/2306.03783 ,  186kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03789 (*cross-listing*)
Date: Thu, 1 Jun 2023 21:31:00 GMT   (976kb,D)

Title: On the Robustness of Arabic Speech Dialect Identification
Authors: Peter Sullivan, AbdelRahim Elmadany, Muhammad Abdul-Mageed
Categories: eess.AS cs.CL cs.LG
\\
 Arabic dialect identification (ADI) tools are an important part of the
large-scale data collection pipelines necessary for training speech recognition
models. As these pipelines require application of ADI tools to potentially
out-of-domain data, we aim to investigate how vulnerable the tools may be to
this domain shift. With self-supervised learning (SSL) models as a starting
point, we evaluate transfer learning and direct classification from SSL
features. We undertake our evaluation under rich conditions, with a goal to
develop ADI systems from pretrained models and ultimately evaluate performance
on newly collected data. In order to understand what factors contribute to
model decisions, we carry out a careful human study of a subset of our data.
Our analysis confirms that domain shift is a major challenge for ADI models. We
also find that while self-training does alleviate this challenges, it may be
insufficient for realistic conditions.
\\ ( https://arxiv.org/abs/2306.03789 ,  976kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03887 (*cross-listing*)
Date: Tue, 6 Jun 2023 17:46:48 GMT   (1053kb,D)

Title: Fast Context Adaptation in Cost-Aware Continual Learning
Authors: Seyyidahmed Lahmer, Federico Mason, Federico Chiariotti, Andrea
 Zanella
Categories: cs.NI cs.LG
Comments: arXiv admin note: text overlap with arXiv:2211.16915
\\
 In the past few years, DRL has become a valuable solution to automatically
learn efficient resource management strategies in complex networks with
time-varying statistics. However, the increased complexity of 5G and Beyond
networks requires correspondingly more complex learning agents and the learning
process itself might end up competing with users for communication and
computational resources. This creates friction: on the one hand, the learning
process needs resources to quickly convergence to an effective strategy; on the
other hand, the learning process needs to be efficient, i.e., take as few
resources as possible from the user's data plane, so as not to throttle users'
QoS. In this paper, we investigate this trade-off and propose a dynamic
strategy to balance the resources assigned to the data plane and those reserved
for learning. With the proposed approach, a learning agent can quickly converge
to an efficient resource allocation strategy and adapt to changes in the
environment as for the CL paradigm, while minimizing the impact on the users'
QoS. Simulation results show that the proposed method outperforms static
allocation methods with minimal learning overhead, almost reaching the
performance of an ideal out-of-band CL solution.
\\ ( https://arxiv.org/abs/2306.03887 ,  1053kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03170 (*cross-listing*)
Date: Mon, 5 Jun 2023 18:24:50 GMT   (620kb)

Title: Segregated FLS Processing Cores for V/STOL Autonomous Landing Guidance
 Assistant System using FPGA
Authors: Hossam O. Ahmed
Categories: cs.DC cs.AR cs.RO
Comments: 2021 Integrated Communications Navigation and Surveillance Conference
 (ICNS), Dulles, VA, USA
DOI: 10.1109/ICNS52807.2021.9441573
\\
 It is highly predicted that the roads and parking areas will be extremely
congested with vehicles to the point that searching for a novel solution will
not be an optional choice for conserving the sustainability rate of the overall
humanity's development growth. Such issue could be overcome by developing
modified generations of the Urban Air Mobility (UAM) vehicles that essentially
depend on the Vertical and/or Short Take-Off and Landing (V/STOL) feature to
increase the efficiency of landing capabilities on limited-space parking areas.
The complexity of integrating an efficient and safe V/STOL feature in such UAM
vehicles is notably difficult comparing with the conventional and normal
techniques for landing and take-off. The efficient V/STOL feature should be
carried out by a complete and collaborative Cyber-Physical System (CPS)
processing architecture, such as the CPS-5C architecture. In this paper, we
only proposed two CPS-5C physical layers of a V/STOL Autonomous Landing
Guidance Assistant System (ALGAS2) processing unit to increase the reliability
of the vertical landing mechanism. The proposed V/STOL-ALGAS2 system depends on
Fuzzy Logic System (FLS) as the advanced control unit. Furthermore, the
proposed ALGAS2 system depends on four symmetric and segregated processing
ALGAS2 cores that processing the data in a fully parallel and independent
manner to enhance many essential security and safety factors for the futuristic
UAM vehicles. The proposed ALGAS2 digital circuits architecture has been
designed using MATLAB and VHDL. Also, it has been further analyzed for the
implementation and validation tests using the Intel Altera OpenVINO FPGA board.
The proposed ALGAS processing unit attained a maximum computational processing
performance of about 21.22 Giga Operations per Seconds (GOPS).
\\ ( https://arxiv.org/abs/2306.03170 ,  620kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03174 (*cross-listing*)
Date: Mon, 5 Jun 2023 18:29:00 GMT   (3361kb,D)

Title: Computational Design of Passive Grippers
Authors: Milin Kodnongbua, Ian Good Yu Lou, Jeffrey Lipton, Adriana Schulz
Categories: cs.GR cs.RO
Journal-ref: ACM Transactions on Graphics, Volume 41, Issue 4, July 2022,
 Article No.: 149, pp 2-12
DOI: 10.1145/3528223.3530162
\\
 This work proposes a novel generative design tool for passive grippers --
robot end effectors that have no additional actuation and instead leverage the
existing degrees of freedom in a robotic arm to perform grasping tasks. Passive
grippers are used because they offer interesting trade-offs between cost and
capabilities. However, existing designs are limited in the types of shapes that
can be grasped. This work proposes to use rapid-manufacturing and design
optimization to expand the space of shapes that can be passively grasped. Our
novel generative design algorithm takes in an object and its positioning with
respect to a robotic arm and generates a 3D printable passive gripper that can
stably pick the object up. To achieve this, we address the key challenge of
jointly optimizing the shape and the insert trajectory to ensure a passively
stable grasp. We evaluate our method on a testing suite of 22 objects (23
experiments), all of which were evaluated with physical experiments to bridge
the virtual-to-real gap. Code and data are at
https://homes.cs.washington.edu/~milink/passive-gripper/
\\ ( https://arxiv.org/abs/2306.03174 ,  3361kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03101 (*cross-listing*)
Date: Thu, 1 Jun 2023 18:32:03 GMT   (1024kb)

Title: Ten Steps to Becoming a Musculoskeletal Simulation Expert: A
 Half-Century of Progress and Outlook for the Future
Authors: Scott D. Uhlrich, Thomas K. Uchida, Marissa R. Lee and Scott L. Delp
Categories: cs.HC cs.SY eess.SY
Comments: 41 pages, 7 figures
Journal-ref: J. Biomech. 154 (2023) 111623
DOI: 10.1016/j.jbiomech.2023.111623
\\
 Over the past half-century, musculoskeletal simulations have deepened our
knowledge of human and animal movement. This article outlines ten steps to
becoming a musculoskeletal simulation expert so you can contribute to the next
half-century of technical innovation and scientific discovery. We advocate
looking to the past, present, and future to harness the power of simulations
that seek to understand and improve mobility. Instead of presenting a
comprehensive literature review, we articulate a set of ideas intended to help
researchers use simulations effectively and responsibly by understanding the
work on which today's musculoskeletal simulations are built, following
established modeling and simulation principles, and branching out in new
directions.
\\ ( https://arxiv.org/abs/2306.03101 ,  1024kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03394 (*cross-listing*)
Date: Tue, 6 Jun 2023 04:14:31 GMT   (17927kb,D)

Title: Predicting oscillations in relay feedback systems, using fixed points of
 Poincar\'e maps, and Hopf bifurcations
Authors: Maben Rabi
Categories: math.OC cs.SY eess.SY math.DS
Comments: submitted to the IEEE transactions on Automatic Control
\\
 The relay autotuning method identifies plant parameters, from oscillations of
the plant under relay feedback. To predict the presence and nature of such
oscillations, we apply the following two approaches: (a) analysis of the
switching dynamics, while using an ideal relay, and (b) bifurcation analysis,
while using a smooth approximation of the relay. For stable plants with
positive DC gains, our analyses predict that: (i) a periodic orbit is
guaranteed, for a class of non-minimum phase plants of relative degree one,
whose step response starts with an inverse response, and (ii) for a wider class
of plants, whose root locus diagrams cross the imaginary axis at complex
conjugate values, limit cycles are merely suggested.
\\ ( https://arxiv.org/abs/2306.03394 ,  17927kb)
%%--%%--%%--%%--%%--%%--%%--%%--%%--%%--%%--%%--%%--%%--%%--%%--%%--%%--%%--%%
------------------------------------------------------------------------------
\\
arXiv:2206.05731
replaced with revised version Tue, 6 Jun 2023 03:34:34 GMT   (4183kb,D)

Title: Human Mobility Prediction with Causal and Spatial-constrained Multi-task
 Network
Authors: Zongyuan Huang, Shengyuan Xu, Menghan Wang, Hansi Wu, Yanyan Xu,
 Yaohui Jin
Categories: cs.AI cs.IR
Comments: Updated version (We have corrected the title error in the previous
 version.)
\\ ( https://arxiv.org/abs/2206.05731 ,  4183kb)
------------------------------------------------------------------------------
\\
arXiv:2208.09951
replaced with revised version Tue, 6 Jun 2023 13:28:32 GMT   (38kb)

Title: Individual fairness under Varied Notions of Group Fairness in Bipartite
 Matching -- One Framework to Approximate Them Al
Authors: Atasi Panda, Anand Louis, Prajakta Nimbhorkar
Categories: cs.AI cs.DS
\\ ( https://arxiv.org/abs/2208.09951 ,  38kb)
------------------------------------------------------------------------------
\\
arXiv:2209.13873
replaced with revised version Tue, 6 Jun 2023 02:08:12 GMT   (3029kb,D)

Title: InFi: End-to-End Learning to Filter Input for Resource-Efficiency in
 Mobile-Centric Inference
Authors: Mu Yuan, Lan Zhang, Fengxiang He, Xueting Tong, Miao-Hui Song,
 Zhengyuan Xu, Xiang-Yang Li
Categories: cs.AI
Comments: 28th Annual International Conference on Mobile Computing And
 Networking (MobiCom '22)
\\ ( https://arxiv.org/abs/2209.13873 ,  3029kb)
------------------------------------------------------------------------------
\\
arXiv:2209.13883
replaced with revised version Tue, 6 Jun 2023 02:14:07 GMT   (3712kb,D)

Title: MLink: Linking Black-Box Models from Multiple Domains for Collaborative
 Inference
Authors: Mu Yuan, Lan Zhang, Zimu Zheng, Yi-Nan Zhang, Xiang-Yang Li
Categories: cs.AI
Comments: 36th AAAI Conference on Artificial Intelligence (AAAI '22)
\\ ( https://arxiv.org/abs/2209.13883 ,  3712kb)
------------------------------------------------------------------------------
\\
arXiv:2212.12139
replaced with revised version Tue, 6 Jun 2023 13:05:01 GMT   (3207kb,D)

Title: HiTSKT: A Hierarchical Transformer Model for Session-Aware Knowledge
 Tracing
Authors: Fucai Ke, Weiqing Wang, Weicong Tan, Lan Du, Yuan Jin, Yujin Huang and
 Hongzhi Yin
Categories: cs.AI
\\ ( https://arxiv.org/abs/2212.12139 ,  3207kb)
------------------------------------------------------------------------------
\\
arXiv:2303.02927
replaced with revised version Tue, 6 Jun 2023 01:21:41 GMT   (18007kb,D)

Title: LIDA: A Tool for Automatic Generation of Grammar-Agnostic Visualizations
 and Infographics using Large Language Models
Authors: Victor Dibia
Categories: cs.AI cs.HC cs.PL
Comments: Accepted at ACL 2023 (Demonstration track). Fix formatting issues,
 update information on evaluation metrics, prompts and project website
 (https://microsoft.github.io/lida/)
\\ ( https://arxiv.org/abs/2303.02927 ,  18007kb)
------------------------------------------------------------------------------
\\
arXiv:2303.10623
replaced with revised version Tue, 6 Jun 2023 11:29:51 GMT   (944kb,D)

Title: Active hypothesis testing in unknown environments using recurrent neural
 networks and model free reinforcement learning
Authors: George Stamatelis, Nicholas Kalouptsidis
Categories: cs.AI cs.IT math.IT
Comments: 5 pages, 6 tables
\\ ( https://arxiv.org/abs/2303.10623 ,  944kb)
------------------------------------------------------------------------------
\\
arXiv:2305.14019
replaced with revised version Mon, 5 Jun 2023 13:24:11 GMT   (2703kb,D)

Title: ChipGPT: How far are we from natural language hardware design
Authors: Kaiyan Chang
Categories: cs.AI cs.AR cs.PL
\\ ( https://arxiv.org/abs/2305.14019 ,  2703kb)
------------------------------------------------------------------------------
\\
arXiv:2306.01021
replaced with revised version Tue, 6 Jun 2023 08:50:50 GMT   (1541kb,D)

Title: A Virtual-Force Based Swarm Algorithm for Balanced Circular Bin Packing
 Problems
Authors: Juliette Gamot, Mathieu Balesdent, Romain Wuilbercq, Arnault Tremolet,
 Nouredine Melab, El-Ghazali Talbi
Categories: cs.AI cs.NE
Comments: 23 pages including references
\\ ( https://arxiv.org/abs/2306.01021 ,  1541kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02910
replaced with revised version Tue, 6 Jun 2023 11:41:31 GMT   (454kb,D)

Title: Action-Evolution Petri Nets: a Framework for Modeling and Solving
 Dynamic Task Assignment Problems
Authors: Riccardo Lo Bianco, Remco Dijkman, Wim Nuijten, Willem van Jaarsveld
Categories: cs.AI
\\ ( https://arxiv.org/abs/2306.02910 ,  454kb)
------------------------------------------------------------------------------
\\
arXiv:2007.06676
replaced with revised version Tue, 6 Jun 2023 14:26:28 GMT   (5978kb,D)

Title: UnRectDepthNet: Self-Supervised Monocular Depth Estimation using a
 Generic Framework for Handling Common Camera Distortion Models
Authors: Varun Ravi Kumar, Senthil Yogamani, Markus Bach, Christian Witt,
 Stefan Milz and Patrick Mader
Categories: cs.CV cs.LG cs.RO
Comments: Minor fixes added after IROS 2020 Camera ready submission. IROS 2020
 presentation video - https://www.youtube.com/watch?v=3Br2KSWZRrY
\\ ( https://arxiv.org/abs/2007.06676 ,  5978kb)
------------------------------------------------------------------------------
\\
arXiv:2102.07448
replaced with revised version Tue, 6 Jun 2023 14:31:21 GMT   (2166kb,D)

Title: OmniDet: Surround View Cameras based Multi-task Visual Perception
 Network for Autonomous Driving
Authors: Varun Ravi Kumar, Senthil Yogamani, Hazem Rashed, Ganesh Sistu,
 Christian Witt, Isabelle Leang, Stefan Milz and Patrick M\"ader
Categories: cs.CV cs.RO
Comments: Best Robot Vision paper award finalist (top 4). Camera ready version
 accepted for RA-L and ICRA 2021 publication
\\ ( https://arxiv.org/abs/2102.07448 ,  2166kb)
------------------------------------------------------------------------------
\\
arXiv:2103.17001
replaced with revised version Tue, 6 Jun 2023 15:25:08 GMT   (14990kb,D)

Title: Near-field Perception for Low-Speed Vehicle Automation using
 Surround-view Fisheye Cameras
Authors: Ciaran Eising, Jonathan Horgan and Senthil Yogamani
Categories: cs.CV cs.RO
Comments: Accepted for publication at IEEE Transactions on Intelligent
 Transportation Systems
\\ ( https://arxiv.org/abs/2103.17001 ,  14990kb)
------------------------------------------------------------------------------
\\
arXiv:2205.08209
replaced with revised version Tue, 6 Jun 2023 17:54:34 GMT   (17247kb,D)

Title: blob loss: instance imbalance aware loss functions for semantic
 segmentation
Authors: Florian Kofler, Suprosanna Shit, Ivan Ezhov, Lucas Fidon, Izabela
 Horvath, Rami Al-Maskari, Hongwei Li, Harsharan Bhatia, Timo Loehr, Marie
 Piraud, Ali Erturk, Jan Kirschke, Jan C. Peeken, Tom Vercauteren, Claus
 Zimmer, Benedikt Wiestler, Bjoern Menze
Categories: cs.CV cs.LG eess.IV
Comments: 23 pages, 7 figures // corrected one mistake where it said beta
 instead of alpha in the text
\\ ( https://arxiv.org/abs/2205.08209 ,  17247kb)
------------------------------------------------------------------------------
\\
arXiv:2206.09959
replaced with revised version Tue, 6 Jun 2023 08:17:18 GMT   (1786kb,D)

Title: Global Context Vision Transformers
Authors: Ali Hatamizadeh, Hongxu Yin, Greg Heinrich, Jan Kautz, and Pavlo
 Molchanov
Categories: cs.CV cs.AI cs.LG
Comments: Accepted to ICML 2023
\\ ( https://arxiv.org/abs/2206.09959 ,  1786kb)
------------------------------------------------------------------------------
\\
arXiv:2207.03132
replaced with revised version Tue, 6 Jun 2023 06:54:15 GMT   (3420kb,D)

Title: Style Interleaved Learning for Generalizable Person Re-identification
Authors: Wentao Tan and Changxing Ding and Pengfei Wang and Mingming Gong and
 Kui Jia
Categories: cs.CV
\\ ( https://arxiv.org/abs/2207.03132 ,  3420kb)
------------------------------------------------------------------------------
\\
arXiv:2209.05044
replaced with revised version Tue, 6 Jun 2023 05:38:02 GMT   (1560kb,D)

Title: Predicting the Next Action by Modeling the Abstract Goal
Authors: Debaditya Roy and Basura Fernando
Categories: cs.CV cs.AI
Comments: This work has been submitted to the IEEE for possible publication.
 Copyright may be transferred without notice, after which this version may no
 longer be accessible
\\ ( https://arxiv.org/abs/2209.05044 ,  1560kb)
------------------------------------------------------------------------------
\\
arXiv:2209.11355
replaced with revised version Tue, 6 Jun 2023 13:39:49 GMT   (18154kb,D)

Title: Learning to predict 3D rotational dynamics from images of a rigid body
 with unknown mass distribution
Authors: Justice Mason and Christine Allen-Blanchette and Nicholas Zolman and
 Elizabeth Davison and Naomi Leonard
Categories: cs.CV cs.AI cs.LG
Comments: 21 pages, 9 figures
\\ ( https://arxiv.org/abs/2209.11355 ,  18154kb)
------------------------------------------------------------------------------
\\
arXiv:2209.15404
replaced with revised version Tue, 6 Jun 2023 07:23:21 GMT   (31341kb,D)

Title: Entropy-driven Unsupervised Keypoint Representation Learning in Videos
Authors: Ali Younes, Simone Schaub-Meyer, Georgia Chalvatzaki
Categories: cs.CV cs.LG
Comments: 29 pages, 14 figures, Accepted at ICML 2023
\\ ( https://arxiv.org/abs/2209.15404 ,  31341kb)
------------------------------------------------------------------------------
\\
arXiv:2210.00586
replaced with revised version Mon, 5 Jun 2023 20:25:22 GMT   (3622kb,D)

Title: Generated Faces in the Wild: Quantitative Comparison of Stable
 Diffusion, Midjourney and DALL-E 2
Authors: Ali Borji
Categories: cs.CV
Comments: dataset link udated!
\\ ( https://arxiv.org/abs/2210.00586 ,  3622kb)
------------------------------------------------------------------------------
\\
arXiv:2211.12561
replaced with revised version Tue, 6 Jun 2023 00:28:34 GMT   (10040kb,D)

Title: Retrieval-Augmented Multimodal Language Modeling
Authors: Michihiro Yasunaga, Armen Aghajanyan, Weijia Shi, Rich James, Jure
 Leskovec, Percy Liang, Mike Lewis, Luke Zettlemoyer, Wen-tau Yih
Categories: cs.CV cs.CL cs.LG
Comments: Published at ICML 2023. Blog post available at
 https://cs.stanford.edu/~myasu/blog/racm3/
\\ ( https://arxiv.org/abs/2211.12561 ,  10040kb)
------------------------------------------------------------------------------
\\
arXiv:2211.14154
replaced with revised version Tue, 6 Jun 2023 05:38:58 GMT   (22810kb,D)

Title: Interaction Visual Transformer for Egocentric Action Anticipation
Authors: Debaditya Roy, Ramanathan Rajendiran and Basura Fernando
Categories: cs.CV
Comments: fixed affliation
\\ ( https://arxiv.org/abs/2211.14154 ,  22810kb)
------------------------------------------------------------------------------
\\
arXiv:2212.10015
replaced with revised version Tue, 6 Jun 2023 08:08:29 GMT   (5459kb,D)

Title: Benchmarking Spatial Relationships in Text-to-Image Generation
Authors: Tejas Gokhale, Hamid Palangi, Besmira Nushi, Vibhav Vineet, Eric
 Horvitz, Ece Kamar, Chitta Baral, Yezhou Yang
Categories: cs.CV cs.AI cs.CL
Comments: preprint; Code and Data at https://github.com/microsoft/VISOR and
 https://huggingface.co/datasets/tgokhale/sr2d_visor
\\ ( https://arxiv.org/abs/2212.10015 ,  5459kb)
------------------------------------------------------------------------------
\\
arXiv:2212.10431
replaced with revised version Mon, 5 Jun 2023 20:20:08 GMT   (15770kb,D)

Title: QuantArt: Quantizing Image Style Transfer Towards High Visual Fidelity
Authors: Siyu Huang, Jie An, Donglai Wei, Jiebo Luo, Hanspeter Pfister
Categories: cs.CV cs.LG cs.MM eess.IV
Comments: Accepted to CVPR 2023. Code is available at
 https://github.com/siyuhuang/QuantArt
\\ ( https://arxiv.org/abs/2212.10431 ,  15770kb)
------------------------------------------------------------------------------
\\
arXiv:2302.04578
replaced with revised version Tue, 6 Jun 2023 06:34:46 GMT   (10067kb,D)

Title: Adversarial Example Does Good: Preventing Painting Imitation from
 Diffusion Models via Adversarial Examples
Authors: Chumeng Liang, Xiaoyu Wu, Yang Hua, Jiaru Zhang, Yiming Xue, Tao Song,
 Zhengui Xue, Ruhui Ma, Haibing Guan
Categories: cs.CV cs.AI cs.CR cs.LG
Comments: Accepted by ICML2023 (Oral)
\\ ( https://arxiv.org/abs/2302.04578 ,  10067kb)
------------------------------------------------------------------------------
\\
arXiv:2302.10586
replaced with revised version Tue, 6 Jun 2023 11:53:03 GMT   (38705kb,D)

Title: Diffusion Models and Semi-Supervised Learners Benefit Mutually with Few
 Labels
Authors: Zebin You, Yong Zhong, Fan Bao, Jiacheng Sun, Chongxuan Li, Jun Zhu
Categories: cs.CV cs.AI cs.LG
\\ ( https://arxiv.org/abs/2302.10586 ,  38705kb)
------------------------------------------------------------------------------
\\
arXiv:2303.13190
replaced with revised version Tue, 6 Jun 2023 03:21:47 GMT   (8281kb,D)

Title: Marching-Primitives: Shape Abstraction from Signed Distance Function
Authors: Weixiao Liu, Yuwei Wu, Sipu Ruan, Gregory S. Chirikjian
Categories: cs.CV
Comments: Accepted to CVPR2023 Highlight
\\ ( https://arxiv.org/abs/2303.13190 ,  8281kb)
------------------------------------------------------------------------------
\\
arXiv:2303.13434
replaced with revised version Tue, 6 Jun 2023 04:43:11 GMT   (11723kb,D)

Title: Patch-Mix Transformer for Unsupervised Domain Adaptation: A Game
 Perspective
Authors: Jinjing Zhu, Haotian Bai, Lin Wang
Categories: cs.CV
Comments: Accepted by CVPR 2023 (Highlight)
\\ ( https://arxiv.org/abs/2303.13434 ,  11723kb)
------------------------------------------------------------------------------
\\
arXiv:2304.04874
replaced with revised version Mon, 5 Jun 2023 22:06:07 GMT   (22990kb,D)

Title: ImageCaptioner$^2$: Image Captioner for Image Captioning Bias
 Amplification Assessment
Authors: Eslam Mohamed Bakr, Pengzhan Sun, Li Erran Li, Mohamed Elhoseiny
Categories: cs.CV cs.AI cs.LG
\\ ( https://arxiv.org/abs/2304.04874 ,  22990kb)
------------------------------------------------------------------------------
\\
arXiv:2304.06447
replaced with revised version Tue, 6 Jun 2023 02:26:42 GMT   (7072kb,D)

Title: PDFVQA: A New Dataset for Real-World VQA on PDF Documents
Authors: Yihao Ding, Siwen Luo, Hyunsuk Chung, Soyeon Caren Han
Categories: cs.CV cs.CL
Comments: Accepted by ECML-PKDD 2023
\\ ( https://arxiv.org/abs/2304.06447 ,  7072kb)
------------------------------------------------------------------------------
\\
arXiv:2304.09172
replaced with revised version Tue, 6 Jun 2023 00:33:42 GMT   (4887kb,D)

Title: Hyperbolic Image-Text Representations
Authors: Karan Desai, Maximilian Nickel, Tanmay Rajpurohit, Justin Johnson,
 Ramakrishna Vedantam
Categories: cs.CV cs.LG
Comments: ICML 2023
\\ ( https://arxiv.org/abs/2304.09172 ,  4887kb)
------------------------------------------------------------------------------
\\
arXiv:2304.10226
replaced with revised version Tue, 6 Jun 2023 15:25:37 GMT   (12089kb,D)

Title: Domain Generalization for Mammographic Image Analysis via Contrastive
 Learning
Authors: Zheren Li, Zhiming Cui, Lichi Zhang, Sheng Wang, Chenjin Lei, Xi
 Ouyang, Dongdong Chen, Xiangyu Zhao, Yajia Gu, Zaiyi Liu, Chunling Liu,
 Dinggang Shen, Jie-Zhi Cheng
Categories: cs.CV cs.LG
Comments: arXiv admin note: text overlap with arXiv:2111.10827
\\ ( https://arxiv.org/abs/2304.10226 ,  12089kb)
------------------------------------------------------------------------------
\\
arXiv:2304.11966
replaced with revised version Mon, 5 Jun 2023 21:56:29 GMT   (1233kb,D)

Title: ICDAR 2023 Competition on Reading the Seal Title
Authors: Wenwen Yu, Mingyu Liu, Mingrui Chen, Ning Lu, Yinlong Wen, Yuliang
 Liu, Dimosthenis Karatzas, Xiang Bai
Categories: cs.CV
Comments: ICDAR2023 Competition on ReST report (To be appear in ICDAR 2023)
\\ ( https://arxiv.org/abs/2304.11966 ,  1233kb)
------------------------------------------------------------------------------
\\
arXiv:2305.04379
replaced with revised version Tue, 6 Jun 2023 07:33:13 GMT   (1641kb,D)

Title: Data Efficient Training with Imbalanced Label Sample Distribution for
 Fashion Detection
Authors: Xin Shen, Praful Agrawal, Zhongwei Cheng
Categories: cs.CV cs.AI
Comments: We have identified a substantial error in the experimental results
 and a potentially misleading explanation of the algorithm. We kindly request
 that you consider withdrawing this version to mitigate the risk of
 disseminating inaccurate information
\\ ( https://arxiv.org/abs/2305.04379 ,  1641kb)
------------------------------------------------------------------------------
\\
arXiv:2305.05222
replaced with revised version Tue, 6 Jun 2023 07:41:48 GMT   (9374kb,D)

Title: FishRecGAN: An End to End GAN Based Network for Fisheye Rectification
 and Calibration
Authors: Xin Shen, Kyungdon Joo, Jean Oh
Categories: cs.CV cs.AI
\\ ( https://arxiv.org/abs/2305.05222 ,  9374kb)
------------------------------------------------------------------------------
\\
arXiv:2305.05228
replaced with revised version Mon, 5 Jun 2023 21:30:25 GMT   (5241kb,D)

Title: Semantic Embedded Deep Neural Network: A Generic Approach to Boost
 Multi-Label Image Classification Performance
Authors: Xin Shen, Xiaonan Zhao, Rui Luo
Categories: cs.CV cs.AI cs.RO
\\ ( https://arxiv.org/abs/2305.05228 ,  5241kb)
------------------------------------------------------------------------------
\\
arXiv:2305.07598
replaced with revised version Tue, 6 Jun 2023 09:06:28 GMT   (37980kb,D)

Title: RHINO: Rotated DETR with Dynamic Denoising via Hungarian Matching for
 Oriented Object Detection
Authors: Hakjin Lee, Minki Song, Jamyoung Koo, Junghoon Seo
Categories: cs.CV cs.LG
Comments: State-of-the-art rotated object detector in DOTA v1.0/v1.5/v2.0 and
 DIOR-R at the time of publication
\\ ( https://arxiv.org/abs/2305.07598 ,  37980kb)
------------------------------------------------------------------------------
\\
arXiv:2305.10071
replaced with revised version Tue, 6 Jun 2023 07:31:15 GMT   (11150kb,D)

Title: Cold PAWS: Unsupervised class discovery and addressing the cold-start
 problem for semi-supervised learning
Authors: Evelyn J. Mannix, Howard D. Bondell
Categories: cs.CV cs.AI cs.LG
\\ ( https://arxiv.org/abs/2305.10071 ,  11150kb)
------------------------------------------------------------------------------
\\
arXiv:2305.10118
replaced with revised version Tue, 6 Jun 2023 16:13:53 GMT   (1030kb,D)

Title: Bridging the Gap: Enhancing the Utility of Synthetic Data via
 Post-Processing Techniques
Authors: Andrea Lampis, Eugenio Lomurno, Matteo Matteucci
Categories: cs.CV cs.AI cs.LG
\\ ( https://arxiv.org/abs/2305.10118 ,  1030kb)
------------------------------------------------------------------------------
\\
arXiv:2305.12635
replaced with revised version Tue, 6 Jun 2023 12:17:15 GMT   (19055kb,D)

Title: A bioinspired three-stage model for camouflaged object detection
Authors: Tianyou Chen, Jin Xiao, Xiaoguang Hu, Guofeng Zhang, Shaojie Wang
Categories: cs.CV
\\ ( https://arxiv.org/abs/2305.12635 ,  19055kb)
------------------------------------------------------------------------------
\\
arXiv:2305.13563
replaced with revised version Tue, 6 Jun 2023 10:07:05 GMT   (321kb)

Title: Efficient Multi-Scale Attention Module with Cross-Spatial Learning
Authors: Daliang Ouyang, Su He, Guozhong Zhang, Mingzhu Luo, Huaiyong Guo, Jian
 Zhan, Zhijie Huang
Categories: cs.CV cs.AI
Comments: Accepted to ICASSP2023
Report-no: originally announced March 2023
DOI: 10.1109/ICASSP49357.2023.10096516
\\ ( https://arxiv.org/abs/2305.13563 ,  321kb)
------------------------------------------------------------------------------
\\
arXiv:2305.14849
replaced with revised version Tue, 6 Jun 2023 06:35:25 GMT   (34162kb,D)

Title: DuDGAN: Improving Class-Conditional GANs via Dual-Diffusion
Authors: Taesun Yeom, Minhyeok Lee
Categories: cs.CV eess.IV
Comments: 8 page, 3 figures, supplementary material included
\\ ( https://arxiv.org/abs/2305.14849 ,  34162kb)
------------------------------------------------------------------------------
\\
arXiv:2305.16914
replaced with revised version Tue, 6 Jun 2023 10:01:48 GMT   (43587kb,D)

Title: PlaNeRF: SVD Unsupervised 3D Plane Regularization for NeRF Large-Scale
 Scene Reconstruction
Authors: Fusang Wang, Arnaud Louys, Nathan Piasco, Moussab Bennehar, Luis
 Rold\~ao, Dzmitry Tsishkou
Categories: cs.CV cs.LG
Comments: 14 pages, 7 figures
MSC-class: I.4.5, I.2.10
\\ ( https://arxiv.org/abs/2305.16914 ,  43587kb)
------------------------------------------------------------------------------
\\
arXiv:2305.17449
replaced with revised version Tue, 6 Jun 2023 07:02:32 GMT   (10957kb)

Title: FishEye8K: A Benchmark and Dataset for Fisheye Camera Object Detection
Authors: Munkhjargal Gochoo, Munkh-Erdene Otgonbold, Erkhembayar Ganbold,
 Jun-Wei Hsieh, Ming-Ching Chang, Ping-Yang Chen, Byambaa Dorj, Hamad Al
 Jassmi, Ganzorig Batnasan, Fady Alnajjar, Mohammed Abduljabbar, Fang-Pang Lin
Categories: cs.CV
Comments: CVPR Workshops 2023
\\ ( https://arxiv.org/abs/2305.17449 ,  10957kb)
------------------------------------------------------------------------------
\\
arXiv:2305.17716
replaced with revised version Mon, 5 Jun 2023 22:52:57 GMT   (174kb,D)

Title: InDL: A New Dataset and Benchmark for In-Diagram Logic Interpretation
 based on Visual Illusion
Authors: Haobo Yang, Wenyu Wang, Ze Cao, Zhekai Duan, Xuchen Liu
Categories: cs.CV cs.AI
Comments: arXiv admin note: text overlap with arXiv:2305.02299,
 arXiv:2302.11939, arXiv:2301.13287, arXiv:2305.12686
\\ ( https://arxiv.org/abs/2305.17716 ,  174kb)
------------------------------------------------------------------------------
\\
arXiv:2306.00966
replaced with revised version Tue, 6 Jun 2023 13:16:43 GMT   (18802kb,D)

Title: The Hidden Language of Diffusion Models
Authors: Hila Chefer, Oran Lang, Mor Geva, Volodymyr Polosukhin, Assaf Shocher,
 Michal Irani, Inbar Mosseri, Lior Wolf
Categories: cs.CV
\\ ( https://arxiv.org/abs/2306.00966 ,  18802kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02018
replaced with revised version Tue, 6 Jun 2023 03:54:10 GMT   (37962kb,D)

Title: VideoComposer: Compositional Video Synthesis with Motion Controllability
Authors: Xiang Wang, Hangjie Yuan, Shiwei Zhang, Dayou Chen, Jiuniu Wang,
 Yingya Zhang, Yujun Shen, Deli Zhao, Jingren Zhou
Categories: cs.CV
Comments: The first four authors contributed equally. Project page:
 https://videocomposer.github.io
\\ ( https://arxiv.org/abs/2306.02018 ,  37962kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02291
replaced with revised version Tue, 6 Jun 2023 01:49:09 GMT   (194kb,D)

Title: 3rd Place Solution for PVUW2023 VSS Track: A Large Model for Semantic
 Segmentation on VSPW
Authors: Shijie Chang, Zeqi Hao, Ben Kang, Xiaoqi Zhao, Jiawen Zhu, Zhenyu
 Chen, Lihe Zhang, Lu Zhang, Huchuan Lu
Categories: cs.CV
Comments: 3rd Place Solution for CVPR 2023 PVUW VSS Track
\\ ( https://arxiv.org/abs/2306.02291 ,  194kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02416
replaced with revised version Tue, 6 Jun 2023 02:00:27 GMT   (4381kb,D)

Title: Training Like a Medical Resident: Universal Medical Image Segmentation
 via Context Prior Learning
Authors: Yunhe Gao, Zhuowei Li, Di Liu, Mu Zhou, Shaoting Zhang, Dimitris N.
 Metaxas
Categories: cs.CV
\\ ( https://arxiv.org/abs/2306.02416 ,  4381kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02548
replaced with revised version Tue, 6 Jun 2023 08:55:47 GMT   (7608kb,D)

Title: Inflated 3D Convolution-Transformer for Weakly-supervised Carotid
 Stenosis Grading with Ultrasound Videos
Authors: Xinrui Zhou, Yuhao Huang, Wufeng Xue, Xin Yang, Yuxin Zou, Qilong
 Ying, Yuanji Zhang, Jia Liu, Jie Ren, Dong Ni
Categories: cs.CV
Comments: Accepted by MICCAI 2023
\\ ( https://arxiv.org/abs/2306.02548 ,  7608kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02583
replaced with revised version Tue, 6 Jun 2023 04:28:17 GMT   (47247kb,D)

Title: Stable Diffusion is Unstable
Authors: Chengbin Du, Yanxi Li, Zhongwei Qiu, Chang Xu
Categories: cs.CV
Comments: 22 pages, 20 figures
\\ ( https://arxiv.org/abs/2306.02583 ,  47247kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02644
replaced with revised version Tue, 6 Jun 2023 01:52:18 GMT   (2829kb,D)

Title: Learned Alternating Minimization Algorithm for Dual-domain Sparse-View
 CT Reconstruction
Authors: Chi Ding, Qingchao Zhang, Ge Wang, Xiaojing Ye and Yunmei Chen
Categories: cs.CV
\\ ( https://arxiv.org/abs/2306.02644 ,  2829kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02744
replaced with revised version Tue, 6 Jun 2023 04:30:41 GMT   (33320kb,D)

Title: Towards Better Explanations for Object Detection
Authors: Van Binh Truong, Truong Thanh Hung Nguyen, Vo Thanh Khang Nguyen, Quoc
 Khanh Nguyen, Quoc Hung Cao
Categories: cs.CV cs.AI cs.LG
Comments: 9 pages, 10 figures
\\ ( https://arxiv.org/abs/2306.02744 ,  33320kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02851
replaced with revised version Tue, 6 Jun 2023 12:57:11 GMT   (15847kb,D)

Title: Scene as Occupancy
Authors: Wenwen Tong, Chonghao Sima, Tai Wang, Silei Wu, Hanming Deng, Li Chen,
 Yi Gu, Lewei Lu, Ping Luo, Dahua Lin, Hongyang Li
Categories: cs.CV cs.RO
\\ ( https://arxiv.org/abs/2306.02851 ,  15847kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02898
replaced with revised version Tue, 6 Jun 2023 06:42:56 GMT   (5178kb,D)

Title: Towards Unified Text-based Person Retrieval: A Large-scale
 Multi-Attribute and Language Search Benchmark
Authors: Shuyu Yang, Yinan Zhou, Yaxiong Wang, Yujiao Wu, Li Zhu, Zhedong Zheng
Categories: cs.CV cs.MM
\\ ( https://arxiv.org/abs/2306.02898 ,  5178kb)
------------------------------------------------------------------------------
\\
arXiv:2301.09159
replaced with revised version Tue, 6 Jun 2023 01:26:18 GMT   (617kb,D)

Title: Abstracting Imperfect Information Away from Two-Player Zero-Sum Games
Authors: Samuel Sokota, Ryan D'Orazio, Chun Kai Ling, David J. Wu, J. Zico
 Kolter, Noam Brown
Categories: cs.GT cs.AI cs.LG
\\ ( https://arxiv.org/abs/2301.09159 ,  617kb)
------------------------------------------------------------------------------
\\
arXiv:2305.11866
replaced with revised version Tue, 6 Jun 2023 01:10:35 GMT   (1795kb,D)

Title: Consistent Conjectural Variations Equilibrium: Characterization &
 Stability for a Class of Continuous Games
Authors: Daniel J. Calderone, Benjamin J. Chasnov, Samuel A. Burden, Lillian J.
 Ratliff
Categories: cs.GT
\\ ( https://arxiv.org/abs/2305.11866 ,  1795kb)
------------------------------------------------------------------------------
\\
arXiv:1606.08415
replaced with revised version Tue, 6 Jun 2023 01:53:32 GMT   (3016kb,D)

Title: Gaussian Error Linear Units (GELUs)
Authors: Dan Hendrycks and Kevin Gimpel
Categories: cs.LG
Comments: Trimmed version of 2016 draft
\\ ( https://arxiv.org/abs/1606.08415 ,  3016kb)
------------------------------------------------------------------------------
\\
arXiv:1902.00778
replaced with revised version Tue, 6 Jun 2023 15:52:30 GMT   (7095kb,D)

Title: Certified Reinforcement Learning with Logic Guidance
Authors: Hosein Hasanbeig, Daniel Kroening, Alessandro Abate
Categories: cs.LG stat.ML
\\ ( https://arxiv.org/abs/1902.00778 ,  7095kb)
------------------------------------------------------------------------------
\\
arXiv:2007.15353
replaced with revised version Tue, 6 Jun 2023 03:20:50 GMT   (2954kb,D)

Title: Growing Efficient Deep Networks by Structured Continuous Sparsification
Authors: Xin Yuan, Pedro Savarese, Michael Maire
Categories: cs.LG stat.ML
Comments: Published as a conference paper at ICLR 2021
\\ ( https://arxiv.org/abs/2007.15353 ,  2954kb)
------------------------------------------------------------------------------
\\
arXiv:2101.12588
replaced with revised version Tue, 6 Jun 2023 14:06:09 GMT   (7377kb,D)

Title: No-Regret Caching via Online Mirror Descent
Authors: T. Si Salem, G. Neglia and S. Ioannidis
Categories: cs.LG cs.NI cs.PF
\\ ( https://arxiv.org/abs/2101.12588 ,  7377kb)
------------------------------------------------------------------------------
\\
arXiv:2112.14869
replaced with revised version Tue, 6 Jun 2023 05:29:54 GMT   (1917kb,D)

Title: Label Distributionally Robust Losses for Multi-class Classification:
 Consistency, Robustness and Adaptivity
Authors: Dixian Zhu, Yiming Ying and Tianbao Yang
Categories: cs.LG
Comments: To appear in ICML2023; 37 pages
\\ ( https://arxiv.org/abs/2112.14869 ,  1917kb)
------------------------------------------------------------------------------
\\
arXiv:2201.12658
replaced with revised version Tue, 6 Jun 2023 01:35:13 GMT   (2489kb,D)

Title: Learning Intuitive Policies Using Action Features
Authors: Mingwei Ma, Jizhou Liu, Samuel Sokota, Max Kleiman-Weiner, Jakob
 Foerster
Categories: cs.LG cs.AI cs.MA
Comments: ICML 2023
\\ ( https://arxiv.org/abs/2201.12658 ,  2489kb)
------------------------------------------------------------------------------
\\
arXiv:2201.13387
replaced with revised version Tue, 6 Jun 2023 02:59:25 GMT   (24285kb,D)

Title: L-SVRG and L-Katyusha with Adaptive Sampling
Authors: Boxin Zhao, Boxiang Lyu, Mladen Kolar
Categories: cs.LG math.OC
Comments: Published in Transactions on Machine Learning Research (03/2023)
\\ ( https://arxiv.org/abs/2201.13387 ,  24285kb)
------------------------------------------------------------------------------
\\
arXiv:2202.05535
replaced with revised version Mon, 5 Jun 2023 20:52:32 GMT   (702kb,D)

Title: A Lightweight, Efficient and Explainable-by-Design Convolutional Neural
 Network for Internet Traffic Classification
Authors: Kevin Fauvel, Fuxing Chen, Dario Rossi
Categories: cs.LG
Comments: Accepted for publication in the 29th ACM SIGKDD Conference on
 Knowledge Discovery and Data Mining, Long Beach, USA, 2023
\\ ( https://arxiv.org/abs/2202.05535 ,  702kb)
------------------------------------------------------------------------------
\\
arXiv:2203.02586
replaced with revised version Tue, 6 Jun 2023 17:17:15 GMT   (21116kb,D)

Title: Concept-based Explanations for Out-Of-Distribution Detectors
Authors: Jihye Choi, Jayaram Raghuram, Ryan Feng, Jiefeng Chen, Somesh Jha,
 Atul Prakash
Categories: cs.LG cs.CV
Comments: Paper published at International Conference on Machine Learning
 (ICML'23)
\\ ( https://arxiv.org/abs/2203.02586 ,  21116kb)
------------------------------------------------------------------------------
\\
arXiv:2205.10752
replaced with revised version Tue, 6 Jun 2023 00:16:23 GMT   (21262kb,D)

Title: Covariance Matrix Adaptation MAP-Annealing
Authors: Matthew C. Fontaine, Stefanos Nikolaidis
Categories: cs.LG cs.AI
Comments: Accepted to GECCO 2023
\\ ( https://arxiv.org/abs/2205.10752 ,  21262kb)
------------------------------------------------------------------------------
\\
arXiv:2206.01132
replaced with revised version Tue, 6 Jun 2023 16:17:23 GMT   (90kb)

Title: A Communication-efficient Algorithm with Linear Convergence for
 Federated Minimax Learning
Authors: Zhenyu Sun, Ermin Wei
Categories: cs.LG cs.DC
Comments: Accepted by NeurIPS 2022
\\ ( https://arxiv.org/abs/2206.01132 ,  90kb)
------------------------------------------------------------------------------
\\
arXiv:2206.04285
replaced with revised version Tue, 6 Jun 2023 12:38:45 GMT   (3134kb,D)

Title: A Unification Framework for Euclidean and Hyperbolic Graph Neural
 Networks
Authors: Mehrdad Khatir, Nurendra Choudhary, Sutanay Choudhury, Khushbu
 Agarwal, Chandan K. Reddy
Categories: cs.LG cs.NE
\\ ( https://arxiv.org/abs/2206.04285 ,  3134kb)
------------------------------------------------------------------------------
\\
arXiv:2206.04882
replaced with revised version Mon, 5 Jun 2023 20:58:47 GMT   (16773kb,D)

Title: $\mathsf{G^2Retro}$ as a Two-Step Graph Generative Models for
 Retrosynthesis Prediction
Authors: Ziqi Chen, Oluwatosin R. Ayinde, James R. Fuchs, Huan Sun, Xia Ning
Categories: cs.LG physics.chem-ph q-bio.BM
Journal-ref: Commun Chem 6, 102 (2023)
DOI: 10.1038/s42004-023-00897-3
\\ ( https://arxiv.org/abs/2206.04882 ,  16773kb)
------------------------------------------------------------------------------
\\
arXiv:2206.08451
replaced with revised version Tue, 6 Jun 2023 09:52:41 GMT   (3195kb,D)

Title: I Know What You Trained Last Summer: A Survey on Stealing Machine
 Learning Models and Defences
Authors: Daryna Oliynyk, Rudolf Mayer, Andreas Rauber
Categories: cs.LG cs.AI cs.CR
Comments: Accepted at ACM Computing Surveys, 2023:
 https://doi.org/10.1145/3595292
ACM-class: I.2
Journal-ref: ACM Computing Surveys, 2023
DOI: 10.1145/3595292
\\ ( https://arxiv.org/abs/2206.08451 ,  3195kb)
------------------------------------------------------------------------------
\\
arXiv:2206.10713
replaced with revised version Tue, 6 Jun 2023 01:26:35 GMT   (147kb,D)

Title: Beyond Uniform Lipschitz Condition in Differentially Private
 Optimization
Authors: Rudrajit Das, Satyen Kale, Zheng Xu, Tong Zhang, Sujay Sanghavi
Categories: cs.LG stat.ML
Comments: To appear in ICML 2023
\\ ( https://arxiv.org/abs/2206.10713 ,  147kb)
------------------------------------------------------------------------------
\\
arXiv:2206.10858
replaced with revised version Tue, 6 Jun 2023 05:16:38 GMT   (8559kb,D)

Title: Robust Universal Adversarial Perturbations
Authors: Changming Xu, Gagandeep Singh
Categories: cs.LG cs.CR
Comments: 16 pages, 3 figures
\\ ( https://arxiv.org/abs/2206.10858 ,  8559kb)
------------------------------------------------------------------------------
\\
arXiv:2206.12839
replaced with revised version Mon, 5 Jun 2023 18:43:50 GMT   (667kb,D)

Title: Repository-Level Prompt Generation for Large Language Models of Code
Authors: Disha Shrivastava, Hugo Larochelle, Daniel Tarlow
Categories: cs.LG cs.PL cs.SE
Comments: ICML 2023 (Camera-Ready version)
Journal-ref: ICML, 2023
\\ ( https://arxiv.org/abs/2206.12839 ,  667kb)
------------------------------------------------------------------------------
\\
arXiv:2207.12067
replaced with revised version Tue, 6 Jun 2023 13:08:55 GMT   (2779kb,D)

Title: Homomorphism Autoencoder -- Learning Group Structured Representations
 from Observed Transitions
Authors: Hamza Keurti, Hsiao-Ru Pan, Michel Besserve, Benjamin F. Grewe,
 Bernhard Sch\"olkopf
Categories: cs.LG math.GR stat.ML
Comments: ICML2023, 26 pages, 17 figures
\\ ( https://arxiv.org/abs/2207.12067 ,  2779kb)
------------------------------------------------------------------------------
\\
arXiv:2207.14443
replaced with revised version Tue, 6 Jun 2023 15:44:14 GMT   (7504kb,D)

Title: A Survey of Learning on Small Data: Generalization, Optimization, and
 Challenge
Authors: Xiaofeng Cao, Weixin Bu, Shengjun Huang, Minling Zhang, Ivor W. Tsang,
 Yew Soon Ong, and James T. Kwok
Categories: cs.LG
\\ ( https://arxiv.org/abs/2207.14443 ,  7504kb)
------------------------------------------------------------------------------
\\
arXiv:2208.02447
replaced with revised version Tue, 6 Jun 2023 07:45:31 GMT   (13358kb,D)

Title: DL-DRL: A double-level deep reinforcement learning approach for
 large-scale task scheduling of multi-UAV
Authors: Xiao Mao, Zhiguang Cao, Mingfeng Fan, Guohua Wu, and Witold Pedrycz
Categories: cs.LG cs.RO eess.SP
Comments: 13 pages, 7 figures
\\ ( https://arxiv.org/abs/2208.02447 ,  13358kb)
------------------------------------------------------------------------------
\\
arXiv:2209.05098
replaced with revised version Tue, 6 Jun 2023 11:02:06 GMT   (12052kb,D)

Title: SELTO: Sample-Efficient Learned Topology Optimization
Authors: S\"oren Dittmer, David Erzmann, Henrik Harms, Peter Maass
Categories: cs.LG cs.CV
Comments: 25 pages, 10 figures, submitted to the International Journal for
 Numerical Methods in Engineering
MSC-class: 68U05, 68U07, 65N21, 68T01
\\ ( https://arxiv.org/abs/2209.05098 ,  12052kb)
------------------------------------------------------------------------------
\\
arXiv:2209.15245
replaced with revised version Tue, 6 Jun 2023 06:27:08 GMT   (7375kb,D)

Title: Fed-CBS: A Heterogeneity-Aware Client Sampling Mechanism for Federated
 Learning via Class-Imbalance Reduction
Authors: Jianyi Zhang, Ang Li, Minxue Tang, Jingwei Sun, Xiang Chen, Fan Zhang,
 Changyou Chen, Yiran Chen, Hai Li
Categories: cs.LG
Comments: ICML 2023
\\ ( https://arxiv.org/abs/2209.15245 ,  7375kb)
------------------------------------------------------------------------------
\\
arXiv:2210.00380
replaced with revised version Mon, 5 Jun 2023 22:57:20 GMT   (2009kb,D)

Title: Transfer Learning for Individual Treatment Effect Estimation
Authors: Ahmed Aloui, Juncheng Dong, Cat P. Le, Vahid Tarokh
Categories: cs.LG stat.ME stat.ML
\\ ( https://arxiv.org/abs/2210.00380 ,  2009kb)
------------------------------------------------------------------------------
\\
arXiv:2210.00949
replaced with revised version Tue, 6 Jun 2023 13:48:11 GMT   (729kb,D)

Title: Block-wise Training of Residual Networks via the Minimizing Movement
 Scheme
Authors: Skander Karkar and Ibrahim Ayed and Emmanuel de B\'ezenac and Patrick
 Gallinari
Categories: cs.LG
Comments: 1st International Workshop on Practical Deep Learning in the Wild at
 AAAI 2022
\\ ( https://arxiv.org/abs/2210.00949 ,  729kb)
------------------------------------------------------------------------------
\\
arXiv:2210.01212
replaced with revised version Tue, 6 Jun 2023 04:30:36 GMT   (4932kb,D)

Title: spred: Solving $L_1$ Penalty with SGD
Authors: Liu Ziyin, Zihao Wang
Categories: cs.LG stat.ML
Comments: ICML 2023, 16 pages, 10 figures, and 2 tables
\\ ( https://arxiv.org/abs/2210.01212 ,  4932kb)
------------------------------------------------------------------------------
\\
arXiv:2210.05643
replaced with revised version Tue, 6 Jun 2023 09:06:42 GMT   (563kb,D)

Title: A Kernel-Based View of Language Model Fine-Tuning
Authors: Sadhika Malladi, Alexander Wettig, Dingli Yu, Danqi Chen, Sanjeev
 Arora
Categories: cs.LG cs.CL
Comments: Accepted at ICML 2023. Code and pre-computed kernels are publicly
 available at https://github.com/princeton-nlp/LM-Kernel-FT
\\ ( https://arxiv.org/abs/2210.05643 ,  563kb)
------------------------------------------------------------------------------
\\
arXiv:2210.10769
replaced with revised version Tue, 6 Jun 2023 07:05:12 GMT   (1868kb,D)

Title: "Why did the Model Fail?": Attributing Model Performance Changes to
 Distribution Shifts
Authors: Haoran Zhang, Harvineet Singh, Marzyeh Ghassemi, Shalmali Joshi
Categories: cs.LG stat.ML
Comments: Published in ICML 2023
\\ ( https://arxiv.org/abs/2210.10769 ,  1868kb)
------------------------------------------------------------------------------
\\
arXiv:2210.11466
replaced with revised version Tue, 6 Jun 2023 05:58:11 GMT   (2998kb,D)

Title: Surgical Fine-Tuning Improves Adaptation to Distribution Shifts
Authors: Yoonho Lee, Annie S. Chen, Fahim Tajwar, Ananya Kumar, Huaxiu Yao,
 Percy Liang, Chelsea Finn
Categories: cs.LG cs.AI
Comments: ICLR 2023
\\ ( https://arxiv.org/abs/2210.11466 ,  2998kb)
------------------------------------------------------------------------------
\\
arXiv:2210.12156
replaced with revised version Mon, 5 Jun 2023 21:09:51 GMT   (256kb,D)

Title: Improving Medical Predictions by Irregular Multimodal Electronic Health
 Records Modeling
Authors: Xinlu Zhang, Shiyang Li, Zhiyu Chen, Xifeng Yan, Linda Petzold
Categories: cs.LG cs.AI
\\ ( https://arxiv.org/abs/2210.12156 ,  256kb)
------------------------------------------------------------------------------
\\
arXiv:2210.13954
replaced with revised version Tue, 6 Jun 2023 08:37:56 GMT   (2366kb,D)

Title: I Prefer not to Say: Protecting User Consent in Models with Optional
 Personal Data
Authors: Tobias Leemann, Martin Pawelczyk, Christian Thomas Eberle, Gjergji
 Kasneci
Categories: cs.LG cs.AI cs.CY stat.ML
Comments: Updated Version. v1 accepted at NeurIPS 2022 Workshop on Algorithmic
 Fairness through the Lens of Causality and Privacy (AFCP)
\\ ( https://arxiv.org/abs/2210.13954 ,  2366kb)
------------------------------------------------------------------------------
\\
arXiv:2211.02139
replaced with revised version Mon, 5 Jun 2023 20:55:12 GMT   (9417kb,D)

Title: Can Querying for Bias Leak Protected Attributes? Achieving Privacy With
 Smooth Sensitivity
Authors: Faisal Hamman, Jiahao Chen, Sanghamitra Dutta
Categories: cs.LG cs.AI cs.CR cs.CY
Comments: Published in 2023 ACM Conference on Fairness, Accountability, and
 Transparency (FAccT2023)
DOI: 10.1145/3593013.3594086
\\ ( https://arxiv.org/abs/2211.02139 ,  9417kb)
------------------------------------------------------------------------------
\\
arXiv:2211.05311
replaced with revised version Tue, 6 Jun 2023 01:40:23 GMT   (70kb)

Title: When is Realizability Sufficient for Off-Policy Reinforcement Learning?
Authors: Andrea Zanette
Categories: cs.LG
Comments: Appears in ICML 2023 - any feedback is welcome
\\ ( https://arxiv.org/abs/2211.05311 ,  70kb)
------------------------------------------------------------------------------
\\
arXiv:2211.08583
replaced with revised version Mon, 5 Jun 2023 22:23:52 GMT   (3486kb,D)

Title: Empirical Study on Optimizer Selection for Out-of-Distribution
 Generalization
Authors: Hiroki Naganuma, Kartik Ahuja, Shiro Takagi, Tetsuya Motokawa, Rio
 Yokota, Kohta Ishikawa, Ikuro Sato, Ioannis Mitliagkas
Categories: cs.LG cs.AI
Comments: Accepted to TMLR
\\ ( https://arxiv.org/abs/2211.08583 ,  3486kb)
------------------------------------------------------------------------------
\\
arXiv:2301.00489
replaced with revised version Tue, 6 Jun 2023 05:30:05 GMT   (2502kb,D)

Title: Navigating Alignment for Non-identical Client Class Sets: A Label
 Name-Anchored Federated Learning Framework
Authors: Jiayun Zhang, Xiyuan Zhang, Xinyang Zhang, Dezhi Hong, Rajesh K.
 Gupta, Jingbo Shang
Categories: cs.LG
Comments: Accepted by KDD 2023
DOI: 10.1145/3580305.3599443
\\ ( https://arxiv.org/abs/2301.00489 ,  2502kb)
------------------------------------------------------------------------------
\\
arXiv:2301.08839
replaced with revised version Tue, 6 Jun 2023 17:16:48 GMT   (19512kb,D)

Title: A Trustworthiness Score to Evaluate CNNs Predictions
Authors: Abanoub Ghobrial, Darryl Hond, Hamid Asgari, Kerstin Eder
Categories: cs.LG
\\ ( https://arxiv.org/abs/2301.08839 ,  19512kb)
------------------------------------------------------------------------------
\\
arXiv:2301.08869
replaced with revised version Mon, 5 Jun 2023 18:23:06 GMT   (519kb,D)

Title: A Communication-Efficient Adaptive Algorithm for Federated Learning
 under Cumulative Regret
Authors: Sudeep Salgia, Qing Zhao, Tamir Gabay, Kobi Cohen
Categories: cs.LG cs.DC
\\ ( https://arxiv.org/abs/2301.08869 ,  519kb)
------------------------------------------------------------------------------
\\
arXiv:2301.08987
replaced with revised version Tue, 6 Jun 2023 13:51:08 GMT   (2775kb)

Title: Tier Balancing: Towards Dynamic Fairness over Underlying Causal Factors
Authors: Zeyu Tang, Yatong Chen, Yang Liu, Kun Zhang
Categories: cs.LG stat.ML
Journal-ref: The 11th International Conference on Learning Representations
 (ICLR 2023)
\\ ( https://arxiv.org/abs/2301.08987 ,  2775kb)
------------------------------------------------------------------------------
\\
arXiv:2301.10226
replaced with revised version Tue, 6 Jun 2023 17:50:01 GMT   (3618kb,D)

Title: A Watermark for Large Language Models
Authors: John Kirchenbauer, Jonas Geiping, Yuxin Wen, Jonathan Katz, Ian Miers,
 Tom Goldstein
Categories: cs.LG cs.CL cs.CR
Comments: 13 pages in the main body. Published at ICML 2023. Code is available
 at github.com/jwkirchenbauer/lm-watermarking
\\ ( https://arxiv.org/abs/2301.10226 ,  3618kb)
------------------------------------------------------------------------------
\\
arXiv:2301.11355
replaced with revised version Tue, 6 Jun 2023 12:13:33 GMT   (1605kb,D)

Title: Rigid body flows for sampling molecular crystal structures
Authors: Jonas K\"ohler, Michele Invernizzi, Pim de Haan, Frank No\'e
Categories: cs.LG physics.chem-ph physics.comp-ph stat.ML
\\ ( https://arxiv.org/abs/2301.11355 ,  1605kb)
------------------------------------------------------------------------------
\\
arXiv:2301.11526
replaced with revised version Tue, 6 Jun 2023 02:08:49 GMT   (172kb,D)

Title: Direct Parameterization of Lipschitz-Bounded Deep Networks
Authors: Ruigang Wang, Ian R. Manchester
Categories: cs.LG cs.AI
Comments: accepted to ICML 2023
\\ ( https://arxiv.org/abs/2301.11526 ,  172kb)
------------------------------------------------------------------------------
\\
arXiv:2301.13293
replaced with revised version Tue, 6 Jun 2023 16:45:31 GMT   (21290kb,D)

Title: Overcoming Simplicity Bias in Deep Networks using a Feature Sieve
Authors: Rishabh Tiwari, Pradeep Shenoy
Categories: cs.LG cs.AI
Comments: Accepted at ICML 2023
\\ ( https://arxiv.org/abs/2301.13293 ,  21290kb)
------------------------------------------------------------------------------
\\
arXiv:2301.13370
replaced with revised version Tue, 6 Jun 2023 04:04:41 GMT   (86kb,D)

Title: On the Correctness of Automatic Differentiation for Neural Networks with
 Machine-Representable Parameters
Authors: Wonyeol Lee, Sejun Park, Alex Aiken
Categories: cs.LG stat.ML
Comments: To appear at ICML 2023
\\ ( https://arxiv.org/abs/2301.13370 ,  86kb)
------------------------------------------------------------------------------
\\
arXiv:2301.13757
replaced with revised version Tue, 6 Jun 2023 14:28:43 GMT   (7204kb,D)

Title: Toward Efficient Gradient-Based Value Estimation
Authors: Arsalan Sharifnassab, Richard Sutton
Categories: cs.LG cs.AI
\\ ( https://arxiv.org/abs/2301.13757 ,  7204kb)
------------------------------------------------------------------------------
\\
arXiv:2302.00141
replaced with revised version Tue, 6 Jun 2023 16:09:23 GMT   (259kb,D)

Title: Revisiting Bellman Errors for Offline Model Selection
Authors: Joshua P. Zitovsky, Daniel de Marchi, Rishabh Agarwal, Michael R.
 Kosorok
Categories: cs.LG stat.ML
Comments: Published in ICML 2023
ACM-class: I.2.8; I.6.4
\\ ( https://arxiv.org/abs/2302.00141 ,  259kb)
------------------------------------------------------------------------------
\\
arXiv:2302.01186
replaced with revised version Tue, 6 Jun 2023 16:36:11 GMT   (1004kb,D)

Title: The Power of Preconditioning in Overparameterized Low-Rank Matrix
 Sensing
Authors: Xingyu Xu, Yandi Shen, Yuejie Chi, Cong Ma
Categories: cs.LG eess.SP math.OC stat.ML
\\ ( https://arxiv.org/abs/2302.01186 ,  1004kb)
------------------------------------------------------------------------------
\\
arXiv:2302.01567
replaced with revised version Mon, 5 Jun 2023 20:18:01 GMT   (0kb,I)

Title: Deep Reinforcement Learning for Online Error Detection in Cyber-Physical
 Systems
Authors: Seyyedamirhossein Saeidi and Forouzan Fallah and Saeed
 Samieezafarghandi and Hamed Farbeh
Categories: cs.LG cs.AI cs.SY eess.SY
Comments: There are some problems in the paper, so the authors decide to
 withdraw the paper
\\ ( https://arxiv.org/abs/2302.01567 ,  0kb)
------------------------------------------------------------------------------
\\
arXiv:2302.02209
replaced with revised version Tue, 6 Jun 2023 17:15:23 GMT   (57kb)

Title: A Theory of Link Prediction via Relational Weisfeiler-Leman
Authors: Xingyue Huang, Miguel Romero Orth, \.Ismail \.Ilkan Ceylan, Pablo
 Barcel\'o
Categories: cs.LG cs.AI
\\ ( https://arxiv.org/abs/2302.02209 ,  57kb)
------------------------------------------------------------------------------
\\
arXiv:2302.02399
replaced with revised version Tue, 6 Jun 2023 06:26:14 GMT   (5361kb,D)

Title: Enhancing Exploration in Latent Space Bayesian Optimization
Authors: Onur Boyar and Ichiro Takeuchi
Categories: cs.LG
Comments: 20 pages, 7 figures
\\ ( https://arxiv.org/abs/2302.02399 ,  5361kb)
------------------------------------------------------------------------------
\\
arXiv:2302.05783
replaced with revised version Tue, 6 Jun 2023 13:57:12 GMT   (4169kb,D)

Title: ConCerNet: A Contrastive Learning Based Framework for Automated
 Conservation Law Discovery and Trustworthy Dynamical System Prediction
Authors: Wang Zhang, Tsui-Wei Weng, Subhro Das, Alexandre Megretski, Luca
 Daniel, Lam M. Nguyen
Categories: cs.LG
Comments: Accepted by ICML 2023
\\ ( https://arxiv.org/abs/2302.05783 ,  4169kb)
------------------------------------------------------------------------------
\\
arXiv:2302.06835
replaced with revised version Tue, 6 Jun 2023 03:57:37 GMT   (596kb,D)

Title: Understanding Oversquashing in GNNs through the Lens of Effective
 Resistance
Authors: Mitchell Black and Zhengchao Wan and Amir Nayyeri and Yusu Wang
Categories: cs.LG
\\ ( https://arxiv.org/abs/2302.06835 ,  596kb)
------------------------------------------------------------------------------
\\
arXiv:2302.11002
replaced with revised version Tue, 6 Jun 2023 06:49:06 GMT   (18122kb,D)

Title: Learning Physical Models that Can Respect Conservation Laws
Authors: Derek Hansen, Danielle C. Maddix, Shima Alizadeh, Gaurav Gupta,
 Michael W. Mahoney
Categories: cs.LG cs.NA math.AP math.NA
Comments: ICML 2023
Journal-ref: Proceedings of the 40th International Conference on Machine
 Learning (ICML 2023), PMLR 202
\\ ( https://arxiv.org/abs/2302.11002 ,  18122kb)
------------------------------------------------------------------------------
\\
arXiv:2302.14471
replaced with revised version Tue, 6 Jun 2023 09:01:04 GMT   (104kb)

Title: Safe Peeling for L0-Regularized Least-Squares with supplementary
 material
Authors: Th\'eo Guyard, Gilles Monnoyer, Cl\'ement Elvira, C\'edric Herzet
Categories: cs.LG math.OC stat.ML
\\ ( https://arxiv.org/abs/2302.14471 ,  104kb)
------------------------------------------------------------------------------
\\
arXiv:2303.01513
replaced with revised version Tue, 6 Jun 2023 12:02:18 GMT   (691kb)

Title: Safe AI for health and beyond -- Monitoring to transform a health
 service
Authors: Mahed Abroshan, Michael Burkhart, Oscar Giles, Sam Greenbury, Zoe
 Kourtzi, Jack Roberts, Mihaela van der Schaar, Jannetta S Steyn, Alan Wilson,
 May Yong
Categories: cs.LG cs.AI
Comments: 12 pages, 3 figures
ACM-class: I.2.1
\\ ( https://arxiv.org/abs/2303.01513 ,  691kb)
------------------------------------------------------------------------------
\\
arXiv:2303.02278
replaced with revised version Mon, 5 Jun 2023 18:43:26 GMT   (13040kb,D)

Title: Federated Virtual Learning on Heterogeneous Data with Local-global
 Distillation
Authors: Chun-Yin Huang, Ruinan Jin, Can Zhao, Daguang Xu, and Xiaoxiao Li
Categories: cs.LG cs.AI
\\ ( https://arxiv.org/abs/2303.02278 ,  13040kb)
------------------------------------------------------------------------------
\\
arXiv:2303.03592
replaced with revised version Tue, 6 Jun 2023 04:39:06 GMT   (27225kb,D)

Title: Exploring the Limits of Model-Targeted Indiscriminate Data Poisoning
 Attacks
Authors: Yiwei Lu, Gautam Kamath, Yaoliang Yu
Categories: cs.LG cs.CR
Comments: Accepted to ICML 2023
\\ ( https://arxiv.org/abs/2303.03592 ,  27225kb)
------------------------------------------------------------------------------
\\
arXiv:2303.04791
replaced with revised version Tue, 6 Jun 2023 16:15:34 GMT   (6786kb,D)

Title: Ewald-based Long-Range Message Passing for Molecular Graphs
Authors: Arthur Kosmala, Johannes Gasteiger, Nicholas Gao, Stephan G\"unnemann
Categories: cs.LG cond-mat.mtrl-sci physics.chem-ph physics.comp-ph
Comments: Published at the 40th International Conference on Machine Learning
 (ICML 2023)
\\ ( https://arxiv.org/abs/2303.04791 ,  6786kb)
------------------------------------------------------------------------------
\\
arXiv:2303.10909
replaced with revised version Tue, 6 Jun 2023 08:11:51 GMT   (11908kb,D)

Title: Graph Neural Rough Differential Equations for Traffic Forecasting
Authors: Jeongwhan Choi, Noseong Park
Categories: cs.LG cs.AI
Comments: Accepted to ACM Transactions on Intelligent Systems and Technology
 (ACM TIST). arXiv admin note: substantial text overlap with arXiv:2112.03558
\\ ( https://arxiv.org/abs/2303.10909 ,  11908kb)
------------------------------------------------------------------------------
\\
arXiv:2303.11249
replaced with revised version Tue, 6 Jun 2023 04:51:35 GMT   (3374kb,D)

Title: What Makes Data Suitable for a Locally Connected Neural Network? A
 Necessary and Sufficient Condition Based on Quantum Entanglement
Authors: Yotam Alexander, Nimrod De La Vega, Noam Razin, Nadav Cohen
Categories: cs.LG cs.AI quant-ph
\\ ( https://arxiv.org/abs/2303.11249 ,  3374kb)
------------------------------------------------------------------------------
\\
arXiv:2303.14623
replaced with revised version Tue, 6 Jun 2023 06:02:25 GMT   (909kb,D)

Title: Inverse Reinforcement Learning without Reinforcement Learning
Authors: Gokul Swamy, Sanjiban Choudhury, J. Andrew Bagnell, Zhiwei Steven Wu
Categories: cs.LG
\\ ( https://arxiv.org/abs/2303.14623 ,  909kb)
------------------------------------------------------------------------------
\\
arXiv:2303.14771
replaced with revised version Tue, 6 Jun 2023 14:47:01 GMT   (315kb,D)

Title: Prototype-Sample Relation Distillation: Towards Replay-Free Continual
 Learning
Authors: Nader Asadi, MohammadReza Davari, Sudhir Mudur, Rahaf Aljundi and
 Eugene Belilovsky
Categories: cs.LG
Comments: Accepted at ICML 2023
\\ ( https://arxiv.org/abs/2303.14771 ,  315kb)
------------------------------------------------------------------------------
\\
arXiv:2304.04934
replaced with revised version Mon, 5 Jun 2023 22:17:38 GMT   (4336kb,D)

Title: Model Sparsification Can Simplify Machine Unlearning
Authors: Jinghan Jia, Jiancheng Liu, Parikshit Ram, Yuguang Yao, Gaowen Liu,
 Yang Liu, Pranay Sharma, Sijia Liu
Categories: cs.LG
\\ ( https://arxiv.org/abs/2304.04934 ,  4336kb)
------------------------------------------------------------------------------
\\
arXiv:2304.09836
replaced with revised version Tue, 6 Jun 2023 15:39:51 GMT   (2051kb,D)

Title: Regions of Reliability in the Evaluation of Multivariate Probabilistic
 Forecasts
Authors: \'Etienne Marcotte, Valentina Zantedeschi, Alexandre Drouin, Nicolas
 Chapados
Categories: cs.LG stat.ML
Comments: 47 pages, 37 figures, camera-ready version, Fortieth International
 Conference on Machine Learning (ICML 2023)
\\ ( https://arxiv.org/abs/2304.09836 ,  2051kb)
------------------------------------------------------------------------------
\\
arXiv:2304.12680
replaced with revised version Tue, 6 Jun 2023 10:22:56 GMT   (282kb)

Title: Communication-Constrained Bandits under Additive Gaussian Noise
Authors: Prathamesh Mayekar, Jonathan Scarlett, and Vincent Y.F. Tan
Categories: cs.LG cs.IT math.IT stat.ML
\\ ( https://arxiv.org/abs/2304.12680 ,  282kb)
------------------------------------------------------------------------------
\\
arXiv:2304.14209
replaced with revised version Tue, 6 Jun 2023 00:49:07 GMT   (71kb)

Title: A transparent approach to data representation
Authors: Sean Deyo, Veit Elser
Categories: cs.LG
\\ ( https://arxiv.org/abs/2304.14209 ,  71kb)
------------------------------------------------------------------------------
\\
arXiv:2305.00169
replaced with revised version Tue, 6 Jun 2023 12:20:23 GMT   (503kb,D)

Title: An Evidential Real-Time Multi-Mode Fault Diagnosis Approach Based on
 Broad Learning System
Authors: Chen Li and Zeyi Liu and Limin Wang and Minyue Li and Xiao He
Categories: cs.LG cs.AI cs.SY eess.SY
Comments: 6 pages, 11 figures, Accepted by the 34th Chinese Process Control
 Conference
\\ ( https://arxiv.org/abs/2305.00169 ,  503kb)
------------------------------------------------------------------------------
\\
arXiv:2305.08040
replaced with revised version Tue, 6 Jun 2023 05:32:49 GMT   (10679kb,D)

Title: Provable Multi-instance Deep AUC Maximization with Stochastic Pooling
Authors: Dixian Zhu, Bokun Wang, Zhi Chen, Yaxing Wang, Milan Sonka, Xiaodong
 Wu, Tianbao Yang
Categories: cs.LG cs.AI
Comments: To appear in ICML2023, 23 pages
\\ ( https://arxiv.org/abs/2305.08040 ,  10679kb)
------------------------------------------------------------------------------
\\
arXiv:2305.10748
replaced with revised version Tue, 6 Jun 2023 16:52:52 GMT   (10037kb)

Title: Physics Inspired Approaches To Understanding Gaussian Processes
Authors: Maximilian P. Niroomand and Luke Dicks and Edward O. Pyzer-Knapp and
 David J. Wales
Categories: cs.LG cs.AI
Comments: 9 pages, 4 figures
\\ ( https://arxiv.org/abs/2305.10748 ,  10037kb)
------------------------------------------------------------------------------
\\
arXiv:2305.11509
replaced with revised version Tue, 6 Jun 2023 13:28:39 GMT   (492kb,D)

Title: From Random Search to Bandit Learning in Metric Measure Spaces
Authors: Chuying Han, Yasong Feng, Tianyu Wang
Categories: cs.LG stat.ML
\\ ( https://arxiv.org/abs/2305.11509 ,  492kb)
------------------------------------------------------------------------------
\\
arXiv:2305.11640
replaced with revised version Tue, 6 Jun 2023 13:01:29 GMT   (1138kb,D)

Title: Distribution-Free Matrix Prediction Under Arbitrary Missing Pattern
Authors: Meijia Shao and Yuan Zhang
Categories: cs.LG math.ST stat.ME stat.ML stat.TH
Comments: 12 pages, 4 figures
\\ ( https://arxiv.org/abs/2305.11640 ,  1138kb)
------------------------------------------------------------------------------
\\
arXiv:2305.15598
replaced with revised version Tue, 6 Jun 2023 00:19:58 GMT   (1771kb,D)

Title: Linear Neural Network Layers Promote Learning Single- and Multiple-Index
 Models
Authors: Suzanna Parkinson, Greg Ongie, and Rebecca Willett
Categories: cs.LG stat.ML
\\ ( https://arxiv.org/abs/2305.15598 ,  1771kb)
------------------------------------------------------------------------------
\\
arXiv:2306.00267
replaced with revised version Tue, 6 Jun 2023 02:19:58 GMT   (433kb,D)

Title: Provable Benefit of Mixup for Finding Optimal Decision Boundaries
Authors: Junsoo Oh, Chulhee Yun
Categories: cs.LG math.OC stat.ML
Comments: ICML 2023 camera-ready version; 48 pages
\\ ( https://arxiv.org/abs/2306.00267 ,  433kb)
------------------------------------------------------------------------------
\\
arXiv:2306.00301
replaced with revised version Tue, 6 Jun 2023 03:41:05 GMT   (1729kb,D)

Title: CapText: Large Language Model-based Caption Generation From Image
 Context and Description
Authors: Shinjini Ghosh, Sagnik Anupam
Categories: cs.LG cs.CL
Comments: Update 6/6/23: Fixed typographic error in abstract
\\ ( https://arxiv.org/abs/2306.00301 ,  1729kb)
------------------------------------------------------------------------------
\\
arXiv:2306.00390
replaced with revised version Tue, 6 Jun 2023 13:18:50 GMT   (1135kb,D)

Title: Learning Gaussian Mixture Representations for Tensor Time Series
 Forecasting
Authors: Jiewen Deng, Jinliang Deng, Renhe Jiang, Xuan Song
Categories: cs.LG
Comments: Accepted by IJCAI 2023 Main Track
\\ ( https://arxiv.org/abs/2306.00390 ,  1135kb)
------------------------------------------------------------------------------
\\
arXiv:2306.00698
replaced with revised version Tue, 6 Jun 2023 16:12:01 GMT   (1697kb,D)

Title: Prediction of Post-Operative Renal and Pulmonary Complications Using
 Transformers
Authors: Reza Shirkavand, Fei Zhang, Heng Huang
Categories: cs.LG cs.CV
\\ ( https://arxiv.org/abs/2306.00698 ,  1697kb)
------------------------------------------------------------------------------
\\
arXiv:2306.01951
replaced with revised version Tue, 6 Jun 2023 01:57:18 GMT   (3224kb,D)

Title: GAD-NR: Graph Anomaly Detection via Neighborhood Reconstruction
Authors: Amit Roy, Juan Shu, Jia Li, Carl Yang, Olivier Elshocht, Jeroen Smeets
 and Pan Li
Categories: cs.LG
\\ ( https://arxiv.org/abs/2306.01951 ,  3224kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02050
replaced with revised version Tue, 6 Jun 2023 13:46:22 GMT   (3012kb,D)

Title: Provable Dynamic Fusion for Low-Quality Multimodal Data
Authors: Qingyang Zhang, Haitao Wu, Changqing Zhang, Qinghua Hu, Huazhu Fu,
 Joey Tianyi Zhou, Xi Peng
Categories: cs.LG cs.CV
Comments: Accepted by ICML 2023
\\ ( https://arxiv.org/abs/2306.02050 ,  3012kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02157
replaced with revised version Tue, 6 Jun 2023 14:48:36 GMT   (3041kb)

Title: Transforming to Yoked Neural Networks to Improve ANN Structure
Authors: Xinshun Liu and Yizhi Fang and Yichao Jiang
Categories: cs.LG
\\ ( https://arxiv.org/abs/2306.02157 ,  3041kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02685
replaced with revised version Tue, 6 Jun 2023 12:06:03 GMT   (1350kb,D)

Title: Predicting malaria dynamics in Burundi using deep Learning Models
Authors: Daxelle Sakubu, Kelly Joelle Gatore Sinigirira, David Niyukuri
Categories: cs.LG cs.AI
\\ ( https://arxiv.org/abs/2306.02685 ,  1350kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02865
replaced with revised version Tue, 6 Jun 2023 09:52:29 GMT   (34018kb,D)

Title: Seizing Serendipity: Exploiting the Value of Past Success in Off-Policy
 Actor-Critic
Authors: Tianying Ji, Yu Luo, Fuchun Sun, Xianyuan Zhan, Jianwei Zhang, Huazhe
 Xu
Categories: cs.LG cs.AI
\\ ( https://arxiv.org/abs/2306.02865 ,  34018kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02968
replaced with revised version Tue, 6 Jun 2023 01:26:40 GMT   (68kb,D)

Title: Time Interpret: a Unified Model Interpretability Library for Time Series
Authors: Joseph Enguehard
Categories: cs.LG cs.AI
Comments: 7 pages, 1 figure. Code available at
 https://github.com/josephenguehard/time_interpret
\\ ( https://arxiv.org/abs/2306.02968 ,  68kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03007
replaced with revised version Tue, 6 Jun 2023 03:59:26 GMT   (7762kb,D)

Title: Nonparametric Iterative Machine Teaching
Authors: Chen Zhang, Xiaofeng Cao, Weiyang Liu, Ivor Tsang, James Kwok
Categories: cs.LG cs.AI cs.CV
Comments: ICML 2023 (20 pages, 10 figures)
\\ ( https://arxiv.org/abs/2306.03007 ,  7762kb)
------------------------------------------------------------------------------
\\
arXiv:2206.13348
replaced with revised version Tue, 6 Jun 2023 06:56:50 GMT   (790kb)

Title: A Unified Initial Alignment Method of SINS Based on FGO
Authors: Hanwen Zhou, Xiufen Ye
Categories: cs.RO eess.SP
Comments: 8 pages, This article has been accepted for publication in IEEE
 Transactions on Industrial Electronics
\\ ( https://arxiv.org/abs/2206.13348 ,  790kb)
------------------------------------------------------------------------------
\\
arXiv:2210.01199
replaced with revised version Mon, 5 Jun 2023 22:35:42 GMT   (5720kb,D)

Title: Online Update of Safety Assurances Using Confidence-Based Predictions
Authors: Kensuke Nakamura and Somil Bansal
Categories: cs.RO
Comments: 7 pages, 4 figures
\\ ( https://arxiv.org/abs/2210.01199 ,  5720kb)
------------------------------------------------------------------------------
\\
arXiv:2212.08333
replaced with revised version Tue, 6 Jun 2023 08:56:37 GMT   (7155kb,D)

Title: AnyGrasp: Robust and Efficient Grasp Perception in Spatial and Temporal
 Domains
Authors: Hao-Shu Fang, Chenxi Wang, Hongjie Fang, Minghao Gou, Jirong Liu,
 Hengxu Yan, Wenhai Liu, Yichen Xie, Cewu Lu
Categories: cs.RO
Comments: Paper accepted to T-RO. Project page is at
 https://graspnet.net/anygrasp.html
\\ ( https://arxiv.org/abs/2212.08333 ,  7155kb)
------------------------------------------------------------------------------
\\
arXiv:2301.00452
replaced with revised version Tue, 6 Jun 2023 05:48:09 GMT   (5732kb,D)

Title: Human-in-the-loop Embodied Intelligence with Interactive Simulation
 Environment for Surgical Robot Learning
Authors: Yonghao Long, Wang Wei, Tao Huang, Yuehao Wang, Qi Dou
Categories: cs.RO cs.AI cs.CV cs.LG
\\ ( https://arxiv.org/abs/2301.00452 ,  5732kb)
------------------------------------------------------------------------------
\\
arXiv:2304.06312
replaced with revised version Tue, 6 Jun 2023 15:49:58 GMT   (1597kb,D)

Title: Survey on LiDAR Perception in Adverse Weather Conditions
Authors: Mariella Dreissig, Dominik Scheuble, Florian Piewak and Joschka
 Boedecker
Categories: cs.RO cs.CV
Comments: published at IEEE IV 2023
\\ ( https://arxiv.org/abs/2304.06312 ,  1597kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02994
replaced with revised version Tue, 6 Jun 2023 04:25:42 GMT   (13422kb,D)

Title: Long-range UAV Thermal Geo-localization with Satellite Imagery
Authors: Jiuhong Xiao, Daniel Tortei, Eloy Roura, Giuseppe Loianno
Categories: cs.RO cs.CV
Comments: 8 pages, 6 figures
\\ ( https://arxiv.org/abs/2306.02994 ,  13422kb)
------------------------------------------------------------------------------
\\
arXiv:2209.04157
replaced with revised version Tue, 6 Jun 2023 11:52:26 GMT   (733kb,D)

Title: A Fast Algorithm for Onboard Atmospheric Powered Descent Guidance
Authors: Yushu Chen, Guangwen Yang, Lu Wang, Qingzhong Gan, Haipeng Chen, and
 Quanyong Xu
Categories: eess.SY cs.CE cs.SY math.OC
Comments: The paper is accepted by IEEE Transactions on Aerospace and
 Electronic Systems, 2023
DOI: 10.1109/TAES.2023.3271961
\\ ( https://arxiv.org/abs/2209.04157 ,  733kb)
------------------------------------------------------------------------------
\\
arXiv:2212.14665
replaced with revised version Tue, 6 Jun 2023 08:18:04 GMT   (449kb,D)

Title: Sizing Grid-Connected Wind Power Generation and Energy Storage
 Considering Wake Effect and Endogenous Uncertainty: A Distributionally Robust
 Method
Authors: Rui Xie, Wei Wei, Yue Chen
Categories: eess.SY cs.SY math.OC
Comments: 27 pages, 6 figures
\\ ( https://arxiv.org/abs/2212.14665 ,  449kb)
------------------------------------------------------------------------------
\\
arXiv:2304.05693
replaced with revised version Mon, 5 Jun 2023 20:23:15 GMT   (2447kb)

Title: A Persistent-Excitation-Free Method for System Disturbance Estimation
 Using Concurrent Learning
Authors: Zengjie Zhang, Fangzhou Liu, Tong Liu, Jianbin Qiu, and Martin Buss
Categories: eess.SY cs.SY
\\ ( https://arxiv.org/abs/2304.05693 ,  2447kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02944
replaced with revised version Tue, 6 Jun 2023 08:19:23 GMT   (8022kb,D)

Title: Beyond Nyquist in Frequency Response Function Identification: Applied to
 Slow-Sampled Systems
Authors: Max van Haren, Leonid Mirkin, Lennart Blanken and Tom Oomen
Categories: eess.SY cs.SY
\\ ( https://arxiv.org/abs/2306.02944 ,  8022kb)
------------------------------------------------------------------------------
\\
arXiv:2011.08960
replaced with revised version Tue, 6 Jun 2023 09:02:59 GMT   (3032kb,D)

Title: Deep Serial Number: Computational Watermarking for DNN Intellectual
 Property Protection
Authors: Ruixiang Tang, Mengnan Du, Xia Hu
Categories: cs.CR cs.AI
\\ ( https://arxiv.org/abs/2011.08960 ,  3032kb)
------------------------------------------------------------------------------
\\
arXiv:2203.15370
replaced with revised version Tue, 6 Jun 2023 14:04:04 GMT   (1210kb)

Title: A Principles-based Ethics Assurance Argument Pattern for AI and
 Autonomous Systems
Authors: Zoe Porter, Ibrahim Habli, John McDermid, Marten Kaas
Categories: cs.CY cs.AI
Journal-ref: AI and Ethics 2023
DOI: 10.1007/s43681-023-00297-2
\\ ( https://arxiv.org/abs/2203.15370 ,  1210kb)
------------------------------------------------------------------------------
\\
arXiv:2206.13872 (*cross-listing*)
replaced with revised version Tue, 6 Jun 2023 07:01:53 GMT   (8061kb,D)

Title: When are Post-hoc Conceptual Explanations Identifiable?
Authors: Tobias Leemann, Michael Kirchhof, Yao Rong, Enkelejda Kasneci, Gjergji
 Kasneci
Categories: stat.ML cs.AI cs.CV cs.LG
Comments: v5: UAI2023 camera-ready including supplementary material. The first
 two authors contributed equally
\\ ( https://arxiv.org/abs/2206.13872 ,  8061kb)
------------------------------------------------------------------------------
\\
arXiv:2210.01351
replaced with revised version Mon, 5 Jun 2023 22:40:20 GMT   (690kb,D)

Title: Less is More: Task-aware Layer-wise Distillation for Language Model
 Compression
Authors: Chen Liang, Simiao Zuo, Qingru Zhang, Pengcheng He, Weizhu Chen, Tuo
 Zhao
Categories: cs.CL cs.AI cs.LG
Comments: Proceedings of ICML 2023
\\ ( https://arxiv.org/abs/2210.01351 ,  690kb)
------------------------------------------------------------------------------
\\
arXiv:2210.04185
replaced with revised version Tue, 6 Jun 2023 02:19:08 GMT   (1831kb,D)

Title: Controllable Dialogue Simulation with In-Context Learning
Authors: Zekun Li, Wenhu Chen, Shiyang Li, Hong Wang, Jing Qian, Xifeng Yan
Categories: cs.CL cs.AI
Comments: EMNLP 2022 Findings, code and data are available at
 https://github.com/Leezekun/dialogic
\\ ( https://arxiv.org/abs/2210.04185 ,  1831kb)
------------------------------------------------------------------------------
\\
arXiv:2211.10438
replaced with revised version Mon, 5 Jun 2023 21:21:28 GMT   (4172kb,D)

Title: SmoothQuant: Accurate and Efficient Post-Training Quantization for Large
 Language Models
Authors: Guangxuan Xiao, Ji Lin, Mickael Seznec, Hao Wu, Julien Demouth, Song
 Han
Categories: cs.CL cs.AI cs.LG
Comments: ICML 2023. First two authors contributed equally to this work
\\ ( https://arxiv.org/abs/2211.10438 ,  4172kb)
------------------------------------------------------------------------------
\\
arXiv:2212.01692
replaced with revised version Tue, 6 Jun 2023 12:09:47 GMT   (261kb,D)

Title: Can In-context Learners Learn a Reasoning Concept from Demonstrations?
Authors: Michal \v{S}tef\'anik and Marek Kadl\v{c}\'ik
Categories: cs.CL cs.AI cs.LG
Comments: Accepted at ACL 2023 Natural Language Reasoning workshop
\\ ( https://arxiv.org/abs/2212.01692 ,  261kb)
------------------------------------------------------------------------------
\\
arXiv:2301.12132
replaced with revised version Tue, 6 Jun 2023 17:07:23 GMT   (439kb,D)

Title: AutoPEFT: Automatic Configuration Search for Parameter-Efficient
 Fine-Tuning
Authors: Han Zhou, Xingchen Wan, Ivan Vuli\'c, Anna Korhonen
Categories: cs.CL cs.AI cs.LG
Comments: 17 pages, 7 figures, 9 tables
\\ ( https://arxiv.org/abs/2301.12132 ,  439kb)
------------------------------------------------------------------------------
\\
arXiv:2302.00093
replaced with revised version Tue, 6 Jun 2023 08:36:20 GMT   (1142kb,D)

Title: Large Language Models Can Be Easily Distracted by Irrelevant Context
Authors: Freda Shi, Xinyun Chen, Kanishka Misra, Nathan Scales, David Dohan, Ed
 Chi, Nathanael Sch\"arli, Denny Zhou
Categories: cs.CL cs.AI
Comments: Published in ICML 2023
\\ ( https://arxiv.org/abs/2302.00093 ,  1142kb)
------------------------------------------------------------------------------
\\
arXiv:2302.04775
replaced with revised version Tue, 6 Jun 2023 12:52:36 GMT   (1737kb,D)

Title: Adap-$\tau$: Adaptively Modulating Embedding Magnitude for
 Recommendation
Authors: Jiawei Chen, Junkang Wu, Jiancan Wu, Sheng Zhou, Xuezhi Cao, Xiangnan
 He
Categories: cs.IR cs.AI
Journal-ref: WWW2023
DOI: 10.1145/3543507.3583363
\\ ( https://arxiv.org/abs/2302.04775 ,  1737kb)
------------------------------------------------------------------------------
\\
arXiv:2303.17612
replaced with revised version Tue, 6 Jun 2023 16:30:09 GMT   (7220kb,D)

Title: oBERTa: Improving Sparse Transfer Learning via improved initialization,
 distillation, and pruning regimes
Authors: Daniel Campos, Alexandre Marques, Mark Kurtz, and ChengXiang Zhai
Categories: cs.CL cs.AI cs.LG
Comments: SustaiNLP2023 @ ACL 2023,9 pages, 2 figures, 45 tables
\\ ( https://arxiv.org/abs/2303.17612 ,  7220kb)
------------------------------------------------------------------------------
\\
arXiv:2305.03506
replaced with revised version Tue, 6 Jun 2023 12:19:35 GMT   (0kb,I)

Title: SI-LSTM: Speaker Hybrid Long-short Term Memory and Cross Modal Attention
 for Emotion Recognition in Conversation
Authors: Xingwei Liang, You Zou, Ruifeng Xu
Categories: cs.CL cs.AI cs.HC
Comments: modification needed
\\ ( https://arxiv.org/abs/2305.03506 ,  0kb)
------------------------------------------------------------------------------
\\
arXiv:2305.08746
replaced with revised version Tue, 6 Jun 2023 16:11:42 GMT   (24835kb,D)

Title: Seeing is Believing: Brain-Inspired Modular Training for Mechanistic
 Interpretability
Authors: Ziming Liu, Eric Gan, Max Tegmark
Categories: cs.NE cond-mat.dis-nn cs.AI cs.LG math.RT q-bio.NC
Comments: Codes are available here: https://github.com/KindXiaoming/BIMT
\\ ( https://arxiv.org/abs/2305.08746 ,  24835kb)
------------------------------------------------------------------------------
\\
arXiv:2305.16806
replaced with revised version Tue, 6 Jun 2023 03:15:43 GMT   (6960kb,D)

Title: Do GPTs Produce Less Literal Translations?
Authors: Vikas Raunak, Arul Menezes, Matt Post, Hany Hassan Awadalla
Categories: cs.CL cs.AI
Comments: ACL 2023
\\ ( https://arxiv.org/abs/2305.16806 ,  6960kb)
------------------------------------------------------------------------------
\\
arXiv:2305.18302
replaced with revised version Tue, 6 Jun 2023 03:36:00 GMT   (36kb)

Title: What We Know So Far: Artificial Intelligence in African Healthcare
Authors: Naome Etori, Ebasa Temesgen, and Maria Gini
Categories: cs.CY cs.AI
Comments: 8 pages, 1 figure, AAAI-23 conference in Washington, DC,
 International Workshop on the Social Impact of AI for Africa(SIAIA)
\\ ( https://arxiv.org/abs/2305.18302 ,  36kb)
------------------------------------------------------------------------------
\\
arXiv:2305.18885
replaced with revised version Tue, 6 Jun 2023 15:45:30 GMT   (1991kb,D)

Title: Criteria Tell You More than Ratings: Criteria Preference-Aware Light
 Graph Convolution for Effective Multi-Criteria Recommendation
Authors: Jin-Duk Park, Siqing Li, Xin Cao, Won-Yong Shin
Categories: cs.SI cs.AI cs.IR cs.IT cs.LG math.IT
Comments: 12 pages, 10 figures, 5 tables; 29th ACM SIGKDD Conference on
 Knowledge Discovery & Data (KDD 2023) (to appear) (Please cite our conference
 version.)
\\ ( https://arxiv.org/abs/2305.18885 ,  1991kb)
------------------------------------------------------------------------------
\\
arXiv:2306.00107
replaced with revised version Tue, 6 Jun 2023 14:06:02 GMT   (364kb,D)

Title: MERT: Acoustic Music Understanding Model with Large-Scale
 Self-supervised Training
Authors: Yizhi Li, Ruibin Yuan, Ge Zhang, Yinghao Ma, Xingran Chen, Hanzhi Yin,
 Chenghua Lin, Anton Ragni, Emmanouil Benetos, Norbert Gyenge, Roger
 Dannenberg, Ruibo Liu, Wenhu Chen, Gus Xia, Yemin Shi, Wenhao Huang, Yike
 Guo, Jie Fu
Categories: cs.SD cs.AI cs.CL cs.LG eess.AS
\\ ( https://arxiv.org/abs/2306.00107 ,  364kb)
------------------------------------------------------------------------------
\\
arXiv:2306.00477
replaced with revised version Tue, 6 Jun 2023 16:10:28 GMT   (529kb,D)

Title: Make Your Pre-trained Model Reversible: From Parameter to Memory
 Efficient Fine-Tuning
Authors: Baohao Liao, Shaomu Tan, Christof Monz
Categories: cs.CL cs.AI cs.LG
Comments: Code at https://github.com/BaohaoLiao/mefts
\\ ( https://arxiv.org/abs/2306.00477 ,  529kb)
------------------------------------------------------------------------------
\\
arXiv:2306.00597
replaced with revised version Tue, 6 Jun 2023 09:49:36 GMT   (869kb)

Title: Analysis of ChatGPT on Source Code
Authors: Ahmed R. Sadik, Antonello Ceravola, Frank Joublin, Jibesh Patra
Categories: cs.SE cs.AI cs.PL
Comments: 40 pages, examples provided for each experiment
\\ ( https://arxiv.org/abs/2306.00597 ,  869kb)
------------------------------------------------------------------------------
\\
arXiv:2306.01788
replaced with revised version Tue, 6 Jun 2023 15:00:21 GMT   (350kb,D)

Title: Responsible Design Patterns for Machine Learning Pipelines
Authors: Saud Hakem Al Harbi, Lionel Nganyewou Tidjon and Foutse Khomh
Categories: cs.SE cs.AI cs.LG
Comments: 20 pages, 4 figures, 5 tables
\\ ( https://arxiv.org/abs/2306.01788 ,  350kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02051
replaced with revised version Tue, 6 Jun 2023 12:39:21 GMT   (1109kb,D)

Title: A Comprehensive Survey on Deep Learning for Relation Extraction: Recent
 Advances and New Frontiers
Authors: Xiaoyan Zhao, Yang Deng, Min Yang, Lingzhi Wang, Rui Zhang, Hong
 Cheng, Wai Lam, Ying Shen, Ruifeng Xu
Categories: cs.CL cs.AI
\\ ( https://arxiv.org/abs/2306.02051 ,  1109kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02069
replaced with revised version Tue, 6 Jun 2023 06:43:07 GMT   (9587kb,D)

Title: MultiLegalPile: A 689GB Multilingual Legal Corpus
Authors: Joel Niklaus, Veton Matoshi, Matthias St\"urmer, Ilias Chalkidis,
 Daniel E. Ho
Categories: cs.CL cs.AI cs.LG
MSC-class: 68T50
ACM-class: I.2
\\ ( https://arxiv.org/abs/2306.02069 ,  9587kb)
------------------------------------------------------------------------------
\\
arXiv:2102.02115 (*cross-listing*)
replaced with revised version Tue, 6 Jun 2023 08:47:49 GMT   (947kb,D)

Title: TEyeD: Over 20 million real-world eye images with Pupil, Eyelid, and
 Iris 2D and 3D Segmentations, 2D and 3D Landmarks, 3D Eyeball, Gaze Vector,
 and Eye Movement Types
Authors: Wolfgang Fuhl and Gjergji Kasneci and Enkelejda Kasneci
Categories: eess.IV cs.CV
Comments: Download: Just connect via FTP as user TEyeDUser and without password
 to nephrit.cs.uni-tuebingen.de (ftp://nephrit.cs.uni-tuebingen.de)
DOI: 10.1109/ismar52148.2021.00053
\\ ( https://arxiv.org/abs/2102.02115 ,  947kb)
------------------------------------------------------------------------------
\\
arXiv:2202.00179 (*cross-listing*)
replaced with revised version Tue, 6 Jun 2023 02:16:47 GMT   (8926kb,D)

Title: Blind Image Deconvolution Using Variational Deep Image Prior
Authors: Dong Huo, Abbas Masoumzadeh, Rafsanjany Kushol, Yee-Hong Yang
Categories: eess.IV cs.CV
Comments: IEEE Transactions on Pattern Analysis and Machine Intelligence
 (TPAMI), 2023
\\ ( https://arxiv.org/abs/2202.00179 ,  8926kb)
------------------------------------------------------------------------------
\\
arXiv:2303.05785 (*cross-listing*)
replaced with revised version Tue, 6 Jun 2023 03:05:07 GMT   (3289kb,D)

Title: Scaling Up 3D Kernels with Bayesian Frequency Re-parameterization for
 Medical Image Segmentation
Authors: Ho Hin Lee, Quan Liu, Shunxing Bao, Qi Yang, Xin Yu, Leon Y. Cai,
 Thomas Li, Yuankai Huo, Xenofon Koutsoukos, Bennett A. Landman
Categories: eess.IV cs.CV cs.LG
Comments: Accepted to MICCAI 2023 (top 13.6%), both codes and pretrained models
 are available at: https://github.com/MASILab/RepUX-Net
\\ ( https://arxiv.org/abs/2303.05785 ,  3289kb)
------------------------------------------------------------------------------
\\
arXiv:2304.02104 (*cross-listing*)
replaced with revised version Tue, 6 Jun 2023 07:27:32 GMT   (2268kb,D)

Title: Deep learning for diffusion in porous media
Authors: Krzysztof M. Graczyk, Dawid Strzelczyk, Maciej Matyka
Categories: physics.comp-ph cs.CV cs.LG physics.flu-dyn
Comments: 15 pages, 17 figures, to appear in Sci. Rep
\\ ( https://arxiv.org/abs/2304.02104 ,  2268kb)
------------------------------------------------------------------------------
\\
arXiv:2304.08297 (*cross-listing*)
replaced with revised version Tue, 6 Jun 2023 03:03:53 GMT   (4kb)

Title: Comments on 'Fast and scalable search of whole-slide images via
 self-supervised deep learning'
Authors: Milad Sikaroudi, Mehdi Afshari, Abubakr Shafique, Shivam Kalra, H.R.
 Tizhoosh
Categories: eess.IV cs.CV cs.LG
\\ ( https://arxiv.org/abs/2304.08297 ,  4kb)
------------------------------------------------------------------------------
\\
arXiv:2304.13416 (*cross-listing*)
replaced with revised version Tue, 6 Jun 2023 09:44:19 GMT   (12189kb,D)

Title: DiffuseExpand: Expanding dataset for 2D medical image segmentation using
 diffusion models
Authors: Shitong Shao, Xiaohan Yuan, Zhen Huang, Ziming Qiu, Shuai Wang and
 Kevin Zhou
Categories: eess.IV cs.CV
Comments: Accepted by IJCAI workshop (1st International Workshop on
 Generalizing from Limited Resources in the Open World). pre-version was
 rejected by MICCAI
\\ ( https://arxiv.org/abs/2304.13416 ,  12189kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02858
replaced with revised version Tue, 6 Jun 2023 12:28:37 GMT   (2863kb,D)

Title: Video-LLaMA: An Instruction-tuned Audio-Visual Language Model for Video
 Understanding
Authors: Hang Zhang, Xin Li, Lidong Bing
Categories: cs.CL cs.CV cs.SD eess.AS
Comments: Technical Report; Code, Pretrained Model, and Dataset:
 https://github.com/DAMO-NLP-SG/Video-LLaMA
\\ ( https://arxiv.org/abs/2306.02858 ,  2863kb)
------------------------------------------------------------------------------
\\
arXiv:2201.07740
replaced with revised version Tue, 6 Jun 2023 17:18:06 GMT   (309kb,D)

Title: More is Merrier in Collusion Mitigation
Authors: Tiantian Gong, Ryan Henry, Alexandros Psomas, Aniket Kate
Categories: cs.CR cs.GT
Comments: 18 pages, 7 figures
\\ ( https://arxiv.org/abs/2201.07740 ,  309kb)
------------------------------------------------------------------------------
\\
arXiv:1901.09036 (*cross-listing*)
replaced with revised version Tue, 6 Jun 2023 01:44:42 GMT   (1560kb,D)

Title: Orthogonal Statistical Learning
Authors: Dylan J. Foster and Vasilis Syrgkanis
Categories: math.ST cs.LG econ.EM stat.ML stat.TH
Comments: Reorganized, added experiments and additional examples
\\ ( https://arxiv.org/abs/1901.09036 ,  1560kb)
------------------------------------------------------------------------------
\\
arXiv:2004.13612 (*cross-listing*)
replaced with revised version Tue, 6 Jun 2023 09:37:37 GMT   (479kb,D)

Title: Denise: Deep Robust Principal Component Analysis for Positive
 Semidefinite Matrices
Authors: Calypso Herrera, Florian Krach, Anastasis Kratsios, Pierre Ruyssen,
 Josef Teichmann
Categories: stat.ML cs.LG math.OC q-fin.CP
Journal-ref: Transactions on Machine Learning Research (2023)
\\ ( https://arxiv.org/abs/2004.13612 ,  479kb)
------------------------------------------------------------------------------
\\
arXiv:2006.06755 (*cross-listing*)
replaced with revised version Mon, 5 Jun 2023 23:53:27 GMT   (3327kb,D)

Title: Conditional Sampling with Monotone GANs: from Generative Models to
 Likelihood-Free Inference
Authors: Ricardo Baptista, Bamdad Hosseini, Nikola B. Kovachki, Youssef Marzouk
Categories: stat.ML cs.LG stat.CO
Comments: Major expansion of earlier version, with new theoretical results. 33
 pages, 8 figures, 1 table
\\ ( https://arxiv.org/abs/2006.06755 ,  3327kb)
------------------------------------------------------------------------------
\\
arXiv:2101.01366 (*cross-listing*)
replaced with revised version Mon, 5 Jun 2023 23:49:35 GMT   (323kb,D)

Title: A Symmetric Loss Perspective of Reliable Machine Learning
Authors: Nontawat Charoenphakdee, Jongyeong Lee, Masashi Sugiyama
Categories: stat.ML cs.LG
Comments: Invited article preprint
\\ ( https://arxiv.org/abs/2101.01366 ,  323kb)
------------------------------------------------------------------------------
\\
arXiv:2204.06638 (*cross-listing*)
replaced with revised version Tue, 6 Jun 2023 00:15:47 GMT   (34kb,D)

Title: Clifford Circuits can be Properly PAC Learned if and only if
 $\textsf{RP}=\textsf{NP}$
Authors: Daniel Liang
Categories: quant-ph cs.CC cs.LG
Comments: 30 pages, 2 figures
\\ ( https://arxiv.org/abs/2204.06638 ,  34kb)
------------------------------------------------------------------------------
\\
arXiv:2205.02986 (*cross-listing*)
replaced with revised version Tue, 6 Jun 2023 16:20:30 GMT   (160kb,D)

Title: Optimally tackling covariate shift in RKHS-based nonparametric
 regression
Authors: Cong Ma, Reese Pathak, Martin J. Wainwright
Categories: math.ST cs.LG stat.ML stat.TH
Comments: to appear in the Annals of Statistics
\\ ( https://arxiv.org/abs/2205.02986 ,  160kb)
------------------------------------------------------------------------------
\\
arXiv:2211.09801 (*cross-listing*)
replaced with revised version Tue, 6 Jun 2023 15:06:15 GMT   (23703kb,D)

Title: Machine Learned Calabi-Yau Metrics and Curvature
Authors: Per Berglund, Giorgi Butbaia, Tristan H\"ubsch, Vishnu Jejjala,
 Dami\'an Mayorga Pe\~na, Challenger Mishra, Justin Tan
Categories: hep-th cs.LG math.AG math.DG
Comments: Version accepted for publication: 48 pages, 32 figures, 8 tables, 3
 appendices
\\ ( https://arxiv.org/abs/2211.09801 ,  23703kb)
------------------------------------------------------------------------------
\\
arXiv:2211.12600
replaced with revised version Tue, 6 Jun 2023 09:33:37 GMT   (1913kb,D)

Title: ArrayFlex: A Systolic Array Architecture with Configurable Transparent
 Pipelining
Authors: C. Peltekis, D. Filippas, G. Dimitrakopoulos, C. Nicopoulos, D.
 Pnevmatikatos
Categories: cs.AR cs.LG
Comments: DATE 2023
DOI: 10.23919/DATE56975.2023.10136913
\\ ( https://arxiv.org/abs/2211.12600 ,  1913kb)
------------------------------------------------------------------------------
\\
arXiv:2211.17223
replaced with revised version Tue, 6 Jun 2023 11:25:34 GMT   (1360kb,D)

Title: Topological Data Analysis for Speech Processing
Authors: Eduard Tulchinskii, Kristian Kuznetsov, Laida Kushnareva, Daniil
 Cherniavskii, Serguei Barannikov, Irina Piontkovskaya, Sergey Nikolenko,
 Evgeny Burnaev
Categories: cs.SD cs.CL cs.LG eess.AS math.AT
Comments: Accepted to INTERSPEECH 2023 conference
\\ ( https://arxiv.org/abs/2211.17223 ,  1360kb)
------------------------------------------------------------------------------
\\
arXiv:2212.01953 (*cross-listing*)
replaced with revised version Tue, 6 Jun 2023 08:29:28 GMT   (4127kb,D)

Title: Context-aware multi-head self-attentional neural network model for next
 location prediction
Authors: Ye Hong, Yatao Zhang, Konrad Schindler, Martin Raubal
Categories: physics.soc-ph cs.LG
Comments: Updated figures and added more descriptions in Appendix
\\ ( https://arxiv.org/abs/2212.01953 ,  4127kb)
------------------------------------------------------------------------------
\\
arXiv:2301.04761
replaced with revised version Mon, 5 Jun 2023 23:47:43 GMT   (414kb,D)

Title: NarrowBERT: Accelerating Masked Language Model Pretraining and Inference
Authors: Haoxin Li, Phillip Keung, Daniel Cheng, Jungo Kasai, Noah A. Smith
Categories: cs.CL cs.LG
Comments: To appear in ACL 2023 (main conference)
\\ ( https://arxiv.org/abs/2301.04761 ,  414kb)
------------------------------------------------------------------------------
\\
arXiv:2301.06428 (*cross-listing*)
replaced with revised version Tue, 6 Jun 2023 15:37:45 GMT   (1472kb)

Title: Faster Gradient-Free Algorithms for Nonsmooth Nonconvex Stochastic
 Optimization
Authors: Lesi Chen, Jing Xu and Luo Luo
Categories: math.OC cs.LG
Comments: ICML 2023
\\ ( https://arxiv.org/abs/2301.06428 ,  1472kb)
------------------------------------------------------------------------------
\\
arXiv:2302.02563 (*cross-listing*)
replaced with revised version Tue, 6 Jun 2023 16:45:47 GMT   (2787kb,D)

Title: Stochastic Gradient Descent-Induced Drift of Representation in a
 Two-Layer Neural Network
Authors: Farhad Pashakhanloo, Alexei Koulakov
Categories: cond-mat.dis-nn cs.LG
Comments: International Conference on Machine Learning (ICML) 2023
\\ ( https://arxiv.org/abs/2302.02563 ,  2787kb)
------------------------------------------------------------------------------
\\
arXiv:2302.02923 (*cross-listing*)
replaced with revised version Tue, 6 Jun 2023 09:17:12 GMT   (641kb,D)

Title: In Search of Insights, Not Magic Bullets: Towards Demystification of the
 Model Selection Dilemma in Heterogeneous Treatment Effect Estimation
Authors: Alicia Curth, Mihaela van der Schaar
Categories: stat.ML cs.LG econ.EM
Comments: To appear in the Proceedings of the 40th International Conference on
 Machine Learning, Honolulu, Hawaii, USA. PMLR 202, 2023
\\ ( https://arxiv.org/abs/2302.02923 ,  641kb)
------------------------------------------------------------------------------
\\
arXiv:2302.08215
replaced with revised version Tue, 6 Jun 2023 13:09:21 GMT   (48093kb,D)

Title: Aligning Language Models with Preferences through f-divergence
 Minimization
Authors: Dongyoung Go, Tomasz Korbak, Germ\'an Kruszewski, Jos Rozen, Nahyeon
 Ryu, Marc Dymetman
Categories: cs.CL cs.LG stat.ML
\\ ( https://arxiv.org/abs/2302.08215 ,  48093kb)
------------------------------------------------------------------------------
\\
arXiv:2302.12391 (*cross-listing*)
replaced with revised version Tue, 6 Jun 2023 05:34:19 GMT   (130kb,D)

Title: PITS: Variational Pitch Inference without Fundamental Frequency for
 End-to-End Pitch-controllable TTS
Authors: Junhyeok Lee, Wonbin Jung, Hyunjae Cho, Jaeyeon Kim, Jaehwan Kim
Categories: eess.AS cs.LG cs.SD
Comments: 6 pages, preprint
\\ ( https://arxiv.org/abs/2302.12391 ,  130kb)
------------------------------------------------------------------------------
\\
arXiv:2302.14011 (*cross-listing*)
replaced with revised version Tue, 6 Jun 2023 01:33:44 GMT   (1599kb,D)

Title: Causal isotonic calibration for heterogeneous treatment effects
Authors: Lars van der Laan, Ernesto Ulloa-P\'erez, Marco Carone, and Alex
 Luedtke
Categories: stat.ML cs.LG stat.ME
Comments: Accepted to ICML2023
\\ ( https://arxiv.org/abs/2302.14011 ,  1599kb)
------------------------------------------------------------------------------
\\
arXiv:2303.05924 (*cross-listing*)
replaced with revised version Tue, 6 Jun 2023 10:10:51 GMT   (106kb)

Title: Variational formulations of ODE-Net as a mean-field optimal control
 problem and existence results
Authors: Noboru Isobe, Mizuho Okumura
Categories: math.AP cs.LG math.OC
Comments: 33 pages
MSC-class: 49J20 (Primary) 49Q22, 68T07, 35A35 (Secondary)
\\ ( https://arxiv.org/abs/2303.05924 ,  106kb)
------------------------------------------------------------------------------
\\
arXiv:2303.08059 (*cross-listing*)
replaced with revised version Tue, 6 Jun 2023 13:35:42 GMT   (977kb,D)

Title: Fast Rates for Maximum Entropy Exploration
Authors: Daniil Tiapkin, Denis Belomestny, Daniele Calandriello, Eric Moulines,
 Remi Munos, Alexey Naumov, Pierre Perrault, Yunhao Tang, Michal Valko, Pierre
 Menard
Categories: stat.ML cs.LG
Comments: ICML-2023
\\ ( https://arxiv.org/abs/2303.08059 ,  977kb)
------------------------------------------------------------------------------
\\
arXiv:2304.06653
replaced with revised version Tue, 6 Jun 2023 11:56:27 GMT   (1080kb,D)

Title: Graph2topic: an opensource topic modeling framework based on sentence
 embedding and community detection
Authors: Leihang Zhang, Jiapeng Liu, Qiang Yan
Categories: cs.CL cs.LG
Comments: 11pages
\\ ( https://arxiv.org/abs/2304.06653 ,  1080kb)
------------------------------------------------------------------------------
\\
arXiv:2304.10611
replaced with revised version Mon, 5 Jun 2023 18:16:29 GMT   (73kb,D)

Title: Joint Repetition Suppression and Content Moderation of Large Language
 Models
Authors: Minghui Zhang, Alex Sokolov, Weixin Cai, Si-Qing Chen
Categories: cs.CL cs.LG
\\ ( https://arxiv.org/abs/2304.10611 ,  73kb)
------------------------------------------------------------------------------
\\
arXiv:2305.04990
replaced with revised version Tue, 6 Jun 2023 15:31:33 GMT   (7132kb,D)

Title: Explanation-based Finetuning Makes Models More Robust to Spurious Cues
Authors: Josh Magnus Ludan, Yixuan Meng, Tai Nguyen, Saurabh Shah, Qing Lyu,
 Marianna Apidianaki, Chris Callison-Burch
Categories: cs.CL cs.LG
\\ ( https://arxiv.org/abs/2305.04990 ,  7132kb)
------------------------------------------------------------------------------
\\
arXiv:2305.05608
replaced with revised version Tue, 6 Jun 2023 15:02:00 GMT   (2486kb,D)

Title: The Role of Relevance in Fair Ranking
Authors: Aparna Balagopalan, Abigail Z. Jacobs, Asia Biega
Categories: cs.IR cs.CY cs.LG
Comments: Published in SIGIR 2023
DOI: 10.1145/3539618.3591933
\\ ( https://arxiv.org/abs/2305.05608 ,  2486kb)
------------------------------------------------------------------------------
\\
arXiv:2305.07580 (*cross-listing*)
replaced with revised version Tue, 6 Jun 2023 13:20:34 GMT   (3234kb,D)

Title: Fisher Information Embedding for Node and Graph Learning
Authors: Dexiong Chen, Paolo Pellizzoni, Karsten Borgwardt
Categories: stat.ML cs.LG
Comments: ICML 2023
\\ ( https://arxiv.org/abs/2305.07580 ,  3234kb)
------------------------------------------------------------------------------
\\
arXiv:2305.10880 (*cross-listing*)
replaced with revised version Tue, 6 Jun 2023 16:41:35 GMT   (1112kb,D)

Title: Functional sufficient dimension reduction through information
 maximization with application to classification
Authors: Xinyu Li and Jianjun Xu and Wenquan Cui and Haoyang Cheng
Categories: stat.ML cs.LG
\\ ( https://arxiv.org/abs/2305.10880 ,  1112kb)
------------------------------------------------------------------------------
\\
arXiv:2305.19525 (*cross-listing*)
replaced with revised version Tue, 6 Jun 2023 16:21:25 GMT   (1471kb,D)

Title: Discovering New Interpretable Conservation Laws as Sparse Invariants
Authors: Ziming Liu, Patrick Obin Sturm, Saketh Bharadwaj, Sam Silva, Max
 Tegmark
Categories: math.DS cs.LG nlin.SI physics.class-ph physics.flu-dyn
\\ ( https://arxiv.org/abs/2305.19525 ,  1471kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02422 (*cross-listing*)
replaced with revised version Tue, 6 Jun 2023 14:23:42 GMT   (1908kb,D)

Title: A Generalized Alternating Method for Bilevel Learning under the
 Polyak-{\L}ojasiewicz Condition
Authors: Quan Xiao, Songtao Lu, Tianyi Chen
Categories: math.OC cs.LG
\\ ( https://arxiv.org/abs/2306.02422 ,  1908kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03013
replaced with revised version Tue, 6 Jun 2023 14:20:42 GMT   (693kb,D)

Title: Hiding in Plain Sight: Disguising Data Stealing Attacks in Federated
 Learning
Authors: Kostadin Garov, Dimitar I. Dimitrov, Nikola Jovanovi\'c, Martin Vechev
Categories: cs.CR cs.LG
ACM-class: I.2.11
\\ ( https://arxiv.org/abs/2306.03013 ,  693kb)
------------------------------------------------------------------------------
\\
arXiv:2305.05267
replaced with revised version Mon, 5 Jun 2023 21:26:33 GMT   (954kb)

Title: Learning Personalized Page Content Ranking Using Customer Representation
Authors: Xin Shen, Yan Zhao, Sujan Perera, Yujia Liu, Jinyun Yan, Mitchell
 Goodman
Categories: cs.IR cs.MA cs.SI
\\ ( https://arxiv.org/abs/2305.05267 ,  954kb)
------------------------------------------------------------------------------
\\
arXiv:2112.14123 (*cross-listing*)
replaced with revised version Tue, 6 Jun 2023 14:58:44 GMT   (863kb)

Title: Control of dynamic systems with restrictions on input and output signals
Authors: Igor Furtat, Pavel Gushchin, Nguyen Ba Huy
Categories: math.OC cs.SY eess.SY
Comments: in Russian
\\ ( https://arxiv.org/abs/2112.14123 ,  863kb)
------------------------------------------------------------------------------
\\
arXiv:2212.12055
replaced with revised version Tue, 6 Jun 2023 09:00:24 GMT   (19427kb)

Title: DRL-based Energy-Efficient Baseband Function Deployments for
 Service-Oriented Open RAN
Authors: Haiyuan Li, Amin Emami, Karcius Assis, Ruizhi Yang, Reza Nejabati,
 Shuangyi Yan, and Dimitra Simeonidou
Categories: cs.NI cs.SY eess.SY
\\ ( https://arxiv.org/abs/2212.12055 ,  19427kb)
------------------------------------------------------------------------------
\\
arXiv:2212.12677 (*cross-listing*)
replaced with revised version Tue, 6 Jun 2023 07:55:13 GMT   (819kb,D)

Title: Towards a Multimodal Charging Network: Joint Planning of Charging
 Stations and Battery Swapping Stations for Electrified Ride-Hailing Fleets
Authors: Zhijie Lai and Sen Li
Categories: math.OC cs.SY eess.SY
\\ ( https://arxiv.org/abs/2212.12677 ,  819kb)
%%%---%%%---%%%---%%%---%%%---%%%---%%%---%%%---%%%---%%%---%%%---%%%---%%%---