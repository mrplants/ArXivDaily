------------------------------------------------------------------------------
------------------------------------------------------------------------------
Send any comments regarding submissions directly to submitter.
------------------------------------------------------------------------------
Archives at http://arxiv.org/
To unsubscribe, e-mail To: cs@arXiv.org, Subject: cancel
------------------------------------------------------------------------------
Submissions to:
Artificial Intelligence
Computer Vision and Pattern Recognition
Distributed, Parallel, and Cluster Computing
Computer Science and Game Theory
Machine Learning
Multiagent Systems
Robotics
Systems and Control
received from  Mon 12 Jun 23 18:00:00 GMT  to  Tue 13 Jun 23 18:00:00 GMT
------------------------------------------------------------------------------
------------------------------------------------------------------------------
\\
arXiv:2306.07353
Date: Mon, 12 Jun 2023 18:21:23 GMT   (27kb)

Title: HDDL 2.1: Towards Defining a Formalism and a Semantics for Temporal HTN
 Planning
Authors: Damien Pellier, Alexandre Albore, Humbert Fiorino, Rafael Bailon-Ruiz
Categories: cs.AI
Comments: 5 pages, International Workshop of Hierarchical Planning (ICAPS),
 2023
Journal-ref: International Workshop of Hierarchical Planning (ICAPS), 2023
\\
 Real world applications as in industry and robotics need modelling rich and
diverse automated planning problems. Their resolution usually requires
coordinated and concurrent action execution. In several cases, these problems
are naturally decomposed in a hierarchical way and expressed by a Hierarchical
Task Network (HTN) formalism.
 HDDL, a hierarchical extension of the Planning Domain Definition Language
(PDDL), unlike PDDL 2.1 does not allow to represent planning problems with
numerical and temporal constraints, which are essential for real world
applications. We propose to fill the gap between HDDL and these operational
needs and to extend HDDL by taking inspiration from PDDL 2.1 in order to
express numerical and temporal expressions. This paper opens discussions on the
semantics and the syntax needed for a future HDDL 2.1 extension.
\\ ( https://arxiv.org/abs/2306.07353 ,  27kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07429
Date: Mon, 12 Jun 2023 21:15:25 GMT   (15219kb,D)

Title: Explaining CLIP through Co-Creative Drawings and Interaction
Authors: Varvara Guljajeva and Mar Canet Sol\`a and Isaac Joseph Clarke
Categories: cs.AI cs.CV cs.CY
ACM-class: I.2.0; I.2.m
\\
 This paper analyses a visual archive of drawings produced by an interactive
robotic art installation where audience members narrated their dreams into a
system powered by CLIPdraw deep learning (DL) model that interpreted and
transformed their dreams into images. The resulting archive of prompt-image
pairs were examined and clustered based on concept representation accuracy. As
a result of the analysis, the paper proposes four groupings for describing and
explaining CLIP-generated results: clear concept, text-to-text as image,
indeterminacy and confusion, and lost in translation. This article offers a
glimpse into a collection of dreams interpreted, mediated and given form by
Artificial Intelligence (AI), showcasing oftentimes unexpected, visually
compelling or, indeed, the dream-like output of the system, with the emphasis
on processes and results of translations between languages, sign-systems and
various modules of the installation. In the end, the paper argues that proposed
clusters support better understanding of the neural model.
\\ ( https://arxiv.org/abs/2306.07429 ,  15219kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07464
Date: Mon, 12 Jun 2023 23:42:08 GMT   (1839kb,D)

Title: Unlocking Sales Growth: Account Prioritization Engine with Explainable
 AI
Authors: Suvendu Jena, Jilei Yang, Fangfang Tan
Categories: cs.AI cs.LG stat.ML
Comments: 9 pages, 11 figures, 2 tables
\\
 B2B sales requires effective prediction of customer growth, identification of
upsell potential, and mitigation of churn risks. LinkedIn sales representatives
traditionally relied on intuition and fragmented data signals to assess
customer performance. This resulted in significant time investment in data
understanding as well as strategy formulation and under-investment in active
selling. To overcome this challenge, we developed a data product called Account
Prioritizer, an intelligent sales account prioritization engine. It uses
machine learning recommendation models and integrated account-level explanation
algorithms within the sales CRM to automate the manual process of sales book
prioritization. A successful A/B test demonstrated that the Account Prioritizer
generated a substantial +8.08% increase in renewal bookings for the LinkedIn
Business.
\\ ( https://arxiv.org/abs/2306.07464 ,  1839kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07542
Date: Tue, 13 Jun 2023 05:22:30 GMT   (4514kb,D)

Title: A Versatile Multi-Agent Reinforcement Learning Benchmark for Inventory
 Management
Authors: Xianliang Yang, Zhihao Liu, Wei Jiang, Chuheng Zhang, Li Zhao, Lei
 Song, Jiang Bian
Categories: cs.AI
\\
 Multi-agent reinforcement learning (MARL) models multiple agents that
interact and learn within a shared environment. This paradigm is applicable to
various industrial scenarios such as autonomous driving, quantitative trading,
and inventory management. However, applying MARL to these real-world scenarios
is impeded by many challenges such as scaling up, complex agent interactions,
and non-stationary dynamics. To incentivize the research of MARL on these
challenges, we develop MABIM (Multi-Agent Benchmark for Inventory Management)
which is a multi-echelon, multi-commodity inventory management simulator that
can generate versatile tasks with these different challenging properties. Based
on MABIM, we evaluate the performance of classic operations research (OR)
methods and popular MARL algorithms on these challenging tasks to highlight
their weaknesses and potential.
\\ ( https://arxiv.org/abs/2306.07542 ,  4514kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07635
Date: Tue, 13 Jun 2023 09:11:17 GMT   (118kb,D)

Title: Exploiting Configurations of MaxSAT Solvers
Authors: Josep Al\`os, Carlos Ans\'otegui, Josep M. Salvia, Eduard Torres
Categories: cs.AI
\\
 In this paper, we describe how we can effectively exploit alternative
parameter configurations to a MaxSAT solver. We describe how these
configurations can be computed in the context of MaxSAT. In particular, we
experimentally show how to easily combine configurations of a non-competitive
solver to obtain a better solving approach.
\\ ( https://arxiv.org/abs/2306.07635 ,  118kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07637
Date: Tue, 13 Jun 2023 09:16:38 GMT   (7941kb,D)

Title: For Better or Worse: The Impact of Counterfactual Explanations'
 Directionality on User Behavior in xAI
Authors: Ulrike Kuhl and Andr\'e Artelt and Barbara Hammer
Categories: cs.AI cs.HC
Comments: 22 pages, 3 figures This work has been accepted for presentation at
 the 1st World Conference on eXplainable Artificial Intelligence (xAI 2023),
 July 26-28, 2023 - Lisbon, Portugal
\\
 Counterfactual explanations (CFEs) are a popular approach in explainable
artificial intelligence (xAI), highlighting changes to input data necessary for
altering a model's output. A CFE can either describe a scenario that is better
than the factual state (upward CFE), or a scenario that is worse than the
factual state (downward CFE). However, potential benefits and drawbacks of the
directionality of CFEs for user behavior in xAI remain unclear. The current
user study (N=161) compares the impact of CFE directionality on behavior and
experience of participants tasked to extract new knowledge from an automated
system based on model predictions and CFEs. Results suggest that upward CFEs
provide a significant performance advantage over other forms of counterfactual
feedback. Moreover, the study highlights potential benefits of mixed CFEs
improving user performance compared to downward CFEs or no explanations. In
line with the performance results, users' explicit knowledge of the system is
statistically higher after receiving upward CFEs compared to downward
comparisons. These findings imply that the alignment between explanation and
task at hand, the so-called regulatory fit, may play a crucial role in
determining the effectiveness of model explanations, informing future research
directions in xAI. To ensure reproducible research, the entire code, underlying
models and user data of this study is openly available:
https://github.com/ukuhl/DirectionalAlienZoo
\\ ( https://arxiv.org/abs/2306.07637 ,  7941kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07638
Date: Tue, 13 Jun 2023 09:17:12 GMT   (146kb,D)

Title: On Guiding Search in HTN Temporal Planning with non Temporal Heuristics
Authors: Nicolas Cavrel, Damien Pellier, Humbert Fiorino
Categories: cs.AI
Journal-ref: ICAPS Hierarchical Planning Workshop, 2023
\\
 The Hierarchical Task Network (HTN) formalism is used to express a wide
variety of planning problems as task decompositions, and many techniques have
been proposed to solve them. However, few works have been done on temporal HTN.
This is partly due to the lack of a formal and consensual definition of what a
temporal hierarchical planning problem is as well as the difficulty to develop
heuristics in this context. In response to these inconveniences, we propose in
this paper a new general POCL (Partial Order Causal Link) approach to represent
and solve a temporal HTN problem by using existing heuristics developed to
solve non temporal problems. We show experimentally that this approach is
performant and can outperform the existing ones.
\\ ( https://arxiv.org/abs/2306.07638 ,  146kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07662
Date: Tue, 13 Jun 2023 10:12:05 GMT   (91kb)

Title: Temporalising Unique Characterisability and Learnability of
 Ontology-Mediated Queries
Authors: Jean Christoph Jung, Vladislav Ryzhikov, Frank Wolter, Michael
 Zakharyaschev
Categories: cs.AI cs.DB cs.LO
ACM-class: I.2.4; F.4.1
\\
 Recently, the study of the unique characterisability and learnability of
database queries by means of examples has been extended to ontology-mediated
queries. Here, we study in how far the obtained results can be lifted to
temporalised ontology-mediated queries. We provide a systematic introduction to
the relevant approaches in the non-temporal case and then show general transfer
results pinpointing under which conditions existing results can be lifted to
temporalised queries.
\\ ( https://arxiv.org/abs/2306.07662 ,  91kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07675
Date: Tue, 13 Jun 2023 10:41:28 GMT   (841kb,D)

Title: An Interleaving Semantics of the Timed Concurrent Language for
 Argumentation to Model Debates and Dialogue Games
Authors: Stefano Bistarelli, Maria Chiara Meo, Carlo Taticchi
Categories: cs.AI
Comments: Under consideration in Theory and Practice of Logic Programming
 (TPLP)
\\
 Time is a crucial factor in modelling dynamic behaviours of intelligent
agents: activities have a determined temporal duration in a real-world
environment, and previous actions influence agents' behaviour. In this paper,
we propose a language for modelling concurrent interaction between agents that
also allows the specification of temporal intervals in which particular actions
occur. Such a language exploits a timed version of Abstract Argumentation
Frameworks to realise a shared memory used by the agents to communicate and
reason on the acceptability of their beliefs with respect to a given time
interval. An interleaving model on a single processor is used for basic
computation steps, with maximum parallelism for time elapsing. Following this
approach, only one of the enabled agents is executed at each moment. To
demonstrate the capabilities of language, we also show how it can be used to
model interactions such as debates and dialogue games taking place between
intelligent agents. Lastly, we present an implementation of the language that
can be accessed via a web interface. Under consideration in Theory and Practice
of Logic Programming (TPLP).
\\ ( https://arxiv.org/abs/2306.07675 ,  841kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07706
Date: Tue, 13 Jun 2023 11:49:44 GMT   (1650kb,D)

Title: Towards Explainable TOPSIS: Visual Insights into the Effects of Weights
 and Aggregations on Rankings
Authors: Robert Susmaga, Izabela Szczech, Dariusz Brzezinski
Categories: cs.AI
\\
 Multi-Criteria Decision Analysis (MCDA) is extensively used across diverse
industries to assess and rank alternatives. Among numerous MCDA methods
developed to solve real-world ranking problems, TOPSIS remains one of the most
popular choices in many application areas. TOPSIS calculates distances between
the considered alternatives and two predefined ones, namely the ideal and the
anti-ideal, and creates a ranking of the alternatives according to a chosen
aggregation of these distances. However, the interpretation of the inner
workings of TOPSIS is difficult, especially when the number of criteria is
large. To this end, recent research has shown that TOPSIS aggregations can be
expressed using the means (M) and standard deviations (SD) of alternatives,
creating MSD-space, a tool for visualizing and explaining aggregations. Even
though MSD-space is highly useful, it assumes equally important criteria,
making it less applicable to real-world ranking problems. In this paper, we
generalize the concept of MSD-space to weighted criteria by introducing the
concept of WMSD-space defined by what is referred to as weight-scaled means and
standard deviations. We demonstrate that TOPSIS and similar distance-based
aggregation methods can be successfully illustrated in a plane and interpreted
even when the criteria are weighted, regardless of their number. The proposed
WMSD-space offers a practical method for explaining TOPSIS rankings in
real-world decision problems.
\\ ( https://arxiv.org/abs/2306.07706 ,  1650kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07719
Date: Tue, 13 Jun 2023 12:13:41 GMT   (766kb,D)

Title: Contextual Dictionary Lookup for Knowledge Graph Completion
Authors: Jining Wang, Delai Qiu, YouMing Liu, Yining Wang, Chuan Chen, Zibin
 Zheng, Yuren Zhou
Categories: cs.AI
\\
 Knowledge graph completion (KGC) aims to solve the incompleteness of
knowledge graphs (KGs) by predicting missing links from known triples, numbers
of knowledge graph embedding (KGE) models have been proposed to perform KGC by
learning embeddings. Nevertheless, most existing embedding models map each
relation into a unique vector, overlooking the specific fine-grained semantics
of them under different entities. Additionally, the few available fine-grained
semantic models rely on clustering algorithms, resulting in limited performance
and applicability due to the cumbersome two-stage training process. In this
paper, we present a novel method utilizing contextual dictionary lookup,
enabling conventional embedding models to learn fine-grained semantics of
relations in an end-to-end manner. More specifically, we represent each
relation using a dictionary that contains multiple latent semantics. The
composition of a given entity and the dictionary's central semantics serves as
the context for generating a lookup, thus determining the fine-grained
semantics of the relation adaptively. The proposed loss function optimizes both
the central and fine-grained semantics simultaneously to ensure their semantic
consistency. Besides, we introduce two metrics to assess the validity and
accuracy of the dictionary lookup operation. We extend several KGE models with
the method, resulting in substantial performance improvements on widely-used
benchmark datasets.
\\ ( https://arxiv.org/abs/2306.07719 ,  766kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07743
Date: Tue, 13 Jun 2023 13:00:10 GMT   (8434kb,D)

Title: V-LoL: A Diagnostic Dataset for Visual Logical Learning
Authors: Lukas Helff, Wolfgang Stammer, Hikaru Shindo, Devendra Singh Dhami,
 Kristian Kersting
Categories: cs.AI cs.CV cs.LG
\\
 Despite the successes of recent developments in visual AI, different
shortcomings still exist; from missing exact logical reasoning, to abstract
generalization abilities, to understanding complex and noisy scenes.
Unfortunately, existing benchmarks, were not designed to capture more than a
few of these aspects. Whereas deep learning datasets focus on visually complex
data but simple visual reasoning tasks, inductive logic datasets involve
complex logical learning tasks, however, lack the visual component. To address
this, we propose the visual logical learning dataset, V-LoL, that seamlessly
combines visual and logical challenges. Notably, we introduce the first
instantiation of V-LoL, V-LoL-Trains, -- a visual rendition of a classic
benchmark in symbolic AI, the Michalski train problem. By incorporating
intricate visual scenes and flexible logical reasoning tasks within a versatile
framework, V-LoL-Trains provides a platform for investigating a wide range of
visual logical learning challenges. We evaluate a variety of AI systems
including traditional symbolic AI, neural AI, as well as neuro-symbolic AI. Our
evaluations demonstrate that even state-of-the-art AI faces difficulties in
dealing with visual logical learning challenges, highlighting unique advantages
and limitations specific to each methodology. Overall, V-LoL opens up new
avenues for understanding and enhancing current abilities in visual logical
learning for AI systems.
\\ ( https://arxiv.org/abs/2306.07743 ,  8434kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07856
Date: Tue, 13 Jun 2023 15:35:01 GMT   (4748kb,D)

Title: DreamDecompiler: Improved Bayesian Program Learning by Decompiling
 Amortised Knowledge
Authors: Alessandro B. Palmarini, Christopher G. Lucas, N. Siddharth
Categories: cs.AI cs.LG cs.SE
\\
 Solving program induction problems requires searching through an enormous
space of possibilities. DreamCoder is an inductive program synthesis system
that, whilst solving problems, learns to simplify search in an iterative
wake-sleep procedure. The cost of search is amortised by training a neural
search policy, reducing search breadth and effectively "compiling" useful
information to compose program solutions across tasks. Additionally, a library
of program components is learnt to express discovered solutions in fewer
components, reducing search depth. In DreamCoder, the neural search policy has
only an indirect effect on the library learnt through the program solutions it
helps discover. We present an approach for library learning that directly
leverages the neural search policy, effectively "decompiling" its amortised
knowledge to extract relevant program components. This provides stronger
amortised inference: the amortised knowledge learnt to reduce search breadth is
now also used to reduce search depth. We integrate our approach with DreamCoder
and demonstrate faster domain proficiency with improved generalisation on a
range of domains, particularly when fewer example solutions are available.
\\ ( https://arxiv.org/abs/2306.07856 ,  4748kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07863
Date: Tue, 13 Jun 2023 15:49:41 GMT   (363kb,D)

Title: Synapse: Leveraging Few-Shot Exemplars for Human-Level Computer Control
Authors: Longtao Zheng, Rundong Wang, Bo An
Categories: cs.AI
\\
 This paper investigates the design of few-shot exemplars for computer
automation through prompting large language models (LLMs). While previous
prompting approaches focus on self-correction, we find that well-structured
exemplars alone are sufficient for human-level performance. We present Synapse,
an in-context computer control agent demonstrating human-level performance on
the MiniWob++ benchmark. Synapse consists of three main components: 1)
state-conditional decomposition, which divides demonstrations into exemplar
sets based on the agent's need for new environment states, enabling temporal
abstraction; 2) structured prompting, which filters states and reformulates
task descriptions for each set to improve planning correctness; and 3) exemplar
retrieval, which associates incoming tasks with corresponding exemplars in an
exemplar database for multi-task adaptation and generalization. Synapse
overcomes context length limits, reduces errors in multi-step control, and
allows for more exemplars within the context. Importantly, Synapse complements
existing prompting approaches that enhance LLMs' reasoning and planning
abilities. Synapse outperforms previous methods, including behavioral cloning,
reinforcement learning, finetuning, and prompting, with an average success rate
of $98.5\%$ across 63 tasks in MiniWob++. Notably, Synapse relies on exemplars
from only 47 tasks, demonstrating effective generalization to novel tasks. Our
results highlight the potential of in-context learning to advance the
integration of LLMs into practical tool automation.
\\ ( https://arxiv.org/abs/2306.07863 ,  363kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07306
Date: Mon, 12 Jun 2023 04:51:32 GMT   (5807kb,D)

Title: Active Globally Explainable Learning for Medical Images via Class
 Association Embedding and Cyclic Adversarial Generation
Authors: Ruitao Xie, Jingbang Chen, Limai Jiang, Rui Xiao, Yi Pan, Yunpeng Cai
Categories: cs.CV cs.AI
\\
 Explainability poses a major challenge to artificial intelligence (AI)
techniques. Current studies on explainable AI (XAI) lack the efficiency of
extracting global knowledge about the learning task, thus suffer deficiencies
such as imprecise saliency, context-aware absence and vague meaning. In this
paper, we propose the class association embedding (CAE) approach to address
these issues. We employ an encoder-decoder architecture to embed sample
features and separate them into class-related and individual-related style
vectors simultaneously. Recombining the individual-style code of a given sample
with the class-style code of another leads to a synthetic sample with preserved
individual characters but changed class assignment, following a cyclic
adversarial learning strategy. Class association embedding distills the global
class-related features of all instances into a unified domain with well
separation between classes. The transition rules between different classes can
be then extracted and further employed to individual instances. We then propose
an active XAI framework which manipulates the class-style vector of a certain
sample along guided paths towards the counter-classes, resulting in a series of
counter-example synthetic samples with identical individual characters.
Comparing these counterfactual samples with the original ones provides a
global, intuitive illustration to the nature of the classification tasks. We
adopt the framework on medical image classification tasks, which show that more
precise saliency maps with powerful context-aware representation can be
achieved compared with existing methods. Moreover, the disease pathology can be
directly visualized via traversing the paths in the class-style space.
\\ ( https://arxiv.org/abs/2306.07306 ,  5807kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07346
Date: Mon, 12 Jun 2023 18:12:19 GMT   (1179kb,D)

Title: Learning to Mask and Permute Visual Tokens for Vision Transformer
 Pre-Training
Authors: Lorenzo Baraldi, Roberto Amoroso, Marcella Cornia, Lorenzo Baraldi,
 Andrea Pilzer, Rita Cucchiara
Categories: cs.CV cs.AI cs.MM
\\
 The use of self-supervised pre-training has emerged as a promising approach
to enhance the performance of visual tasks such as image classification. In
this context, recent approaches have employed the Masked Image Modeling
paradigm, which pre-trains a backbone by reconstructing visual tokens
associated with randomly masked image patches. This masking approach, however,
introduces noise into the input data during pre-training, leading to
discrepancies that can impair performance during the fine-tuning phase.
Furthermore, input masking neglects the dependencies between corrupted patches,
increasing the inconsistencies observed in downstream fine-tuning tasks. To
overcome these issues, we propose a new self-supervised pre-training approach,
named Masked and Permuted Vision Transformer (MaPeT), that employs
autoregressive and permuted predictions to capture intra-patch dependencies. In
addition, MaPeT employs auxiliary positional information to reduce the
disparity between the pre-training and fine-tuning phases. In our experiments,
we employ a fair setting to ensure reliable and meaningful comparisons and
conduct investigations on multiple visual tokenizers, including our proposed
$k$-CLIP which directly employs discretized CLIP features. Our results
demonstrate that MaPeT achieves competitive performance on ImageNet, compared
to baselines and competitors under the same model setting. Source code and
trained models are publicly available at: https://github.com/aimagelab/MaPeT.
\\ ( https://arxiv.org/abs/2306.07346 ,  1179kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07365
Date: Mon, 12 Jun 2023 18:44:08 GMT   (1889kb)

Title: Intelligent Multi-channel Meta-imagers for Accelerating Machine Vision
Authors: Hanyu Zheng, Quan Liu, Ivan I. Kravchenko, Xiaomeng Zhang, Yuankai
 Huo, and Jason G. Valentine
Categories: cs.CV physics.optics
Comments: 15 pages, 5 figures
\\
 Rapid developments in machine vision have led to advances in a variety of
industries, from medical image analysis to autonomous systems. These
achievements, however, typically necessitate digital neural networks with heavy
computational requirements, which are limited by high energy consumption and
further hinder real-time decision-making when computation resources are not
accessible. Here, we demonstrate an intelligent meta-imager that is designed to
work in concert with a digital back-end to off-load computationally expensive
convolution operations into high-speed and low-power optics. In this
architecture, metasurfaces enable both angle and polarization multiplexing to
create multiple information channels that perform positive and negatively
valued convolution operations in a single shot. The meta-imager is employed for
object classification, experimentally achieving 98.6% accurate classification
of handwritten digits and 88.8% accuracy in classifying fashion images. With
compactness, high speed, and low power consumption, this approach could find a
wide range of applications in artificial intelligence and machine vision
applications.
\\ ( https://arxiv.org/abs/2306.07365 ,  1889kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07383
Date: Mon, 12 Jun 2023 19:17:44 GMT   (4469kb)

Title: Supervised Deep Learning for Content-Aware Image Retargeting with
 Fourier Convolutions
Authors: MohammadHossein Givkashi, MohammadReza Naderi, Nader Karimi, Shahram
 Shirani, Shadrokh Samavi
Categories: cs.CV eess.IV
Comments: 18 pages, 5 figures
\\
 Image retargeting aims to alter the size of the image with attention to the
contents. One of the main obstacles to training deep learning models for image
retargeting is the need for a vast labeled dataset. Labeled datasets are
unavailable for training deep learning models in the image retargeting tasks.
As a result, we present a new supervised approach for training deep learning
models. We use the original images as ground truth and create inputs for the
model by resizing and cropping the original images. A second challenge is
generating different image sizes in inference time. However, regular
convolutional neural networks cannot generate images of different sizes than
the input image. To address this issue, we introduced a new method for
supervised learning. In our approach, a mask is generated to show the desired
size and location of the object. Then the mask and the input image are fed to
the network. Comparing image retargeting methods and our proposed method
demonstrates the model's ability to produce high-quality retargeted images.
Afterward, we compute the image quality assessment score for each output image
based on different techniques and illustrate the effectiveness of our approach.
\\ ( https://arxiv.org/abs/2306.07383 ,  4469kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07399
Date: Mon, 12 Jun 2023 19:59:27 GMT   (21481kb,D)

Title: 4DHumanOutfit: a multi-subject 4D dataset of human motion sequences in
 varying outfits exhibiting large displacements
Authors: Matthieu Armando, Laurence Boissieux, Edmond Boyer, Jean-Sebastien
 Franco, Martin Humenberger, Christophe Legras, Vincent Leroy, Mathieu Marsot,
 Julien Pansiot, Sergi Pujades, Rim Rekik, Gregory Rogez, Anilkumar Swamy,
 Stefanie Wuhrer
Categories: cs.CV
\\
 This work presents 4DHumanOutfit, a new dataset of densely sampled
spatio-temporal 4D human motion data of different actors, outfits and motions.
The dataset is designed to contain different actors wearing different outfits
while performing different motions in each outfit. In this way, the dataset can
be seen as a cube of data containing 4D motion sequences along 3 axes with
identity, outfit and motion. This rich dataset has numerous potential
applications for the processing and creation of digital humans, e.g. augmented
reality, avatar creation and virtual try on. 4DHumanOutfit is released for
research purposes at https://kinovis.inria.fr/4dhumanoutfit/. In addition to
image data and 4D reconstructions, the dataset includes reference solutions for
each axis. We present independent baselines along each axis that demonstrate
the value of these reference solutions for evaluation tasks.
\\ ( https://arxiv.org/abs/2306.07399 ,  21481kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07404
Date: Mon, 12 Jun 2023 20:12:02 GMT   (15068kb,D)

Title: Compositor: Bottom-up Clustering and Compositing for Robust Part and
 Object Segmentation
Authors: Ju He, Jieneng Chen, Ming-Xian Lin, Qihang Yu, Alan Yuille
Categories: cs.CV
\\
 In this work, we present a robust approach for joint part and object
segmentation. Specifically, we reformulate object and part segmentation as an
optimization problem and build a hierarchical feature representation including
pixel, part, and object-level embeddings to solve it in a bottom-up clustering
manner. Pixels are grouped into several clusters where the part-level
embeddings serve as cluster centers. Afterwards, object masks are obtained by
compositing the part proposals. This bottom-up interaction is shown to be
effective in integrating information from lower semantic levels to higher
semantic levels. Based on that, our novel approach Compositor produces part and
object segmentation masks simultaneously while improving the mask quality.
Compositor achieves state-of-the-art performance on PartImageNet and
Pascal-Part by outperforming previous methods by around 0.9% and 1.3% on
PartImageNet, 0.4% and 1.7% on Pascal-Part in terms of part and object mIoU and
demonstrates better robustness against occlusion by around 4.4% and 7.1% on
part and object respectively. Code will be available at
https://github.com/TACJu/Compositor.
\\ ( https://arxiv.org/abs/2306.07404 ,  15068kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07437
Date: Mon, 12 Jun 2023 21:45:18 GMT   (24563kb,D)

Title: Instant Multi-View Head Capture through Learnable Registration
Authors: Timo Bolkart and Tianye Li and Michael J. Black
Categories: cs.CV
Comments: Conference on Computer Vision and Pattern Recognition (CVPR) 2023
\\
 Existing methods for capturing datasets of 3D heads in dense semantic
correspondence are slow, and commonly address the problem in two separate
steps; multi-view stereo (MVS) reconstruction followed by non-rigid
registration. To simplify this process, we introduce TEMPEH (Towards Estimation
of 3D Meshes from Performances of Expressive Heads) to directly infer 3D heads
in dense correspondence from calibrated multi-view images. Registering datasets
of 3D scans typically requires manual parameter tuning to find the right
balance between accurately fitting the scans surfaces and being robust to
scanning noise and outliers. Instead, we propose to jointly register a 3D head
dataset while training TEMPEH. Specifically, during training we minimize a
geometric loss commonly used for surface registration, effectively leveraging
TEMPEH as a regularizer. Our multi-view head inference builds on a volumetric
feature representation that samples and fuses features from each view using
camera calibration information. To account for partial occlusions and a large
capture volume that enables head movements, we use view- and surface-aware
feature fusion, and a spatial transformer-based head localization module,
respectively. We use raw MVS scans as supervision during training, but, once
trained, TEMPEH directly predicts 3D heads in dense correspondence without
requiring scans. Predicting one head takes about 0.3 seconds with a median
reconstruction error of 0.26 mm, 64% lower than the current state-of-the-art.
This enables the efficient capture of large datasets containing multiple people
and diverse facial motions. Code, model, and data are publicly available at
https://tempeh.is.tue.mpg.de.
\\ ( https://arxiv.org/abs/2306.07437 ,  24563kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07470
Date: Tue, 13 Jun 2023 00:13:11 GMT   (1378kb,D)

Title: Reviving Shift Equivariance in Vision Transformers
Authors: Peijian Ding, Davit Soselia, Thomas Armstrong, Jiahao Su, and Furong
 Huang
Categories: cs.CV cs.AI
Comments: 9 pages, 3 figures
\\
 Shift equivariance is a fundamental principle that governs how we perceive
the world - our recognition of an object remains invariant with respect to
shifts. Transformers have gained immense popularity due to their effectiveness
in both language and vision tasks. While the self-attention operator in vision
transformers (ViT) is permutation-equivariant and thus shift-equivariant, patch
embedding, positional encoding, and subsampled attention in ViT variants can
disrupt this property, resulting in inconsistent predictions even under small
shift perturbations. Although there is a growing trend in incorporating the
inductive bias of convolutional neural networks (CNNs) into vision
transformers, it does not fully address the issue. We propose an adaptive
polyphase anchoring algorithm that can be seamlessly integrated into vision
transformer models to ensure shift-equivariance in patch embedding and
subsampled attention modules, such as window attention and global subsampled
attention. Furthermore, we utilize depth-wise convolution to encode positional
information. Our algorithms enable ViT, and its variants such as Twins to
achieve 100% consistency with respect to input shift, demonstrate robustness to
cropping, flipping, and affine transformations, and maintain consistent
predictions even when the original models lose 20 percentage points on average
when shifted by just a few pixels with Twins' accuracy dropping from 80.57% to
62.40%.
\\ ( https://arxiv.org/abs/2306.07470 ,  1378kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07476
Date: Tue, 13 Jun 2023 00:43:47 GMT   (20904kb,D)

Title: AniFaceDrawing: Anime Portrait Exploration during Your Sketching
Authors: Zhengyu Huang, Haoran Xie, Tsukasa Fukusato, Kazunori Miyata
Categories: cs.CV cs.GR
Comments: 11 pages, 13 figures. SIGGRAPH 2023 Conference Track. Project
 webpage: http://www.jaist.ac.jp/~xie/AniFaceDrawing.html
\\
 In this paper, we focus on how artificial intelligence (AI) can be used to
assist users in the creation of anime portraits, that is, converting rough
sketches into anime portraits during their sketching process. The input is a
sequence of incomplete freehand sketches that are gradually refined stroke by
stroke, while the output is a sequence of high-quality anime portraits that
correspond to the input sketches as guidance. Although recent GANs can generate
high quality images, it is a challenging problem to maintain the high quality
of generated images from sketches with a low degree of completion due to
ill-posed problems in conditional image generation. Even with the latest
sketch-to-image (S2I) technology, it is still difficult to create high-quality
images from incomplete rough sketches for anime portraits since anime style
tend to be more abstract than in realistic style. To address this issue, we
adopt a latent space exploration of StyleGAN with a two-stage training
strategy. We consider the input strokes of a freehand sketch to correspond to
edge information-related attributes in the latent structural code of StyleGAN,
and term the matching between strokes and these attributes stroke-level
disentanglement. In the first stage, we trained an image encoder with the
pre-trained StyleGAN model as a teacher encoder. In the second stage, we
simulated the drawing process of the generated images without any additional
data (labels) and trained the sketch encoder for incomplete progressive
sketches to generate high-quality portrait images with feature alignment to the
disentangled representations in the teacher encoder. We verified the proposed
progressive S2I system with both qualitative and quantitative evaluations and
achieved high-quality anime portraits from incomplete progressive sketches. Our
user study proved its effectiveness in art creation assistance for the anime
style.
\\ ( https://arxiv.org/abs/2306.07476 ,  20904kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07483
Date: Tue, 13 Jun 2023 01:09:18 GMT   (1292kb,D)

Title: Semi-supervised learning made simple with self-supervised clustering
Authors: Enrico Fini and Pietro Astolfi and Karteek Alahari and Xavier
 Alameda-Pineda and Julien Mairal and Moin Nabi and Elisa Ricci
Categories: cs.CV
Comments: CVPR 2023 - Code available at
 https://github.com/pietroastolfi/suave-daino
Journal-ref: Proceedings of the IEEE/CVF Conference on Computer Vision and
 Pattern Recognition (2023) 3187-3197
\\
 Self-supervised learning models have been shown to learn rich visual
representations without requiring human annotations. However, in many
real-world scenarios, labels are partially available, motivating a recent line
of work on semi-supervised methods inspired by self-supervised principles. In
this paper, we propose a conceptually simple yet empirically powerful approach
to turn clustering-based self-supervised methods such as SwAV or DINO into
semi-supervised learners. More precisely, we introduce a multi-task framework
merging a supervised objective using ground-truth labels and a self-supervised
objective relying on clustering assignments with a single cross-entropy loss.
This approach may be interpreted as imposing the cluster centroids to be class
prototypes. Despite its simplicity, we provide empirical evidence that our
approach is highly effective and achieves state-of-the-art performance on
CIFAR100 and ImageNet.
\\ ( https://arxiv.org/abs/2306.07483 ,  1292kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07490
Date: Tue, 13 Jun 2023 01:42:18 GMT   (7712kb,D)

Title: Grounded Image Captioning in Top-down View
Authors: Chen Cai, Suchen Wang, Kim-hui Yap
Categories: cs.CV
\\
 Weakly supervised grounded image captioning (WSGIC) aims to generate the
caption and ground (localize) predicted object words in the input image without
using bounding box supervision. Recent two-stage solutions mostly apply a
bottom-up pipeline: (1) first apply an off-the-shelf object detector to encode
the input image into multiple region features; (2) and then leverage a
soft-attention mechanism for captioning and grounding. However, object
detectors are mainly designed to extract object semantics (i.e., the object
category). Besides, they break down the structural images into pieces of
individual proposals. As a result, the subsequent grounded captioner is often
overfitted to find the correct object words, while overlooking the relation
between objects (e.g., what is the person doing?), and selecting incompatible
proposal regions for grounding. To address these difficulties, we propose a
one-stage weakly supervised grounded captioner that directly takes the RGB
image as input to perform captioning and grounding at the top-down image level.
In addition, we explicitly inject a relation module into our one-stage
framework to encourage the relation understanding through multi-label
classification. The relation semantics aid the prediction of relation words in
the caption. We observe that the relation words not only assist the grounded
captioner in generating a more accurate caption but also improve the grounding
performance. We validate the effectiveness of our proposed method on two
challenging datasets (Flick30k Entities captioning and MSCOCO captioning). The
experimental results demonstrate that our method achieves state-of-the-art
grounding performance.
\\ ( https://arxiv.org/abs/2306.07490 ,  7712kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07515
Date: Tue, 13 Jun 2023 02:57:32 GMT   (15426kb,D)

Title: A Survey on Video Moment Localization
Authors: Meng Liu, Liqiang Nie, Yunxiao Wang, Meng Wang, Yong Rui
Categories: cs.CV
Journal-ref: ACM Comput. Surv. 55, 9, Article 188 (September 2023)
\\
 Video moment localization, also known as video moment retrieval, aiming to
search a target segment within a video described by a given natural language
query. Beyond the task of temporal action localization whereby the target
actions are pre-defined, video moment retrieval can query arbitrary complex
activities. In this survey paper, we aim to present a comprehensive review of
existing video moment localization techniques, including supervised, weakly
supervised, and unsupervised ones. We also review the datasets available for
video moment localization and group results of related work. In addition, we
discuss promising future directions for this field, in particular large-scale
datasets and interpretable video moment localization models.
\\ ( https://arxiv.org/abs/2306.07515 ,  15426kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07520
Date: Tue, 13 Jun 2023 03:25:33 GMT   (3545kb,D)

Title: Retrieve Anyone: A General-purpose Person Re-identification Task with
 Instructions
Authors: Weizhen He and Shixiang Tang and Yiheng Deng and Qihao Chen and
 Qingsong Xie and Yizhou Wang and Lei Bai and Feng Zhu and Rui Zhao and Wanli
 Ouyang and Donglian Qi and Yunfeng Yan
Categories: cs.CV
\\
 Human intelligence can retrieve any person according to both visual and
language descriptions. However, the current computer vision community studies
specific person re-identification (ReID) tasks in different scenarios
separately, which limits the applications in the real world. This paper strives
to resolve this problem by proposing a new instruct-ReID task that requires the
model to retrieve images according to the given image or language
instructions.Our instruct-ReID is a more general ReID setting, where existing
ReID tasks can be viewed as special cases by designing different instructions.
We propose a large-scale OmniReID benchmark and an adaptive triplet loss as a
baseline method to facilitate research in this new setting. Experimental
results show that the baseline model trained on our OmniReID benchmark can
improve +0.5%, +3.3% mAP on Market1501 and CUHK03 for traditional ReID, +2.1%,
+0.2%, +15.3% mAP on PRCC, VC-Clothes, LTCC for clothes-changing ReID, +12.5%
mAP on COCAS+ real2 for clothestemplate based clothes-changing ReID when using
only RGB images, +25.5% mAP on COCAS+ real2 for our newly defined
language-instructed ReID. The dataset, model, and code will be available at
https://github.com/hwz-zju/Instruct-ReID.
\\ ( https://arxiv.org/abs/2306.07520 ,  3545kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07532
Date: Tue, 13 Jun 2023 04:15:37 GMT   (5137kb,D)

Title: Referring Camouflaged Object Detection
Authors: Xuying Zhang, Bowen Yin, Zheng Lin, Qibin Hou, Deng-Ping Fan,
 Ming-Ming Cheng
Categories: cs.CV
\\
 In this paper, we consider the problem of referring camouflaged object
detection (Ref-COD), a new task that aims to segment specified camouflaged
objects based on some form of reference, e.g., image, text. We first assemble a
large-scale dataset, called R2C7K, which consists of 7K images covering 64
object categories in real-world scenarios. Then, we develop a simple but strong
dual-branch framework, dubbed R2CNet, with a reference branch learning common
representations from the referring information and a segmentation branch
identifying and segmenting camouflaged objects under the guidance of the common
representations. In particular, we design a Referring Mask Generation module to
generate pixel-level prior mask and a Referring Feature Enrichment module to
enhance the capability of identifying camouflaged objects. Extensive
experiments show the superiority of our Ref-COD methods over their COD
counterparts in segmenting specified camouflaged objects and identifying the
main body of target objects. Our code and dataset are publicly available at
https://github.com/zhangxuying1004/RefCOD.
\\ ( https://arxiv.org/abs/2306.07532 ,  5137kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07553
Date: Tue, 13 Jun 2023 05:58:57 GMT   (3271kb,D)

Title: DenseLight: Efficient Control for Large-scale Traffic Signals with Dense
 Feedback
Authors: Junfan Lin, Yuying Zhu, Lingbo Liu, Yang Liu, Guanbin Li, Liang Lin
Categories: cs.CV
Comments: This work is accepted by IJCAI2023
\\
 Traffic Signal Control (TSC) aims to reduce the average travel time of
vehicles in a road network, which in turn enhances fuel utilization efficiency,
air quality, and road safety, benefiting society as a whole. Due to the
complexity of long-horizon control and coordination, most prior TSC methods
leverage deep reinforcement learning (RL) to search for a control policy and
have witnessed great success. However, TSC still faces two significant
challenges. 1) The travel time of a vehicle is delayed feedback on the
effectiveness of TSC policy at each traffic intersection since it is obtained
after the vehicle has left the road network. Although several heuristic reward
functions have been proposed as substitutes for travel time, they are usually
biased and not leading the policy to improve in the correct direction. 2) The
traffic condition of each intersection is influenced by the non-local
intersections since vehicles traverse multiple intersections over time.
Therefore, the TSC agent is required to leverage both the local observation and
the non-local traffic conditions to predict the long-horizontal traffic
conditions of each intersection comprehensively. To address these challenges,
we propose DenseLight, a novel RL-based TSC method that employs an unbiased
reward function to provide dense feedback on policy effectiveness and a
non-local enhanced TSC agent to better predict future traffic conditions for
more precise traffic control. Extensive experiments and ablation studies
demonstrate that DenseLight can consistently outperform advanced baselines on
various road networks with diverse traffic flows. The code is available at
https://github.com/junfanlin/DenseLight.
\\ ( https://arxiv.org/abs/2306.07553 ,  3271kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07559
Date: Tue, 13 Jun 2023 06:16:49 GMT   (1684kb,D)

Title: Marking anything: application of point cloud in extracting video target
 features
Authors: Xiangchun Xu
Categories: cs.CV eess.IV
Comments: 8 pages
MSC-class: 68T45
ACM-class: I.4.7
\\
 Extracting retrievable features from video is of great significance for
structured video database construction, video copyright protection and fake
video rumor refutation. Inspired by point cloud data processing, this paper
proposes a method for marking anything (MA) in the video, which can extract the
contour features of any target in the video and convert it into a feature
vector with a length of 256 that can be retrieved. The algorithm uses YOLO-v8
algorithm, multi-object tracking algorithm and PointNet++ to extract contour of
the video detection target to form spatial point cloud data. Then extract the
point cloud feature vector and use it as the retrievable feature of the video
detection target. In order to verify the effectiveness and robustness of
contour feature, some datasets are crawled from Dou Yin and Kinetics-700
dataset as experimental data. For Dou Yin's homogenized videos, the proposed
contour features achieve retrieval accuracy higher than 97% in Top1 return
mode. For videos from Kinetics 700, the contour feature also showed good
robustness for partial clip mode video tracing.
\\ ( https://arxiv.org/abs/2306.07559 ,  1684kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07576
Date: Tue, 13 Jun 2023 06:56:09 GMT   (493kb,D)

Title: Action Recognition with Multi-stream Motion Modeling and Mutual
 Information Maximization
Authors: Yuheng Yang, Haipeng Chen, Zhenguang Liu, Yingda Lyu, Beibei Zhang,
 Shuang Wu, Zhibo Wang, Kui Ren
Categories: cs.CV
Comments: 9 pages, 5 figures
\\
 Action recognition has long been a fundamental and intriguing problem in
artificial intelligence. The task is challenging due to the high dimensionality
nature of an action, as well as the subtle motion details to be considered.
Current state-of-the-art approaches typically learn from articulated motion
sequences in the straightforward 3D Euclidean space. However, the vanilla
Euclidean space is not efficient for modeling important motion characteristics
such as the joint-wise angular acceleration, which reveals the driving force
behind the motion. Moreover, current methods typically attend to each channel
equally and lack theoretical constrains on extracting task-relevant features
from the input.
 In this paper, we seek to tackle these challenges from three aspects: (1) We
propose to incorporate an acceleration representation, explicitly modeling the
higher-order variations in motion. (2) We introduce a novel Stream-GCN network
equipped with multi-stream components and channel attention, where different
representations (i.e., streams) supplement each other towards a more precise
action recognition while attention capitalizes on those important channels. (3)
We explore feature-level supervision for maximizing the extraction of
task-relevant information and formulate this into a mutual information loss.
Empirically, our approach sets the new state-of-the-art performance on three
benchmark datasets, NTU RGB+D, NTU RGB+D 120, and NW-UCLA. Our code is
anonymously released at https://github.com/ActionR-Group/Stream-GCN, hoping to
inspire the community.
\\ ( https://arxiv.org/abs/2306.07576 ,  493kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07579
Date: Tue, 13 Jun 2023 07:08:22 GMT   (4557kb,D)

Title: Parametric Implicit Face Representation for Audio-Driven Facial
 Reenactment
Authors: Ricong Huang, Peiwen Lai, Yipeng Qin, Guanbin Li
Categories: cs.CV
Comments: CVPR 2023
\\
 Audio-driven facial reenactment is a crucial technique that has a range of
applications in film-making, virtual avatars and video conferences. Existing
works either employ explicit intermediate face representations (e.g., 2D facial
landmarks or 3D face models) or implicit ones (e.g., Neural Radiance Fields),
thus suffering from the trade-offs between interpretability and expressive
power, hence between controllability and quality of the results. In this work,
we break these trade-offs with our novel parametric implicit face
representation and propose a novel audio-driven facial reenactment framework
that is both controllable and can generate high-quality talking heads.
Specifically, our parametric implicit representation parameterizes the implicit
representation with interpretable parameters of 3D face models, thereby taking
the best of both explicit and implicit methods. In addition, we propose several
new techniques to improve the three components of our framework, including i)
incorporating contextual information into the audio-to-expression parameters
encoding; ii) using conditional image synthesis to parameterize the implicit
representation and implementing it with an innovative tri-plane structure for
efficient learning; iii) formulating facial reenactment as a conditional image
inpainting problem and proposing a novel data augmentation technique to improve
model generalizability. Extensive experiments demonstrate that our method can
generate more realistic results than previous methods with greater fidelity to
the identities and talking styles of speakers.
\\ ( https://arxiv.org/abs/2306.07579 ,  4557kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07581
Date: Tue, 13 Jun 2023 07:11:10 GMT   (6644kb,D)

Title: Binary Radiance Fields
Authors: Seungjoo Shin, Jaesik Park
Categories: cs.CV
Comments: 21 pages, 12 Figures, and 11 Tables
\\
 In this paper, we propose binary radiance fields (BiRF), a storage-efficient
radiance field representation employing binary feature encoding that encodes
local features using binary encoding parameters in a format of either $+1$ or
$-1$. This binarization strategy lets us represent the feature grid with highly
compact feature encoding and a dramatic reduction in storage size. Furthermore,
our 2D-3D hybrid feature grid design enhances the compactness of feature
encoding as the 3D grid includes main components while 2D grids capture
details. In our experiments, binary radiance field representation successfully
outperforms the reconstruction performance of state-of-the-art (SOTA) efficient
radiance field models with lower storage allocation. In particular, our model
achieves impressive results in static scene reconstruction, with a PSNR of
31.53 dB for Synthetic-NeRF scenes, 34.26 dB for Synthetic-NSVF scenes, 28.02
dB for Tanks and Temples scenes while only utilizing 0.7 MB, 0.8 MB, and 0.8 MB
of storage space, respectively. We hope the proposed binary radiance field
representation will make radiance fields more accessible without a storage
bottleneck.
\\ ( https://arxiv.org/abs/2306.07581 ,  6644kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07591
Date: Tue, 13 Jun 2023 07:35:28 GMT   (10293kb,D)

Title: I See Dead People: Gray-Box Adversarial Attack on Image-To-Text Models
Authors: Raz Lapid, Moshe Sipper
Categories: cs.CV cs.NE
\\
 Modern image-to-text systems typically adopt the encoder-decoder framework,
which comprises two main components: an image encoder, responsible for
extracting image features, and a transformer-based decoder, used for generating
captions. Taking inspiration from the analysis of neural networks' robustness
against adversarial perturbations, we propose a novel gray-box algorithm for
creating adversarial examples in image-to-text models. Unlike image
classification tasks that have a finite set of class labels, finding visually
similar adversarial examples in an image-to-text task poses greater challenges
because the captioning system allows for a virtually infinite space of possible
captions. In this paper, we present a gray-box adversarial attack on
image-to-text, both untargeted and targeted. We formulate the process of
discovering adversarial perturbations as an optimization problem that uses only
the image-encoder component, meaning the proposed attack is language-model
agnostic. Through experiments conducted on the ViT-GPT2 model, which is the
most-used image-to-text model in Hugging Face, and the Flickr30k dataset, we
demonstrate that our proposed attack successfully generates visually similar
adversarial examples, both with untargeted and targeted captions. Notably, our
attack operates in a gray-box manner, requiring no knowledge about the decoder
module. We also show that our attacks fool the popular open-source platform
Hugging Face.
\\ ( https://arxiv.org/abs/2306.07591 ,  10293kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07596
Date: Tue, 13 Jun 2023 07:43:10 GMT   (16339kb,D)

Title: Paste, Inpaint and Harmonize via Denoising: Subject-Driven Image Editing
 with Pre-Trained Diffusion Model
Authors: Xin Zhang, Jiaxian Guo, Paul Yoo, Yutaka Matsuo, Yusuke Iwasawa
Categories: cs.CV cs.AI
Comments: 10 pages, 12 figures
\\
 Text-to-image generative models have attracted rising attention for flexible
image editing via user-specified descriptions. However, text descriptions alone
are not enough to elaborate the details of subjects, often compromising the
subjects' identity or requiring additional per-subject fine-tuning. We
introduce a new framework called \textit{Paste, Inpaint and Harmonize via
Denoising} (PhD), which leverages an exemplar image in addition to text
descriptions to specify user intentions. In the pasting step, an off-the-shelf
segmentation model is employed to identify a user-specified subject within an
exemplar image which is subsequently inserted into a background image to serve
as an initialization capturing both scene context and subject identity in one.
To guarantee the visual coherence of the generated or edited image, we
introduce an inpainting and harmonizing module to guide the pre-trained
diffusion model to seamlessly blend the inserted subject into the scene
naturally. As we keep the pre-trained diffusion model frozen, we preserve its
strong image synthesis ability and text-driven ability, thus achieving
high-quality results and flexible editing with diverse texts. In our
experiments, we apply PhD to both subject-driven image editing tasks and
explore text-driven scene generation given a reference subject. Both
quantitative and qualitative comparisons with baseline methods demonstrate that
our approach achieves state-of-the-art performance in both tasks. More
qualitative results can be found at
\url{https://sites.google.com/view/phd-demo-page}.
\\ ( https://arxiv.org/abs/2306.07596 ,  16339kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07598
Date: Tue, 13 Jun 2023 07:45:42 GMT   (2524kb,D)

Title: Learning to Estimate 6DoF Pose from Limited Data: A Few-Shot,
 Generalizable Approach using RGB Images
Authors: Panwang Pan, Zhiwen Fan, Brandon Y. Feng, Peihao Wang, Chenxin Li,
 Zhangyang Wang
Categories: cs.CV
\\
 The accurate estimation of six degrees-of-freedom (6DoF) object poses is
essential for many applications in robotics and augmented reality. However,
existing methods for 6DoF pose estimation often depend on CAD templates or
dense support views, restricting their usefulness in realworld situations. In
this study, we present a new cascade framework named Cas6D for few-shot 6DoF
pose estimation that is generalizable and uses only RGB images. To address the
false positives of target object detection in the extreme few-shot setting, our
framework utilizes a selfsupervised pre-trained ViT to learn robust feature
representations. Then, we initialize the nearest top-K pose candidates based on
similarity score and refine the initial poses using feature pyramids to
formulate and update the cascade warped feature volume, which encodes context
at increasingly finer scales. By discretizing the pose search range using
multiple pose bins and progressively narrowing the pose search range in each
stage using predictions from the previous stage, Cas6D can overcome the large
gap between pose candidates and ground truth poses, which is a common failure
mode in sparse-view scenarios. Experimental results on the LINEMOD and GenMOP
datasets demonstrate that Cas6D outperforms state-of-the-art methods by 9.2%
and 3.8% accuracy (Proj-5) under the 32-shot setting compared to OnePose++ and
Gen6D.
\\ ( https://arxiv.org/abs/2306.07598 ,  2524kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07613
Date: Tue, 13 Jun 2023 08:12:52 GMT   (1367kb,D)

Title: Rethinking Adversarial Training with A Simple Baseline
Authors: Hong Liu, Shin'ichi Satoh
Categories: cs.CV cs.LG
Comments: 19 pages, 8 figures, 6 tables
\\
 We report competitive results on RobustBench for CIFAR and SVHN using a
simple yet effective baseline approach. Our approach involves a training
protocol that integrates rescaled square loss, cyclic learning rates, and
erasing-based data augmentation. The outcomes we have achieved are comparable
to those of the model trained with state-of-the-art techniques, which is
currently the predominant choice for adversarial training. Our baseline,
referred to as SimpleAT, yields three novel empirical insights. (i) By
switching to square loss, the accuracy is comparable to that obtained by using
both de-facto training protocol plus data augmentation. (ii) One cyclic
learning rate is a good scheduler, which can effectively reduce the risk of
robust overfitting. (iii) Employing rescaled square loss during model training
can yield a favorable balance between adversarial and natural accuracy. In
general, our experimental results show that SimpleAT effectively mitigates
robust overfitting and consistently achieves the best performance at the end of
training. For example, on CIFAR-10 with ResNet-18, SimpleAT achieves
approximately 52% adversarial accuracy against the current strong AutoAttack.
Furthermore, SimpleAT exhibits robust performance on various image corruptions,
including those commonly found in CIFAR-10-C dataset. Finally, we assess the
effectiveness of these insights through two techniques: bias-variance analysis
and logit penalty methods. Our findings demonstrate that all of these simple
techniques are capable of reducing the variance of model predictions, which is
regarded as the primary contributor to robust overfitting. In addition, our
analysis also uncovers connections with various advanced state-of-the-art
methods.
\\ ( https://arxiv.org/abs/2306.07613 ,  1367kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07615
Date: Tue, 13 Jun 2023 08:19:14 GMT   (1568kb,D)

Title: UOD: Universal One-shot Detection of Anatomical Landmarks
Authors: Heqin Zhu, Quan Quan, Qingsong Yao, Zaiyi Liu, S.kevin Zhou
Categories: cs.CV
Comments: Eealy accepted by MICCAI 2023. 11pages, 4 figures, 2 tables
\\
 One-shot medical landmark detection gains much attention and achieves great
success for its label-efficient training process. However, existing one-shot
learning methods are highly specialized in a single domain and suffer domain
preference heavily in the situation of multi-domain unlabeled data. Moreover,
one-shot learning is not robust that it faces performance drop when annotating
a sub-optimal image. To tackle these issues, we resort to developing a
domain-adaptive one-shot landmark detection framework for handling multi-domain
medical images, named Universal One-shot Detection (UOD). UOD consists of two
stages and two corresponding universal models which are designed as
combinations of domain-specific modules and domain-shared modules. In the first
stage, a domain-adaptive convolution model is self-supervised learned to
generate pseudo landmark labels. In the second stage, we design a
domain-adaptive transformer to eliminate domain preference and build the global
context for multi-domain data. Even though only one annotated sample from each
domain is available for training, the domain-shared modules help UOD aggregate
all one-shot samples to detect more robust and accurate landmarks. We
investigated both qualitatively and quantitatively the proposed UOD on three
widely-used public X-ray datasets in different anatomical domains (i.e., head,
hand, chest) and obtained state-of-the-art performances in each domain.
\\ ( https://arxiv.org/abs/2306.07615 ,  1568kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07632
Date: Tue, 13 Jun 2023 09:02:57 GMT   (20721kb,D)

Title: NeuS-PIR: Learning Relightable Neural Surface using Pre-Integrated
 Rendering
Authors: Shi Mao, Chenming Wu, Zhelun Shen, Liangjun Zhang
Categories: cs.CV cs.GR
\\
 Recent advances in neural implicit fields enables rapidly reconstructing 3D
geometry from multi-view images. Beyond that, recovering physical properties
such as material and illumination is essential for enabling more applications.
This paper presents a new method that effectively learns relightable neural
surface using pre-intergrated rendering, which simultaneously learns geometry,
material and illumination within the neural implicit field. The key insight of
our work is that these properties are closely related to each other, and
optimizing them in a collaborative manner would lead to consistent
improvements. Specifically, we propose NeuS-PIR, a method that factorizes the
radiance field into a spatially varying material field and a differentiable
environment cubemap, and jointly learns it with geometry represented by neural
surface. Our experiments demonstrate that the proposed method outperforms the
state-of-the-art method in both synthetic and real datasets.
\\ ( https://arxiv.org/abs/2306.07632 ,  20721kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07646
Date: Tue, 13 Jun 2023 09:35:37 GMT   (2623kb,D)

Title: Enhanced Multimodal Representation Learning with Cross-modal KD
Authors: Mengxi Chen, Linyu Xing, Yu Wang, Ya Zhang
Categories: cs.CV cs.MM
Comments: Accepted by CVPR2023
\\
 This paper explores the tasks of leveraging auxiliary modalities which are
only available at training to enhance multimodal representation learning
through cross-modal Knowledge Distillation (KD). The widely adopted mutual
information maximization-based objective leads to a short-cut solution of the
weak teacher, i.e., achieving the maximum mutual information by simply making
the teacher model as weak as the student model. To prevent such a weak
solution, we introduce an additional objective term, i.e., the mutual
information between the teacher and the auxiliary modality model. Besides, to
narrow down the information gap between the student and teacher, we further
propose to minimize the conditional entropy of the teacher given the student.
Novel training schemes based on contrastive learning and adversarial learning
are designed to optimize the mutual information and the conditional entropy,
respectively. Experimental results on three popular multimodal benchmark
datasets have shown that the proposed method outperforms a range of
state-of-the-art approaches for video recognition, video retrieval and emotion
classification.
\\ ( https://arxiv.org/abs/2306.07646 ,  2623kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07649
Date: Tue, 13 Jun 2023 09:38:23 GMT   (3425kb,D)

Title: Sea Ice Segmentation From SAR Data by Convolutional Transformer Networks
Authors: Nicolae-Catalin Ristea, Andrei Anghel, Mihai Datcu
Categories: cs.CV eess.IV
\\
 Sea ice is a crucial component of the Earth's climate system and is highly
sensitive to changes in temperature and atmospheric conditions. Accurate and
timely measurement of sea ice parameters is important for understanding and
predicting the impacts of climate change. Nevertheless, the amount of satellite
data acquired over ice areas is huge, making the subjective measurements
ineffective. Therefore, automated algorithms must be used in order to fully
exploit the continuous data feeds coming from satellites. In this paper, we
present a novel approach for sea ice segmentation based on SAR satellite
imagery using hybrid convolutional transformer (ConvTr) networks. We show that
our approach outperforms classical convolutional networks, while being
considerably more efficient than pure transformer models. ConvTr obtained a
mean intersection over union (mIoU) of 63.68% on the AI4Arctic data set,
assuming an inference time of 120ms for a 400 x 400 squared km product.
\\ ( https://arxiv.org/abs/2306.07649 ,  3425kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07678
Date: Tue, 13 Jun 2023 10:45:24 GMT   (13126kb,D)

Title: Localization of Just Noticeable Difference for Image Compression
Authors: Guangan Chen, Hanhe Lin, Oliver Wiedemann, Dietmar Saupe
Categories: cs.CV cs.MM eess.IV
\\
 The just noticeable difference (JND) is the minimal difference between
stimuli that can be detected by a person. The picture-wise just noticeable
difference (PJND) for a given reference image and a compression algorithm
represents the minimal level of compression that causes noticeable differences
in the reconstruction. These differences can only be observed in some specific
regions within the image, dubbed as JND-critical regions. Identifying these
regions can improve the development of image compression algorithms. Due to the
fact that visual perception varies among individuals, determining the PJND
values and JND-critical regions for a target population of consumers requires
subjective assessment experiments involving a sufficiently large number of
observers. In this paper, we propose a novel framework for conducting such
experiments using crowdsourcing. By applying this framework, we created a novel
PJND dataset, KonJND++, consisting of 300 source images, compressed versions
thereof under JPEG or BPG compression, and an average of 43 ratings of PJND and
129 self-reported locations of JND-critical regions for each source image. Our
experiments demonstrate the effectiveness and reliability of our proposed
framework, which is easy to be adapted for collecting a large-scale dataset.
The source code and dataset are available at
https://github.com/angchen-dev/LocJND.
\\ ( https://arxiv.org/abs/2306.07678 ,  13126kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07684
Date: Tue, 13 Jun 2023 10:55:20 GMT   (1819kb,D)

Title: Lookaround Optimizer: $k$ steps around, 1 step average
Authors: Jiangtao Zhang, Shunyu Liu, Jie Song, Tongtian Zhu, Zhengqi Xu, Mingli
 Song
Categories: cs.CV
Comments: 18 pages, 9 figures
\\
 Weight Average (WA) is an active research topic due to its simplicity in
ensembling deep networks and the effectiveness in promoting generalization.
Existing weight average approaches, however, are often carried out along only
one training trajectory in a post-hoc manner (i.e., the weights are averaged
after the entire training process is finished), which significantly degrades
the diversity between networks and thus impairs the effectiveness in
ensembling. In this paper, inspired by weight average, we propose Lookaround, a
straightforward yet effective SGD-based optimizer leading to flatter minima
with better generalization. Specifically, Lookaround iterates two steps during
the whole training period: the around step and the average step. In each
iteration, 1) the around step starts from a common point and trains multiple
networks simultaneously, each on transformed data by a different data
augmentation, and 2) the average step averages these trained networks to get
the averaged network, which serves as the starting point for the next
iteration. The around step improves the functionality diversity while the
average step guarantees the weight locality of these networks during the whole
training, which is essential for WA to work. We theoretically explain the
superiority of Lookaround by convergence analysis, and make extensive
experiments to evaluate Lookaround on popular benchmarks including CIFAR and
ImageNet with both CNNs and ViTs, demonstrating clear superiority over
state-of-the-arts. Our code is available at
https://github.com/Ardcy/Lookaround.
\\ ( https://arxiv.org/abs/2306.07684 ,  1819kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07703
Date: Tue, 13 Jun 2023 11:41:15 GMT   (729kb,D)

Title: E2E-LOAD: End-to-End Long-form Online Action Detection
Authors: Shuqiang Cao, Weixin Luo, Bairui Wang, Wei Zhang, Lin Ma
Categories: cs.CV
\\
 Recently, there has been a growing trend toward feature-based approaches for
Online Action Detection (OAD). However, these approaches have limitations due
to their fixed backbone design, which ignores the potential capability of a
trainable backbone. In this paper, we propose the first end-to-end OAD model,
termed E2E-LOAD, designed to address the major challenge of OAD, namely,
long-term understanding and efficient online reasoning. Specifically, our
proposed approach adopts an initial spatial model that is shared by all frames
and maintains a long sequence cache for inference at a low computational cost.
We also advocate an asymmetric spatial-temporal model for long-form and
short-form modeling effectively. Furthermore, we propose a novel and efficient
inference mechanism that accelerates heavy spatial-temporal exploration.
Extensive ablation studies and experiments demonstrate the effectiveness and
efficiency of our proposed method. Notably, we achieve 17.3 (+12.6) FPS for
end-to-end OAD with 72.4%~(+1.2%), 90.3%~(+0.7%), and 48.1%~(+26.0%) mAP on
THMOUS14, TVSeries, and HDD, respectively, which is 3x faster than previous
approaches. The source code will be made publicly available.
\\ ( https://arxiv.org/abs/2306.07703 ,  729kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07713
Date: Tue, 13 Jun 2023 12:00:49 GMT   (5295kb,D)

Title: Robustness of SAM: Segment Anything Under Corruptions and Beyond
Authors: Yu Qiao, Chaoning Zhang, Taegoo Kang, Donghun Kim, Shehbaz Tariq,
 Chenshuang Zhang, Choong Seon Hong
Categories: cs.CV
Comments: 16pages
\\
 Segment anything model (SAM), as the name suggests, is claimed to be capable
of cutting out any object. SAM is a vision foundation model which demonstrates
impressive zero-shot transfer performance with the guidance of a prompt.
However, there is currently a lack of comprehensive evaluation of its
robustness performance under various types of corruptions. Prior works show
that SAM is biased towards texture (style) rather than shape, motivated by
which we start by investigating SAM's robustness against style transfer, which
is synthetic corruption. With the effect of corruptions interpreted as a style
change, we further evaluate its robustness on 15 common corruptions with 5
severity levels for each real-world corruption. Beyond the corruptions, we
further evaluate the SAM robustness on local occlusion and adversarial
perturbations. Overall, this work provides a comprehensive empirical study on
the robustness of the SAM under corruptions and beyond.
\\ ( https://arxiv.org/abs/2306.07713 ,  5295kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07716
Date: Tue, 13 Jun 2023 12:07:01 GMT   (2541kb,D)

Title: Dynamically Masked Discriminator for Generative Adversarial Networks
Authors: Wentian Zhang, Haozhe Liu, Bing Li, Jinheng Xie, Yawen Huang, Yuexiang
 Li, Yefeng Zheng, Bernard Ghanem
Categories: cs.CV
\\
 Training Generative Adversarial Networks (GANs) remains a challenging
problem. The discriminator trains the generator by learning the distribution of
real/generated data. However, the distribution of generated data changes
throughout the training process, which is difficult for the discriminator to
learn. In this paper, we propose a novel method for GANs from the viewpoint of
online continual learning. We observe that the discriminator model, trained on
historically generated data, often slows down its adaptation to the changes in
the new arrival generated data, which accordingly decreases the quality of
generated results. By treating the generated data in training as a stream, we
propose to detect whether the discriminator slows down the learning of new
knowledge in generated data. Therefore, we can explicitly enforce the
discriminator to learn new knowledge fast. Particularly, we propose a new
discriminator, which automatically detects its retardation and then dynamically
masks its features, such that the discriminator can adaptively learn the
temporally-vary distribution of generated data. Experimental results show our
method outperforms the state-of-the-art approaches.
\\ ( https://arxiv.org/abs/2306.07716 ,  2541kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07724
Date: Tue, 13 Jun 2023 12:22:54 GMT   (829kb)

Title: Effects of Data Enrichment with Image Transformations on the Performance
 of Deep Networks
Authors: Hakan Temiz
Categories: cs.CV cs.LG eess.IV
Journal-ref: The European Journal of Research and Development, 2(2), 23-33
 (2022)
DOI: 10.56038/ejrnd.v2i2.23
\\
 Images cannot always be expected to come in a certain standard format and
orientation. Deep networks need to be trained to take into account unexpected
variations in orientation or format. For this purpose, training data should be
enriched to include different conditions. In this study, the effects of data
enrichment on the performance of deep networks in the super resolution problem
were investigated experimentally. A total of six basic image transformations
were used for the enrichment procedures. In the experiments, two deep network
models were trained with variants of the ILSVRC2012 dataset enriched by these
six image transformation processes. Considering a single image transformation,
it has been observed that the data enriched with 180 degree rotation provides
the best results. The most unsuccessful result was obtained when the models
were trained on the enriched data generated by the flip upside down process.
Models scored highest when trained with a mix of all transformations.
\\ ( https://arxiv.org/abs/2306.07724 ,  829kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07727
Date: Tue, 13 Jun 2023 12:29:42 GMT   (822kb)

Title: Automatic and Accurate Classification of Hotel Bathrooms from Images
 with Deep Learning
Authors: Hakan Temiz
Categories: cs.CV cs.LG
Journal-ref: International Journal of Engineering Research and Development ,
 Special Issue 2022 , 211-218
DOI: 10.29137/umagd.1217004
\\
 Hotel bathrooms are one of the most important places in terms of customer
satisfaction, and where the most complaints are reported. To share their
experiences, guests rate hotels, comment, and share images of their positive or
negative ratings. An important part of the room images shared by guests is
related to bathrooms. Guests tend to prove their satisfaction or
dissatisfaction with the bathrooms with images in their comments. These
Positive or negative comments and visuals potentially affect the prospective
guests. In this study, two different versions of a deep learning algorithm were
designed to classify hotel bathrooms as satisfactory (good) or unsatisfactory
(bad, when any defects such as dirtiness, deficiencies, malfunctions were
present) by analyzing images. The best-performer between the two models was
determined as a result of a series of extensive experimental studies. The
models were trained for each of 144 combinations of 5 hyper-parameter sets with
a data set containing more than 11 thousand bathroom images, specially created
for this study. The "HotelBath" data set was shared also with the community
with this study. Four different image sizes were taken into consideration: 128,
256, 512 and 1024 pixels in both directions. The classification performances of
the models were measured with several metrics. Both algorithms showed very
attractive performances even with many combinations of hyper-parameters. They
can classify bathroom images with very high accuracy. Suh that the top
algorithm achieved an accuracy of 92.4% and an AUC (area under the curve) score
of 0.967. In addition, other metrics also proved the success...
\\ ( https://arxiv.org/abs/2306.07727 ,  822kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07754
Date: Tue, 13 Jun 2023 13:12:04 GMT   (30932kb,D)

Title: Generative Watermarking Against Unauthorized Subject-Driven Image
 Synthesis
Authors: Yihan Ma, Zhengyu Zhao, Xinlei He, Zheng Li, Michael Backes, Yang
 Zhang
Categories: cs.CV cs.CR
\\
 Large text-to-image models have shown remarkable performance in synthesizing
high-quality images. In particular, the subject-driven model makes it possible
to personalize the image synthesis for a specific subject, e.g., a human face
or an artistic style, by fine-tuning the generic text-to-image model with a few
images from that subject. Nevertheless, misuse of subject-driven image
synthesis may violate the authority of subject owners. For example, malicious
users may use subject-driven synthesis to mimic specific artistic styles or to
create fake facial images without authorization. To protect subject owners
against such misuse, recent attempts have commonly relied on adversarial
examples to indiscriminately disrupt subject-driven image synthesis. However,
this essentially prevents any benign use of subject-driven synthesis based on
protected images.
 In this paper, we take a different angle and aim at protection without
sacrificing the utility of protected images for general synthesis purposes.
Specifically, we propose GenWatermark, a novel watermark system based on
jointly learning a watermark generator and a detector. In particular, to help
the watermark survive the subject-driven synthesis, we incorporate the
synthesis process in learning GenWatermark by fine-tuning the detector with
synthesized images for a specific subject. This operation is shown to largely
improve the watermark detection accuracy and also ensure the uniqueness of the
watermark for each individual subject. Extensive experiments validate the
effectiveness of GenWatermark, especially in practical scenarios with unknown
models and text prompts (74% Acc.), as well as partial data watermarking (80%
Acc. for 1/4 watermarking). We also demonstrate the robustness of GenWatermark
to two potential countermeasures that substantially degrade the synthesis
quality.
\\ ( https://arxiv.org/abs/2306.07754 ,  30932kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07768
Date: Tue, 13 Jun 2023 13:33:53 GMT   (7106kb,D)

Title: Area is all you need: repeatable elements make stronger adversarial
 attacks
Authors: Dillon Niederhut
Categories: cs.CV cs.CR cs.LG
\\
 Over the last decade, deep neural networks have achieved state of the art in
computer vision tasks. These models, however, are susceptible to unusual
inputs, known as adversarial examples, that cause them to misclassify or
otherwise fail to detect objects. Here, we provide evidence that the increasing
success of adversarial attacks is primarily due to increasing their size. We
then demonstrate a method for generating the largest possible adversarial patch
by building a adversarial pattern out of repeatable elements. This approach
achieves a new state of the art in evading detection by YOLOv2 and YOLOv3.
Finally, we present an experiment that fails to replicate the prior success of
several attacks published in this field, and end with some comments on testing
and reproducibility.
\\ ( https://arxiv.org/abs/2306.07768 ,  7106kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07783
Date: Tue, 13 Jun 2023 14:06:55 GMT   (1930kb,D)

Title: Compositionally Equivariant Representation Learning
Authors: Xiao Liu, Pedro Sanchez, Spyridon Thermos, Alison Q. O'Neil and
 Sotirios A. Tsaftaris
Categories: cs.CV cs.LG
Comments: Submitted. 10 pages. arXiv admin note: text overlap with
 arXiv:2206.14538
\\
 Deep learning models often need sufficient supervision (i.e. labelled data)
in order to be trained effectively. By contrast, humans can swiftly learn to
identify important anatomy in medical images like MRI and CT scans, with
minimal guidance. This recognition capability easily generalises to new images
from different medical facilities and to new tasks in different settings. This
rapid and generalisable learning ability is largely due to the compositional
structure of image patterns in the human brain, which are not well represented
in current medical models. In this paper, we study the utilisation of
compositionality in learning more interpretable and generalisable
representations for medical image segmentation. Overall, we propose that the
underlying generative factors that are used to generate the medical images
satisfy compositional equivariance property, where each factor is compositional
(e.g. corresponds to the structures in human anatomy) and also equivariant to
the task. Hence, a good representation that approximates well the ground truth
factor has to be compositionally equivariant. By modelling the compositional
representations with learnable von-Mises-Fisher (vMF) kernels, we explore how
different design and learning biases can be used to enforce the representations
to be more compositionally equivariant under un-, weakly-, and semi-supervised
settings. Extensive results show that our methods achieve the best performance
over several strong baselines on the task of semi-supervised domain-generalised
medical image segmentation. Code will be made publicly available upon
acceptance at https://github.com/vios-s.
\\ ( https://arxiv.org/abs/2306.07783 ,  1930kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07809
Date: Tue, 13 Jun 2023 14:36:06 GMT   (2626kb,D)

Title: Low-Resource White-Box Semantic Segmentation of Supporting Towers on 3D
 Point Clouds via Signature Shape Identification
Authors: Diogo Lavado, Cl\'audia Soares, Alessandra Micheletti, Giovanni
 Bocchi, Alex Coronati, Manuel Silva and Patrizio Frosini
Categories: cs.CV cs.LG math.GT
\\
 Research in 3D semantic segmentation has been increasing performance metrics,
like the IoU, by scaling model complexity and computational resources, leaving
behind researchers and practitioners that (1) cannot access the necessary
resources and (2) do need transparency on the model decision mechanisms. In
this paper, we propose SCENE-Net, a low-resource white-box model for 3D point
cloud semantic segmentation. SCENE-Net identifies signature shapes on the point
cloud via group equivariant non-expansive operators (GENEOs), providing
intrinsic geometric interpretability. Our training time on a laptop is 85~min,
and our inference time is 20~ms. SCENE-Net has 11 trainable geometrical
parameters and requires fewer data than black-box models. SCENE--Net offers
robustness to noisy labeling and data imbalance and has comparable IoU to
state-of-the-art methods. With this paper, we release a 40~000 Km labeled
dataset of rural terrain point clouds and our code implementation.
\\ ( https://arxiv.org/abs/2306.07809 ,  2626kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07831
Date: Tue, 13 Jun 2023 15:05:24 GMT   (16543kb,D)

Title: Visual Language Pretrained Multiple Instance Zero-Shot Transfer for
 Histopathology Images
Authors: Ming Y. Lu, Bowen Chen, Andrew Zhang, Drew F.K. Williamson, Richard J.
 Chen, Tong Ding, Long Phi Le, Yung-Sung Chuang, Faisal Mahmood
Categories: cs.CV
Comments: Accepted to CVPR 2023
\\
 Contrastive visual language pretraining has emerged as a powerful method for
either training new language-aware image encoders or augmenting existing
pretrained models with zero-shot visual recognition capabilities. However,
existing works typically train on large datasets of image-text pairs and have
been designed to perform downstream tasks involving only small to medium
sized-images, neither of which are applicable to the emerging field of
computational pathology where there are limited publicly available paired
image-text datasets and each image can span up to 100,000 x 100,000 pixels. In
this paper we present MI-Zero, a simple and intuitive framework for unleashing
the zero-shot transfer capabilities of contrastively aligned image and text
models on gigapixel histopathology whole slide images, enabling multiple
downstream diagnostic tasks to be carried out by pretrained encoders without
requiring any additional labels. MI-Zero reformulates zero-shot transfer under
the framework of multiple instance learning to overcome the computational
challenge of inference on extremely large images. We used over 550k pathology
reports and other available in-domain text corpora to pre-train our text
encoder. By effectively leveraging strong pre-trained encoders, our best model
pretrained on over 33k histopathology image-caption pairs achieves an average
median zero-shot accuracy of 70.2% across three different real-world cancer
subtyping tasks. Our code is available at:
https://github.com/mahmoodlab/MI-Zero.
\\ ( https://arxiv.org/abs/2306.07831 ,  16543kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07835
Date: Tue, 13 Jun 2023 15:13:29 GMT   (32933kb,D)

Title: LMD: Light-weight Prediction Quality Estimation for Object Detection in
 Lidar Point Clouds
Authors: Tobias Riedlinger, Marius Schubert, Sarina Penquitt, Jan-Marcel
 Kezmann, Pascal Colling, Karsten Kahl, Lutz Roese-Koerner, Michael Arnold,
 Urs Zimmermann, Matthias Rottmann
Categories: cs.CV
Comments: 19 pages, 11 figures, 11 tables
\\
 Object detection on Lidar point cloud data is a promising technology for
autonomous driving and robotics which has seen a significant rise in
performance and accuracy during recent years. Particularly uncertainty
estimation is a crucial component for down-stream tasks and deep neural
networks remain error-prone even for predictions with high confidence.
Previously proposed methods for quantifying prediction uncertainty tend to
alter the training scheme of the detector or rely on prediction sampling which
results in vastly increased inference time. In order to address these two
issues, we propose LidarMetaDetect (LMD), a light-weight post-processing scheme
for prediction quality estimation. Our method can easily be added to any
pre-trained Lidar object detector without altering anything about the base
model and is purely based on post-processing, therefore, only leading to a
negligible computational overhead. Our experiments show a significant increase
of statistical reliability in separating true from false predictions. We
propose and evaluate an additional application of our method leading to the
detection of annotation errors. Explicit samples and a conservative count of
annotation error proposals indicates the viability of our method for
large-scale datasets like KITTI and nuScenes. On the widely-used nuScenes test
dataset, 43 out of the top 100 proposals of our method indicate, in fact,
erroneous annotations.
\\ ( https://arxiv.org/abs/2306.07835 ,  32933kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07842
Date: Tue, 13 Jun 2023 15:20:37 GMT   (5672kb)

Title: PSSTRNet: Progressive Segmentation-guided Scene Text Removal Network
Authors: Guangtao Lyu, Anna Zhu
Categories: cs.CV
Comments: Accepted by ICME2022
Journal-ref: 2022 IEEE International Conference on Multimedia and Expo (ICME)
DOI: 10.1109/ICME52920.2022.9859792
\\
 Scene text removal (STR) is a challenging task due to the complex text fonts,
colors, sizes, and background textures in scene images. However, most previous
methods learn both text location and background inpainting implicitly within a
single network, which weakens the text localization mechanism and makes a lossy
background. To tackle these problems, we propose a simple Progressive
Segmentation-guided Scene Text Removal Network(PSSTRNet) to remove the text in
the image iteratively. It contains two decoder branches, a text segmentation
branch, and a text removal branch, with a shared encoder. The text segmentation
branch generates text mask maps as the guidance for the regional removal
branch. In each iteration, the original image, previous text removal result,
and text mask are input to the network to extract the rest part of the text
segments and cleaner text removal result. To get a more accurate text mask map,
an update module is developed to merge the mask map in the current and previous
stages. The final text removal result is obtained by adaptive fusion of results
from all previous stages. A sufficient number of experiments and ablation
studies conducted on the real and synthetic public datasets demonstrate our
proposed method achieves state-of-the-art performance. The source code of our
work is available at:
\href{https://github.com/GuangtaoLyu/PSSTRNet}{https://github.com/GuangtaoLyu/PSSTRNet.}
\\ ( https://arxiv.org/abs/2306.07842 ,  5672kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07879
Date: Tue, 13 Jun 2023 16:14:40 GMT   (11942kb,D)

Title: Rethinking pose estimation in crowds: overcoming the detection
 information-bottleneck and ambiguity
Authors: Mu Zhou and Lucas Stoffl and Mackenzie Mathis and Alexander Mathis
Categories: cs.CV q-bio.QM
\\
 Frequent interactions between individuals are a fundamental challenge for
pose estimation algorithms. Current pipelines either use an object detector
together with a pose estimator (top-down approach), or localize all body parts
first and then link them to predict the pose of individuals (bottom-up). Yet,
when individuals closely interact, top-down methods are ill-defined due to
overlapping individuals, and bottom-up methods often falsely infer connections
to distant body parts. Thus, we propose a novel pipeline called bottom-up
conditioned top-down pose estimation (BUCTD) that combines the strengths of
bottom-up and top-down methods. Specifically, we propose to use a bottom-up
model as the detector, which in addition to an estimated bounding box provides
a pose proposal that is fed as condition to an attention-based top-down model.
We demonstrate the performance and efficiency of our approach on animal and
human pose estimation benchmarks. On CrowdPose and OCHuman, we outperform
previous state-of-the-art models by a significant margin. We achieve 78.5 AP on
CrowdPose and 47.2 AP on OCHuman, an improvement of 8.6% and 4.9% over the
prior art, respectively. Furthermore, we show that our method has excellent
performance on non-crowded datasets such as COCO, and strongly improves the
performance on multi-animal benchmarks involving mice, fish and monkeys.
\\ ( https://arxiv.org/abs/2306.07879 ,  11942kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07881
Date: Tue, 13 Jun 2023 16:18:51 GMT   (7364kb,D)

Title: Viewset Diffusion: (0-)Image-Conditioned 3D Generative Models from 2D
 Data
Authors: Stanislaw Szymanowicz and Christian Rupprecht and Andrea Vedaldi
Categories: cs.CV
\\
 We present Viewset Diffusion: a framework for training image-conditioned 3D
generative models from 2D data. Image-conditioned 3D generative models allow us
to address the inherent ambiguity in single-view 3D reconstruction. Given one
image of an object, there is often more than one possible 3D volume that
matches the input image, because a single image never captures all sides of an
object. Deterministic models are inherently limited to producing one possible
reconstruction and therefore make mistakes in ambiguous settings. Modelling
distributions of 3D shapes is challenging because 3D ground truth data is often
not available. We propose to solve the issue of data availability by training a
diffusion model which jointly denoises a multi-view image set.We constrain the
output of Viewset Diffusion models to a single 3D volume per image set,
guaranteeing consistent geometry. Training is done through reconstruction
losses on renderings, allowing training with only three images per object. Our
design of architecture and training scheme allows our model to perform 3D
generation and generative, ambiguity-aware single-view reconstruction in a
feed-forward manner. Project page: szymanowiczs.github.io/viewset-diffusion.
\\ ( https://arxiv.org/abs/2306.07881 ,  7364kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07890
Date: Tue, 13 Jun 2023 16:31:02 GMT   (414kb,D)

Title: VISION Datasets: A Benchmark for Vision-based InduStrial InspectiON
Authors: Haoping Bai, Shancong Mou, Tatiana Likhomanenko, Ramazan Gokberk
 Cinbis, Oncel Tuzel, Ping Huang, Jiulong Shan, Jianjun Shi, Meng Cao
Categories: cs.CV cs.LG
\\
 Despite progress in vision-based inspection algorithms, real-world industrial
challenges -- specifically in data availability, quality, and complex
production requirements -- often remain under-addressed. We introduce the
VISION Datasets, a diverse collection of 14 industrial inspection datasets,
uniquely poised to meet these challenges. Unlike previous datasets, VISION
brings versatility to defect detection, offering annotation masks across all
splits and catering to various detection methodologies. Our datasets also
feature instance-segmentation annotation, enabling precise defect
identification. With a total of 18k images encompassing 44 defect types, VISION
strives to mirror a wide range of real-world production scenarios. By
supporting two ongoing challenge competitions on the VISION Datasets, we hope
to foster further advancements in vision-based industrial inspection.
\\ ( https://arxiv.org/abs/2306.07890 ,  414kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07915
Date: Tue, 13 Jun 2023 17:18:01 GMT   (195kb,D)

Title: Image Captioners Are Scalable Vision Learners Too
Authors: Michael Tschannen, Manoj Kumar, Andreas Steiner, Xiaohua Zhai, Neil
 Houlsby, Lucas Beyer
Categories: cs.CV
\\
 Contrastive pretraining on image-text pairs from the web is one of the most
popular large-scale pretraining strategies for vision backbones, especially in
the context of large multimodal models. At the same time, image captioning on
this type of data is commonly considered an inferior pretraining strategy. In
this paper, we perform a fair comparison of these two pretraining strategies,
carefully matching training data, compute, and model capacity. Using a standard
encoder-decoder transformer, we find that captioning alone is surprisingly
effective: on classification tasks, captioning produces vision encoders
competitive with contrastively pretrained encoders, while surpassing them on
vision & language tasks. We further analyze the effect of the model
architecture and scale, as well as the pretraining data on the representation
quality, and find that captioning exhibits the same or better scaling behavior
along these axes. Overall our results show that plain image captioning is a
more powerful pretraining strategy than was previously believed.
\\ ( https://arxiv.org/abs/2306.07915 ,  195kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07921
Date: Tue, 13 Jun 2023 17:26:50 GMT   (43855kb,D)

Title: Continuous Cost Aggregation for Dual-Pixel Disparity Extraction
Authors: Sagi Monin, Sagi Katz and Georgios Evangelidis
Categories: cs.CV
\\
 Recent works have shown that depth information can be obtained from
Dual-Pixel (DP) sensors. A DP arrangement provides two views in a single shot,
thus resembling a stereo image pair with a tiny baseline. However, the
different point spread function (PSF) per view, as well as the small disparity
range, makes the use of typical stereo matching algorithms problematic. To
address the above shortcomings, we propose a Continuous Cost Aggregation (CCA)
scheme within a semi-global matching framework that is able to provide accurate
continuous disparities from DP images. The proposed algorithm fits parabolas to
matching costs and aggregates parabola coefficients along image paths. The
aggregation step is performed subject to a quadratic constraint that not only
enforces the disparity smoothness but also maintains the quadratic form of the
total costs. This gives rise to an inherently efficient disparity propagation
scheme with a pixel-wise minimization in closed-form. Furthermore, the
continuous form allows for a robust multi-scale aggregation that better
compensates for the varying PSF. Experiments on DP data from both DSLR and
phone cameras show that the proposed scheme attains state-of-the-art
performance in DP disparity estimation.
\\ ( https://arxiv.org/abs/2306.07921 ,  43855kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07952
Date: Tue, 13 Jun 2023 17:51:18 GMT   (5074kb,D)

Title: MOFI: Learning Image Representations from Noisy Entity Annotated Images
Authors: Wentao Wu, Aleksei Timofeev, Chen Chen, Bowen Zhang, Kun Duan,
 Shuangning Liu, Yantao Zheng, Jon Shlens, Xianzhi Du, Zhe Gan, Yinfei Yang
Categories: cs.CV cs.CL cs.LG
\\
 We present MOFI, a new vision foundation model designed to learn image
representations from noisy entity annotated images. MOFI differs from previous
work in two key aspects: ($i$) pre-training data, and ($ii$) training recipe.
Regarding data, we introduce a new approach to automatically assign entity
labels to images from noisy image-text pairs. Our approach involves employing a
named entity recognition model to extract entities from the alt-text, and then
using a CLIP model to select the correct entities as labels of the paired
image. The approach is simple, does not require costly human annotation, and
can be readily scaled up to billions of image-text pairs mined from the web.
Through this method, we have created Image-to-Entities (I2E), a new large-scale
dataset with 1 billion images and 2 million distinct entities, covering rich
visual concepts in the wild. Building upon the I2E dataset, we study different
training recipes, including supervised pre-training, contrastive pre-training,
and multi-task learning. For constrastive pre-training, we treat entity names
as free-form text, and further enrich them with entity descriptions.
Experiments show that supervised pre-training with large-scale fine-grained
entity labels is highly effective for image retrieval tasks, and multi-task
training further improves the performance. The final MOFI model achieves 86.66%
mAP on the challenging GPR1200 dataset, surpassing the previous
state-of-the-art performance of 72.19% from OpenAI's CLIP model. Further
experiments on zero-shot and linear probe image classification also show that
MOFI outperforms a CLIP model trained on the original image-text data,
demonstrating the effectiveness of the I2E dataset in learning strong image
representations.
\\ ( https://arxiv.org/abs/2306.07952 ,  5074kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07954
Date: Tue, 13 Jun 2023 17:52:23 GMT   (17874kb,D)

Title: Rerender A Video: Zero-Shot Text-Guided Video-to-Video Translation
Authors: Shuai Yang, Yifan Zhou, Ziwei Liu and Chen Change Loy
Categories: cs.CV
Comments: Project page: https://anonymous-31415926.github.io/
\\
 Large text-to-image diffusion models have exhibited impressive proficiency in
generating high-quality images. However, when applying these models to video
domain, ensuring temporal consistency across video frames remains a formidable
challenge. This paper proposes a novel zero-shot text-guided video-to-video
translation framework to adapt image models to videos. The framework includes
two parts: key frame translation and full video translation. The first part
uses an adapted diffusion model to generate key frames, with hierarchical
cross-frame constraints applied to enforce coherence in shapes, textures and
colors. The second part propagates the key frames to other frames with
temporal-aware patch matching and frame blending. Our framework achieves global
style and local texture temporal consistency at a low cost (without re-training
or optimization). The adaptation is compatible with existing image diffusion
techniques, allowing our framework to take advantage of them, such as
customizing a specific subject with LoRA, and introducing extra spatial
guidance with ControlNet. Extensive experimental results demonstrate the
effectiveness of our proposed framework over existing methods in rendering
high-quality and temporally-coherent videos.
\\ ( https://arxiv.org/abs/2306.07954 ,  17874kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07957
Date: Tue, 13 Jun 2023 17:55:17 GMT   (7730kb,D)

Title: Hidden Biases of End-to-End Driving Models
Authors: Bernhard Jaeger and Kashyap Chitta and Andreas Geiger
Categories: cs.CV cs.AI cs.LG cs.RO
Comments: 18 pages, 17 Tables, 10 Figures
\\
 End-to-end driving systems have recently made rapid progress, in particular
on CARLA. Independent of their major contribution, they introduce changes to
minor system components. Consequently, the source of improvements is unclear.
We identify two biases that recur in nearly all state-of-the-art methods and
are critical for the observed progress on CARLA: (1) lateral recovery via a
strong inductive bias towards target point following, and (2) longitudinal
averaging of multimodal waypoint predictions for slowing down. We investigate
the drawbacks of these biases and identify principled alternatives. By
incorporating our insights, we develop TF++, a simple end-to-end method that
ranks first on the Longest6 and LAV benchmarks, gaining 14 driving score over
the best prior work on Longest6.
\\ ( https://arxiv.org/abs/2306.07957 ,  7730kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07969
Date: Tue, 13 Jun 2023 17:59:58 GMT   (3752kb,D)

Title: GeneCIS: A Benchmark for General Conditional Image Similarity
Authors: Sagar Vaze, Nicolas Carion, Ishan Misra
Categories: cs.CV cs.AI cs.LG cs.MM
Comments: CVPR 2023 (Highlighted Paper). Project page at
 https://sgvaze.github.io/genecis/
\\
 We argue that there are many notions of 'similarity' and that models, like
humans, should be able to adapt to these dynamically. This contrasts with most
representation learning methods, supervised or self-supervised, which learn a
fixed embedding function and hence implicitly assume a single notion of
similarity. For instance, models trained on ImageNet are biased towards object
categories, while a user might prefer the model to focus on colors, textures or
specific elements in the scene. In this paper, we propose the GeneCIS
('genesis') benchmark, which measures models' ability to adapt to a range of
similarity conditions. Extending prior work, our benchmark is designed for
zero-shot evaluation only, and hence considers an open-set of similarity
conditions. We find that baselines from powerful CLIP models struggle on
GeneCIS and that performance on the benchmark is only weakly correlated with
ImageNet accuracy, suggesting that simply scaling existing methods is not
fruitful. We further propose a simple, scalable solution based on automatically
mining information from existing image-caption datasets. We find our method
offers a substantial boost over the baselines on GeneCIS, and further improves
zero-shot performance on related image retrieval benchmarks. In fact, though
evaluated zero-shot, our model surpasses state-of-the-art supervised models on
MIT-States. Project page at https://sgvaze.github.io/genecis/.
\\ ( https://arxiv.org/abs/2306.07969 ,  3752kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07970
Date: Tue, 13 Jun 2023 17:59:58 GMT   (34532kb,D)

Title: Neural Scene Chronology
Authors: Haotong Lin, Qianqian Wang, Ruojin Cai, Sida Peng, Hadar
 Averbuch-Elor, Xiaowei Zhou, Noah Snavely
Categories: cs.CV
Comments: CVPR 2023; Project page: https://zju3dv.github.io/neusc/
\\
 In this work, we aim to reconstruct a time-varying 3D model, capable of
rendering photo-realistic renderings with independent control of viewpoint,
illumination, and time, from Internet photos of large-scale landmarks. The core
challenges are twofold. First, different types of temporal changes, such as
illumination and changes to the underlying scene itself (such as replacing one
graffiti artwork with another) are entangled together in the imagery. Second,
scene-level temporal changes are often discrete and sporadic over time, rather
than continuous. To tackle these problems, we propose a new scene
representation equipped with a novel temporal step function encoding method
that can model discrete scene-level content changes as piece-wise constant
functions over time. Specifically, we represent the scene as a space-time
radiance field with a per-image illumination embedding, where
temporally-varying scene changes are encoded using a set of learned step
functions. To facilitate our task of chronology reconstruction from Internet
imagery, we also collect a new dataset of four scenes that exhibit various
changes over time. We demonstrate that our method exhibits state-of-the-art
view synthesis results on this dataset, while achieving independent control of
viewpoint, time, and illumination.
\\ ( https://arxiv.org/abs/2306.07970 ,  34532kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07971
Date: Tue, 13 Jun 2023 17:59:59 GMT   (1068kb,D)

Title: XrayGPT: Chest Radiographs Summarization using Medical Vision-Language
 Models
Authors: Omkar Thawkar, Abdelrahman Shaker, Sahal Shaji Mullappilly, Hisham
 Cholakkal, Rao Muhammad Anwer, Salman Khan, Jorma Laaksonen, Fahad Shahbaz
 Khan
Categories: cs.CV
Comments: Technical report
\\
 The latest breakthroughs in large vision-language models, such as Bard and
GPT-4, have showcased extraordinary abilities in performing a wide range of
tasks. Such models are trained on massive datasets comprising billions of
public image-text pairs with diverse tasks. However, their performance on
task-specific domains, such as radiology, is still under-investigated and
potentially limited due to a lack of sophistication in understanding biomedical
images. On the other hand, conversational medical models have exhibited
remarkable success but have mainly focused on text-based analysis. In this
paper, we introduce XrayGPT, a novel conversational medical vision-language
model that can analyze and answer open-ended questions about chest radiographs.
Specifically, we align both medical visual encoder (MedClip) with a fine-tuned
large language model (Vicuna), using a simple linear transformation. This
alignment enables our model to possess exceptional visual conversation
abilities, grounded in a deep understanding of radiographs and medical domain
knowledge. To enhance the performance of LLMs in the medical context, we
generate ~217k interactive and high-quality summaries from free-text radiology
reports. These summaries serve to enhance the performance of LLMs through the
fine-tuning process. Our approach opens up new avenues the research for
advancing the automated analysis of chest radiographs. Our open-source demos,
models, and instruction sets are available at:
https://github.com/mbzuai-oryx/XrayGPT.
\\ ( https://arxiv.org/abs/2306.07971 ,  1068kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07436
Date: Mon, 12 Jun 2023 21:41:52 GMT   (176kb)

Title: Evaluating FAIR Digital Object and Linked Data as distributed object
 systems
Authors: Stian Soiland-Reyes, Carole Goble, Paul Groth
Categories: cs.DC cs.NI
Comments: 40 pages, submitted to PeerJ CS
ACM-class: H.3; C.2
\\
 FAIR Digital Object (FDO) is an emerging concept that is highlighted by
European Open Science Cloud (EOSC) as a potential candidate for building a
ecosystem of machine-actionable research outputs. In this work we
systematically evaluate FDO and its implementations as a global distributed
object system, by using five different conceptual frameworks that cover
interoperability, middleware, FAIR principles, EOSC requirements and FDO
guidelines themself.
 We compare the FDO approach with established Linked Data practices and the
existing Web architecture, and provide a brief history of the Semantic Web
while discussing why these technologies may have been difficult to adopt for
FDO purposes. We conclude with recommendations for both Linked Data and FDO
communities to further their adaptation and alignment.
\\ ( https://arxiv.org/abs/2306.07436 ,  176kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07795
Date: Tue, 13 Jun 2023 14:17:07 GMT   (229kb,D)

Title: Efficient GPU implementation of a class of array permutations
Authors: Mathis Bouverot-Dupuis and Mary Sheeran
Categories: cs.DC
Comments: Submitted to ACM SIGPLAN International Workshop on Functional
 High-Performance and Numerical Computing 2023
\\
 Optimal usage of the memory system is a key element of fast GPU algorithms.
Unfortunately many common algorithms fail in this regard despite exhibiting
great regularity in memory access patterns. In this paper we propose efficient
kernels to permute the elements of an array, which can be used to improve the
access patterns of many algorithms. We handle a class of permutations known as
Bit Matrix Multiply Complement (BMMC) permutations, for which we design kernels
of speed comparable to that of a simple array copy. This is a first step
towards implementing a set of array combinators based on these permutations.
\\ ( https://arxiv.org/abs/2306.07795 ,  229kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07352
Date: Mon, 12 Jun 2023 18:21:10 GMT   (429kb,D)

Title: Multi-Platform Budget Management in Ad Markets with Non-IC Auctions
Authors: Fransisca Susan, Negin Golrezaei, Okke Schrijvers
Categories: cs.GT cs.LG math.OC stat.ML
Comments: 34 pages, 5 figures
\\
 In online advertising markets, budget-constrained advertisers acquire ad
placements through repeated bidding in auctions on various platforms. We
present a strategy for bidding optimally in a set of auctions that may or may
not be incentive-compatible under the presence of budget constraints. Our
strategy maximizes the expected total utility across auctions while satisfying
the advertiser's budget constraints in expectation. Additionally, we
investigate the online setting where the advertiser must submit bids across
platforms while learning about other bidders' bids over time. Our algorithm has
$O(T^{3/4})$ regret under the full-information setting. Finally, we demonstrate
that our algorithms have superior cumulative regret on both synthetic and
real-world datasets of ad placement auctions, compared to existing adaptive
pacing algorithms.
\\ ( https://arxiv.org/abs/2306.07352 ,  429kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07479
Date: Tue, 13 Jun 2023 00:55:10 GMT   (46kb)

Title: Incentivizing High-Quality Content in Online Recommender Systems
Authors: Xinyan Hu, Meena Jagadeesan, Michael I. Jordan, and Jacob Steinhard
Categories: cs.GT cs.IR cs.LG stat.ML
\\
 For content recommender systems such as TikTok and YouTube, the platform's
decision algorithm shapes the incentives of content producers, including how
much effort the content producers invest in the quality of their content. Many
platforms employ online learning, which creates intertemporal incentives, since
content produced today affects recommendations of future content. In this
paper, we study the incentives arising from online learning, analyzing the
quality of content produced at a Nash equilibrium. We show that classical
online learning algorithms, such as Hedge and EXP3, unfortunately incentivize
producers to create low-quality content. In particular, the quality of content
is upper bounded in terms of the learning rate and approaches zero for typical
learning rate schedules. Motivated by this negative result, we design a
different learning algorithm -- based on punishing producers who create
low-quality content -- that correctly incentivizes producers to create
high-quality content. At a conceptual level, our work illustrates the
unintended impact that a platform's learning algorithm can have on content
quality and opens the door towards designing platform learning algorithms that
incentivize the creation of high-quality content.
\\ ( https://arxiv.org/abs/2306.07479 ,  46kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07707
Date: Tue, 13 Jun 2023 11:50:07 GMT   (812kb,D)

Title: Incentive-Compatible Selection for One or Two Influentials
Authors: Yuxin Zhao, Yao Zhang and Dengji Zhao
Categories: cs.GT
Comments: To Appear on IJCAI 2023
\\
 Selecting influentials in networks against strategic manipulations has
attracted many researchers' attention and it also has many practical
applications. Here, we aim to select one or two influentials in terms of
progeny (the influential power) and prevent agents from manipulating their
edges (incentive compatibility). The existing studies mostly focused on
selecting a single influential for this setting. Zhang et al. [2021] studied
the problem of selecting one agent and proved an upper bound of 1/(1+ln2) to
approximate the optimal selection. In this paper, we first design a mechanism
to actually reach the bound. Then, we move this forward to choosing two agents
and propose a mechanism to achieve an approximation ratio of (3+ln2)/(4(1+ln2))
(approx. 0.54).
\\ ( https://arxiv.org/abs/2306.07707 ,  812kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07709
Date: Tue, 13 Jun 2023 11:55:04 GMT   (4470kb,D)

Title: Coordinated Dynamic Bidding in Repeated Second-Price Auctions with
 Budgets
Authors: Yurong Chen, Qian Wang, Zhijian Duan, Haoran Sun, Zhaohua Chen, Xiang
 Yan, Xiaotie Deng
Categories: cs.GT cs.LG econ.TH
Comments: 43 pages, 12 figures
\\
 In online ad markets, a rising number of advertisers are employing bidding
agencies to participate in ad auctions. These agencies are specialized in
designing online algorithms and bidding on behalf of their clients. Typically,
an agency usually has information on multiple advertisers, so she can
potentially coordinate bids to help her clients achieve higher utilities than
those under independent bidding.
 In this paper, we study coordinated online bidding algorithms in repeated
second-price auctions with budgets. We propose algorithms that guarantee every
client a higher utility than the best she can get under independent bidding. We
show that these algorithms achieve maximal coalition welfare and discuss
bidders' incentives to misreport their budgets, in symmetric cases. Our proofs
combine the techniques of online learning and equilibrium analysis, overcoming
the difficulty of competing with a multi-dimensional benchmark. The performance
of our algorithms is further evaluated by experiments on both synthetic and
real data. To the best of our knowledge, we are the first to consider bidder
coordination in online repeated auctions with constraints.
\\ ( https://arxiv.org/abs/2306.07709 ,  4470kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07893
Date: Tue, 13 Jun 2023 16:38:47 GMT   (944kb,D)

Title: Rethinking Incentives in Recommender Systems: Are Monotone Rewards
 Always Beneficial?
Authors: Fan Yao, Chuanhao Li, Karthik Abinav Sankararaman, Yiming Liao, Yan
 Zhu, Qifan Wang, Hongning Wang, Haifeng Xu
Categories: cs.GT
\\
 The past decade has witnessed the flourishing of a new profession as media
content creators, who rely on revenue streams from online content
recommendation platforms. The reward mechanism employed by these platforms
creates a competitive environment among creators which affect their production
choices and, consequently, content distribution and system welfare. It is thus
crucial to design the platform's reward mechanism in order to steer the
creators' competition towards a desirable welfare outcome in the long run. This
work makes two major contributions in this regard: first, we uncover a
fundamental limit about a class of widely adopted mechanisms, coined
Merit-based Monotone Mechanisms, by showing that they inevitably lead to a
constant fraction loss of the welfare. To circumvent this limitation, we
introduce Backward Rewarding Mechanisms (BRMs) and show that the competition
games resulting from BRM possess a potential game structure, which naturally
induces the strategic creators' behavior dynamics to optimize any given welfare
metric. In addition, the class of BRM can be parameterized so that it allows
the platform to directly optimize welfare within the feasible mechanism space
even when the welfare metric is not explicitly defined.
\\ ( https://arxiv.org/abs/2306.07893 ,  944kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07290
Date: Fri, 9 Jun 2023 18:40:55 GMT   (7087kb,D)

Title: Value function estimation using conditional diffusion models for control
Authors: Bogdan Mazoure, Walter Talbott, Miguel Angel Bautista, Devon Hjelm,
 Alexander Toshev, Josh Susskind
Categories: cs.LG cs.AI
\\
 A fairly reliable trend in deep reinforcement learning is that the
performance scales with the number of parameters, provided a complimentary
scaling in amount of training data. As the appetite for large models increases,
it is imperative to address, sooner than later, the potential problem of
running out of high-quality demonstrations. In this case, instead of collecting
only new data via costly human demonstrations or risking a simulation-to-real
transfer with uncertain effects, it would be beneficial to leverage vast
amounts of readily-available low-quality data. Since classical control
algorithms such as behavior cloning or temporal difference learning cannot be
used on reward-free or action-free data out-of-the-box, this solution warrants
novel training paradigms for continuous control. We propose a simple algorithm
called Diffused Value Function (DVF), which learns a joint multi-step model of
the environment-robot interaction dynamics using a diffusion model. This model
can be efficiently learned from state sequences (i.e., without access to reward
functions nor actions), and subsequently used to estimate the value of each
action out-of-the-box. We show how DVF can be used to efficiently capture the
state visitation measure for multiple controllers, and show promising
qualitative and quantitative results on challenging robotics benchmarks.
\\ ( https://arxiv.org/abs/2306.07290 ,  7087kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07292
Date: Fri, 9 Jun 2023 21:01:29 GMT   (2453kb,D)

Title: Urban Spatiotemporal Data Synthesis via Neural Disaggregation
Authors: Bin Han, Bill Howe
Categories: cs.LG cs.AI cs.CR
\\
 The level of granularity of open data often conflicts the benefits it can
provide. Less granular data can protect individual privacy, but to certain
degrees, sabotage the promise of open data to promote transparency and assist
research. Similar in the urban setting, aggregated urban data at high-level
geographic units can mask out the underline particularities of city dynamics
that may vary at lower areal levels. In this work, we aim to synthesize
fine-grained, high resolution urban data, by breaking down aggregated urban
data at coarse, low resolution geographic units. The goal is to increase the
usability and realize the values as much as possible of highly aggregated urban
data. To address the issue of simplicity of some traditional disaggregation
methods -- 1) we experimented with numerous neural-based models that are
capable of modeling intricate non-linear relationships among features. Neural
methods can also leverage both spatial and temporal information concurrently.
We showed that all neural methods perform better than traditional
disaggregation methods. Incorporating the temporal information further enhances
the results. 2) We proposed a training approach for disaggregation task,
Chain-of-Training (COT), that can be incorporated into any of the
training-based models. COT adds transitional disaggregation steps by
incorporating intermediate geographic dimensions, which enhances the
predictions at low geographic level and boosts the results at higher levels. 3)
We adapted the idea of reconstruction (REC) from super-resolution domain in our
disaggregation case -- after disaggregating from low to high geographic level,
we then re-aggregate back to the low level from our generated high level
values. Both strategies improved disaggregation results on three datasets and
two cities we tested on.
\\ ( https://arxiv.org/abs/2306.07292 ,  2453kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07294
Date: Sat, 10 Jun 2023 11:25:31 GMT   (718kb,D)

Title: Expressivity Enhancement with Efficient Quadratic Neurons for
 Convolutional Neural Networks
Authors: Chuangtao Chen and Grace Li Zhang and Xunzhao Yin and Cheng Zhuo and
 Ulf Schlichtmann and Bing Li
Categories: cs.LG cs.AI cs.NE
\\
 Convolutional neural networks (CNNs) have been successfully applied in a
range of fields such as image classification and object segmentation. To
improve their expressivity, various techniques, such as novel CNN
architectures, have been explored. However, the performance gain from such
techniques tends to diminish. To address this challenge, many researchers have
shifted their focus to increasing the non-linearity of neurons, the fundamental
building blocks of neural networks, to enhance the network expressivity.
Nevertheless, most of these approaches incur a large number of parameters and
thus formidable computation cost inevitably, impairing their efficiency to be
deployed in practice. In this work, an efficient quadratic neuron structure is
proposed to preserve the non-linearity with only negligible parameter and
computation cost overhead. The proposed quadratic neuron can maximize the
utilization of second-order computation information to improve the network
performance. The experimental results have demonstrated that the proposed
quadratic neuron can achieve a higher accuracy and a better computation
efficiency in classification tasks compared with both linear neurons and
non-linear neurons from previous works.
\\ ( https://arxiv.org/abs/2306.07294 ,  718kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07296
Date: Sat, 10 Jun 2023 16:06:44 GMT   (856kb)

Title: Optimized Three Deep Learning Models Based-PSO Hyperparameters for
 Beijing PM2.5 Prediction
Authors: Andri Pranolo, Yingchi Mao, Aji Prasetya Wibawa, Agung Bella Putra
 Utama, Felix Andika Dwiyanto
Categories: cs.LG cs.AI cs.NE
Comments: Volume 5 (1): 53-66
Journal-ref: Knowledge Engineering and Data Science, 2022, Vol 5 No 1, pp:
 53-66
DOI: 10.17977/um018v5i12022p53-66
\\
 Deep learning is a machine learning approach that produces excellent
performance in various applications, including natural language processing,
image identification, and forecasting. Deep learning network performance
depends on the hyperparameter settings. This research attempts to optimize the
deep learning architecture of Long short term memory (LSTM), Convolutional
neural network (CNN), and Multilayer perceptron (MLP) for forecasting tasks
using Particle swarm optimization (PSO), a swarm intelligence-based
metaheuristic optimization methodology: Proposed M-1 (PSO-LSTM), M-2 (PSO-CNN),
and M-3 (PSO-MLP). Beijing PM2.5 datasets was analyzed to measure the
performance of the proposed models. PM2.5 as a target variable was affected by
dew point, pressure, temperature, cumulated wind speed, hours of snow, and
hours of rain. The deep learning network inputs consist of three different
scenarios: daily, weekly, and monthly. The results show that the proposed M-1
with three hidden layers produces the best results of RMSE and MAPE compared to
the proposed M-2, M-3, and all the baselines. A recommendation for air
pollution management could be generated by using these optimized models
\\ ( https://arxiv.org/abs/2306.07296 ,  856kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07300
Date: Sun, 11 Jun 2023 04:58:31 GMT   (8559kb,D)

Title: Progressive Class-Wise Attention (PCA) Approach for Diagnosing Skin
 Lesions
Authors: Asim Naveed, Syed S. Naqvi, Tariq M. Khan, Imran Razzak
Categories: cs.LG cs.AI cs.CV
\\
 Skin cancer holds the highest incidence rate among all cancers globally. The
importance of early detection cannot be overstated, as late-stage cases can be
lethal. Classifying skin lesions, however, presents several challenges due to
the many variations they can exhibit, such as differences in colour, shape, and
size, significant variation within the same class, and notable similarities
between different classes. This paper introduces a novel class-wise attention
technique that equally regards each class while unearthing more specific
details about skin lesions. This attention mechanism is progressively used to
amalgamate discriminative feature details from multiple scales. The introduced
technique demonstrated impressive performance, surpassing more than 15
cutting-edge methods including the winners of HAM1000 and ISIC 2019
leaderboards. It achieved an impressive accuracy rate of 97.40% on the HAM10000
dataset and 94.9% on the ISIC 2019 dataset.
\\ ( https://arxiv.org/abs/2306.07300 ,  8559kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07301
Date: Sun, 11 Jun 2023 06:56:00 GMT   (458kb)

Title: Novel Regression and Least Square Support Vector Machine Learning
 Technique for Air Pollution Forecasting
Authors: Dhanalakshmi M and Radha V
Categories: cs.LG cs.AI
Comments: 11 pages, 7 figures, 3 tables, Article Published in April 2023,
 Volume 71, Issue 04, of SSRG-International Journal of Engineering Trends and
 Technology (IJETT)", ISSN: 2231-5381
DOI: 10.14445/22315381/IJETT-V71I4P214
\\
 Air pollution is the origination of particulate matter, chemicals, or
biological substances that brings pain to either humans or other living
creatures or instigates discomfort to the natural habitat and the airspace.
Hence, air pollution remains one of the paramount environmental issues as far
as metropolitan cities are concerned. Several air pollution benchmarks are even
said to have a negative influence on human health. Also, improper detection of
air pollution benchmarks results in severe complications for humans and living
creatures. To address this aspect, a novel technique called, Discretized
Regression and Least Square Support Vector (DR-LSSV) based air pollution
forecasting is proposed. The results indicate that the proposed DR-LSSV
Technique can efficiently enhance air pollution forecasting performance and
outperforms the conventional machine learning methods in terms of air pollution
forecasting accuracy, air pollution forecasting time, and false positive rate.
\\ ( https://arxiv.org/abs/2306.07301 ,  458kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07303
Date: Sun, 11 Jun 2023 23:13:51 GMT   (3462kb,D)

Title: A Comprehensive Survey on Applications of Transformers for Deep Learning
 Tasks
Authors: Saidul Islam, Hanae Elmekki, Ahmed Elsebai, Jamal Bentahar, Najat
 Drawel, Gaith Rjoub, Witold Pedrycz
Categories: cs.LG cs.CL
\\
 Transformer is a deep neural network that employs a self-attention mechanism
to comprehend the contextual relationships within sequential data. Unlike
conventional neural networks or updated versions of Recurrent Neural Networks
(RNNs) such as Long Short-Term Memory (LSTM), transformer models excel in
handling long dependencies between input sequence elements and enable parallel
processing. As a result, transformer-based models have attracted substantial
interest among researchers in the field of artificial intelligence. This can be
attributed to their immense potential and remarkable achievements, not only in
Natural Language Processing (NLP) tasks but also in a wide range of domains,
including computer vision, audio and speech processing, healthcare, and the
Internet of Things (IoT). Although several survey papers have been published
highlighting the transformer's contributions in specific fields, architectural
differences, or performance evaluations, there is still a significant absence
of a comprehensive survey paper encompassing its major applications across
various domains. Therefore, we undertook the task of filling this gap by
conducting an extensive survey of proposed transformer models from 2017 to
2022. Our survey encompasses the identification of the top five application
domains for transformer-based models, namely: NLP, Computer Vision,
Multi-Modality, Audio and Speech Processing, and Signal Processing. We analyze
the impact of highly influential transformer-based models in these domains and
subsequently classify them based on their respective tasks using a proposed
taxonomy. Our aim is to shed light on the existing potential and future
possibilities of transformers for enthusiastic researchers, thus contributing
to the broader understanding of this groundbreaking technology.
\\ ( https://arxiv.org/abs/2306.07303 ,  3462kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07304
Date: Sun, 11 Jun 2023 23:28:02 GMT   (3501kb,D)

Title: A Holistic Approach to Unifying Automatic Concept Extraction and Concept
 Importance Estimation
Authors: Thomas Fel, Victor Boutin, Mazda Moayeri, R\'emi Cad\`ene, Louis
 Bethune, L\'eo and\'eol, Mathieu Chalvidal, Thomas Serre
Categories: cs.LG cs.AI
\\
 In recent years, concept-based approaches have emerged as some of the most
promising explainability methods to help us interpret the decisions of
Artificial Neural Networks (ANNs). These methods seek to discover intelligible
visual 'concepts' buried within the complex patterns of ANN activations in two
key steps: (1) concept extraction followed by (2) importance estimation. While
these two steps are shared across methods, they all differ in their specific
implementations. Here, we introduce a unifying theoretical framework that
comprehensively defines and clarifies these two steps. This framework offers
several advantages as it allows us: (i) to propose new evaluation metrics for
comparing different concept extraction approaches; (ii) to leverage modern
attribution methods and evaluation metrics to extend and systematically
evaluate state-of-the-art concept-based approaches and importance estimation
techniques; (iii) to derive theoretical guarantees regarding the optimality of
such methods. We further leverage our framework to try to tackle a crucial
question in explainability: how to efficiently identify clusters of data points
that are classified based on a similar shared strategy. To illustrate these
findings and to highlight the main strategies of a model, we introduce a visual
representation called the strategic cluster graph. Finally, we present
https://serre-lab.github.io/Lens, a dedicated website that offers a complete
compilation of these visualizations for all classes of the ImageNet dataset.
\\ ( https://arxiv.org/abs/2306.07304 ,  3501kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07305
Date: Mon, 12 Jun 2023 03:26:11 GMT   (549kb,D)

Title: Making forecasting self-learning and adaptive -- Pilot forecasting rack
Authors: Shaun D'Souza, Dheeraj Shah, Amareshwar Allati, Parikshit Soni
Categories: cs.LG cs.AI q-fin.CP
\\
 Retail sales and price projections are typically based on time series
forecasting. For some product categories, the accuracy of demand forecasts
achieved is low, negatively impacting inventory, transport, and replenishment
planning. This paper presents our findings based on a proactive pilot exercise
to explore ways to help retailers to improve forecast accuracy for such product
categories.
 We evaluated opportunities for algorithmic interventions to improve forecast
accuracy based on a sample product category, Knitwear. The Knitwear product
category has a current demand forecast accuracy from non-AI models in the range
of 60%. We explored how to improve the forecast accuracy using a rack approach.
To generate forecasts, our decision model dynamically selects the best
algorithm from an algorithm rack based on performance for a given state and
context. Outcomes from our AI/ML forecasting model built using advanced feature
engineering show an increase in the accuracy of demand forecast for Knitwear
product category by 20%, taking the overall accuracy to 80%. Because our rack
comprises algorithms that cater to a range of customer data sets, the
forecasting model can be easily tailored for specific customer contexts.
\\ ( https://arxiv.org/abs/2306.07305 ,  549kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07307
Date: Mon, 12 Jun 2023 11:42:13 GMT   (1336kb,D)

Title: Online Prototype Alignment for Few-shot Policy Transfer
Authors: Qi Yi, Rui Zhang, Shaohui Peng, Jiaming Guo, Yunkai Gao, Kaizhao Yuan,
 Ruizhi Chen, Siming Lan, Xing Hu, Zidong Du, Xishan Zhang, Qi Guo, and Yunji
 Chen
Categories: cs.LG cs.AI
Comments: This paper has been accepted at ICML2023
\\
 Domain adaptation in reinforcement learning (RL) mainly deals with the
changes of observation when transferring the policy to a new environment. Many
traditional approaches of domain adaptation in RL manage to learn a mapping
function between the source and target domain in explicit or implicit ways.
However, they typically require access to abundant data from the target domain.
Besides, they often rely on visual clues to learn the mapping function and may
fail when the source domain looks quite different from the target domain. To
address these problems, we propose a novel framework Online Prototype Alignment
(OPA) to learn the mapping function based on the functional similarity of
elements and is able to achieve the few-shot policy transfer within only
several episodes. The key insight of OPA is to introduce an exploration
mechanism that can interact with the unseen elements of the target domain in an
efficient and purposeful manner, and then connect them with the seen elements
in the source domain according to their functionalities (instead of visual
clues). Experimental results show that when the target domain looks visually
different from the source domain, OPA can achieve better transfer performance
even with much fewer samples from the target domain, outperforming prior
methods.
\\ ( https://arxiv.org/abs/2306.07307 ,  1336kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07309
Date: Mon, 12 Jun 2023 17:50:09 GMT   (571kb,D)

Title: A New Probabilistic Distance Metric With Application In Gaussian Mixture
 Reduction
Authors: Ahmad Sajedi, Yuri A. Lawryshyn, and Konstantinos N. Plataniotis
Categories: cs.LG stat.AP stat.CO
DOI: 10.1109/ICASSP49357.2023.10096094
\\
 This paper presents a new distance metric to compare two continuous
probability density functions. The main advantage of this metric is that,
unlike other statistical measurements, it can provide an analytic, closed-form
expression for a mixture of Gaussian distributions while satisfying all metric
properties. These characteristics enable fast, stable, and efficient
calculations, which are highly desirable in real-world signal processing
applications. The application in mind is Gaussian Mixture Reduction (GMR),
which is widely used in density estimation, recursive tracking, and belief
propagation. To address this problem, we developed a novel algorithm dubbed the
Optimization-based Greedy GMR (OGGMR), which employs our metric as a criterion
to approximate a high-order Gaussian mixture with a lower order. Experimental
results show that the OGGMR algorithm is significantly faster and more
efficient than state-of-the-art GMR algorithms while retaining the geometric
shape of the original mixture.
\\ ( https://arxiv.org/abs/2306.07309 ,  571kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07349
Date: Tue, 6 Jun 2023 17:59:10 GMT   (46984kb,D)

Title: ATT3D: Amortized Text-to-3D Object Synthesis
Authors: Jonathan Lorraine, Kevin Xie, Xiaohui Zeng, Chen-Hsuan Lin, Towaki
 Takikawa, Nicholas Sharp, Tsung-Yi Lin, Ming-Yu Liu, Sanja Fidler, James
 Lucas
Categories: cs.LG cs.AI cs.CV
Comments: 22 pages, 20 figures
MSC-class: 68T45
ACM-class: I.2.6; I.2.7; I.3.6; I.3.7
\\
 Text-to-3D modelling has seen exciting progress by combining generative
text-to-image models with image-to-3D methods like Neural Radiance Fields.
DreamFusion recently achieved high-quality results but requires a lengthy,
per-prompt optimization to create 3D objects. To address this, we amortize
optimization over text prompts by training on many prompts simultaneously with
a unified model, instead of separately. With this, we share computation across
a prompt set, training in less time than per-prompt optimization. Our framework
- Amortized text-to-3D (ATT3D) - enables knowledge-sharing between prompts to
generalize to unseen setups and smooth interpolations between text for novel
assets and simple animations.
\\ ( https://arxiv.org/abs/2306.07349 ,  46984kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07350
Date: Mon, 12 Jun 2023 18:16:33 GMT   (831kb)

Title: G-invariant diffusion maps
Authors: Eitan Rosen and Xiuyuan Cheng and Yoel Shkolnisky
Categories: cs.LG
\\
 The diffusion maps embedding of data lying on a manifold have shown success
in tasks ranging from dimensionality reduction and clustering, to data
visualization. In this work, we consider embedding data sets which were sampled
from a manifold which is closed under the action of a continuous matrix group.
An example of such a data set are images who's planar rotations are arbitrary.
The G-invariant graph Laplacian, introduced in a previous work of the authors,
admits eigenfunctions in the form of tensor products between the elements of
the irreducible unitary representations of the group and eigenvectors of
certain matrices. We employ these eigenfunctions to derive diffusion maps that
intrinsically account for the group action on the data. In particular, we
construct both equivariant and invariant embeddings which can be used naturally
to cluster and align the data points. We demonstrate the effectiveness of our
construction with simulated data.
\\ ( https://arxiv.org/abs/2306.07350 ,  831kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07372
Date: Mon, 12 Jun 2023 18:55:56 GMT   (16193kb,D)

Title: Composing Efficient, Robust Tests for Policy Selection
Authors: Dustin Morrill, Thomas J. Walsh, Daniel Hernandez, Peter R. Wurman,
 Peter Stone
Categories: cs.LG cs.AI cs.GT
Comments: 26 pages, 13 figures. To appear in Proceedings of the Thirty-Ninth
 Conference on Uncertainty in Artificial Intelligence (UAI 2023)
ACM-class: B.8.1; I.2.6
\\
 Modern reinforcement learning systems produce many high-quality policies
throughout the learning process. However, to choose which policy to actually
deploy in the real world, they must be tested under an intractable number of
environmental conditions. We introduce RPOSST, an algorithm to select a small
set of test cases from a larger pool based on a relatively small number of
sample evaluations. RPOSST treats the test case selection problem as a
two-player game and optimizes a solution with provable $k$-of-$N$ robustness,
bounding the error relative to a test that used all the test cases in the pool.
Empirical results demonstrate that RPOSST finds a small set of test cases that
identify high quality policies in a toy one-shot game, poker datasets, and a
high-fidelity racing simulator.
\\ ( https://arxiv.org/abs/2306.07372 ,  16193kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07381
Date: Mon, 12 Jun 2023 19:14:45 GMT   (375kb,D)

Title: "Private Prediction Strikes Back!'' Private Kernelized Nearest Neighbors
 with Individual Renyi Filter
Authors: Yuqing Zhu, Xuandong Zhao, Chuan Guo, Yu-Xiang Wang
Categories: cs.LG cs.CR
\\
 Most existing approaches of differentially private (DP) machine learning
focus on private training. Despite its many advantages, private training lacks
the flexibility in adapting to incremental changes to the training dataset such
as deletion requests from exercising GDPR's right to be forgotten. We revisit a
long-forgotten alternative, known as private prediction, and propose a new
algorithm named Individual Kernelized Nearest Neighbor (Ind-KNN). Ind-KNN is
easily updatable over dataset changes and it allows precise control of the
R\'{e}nyi DP at an individual user level -- a user's privacy loss is measured
by the exact amount of her contribution to predictions; and a user is removed
if her prescribed privacy budget runs out. Our results show that Ind-KNN
consistently improves the accuracy over existing private prediction methods for
a wide range of $\epsilon$ on four vision and language tasks. We also
illustrate several cases under which Ind-KNN is preferable over private
training with NoisySGD.
\\ ( https://arxiv.org/abs/2306.07381 ,  375kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07397
Date: Mon, 12 Jun 2023 19:54:33 GMT   (42151kb,D)

Title: Adversarial Attacks on the Interpretation of Neuron Activation
 Maximization
Authors: Geraldin Nanfack, Alexander Fulleringer, Jonathan Marty, Michael
 Eickenberg, Eugene Belilovsky
Categories: cs.LG cs.CV
\\
 The internal functional behavior of trained Deep Neural Networks is
notoriously difficult to interpret. Activation-maximization approaches are one
set of techniques used to interpret and analyze trained deep-learning models.
These consist in finding inputs that maximally activate a given neuron or
feature map. These inputs can be selected from a data set or obtained by
optimization. However, interpretability methods may be subject to being
deceived. In this work, we consider the concept of an adversary manipulating a
model for the purpose of deceiving the interpretation. We propose an
optimization framework for performing this manipulation and demonstrate a
number of ways that popular activation-maximization interpretation techniques
associated with CNNs can be manipulated to change the interpretations, shedding
light on the reliability of these methods.
\\ ( https://arxiv.org/abs/2306.07397 ,  42151kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07408
Date: Mon, 12 Jun 2023 20:21:40 GMT   (233kb,D)

Title: Robust Reinforcement Learning through Efficient Adversarial Herding
Authors: Juncheng Dong, Hao-Lun Hsu, Qitong Gao, Vahid Tarokh, Miroslav Pajic
Categories: cs.LG cs.AI cs.RO
\\
 Although reinforcement learning (RL) is considered the gold standard for
policy design, it may not always provide a robust solution in various
scenarios. This can result in severe performance degradation when the
environment is exposed to potential disturbances. Adversarial training using a
two-player max-min game has been proven effective in enhancing the robustness
of RL agents. In this work, we extend the two-player game by introducing an
adversarial herd, which involves a group of adversaries, in order to address
($\textit{i}$) the difficulty of the inner optimization problem, and
($\textit{ii}$) the potential over pessimism caused by the selection of a
candidate adversary set that may include unlikely scenarios. We first prove
that adversarial herds can efficiently approximate the inner optimization
problem. Then we address the second issue by replacing the worst-case
performance in the inner optimization with the average performance over the
worst-$k$ adversaries. We evaluate the proposed method on multiple MuJoCo
environments. Experimental results demonstrate that our approach consistently
generates more robust policies.
\\ ( https://arxiv.org/abs/2306.07408 ,  233kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07432
Date: Mon, 12 Jun 2023 21:27:39 GMT   (4290kb,D)

Title: FIRE: An Optimization Approach for Fast Interpretable Rule Extraction
Authors: Brian Liu and Rahul Mazumder
Categories: cs.LG stat.ML
Journal-ref: Proceedings of the 29th ACM SIGKDD Conference on Knowledge
 Discovery and Data Mining (KDD 2023)
DOI: 10.1145/3580305.3599353
\\
 We present FIRE, Fast Interpretable Rule Extraction, an optimization-based
framework to extract a small but useful collection of decision rules from tree
ensembles. FIRE selects sparse representative subsets of rules from tree
ensembles, that are easy for a practitioner to examine. To further enhance the
interpretability of the extracted model, FIRE encourages fusing rules during
selection, so that many of the selected decision rules share common
antecedents. The optimization framework utilizes a fusion regularization
penalty to accomplish this, along with a non-convex sparsity-inducing penalty
to aggressively select rules. Optimization problems in FIRE pose a challenge to
off-the-shelf solvers due to problem scale and the non-convexity of the
penalties. To address this, making use of problem-structure, we develop a
specialized solver based on block coordinate descent principles; our solver
performs up to 40x faster than existing solvers. We show in our experiments
that FIRE outperforms state-of-the-art rule ensemble algorithms at building
sparse rule sets, and can deliver more interpretable models compared to
existing methods.
\\ ( https://arxiv.org/abs/2306.07432 ,  4290kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07462
Date: Mon, 12 Jun 2023 23:33:13 GMT   (7742kb,D)

Title: On the Robustness of Removal-Based Feature Attributions
Authors: Chris Lin, Ian Covert, Su-In Lee
Categories: cs.LG stat.ML
\\
 To explain complex models based on their inputs, many feature attribution
methods have been developed that assign importance scores to input features.
However, some recent work challenges the robustness of feature attributions by
showing that these methods are sensitive to input and model perturbations,
while other work addresses this robustness issue by proposing robust
attribution methods and model modifications. Nevertheless, previous work on
attribution robustness has focused primarily on gradient-based feature
attributions. In contrast, the robustness properties of removal-based
attribution methods are not comprehensively well understood. To bridge this
gap, we theoretically characterize the robustness of removal-based feature
attributions. Specifically, we provide a unified analysis of such methods and
prove upper bounds for the difference between intact and perturbed
attributions, under settings of both input and model perturbations. Our
empirical experiments on synthetic and real-world data validate our theoretical
results and demonstrate their practical implications.
\\ ( https://arxiv.org/abs/2306.07462 ,  7742kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07465
Date: Mon, 12 Jun 2023 23:48:24 GMT   (48kb,D)

Title: A Black-box Approach for Non-stationary Multi-agent Reinforcement
 Learning
Authors: Haozhe Jiang, Qiwen Cui, Zhihan Xiong, Maryam Fazel, Simon S. Du
Categories: cs.LG cs.AI cs.GT cs.MA stat.ML
Comments: 25 Pages, 2 figures
\\
 We investigate learning the equilibria in non-stationary multi-agent systems
and address the challenges that differentiate multi-agent learning from
single-agent learning. Specifically, we focus on games with bandit feedback,
where testing an equilibrium can result in substantial regret even when the gap
to be tested is small, and the existence of multiple optimal solutions
(equilibria) in stationary games poses extra challenges. To overcome these
obstacles, we propose a versatile black-box approach applicable to a broad
spectrum of problems, such as general-sum games, potential games, and Markov
games, when equipped with appropriate learning and testing oracles for
stationary environments. Our algorithms can achieve
$\widetilde{O}\left(\Delta^{1/4}T^{3/4}\right)$ regret when the degree of
nonstationarity, as measured by total variation $\Delta$, is known, and
$\widetilde{O}\left(\Delta^{1/5}T^{4/5}\right)$ regret when $\Delta$ is
unknown, where $T$ is the number of rounds. Meanwhile, our algorithm inherits
the favorable dependence on number of agents from the oracles. As a side
contribution that may be independent of interest, we show how to test for
various types of equilibria by a black-box reduction to single-agent learning,
which includes Nash equilibria, correlated equilibria, and coarse correlated
equilibria.
\\ ( https://arxiv.org/abs/2306.07465 ,  48kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07473
Date: Tue, 13 Jun 2023 00:38:51 GMT   (6224kb,D)

Title: 3D molecule generation by denoising voxel grids
Authors: Pedro O. Pinheiro, Joshua Rackers, Joseph Kleinhenz, Michael Maser,
 Omar Mahmood, Andrew Martin Watkins, Stephen Ra, Vishnu Sresht, Saeed Saremi
Categories: cs.LG q-bio.QM
\\
 We propose a new score-based approach to generate 3D molecules represented as
atomic densities on regular grids. First, we train a denoising neural network
that learns to map from a smooth distribution of noisy molecules to the
distribution of real molecules. Then, we follow the neural empirical Bayes
framework [Saremi and Hyvarinen, 2019] and generate molecules in two steps: (i)
sample noisy density grids from a smooth distribution via underdamped Langevin
Markov chain Monte Carlo, and (ii) recover the ``clean'' molecule by denoising
the noisy grid with a single step. Our method, VoxMol, generates molecules in a
fundamentally different way than the current state of the art (i.e., diffusion
models applied to atom point clouds). It differs in terms of the data
representation, the noise model, the network architecture and the generative
modeling algorithm. VoxMol achieves comparable results to state of the art on
unconditional 3D molecule generation while being simpler to train and faster to
generate molecules.
\\ ( https://arxiv.org/abs/2306.07473 ,  6224kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07484
Date: Tue, 13 Jun 2023 01:12:31 GMT   (22674kb,D)

Title: Multi-objective Molecular Optimization for Opioid Use Disorder Treatment
 Using Generative Network Complex
Authors: Hongsong Feng, Rui Wang, Chang-Guo Zhan, Guo-Wei Wei
Categories: cs.LG q-bio.BM
\\
 Opioid Use Disorder (OUD) has emerged as a significant global public health
issue, with complex multifaceted conditions. Due to the lack of effective
treatment options for various conditions, there is a pressing need for the
discovery of new medications. In this study, we propose a deep generative model
that combines a stochastic differential equation (SDE)-based diffusion modeling
with the latent space of a pretrained autoencoder model. The molecular
generator enables efficient generation of molecules that are effective on
multiple targets, specifically the mu, kappa, and delta opioid receptors.
Furthermore, we assess the ADMET (absorption, distribution, metabolism,
excretion, and toxicity) properties of the generated molecules to identify
drug-like compounds. To enhance the pharmacokinetic properties of some lead
compounds, we employ a molecular optimization approach. We obtain a diverse set
of drug-like molecules. We construct binding affinity predictors by integrating
molecular fingerprints derived from autoencoder embeddings, transformer
embeddings, and topological Laplacians with advanced machine learning
algorithms. Further experimental studies are needed to evaluate the
pharmacological effects of these drug-like compounds for OUD treatment. Our
machine learning platform serves as a valuable tool in designing and optimizing
effective molecules for addressing OUD.
\\ ( https://arxiv.org/abs/2306.07484 ,  22674kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07485
Date: Tue, 13 Jun 2023 01:18:16 GMT   (2616kb,D)

Title: Learning Unnormalized Statistical Models via Compositional Optimization
Authors: Wei Jiang, Jiayu Qin, Lingyu Wu, Changyou Chen, Tianbao Yang, Lijun
 Zhang
Categories: cs.LG math.OC
\\
 Learning unnormalized statistical models (e.g., energy-based models) is
computationally challenging due to the complexity of handling the partition
function. To eschew this complexity, noise-contrastive estimation~(NCE) has
been proposed by formulating the objective as the logistic loss of the real
data and the artificial noise. However, as found in previous works, NCE may
perform poorly in many tasks due to its flat loss landscape and slow
convergence. In this paper, we study it a direct approach for optimizing the
negative log-likelihood of unnormalized models from the perspective of
compositional optimization. To tackle the partition function, a noise
distribution is introduced such that the log partition function can be written
as a compositional function whose inner function can be estimated with
stochastic samples. Hence, the objective can be optimized by stochastic
compositional optimization algorithms. Despite being a simple method, we
demonstrate that it is more favorable than NCE by (1) establishing a fast
convergence rate and quantifying its dependence on the noise distribution
through the variance of stochastic estimators; (2) developing better results
for one-dimensional Gaussian mean estimation by showing our objective has a
much favorable loss landscape and hence our method enjoys faster convergence;
(3) demonstrating better performance on multiple applications, including
density estimation, out-of-distribution detection, and real image generation.
\\ ( https://arxiv.org/abs/2306.07485 ,  2616kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07497
Date: Tue, 13 Jun 2023 02:18:24 GMT   (1866kb)

Title: GQFedWAvg: Optimization-Based Quantized Federated Learning in General
 Edge Computing Systems
Authors: Yangchen Li, Ying Cui, and Vincent Lau
Categories: cs.LG cs.DC
Comments: submitted to IEEE Transactions on Wireless Communications, under
 major revision
\\
 The optimal implementation of federated learning (FL) in practical edge
computing systems has been an outstanding problem. In this paper, we propose an
optimization-based quantized FL algorithm, which can appropriately fit a
general edge computing system with uniform or nonuniform computing and
communication resources at the workers. Specifically, we first present a new
random quantization scheme and analyze its properties. Then, we propose a
general quantized FL algorithm, namely GQFedWAvg. Specifically, GQFedWAvg
applies the proposed quantization scheme to quantize wisely chosen model
update-related vectors and adopts a generalized mini-batch stochastic gradient
descent (SGD) method with the weighted average local model updates in global
model aggregation. Besides, GQFedWAvg has several adjustable algorithm
parameters to flexibly adapt to the computing and communication resources at
the server and workers. We also analyze the convergence of GQFedWAvg. Next, we
optimize the algorithm parameters of GQFedWAvg to minimize the convergence
error under the time and energy constraints. We successfully tackle the
challenging non-convex problem using general inner approximation (GIA) and
multiple delicate tricks. Finally, we interpret GQFedWAvg's function principle
and show its considerable gains over existing FL algorithms using numerical
results.
\\ ( https://arxiv.org/abs/2306.07497 ,  1866kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07503
Date: Tue, 13 Jun 2023 02:29:34 GMT   (11687kb,D)

Title: PaVa: a novel Path-based Valley-seeking clustering algorithm
Authors: Lin Ma and Conan Liu and Tiefeng Ma and Shuangzhe Liu
Categories: cs.LG
\\
 Clustering methods are being applied to a wider range of scenarios involving
more complex datasets, where the shapes of clusters tend to be arbitrary. In
this paper, we propose a novel Path-based Valley-seeking clustering algorithm
for arbitrarily shaped clusters. This work aims to seek the valleys among
clusters and then individually extract clusters. Three vital techniques are
used in this algorithm. First, path distance (minmax distance) is employed to
transform the irregular boundaries among clusters, that is density valleys,
into perfect spherical shells. Second, a suitable density measurement,
$k$-distance, is employed to make adjustment on Minimum Spanning Tree, by which
a robust minmax distance is calculated. Third, we seek the transformed density
valleys by determining their centers and radius. First, the clusters are
wrapped in spherical shells after the distance transformation, making the
extraction process efficient even with clusters of arbitrary shape. Second,
adjusted Minimum Spanning Tree enhances the robustness of minmax distance under
different kinds of noise. Last, the number of clusters does not need to be
inputted or decided manually due to the individual extraction process. After
applying the proposed algorithm to several commonly used synthetic datasets,
the results indicate that the Path-based Valley-seeking algorithm is accurate
and efficient. The algorithm is based on the dissimilarity of objects, so it
can be applied to a wide range of fields. Its performance on real-world
datasets illustrates its versatility.
\\ ( https://arxiv.org/abs/2306.07503 ,  11687kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07512
Date: Tue, 13 Jun 2023 02:43:21 GMT   (5912kb,D)

Title: Noisy Positive-Unlabeled Learning with Self-Training for Speculative
 Knowledge Graph Reasoning
Authors: Ruijie Wang, Baoyu Li, Yichen Lu, Dachun Sun, Jinning Li, Yuchen Yan,
 Shengzhong Liu, Hanghang Tong, Tarek F. Abdelzaher
Categories: cs.LG cs.AI cs.CL cs.SI
Comments: This paper is accepted by ACL-Findings 2023
\\
 This paper studies speculative reasoning task on real-world knowledge graphs
(KG) that contain both \textit{false negative issue} (i.e., potential true
facts being excluded) and \textit{false positive issue} (i.e., unreliable or
outdated facts being included). State-of-the-art methods fall short in the
speculative reasoning ability, as they assume the correctness of a fact is
solely determined by its presence in KG, making them vulnerable to false
negative/positive issues. The new reasoning task is formulated as a noisy
Positive-Unlabeled learning problem. We propose a variational framework, namely
nPUGraph, that jointly estimates the correctness of both collected and
uncollected facts (which we call \textit{label posterior}) and updates model
parameters during training. The label posterior estimation facilitates
speculative reasoning from two perspectives. First, it improves the robustness
of a label posterior-aware graph encoder against false positive links. Second,
it identifies missing facts to provide high-quality grounds of reasoning. They
are unified in a simple yet effective self-training procedure. Empirically,
extensive experiments on three benchmark KG and one Twitter dataset with
various degrees of false negative/positive cases demonstrate the effectiveness
of nPUGraph.
\\ ( https://arxiv.org/abs/2306.07512 ,  5912kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07526
Date: Tue, 13 Jun 2023 03:42:03 GMT   (881kb,D)

Title: User-defined Event Sampling and Uncertainty Quantification in Diffusion
 Models for Physical Dynamical Systems
Authors: Marc Finzi, Anudhyan Boral, Andrew Gordon Wilson, Fei Sha, Leonardo
 Zepeda-N\'u\~nez
Categories: cs.LG cs.AI
Comments: ICML 2023 Conference
\\
 Diffusion models are a class of probabilistic generative models that have
been widely used as a prior for image processing tasks like text conditional
generation and inpainting. We demonstrate that these models can be adapted to
make predictions and provide uncertainty quantification for chaotic dynamical
systems. In these applications, diffusion models can implicitly represent
knowledge about outliers and extreme events; however, querying that knowledge
through conditional sampling or measuring probabilities is surprisingly
difficult. Existing methods for conditional sampling at inference time seek
mainly to enforce the constraints, which is insufficient to match the
statistics of the distribution or compute the probability of the chosen events.
To achieve these ends, optimally one would use the conditional score function,
but its computation is typically intractable. In this work, we develop a
probabilistic approximation scheme for the conditional score function which
provably converges to the true distribution as the noise level decreases. With
this scheme we are able to sample conditionally on nonlinear userdefined events
at inference time, and matches data statistics even when sampling from the
tails of the distribution.
\\ ( https://arxiv.org/abs/2306.07526 ,  881kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07528
Date: Tue, 13 Jun 2023 03:46:22 GMT   (412kb,D)

Title: Unified Off-Policy Learning to Rank: a Reinforcement Learning
 Perspective
Authors: Zeyu Zhang, Yi Su, Hui Yuan, Yiran Wu, Rishab Balasubramanian, Qingyun
 Wu, Huazheng Wang, Mengdi Wang
Categories: cs.LG cs.IR
\\
 Off-policy Learning to Rank (LTR) aims to optimize a ranker from data
collected by a deployed logging policy. However, existing off-policy learning
to rank methods often make strong assumptions about how users generate the
click data, i.e., the click model, and hence need to tailor their methods
specifically under different click models. In this paper, we unified the
ranking process under general stochastic click models as a Markov Decision
Process (MDP), and the optimal ranking could be learned with offline
reinforcement learning (RL) directly. Building upon this, we leverage offline
RL techniques for off-policy LTR and propose the Click Model-Agnostic Unified
Off-policy Learning to Rank (CUOLR) method, which could be easily applied to a
wide range of click models. Through a dedicated formulation of the MDP, we show
that offline RL algorithms can adapt to various click models without complex
debiasing techniques and prior knowledge of the model. Results on various
large-scale datasets demonstrate that CUOLR consistently outperforms the
state-of-the-art off-policy learning to rank algorithms while maintaining
consistency and robustness under different click models.
\\ ( https://arxiv.org/abs/2306.07528 ,  412kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07536
Date: Tue, 13 Jun 2023 04:37:00 GMT   (14753kb,D)

Title: TART: A plug-and-play Transformer module for task-agnostic reasoning
Authors: Kush Bhatia, Avanika Narayan, Christopher De Sa, Christopher R\'e
Categories: cs.LG cs.AI cs.CL
\\
 Large language models (LLMs) exhibit in-context learning abilities which
enable the same model to perform several tasks without any task-specific
training. In contrast, traditional adaptation approaches, such as fine-tuning,
modify the underlying models for each specific task. In-context learning,
however, consistently underperforms task-specific tuning approaches even when
presented with the same examples. While most existing approaches (e.g., prompt
engineering) focus on the LLM's learned representations to patch this
performance gap, our analysis actually reveal that LLM representations contain
sufficient information to make good predictions. As such, we focus on the LLM's
reasoning abilities and demonstrate that this performance gap exists due to
their inability to perform simple probabilistic reasoning tasks. This raises an
intriguing question: Are LLMs actually capable of learning how to reason in a
task-agnostic manner? We answer this in the affirmative and propose TART which
generically improves an LLM's reasoning abilities using a synthetically trained
Transformer-based reasoning module. TART trains this reasoning module in a
task-agnostic manner using only synthetic logistic regression tasks and
composes it with an arbitrary real-world pre-trained model without any
additional training. With a single inference module, TART improves performance
across different model families (GPT-Neo, Pythia, BLOOM), model sizes (100M -
6B), tasks (14 NLP binary classification tasks), and even across different
modalities (audio and vision). Additionally, on the RAFT Benchmark, TART
improves GPT-Neo (125M)'s performance such that it outperforms BLOOM (176B),
and is within 4% of GPT-3 (175B). Our code and models are available at
https://github.com/HazyResearch/TART .
\\ ( https://arxiv.org/abs/2306.07536 ,  14753kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07541
Date: Tue, 13 Jun 2023 05:22:26 GMT   (1061kb,D)

Title: A Simple Unified Uncertainty-Guided Framework for Offline-to-Online
 Reinforcement Learning
Authors: Siyuan Guo, Yanchao Sun, Jifeng Hu, Sili Huang, Hechang Chen, Haiyin
 Piao, Lichao Sun, Yi Chang
Categories: cs.LG cs.AI
\\
 Offline reinforcement learning (RL) provides a promising solution to learning
an agent fully relying on a data-driven paradigm. However, constrained by the
limited quality of the offline dataset, its performance is often sub-optimal.
Therefore, it is desired to further finetune the agent via extra online
interactions before deployment. Unfortunately, offline-to-online RL can be
challenging due to two main challenges: constrained exploratory behavior and
state-action distribution shift. To this end, we propose a Simple Unified
uNcertainty-Guided (SUNG) framework, which naturally unifies the solution to
both challenges with the tool of uncertainty. Specifically, SUNG quantifies
uncertainty via a VAE-based state-action visitation density estimator. To
facilitate efficient exploration, SUNG presents a practical optimistic
exploration strategy to select informative actions with both high value and
high uncertainty. Moreover, SUNG develops an adaptive exploitation method by
applying conservative offline RL objectives to high-uncertainty samples and
standard online RL objectives to low-uncertainty samples to smoothly bridge
offline and online stages. SUNG achieves state-of-the-art online finetuning
performance when combined with different offline RL methods, across various
environments and datasets in D4RL benchmark.
\\ ( https://arxiv.org/abs/2306.07541 ,  1061kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07544
Date: Tue, 13 Jun 2023 05:25:51 GMT   (100kb,D)

Title: On Achieving Optimal Adversarial Test Error
Authors: Justin D. Li, Matus Telgarsky
Categories: cs.LG stat.ML
Comments: ICLR 2023
\\
 We first elucidate various fundamental properties of optimal adversarial
predictors: the structure of optimal adversarial convex predictors in terms of
optimal adversarial zero-one predictors, bounds relating the adversarial convex
loss to the adversarial zero-one loss, and the fact that continuous predictors
can get arbitrarily close to the optimal adversarial error for both convex and
zero-one losses. Applying these results along with new Rademacher complexity
bounds for adversarial training near initialization, we prove that for general
data distributions and perturbation sets, adversarial training on shallow
networks with early stopping and an idealized optimal adversary is able to
achieve optimal adversarial test error. By contrast, prior theoretical work
either considered specialized data distributions or only provided training
error guarantees.
\\ ( https://arxiv.org/abs/2306.07544 ,  100kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07549
Date: Tue, 13 Jun 2023 05:41:38 GMT   (353kb,D)

Title: Fixed-Budget Best-Arm Identification with Heterogeneous Reward Variances
Authors: Anusha Lalitha, Kousha Kalantari, Yifei Ma, Anoop Deoras, Branislav
 Kveton
Categories: cs.LG stat.ML
\\
 We study the problem of best-arm identification (BAI) in the fixed-budget
setting with heterogeneous reward variances. We propose two variance-adaptive
BAI algorithms for this setting: SHVar for known reward variances and SHAdaVar
for unknown reward variances. Our algorithms rely on non-uniform budget
allocations among the arms where the arms with higher reward variances are
pulled more often than those with lower variances. The main algorithmic novelty
is in the design of SHAdaVar, which allocates budget greedily based on
overestimating the unknown reward variances. We bound probabilities of
misidentifying the best arms in both SHVar and SHAdaVar. Our analyses rely on
novel lower bounds on the number of pulls of an arm that do not require
closed-form solutions to the budget allocation problem. Since one of our budget
allocation problems is analogous to the optimal experiment design with unknown
variances, we believe that our results are of a broad interest. Our experiments
validate our theory, and show that SHVar and SHAdaVar outperform algorithms
from prior works with analytical guarantees.
\\ ( https://arxiv.org/abs/2306.07549 ,  353kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07552
Date: Tue, 13 Jun 2023 05:53:23 GMT   (6032kb,D)

Title: Galactic: Scaling End-to-End Reinforcement Learning for Rearrangement at
 100k Steps-Per-Second
Authors: Vincent-Pierre Berges, Andrew Szot, Devendra Singh Chaplot, Aaron
 Gokaslan, Roozbeh Mottaghi, Dhruv Batra, Eric Undersander
Categories: cs.LG cs.AI cs.RO
\\
 We present Galactic, a large-scale simulation and reinforcement-learning (RL)
framework for robotic mobile manipulation in indoor environments. Specifically,
a Fetch robot (equipped with a mobile base, 7DoF arm, RGBD camera, egomotion,
and onboard sensing) is spawned in a home environment and asked to rearrange
objects - by navigating to an object, picking it up, navigating to a target
location, and then placing the object at the target location.
 Galactic is fast. In terms of simulation speed (rendering + physics),
Galactic achieves over 421,000 steps-per-second (SPS) on an 8-GPU node, which
is 54x faster than Habitat 2.0 (7699 SPS). More importantly, Galactic was
designed to optimize the entire rendering + physics + RL interplay since any
bottleneck in the interplay slows down training. In terms of simulation+RL
speed (rendering + physics + inference + learning), Galactic achieves over
108,000 SPS, which 88x faster than Habitat 2.0 (1243 SPS).
 These massive speed-ups not only drastically cut the wall-clock training time
of existing experiments, but also unlock an unprecedented scale of new
experiments. First, Galactic can train a mobile pick skill to >80% accuracy in
under 16 minutes, a 100x speedup compared to the over 24 hours it takes to
train the same skill in Habitat 2.0. Second, we use Galactic to perform the
largest-scale experiment to date for rearrangement using 5B steps of experience
in 46 hours, which is equivalent to 20 years of robot experience. This scaling
results in a single neural network composed of task-agnostic components
achieving 85% success in GeometricGoal rearrangement, compared to 0% success
reported in Habitat 2.0 for the same approach. The code is available at
github.com/facebookresearch/galactic.
\\ ( https://arxiv.org/abs/2306.07552 ,  6032kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07567
Date: Tue, 13 Jun 2023 06:40:37 GMT   (928kb,D)

Title: Large Language Models Sometimes Generate Purely Negatively-Reinforced
 Text
Authors: Fabien Roger
Categories: cs.LG cs.CL
\\
 When using adversarial training, it is common practice to train against the
most egregious failures. However, this might imply using examples with
sensitive information (such as leaked passwords or security vulnerabilities) as
training data. One might assume that language models trained with gradient
descent never generate text snippets which were only present in examples
associated with the lowest possible reward. In this paper, we show that this
assumption is wrong: in some situations, large language models do learn from
such negatively-reinforced examples. We present a specific training setup that
enables Pythia-160M to generate passwords with a probability slightly greater
than chance, despite only showing it these passwords on examples where the
model is incentivized to not output these passwords. Our code is available at
https://github.com/FabienRoger/Learning-From-Negative-Examples
\\ ( https://arxiv.org/abs/2306.07567 ,  928kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07618
Date: Tue, 13 Jun 2023 08:22:18 GMT   (5959kb,D)

Title: Hyperbolic Graph Diffusion Model for Molecule Generation
Authors: Lingfeng Wen, Xian Wei
Categories: cs.LG cs.AI q-bio.QM
\\
 Recently, diffusion models have achieved remarkable performance in data
generation, e.g., generating high-quality images. Nevertheless, chemistry
molecules often have complex non-Euclidean spatial structures, with the
behavior changing dynamically and unpredictably. Most existing diffusion models
highly rely on computing the probability distribution, i.e., Gaussian
distribution, in Euclidean space, which cannot capture internal non-Euclidean
structures of molecules, especially the hierarchical structures of the implicit
manifold surface represented by molecules. It has been observed that the
complex hierarchical structures in hyperbolic embedding space become more
prominent and easier to be captured. In order to leverage both the data
generation power of diffusion models and the strong capability to extract
complex geometric features of hyperbolic embedding, we propose to extend the
diffusion model to hyperbolic manifolds for molecule generation, namely,
Hyperbolic Graph Diffusion Model (HGDM). The proposed HGDM employs a hyperbolic
variational autoencoder to generate the hyperbolic hidden representation of
nodes and then a score-based hyperbolic graph neural network is used to learn
the distribution in hyperbolic space. Numerical experimental results show that
the proposed HGDM achieves higher performance on several molecular datasets,
compared with state-of-the-art methods.
\\ ( https://arxiv.org/abs/2306.07618 ,  5959kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07644
Date: Tue, 13 Jun 2023 09:33:26 GMT   (213kb,D)

Title: SRATTA : Sample Re-ATTribution Attack of Secure Aggregation in Federated
 Learning
Authors: Tanguy Marchand, R\'egis Loeb, Ulysse Marteau-Ferey, Jean Ogier du
 Terrail, Arthur Pignet
Categories: cs.LG cs.CR
Comments: Accepted to ICML2023
\\
 We consider a cross-silo federated learning (FL) setting where a machine
learning model with a fully connected first layer is trained between different
clients and a central server using FedAvg, and where the aggregation step can
be performed with secure aggregation (SA). We present SRATTA an attack relying
only on aggregated models which, under realistic assumptions, (i) recovers data
samples from the different clients, and (ii) groups data samples coming from
the same client together. While sample recovery has already been explored in an
FL setting, the ability to group samples per client, despite the use of SA, is
novel. This poses a significant unforeseen security threat to FL and
effectively breaks SA. We show that SRATTA is both theoretically grounded and
can be used in practice on realistic models and datasets. We also propose
counter-measures, and claim that clients should play an active role to
guarantee their privacy during training.
\\ ( https://arxiv.org/abs/2306.07644 ,  213kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07651
Date: Tue, 13 Jun 2023 09:43:32 GMT   (2907kb,D)

Title: Variational Positive-incentive Noise: How Noise Benefits Models
Authors: Hongyuan Zhang, Sida Huang, Xuelong Li
Categories: cs.LG cs.CV
\\
 A large number of works aim to alleviate the impact of noise due to an
underlying conventional assumption of the negative role of noise. However, some
existing works show that the assumption does not always hold. In this paper, we
investigate how to benefit the classical models by random noise under the
framework of Positive-incentive Noise (Pi-Noise). Since the ideal objective of
Pi-Noise is intractable, we propose to optimize its variational bound instead,
namely variational Pi-Noise (VPN). With the variational inference, a VPN
generator implemented by neural networks is designed for enhancing base models
and simplifying the inference of base models, without changing the architecture
of base models. Benefiting from the independent design of base models and VPN
generators, the VPN generator can work with most existing models. From the
experiments, it is shown that the proposed VPN generator can improve the base
models. It is appealing that the trained variational VPN generator prefers to
blur the irrelevant ingredients in complicated images, which meets our
expectations.
\\ ( https://arxiv.org/abs/2306.07651 ,  2907kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07699
Date: Tue, 13 Jun 2023 11:34:36 GMT   (330kb,D)

Title: Time-aware Graph Structure Learning via Sequence Prediction on Temporal
 Graphs
Authors: Haozhen Zhang, Xueting Han, Xi Xiao, Jing Bai
Categories: cs.LG cs.AI
Comments: 10 pages,4 figures,5 tables
\\
 Temporal Graph Learning, which aims to model the time-evolving nature of
graphs, has gained increasing attention and achieved remarkable performance
recently. However, in reality, graph structures are often incomplete and noisy,
which hinders temporal graph networks (TGNs) from learning informative
representations. Graph contrastive learning uses data augmentation to generate
plausible variations of existing data and learn robust representations.
However, rule-based augmentation approaches may be suboptimal as they lack
learnability and fail to leverage rich information from downstream tasks. To
address these issues, we propose a Time-aware Graph Structure Learning (TGSL)
approach via sequence prediction on temporal graphs, which learns better graph
structures for downstream tasks through adding potential temporal edges. In
particular, it predicts time-aware context embedding based on previously
observed interactions and uses the Gumble-Top-K to select the closest candidate
edges to this context embedding. Additionally, several candidate sampling
strategies are proposed to ensure both efficiency and diversity. Furthermore,
we jointly learn the graph structure and TGNs in an end-to-end manner and
perform inference on the refined graph. Extensive experiments on temporal link
prediction benchmarks demonstrate that TGSL yields significant gains for the
popular TGNs such as TGAT and GraphMixer, and it outperforms other contrastive
learning methods on temporal graphs. We will release the code in the future.
\\ ( https://arxiv.org/abs/2306.07699 ,  330kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07723
Date: Tue, 13 Jun 2023 12:20:55 GMT   (3063kb)

Title: Theoretical Foundations of Adversarially Robust Learning
Authors: Omar Montasser
Categories: cs.LG cs.CR stat.ML
Comments: PhD Thesis
\\
 Despite extraordinary progress, current machine learning systems have been
shown to be brittle against adversarial examples: seemingly innocuous but
carefully crafted perturbations of test examples that cause machine learning
predictors to misclassify. Can we learn predictors robust to adversarial
examples? and how? There has been much empirical interest in this contemporary
challenge in machine learning, and in this thesis, we address it from a
theoretical perspective.
 In this thesis, we explore what robustness properties can we hope to
guarantee against adversarial examples and develop an understanding of how to
algorithmically guarantee them. We illustrate the need to go beyond traditional
approaches and principles such as empirical risk minimization and uniform
convergence, and make contributions that can be categorized as follows: (1)
introducing problem formulations capturing aspects of emerging practical
challenges in robust learning, (2) designing new learning algorithms with
provable robustness guarantees, and (3) characterizing the complexity of robust
learning and fundamental limitations on the performance of any algorithm.
\\ ( https://arxiv.org/abs/2306.07723 ,  3063kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07730
Date: Tue, 13 Jun 2023 12:36:00 GMT   (1276kb,D)

Title: BeliefPPG: Uncertainty-aware Heart Rate Estimation from PPG signals via
 Belief Propagation
Authors: Valentin Bieri, Paul Streli, Berken Utku Demirel and Christian Holz
Categories: cs.LG cs.CV eess.SP
Comments: Conference on Uncertainty in Artificial Intelligence (UAI) 2023. The
 first two authors contributed equally
ACM-class: I.5; J.3
\\
 We present a novel learning-based method that achieves state-of-the-art
performance on several heart rate estimation benchmarks extracted from
photoplethysmography signals (PPG). We consider the evolution of the heart rate
in the context of a discrete-time stochastic process that we represent as a
hidden Markov model. We derive a distribution over possible heart rate values
for a given PPG signal window through a trained neural network. Using belief
propagation, we incorporate the statistical distribution of heart rate changes
to refine these estimates in a temporal context. From this, we obtain a
quantized probability distribution over the range of possible heart rate values
that captures a meaningful and well-calibrated estimate of the inherent
predictive uncertainty. We show the robustness of our method on eight public
datasets with three different cross-validation experiments.
\\ ( https://arxiv.org/abs/2306.07730 ,  1276kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07735
Date: Tue, 13 Jun 2023 12:40:39 GMT   (1763kb,D)

Title: Vector-Quantized Graph Auto-Encoder
Authors: Yoann Boget, Magda Gregorova, Alexandros Kalousis
Categories: cs.LG
\\
 In this work, we addresses the problem of modeling distributions of graphs.
We introduce the Vector-Quantized Graph Auto-Encoder (VQ-GAE), a
permutation-equivariant discrete auto-encoder and designed to model the
distribution of graphs. By exploiting the permutation-equivariance of graph
neural networks (GNNs), our autoencoder circumvents the problem of the ordering
of the graph representation. We leverage the capability of GNNs to capture
local structures of graphs while employing vector-quantization to prevent the
mapping of discrete objects to a continuous latent space. Furthermore, the use
of autoregressive models enables us to capture the global structure of graphs
via the latent representation. We evaluate our model on standard datasets used
for graph generation and observe that it achieves excellent performance on some
of the most salient evaluation metrics compared to the state-of-the-art.
\\ ( https://arxiv.org/abs/2306.07735 ,  1763kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07737
Date: Tue, 13 Jun 2023 12:43:59 GMT   (498kb,D)

Title: Robustness and Generalization Performance of Deep Learning Models on
 Cyber-Physical Systems: A Comparative Study
Authors: Alexander Windmann and Henrik Steude and Oliver Niggemann
Categories: cs.LG cs.AI
Comments: Accepted at the IJCAI 2023 Workshop of Artificial Intelligence for
 Time Series Analysis (AI4TS)
\\
 Deep learning (DL) models have seen increased attention for time series
forecasting, yet the application on cyber-physical systems (CPS) is hindered by
the lacking robustness of these methods. Thus, this study evaluates the
robustness and generalization performance of DL architectures on multivariate
time series data from CPS. Our investigation focuses on the models' ability to
handle a range of perturbations, such as sensor faults and noise, and assesses
their impact on overall performance. Furthermore, we test the generalization
and transfer learning capabilities of these models by exposing them to
out-of-distribution (OOD) samples. These include deviations from standard
system operations, while the core dynamics of the underlying physical system
are preserved. Additionally, we test how well the models respond to several
data augmentation techniques, including added noise and time warping. Our
experimental framework utilizes a simulated three-tank system, proposed as a
novel benchmark for evaluating the robustness and generalization performance of
DL algorithms in CPS data contexts. The findings reveal that certain DL model
architectures and training techniques exhibit superior effectiveness in
handling OOD samples and various perturbations. These insights have significant
implications for the development of DL models that deliver reliable and robust
performance in real-world CPS applications.
\\ ( https://arxiv.org/abs/2306.07737 ,  498kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07741
Date: Tue, 13 Jun 2023 12:58:12 GMT   (856kb,D)

Title: Stepsize Learning for Policy Gradient Methods in Contextual Markov
 Decision Processes
Authors: Luca Sabbioni, Francesco Corda, Marcello Restelli
Categories: cs.LG
\\
 Policy-based algorithms are among the most widely adopted techniques in
model-free RL, thanks to their strong theoretical groundings and good
properties in continuous action spaces. Unfortunately, these methods require
precise and problem-specific hyperparameter tuning to achieve good performance,
and tend to struggle when asked to accomplish a series of heterogeneous tasks.
In particular, the selection of the step size has a crucial impact on their
ability to learn a highly performing policy, affecting the speed and the
stability of the training process, and often being the main culprit for poor
results. In this paper, we tackle these issues with a Meta Reinforcement
Learning approach, by introducing a new formulation, known as meta-MDP, that
can be used to solve any hyperparameter selection problem in RL with contextual
processes. After providing a theoretical Lipschitz bound to the difference of
performance in different tasks, we adopt the proposed framework to train a
batch RL algorithm to dynamically recommend the most adequate step size for
different policies and tasks. In conclusion, we present an experimental
campaign to show the advantages of selecting an adaptive learning rate in
heterogeneous environments.
\\ ( https://arxiv.org/abs/2306.07741 ,  856kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07745
Date: Tue, 13 Jun 2023 13:01:42 GMT   (81kb,D)

Title: Kernelized Reinforcement Learning with Order Optimal Regret Bounds
Authors: Sattar Vakili, Julia Olkhovskaya
Categories: cs.LG cs.AI stat.ML
\\
 Reinforcement learning (RL) has shown empirical success in various real world
settings with complex models and large state-action spaces. The existing
analytical results, however, typically focus on settings with a small number of
state-actions or simple models such as linearly modeled state-action value
functions. To derive RL policies that efficiently handle large state-action
spaces with more general value functions, some recent works have considered
nonlinear function approximation using kernel ridge regression. We propose
$\pi$-KRVI, an optimistic modification of least-squares value iteration, when
the state-action value function is represented by an RKHS. We prove the first
order-optimal regret guarantees under a general setting. Our results show a
significant polynomial in the number of episodes improvement over the state of
the art. In particular, with highly non-smooth kernels (such as Neural Tangent
kernel or some Mat\'ern kernels) the existing results lead to trivial
(superlinear in the number of episodes) regret bounds. We show a sublinear
regret bound that is order optimal in the case of Mat\'ern kernels where a
lower bound on regret is known.
\\ ( https://arxiv.org/abs/2306.07745 ,  81kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07749
Date: Tue, 13 Jun 2023 13:08:31 GMT   (203kb,D)

Title: Provably Learning Nash Policies in Constrained Markov Potential Games
Authors: Pragnya Alatur, Giorgia Ramponi, Niao He, Andreas Krause
Categories: cs.LG cs.GT cs.MA
Comments: 30 pages
\\
 Multi-agent reinforcement learning (MARL) addresses sequential
decision-making problems with multiple agents, where each agent optimizes its
own objective. In many real-world instances, the agents may not only want to
optimize their objectives, but also ensure safe behavior. For example, in
traffic routing, each car (agent) aims to reach its destination quickly
(objective) while avoiding collisions (safety). Constrained Markov Games (CMGs)
are a natural formalism for safe MARL problems, though generally intractable.
In this work, we introduce and study Constrained Markov Potential Games
(CMPGs), an important class of CMGs. We first show that a Nash policy for CMPGs
can be found via constrained optimization. One tempting approach is to solve it
by Lagrangian-based primal-dual methods. As we show, in contrast to the
single-agent setting, however, CMPGs do not satisfy strong duality, rendering
such approaches inapplicable and potentially unsafe. To solve the CMPG problem,
we propose our algorithm Coordinate-Ascent for CMPGs (CA-CMPG), which provably
converges to a Nash policy in tabular, finite-horizon CMPGs. Furthermore, we
provide the first sample complexity bounds for learning Nash policies in
unknown CMPGs, and, which under additional assumptions, guarantee safe
exploration.
\\ ( https://arxiv.org/abs/2306.07749 ,  203kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07761
Date: Tue, 13 Jun 2023 13:19:20 GMT   (1104kb,D)

Title: Multi-Fidelity Multi-Armed Bandits Revisited
Authors: Xuchuang Wang, Qingyun Wu, Wei Chen, John C.S. Lui
Categories: cs.LG stat.ML
\\
 We study the multi-fidelity multi-armed bandit (MF-MAB), an extension of the
canonical multi-armed bandit (MAB) problem. MF-MAB allows each arm to be pulled
with different costs (fidelities) and observation accuracy. We study both the
best arm identification with fixed confidence (BAI) and the regret minimization
objectives. For BAI, we present (a) a cost complexity lower bound, (b) an
algorithmic framework with two alternative fidelity selection procedures, and
(c) both procedures' cost complexity upper bounds. From both cost complexity
bounds of MF-MAB, one can recover the standard sample complexity bounds of the
classic (single-fidelity) MAB. For regret minimization of MF-MAB, we propose a
new regret definition, prove its problem-independent regret lower bound
$\Omega(K^{1/3}\Lambda^{2/3})$ and problem-dependent lower bound $\Omega(K\log
\Lambda)$, where $K$ is the number of arms and $\Lambda$ is the decision budget
in terms of cost, and devise an elimination-based algorithm whose worst-cost
regret upper bound matches its corresponding lower bound up to some logarithmic
terms and, whose problem-dependent bound matches its corresponding lower bound
in terms of $\Lambda$.
\\ ( https://arxiv.org/abs/2306.07761 ,  1104kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07775
Date: Tue, 13 Jun 2023 13:56:56 GMT   (1309kb,D)

Title: iPDP: On Partial Dependence Plots in Dynamic Modeling Scenarios
Authors: Maximilian Muschalik, Fabian Fumagalli, Rohit Jagtani, Barbara Hammer,
 Eyke H\"ullermeier
Categories: cs.LG cs.AI eess.SP
Comments: This preprint has not undergone peer review or any post-submission
 improvements or corrections
\\
 Post-hoc explanation techniques such as the well-established partial
dependence plot (PDP), which investigates feature dependencies, are used in
explainable artificial intelligence (XAI) to understand black-box machine
learning models. While many real-world applications require dynamic models that
constantly adapt over time and react to changes in the underlying distribution,
XAI, so far, has primarily considered static learning environments, where
models are trained in a batch mode and remain unchanged. We thus propose a
novel model-agnostic XAI framework called incremental PDP (iPDP) that extends
on the PDP to extract time-dependent feature effects in non-stationary learning
environments. We formally analyze iPDP and show that it approximates a
time-dependent variant of the PDP that properly reacts to real and virtual
concept drift. The time-sensitivity of iPDP is controlled by a single smoothing
parameter, which directly corresponds to the variance and the approximation
error of iPDP in a static learning environment. We illustrate the efficacy of
iPDP by showcasing an example application for drift detection and conducting
multiple experiments on real-world and synthetic data sets and streams.
\\ ( https://arxiv.org/abs/2306.07775 ,  1309kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07796
Date: Tue, 13 Jun 2023 14:17:25 GMT   (9686kb,D)

Title: Finite Gaussian Neurons: Defending against adversarial attacks by making
 neural networks say "I don't know"
Authors: Felix Grezes
Categories: cs.LG cs.CR
Comments: PhD thesis
\\
 Since 2014, artificial neural networks have been known to be vulnerable to
adversarial attacks, which can fool the network into producing wrong or
nonsensical outputs by making humanly imperceptible alterations to inputs.
While defenses against adversarial attacks have been proposed, they usually
involve retraining a new neural network from scratch, a costly task. In this
work, I introduce the Finite Gaussian Neuron (FGN), a novel neuron architecture
for artificial neural networks. My works aims to: - easily convert existing
models to Finite Gaussian Neuron architecture, - while preserving the existing
model's behavior on real data, - and offering resistance against adversarial
attacks. I show that converted and retrained Finite Gaussian Neural Networks
(FGNN) always have lower confidence (i.e., are not overconfident) in their
predictions over randomized and Fast Gradient Sign Method adversarial images
when compared to classical neural networks, while maintaining high accuracy and
confidence over real MNIST images. To further validate the capacity of Finite
Gaussian Neurons to protect from adversarial attacks, I compare the behavior of
FGNs to that of Bayesian Neural Networks against both randomized and
adversarial images, and show how the behavior of the two architectures differs.
Finally I show some limitations of the FGN models by testing them on the more
complex SPEECHCOMMANDS task, against the stronger Carlini-Wagner and Projected
Gradient Descent adversarial attacks.
\\ ( https://arxiv.org/abs/2306.07796 ,  9686kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07803
Date: Tue, 13 Jun 2023 14:25:26 GMT   (5286kb,D)

Title: Inferring dynamic regulatory interaction graphs from time series data
 with perturbations
Authors: Dhananjay Bhaskar, Sumner Magruder, Edward De Brouwer, Aarthi Venkat,
 Frederik Wenkel, Guy Wolf, Smita Krishnaswamy
Categories: cs.LG
\\
 Complex systems are characterized by intricate interactions between entities
that evolve dynamically over time. Accurate inference of these dynamic
relationships is crucial for understanding and predicting system behavior. In
this paper, we propose Regulatory Temporal Interaction Network Inference
(RiTINI) for inferring time-varying interaction graphs in complex systems using
a novel combination of space-and-time graph attentions and graph neural
ordinary differential equations (ODEs). RiTINI leverages time-lapse signals on
a graph prior, as well as perturbations of signals at various nodes in order to
effectively capture the dynamics of the underlying system. This approach is
distinct from traditional causal inference networks, which are limited to
inferring acyclic and static graphs. In contrast, RiTINI can infer cyclic,
directed, and time-varying graphs, providing a more comprehensive and accurate
representation of complex systems. The graph attention mechanism in RiTINI
allows the model to adaptively focus on the most relevant interactions in time
and space, while the graph neural ODEs enable continuous-time modeling of the
system's dynamics. We evaluate RiTINI's performance on various simulated and
real-world datasets, demonstrating its state-of-the-art capability in inferring
interaction graphs compared to previous methods.
\\ ( https://arxiv.org/abs/2306.07803 ,  5286kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07818
Date: Tue, 13 Jun 2023 14:50:03 GMT   (1892kb,D)

Title: A Primal-Dual-Critic Algorithm for Offline Constrained Reinforcement
 Learning
Authors: Kihyuk Hong, Yuhang Li, Ambuj Tewari
Categories: cs.LG stat.ML
\\
 Offline constrained reinforcement learning (RL) aims to learn a policy that
maximizes the expected cumulative reward subject to constraints on expected
value of cost functions using an existing dataset. In this paper, we propose
Primal-Dual-Critic Algorithm (PDCA), a novel algorithm for offline constrained
RL with general function approximation. PDCA runs a primal-dual algorithm on
the Lagrangian function estimated by critics. The primal player employs a
no-regret policy optimization oracle to maximize the Lagrangian estimate given
any choices of the critics and the dual player. The dual player employs a
no-regret online linear optimization oracle to minimize the Lagrangian estimate
given any choices of the critics and the primal player. We show that PDCA can
successfully find a near saddle point of the Lagrangian, which is nearly
optimal for the constrained RL problem. Unlike previous work that requires
concentrability and strong Bellman completeness assumptions, PDCA only requires
concentrability and value function/marginalized importance weight realizability
assumptions.
\\ ( https://arxiv.org/abs/2306.07818 ,  1892kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07850
Date: Tue, 13 Jun 2023 15:29:23 GMT   (358kb,D)

Title: Exact Mean Square Linear Stability Analysis for SGD
Authors: Rotem Mulayoff, Tomer Michaeli
Categories: cs.LG
Comments: Preprint
\\
 The dynamical stability of optimization methods at the vicinity of minima of
the loss has recently attracted significant attention. For gradient descent
(GD), stable convergence is possible only to minima that are sufficiently flat
w.r.t. the step size, and those have been linked with favorable properties of
the trained model. However, while the stability threshold of GD is well-known,
to date, no explicit expression has been derived for the exact threshold of
stochastic GD (SGD). In this paper, we derive such a closed-form expression.
Specifically, we provide an explicit condition on the step size $\eta$ that is
both necessary and sufficient for the stability of SGD in the mean square
sense. Our analysis sheds light on the precise role of the batch size $B$.
Particularly, we show that the stability threshold is a monotonically
non-decreasing function of the batch size, which means that reducing the batch
size can only hurt stability. Furthermore, we show that SGD's stability
threshold is equivalent to that of a process which takes in each iteration a
full batch gradient step w.p. $1-p$, and a single sample gradient step w.p.
$p$, where $p \approx 1/B $. This indicates that even with moderate batch
sizes, SGD's stability threshold is very close to that of GD's. Finally, we
prove simple necessary conditions for stability, which depend on the batch
size, and are easier to compute than the precise threshold. We demonstrate our
theoretical findings through experiments on the MNIST dataset.
\\ ( https://arxiv.org/abs/2306.07850 ,  358kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07858
Date: Tue, 13 Jun 2023 15:43:04 GMT   (833kb,D)

Title: Additive Causal Bandits with Unknown Graph
Authors: Alan Malek and Virginia Aglietti and Silvia Chiappa
Categories: cs.LG stat.ML
Journal-ref: International Conference on Machine Learning, 2023
\\
 We explore algorithms to select actions in the causal bandit setting where
the learner can choose to intervene on a set of random variables related by a
causal graph, and the learner sequentially chooses interventions and observes a
sample from the interventional distribution. The learner's goal is to quickly
find the intervention, among all interventions on observable variables, that
maximizes the expectation of an outcome variable. We depart from previous
literature by assuming no knowledge of the causal graph except that latent
confounders between the outcome and its ancestors are not present. We first
show that the unknown graph problem can be exponentially hard in the parents of
the outcome. To remedy this, we adopt an additional additive assumption on the
outcome which allows us to solve the problem by casting it as an additive
combinatorial linear bandit problem with full-bandit feedback. We propose a
novel action-elimination algorithm for this setting, show how to apply this
algorithm to the causal bandit problem, provide sample complexity bounds, and
empirically validate our findings on a suite of randomly generated causal
models, effectively showing that one does not need to explicitly learn the
parents of the outcome to identify the best intervention.
\\ ( https://arxiv.org/abs/2306.07858 ,  833kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07874
Date: Tue, 13 Jun 2023 16:04:14 GMT   (1222kb,D)

Title: Taxonomy-Structured Domain Adaptation
Authors: Tianyi Liu, Zihao Xu, Hao He, Guang-Yuan Hao, Guang-He Lee, Hao Wang
Categories: cs.LG cs.AI cs.CV
Comments: Accepted by ICML 2023
\\
 Domain adaptation aims to mitigate distribution shifts among different
domains. However, traditional formulations are mostly limited to categorical
domains, greatly simplifying nuanced domain relationships in the real world. In
this work, we tackle a generalization with taxonomy-structured domains, which
formalizes domains with nested, hierarchical similarity structures such as
animal species and product catalogs. We build on the classic adversarial
framework and introduce a novel taxonomist, which competes with the adversarial
discriminator to preserve the taxonomy information. The equilibrium recovers
the classic adversarial domain adaptation's solution if given a non-informative
domain taxonomy (e.g., a flat taxonomy where all leaf nodes connect to the root
node) while yielding non-trivial results with other taxonomies. Empirically,
our method achieves state-of-the-art performance on both synthetic and
real-world datasets with successful adaptation. Code is available at
https://github.com/Wang-ML-Lab/TSDA.
\\ ( https://arxiv.org/abs/2306.07874 ,  1222kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07883
Date: Tue, 13 Jun 2023 16:21:34 GMT   (27313kb,D)

Title: Temporal Gradient Inversion Attacks with Robust Optimization
Authors: Bowen Li, Hanlin Gu, Ruoxin Chen, Jie Li, Chentao Wu, Na Ruan, Xueming
 Si, Lixin Fan
Categories: cs.LG cs.CR
Comments: 24 pages
\\
 Federated Learning (FL) has emerged as a promising approach for collaborative
model training without sharing private data. However, privacy concerns
regarding information exchanged during FL have received significant research
attention. Gradient Inversion Attacks (GIAs) have been proposed to reconstruct
the private data retained by local clients from the exchanged gradients. While
recovering private data, the data dimensions and the model complexity increase,
which thwart data reconstruction by GIAs. Existing methods adopt prior
knowledge about private data to overcome those challenges. In this paper, we
first observe that GIAs with gradients from a single iteration fail to
reconstruct private data due to insufficient dimensions of leaked gradients,
complex model architectures, and invalid gradient information. We investigate a
Temporal Gradient Inversion Attack with a Robust Optimization framework, called
TGIAs-RO, which recovers private data without any prior knowledge by leveraging
multiple temporal gradients. To eliminate the negative impacts of outliers,
e.g., invalid gradients for collaborative optimization, robust statistics are
proposed. Theoretical guarantees on the recovery performance and robustness of
TGIAs-RO against invalid gradients are also provided. Extensive empirical
results on MNIST, CIFAR10, ImageNet and Reuters 21578 datasets show that the
proposed TGIAs-RO with 10 temporal gradients improves reconstruction
performance compared to state-of-the-art methods, even for large batch sizes
(up to 128), complex models like ResNet18, and large datasets like ImageNet
(224*224 pixels). Furthermore, the proposed attack method inspires further
exploration of privacy-preserving methods in the context of FL.
\\ ( https://arxiv.org/abs/2306.07883 ,  27313kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07892
Date: Tue, 13 Jun 2023 16:34:02 GMT   (71kb,D)

Title: Robustly Learning a Single Neuron via Sharpness
Authors: Puqian Wang, Nikos Zarifis, Ilias Diakonikolas, Jelena Diakonikolas
Categories: cs.LG cs.DS math.OC math.ST stat.ML stat.TH
\\
 We study the problem of learning a single neuron with respect to the
$L_2^2$-loss in the presence of adversarial label noise. We give an efficient
algorithm that, for a broad family of activations including ReLUs, approximates
the optimal $L_2^2$-error within a constant factor. Our algorithm applies under
much milder distributional assumptions compared to prior work. The key
ingredient enabling our results is a novel connection to local error bounds
from optimization theory.
\\ ( https://arxiv.org/abs/2306.07892 ,  71kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07903
Date: Tue, 13 Jun 2023 16:54:13 GMT   (32kb)

Title: Tight Memory-Regret Lower Bounds for Streaming Bandits
Authors: Shaoang Li, Lan Zhang, Junhao Wang, Xiang-Yang Li
Categories: cs.LG
\\
 In this paper, we investigate the streaming bandits problem, wherein the
learner aims to minimize regret by dealing with online arriving arms and
sublinear arm memory. We establish the tight worst-case regret lower bound of
$\Omega \left( (TB)^{\alpha} K^{1-\alpha}\right), \alpha = 2^{B} / (2^{B+1}-1)$
for any algorithm with a time horizon $T$, number of arms $K$, and number of
passes $B$. The result reveals a separation between the stochastic bandits
problem in the classical centralized setting and the streaming setting with
bounded arm memory. Notably, in comparison to the well-known
$\Omega(\sqrt{KT})$ lower bound, an additional double logarithmic factor is
unavoidable for any streaming bandits algorithm with sublinear memory
permitted. Furthermore, we establish the first instance-dependent lower bound
of $\Omega \left(T^{1/(B+1)} \sum_{\Delta_x>0} \frac{\mu^*}{\Delta_x}\right)$
for streaming bandits. These lower bounds are derived through a unique
reduction from the regret-minimization setting to the sample complexity
analysis for a sequence of $\epsilon$-optimal arms identification tasks, which
maybe of independent interest. To complement the lower bound, we also provide a
multi-pass algorithm that achieves a regret upper bound of $\tilde{O} \left(
(TB)^{\alpha} K^{1 - \alpha}\right)$ using constant arm memory.
\\ ( https://arxiv.org/abs/2306.07903 ,  32kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07905
Date: Tue, 13 Jun 2023 16:56:13 GMT   (136kb,D)

Title: Omega: Optimistic EMA Gradients
Authors: Juan Ramirez, Rohan Sukumaran, Quentin Bertrand, Gauthier Gidel
Categories: cs.LG math.OC stat.ML
Comments: Oral at the LatinX in AI workshop @ ICML 2023
\\
 Stochastic min-max optimization has gained interest in the machine learning
community with the advancements in GANs and adversarial training. Although game
optimization is fairly well understood in the deterministic setting, some
issues persist in the stochastic regime. Recent work has shown that stochastic
gradient descent-ascent methods such as the optimistic gradient are highly
sensitive to noise or can fail to converge. Although alternative strategies
exist, they can be prohibitively expensive. We introduce Omega, a method with
optimistic-like updates that mitigates the impact of noise by incorporating an
EMA of historic gradients in its update rule. We also explore a variation of
this algorithm that incorporates momentum. Although we do not provide
convergence guarantees, our experiments on stochastic games show that Omega
outperforms the optimistic gradient method when applied to linear players.
\\ ( https://arxiv.org/abs/2306.07905 ,  136kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07916
Date: Tue, 13 Jun 2023 17:19:37 GMT   (742kb,D)

Title: Identification of Nonlinear Latent Hierarchical Models
Authors: Lingjing Kong, Biwei Huang, Feng Xie, Eric Xing, Yuejie Chi, Kun Zhang
Categories: cs.LG cs.AI stat.ML
\\
 Identifying latent variables and causal structures from observational data is
essential to many real-world applications involving biological data, medical
data, and unstructured data such as images and languages. However, this task
can be highly challenging, especially when observed variables are generated by
causally related latent variables and the relationships are nonlinear. In this
work, we investigate the identification problem for nonlinear latent
hierarchical causal models in which observed variables are generated by a set
of causally related latent variables, and some latent variables may not have
observed children. We show that the identifiability of both causal structure
and latent variables can be achieved under mild assumptions: on causal
structures, we allow for the existence of multiple paths between any pair of
variables in the graph, which relaxes latent tree assumptions in prior work; on
structural functions, we do not make parametric assumptions, thus permitting
general nonlinearity and multi-dimensional continuous variables. Specifically,
we first develop a basic identification criterion in the form of novel
identifiability guarantees for an elementary latent variable model. Leveraging
this criterion, we show that both causal structures and latent variables of the
hierarchical model can be identified asymptotically by explicitly constructing
an estimation procedure. To the best of our knowledge, our work is the first to
establish identifiability guarantees for both causal structures and latent
variables in nonlinear latent hierarchical models.
\\ ( https://arxiv.org/abs/2306.07916 ,  742kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07918
Date: Tue, 13 Jun 2023 17:22:59 GMT   (5781kb,D)

Title: Causal Mediation Analysis with Multi-dimensional and Indirectly Observed
 Mediators
Authors: Ziyang Jiang, Yiling Liu, Michael H. Klein, Ahmed Aloui, Yiman Ren,
 Keyu Li, Vahid Tarokh, David Carlson
Categories: cs.LG stat.ML
Comments: 16 pages, 4 figures, 5 tables
\\
 Causal mediation analysis (CMA) is a powerful method to dissect the total
effect of a treatment into direct and mediated effects within the potential
outcome framework. This is important in many scientific applications to
identify the underlying mechanisms of a treatment effect. However, in many
scientific applications the mediator is unobserved, but there may exist related
measurements. For example, we may want to identify how changes in brain
activity or structure mediate an antidepressant's effect on behavior, but we
may only have access to electrophysiological or imaging brain measurements. To
date, most CMA methods assume that the mediator is one-dimensional and
observable, which oversimplifies such real-world scenarios. To overcome this
limitation, we introduce a CMA framework that can handle complex and indirectly
observed mediators based on the identifiable variational autoencoder (iVAE)
architecture. We prove that the true joint distribution over observed and
latent variables is identifiable with the proposed method. Additionally, our
framework captures a disentangled representation of the indirectly observed
mediator and yields accurate estimation of the direct and mediated effects in
synthetic and semi-synthetic experiments, providing evidence of its potential
utility in real-world applications.
\\ ( https://arxiv.org/abs/2306.07918 ,  5781kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07919
Date: Tue, 13 Jun 2023 17:24:37 GMT   (3534kb,D)

Title: Skill Disentanglement for Imitation Learning from Suboptimal
 Demonstrations
Authors: Tianxiang Zhao, Wenchao Yu, Suhang Wang, Lu Wang, Xiang Zhang, Yuncong
 Chen, Yanchi Liu, Wei Cheng, Haifeng Chen
Categories: cs.LG
Journal-ref: Proceedings of the 29th ACM SIGKDD Conference on Knowledge
 Discovery and Data Mining (KDD '23), August 6--10, 2023, Long Beach, CA, USA
DOI: 10.1145/3580305.3599506
\\
 Imitation learning has achieved great success in many sequential
decision-making tasks, in which a neural agent is learned by imitating
collected human demonstrations. However, existing algorithms typically require
a large number of high-quality demonstrations that are difficult and expensive
to collect. Usually, a trade-off needs to be made between demonstration quality
and quantity in practice. Targeting this problem, in this work we consider the
imitation of sub-optimal demonstrations, with both a small clean demonstration
set and a large noisy set. Some pioneering works have been proposed, but they
suffer from many limitations, e.g., assuming a demonstration to be of the same
optimality throughout time steps and failing to provide any interpretation
w.r.t knowledge learned from the noisy set. Addressing these problems, we
propose {\method} by evaluating and imitating at the sub-demonstration level,
encoding action primitives of varying quality into different skills.
Concretely, {\method} consists of a high-level controller to discover skills
and a skill-conditioned module to capture action-taking policies, and is
trained following a two-phase pipeline by first discovering skills with all
demonstrations and then adapting the controller to only the clean set. A
mutual-information-based regularization and a dynamic sub-demonstration
optimality estimator are designed to promote disentanglement in the skill
space. Extensive experiments are conducted over two gym environments and a
real-world healthcare dataset to demonstrate the superiority of {\method} in
learning from sub-optimal demonstrations and its improved interpretability by
examining learned skills.
\\ ( https://arxiv.org/abs/2306.07919 ,  3534kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07923
Date: Tue, 13 Jun 2023 17:29:50 GMT   (166kb,D)

Title: Oracle-Efficient Pessimism: Offline Policy Optimization in Contextual
 Bandits
Authors: Lequn Wang, Akshay Krishnamurthy, Aleksandrs Slivkins
Categories: cs.LG
\\
 We consider policy optimization in contextual bandits, where one is given a
fixed dataset of logged interactions. While pessimistic regularizers are
typically used to mitigate distribution shift, prior implementations thereof
are not computationally efficient. We present the first oracle-efficient
algorithm for pessimistic policy optimization: it reduces to supervised
learning, leading to broad applicability. We also obtain best-effort
statistical guarantees analogous to those for pessimistic approaches in prior
work. We instantiate our approach for both discrete and continuous actions. We
perform extensive experiments in both settings, showing advantage over
unregularized policy optimization across a wide range of configurations.
\\ ( https://arxiv.org/abs/2306.07923 ,  166kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07959
Date: Tue, 13 Jun 2023 17:55:30 GMT   (536kb,D)

Title: Privacy Preserving Bayesian Federated Learning in Heterogeneous Settings
Authors: Disha Makhija and Joydeep Ghosh and Nhat Ho
Categories: cs.LG
\\
 In several practical applications of federated learning (FL), the clients are
highly heterogeneous in terms of both their data and compute resources, and
therefore enforcing the same model architecture for each client is very
limiting. Moreover, the need for uncertainty quantification and data privacy
constraints are often particularly amplified for clients that have limited
local data. This paper presents a unified FL framework to simultaneously
address all these constraints and concerns, based on training customized local
Bayesian models that learn well even in the absence of large local datasets. A
Bayesian framework provides a natural way of incorporating supervision in the
form of prior distributions. We use priors in the functional (output) space of
the networks to facilitate collaboration across heterogeneous clients.
Moreover, formal differential privacy guarantees are provided for this
framework. Experiments on standard FL datasets demonstrate that our approach
outperforms strong baselines in both homogeneous and heterogeneous settings and
under strict privacy constraints, while also providing characterizations of
model uncertainties.
\\ ( https://arxiv.org/abs/2306.07959 ,  536kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07960
Date: Tue, 13 Jun 2023 17:55:39 GMT   (4035kb,D)

Title: Supervised-Contrastive Loss Learns Orthogonal Frames and Batching
 Matters
Authors: Ganesh Ramachandra Kini, Vala Vakilian, Tina Behnia, Jaidev Gill,
 Christos Thrampoulidis
Categories: cs.LG stat.ML
\\
 Supervised contrastive loss (SCL) is a competitive and often superior
alternative to the cross-entropy (CE) loss for classification. In this paper we
ask: what differences in the learning process occur when the two different loss
functions are being optimized? To answer this question, our main finding is
that the geometry of embeddings learned by SCL forms an orthogonal frame (OF)
regardless of the number of training examples per class. This is in contrast to
the CE loss, for which previous work has shown that it learns embeddings
geometries that are highly dependent on the class sizes. We arrive at our
finding theoretically, by proving that the global minimizers of an
unconstrained features model with SCL loss and entry-wise non-negativity
constraints form an OF. We then validate the model's prediction by conducting
experiments with standard deep-learning models on benchmark vision datasets.
Finally, our analysis and experiments reveal that the batching scheme chosen
during SCL training plays a critical role in determining the quality of
convergence to the OF geometry. This finding motivates a simple algorithm
wherein the addition of a few binding examples in each batch significantly
speeds up the occurrence of the OF geometry.
\\ ( https://arxiv.org/abs/2306.07960 ,  4035kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07967
Date: Tue, 13 Jun 2023 17:59:32 GMT   (1089kb,D)

Title: One-for-All: Generalized LoRA for Parameter-Efficient Fine-tuning
Authors: Arnav Chavan and Zhuang Liu and Deepak Gupta and Eric Xing and
 Zhiqiang Shen
Categories: cs.LG cs.AI cs.CV
Comments: Technical report
\\
 We present Generalized LoRA (GLoRA), an advanced approach for universal
parameter-efficient fine-tuning tasks. Enhancing Low-Rank Adaptation (LoRA),
GLoRA employs a generalized prompt module to optimize pre-trained model weights
and adjust intermediate activations, providing more flexibility and capability
across diverse tasks and datasets. Moreover, GLoRA facilitates efficient
parameter adaptation by employing a scalable, modular, layer-wise structure
search that learns individual adapter of each layer. Originating from a unified
mathematical formulation, GLoRA exhibits strong transfer learning, few-shot
learning and domain generalization abilities, as it adjusts to new tasks
through additional dimensions on weights and activations. Comprehensive
experiments demonstrate that GLoRA outperforms all previous methods in natural,
specialized, and structured benchmarks, achieving superior accuracy with fewer
parameters and computations on various datasets. Furthermore, our structural
re-parameterization design ensures that GLoRA incurs no extra inference cost,
rendering it a practical solution for resource-limited applications. Code is
available at: https://github.com/Arnav0400/ViT-Slim/tree/master/GLoRA.
\\ ( https://arxiv.org/abs/2306.07967 ,  1089kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07344
Date: Mon, 12 Jun 2023 18:06:29 GMT   (8118kb,D)

Title: Towards a Robust Sensor Fusion Step for 3D Object Detection on Corrupted
 Data
Authors: Maciej K. Wozniak, Viktor Karefjards, Marko Thiel, Patric Jensfelt
Categories: cs.RO cs.CV
\\
 Multimodal sensor fusion methods for 3D object detection have been
revolutionizing the autonomous driving research field. Nevertheless, most of
these methods heavily rely on dense LiDAR data and accurately calibrated
sensors which is often not the case in real-world scenarios. Data from LiDAR
and cameras often come misaligned due to the miscalibration, decalibration, or
different frequencies of the sensors. Additionally, some parts of the LiDAR
data may be occluded and parts of the data may be missing due to hardware
malfunction or weather conditions. This work presents a novel fusion step that
addresses data corruptions and makes sensor fusion for 3D object detection more
robust. Through extensive experiments, we demonstrate that our method performs
on par with state-of-the-art approaches on normal data and outperforms them on
misaligned data.
\\ ( https://arxiv.org/abs/2306.07344 ,  8118kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07363
Date: Mon, 12 Jun 2023 18:39:03 GMT   (8939kb,D)

Title: H-SLAM: Hybrid Direct-Indirect Visual SLAM
Authors: Georges Younes, Douaa Khalil, John Zelek, Daniel Asmar
Categories: cs.RO cs.CV
\\
 The recent success of hybrid methods in monocular odometry has led to many
attempts to generalize the performance gains to hybrid monocular SLAM. However,
most attempts fall short in several respects, with the most prominent issue
being the need for two different map representations (local and global maps),
with each requiring different, computationally expensive, and often redundant
processes to maintain. Moreover, these maps tend to drift with respect to each
other, resulting in contradicting pose and scene estimates, and leading to
catastrophic failure. In this paper, we propose a novel approach that makes use
of descriptor sharing to generate a single inverse depth scene representation.
This representation can be used locally, queried globally to perform loop
closure, and has the ability to re-activate previously observed map points
after redundant points are marginalized from the local map, eliminating the
need for separate and redundant map maintenance processes. The maps generated
by our method exhibit no drift between each other, and can be computed at a
fraction of the computational cost and memory footprint required by other
monocular SLAM systems. Despite the reduced resource requirements, the proposed
approach maintains its robustness and accuracy, delivering performance
comparable to state-of-the-art SLAM methods (e.g., LDSO, ORB-SLAM3) on the
majority of sequences from well-known datasets like EuRoC, KITTI, and TUM VI.
The source code is available at: https://github.com/AUBVRL/fslam_ros_docker.
\\ ( https://arxiv.org/abs/2306.07363 ,  8939kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07385
Date: Mon, 12 Jun 2023 19:25:19 GMT   (2812kb,D)

Title: Range Limited Coverage Control using Air-Ground Multi-Robot Teams
Authors: Max Rudolph, Sean Wilson, Magnus Egerstedt
Categories: cs.RO cs.MA
Comments: Published at 2021 IEEE International Conference on Robotics and
 Automation (ICRA)
DOI: 10.1109/ICRA48506.2021.9561706
\\
 In this paper, we investigate how heterogeneous multi-robot systems with
different sensing capabilities can observe a domain with an apriori unknown
density function. Common coverage control techniques are targeted towards
homogeneous teams of robots and do not consider what happens when the sensing
capabilities of the robots are vastly different. This work proposes an
extension to Lloyd's algorithm that fuses coverage information from
heterogeneous robots with differing sensing capabilities to effectively observe
a domain. Namely, we study a bimodal team of robots consisting of aerial and
ground agents. In our problem formulation we use aerial robots with coarse
domain sensors to approximate the number of ground robots needed within their
sensing region to effectively cover it. This information is relayed to ground
robots, who perform an extension to the Lloyd's algorithm that balances a
locally focused coverage controller with a globally focused distribution
controller. The stability of the Lloyd's algorithm extension is proven and its
performance is evaluated through simulation and experiments using the
Robotarium, a remotely-accessible, multi-robot testbed.
\\ ( https://arxiv.org/abs/2306.07385 ,  2812kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07392
Date: Mon, 12 Jun 2023 19:42:26 GMT   (21469kb,D)

Title: Learning Any-View 6DoF Robotic Grasping in Cluttered Scenes via Neural
 Surface Rendering
Authors: Snehal Jauhri, Ishikaa Lunawat, Georgia Chalvatzaki
Categories: cs.RO cs.CV cs.LG
Comments: Preprint
\\
 Robotic manipulation is critical for admitting robotic agents to various
application domains, like intelligent assistance. A major challenge therein is
the effective 6DoF grasping of objects in cluttered environments from any
viewpoint without requiring additional scene exploration. We introduce
$\textit{NeuGraspNet}$, a novel method for 6DoF grasp detection that leverages
recent advances in neural volumetric representations and surface rendering. Our
approach learns both global (scene-level) and local (grasp-level) neural
surface representations, enabling effective and fully implicit 6DoF grasp
quality prediction, even in unseen parts of the scene. Further, we reinterpret
grasping as a local neural surface rendering problem, allowing the model to
encode the interaction between the robot's end-effector and the object's
surface geometry. NeuGraspNet operates on single viewpoints and can sample
grasp candidates in occluded scenes, outperforming existing implicit and
semi-implicit baseline methods in the literature. We demonstrate the real-world
applicability of NeuGraspNet with a mobile manipulator robot, grasping in open
spaces with clutter by rendering the scene, reasoning about graspable areas of
different objects, and selecting grasps likely to succeed without colliding
with the environment. Visit our project website:
https://sites.google.com/view/neugraspnet
\\ ( https://arxiv.org/abs/2306.07392 ,  21469kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07419
Date: Mon, 12 Jun 2023 20:50:30 GMT   (5183kb,D)

Title: DeepTransition: Viability Leads to the Emergence of Gait Transitions in
 Learning Anticipatory Quadrupedal Locomotion Skills
Authors: Milad Shafiee, Guillaume Bellegarda, and Auke Ijspeert
Categories: cs.RO cs.AI cs.LG
\\
 Quadruped animals seamlessly transition between gaits as they change
locomotion speeds. While the most widely accepted explanation for gait
transitions is energy efficiency, there is no clear consensus on the
determining factor, nor on the potential effects from terrain properties. In
this article, we propose that viability, i.e. the avoidance of falls,
represents an important criterion for gait transitions. We investigate the
emergence of gait transitions through the interaction between supraspinal drive
(brain), the central pattern generator in the spinal cord, the body, and
exteroceptive sensing by leveraging deep reinforcement learning and robotics
tools. Consistent with quadruped animal data, we show that the walk-trot gait
transition for quadruped robots on flat terrain improves both viability and
energy efficiency. Furthermore, we investigate the effects of discrete terrain
(i.e. crossing successive gaps) on imposing gait transitions, and find the
emergence of trot-pronk transitions to avoid non-viable states. Compared with
other potential criteria such as peak forces and energy efficiency, viability
is the only improved factor after gait transitions on both flat and discrete
gap terrains, suggesting that viability could be a primary and universal
objective of gait transitions, while other criteria are secondary objectives
and/or a consequence of viability. Moreover, we deploy our learned controller
in sim-to-real hardware experiments and demonstrate state-of-the-art quadruped
agility in challenging scenarios, where the Unitree A1 quadruped autonomously
transitions gaits between trot and pronk to cross consecutive gaps of up to 30
cm (83.3 % of the body-length) at over 1.3 m/s.
\\ ( https://arxiv.org/abs/2306.07419 ,  5183kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07525
Date: Tue, 13 Jun 2023 03:38:05 GMT   (5351kb,D)

Title: Using Collision Momentum in Deep Reinforcement Learning Based
 Adversarial Pedestrian Modeling
Authors: Dianwei Chen, Ekim Yurtsever, Keith Redmill and Umit Ozguner
Categories: cs.RO cs.AI cs.LG
\\
 Recent research in pedestrian simulation often aims to develop realistic
behaviors in various situations, but it is challenging for existing algorithms
to generate behaviors that identify weaknesses in automated vehicles'
performance in extreme and unlikely scenarios and edge cases. To address this,
specialized pedestrian behavior algorithms are needed. Current research focuses
on realistic trajectories using social force models and reinforcement learning
based models. However, we propose a reinforcement learning algorithm that
specifically targets collisions and better uncovers unique failure modes of
automated vehicle controllers. Our algorithm is efficient and generates more
severe collisions, allowing for the identification and correction of weaknesses
in autonomous driving algorithms in complex and varied scenarios.
\\ ( https://arxiv.org/abs/2306.07525 ,  5351kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07537
Date: Tue, 13 Jun 2023 04:54:03 GMT   (6486kb,D)

Title: Hybrid and Oriented Harmonic Potentials for Safe Task Execution in
 Unknown Environment
Authors: Shuaikang Wang and Meng Guo
Categories: cs.RO
Comments: 15 pages, 11 figures
\\
 Harmonic potentials provide globally convergent potential fields that are
provably free of local minima. Due to its analytical format, it is particularly
suitable for generating safe and reliable robot navigation policies. However,
for complex environments that consist of a large number of overlapping
non-sphere obstacles, the computation of associated transformation functions
can be tedious. This becomes more apparent when: (i) the workspace is initially
unknown and the underlying potential fields are updated constantly as the robot
explores it; (ii) the high-level mission consists of sequential navigation
tasks among numerous regions, requiring the robot to switch between different
potentials. Thus, this work proposes an efficient and automated scheme to
construct harmonic potentials incrementally online as guided by the task
automaton. A novel two-layer harmonic tree (HT) structure is introduced that
facilitates the hybrid combination of oriented search algorithms for task
planning and harmonic-based navigation controllers for non-holonomic robots.
Both layers are adapted efficiently and jointly during online execution to
reflect the actual feasibility and cost of navigation within the updated
workspace. Global safety and convergence are ensured both for the high-level
task plan and the low-level robot trajectory. Known issues such as oscillation
or long-detours for purely potential-based methods and sharp-turns or high
computation complexity for purely search-based methods are prevented. Extensive
numerical simulation and hardware experiments are conducted against several
strong baselines.
\\ ( https://arxiv.org/abs/2306.07537 ,  6486kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07569
Date: Tue, 13 Jun 2023 06:44:02 GMT   (223kb,D)

Title: Ontological component-based description of robot capabilities
Authors: Bastien Dussard (LAAS, LAAS-RIS), Guillaume Sarthou, Aur\'elie Clodic
 (LAAS-IDEA, LAAS-RIS)
Categories: cs.RO
Comments: International Workshop on Working towards Ontology-based Standards
 for Robotics and Automation (WOSRA 2023 - 2nd Edition), Jun 2023, Londres,
 United Kingdom
\\
 A key aspect of a robot's knowledge base is self-awareness about what it is
capable of doing. It allows to define which tasks it can be assigned to and
which it cannot. We will refer to this knowledge as the Capability concept. As
capabilities stems from the components the robot owns, they can be linked
together. In this work, we hypothesize that this concept can be inferred from
the components rather than merely linked to them. Therefore, we introduce an
ontological means of inferring the agent's capabilities based on the components
it owns as well as low-level capabilities. This inference allows the agent to
acknowledge what it is able to do in a responsive way and it is generalizable
to external entities the agent can carry for example. To initiate an action,
the robot needs to link its capabilities with external entities. To do so, it
needs to infer affordance relations from its capabilities as well as the
external entity's dispositions. This work is part of a broader effort to
integrate social affordances into a Human-Robot collaboration context and is an
extension of an already existing ontology.
\\ ( https://arxiv.org/abs/2306.07569 ,  223kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07580
Date: Tue, 13 Jun 2023 07:09:11 GMT   (48004kb,D)

Title: SayTap: Language to Quadrupedal Locomotion
Authors: Yujin Tang, Wenhao Yu, Jie Tan, Heiga Zen, Aleksandra Faust, Tatsuya
 Harada
Categories: cs.RO
\\
 Large language models (LLMs) have demonstrated the potential to perform
high-level planning. Yet, it remains a challenge for LLMs to comprehend
low-level commands, such as joint angle targets or motor torques. This paper
proposes an approach to use foot contact patterns as an interface that bridges
human commands in natural language and a locomotion controller that outputs
these low-level commands. This results in an interactive system for quadrupedal
robots that allows the users to craft diverse locomotion behaviors flexibly. We
contribute an LLM prompt design, a reward function, and a method to expose the
controller to the feasible distribution of contact patterns. The results are a
controller capable of achieving diverse locomotion patterns that can be
transferred to real robot hardware. Compared with other design choices, the
proposed approach enjoys more than 50% success rate in predicting the correct
contact patterns and can solve 10 more tasks out of a total of 30 tasks. Our
project site is: https://saytap.github.io.
\\ ( https://arxiv.org/abs/2306.07580 ,  48004kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07647
Date: Tue, 13 Jun 2023 09:36:38 GMT   (11196kb,D)

Title: Multi-Robot Motion Planning: A Learning-Based Artificial Potential Field
 Solution
Authors: Dengyu Zhang, Guobin Zhu, Qingrui Zhang
Categories: cs.RO
Comments: 6 pages
\\
 Motion planning is a crucial aspect of robot autonomy as it involves
identifying a feasible motion path to a destination while taking into
consideration various constraints, such as input, safety, and performance
constraints, without violating either system or environment boundaries. This
becomes particularly challenging when multiple robots run without
communication, which compromises their real-time efficiency, safety, and
performance. In this paper, we present a learning-based potential field
algorithm that incorporates deep reinforcement learning into an artificial
potential field (APF). Specifically, we introduce an observation embedding
mechanism that pre-processes dynamic information about the environment and
develop a soft wall-following rule to improve trajectory smoothness. Our
method, while belonging to reactive planning, implicitly encodes environmental
properties. Additionally, our approach can scale up to any number of robots and
has demonstrated superior performance compared to APF and RL through numerical
simulations. Finally, experiments are conducted to highlight the effectiveness
of our proposed method.
\\ ( https://arxiv.org/abs/2306.07647 ,  11196kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07688
Date: Tue, 13 Jun 2023 11:02:22 GMT   (10312kb,D)

Title: Mobility Strategy of Multi-Limbed Climbing Robots for Asteroid
 Exploration
Authors: Warley F. R. Ribeiro, Kentaro Uno, Masazumi Imai, Koki Murase,
 Bar{\i}\c{s} Can Yal\c{c}{\i}n, Matteo El Hariry, Miguel A. Olivares-Mendez
 and Kazuya Yoshida
Categories: cs.RO
Comments: Submitted version of paper accepted for presentation at the CLAWAR
 2023 (26th International Conference on Climbing and Walking Robots and the
 Support Technologies for Mobile Machines)
\\
 Mobility on asteroids by multi-limbed climbing robots is expected to achieve
our exploration goals in such challenging environments. We propose a mobility
strategy to improve the locomotion safety of climbing robots in such harsh
environments that picture extremely low gravity and highly uneven terrain. Our
method plans the gait by decoupling the base and limbs' movements and adjusting
the main body pose to avoid ground collisions. The proposed approach includes a
motion planning that reduces the reactions generated by the robot's movement by
optimizing the swinging trajectory and distributing the momentum. Lower motion
reactions decrease the pulling forces on the grippers, avoiding the slippage
and flotation of the robot. Dynamic simulations and experiments demonstrate
that the proposed method could improve the robot's mobility on the surface of
asteroids.
\\ ( https://arxiv.org/abs/2306.07688 ,  10312kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07815
Date: Tue, 13 Jun 2023 14:45:21 GMT   (1323kb,D)

Title: Scenario Extraction from a Large Real-World Dataset for the Assessment
 of Automated Vehicles
Authors: Detian Guo, Manuel Mu\~noz S\'anchez, Erwin de Gelder, Tom P.J. van
 der Sande
Categories: cs.RO
Comments: 7 pages, ITSC 2023
\\
 Many players in the automotive field support scenario-based assessment of
automated vehicles (AVs), where individual traffic situations can be tested
and, thus, facilitate concluding on the performance of AVs in different
situations. Since an extremely large number of different scenarios can occur in
real-world traffic, the question is how to find a finite set of relevant
scenarios. Scenarios extracted from large real-world datasets represent
real-world traffic since real driving data is used. Extracting scenarios,
however, is challenging because (1) the scenarios to be tested should ensure
the AVs behave safely, which conflicts with the fact that the majority of the
data contains scenarios that are not interesting from a safety perspective, and
(2) extensive data processing is required, which hinders the utilization of
large real-world datasets. In this work, we propose a three-step approach for
extracting scenarios from real-world driving data. The first step is data
preprocessing to tackle the errors and noise in real-world data. The second
step performs data tagging to label actors' activities, their interactions with
each other, and their interactions with the environment. Finally, the scenarios
are extracted by searching for combinations of tags. The proposed approach is
evaluated using data simulated with CARLA and applied to a part of a large
real-world driving dataset, i.e., the Waymo Open Motion Dataset.
\\ ( https://arxiv.org/abs/2306.07815 ,  1323kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07894
Date: Tue, 13 Jun 2023 16:39:39 GMT   (672kb,D)

Title: iSLAM: Imperative SLAM
Authors: Taimeng Fu, Shaoshu Su, Chen Wang
Categories: cs.RO cs.CV
\\
 Simultaneous localization and mapping (SLAM) stands as one of the critical
challenges in robot navigation. Recent advancements suggest that methods based
on supervised learning deliver impressive performance in front-end odometry,
while traditional optimization-based methods still play a vital role in the
back-end for minimizing estimation drift. In this paper, we found that such
decoupled paradigm can lead to only sub-optimal performance, consequently
curtailing system capabilities and generalization potential. To solve this
problem, we proposed a novel self-supervised learning framework, imperative
SLAM (iSLAM), which fosters reciprocal correction between the front-end and
back-end, thus enhancing performance without necessitating any external
supervision. Specifically, we formulate a SLAM system as a bi-level
optimization problem so that the two components are bidirectionally connected.
As a result, the front-end model is able to learn global geometric knowledge
obtained through pose graph optimization by back-propagating the residuals from
the back-end. This significantly improves the generalization ability of the
entire system and thus achieves the accuracy improvement up to 45%. To the best
of our knowledge, iSLAM is the first SLAM system showing that the front-end and
back-end can learn jointly and mutually contribute to each other in a
self-supervised manner.
\\ ( https://arxiv.org/abs/2306.07894 ,  672kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07962
Date: Tue, 13 Jun 2023 17:57:03 GMT   (187kb,D)

Title: Parting with Misconceptions about Learning-based Vehicle Motion Planning
Authors: Daniel Dauner, Marcel Hallgarten, Andreas Geiger, Kashyap Chitta
Categories: cs.RO cs.AI cs.CV cs.LG
\\
 The release of nuPlan marks a new era in vehicle motion planning research,
offering the first large-scale real-world dataset and evaluation schemes
requiring both precise short-term planning and long-horizon ego-forecasting.
Existing systems struggle to simultaneously meet both requirements. Indeed, we
find that these tasks are fundamentally misaligned and should be addressed
independently. We further assess the current state of closed-loop planning in
the field, revealing the limitations of learning-based methods in complex
real-world scenarios and the value of simple rule-based priors such as
centerline selection through lane graph search algorithms. More surprisingly,
for the open-loop sub-task, we observe that the best results are achieved when
using only this centerline as scene context (\ie, ignoring all information
regarding the map and other agents). Combining these insights, we propose an
extremely simple and efficient planner which outperforms an extensive set of
competitors, winning the nuPlan planning challenge 2023.
\\ ( https://arxiv.org/abs/2306.07962 ,  187kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07369
Date: Mon, 12 Jun 2023 18:51:27 GMT   (10983kb,D)

Title: Set-based state estimation and fault diagnosis using constrained
 zonotopes and applications
Authors: Brenner S. Rego
Categories: eess.SY cs.SY
Comments: My PhD Thesis from Federal University of Minas Gerais, Brazil. Most
 of the research work has already been published in DOIs
 10.1109/CDC.2018.8618678, 10.23919/ECC.2018.8550353,
 10.1016/j.automatica.2019.108614, 10.1016/j.ifacol.2020.12.2484,
 10.1016/j.ifacol.2021.08.308, 10.1016/j.automatica.2021.109638,
 10.1109/TCST.2021.3130534, 10.1016/j.automatica.2022.110425
\\
 This doctoral thesis develops new methods for set-based state estimation and
active fault diagnosis (AFD) of (i) nonlinear discrete-time systems, (ii)
discrete-time nonlinear systems whose trajectories satisfy nonlinear equality
constraints (called invariants), (iii) linear descriptor systems, and (iv)
joint state and parameter estimation of nonlinear descriptor systems. Set-based
estimation aims to compute tight enclosures of the possible system states in
each time step subject to unknown-but-bounded uncertainties. To address this
issue, the present doctoral thesis proposes new methods for efficiently
propagating constrained zonotopes (CZs) through nonlinear mappings. Besides,
this thesis improves the standard prediction-update framework for systems with
invariants using new algorithms for refining CZs based on nonlinear
constraints. In addition, this thesis introduces a new approach for set-based
AFD of a class of nonlinear discrete-time systems. An affine parametrization of
the reachable sets is obtained for the design of an optimal input for set-based
AFD. In addition, this thesis presents new methods based on CZs for set-valued
state estimation and AFD of linear descriptor systems. Linear static
constraints on the state variables can be directly incorporated into CZs.
Moreover, this thesis proposes a new representation for unbounded sets based on
zonotopes, which allows to develop methods for state estimation and AFD also of
unstable linear descriptor systems, without the knowledge of an enclosure of
all the trajectories of the system. This thesis also develops a new method for
set-based joint state and parameter estimation of nonlinear descriptor systems
using CZs in a unified framework. Lastly, this manuscript applies the proposed
set-based state estimation and AFD methods using CZs to unmanned aerial
vehicles, water distribution networks, and a lithium-ion cell.
\\ ( https://arxiv.org/abs/2306.07369 ,  10983kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07510
Date: Tue, 13 Jun 2023 02:37:57 GMT   (5662kb,D)

Title: Require Process Control? \textbf{LSTMc} is all you need!
Authors: Niranjan Sitapure and Joseph S Kwon
Categories: eess.SY cs.SY
Comments: 18 pages, 11 figures. Submitted for review to the AIChE Journal, and
 a preprint has been uploaded on arXiv
ACM-class: I.6.3; I.2.8; J.7
\\
 Over the past three decades, numerous controllers have been developed to
regulate complex chemical processes, but they have certain limitations.
Traditional PI/PID controllers often require customized tuning for various
set-point scenarios. On the other hand, MPC frameworks involve
resource-intensive steps, and the utilization of black-box machine learning
(ML) models can lead to issues such as local minima and infeasibility. Thus,
there is a need for an alternative controller paradigm that combines the
simplicity of a PI controller with the grade-to-grade (G2G) transferability of
an MPC approach. To this end, we developed a novel LSTM controller (LSTMc) as a
model-free data-driven controller framework. The LSTMc considers an augmented
input tensor that incorporates information on state evolution and error
dynamics for the current and previous $W$ time steps, to predict the
manipulated input at the next step ($u_{t+1}$). To demonstrate LSTMc, batch
crystallization of dextrose was taken as a representative case study. The
desired output for set-point tracking was the mean crystal size ($\bar{L}$),
with the manipulated input being the jacket temperature ($T_j$). Extensive
training data, encompassing 7000+ different operating conditions, was compiled
to ensure comprehensive training of LSTMc across a wide state space region. For
comparison, we also designed a PI controller and an LSTM-MPC for different
set-point tracking cases. The results consistently showed that LSTMc achieved
the lowest set-point deviation ($<$2\%), three times lower than the MPC.
Remarkably, LSTMc maintained this superior performance across all set points,
even when sensor measurements contained noise levels of 10\% to 15\%. In
summary, by effectively leveraging process data and utilizing sequential ML
models, LSTMc offers a superior controller design approach.
\\ ( https://arxiv.org/abs/2306.07510 ,  5662kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07535
Date: Tue, 13 Jun 2023 04:35:44 GMT   (3360kb,D)

Title: Learning with Delayed Payoffs in Population Games using Kullback-Leibler
 Divergence Regularization
Authors: Shinkyu Park and Naomi Ehrich Leonard
Categories: eess.SY cs.SY
\\
 We study a multi-agent decision problem in large population games. Agents
across multiple populations select strategies for repeated interactions with
one another. At each stage of the interactions, agents use their
decision-making model to revise their strategy selections based on payoffs
determined by an underlying game. Their goal is to learn the strategies of the
Nash equilibrium of the game. However, when games are subject to time delays,
conventional decision-making models from the population game literature result
in oscillation in the strategy revision process or convergence to an
equilibrium other than the Nash. To address this problem, we propose the
Kullback-Leibler Divergence Regularized Learning (KLD-RL) model and an
algorithm to iteratively update the model's regularization parameter. Using
passivity-based convergence analysis techniques, we show that the KLD-RL model
achieves convergence to the Nash equilibrium, without oscillation, for a class
of population games that are subject to time delays. We demonstrate our main
results numerically on a two-population congestion game and a two-population
zero-sum game.
\\ ( https://arxiv.org/abs/2306.07535 ,  3360kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07612
Date: Tue, 13 Jun 2023 08:12:00 GMT   (20279kb,D)

Title: An Evaluation of Multi-Component Weft-Knitted Twill Structures for
 Sensing Tensile Force
Authors: Roland Aigner and Frank Hepper
Categories: eess.SY cs.SY
\\
 We present multi-component knitted resistive sensors for tracking tensile
force. The knits were fabricated using a Twill structure, which is a simple
pattern featuring anisotropic elastic behavior, providing high stability along
course-direction. Our sensors are made of two commercially available conductive
yarn types, with highly different linear resistance. We present a variety of
integration methods using the proposed Twill structure, all of which can be
easily replicated on a two-bed weft-knitting machine. We evaluate the
performance of the resulting sensor variations, with respect to consistency,
hysteresis, short-term and long-term relaxation and drift, among other metrics.
We found that particulars of the knit's loop composition have a crucial effect
on the consistency of the sensor readings. Furthermore, we show that knitting
resistive yarn more tightly than the substrate material gives superior results
and that improving elastic recoil by adding Lycra to the supporting substrate
can considerably improve performance.
\\ ( https://arxiv.org/abs/2306.07612 ,  20279kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07620
Date: Tue, 13 Jun 2023 08:31:53 GMT   (1663kb,D)

Title: Non-Asymptotic State and Disturbance Estimation for a Class of
 Triangular Nonlinear Systems using Modulating Functions
Authors: Yasmine Marani, Ibrahima N'Doye, and Taous-Meriem Laleg-Kirati
Categories: eess.SY cs.SY
Comments: 24 pages
\\
 Dynamical models are often corrupted by model uncertainties, external
disturbances, and measurement noise. These factors affect the performance of
model-based observers and as a result, affect the closed-loop performance.
Therefore, it is critical to develop robust model-based estimators that
reconstruct both the states and the model disturbances while mitigating the
effect of measurement noise in order to ensure good system monitoring and
closed-loop performance when designing controllers. In this article, a robust
step by step non-asymptotic observer for triangular nonlinear systems for the
joint estimation of the state and the disturbance is developed. The proposed
approach provides a sequential estimation of the states and the disturbance in
finite time using smooth modulating functions. The robustness of the proposed
observer is both in the sense of model disturbances and measurement noise. In
fact, the structure of triangular systems combined with the modulating
function-based method allows the estimation of the states independently of
model disturbances and the integral operator involved in the modulating
function-based method mitigates the noise. Additionally, the modulating
function method shifts the derivative from the noisy output to the smooth
modulating function which strengthens its robustness properties. The
applicability of the proposed modulating function-based estimator is
illustrated in numerical simulations and compared to a second-order sliding
mode super twisting observer under different measurement noise levels.
\\ ( https://arxiv.org/abs/2306.07620 ,  1663kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07663
Date: Tue, 13 Jun 2023 10:12:25 GMT   (744kb,D)

Title: Nash equilibria of the pay-as-bid auction with K-Lipschitz supply
 functions
Authors: Martina Vanelli, Giacomo Como, Fabio Fagnani
Categories: eess.SY cs.MA cs.SI cs.SY math.OC
Comments: 6 pages, 5 figures, to appear Proc. of the 22nd International
 Federation of Automatic Control World Congress (IFAC 2023)
\\
 We model a system of n asymmetric firms selling a homogeneous good in a
common market through a pay-as-bid auction. Every producer chooses as its
strategy a supply function returning the quantity S(p) that it is willing to
sell at a minimum unit price p. The market clears at the price at which the
aggregate demand intersects the total supply and firms are paid the bid prices.
We study a game theoretic model of competition among such firms and focus on
its equilibria (Supply function equilibrium). The game we consider is a
generalization of both models where firms can either set a fixed quantity
(Cournot model) or set a fixed price (Bertrand model). Our main result is to
prove existence and provide a characterization of (pure strategy) Nash
equilibria in the space of K-Lipschitz supply functions.
\\ ( https://arxiv.org/abs/2306.07663 ,  744kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07712
Date: Tue, 13 Jun 2023 12:00:48 GMT   (539kb)

Title: Multiple-Step Quantized Triplet STDP Implemented with Memristive Synapse
Authors: Y. Liu, D. Wang, Z. Dong, and W. Zhao
Categories: eess.SY cs.NE cs.SY
Comments: 5 pages, 10 figures
\\
 As an extension of the pairwise spike-timingdependent plasticity (STDP)
learning rule, the triplet STDP is provided with greater capability in
characterizing the synaptic changes in the biological neural cell. In this
work, a novel mixedsignal circuit scheme, called multiple-step quantized
triplet STDP, is designed to provide a precise and flexible implementation of
coactivation triplet STDP learning rule in memristive synapse spiking neural
network. The robustness of the circuit is greatly improved through the
utilization of pulse-width encoded weight modulation signals. The circuit
performance is studied through the simulations which are carried out in MATLAB
Simulink & Simscape, and assessment is given by comparing the results of
circuits with the algorithmic approaches.
\\ ( https://arxiv.org/abs/2306.07712 ,  539kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07772
Date: Tue, 13 Jun 2023 13:49:34 GMT   (600kb,D)

Title: A step towards digital operations -- A novel grey-box approach for
 modelling the heat dynamics of Ultra-low temperature freezing chambers
Authors: Tao Huang and Peder Bacher and Jan Kloppenborg M{\o}ller and Francesco
 D'Ettorre and Wiebke Brix Markussen
Categories: eess.SY cs.SY
\\
 Ultra-low temperature (ULT) freezers store perishable bio-contents and have
high energy consumption, which highlight a demand for reliable methods for
intelligent surveillance and smart energy management. This study introduces a
novel grey-box modelling approach based on stochastic differential equations to
describe the heat dynamics of the ULT freezing chambers. The proposed modelling
approach only requires temperature data measured by the embedded sensors and
uses data from the regular operation periods for model identification. The
model encompasses three states: chamber temperature, envelope temperature, and
local evaporator temperature. Special attention is given to the local
evaporator temperature state, which is modelled as a time-variant system, to
characterize the time delay and dynamic variations in cooling intensity. Two
ULT freezers with different operational patterns are modelled. The unknown
model parameters are estimated using the maximum likelihood method. The results
demonstrate that the models can accurately predict the chamber temperature
measured by the control probe (RMSE < 0.19 {\deg}C) and are promising to be
applied for forecasting future states. In addition, the model for local
evaporator temperature can effectively adapt to different operational patterns
and provide insight into the local cooling supply status. The proposed approach
greatly promotes the practical feasibility of grey-box modelling of the heat
dynamics for ULT freezers and can serve several potential digital applications.
A major limitation of the modelling approach is the low identifiability, which
can potentially be addressed by inferring model parameters based on relative
parameter changes.
\\ ( https://arxiv.org/abs/2306.07772 ,  600kb)
%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-
------------------------------------------------------------------------------
\\
arXiv:2306.07285 (*cross-listing*)
Date: Tue, 23 May 2023 06:59:22 GMT   (4148kb,D)

Title: TransCoder: Towards Unified Transferable Code Representation Learning
 Inspired by Human Skills
Authors: Qiushi Sun, Nuo Chen, Jianing Wang, Xiang Li, Ming Gao
Categories: cs.SE cs.AI
Comments: work in progress
\\
 Code pre-trained models (CodePTMs) have recently demonstrated a solid
capacity to process various software intelligence tasks, e.g., code clone
detection, code translation, and code summarization. The current mainstream
method that deploys these models to downstream tasks is to fine-tune them on
individual tasks, which is generally costly and needs sufficient data for large
models. To tackle the issue, in this paper, we present TransCoder, a unified
Transferable fine-tuning strategy for Code representation learning. Inspired by
human inherent skills of knowledge generalization, TransCoder drives the model
to learn better code-related meta-knowledge like human programmers.
Specifically, we employ a tunable prefix encoder as the meta-learner to capture
cross-task and cross-language transferable knowledge, respectively. Besides,
tasks with minor training sample sizes and languages with small corpus can be
remarkably benefited from our approach. Extensive experiments conducted on
benchmark datasets clearly demonstrate that our method can lead to superior
performance on various code-related tasks and encourage mutual reinforcement.
We also show that TransCoder is applicable in low-resource scenarios.
\\ ( https://arxiv.org/abs/2306.07285 ,  4148kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07297 (*cross-listing*)
Date: Sat, 10 Jun 2023 20:55:21 GMT   (253kb,D)

Title: Medical Data Augmentation via ChatGPT: A Case Study on Medication
 Identification and Medication Event Classification
Authors: Shouvon Sarker, Lijun Qian, Xishuang Dong
Categories: cs.CL cs.AI cs.LG
\\
 The identification of key factors such as medications, diseases, and
relationships within electronic health records and clinical notes has a wide
range of applications in the clinical field. In the N2C2 2022 competitions,
various tasks were presented to promote the identification of key factors in
electronic health records (EHRs) using the Contextualized Medication Event
Dataset (CMED). Pretrained large language models (LLMs) demonstrated
exceptional performance in these tasks. This study aims to explore the
utilization of LLMs, specifically ChatGPT, for data augmentation to overcome
the limited availability of annotated data for identifying the key factors in
EHRs. Additionally, different pre-trained BERT models, initially trained on
extensive datasets like Wikipedia and MIMIC, were employed to develop models
for identifying these key variables in EHRs through fine-tuning on augmented
datasets. The experimental results of two EHR analysis tasks, namely medication
identification and medication event classification, indicate that data
augmentation based on ChatGPT proves beneficial in improving performance for
both medication identification and medication event classification.
\\ ( https://arxiv.org/abs/2306.07297 ,  253kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07298 (*cross-listing*)
Date: Sat, 10 Jun 2023 22:43:16 GMT   (12810kb,D)

Title: Referring to Screen Texts with Voice Assistants
Authors: Shruti Bhargava, Anand Dhoot, Ing-Marie Jonsson, Hoang Long Nguyen,
 Alkesh Patel, Hong Yu, Vincent Renkens
Categories: cs.HC cs.AI
Comments: 7 pages, Accepted to ACL Industry Track 2023
\\
 Voice assistants help users make phone calls, send messages, create events,
navigate, and do a lot more. However, assistants have limited capacity to
understand their users' context. In this work, we aim to take a step in this
direction. Our work dives into a new experience for users to refer to phone
numbers, addresses, email addresses, URLs, and dates on their phone screens.
Our focus lies in reference understanding, which becomes particularly
interesting when multiple similar texts are present on screen, similar to
visual grounding. We collect a dataset and propose a lightweight
general-purpose model for this novel experience. Due to the high cost of
consuming pixels directly, our system is designed to rely on the extracted text
from the UI. Our model is modular, thus offering flexibility, improved
interpretability, and efficient runtime memory utilization.
\\ ( https://arxiv.org/abs/2306.07298 ,  12810kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07302 (*cross-listing*)
Date: Sun, 11 Jun 2023 21:49:42 GMT   (2140kb,D)

Title: Impact of Experiencing Misrecognition by Teachable Agents on Learning
 and Rapport
Authors: Yuya Asano, Diane Litman, Mingzhi Yu, Nikki Lobczowski, Timothy
 Nokes-Malach, Adriana Kovashka, Erin Walker
Categories: cs.HC cs.AI cs.CL
Comments: Accepted to AIED 2023
\\
 While speech-enabled teachable agents have some advantages over typing-based
ones, they are vulnerable to errors stemming from misrecognition by automatic
speech recognition (ASR). These errors may propagate, resulting in unexpected
changes in the flow of conversation. We analyzed how such changes are linked
with learning gains and learners' rapport with the agents. Our results show
they are not related to learning gains or rapport, regardless of the types of
responses the agents should have returned given the correct input from learners
without ASR errors. We also discuss the implications for optimal error-recovery
policies for teachable agents that can be drawn from these findings.
\\ ( https://arxiv.org/abs/2306.07302 ,  2140kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07310 (*cross-listing*)
Date: Mon, 12 Jun 2023 17:53:06 GMT   (2135kb,D)

Title: Employing Crowdsourcing for Enriching a Music Knowledge Base in Higher
 Education
Authors: Vassilis Lyberatos, Spyridon Kantarelis, Eirini Kaldeli, Spyros
 Bekiaris, Panagiotis Tzortzis, Orfeas Menis - Mastromichalakis and Giorgos
 Stamou
Categories: cs.HC cs.AI
Comments: To be published in The 4th International Conference on Artificial
 Intelligence in Education Technology (AIET 2023), Berlin, Germany, 31 June-2
 July 2023. For The GitHub code for the created music dataset, see
 https://github.com/vaslyb/MusicCrow
\\
 This paper describes the methodology followed and the lessons learned from
employing crowdsourcing techniques as part of a homework assignment involving
higher education students of computer science. Making use of a platform that
supports crowdsourcing in the cultural heritage domain students were solicited
to enrich the metadata associated with a selection of music tracks. The results
of the campaign were further analyzed and exploited by students through the use
of semantic web technologies. In total, 98 students participated in the
campaign, contributing more than 6400 annotations concerning 854 tracks. The
process also led to the creation of an openly available annotated dataset,
which can be useful for machine learning models for music tagging. The
campaign's results and the comments gathered through an online survey enable us
to draw some useful insights about the benefits and challenges of integrating
crowdsourcing into computer science curricula and how this can enhance
students' engagement in the learning process.
\\ ( https://arxiv.org/abs/2306.07310 ,  2135kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07377 (*cross-listing*)
Date: Mon, 12 Jun 2023 19:10:47 GMT   (2842kb)

Title: Lost in Translation: Large Language Models in Non-English Content
 Analysis
Authors: Gabriel Nicholas and Aliya Bhatia
Categories: cs.CL cs.AI
Comments: 50 pages, 4 figures
\\
 In recent years, large language models (e.g., Open AI's GPT-4, Meta's LLaMa,
Google's PaLM) have become the dominant approach for building AI systems to
analyze and generate language online. However, the automated systems that
increasingly mediate our interactions online -- such as chatbots, content
moderation systems, and search engines -- are primarily designed for and work
far more effectively in English than in the world's other 7,000 languages.
Recently, researchers and technology companies have attempted to extend the
capabilities of large language models into languages other than English by
building what are called multilingual language models.
 In this paper, we explain how these multilingual language models work and
explore their capabilities and limits. Part I provides a simple technical
explanation of how large language models work, why there is a gap in available
data between English and other languages, and how multilingual language models
attempt to bridge that gap. Part II accounts for the challenges of doing
content analysis with large language models in general and multilingual
language models in particular. Part III offers recommendations for companies,
researchers, and policymakers to keep in mind when considering researching,
developing and deploying large and multilingual language models.
\\ ( https://arxiv.org/abs/2306.07377 ,  2842kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07401 (*cross-listing*)
Date: Fri, 9 Jun 2023 17:53:19 GMT   (572kb)

Title: Implementing BERT and fine-tuned RobertA to detect AI generated news by
 ChatGPT
Authors: Zecong Wang, Jiaxi Cheng, Chen Cui, and Chenhao Yu
Categories: cs.CL cs.AI
\\
 The abundance of information on social media has increased the necessity of
accurate real-time rumour detection. Manual techniques of identifying and
verifying fake news generated by AI tools are impracticable and time-consuming
given the enormous volume of information generated every day. This has sparked
an increase in interest in creating automated systems to find fake news on the
Internet. The studies in this research demonstrate that the BERT and RobertA
models with fine-tuning had the best success in detecting AI generated news.
With a score of 98%, tweaked RobertA in particular showed excellent precision.
In conclusion, this study has shown that neural networks can be used to
identify bogus news AI generation news created by ChatGPT. The RobertA and BERT
models' excellent performance indicates that these models can play a critical
role in the fight against misinformation.
\\ ( https://arxiv.org/abs/2306.07401 ,  572kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07402 (*cross-listing*)
Date: Thu, 8 Jun 2023 20:35:53 GMT   (1936kb,D)

Title: The economic trade-offs of large language models: A case study
Authors: Kristen Howell, Gwen Christian, Pavel Fomitchov, Gitit Kehat, Julianne
 Marzulla, Leanne Rolston, Jadin Tredup, Ilana Zimmerman, Ethan Selfridge, and
 Joseph Bradley
Categories: cs.CL cs.AI
Comments: Paper to be published at the Association for Computational
 Linguistics in the Industry Track 2023
\\
 Contacting customer service via chat is a common practice. Because employing
customer service agents is expensive, many companies are turning to NLP that
assists human agents by auto-generating responses that can be used directly or
with modifications. Large Language Models (LLMs) are a natural fit for this use
case; however, their efficacy must be balanced with the cost of training and
serving them. This paper assesses the practical cost and impact of LLMs for the
enterprise as a function of the usefulness of the responses that they generate.
We present a cost framework for evaluating an NLP model's utility for this use
case and apply it to a single brand as a case study in the context of an
existing agent assistance product. We compare three strategies for specializing
an LLM - prompt engineering, fine-tuning, and knowledge distillation - using
feedback from the brand's customer service agents. We find that the usability
of a model's responses can make up for a large difference in inference cost for
our case study brand, and we extrapolate our findings to the broader enterprise
space.
\\ ( https://arxiv.org/abs/2306.07402 ,  1936kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07416 (*cross-listing*)
Date: Mon, 12 Jun 2023 20:47:59 GMT   (2983kb,D)

Title: Synaptic Scaling and Optimal Bias Adjustments for Power Reduction in
 Neuromorphic Systems
Authors: Cory Merkel
Categories: cs.NE cs.AI
Comments: Accepted in MWSCAS
\\
 Recent animal studies have shown that biological brains can enter a low power
mode in times of food scarcity. This paper explores the possibility of applying
similar mechanisms to a broad class of neuromorphic systems where power
consumption is strongly dependent on the magnitude of synaptic weights. In
particular, we show through mathematical models and simulations that careful
scaling of synaptic weights can significantly reduce power consumption (by over
80\% in some of the cases tested) while having a relatively small impact on
accuracy. These results uncover an exciting opportunity to design neuromorphic
systems for edge AI applications, where power consumption can be dynamically
adjusted based on energy availability and performance requirements.
\\ ( https://arxiv.org/abs/2306.07416 ,  2983kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07457 (*cross-listing*)
Date: Mon, 12 Jun 2023 23:19:55 GMT   (4474kb,D)

Title: Accurate Measures of Vaccination and Concerns of Vaccine Holdouts from
 Web Search Logs
Authors: Serina Chang, Adam Fourney, Eric Horvitz
Categories: cs.CY cs.AI
\\
 To design effective vaccine policies, policymakers need detailed data about
who has been vaccinated, who is holding out, and why. However, existing data in
the US are insufficient: reported vaccination rates are often delayed or
missing, and surveys of vaccine hesitancy are limited by high-level questions
and self-report biases. Here, we show how large-scale search engine logs and
machine learning can be leveraged to fill these gaps and provide novel insights
about vaccine intentions and behaviors. First, we develop a vaccine intent
classifier that can accurately detect when a user is seeking the COVID-19
vaccine on search. Our classifier demonstrates strong agreement with CDC
vaccination rates, with correlations above 0.86, and estimates vaccine intent
rates to the level of ZIP codes in real time, allowing us to pinpoint more
granular trends in vaccine seeking across regions, demographics, and time. To
investigate vaccine hesitancy, we use our classifier to identify two groups,
vaccine early adopters and vaccine holdouts. We find that holdouts, compared to
early adopters matched on covariates, are 69% more likely to click on untrusted
news sites. Furthermore, we organize 25,000 vaccine-related URLs into a
hierarchical ontology of vaccine concerns, and we find that holdouts are far
more concerned about vaccine requirements, vaccine development and approval,
and vaccine myths, and even within holdouts, concerns vary significantly across
demographic groups. Finally, we explore the temporal dynamics of vaccine
concerns and vaccine seeking, and find that key indicators emerge when
individuals convert from holding out to preparing to accept the vaccine.
\\ ( https://arxiv.org/abs/2306.07457 ,  4474kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07458 (*cross-listing*)
Date: Mon, 12 Jun 2023 23:24:16 GMT   (135kb,D)

Title: Adaptive interventions for both accuracy and time in AI-assisted human
 decision making
Authors: Siddharth Swaroop, Zana Bu\c{c}inca, Finale Doshi-Velez
Categories: cs.HC cs.AI
\\
 In settings where users are both time-pressured and need high accuracy, such
as doctors working in Emergency Rooms, we want to provide AI assistance that
both increases accuracy and reduces time. However, different types of AI
assistance have different benefits: some reduce time taken while increasing
overreliance on AI, while others do the opposite. We therefore want to adapt
what AI assistance we show depending on various properties (of the question and
of the user) in order to best tradeoff our two objectives. We introduce a study
where users have to prescribe medicines to aliens, and use it to explore the
potential for adapting AI assistance. We find evidence that it is beneficial to
adapt our AI assistance depending on the question, leading to good tradeoffs
between time taken and accuracy. Future work would consider machine-learning
algorithms (such as reinforcement learning) to automatically adapt quickly.
\\ ( https://arxiv.org/abs/2306.07458 ,  135kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07489 (*cross-listing*)
Date: Tue, 13 Jun 2023 01:36:55 GMT   (720kb,D)

Title: PauseSpeech: Natural Speech Synthesis via Pre-trained Language Model and
 Pause-based Prosody Modeling
Authors: Ji-Sang Hwang, Sang-Hoon Lee, and Seong-Whan Lee
Categories: eess.AS cs.AI cs.SD eess.SP
Comments: 13 pages, 4 figures, 3 tables, under reivew
\\
 Although text-to-speech (TTS) systems have significantly improved, most TTS
systems still have limitations in synthesizing speech with appropriate
phrasing. For natural speech synthesis, it is important to synthesize the
speech with a phrasing structure that groups words into phrases based on
semantic information. In this paper, we propose PuaseSpeech, a speech synthesis
system with a pre-trained language model and pause-based prosody modeling.
First, we introduce a phrasing structure encoder that utilizes a context
representation from the pre-trained language model. In the phrasing structure
encoder, we extract a speaker-dependent syntactic representation from the
context representation and then predict a pause sequence that separates the
input text into phrases. Furthermore, we introduce a pause-based word encoder
to model word-level prosody based on pause sequence. Experimental results show
PauseSpeech outperforms previous models in terms of naturalness. Furthermore,
in terms of objective evaluations, we can observe that our proposed methods
help the model decrease the distance between ground-truth and synthesized
speech. Audio samples are available at
https://jisang93.github.io/pausespeech-demo/.
\\ ( https://arxiv.org/abs/2306.07489 ,  720kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07499 (*cross-listing*)
Date: Tue, 13 Jun 2023 02:20:58 GMT   (7614kb,D)

Title: Improving Opinion-based Question Answering Systems Through Label Error
 Detection and Overwrite
Authors: Xiao Yang, Ahmed K. Mohamed, Shashank Jain, Stanislav Peshterliev,
 Debojeet Chatterjee, Hanwen Zha, Nikita Bhalla, Gagan Aneja and Pranab
 Mohanty
Categories: cs.CL cs.AI cs.LG
\\
 Label error is a ubiquitous problem in annotated data. Large amounts of label
error substantially degrades the quality of deep learning models. Existing
methods to tackle the label error problem largely focus on the classification
task, and either rely on task specific architecture or require non-trivial
additional computations, which is undesirable or even unattainable for industry
usage. In this paper, we propose LEDO: a model-agnostic and computationally
efficient framework for Label Error Detection and Overwrite. LEDO is based on
Monte Carlo Dropout combined with uncertainty metrics, and can be easily
generalized to multiple tasks and data sets. Applying LEDO to an industry
opinion-based question answering system demonstrates it is effective at
improving accuracy in all the core models. Specifically, LEDO brings 1.1% MRR
gain for the retrieval model, 1.5% PR AUC improvement for the machine reading
comprehension model, and 0.9% rise in the Average Precision for the ranker, on
top of the strong baselines with a large-scale social media dataset.
Importantly, LEDO is computationally efficient compared to methods that require
loss function change, and cost-effective as the resulting data can be used in
the same continuous training pipeline for production. Further analysis shows
that these gains come from an improved decision boundary after cleaning the
label errors existed in the training data.
\\ ( https://arxiv.org/abs/2306.07499 ,  7614kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07500 (*cross-listing*)
Date: Tue, 13 Jun 2023 02:23:04 GMT   (181kb,D)

Title: Adding guardrails to advanced chatbots
Authors: Yanchen Wang, Lisa Singh
Categories: cs.CY cs.AI cs.CL
\\
 Generative AI models continue to become more powerful. The launch of ChatGPT
in November 2022 has ushered in a new era of AI. ChatGPT and other similar
chatbots have a range of capabilities, from answering student homework
questions to creating music and art. There are already concerns that humans may
be replaced by chatbots for a variety of jobs. Because of the wide spectrum of
data chatbots are built on, we know that they will have human errors and human
biases built into them. These biases may cause significant harm and/or inequity
toward different subpopulations. To understand the strengths and weakness of
chatbot responses, we present a position paper that explores different use
cases of ChatGPT to determine the types of questions that are answered fairly
and the types that still need improvement. We find that ChatGPT is a fair
search engine for the tasks we tested; however, it has biases on both text
generation and code generation. We find that ChatGPT is very sensitive to
changes in the prompt, where small changes lead to different levels of
fairness. This suggests that we need to immediately implement "corrections" or
mitigation strategies in order to improve fairness of these systems. We suggest
different strategies to improve chatbots and also advocate for an impartial
review panel that has access to the model parameters to measure the levels of
different types of biases and then recommends safeguards that move toward
responses that are less discriminatory and more accurate.
\\ ( https://arxiv.org/abs/2306.07500 ,  181kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07608 (*cross-listing*)
Date: Tue, 13 Jun 2023 08:06:10 GMT   (465kb,D)

Title: Finding the Missing-half: Graph Complementary Learning for
 Homophily-prone and Heterophily-prone Graphs
Authors: Yizhen Zheng, He Zhang, Vincent CS Lee, Yu Zheng, Xiao Wang, Shirui
 Pan
Categories: cs.SI cs.AI
Comments: Accepted by ICML 2023
\\
 Real-world graphs generally have only one kind of tendency in their
connections. These connections are either homophily-prone or heterophily-prone.
While graphs with homophily-prone edges tend to connect nodes with the same
class (i.e., intra-class nodes), heterophily-prone edges tend to build
relationships between nodes with different classes (i.e., inter-class nodes).
Existing GNNs only take the original graph during training. The problem with
this approach is that it forgets to take into consideration the ``missing-half"
structural information, that is, heterophily-prone topology for homophily-prone
graphs and homophily-prone topology for heterophily-prone graphs. In our paper,
we introduce Graph cOmplementAry Learning, namely GOAL, which consists of two
components: graph complementation and complemented graph convolution. The first
component finds the missing-half structural information for a given graph to
complement it. The complemented graph has two sets of graphs including both
homophily- and heterophily-prone topology. In the latter component, to handle
complemented graphs, we design a new graph convolution from the perspective of
optimisation. The experiment results show that GOAL consistently outperforms
all baselines in eight real-world datasets.
\\ ( https://arxiv.org/abs/2306.07608 ,  465kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07622 (*cross-listing*)
Date: Tue, 13 Jun 2023 08:43:13 GMT   (736kb)

Title: Human-Like Intuitive Behavior and Reasoning Biases Emerged in Language
 Models -- and Disappeared in GPT-4
Authors: Thilo Hagendorff, Sarah Fabi
Categories: cs.CL cs.AI cs.LG
Comments: arXiv admin note: substantial text overlap with arXiv:2212.05206
\\
 Large language models (LLMs) are currently at the forefront of intertwining
AI systems with human communication and everyday life. Therefore, it is of
great importance to evaluate their emerging abilities. In this study, we show
that LLMs, most notably GPT-3, exhibit behavior that strikingly resembles
human-like intuition -- and the cognitive errors that come with it. However,
LLMs with higher cognitive capabilities, in particular ChatGPT and GPT-4,
learned to avoid succumbing to these errors and perform in a hyperrational
manner. For our experiments, we probe LLMs with the Cognitive Reflection Test
(CRT) as well as semantic illusions that were originally designed to
investigate intuitive decision-making in humans. Moreover, we probe how sturdy
the inclination for intuitive-like decision-making is. Our study demonstrates
that investigating LLMs with methods from psychology has the potential to
reveal otherwise unknown emergent traits.
\\ ( https://arxiv.org/abs/2306.07622 ,  736kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07664 (*cross-listing*)
Date: Tue, 13 Jun 2023 10:14:58 GMT   (181kb,D)

Title: Rethink the Effectiveness of Text Data Augmentation: An Empirical
 Analysis
Authors: Zhengxiang Shi, Aldo Lipani
Categories: cs.CL cs.AI cs.LG
Comments: Accepted at ESANN 2023
\\
 In recent years, language models (LMs) have made remarkable progress in
advancing the field of natural language processing (NLP). However, the impact
of data augmentation (DA) techniques on the fine-tuning (FT) performance of
these LMs has been a topic of ongoing debate. In this study, we evaluate the
effectiveness of three different FT methods in conjugation with
back-translation across an array of 7 diverse NLP tasks, including
classification and regression types, covering single-sentence and sentence-pair
tasks. Contrary to prior assumptions that DA does not contribute to the
enhancement of LMs' FT performance, our findings reveal that continued
pre-training on augmented data can effectively improve the FT performance of
the downstream tasks. In the most favourable case, continued pre-training
improves the performance of FT by more than 10% in the few-shot learning
setting. Our finding highlights the potential of DA as a powerful tool for
bolstering LMs' performance.
\\ ( https://arxiv.org/abs/2306.07664 ,  181kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07685 (*cross-listing*)
Date: Tue, 13 Jun 2023 10:56:23 GMT   (678kb,D)

Title: Few-shot Multi-domain Knowledge Rearming for Context-aware Defence
 against Advanced Persistent Threats
Authors: Gaolei Li, Yuanyuan Zhao, Wenqi Wei, Yuchen Liu
Categories: cs.CR cs.AI
Comments: It has been accepted by IEEE SmartNets
\\
 Advanced persistent threats (APTs) have novel features such as multi-stage
penetration, highly-tailored intention, and evasive tactics. APTs defense
requires fusing multi-dimensional Cyber threat intelligence data to identify
attack intentions and conducts efficient knowledge discovery strategies by
data-driven machine learning to recognize entity relationships. However,
data-driven machine learning lacks generalization ability on fresh or unknown
samples, reducing the accuracy and practicality of the defense model. Besides,
the private deployment of these APT defense models on heterogeneous
environments and various network devices requires significant investment in
context awareness (such as known attack entities, continuous network states,
and current security strategies). In this paper, we propose a few-shot
multi-domain knowledge rearming (FMKR) scheme for context-aware defense against
APTs. By completing multiple small tasks that are generated from different
network domains with meta-learning, the FMKR firstly trains a model with good
discrimination and generalization ability for fresh and unknown APT attacks. In
each FMKR task, both threat intelligence and local entities are fused into the
support/query sets in meta-learning to identify possible attack stages.
Secondly, to rearm current security strategies, an finetuning-based deployment
mechanism is proposed to transfer learned knowledge into the student model,
while minimizing the defense cost. Compared to multiple model replacement
strategies, the FMKR provides a faster response to attack behaviors while
consuming less scheduling cost. Based on the feedback from multiple real users
of the Industrial Internet of Things (IIoT) over 2 months, we demonstrate that
the proposed scheme can improve the defense satisfaction rate.
\\ ( https://arxiv.org/abs/2306.07685 ,  678kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07691 (*cross-listing*)
Date: Tue, 13 Jun 2023 11:04:43 GMT   (4985kb,D)

Title: StyleTTS 2: Towards Human-Level Text-to-Speech through Style Diffusion
 and Adversarial Training with Large Speech Language Models
Authors: Yinghao Aaron Li, Cong Han, Vinay S. Raghavan, Gavin Mischler, Nima
 Mesgarani
Categories: eess.AS cs.AI cs.CL cs.LG cs.SD
\\
 In this paper, we present StyleTTS 2, a text-to-speech (TTS) model that
leverages style diffusion and adversarial training with large speech language
models (SLMs) to achieve human-level TTS synthesis. StyleTTS 2 differs from its
predecessor by modeling styles as a latent random variable through diffusion
models to generate the most suitable style for the text without requiring
reference speech, achieving efficient latent diffusion while benefiting from
the diverse speech synthesis offered by diffusion models. Furthermore, we
employ large pre-trained SLMs, such as WavLM, as discriminators with our novel
differentiable duration modeling for end-to-end training, resulting in improved
speech naturalness. StyleTTS 2 surpasses human recordings on the single-speaker
LJSpeech dataset and matches it on the multispeaker VCTK dataset as judged by
native English speakers. Moreover, when trained on the LibriTTS dataset, our
model outperforms previous publicly available models for zero-shot speaker
adaptation. This work achieves the first human-level TTS on both single and
multispeaker datasets, showcasing the potential of style diffusion and
adversarial training with large SLMs. The audio demos and source code are
available at https://styletts2.github.io/.
\\ ( https://arxiv.org/abs/2306.07691 ,  4985kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07764 (*cross-listing*)
Date: Tue, 13 Jun 2023 13:27:34 GMT   (7399kb,D)

Title: Tokenization with Factorized Subword Encoding
Authors: David Samuel and Lilja {\O}vrelid
Categories: cs.CL cs.AI
Comments: Findings of ACL 2023
\\
 In recent years, language models have become increasingly larger and more
complex. However, the input representations for these models continue to rely
on simple and greedy subword tokenization methods. In this paper, we propose a
novel tokenization method that factorizes subwords onto discrete triplets using
a VQ-VAE model. The effectiveness of the proposed tokenization method, referred
to as the Factorizer, is evaluated on language modeling and morpho-syntactic
tasks for 7 diverse languages. Results indicate that this method is more
appropriate and robust for morphological tasks than the commonly used byte-pair
encoding (BPE) tokenization algorithm.
\\ ( https://arxiv.org/abs/2306.07764 ,  7399kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07786 (*cross-listing*)
Date: Tue, 13 Jun 2023 14:07:52 GMT   (1134kb,D)

Title: A Cloud-based Machine Learning Pipeline for the Efficient Extraction of
 Insights from Customer Reviews
Authors: Robert Lakatos, Gergo Bogacsovics, Balazs Harangi, Istvan Lakatos,
 Attila Tiba, Janos Toth, Marianna Szabo, Andras Hajdu
Categories: cs.CL cs.AI
\\
 The efficiency of natural language processing has improved dramatically with
the advent of machine learning models, particularly neural network-based
solutions. However, some tasks are still challenging, especially when
considering specific domains. In this paper, we present a cloud-based system
that can extract insights from customer reviews using machine learning methods
integrated into a pipeline. For topic modeling, our composite model uses
transformer-based neural networks designed for natural language processing,
vector embedding-based keyword extraction, and clustering. The elements of our
model have been integrated and further developed to meet better the
requirements of efficient information extraction, topic modeling of the
extracted information, and user needs. Furthermore, our system can achieve
better results than this task's existing topic modeling and keyword extraction
solutions. Our approach is validated and compared with other state-of-the-art
methods using publicly available datasets for benchmarking.
\\ ( https://arxiv.org/abs/2306.07786 ,  1134kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07790 (*cross-listing*)
Date: Tue, 13 Jun 2023 14:11:19 GMT   (7041kb,D)

Title: NoCoLA: The Norwegian Corpus of Linguistic Acceptability
Authors: Matias Jentoft and David Samuel
Categories: cs.CL cs.AI
Comments: Published at NoDaLiDa 2023
\\
 While there has been a surge of large language models for Norwegian in recent
years, we lack any tool to evaluate their understanding of grammaticality. We
present two new Norwegian datasets for this task. NoCoLA_class is a supervised
binary classification task where the goal is to discriminate between acceptable
and non-acceptable sentences. On the other hand, NoCoLA_zero is a purely
diagnostic task for evaluating the grammatical judgement of a language model in
a completely zero-shot manner, i.e. without any further training. In this
paper, we describe both datasets in detail, show how to use them for different
flavors of language models, and conduct a comparative study of the existing
Norwegian language models.
\\ ( https://arxiv.org/abs/2306.07790 ,  7041kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07797 (*cross-listing*)
Date: Tue, 13 Jun 2023 14:19:45 GMT   (21kb)

Title: Monolingual and Cross-Lingual Knowledge Transfer for Topic
 Classification
Authors: Dmitry Karpov, Mikhail Burtsev
Categories: cs.CL cs.AI
\\
 This article investigates the knowledge transfer from the RuQTopics dataset.
This Russian topical dataset combines a large sample number (361,560
single-label, 170,930 multi-label) with extensive class coverage (76 classes).
We have prepared this dataset from the "Yandex Que" raw data. By evaluating the
RuQTopics - trained models on the six matching classes of the Russian MASSIVE
subset, we have proved that the RuQTopics dataset is suitable for real-world
conversational tasks, as the Russian-only models trained on this dataset
consistently yield an accuracy around 85\% on this subset. We also have figured
out that for the multilingual BERT, trained on the RuQTopics and evaluated on
the same six classes of MASSIVE (for all MASSIVE languages), the language-wise
accuracy closely correlates (Spearman correlation 0.773 with p-value 2.997e-11)
with the approximate size of the pretraining BERT's data for the corresponding
language. At the same time, the correlation of the language-wise accuracy with
the linguistical distance from Russian is not statistically significant.
\\ ( https://arxiv.org/abs/2306.07797 ,  21kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07799 (*cross-listing*)
Date: Tue, 13 Jun 2023 14:21:35 GMT   (10084kb,D)

Title: ChatGPT vs Human-authored Text: Insights into Controllable Text
 Summarization and Sentence Style Transfer
Authors: Dongqi Pu, Vera Demberg
Categories: cs.CL cs.AI cs.LG
Comments: ACL-SRW 2023
\\
 Large-scale language models, like ChatGPT, have garnered significant media
attention and stunned the public with their remarkable capacity for generating
coherent text from short natural language prompts. In this paper, we aim to
conduct a systematic inspection of ChatGPT's performance in two controllable
generation tasks, with respect to ChatGPT's ability to adapt its output to
different target audiences (expert vs. layman) and writing styles (formal vs.
informal). Additionally, we evaluate the faithfulness of the generated text,
and compare the model's performance with human-authored texts. Our findings
indicate that the stylistic variations produced by humans are considerably
larger than those demonstrated by ChatGPT, and the generated texts diverge from
human samples in several characteristics, such as the distribution of word
types. Moreover, we observe that ChatGPT sometimes incorporates factual errors
or hallucinations when adapting the text to suit a specific style.
\\ ( https://arxiv.org/abs/2306.07799 ,  10084kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07812 (*cross-listing*)
Date: Tue, 13 Jun 2023 14:43:13 GMT   (5544kb,D)

Title: Automated 3D Pre-Training for Molecular Property Prediction
Authors: Xu Wang and Huan Zhao and Weiwei Tu and Quanming Yao
Categories: q-bio.QM cs.AI cs.LG
DOI: 10.1145/3580305.3599252
\\
 Molecular property prediction is an important problem in drug discovery and
materials science. As geometric structures have been demonstrated necessary for
molecular property prediction, 3D information has been combined with various
graph learning methods to boost prediction performance. However, obtaining the
geometric structure of molecules is not feasible in many real-world
applications due to the high computational cost. In this work, we propose a
novel 3D pre-training framework (dubbed 3D PGT), which pre-trains a model on 3D
molecular graphs, and then fine-tunes it on molecular graphs without 3D
structures. Based on fact that bond length, bond angle, and dihedral angle are
three basic geometric descriptors corresponding to a complete molecular 3D
conformer, we first develop a multi-task generative pre-train framework based
on these three attributes. Next, to automatically fuse these three generative
tasks, we design a surrogate metric using the \textit{total energy} to search
for weight distribution of the three pretext task since total energy
corresponding to the quality of 3D conformer.Extensive experiments on 2D
molecular graphs are conducted to demonstrate the accuracy, efficiency and
generalization ability of the proposed 3D PGT compared to various pre-training
baselines.
\\ ( https://arxiv.org/abs/2306.07812 ,  5544kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07853 (*cross-listing*)
Date: Tue, 13 Jun 2023 15:33:09 GMT   (317kb)

Title: Show me the numbers! -- Student-facing Interventions in Adaptive
 Learning Environments for German Spelling
Authors: Nathalie Rzepka, Katharina Simbeck, Hans-Georg Mueller, Marlene
 Bueltemann, Niels Pinkwart
Categories: cs.CY cs.AI cs.HC
\\
 Since adaptive learning comes in many shapes and sizes, it is crucial to find
out which adaptations can be meaningful for which areas of learning. Our work
presents the result of an experiment conducted on an online platform for the
acquisition of German spelling skills. We compared the traditional online
learning platform to three different adaptive versions of the platform that
implement machine learning-based student-facing interventions that show the
personalized solution probability. We evaluate the different interventions with
regard to the error rate, the number of early dropouts, and the users
competency. Our results show that the number of mistakes decreased in
comparison to the control group. Additionally, an increasing number of dropouts
was found. We did not find any significant effects on the users competency. We
conclude that student-facing adaptive learning environments are effective in
improving a persons error rate and should be chosen wisely to have a motivating
impact.
\\ ( https://arxiv.org/abs/2306.07853 ,  317kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07875 (*cross-listing*)
Date: Tue, 13 Jun 2023 16:10:10 GMT   (3402kb,D)

Title: ReadProbe: A Demo of Retrieval-Enhanced Large Language Models to Support
 Lateral Reading
Authors: Dake Zhang and Ronak Pradeep
Categories: cs.IR cs.AI cs.CL cs.HC
\\
 With the rapid growth and spread of online misinformation, people need tools
to help them evaluate the credibility and accuracy of online information.
Lateral reading, a strategy that involves cross-referencing information with
multiple sources, may be an effective approach to achieving this goal. In this
paper, we present ReadProbe, a tool to support lateral reading, powered by
generative large language models from OpenAI and the Bing search engine. Our
tool is able to generate useful questions for lateral reading, scour the web
for relevant documents, and generate well-attributed answers to help people
better evaluate online information. We made a web-based application to
demonstrate how ReadProbe can help reduce the risk of being misled by false
information. The code is available at
https://github.com/DakeZhang1998/ReadProbe. An earlier version of our tool won
the first prize in a national AI misinformation hackathon.
\\ ( https://arxiv.org/abs/2306.07875 ,  3402kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07902 (*cross-listing*)
Date: Tue, 13 Jun 2023 16:54:13 GMT   (8026kb,D)

Title: Massively Multilingual Corpus of Sentiment Datasets and Multi-faceted
 Sentiment Classification Benchmark
Authors: {\L}ukasz Augustyniak, Szymon Wo\'zniak, Marcin Gruza, Piotr Gramacki,
 Krzysztof Rajda, Miko{\l}aj Morzy, Tomasz Kajdanowicz
Categories: cs.CL cs.AI
Comments: submitted to NeurIPS 2023 Datasets and Benchmarks track. Dataset:
 https://huggingface.co/datasets/Brand24/mms Code:
 https://github.com/Brand24-AI/mms_benchmark
\\
 Despite impressive advancements in multilingual corpora collection and model
training, developing large-scale deployments of multilingual models still
presents a significant challenge. This is particularly true for language tasks
that are culture-dependent. One such example is the area of multilingual
sentiment analysis, where affective markers can be subtle and deeply ensconced
in culture. This work presents the most extensive open massively multilingual
corpus of datasets for training sentiment models. The corpus consists of 79
manually selected datasets from over 350 datasets reported in the scientific
literature based on strict quality criteria. The corpus covers 27 languages
representing 6 language families. Datasets can be queried using several
linguistic and functional features. In addition, we present a multi-faceted
sentiment classification benchmark summarizing hundreds of experiments
conducted on different base models, training objectives, dataset collections,
and fine-tuning strategies.
\\ ( https://arxiv.org/abs/2306.07902 ,  8026kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07906 (*cross-listing*)
Date: Tue, 13 Jun 2023 16:57:53 GMT   (8190kb,D)

Title: WebGLM: Towards An Efficient Web-Enhanced Question Answering System with
 Human Preferences
Authors: Xiao Liu, Hanyu Lai, Hao Yu, Yifan Xu, Aohan Zeng, Zhengxiao Du, Peng
 Zhang, Yuxiao Dong, Jie Tang
Categories: cs.CL cs.AI
Comments: Accepted to KDD 2023
\\
 We present WebGLM, a web-enhanced question-answering system based on the
General Language Model (GLM). Its goal is to augment a pre-trained large
language model (LLM) with web search and retrieval capabilities while being
efficient for real-world deployments. To achieve this, we develop WebGLM with
strategies for the LLM-augmented retriever, bootstrapped generator, and human
preference-aware scorer. Specifically, we identify and address the limitations
of WebGPT (OpenAI), through which WebGLM is enabled with accuracy, efficiency,
and cost-effectiveness advantages. In addition, we propose systematic criteria
for evaluating web-enhanced QA systems. We conduct multi-dimensional human
evaluation and quantitative ablation studies, which suggest the outperformance
of the proposed WebGLM designs over existing systems. WebGLM with the
10-billion-parameter GLM (10B) is shown to perform better than the
similar-sized WebGPT (13B) and even comparably to WebGPT (175B) in human
evaluation. The code, demo, and data are at
\url{https://github.com/THUDM/WebGLM}.
\\ ( https://arxiv.org/abs/2306.07906 ,  8190kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07929 (*cross-listing*)
Date: Fri, 9 Jun 2023 08:08:18 GMT   (287kb,D)

Title: Large Language Model Is Semi-Parametric Reinforcement Learning Agent
Authors: Danyang Zhang, Lu Chen, Situo Zhang, Hongshen Xu, Zihan Zhao, Kai Yu
Categories: cs.CL cs.AI
\\
 Inspired by the insights in cognitive science with respect to human memory
and reasoning mechanism, a novel evolvable LLM-based (Large Language Model)
agent framework is proposed as REMEMBERER. By equipping the LLM with a
long-term experience memory, REMEMBERER is capable of exploiting the
experiences from the past episodes even for different task goals, which excels
an LLM-based agent with fixed exemplars or equipped with a transient working
memory. We further introduce Reinforcement Learning with Experience Memory
(RLEM) to update the memory. Thus, the whole system can learn from the
experiences of both success and failure, and evolve its capability without
fine-tuning the parameters of the LLM. In this way, the proposed REMEMBERER
constitutes a semi-parametric RL agent. Extensive experiments are conducted on
two RL task sets to evaluate the proposed framework. The average results with
different initialization and training sets exceed the prior SOTA by 4% and 2%
for the success rate on two task sets and demonstrate the superiority and
robustness of REMEMBERER.
\\ ( https://arxiv.org/abs/2306.07929 ,  287kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07932 (*cross-listing*)
Date: Sat, 10 Jun 2023 04:31:57 GMT   (1614kb,D)

Title: Human-in-the-Loop through Chain-of-Thought
Authors: Zefan Cai, Baobao Chang, Wenjuan Han
Categories: cs.CL cs.AI
\\
 While the emergence of powerful language models along with Chain-of-thought
prompting has made automation more and more omnipresent, it sometimes
demonstrates its weakness in long-term or multi-step logical reasoning. For
example, users don't always get desirable answers for complex mathematical
problems without human involvement. Against this background, we present the
Manual Correction System (MCS) -- a human-in-the-loop system enhanced by
Chain-of-Thought prompting, which explores how manual correction of sub-logics
in rationales can improve LLM's reasoning performance. Moving one step forward,
considering a system with human-in-the-loop involves more than having humans
improve performance but also controlling the cost. Therefore, we post a
Cost-utility Analysis Model for Human-in-the-Loop systems (CAMLOP) based on
classical economics theory to analyze, quantify and balance the utility and the
corresponding cost. We conduct experiments of MCS and CAMLOP with twelve
datasets. A significant advantage w.r.t cost and utility proves its superiority
over strong baselines.
\\ ( https://arxiv.org/abs/2306.07932 ,  1614kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07933 (*cross-listing*)
Date: Fri, 9 Jun 2023 15:44:41 GMT   (179kb,D)

Title: Understanding Telecom Language Through Large Language Models
Authors: Lina Bariah and Hang Zou and Qiyang Zhao and Belkacem Mouhouche and
 Faouzi Bader and Merouane Debbah
Categories: cs.CL cs.AI
\\
 The recent progress of artificial intelligence (AI) opens up new frontiers in
the possibility of automating many tasks involved in Telecom networks design,
implementation, and deployment. This has been further pushed forward with the
evolution of generative artificial intelligence (AI), including the emergence
of large language models (LLMs), which is believed to be the cornerstone toward
realizing self-governed, interactive AI agents. Motivated by this, in this
paper, we aim to adapt the paradigm of LLMs to the Telecom domain. In
particular, we fine-tune several LLMs including BERT, distilled BERT, RoBERTa
and GPT-2, to the Telecom domain languages, and demonstrate a use case for
identifying the 3rd Generation Partnership Project (3GPP) standard working
groups. We consider training the selected models on 3GPP technical documents
(Tdoc) pertinent to years 2009-2019 and predict the Tdoc categories in years
2020-2023. The results demonstrate that fine-tuning BERT and RoBERTa model
achieves 84.6% accuracy, while GPT-2 model achieves 83% in identifying 3GPP
working groups. The distilled BERT model with around 50% less parameters
achieves similar performance as others. This corroborates that fine-tuning
pretrained LLM can effectively identify the categories of Telecom language. The
developed framework shows a stepping stone towards realizing intent-driven and
self-evolving wireless networks from Telecom languages, and paves the way for
the implementation of generative AI in the Telecom domain.
\\ ( https://arxiv.org/abs/2306.07933 ,  179kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07934 (*cross-listing*)
Date: Tue, 13 Jun 2023 17:39:20 GMT   (833kb,D)

Title: BoardgameQA: A Dataset for Natural Language Reasoning with Contradictory
 Information
Authors: Mehran Kazemi, Quan Yuan, Deepti Bhatia, Najoung Kim, Xin Xu, Vaiva
 Imbrasaite, Deepak Ramachandran
Categories: cs.CL cs.AI cs.LG
\\
 Automated reasoning with unstructured natural text is a key requirement for
many potential applications of NLP and for developing robust AI systems.
Recently, Language Models (LMs) have demonstrated complex reasoning capacities
even without any finetuning. However, existing evaluation for automated
reasoning assumes access to a consistent and coherent set of information over
which models reason. When reasoning in the real-world, the available
information is frequently inconsistent or contradictory, and therefore models
need to be equipped with a strategy to resolve such conflicts when they arise.
One widely-applicable way of resolving conflicts is to impose preferences over
information sources (e.g., based on source credibility or information recency)
and adopt the source with higher preference. In this paper, we formulate the
problem of reasoning with contradictory information guided by preferences over
sources as the classical problem of defeasible reasoning, and develop a dataset
called BoardgameQA for measuring the reasoning capacity of LMs in this setting.
BoardgameQA also incorporates reasoning with implicit background knowledge, to
better reflect reasoning problems in downstream applications. We benchmark
various LMs on BoardgameQA and the results reveal a significant gap in the
reasoning capacity of state-of-the-art LMs on this problem, showing that
reasoning with conflicting information does not surface out-of-the-box in LMs.
While performance can be improved with finetuning, it nevertheless remains
poor.
\\ ( https://arxiv.org/abs/2306.07934 ,  833kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07935 (*cross-listing*)
Date: Sun, 11 Jun 2023 02:35:48 GMT   (574kb,D)

Title: Multi-modal Representation Learning for Social Post Location Inference
Authors: Ruiting Dai, Jiayi Luo, Xucheng Luo, Lisi Mo, Wanlun Ma, Fan Zhou
Categories: cs.CL cs.AI cs.LG
Comments: 6 pages, 2023 International Conference on Communications
\\
 Inferring geographic locations via social posts is essential for many
practical location-based applications such as product marketing,
point-of-interest recommendation, and infector tracking for COVID-19. Unlike
image-based location retrieval or social-post text embedding-based location
inference, the combined effect of multi-modal information (i.e., post images,
text, and hashtags) for social post positioning receives less attention. In
this work, we collect real datasets of social posts with images, texts, and
hashtags from Instagram and propose a novel Multi-modal Representation Learning
Framework (MRLF) capable of fusing different modalities of social posts for
location inference. MRLF integrates a multi-head attention mechanism to enhance
location-salient information extraction while significantly improving location
inference compared with single domain-based methods. To overcome the noisy
user-generated textual content, we introduce a novel attention-based
character-aware module that considers the relative dependencies between
characters of social post texts and hashtags for flexible multi-model
information fusion. The experimental results show that MRLF can make accurate
location predictions and open a new door to understanding the multi-modal data
of social posts for online inference tasks.
\\ ( https://arxiv.org/abs/2306.07935 ,  574kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07944 (*cross-listing*)
Date: Thu, 8 Jun 2023 22:33:22 GMT   (203kb,D)

Title: Speech-to-Text Adapter and Speech-to-Entity Retriever Augmented LLMs for
 Speech Understanding
Authors: Mingqiu Wang, Izhak Shafran, Hagen Soltau, Wei Han, Yuan Cao, Dian Yu,
 Laurent El Shafey
Categories: eess.AS cs.AI cs.CL
\\
 Large Language Models (LLMs) have been applied in the speech domain, often
incurring a performance drop due to misaligned between speech and language
representations. To bridge this gap, we propose a joint speech and language
model (SLM) using a Speech2Text adapter, which maps speech into text token
embedding space without speech information loss. Additionally, using a
CTC-based blank-filtering, we can reduce the speech sequence length to that of
text. In speech MultiWoz dataset (DSTC11 challenge), SLM largely improves the
dialog state tracking (DST) performance (24.7% to 28.4% accuracy). Further to
address errors on rare entities, we augment SLM with a Speech2Entity retriever,
which uses speech to retrieve relevant entities, and then adds them to the
original SLM input as a prefix. With this retrieval-augmented SLM (ReSLM), the
DST performance jumps to 34.6% accuracy. Moreover, augmenting the ASR task with
the dialog understanding task improves the ASR performance from 9.4% to 8.5%
WER.
\\ ( https://arxiv.org/abs/2306.07944 ,  203kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07946 (*cross-listing*)
Date: Fri, 2 Jun 2023 14:47:56 GMT   (235kb,D)

Title: STUDY: Socially Aware Temporally Casual Decoder Recommender Systems
Authors: Eltayeb Ahmed, Diana Mincu, Lauren Harrell, Katherine Heller,
 Subhrajit Roy
Categories: cs.SI cs.AI cs.IR
Comments: 15 pages, 5 figures
\\
 With the overwhelming amount of data available both on and offline today,
recommender systems have become much needed to help users find items tailored
to their interests. When social network information exists there are methods
that utilize this information to make better recommendations, however the
methods are often clunky with complex architectures and training procedures.
Furthermore many of the existing methods utilize graph neural networks which
are notoriously difficult to train. To address this, we propose Socially-aware
Temporally caUsal Decoder recommender sYstems (STUDY). STUDY does joint
inference over groups of users who are adjacent in the social network graph
using a single forward pass of a modified transformer decoder network. We test
our method in a school-based educational content setting, using classroom
structure to define social networks. Our method outperforms both social and
sequential methods while maintaining the design simplicity of a single
homogeneous network that models all interactions in the data. We also carry out
ablation studies to understand the drivers of our performance gains and find
that our model depends on leveraging a social network structure that
effectively models the similarities in user behavior.
\\ ( https://arxiv.org/abs/2306.07946 ,  235kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07949 (*cross-listing*)
Date: Fri, 9 Jun 2023 03:36:00 GMT   (554kb,D)

Title: Improving Frame-level Classifier for Word Timings with Non-peaky CTC in
 End-to-End Automatic Speech Recognition
Authors: Xianzhao Chen, Yist Y. Lin, Kang Wang, Yi He, Zejun Ma
Categories: eess.AS cs.AI cs.LG
Comments: To appear in the proceedings of INTERSPEECH 2023
\\
 End-to-end (E2E) systems have shown comparable performance to hybrid systems
for automatic speech recognition (ASR). Word timings, as a by-product of ASR,
are essential in many applications, especially for subtitling and
computer-aided pronunciation training. In this paper, we improve the
frame-level classifier for word timings in E2E system by introducing label
priors in connectionist temporal classification (CTC) loss, which is adopted
from prior works, and combining low-level Mel-scale filter banks with
high-level ASR encoder output as input feature. On the internal Chinese corpus,
the proposed method achieves 95.68%/94.18% compared to the hybrid system
93.0%/90.22% on the word timing accuracy metrics. It also surpass a previous
E2E approach with an absolute increase of 4.80%/8.02% on the metrics on 7
languages. In addition, we further improve word timing accuracy by delaying CTC
peaks with frame-wise knowledge distillation, though only experimenting on
LibriSpeech.
\\ ( https://arxiv.org/abs/2306.07949 ,  554kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07956 (*cross-listing*)
Date: Tue, 13 Jun 2023 17:54:13 GMT   (367kb,D)

Title: Adaptive Monte Carlo Search for Conjecture Refutation in Graph Theory
Authors: Valentino Vito and Lim Yohanes Stefanus
Categories: math.CO cs.AI cs.DM
Comments: 27 pages, 11 figures, 3 tables
\\
 Graph theory is an interdisciplinary field of study that has various
applications in mathematical modeling and computer science. Research in graph
theory depends on the creation of not only theorems but also conjectures.
Conjecture-refuting algorithms attempt to refute conjectures by searching for
counterexamples to those conjectures, often by maximizing certain score
functions on graphs. This study proposes a novel conjecture-refuting algorithm,
referred to as the adaptive Monte Carlo search (AMCS) algorithm, obtained by
modifying the Monte Carlo tree search algorithm. Evaluated based on its success
in finding counterexamples to several graph theory conjectures, AMCS
outperforms existing conjecture-refuting algorithms. The algorithm is further
utilized to refute six open conjectures, two of which were chemical graph
theory conjectures formulated by Liu et al. in 2021 and four of which were
formulated by the AutoGraphiX computer system in 2006. Finally, four of the
open conjectures are strongly refuted by generalizing the counterexamples
obtained by AMCS to produce a family of counterexamples. It is expected that
the algorithm can help researchers test graph-theoretic conjectures more
effectively.
\\ ( https://arxiv.org/abs/2306.07956 ,  367kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07968 (*cross-listing*)
Date: Tue, 13 Jun 2023 17:59:57 GMT   (6193kb,D)

Title: arXiVeri: Automatic table verification with GPT
Authors: Gyungin Shin, Weidi Xie, Samuel Albanie
Categories: cs.CL cs.AI
Comments: Tech report
\\
 Without accurate transcription of numerical data in scientific documents, a
scientist cannot draw accurate conclusions. Unfortunately, the process of
copying numerical data from one paper to another is prone to human error. In
this paper, we propose to meet this challenge through the novel task of
automatic table verification (AutoTV), in which the objective is to verify the
accuracy of numerical data in tables by cross-referencing cited sources. To
support this task, we propose a new benchmark, arXiVeri, which comprises
tabular data drawn from open-access academic papers on arXiv. We introduce
metrics to evaluate the performance of a table verifier in two key areas: (i)
table matching, which aims to identify the source table in a cited document
that corresponds to a target table, and (ii) cell matching, which aims to
locate shared cells between a target and source table and identify their row
and column indices accurately. By leveraging the flexible capabilities of
modern large language models (LLMs), we propose simple baselines for table
verification. Our findings highlight the complexity of this task, even for
state-of-the-art LLMs like OpenAI's GPT-4. The code and benchmark will be made
publicly available.
\\ ( https://arxiv.org/abs/2306.07968 ,  6193kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07308 (*cross-listing*)
Date: Mon, 12 Jun 2023 13:48:37 GMT   (3526kb,D)

Title: Self-Supervised Hyperspectral Inpainting with the Optimisation inspired
 Deep Neural Network Prior
Authors: Shuo Li and Mehrdad Yaghoobi
Categories: eess.IV cs.CV cs.LG
\\
 Hyperspectral Image (HSI)s cover hundreds or thousands of narrow spectral
bands, conveying a wealth of spatial and spectral information. However, due to
the instrumental errors and the atmospheric changes, the HSI obtained in
practice are often contaminated by noise and dead pixels(lines), resulting in
missing information that may severely compromise the subsequent applications.
We introduce here a novel HSI missing pixel prediction algorithm, called Low
Rank and Sparsity Constraint Plug-and-Play (LRS-PnP). It is shown that LRS-PnP
is able to predict missing pixels and bands even when all spectral bands of the
image are missing. The proposed LRS-PnP algorithm is further extended to a
self-supervised model by combining the LRS-PnP with the Deep Image Prior (DIP),
called LRS-PnP-DIP. In a series of experiments with real data, It is shown that
the LRS-PnP-DIP either achieves state-of-the-art inpainting performance
compared to other learning-based methods, or outperforms them.
\\ ( https://arxiv.org/abs/2306.07308 ,  3526kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07440 (*cross-listing*)
Date: Mon, 12 Jun 2023 21:53:32 GMT   (9482kb,D)

Title: Deep Ultrasound Denoising Using Diffusion Probabilistic Models
Authors: Hojat Asgariandehkordi, Sobhan Goudarzi, Adrian Basarab, Hassan Rivaz
Categories: eess.IV cs.CV
Comments: This paper is accepted in IEEE IUS 2023
\\
 Ultrasound images are widespread in medical diagnosis for musculoskeletal,
cardiac, and obstetrical imaging due to the efficiency and non-invasiveness of
the acquisition methodology. However, the acquired images are degraded by
acoustic (e.g. reverberation and clutter) and electronic sources of noise. To
improve the Peak Signal to Noise Ratio (PSNR) of the images, previous denoising
methods often remove the speckles, which could be informative for radiologists
and also for quantitative ultrasound. Herein, a method based on the recent
Denoising Diffusion Probabilistic Models (DDPM) is proposed. It iteratively
enhances the image quality by eliminating the noise while preserving the
speckle texture. It is worth noting that the proposed method is trained in a
completely unsupervised manner, and no annotated data is required. The
experimental blind test results show that our method outperforms the previous
nonlocal means denoising methods in terms of PSNR and Generalized Contrast to
Noise Ratio (GCNR) while preserving speckles.
\\ ( https://arxiv.org/abs/2306.07440 ,  9482kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07601 (*cross-listing*)
Date: Tue, 13 Jun 2023 07:58:40 GMT   (327kb)

Title: Intrusion Detection: A Deep Learning Approach
Authors: Ishaan Shivhare, Joy Purohit, Vinay Jogani, Samina Attari and Dr.
 Madhav Chandane
Categories: cs.CR cs.CV
Comments: presented at 2023 Second International Conference on Electrical,
 Electronics, Information and Communication Technologies (ICEEICT 2023)
\\
 Network intrusions are a significant problem in all industries today. A
critical part of the solution is being able to effectively detect intrusions.
With recent advances in artificial intelligence, current research has begun
adopting deep learning approaches for intrusion detection. Current approaches
for multi-class intrusion detection include the use of a deep neural network.
However, it fails to take into account spatial relationships between the data
objects and long term dependencies present in the dataset. The paper proposes a
novel architecture to combat intrusion detection that has a Convolutional
Neural Network (CNN) module, along with a Long Short Term Memory(LSTM) module
and with a Support Vector Machine (SVM) classification function. The analysis
is followed by a comparison of both conventional machine learning techniques
and deep learning methodologies, which highlights areas that could be further
explored.
\\ ( https://arxiv.org/abs/2306.07601 ,  327kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07792 (*cross-listing*)
Date: Tue, 13 Jun 2023 14:13:16 GMT   (1786kb,D)

Title: Rethinking Polyp Segmentation from an Out-of-Distribution Perspective
Authors: Ge-Peng Ji, Jing Zhang, Dylan Campbell, Huan Xiong, Nick Barnes
Categories: eess.IV cs.CV
Comments: Technical report
\\
 Unlike existing fully-supervised approaches, we rethink colorectal polyp
segmentation from an out-of-distribution perspective with a simple but
effective self-supervised learning approach. We leverage the ability of masked
autoencoders -- self-supervised vision transformers trained on a reconstruction
task -- to learn in-distribution representations; here, the distribution of
healthy colon images. We then perform out-of-distribution reconstruction and
inference, with feature space standardisation to align the latent distribution
of the diverse abnormal samples with the statistics of the healthy samples. We
generate per-pixel anomaly scores for each image by calculating the difference
between the input and reconstructed images and use this signal for
out-of-distribution (ie, polyp) segmentation. Experimental results on six
benchmarks show that our model has excellent segmentation performance and
generalises across datasets. Our code is publicly available at
https://github.com/GewelsJI/Polyp-OOD.
\\ ( https://arxiv.org/abs/2306.07792 ,  1786kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07872 (*cross-listing*)
Date: Tue, 13 Jun 2023 16:03:12 GMT   (123kb,D)

Title: Expanding the Scope of DAWN: A Novel Version for Weighted Shortest Path
 Problem
Authors: Yelai Feng
Categories: cs.DS cs.DC
Comments: arXiv admin note: text overlap with arXiv:2208.04514
\\
 The shortest path problem is a typical problem in graph theory with wide
potential applications. The state-of-the-art single-source shortest paths
algorithm on the weight graph is the $\Delta$-stepping algorithm, which can
efficiently process weighted graphs in parallel. DAWN is an algorithm that
addresses the shortest path problem on unweighted graphs, and we propose a
weighted version that can handle graphs with weights edges, while maintaining
the high scalability and parallelism features as DAWN. The novel version
requires $O(\mu m)$ and $O(\mu \cdot E_{wcc})$ times on the connected and
unconnected graphs for SSSP problems, respectively. $E_{wcc}$ denote the number
of edges included in the largest weakly connected component, and $\mu$ is a
constant denoting the average number of path transformations in the tasks. We
tested the weighted version on the real graphs from Stanford Network Analysis
Platform and SuiteSparse Matrix Collection, which outperformed the solution of
$\Delta$-stepping algorithm from Gunrock, achieving a speedup of
43.163$\times$.
\\ ( https://arxiv.org/abs/2306.07872 ,  123kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07291 (*cross-listing*)
Date: Wed, 7 Jun 2023 22:26:50 GMT   (4906kb,D)

Title: An Ensemble Machine Learning Approach for Tropical Cyclone Detection
 Using ERA5 Reanalysis Data
Authors: Gabriele Accarino (1), Davide Donno (1), Francesco Immorlano (1 and
 2), Donatello Elia (1), Giovanni Aloisio (1 and 2) ((1) Advanced Scientific
 Computing Division, Centro Euro-Mediterraneo sui Cambiamenti Climatici,
 Lecce, Italy, (2) Department of Innovation Engineering, University of
 Salento, Lecce, Italy)
Categories: physics.ao-ph cs.LG
Comments: 27 pages, 8 figures, 1 table, submitted to Journal of Advances in
 Modeling Earth Systems
\\
 Tropical Cyclones (TCs) are counted among the most destructive phenomena that
can be found in nature. Every year, globally an average of 90 TCs occur over
tropical waters, and global warming is making them stronger, larger and more
destructive. The accurate detection and tracking of such phenomena have become
a relevant and interesting area of research in weather and climate science.
Traditionally, TCs have been identified in large climate datasets through the
use of deterministic tracking schemes that rely on subjective thresholds.
Machine Learning (ML) models can complement deterministic approaches due to
their ability to capture the mapping between the input climatic drivers and the
geographical position of the TC center from the available data. This study
presents a ML ensemble approach for locating TC center coordinates, embedding
both TC classification and localization in a single end-to-end learning task.
The ensemble combines TC center estimates of different ML models that agree
about the presence of a TC in input data. ERA5 reanalysis were used for model
training and testing jointly with the International Best Track Archive for
Climate Stewardship records. Results showed that the ML approach is well-suited
for TC detection providing good generalization capabilities on out of sample
data. In particular, it was able to accurately detect lower TC categories than
those used for training the models. On top of this, the ensemble approach was
able to further improve TC localization performance with respect to single
model TC center estimates, demonstrating the good capabilities of the proposed
approach.
\\ ( https://arxiv.org/abs/2306.07291 ,  4906kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07299 (*cross-listing*)
Date: Sun, 11 Jun 2023 02:42:09 GMT   (12349kb,D)

Title: Additive Multi-Index Gaussian process modeling, with application to
 multi-physics surrogate modeling of the quark-gluon plasma
Authors: Kevin Li, Simon Mak, J.-F Paquet, Steffen A. Bass
Categories: nucl-th cs.LG hep-ph stat.ML
\\
 The Quark-Gluon Plasma (QGP) is a unique phase of nuclear matter, theorized
to have filled the Universe shortly after the Big Bang. A critical challenge in
studying the QGP is that, to reconcile experimental observables with
theoretical parameters, one requires many simulation runs of a complex physics
model over a high-dimensional parameter space. Each run is computationally very
expensive, requiring thousands of CPU hours, thus limiting physicists to only
several hundred runs. Given limited training data for high-dimensional
prediction, existing surrogate models often yield poor predictions with high
predictive uncertainties, leading to imprecise scientific findings. To address
this, we propose a new Additive Multi-Index Gaussian process (AdMIn-GP) model,
which leverages a flexible additive structure on low-dimensional embeddings of
the parameter space. This is guided by prior scientific knowledge that the QGP
is dominated by multiple distinct physical phenomena (i.e., multiphysics), each
involving a small number of latent parameters. The AdMIn-GP models for such
embedded structures within a flexible Bayesian nonparametric framework, which
facilitates efficient model fitting via a carefully constructed variational
inference approach with inducing points. We show the effectiveness of the
AdMIn-GP via a suite of numerical experiments and our QGP application, where we
demonstrate considerably improved surrogate modeling performance over existing
models.
\\ ( https://arxiv.org/abs/2306.07299 ,  12349kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07331 (*cross-listing*)
Date: Mon, 12 Jun 2023 18:00:08 GMT   (566kb,D)

Title: Splitting and Parallelizing of Quantum Convolutional Neural Networks for
 Learning Translationally Symmetric Data
Authors: Koki Chinzei, Quoc Hoan Tran, Kazunori Maruyama, Hirotaka Oshima,
 Shintaro Sato
Categories: quant-ph cs.LG
Comments: 15 pages, 10 figures
\\
 A quantum convolutional neural network (QCNN) is a promising quantum machine
learning (QML) model to achieve quantum advantages in classically intractable
problems. However, QCNN requires a large number of measurements for data
learning, limiting its practical applications for large-scale problems. To
relieve this requirement, we propose a novel architecture called
split-parallelizing QCNN (sp-QCNN), which exploits the prior knowledge of
quantum data for designing efficient circuits. This architecture draws
inspiration from geometric quantum machine learning and targets translationally
symmetric quantum data commonly encountered in condensed matter physics. By
splitting the quantum circuit based on translational symmetry, sp-QCNN
substantially parallelizes conventional QCNN without increasing the number of
qubits and further improves the measurement efficiency by an order of the
number of qubits. To demonstrate its effectiveness, we apply sp-QCNN to a
quantum phase recognition task and show that it can achieve similar performance
to conventional QCNN while considerably reducing the measurement resources
required. Due to its high measurement efficiency, sp-QCNN can mitigate
statistical errors in estimating the gradient of the loss function, thereby
accelerating the learning process. These results open up new possibilities for
incorporating the prior knowledge of data into the efficient design of QML
models, leading to practical quantum advantages.
\\ ( https://arxiv.org/abs/2306.07331 ,  566kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07427 (*cross-listing*)
Date: Mon, 12 Jun 2023 21:08:55 GMT   (39784kb,D)

Title: Towards Fair and Explainable AI using a Human-Centered AI Approach
Authors: Bhavya Ghai
Categories: cs.CY cs.HC cs.LG
Comments: PhD Thesis
\\
 The rise of machine learning (ML) is accompanied by several high-profile
cases that have stressed the need for fairness, accountability, explainability
and trust in ML systems. The existing literature has largely focused on fully
automated ML approaches that try to optimize for some performance metric.
However, human-centric measures like fairness, trust, explainability, etc. are
subjective in nature, context-dependent, and might not correlate with
conventional performance metrics. To deal with these challenges, we explore a
human-centered AI approach that empowers people by providing more transparency
and human control.
 In this dissertation, we present 5 research projects that aim to enhance
explainability and fairness in classification systems and word embeddings. The
first project explores the utility/downsides of introducing local model
explanations as interfaces for machine teachers (crowd workers). Our study
found that adding explanations supports trust calibration for the resulting ML
model and enables rich forms of teaching feedback. The second project presents
D-BIAS, a causality-based human-in-the-loop visual tool for identifying and
mitigating social biases in tabular datasets. Apart from fairness, we found
that our tool also enhances trust and accountability. The third project
presents WordBias, a visual interactive tool that helps audit pre-trained
static word embeddings for biases against groups, such as females, or
subgroups, such as Black Muslim females. The fourth project presents DramatVis
Personae, a visual analytics tool that helps identify social biases in creative
writing. Finally, the last project presents an empirical study aimed at
understanding the cumulative impact of multiple fairness-enhancing
interventions at different stages of the ML pipeline on fairness, utility and
different population groups. We conclude by discussing some of the future
directions.
\\ ( https://arxiv.org/abs/2306.07427 ,  39784kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07455 (*cross-listing*)
Date: Mon, 12 Jun 2023 23:03:58 GMT   (861kb,D)

Title: Getting the Most from Eye-Tracking: User-Interaction Based Reading
 Region Estimation Dataset and Models
Authors: Ruoyan Kong, Ruixuan Sun, Charles Chuankai Zhang, Chen Chen, Sneha
 Patri, Gayathri Gajjela, and Joseph A. Konstan
Categories: cs.HC cs.LG
Comments: Ruoyan Kong, Ruixuan Sun, Charles Chuankai Zhang, Chen Chen, Sneha
 Patri, Gayathri Gajjela, and Joseph A. Konstan. Getting the most from
 eyetracking: User-interaction based reading region estimation dataset and
 models. In Proceedings of the 2023 Symposium on Eye Tracking Research and
 Applications, ETRA 23, New York, NY, USA, 2023. Association for Computing
 Machinery
Journal-ref: In Proceedings of the 2023 Symposium on Eye Tracking Research and
 Applications, ETRA 23, New York, NY, USA, 2023
DOI: 10.1145/3588015.3588404
\\
 A single digital newsletter usually contains many messages (regions). Users'
reading time spent on, and read level (skip/skim/read-in-detail) of each
message is important for platforms to understand their users' interests,
personalize their contents, and make recommendations. Based on accurate but
expensive-to-collect eyetracker-recorded data, we built models that predict
per-region reading time based on easy-to-collect Javascript browser tracking
data.
 With eye-tracking, we collected 200k ground-truth datapoints on participants
reading news on browsers. Then we trained machine learning and deep learning
models to predict message-level reading time based on user interactions like
mouse position, scrolling, and clicking. We reached 27\% percentage error in
reading time estimation with a two-tower neural network based on user
interactions only, against the eye-tracking ground truth data, while the
heuristic baselines have around 46\% percentage error. We also discovered the
benefits of replacing per-session models with per-timestamp models, and adding
user pattern features. We concluded with suggestions on developing
message-level reading estimation techniques based on available data.
\\ ( https://arxiv.org/abs/2306.07455 ,  861kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07472 (*cross-listing*)
Date: Tue, 13 Jun 2023 00:29:57 GMT   (2322kb,D)

Title: Von Mises Mixture Distributions for Molecular Conformation Generation
Authors: Kirk Swanson, Jake Williams, Eric Jonas
Categories: physics.chem-ph cs.LG stat.ML
Comments: ICML 2023
\\
 Molecules are frequently represented as graphs, but the underlying 3D
molecular geometry (the locations of the atoms) ultimately determines most
molecular properties. However, most molecules are not static and at room
temperature adopt a wide variety of geometries or $\textit{conformations}$. The
resulting distribution on geometries $p(x)$ is known as the Boltzmann
distribution, and many molecular properties are expectations computed under
this distribution. Generating accurate samples from the Boltzmann distribution
is therefore essential for computing these expectations accurately. Traditional
sampling-based methods are computationally expensive, and most recent machine
learning-based methods have focused on identifying $\textit{modes}$ in this
distribution rather than generating true $\textit{samples}$. Generating such
samples requires capturing conformational variability, and it has been widely
recognized that the majority of conformational variability in molecules arises
from rotatable bonds. In this work, we present VonMisesNet, a new graph neural
network that captures conformational variability via a variational
approximation of rotatable bond torsion angles as a mixture of von Mises
distributions. We demonstrate that VonMisesNet can generate conformations for
arbitrary molecules in a way that is both physically accurate with respect to
the Boltzmann distribution and orders of magnitude faster than existing
sampling methods.
\\ ( https://arxiv.org/abs/2306.07472 ,  2322kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07519 (*cross-listing*)
Date: Tue, 13 Jun 2023 03:25:04 GMT   (1661kb,D)

Title: Decoding Brain Motor Imagery with various Machine Learning techniques
Authors: Giovanni Jana, Corey Karnei, Shuvam Keshari
Categories: cs.HC cs.LG
\\
 Motor imagery (MI) is a well-documented technique used by subjects in BCI
(Brain Computer Interface) experiments to modulate brain activity within the
motor cortex and surrounding areas of the brain. In our term project, we
conducted an experiment in which the subjects were instructed to perform motor
imagery that would be divided into two classes (Right and Left). Experiments
were conducted with two different types of electrodes (Gel and POLiTag) and
data for individual subjects was collected. In this paper, we will apply
different machine learning (ML) methods to create a decoder based on offline
training data that uses evidence accumulation to predict a subject's intent
from their modulated brain signals in real-time.
\\ ( https://arxiv.org/abs/2306.07519 ,  1661kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07566 (*cross-listing*)
Date: Tue, 13 Jun 2023 06:34:44 GMT   (562kb,D)

Title: Learning under Selective Labels with Heterogeneous Decision-makers: An
 Instrumental Variable Approach
Authors: Jian Chen, Zhehao Li, Xiaojie Mao
Categories: stat.ML cs.LG
\\
 We study the problem of learning with selectively labeled data, which arises
when outcomes are only partially labeled due to historical decision-making. The
labeled data distribution may substantially differ from the full population,
especially when the historical decisions and the target outcome can be
simultaneously affected by some unobserved factors. Consequently, learning with
only the labeled data may lead to severely biased results when deployed to the
full population. Our paper tackles this challenge by exploiting the fact that
in many applications the historical decisions were made by a set of
heterogeneous decision-makers. In particular, we analyze this setup in a
principled instrumental variable (IV) framework. We establish conditions for
the full-population risk of any given prediction rule to be point-identified
from the observed data and provide sharp risk bounds when the point
identification fails. We further propose a weighted learning approach that
learns prediction rules robust to the label selection bias in both
identification settings. Finally, we apply our proposed approach to a
semi-synthetic financial dataset and demonstrate its superior performance in
the presence of selection bias.
\\ ( https://arxiv.org/abs/2306.07566 ,  562kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07604 (*cross-listing*)
Date: Tue, 13 Jun 2023 08:00:59 GMT   (9586kb,D)

Title: Towards a Machine-Learned Poisson Solver for Low-Temperature Plasma
 Simulations in Complex Geometries
Authors: Ihda Chaerony Siffa, Markus M. Becker, Klaus-Dieter Weltmann, and Jan
 Trieschmann
Categories: physics.comp-ph cs.LG cs.NA math.NA
\\
 Poisson's equation plays an important role in modeling many physical systems.
In electrostatic self-consistent low-temperature plasma (LTP) simulations,
Poisson's equation is solved at each simulation time step, which can amount to
a significant computational cost for the entire simulation. In this paper, we
describe the development of a generic machine-learned Poisson solver
specifically designed for the requirements of LTP simulations in complex 2D
reactor geometries on structured Cartesian grids. Here, the reactor geometries
can consist of inner electrodes and dielectric materials as often found in LTP
simulations. The approach leverages a hybrid CNN-transformer network
architecture in combination with a weighted multiterm loss function. We train
the network using highly-randomized synthetic data to ensure the
generalizability of the learned solver to unseen reactor geometries. The
results demonstrate that the learned solver is able to produce quantitatively
and qualitatively accurate solutions. Furthermore, it generalizes well on new
reactor geometries such as reference geometries found in the literature. To
increase the numerical accuracy of the solutions required in LTP simulations,
we employ a conventional iterative solver to refine the raw predictions,
especially to recover the high-frequency features not resolved by the initial
prediction. With this, the proposed learned Poisson solver provides the
required accuracy and is potentially faster than a pure GPU-based conventional
iterative solver. This opens up new possibilities for developing a generic and
high-performing learned Poisson solver for LTP systems in complex geometries.
\\ ( https://arxiv.org/abs/2306.07604 ,  9586kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07629 (*cross-listing*)
Date: Tue, 13 Jun 2023 08:57:54 GMT   (600kb,D)

Title: SqueezeLLM: Dense-and-Sparse Quantization
Authors: Sehoon Kim, Coleman Hooper, Amir Gholami, Zhen Dong, Xiuyu Li, Sheng
 Shen, Michael W. Mahoney, Kurt Keutzer
Categories: cs.CL cs.LG
\\
 Generative Large Language Models (LLMs) have demonstrated remarkable results
for a wide range of tasks. However, deploying these models for inference has
been a significant challenge due to their unprecedented resource requirements.
This has forced existing deployment frameworks to use multi-GPU inference
pipelines, which are often complex and costly, or to use smaller and less
performant models. In this work, we demonstrate that the main bottleneck for
generative inference with LLMs is memory bandwidth, rather than compute,
specifically for single batch inference. While quantization has emerged as a
promising solution by representing model weights with reduced precision,
previous efforts have often resulted in notable performance degradation. To
address this, we introduce SqueezeLLM, a post-training quantization framework
that not only enables lossless compression to ultra-low precisions of up to
3-bit, but also achieves higher quantization performance under the same memory
constraint. Our framework incorporates two novel ideas: (i) sensitivity-based
non-uniform quantization, which searches for the optimal bit precision
assignment based on second-order information; and (ii) the Dense-and-Sparse
decomposition that stores outliers and sensitive weight values in an efficient
sparse format. When applied to the LLaMA models, our 3-bit quantization
significantly reduces the perplexity gap from the FP16 baseline by up to 2.1x
as compared to the state-of-the-art methods with the same memory requirement.
Furthermore, when deployed on an A6000 GPU, our quantized models achieve up to
2.3x speedup compared to the baseline. Our code is open-sourced and available
online.
\\ ( https://arxiv.org/abs/2306.07629 ,  600kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07653 (*cross-listing*)
Date: Tue, 13 Jun 2023 09:48:34 GMT   (87kb,D)

Title: Automating Microservices Test Failure Analysis using Kubernetes Cluster
 Logs
Authors: Pawan Kumar Sarika, Deepika Badampudi, Sai Prashanth Josyula, Muhammad
 Usman
Categories: cs.SE cs.LG
DOI: 10.1145/3593434.3593472
\\
 Kubernetes is a free, open-source container orchestration system for
deploying and managing Docker containers that host microservices. Kubernetes
cluster logs help in determining the reason for the failure. However, as
systems become more complex, identifying failure reasons manually becomes more
difficult and time-consuming. This study aims to identify effective and
efficient classification algorithms to automatically determine the failure
reason. We compare five classification algorithms, Support Vector Machines,
K-Nearest Neighbors, Random Forest, Gradient Boosting Classifier, and
Multilayer Perceptron. Our results indicate that Random Forest produces good
accuracy while requiring fewer computational resources than other algorithms.
\\ ( https://arxiv.org/abs/2306.07653 ,  87kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07655 (*cross-listing*)
Date: Tue, 13 Jun 2023 09:52:44 GMT   (370kb,D)

Title: Malafide: a novel adversarial convolutive noise attack against deepfake
 and spoofing detection systems
Authors: Michele Panariello, Wanying Ge, Hemlata Tak, Massimiliano Todisco and
 Nicholas Evans
Categories: eess.AS cs.CR cs.LG
Comments: Accepted at INTERSPEECH 2023
\\
 We present Malafide, a universal adversarial attack against automatic speaker
verification (ASV) spoofing countermeasures (CMs). By introducing convolutional
noise using an optimised linear time-invariant filter, Malafide attacks can be
used to compromise CM reliability while preserving other speech attributes such
as quality and the speaker's voice. In contrast to other adversarial attacks
proposed recently, Malafide filters are optimised independently of the input
utterance and duration, are tuned instead to the underlying spoofing attack,
and require the optimisation of only a small number of filter coefficients.
Even so, they degrade CM performance estimates by an order of magnitude, even
in black-box settings, and can also be configured to overcome integrated CM and
ASV subsystems. Integrated solutions that use self-supervised learning CMs,
however, are more robust, under both black-box and white-box settings.
\\ ( https://arxiv.org/abs/2306.07655 ,  370kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07674 (*cross-listing*)
Date: Tue, 13 Jun 2023 10:38:12 GMT   (2082kb)

Title: Differentially Private One Permutation Hashing and Bin-wise Consistent
 Weighted Sampling
Authors: Xiaoyun Li and Ping Li
Categories: stat.ML cs.CR cs.DS cs.LG
\\
 Minwise hashing (MinHash) is a standard algorithm widely used in the
industry, for large-scale search and learning applications with the binary
(0/1) Jaccard similarity. One common use of MinHash is for processing massive
n-gram text representations so that practitioners do not have to materialize
the original data (which would be prohibitive). Another popular use of MinHash
is for building hash tables to enable sub-linear time approximate near neighbor
(ANN) search. MinHash has also been used as a tool for building large-scale
machine learning systems. The standard implementation of MinHash requires
applying $K$ random permutations. In comparison, the method of one permutation
hashing (OPH), is an efficient alternative of MinHash which splits the data
vectors into $K$ bins and generates hash values within each bin. OPH is
substantially more efficient and also more convenient to use.
 In this paper, we combine the differential privacy (DP) with OPH (as well as
MinHash), to propose the DP-OPH framework with three variants: DP-OPH-fix,
DP-OPH-re and DP-OPH-rand, depending on which densification strategy is adopted
to deal with empty bins in OPH. A detailed roadmap to the algorithm design is
presented along with the privacy analysis. An analytical comparison of our
proposed DP-OPH methods with the DP minwise hashing (DP-MH) is provided to
justify the advantage of DP-OPH. Experiments on similarity search confirm the
merits of DP-OPH, and guide the choice of the proper variant in different
practical scenarios. Our technique is also extended to bin-wise consistent
weighted sampling (BCWS) to develop a new DP algorithm called DP-BCWS for
non-binary data. Experiments on classification tasks demonstrate that DP-BCWS
is able to achieve excellent utility at around $\epsilon = 5\sim 10$, where
$\epsilon$ is the standard parameter in the language of $(\epsilon,
\delta)$-DP.
\\ ( https://arxiv.org/abs/2306.07674 ,  2082kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07744 (*cross-listing*)
Date: Tue, 13 Jun 2023 13:01:02 GMT   (137kb,D)

Title: Contrastive Learning-Based Audio to Lyrics Alignment for Multiple
 Languages
Authors: Simon Durand, Daniel Stoller, Sebastian Ewert
Categories: cs.SD cs.LG eess.AS
Comments: 5 pages, accepted at the International Conference on Acoustics,
 Speech, and Signal Processing (ICASSP) 2023
Journal-ref: ICASSP 2023 - 2023 IEEE International Conference on Acoustics,
 Speech and Signal Processing (ICASSP), Rhodes Island, Greece, 2023, pp. 1-5
DOI: 10.1109/ICASSP49357.2023.10096725
\\
 Lyrics alignment gained considerable attention in recent years.
State-of-the-art systems either re-use established speech recognition toolkits,
or design end-to-end solutions involving a Connectionist Temporal
Classification (CTC) loss. However, both approaches suffer from specific
weaknesses: toolkits are known for their complexity, and CTC systems use a loss
designed for transcription which can limit alignment accuracy. In this paper,
we use instead a contrastive learning procedure that derives cross-modal
embeddings linking the audio and text domains. This way, we obtain a novel
system that is simple to train end-to-end, can make use of weakly annotated
training data, jointly learns a powerful text model, and is tailored to
alignment. The system is not only the first to yield an average absolute error
below 0.2 seconds on the standard Jamendo dataset but it is also robust to
other languages, even when trained on English data only. Finally, we release
word-level alignments for the JamendoLyrics Multi-Lang dataset.
\\ ( https://arxiv.org/abs/2306.07744 ,  137kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07758 (*cross-listing*)
Date: Tue, 13 Jun 2023 13:18:04 GMT   (4264kb,D)

Title: Generated Graph Detection
Authors: Yihan Ma, Zhikun Zhang, Ning Yu, Xinlei He, Michael Backes, Yun Shen,
 Yang Zhang
Categories: cs.CR cs.LG
Comments: Accepted by ICML 2023
\\
 Graph generative models become increasingly effective for data distribution
approximation and data augmentation. While they have aroused public concerns
about their malicious misuses or misinformation broadcasts, just as what
Deepfake visual and auditory media has been delivering to society. Hence it is
essential to regulate the prevalence of generated graphs. To tackle this
problem, we pioneer the formulation of the generated graph detection problem to
distinguish generated graphs from real ones. We propose the first framework to
systematically investigate a set of sophisticated models and their performance
in four classification scenarios. Each scenario switches between seen and
unseen datasets/generators during testing to get closer to real-world settings
and progressively challenge the classifiers. Extensive experiments evidence
that all the models are qualified for generated graph detection, with specific
models having advantages in specific scenarios. Resulting from the validated
generality and oblivion of the classifiers to unseen datasets/generators, we
draw a safe conclusion that our solution can sustain for a decent while to curb
generated graph misuses.
\\ ( https://arxiv.org/abs/2306.07758 ,  4264kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07774 (*cross-listing*)
Date: Tue, 13 Jun 2023 13:50:31 GMT   (4699kb,D)

Title: The Rank-Reduced Kalman Filter: Approximate Dynamical-Low-Rank Filtering
 In High Dimensions
Authors: Jonathan Schmidt, Philipp Hennig, J\"org Nick, Filip Tronarp
Categories: stat.ML cs.LG
Comments: 12 pages main text (including references) + 9 pages appendix, 6
 figures
\\
 Inference and simulation in the context of high-dimensional dynamical systems
remain computationally challenging problems. Some form of dimensionality
reduction is required to make the problem tractable in general. In this paper,
we propose a novel approximate Gaussian filtering and smoothing method which
propagates low-rank approximations of the covariance matrices. This is
accomplished by projecting the Lyapunov equations associated with the
prediction step to a manifold of low-rank matrices, which are then solved by a
recently developed, numerically stable, dynamical low-rank integrator.
Meanwhile, the update steps are made tractable by noting that the covariance
update only transforms the column space of the covariance matrix, which is
low-rank by construction. The algorithm differentiates itself from existing
ensemble-based approaches in that the low-rank approximations of the covariance
matrices are deterministic, rather than stochastic. Crucially, this enables the
method to reproduce the exact Kalman filter as the low-rank dimension
approaches the true dimensionality of the problem. Our method reduces
computational complexity from cubic (for the Kalman filter) to \emph{quadratic}
in the state-space size in the worst-case, and can achieve \emph{linear}
complexity if the state-space model satisfies certain criteria. Through a set
of experiments in classical data-assimilation and spatio-temporal regression,
we show that the proposed method consistently outperforms the ensemble-based
methods in terms of error in the mean and covariance with respect to the exact
Kalman filter. This comes at no additional cost in terms of asymptotic
computational complexity.
\\ ( https://arxiv.org/abs/2306.07774 ,  4699kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07820 (*cross-listing*)
Date: Tue, 13 Jun 2023 14:52:35 GMT   (131kb,D)

Title: Unsupervised speech enhancement with deep dynamical generative speech
 and noise models
Authors: Xiaoyu Lin, Simon Leglaive, Laurent Girin, Xavier Alameda-Pineda
Categories: eess.AS cs.LG cs.SD
\\
 This work builds on a previous work on unsupervised speech enhancement using
a dynamical variational autoencoder (DVAE) as the clean speech model and
non-negative matrix factorization (NMF) as the noise model. We propose to
replace the NMF noise model with a deep dynamical generative model (DDGM)
depending either on the DVAE latent variables, or on the noisy observations, or
on both. This DDGM can be trained in three configurations: noise-agnostic,
noise-dependent and noise adaptation after noise-dependent training.
Experimental results show that the proposed method achieves competitive
performance compared to state-of-the-art unsupervised speech enhancement
methods, while the noise-dependent training configuration yields a much more
time-efficient inference process.
\\ ( https://arxiv.org/abs/2306.07820 ,  131kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07886 (*cross-listing*)
Date: Tue, 13 Jun 2023 16:25:30 GMT   (26kb)

Title: Symmetry & Critical Points for Symmetric Tensor Decompositions Problems
Authors: Yossi Arjevani, Gal Vinograd
Categories: math.OC cs.LG cs.NA math.AG math.NA stat.ML
\\
 We consider the non-convex optimization problem associated with the
decomposition of a real symmetric tensor into a sum of rank one terms. Use is
made of the rich symmetry structure to derive Puiseux series representations of
families of critical points, and so obtain precise analytic estimates on the
critical values and the Hessian spectrum. The sharp results make possible an
analytic characterization of various geometric obstructions to local
optimization methods, revealing in particular a complex array of saddles and
local minima which differ by their symmetry, structure and analytic properties.
A desirable phenomenon, occurring for all critical points considered, concerns
the index of a point, i.e., the number of negative Hessian eigenvalues,
increasing with the value of the objective function. Lastly, a Newton polytope
argument is used to give a complete enumeration of all critical points of fixed
symmetry, and it is shown that contrarily to the set of global minima which
remains invariant under different choices of tensor norms, certain families of
non-global minima emerge, others disappear.
\\ ( https://arxiv.org/abs/2306.07886 ,  26kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07926 (*cross-listing*)
Date: Fri, 9 Jun 2023 08:12:27 GMT   (9141kb,D)

Title: A Theory of Unsupervised Speech Recognition
Authors: Liming Wang, Mark Hasegawa-Johnson and Chang D. Yoo
Categories: eess.AS cs.CL cs.LG cs.SD
\\
 Unsupervised speech recognition (ASR-U) is the problem of learning automatic
speech recognition (ASR) systems from unpaired speech-only and text-only
corpora. While various algorithms exist to solve this problem, a theoretical
framework is missing from studying their properties and addressing such issues
as sensitivity to hyperparameters and training instability. In this paper, we
proposed a general theoretical framework to study the properties of ASR-U
systems based on random matrix theory and the theory of neural tangent kernels.
Such a framework allows us to prove various learnability conditions and sample
complexity bounds of ASR-U. Extensive ASR-U experiments on synthetic languages
with three classes of transition graphs provide strong empirical evidence for
our theory (code available at cactuswiththoughts/UnsupASRTheory.git).
\\ ( https://arxiv.org/abs/2306.07926 ,  9141kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07937 (*cross-listing*)
Date: Wed, 31 May 2023 07:36:45 GMT   (2485kb,D)

Title: Gibbs-Duhem-Informed Neural Networks for Binary Activity Coefficient
 Prediction
Authors: Jan G. Rittig, Kobi C. Felton, Alexei A. Lapkin, Alexander Mitsos
Categories: physics.chem-ph cs.LG
\\
 We propose Gibbs-Duhem-informed neural networks for the prediction of binary
activity coefficients at varying compositions. That is, we include the
Gibbs-Duhem equation explicitly in the loss function for training neural
networks, which is straightforward in standard machine learning (ML) frameworks
enabling automatic differentiation. In contrast to recent hybrid ML approaches,
our approach does not rely on embedding a specific thermodynamic model inside
the neural network and corresponding prediction limitations. Rather,
Gibbs-Duhem consistency serves as regularization, with the flexibility of ML
models being preserved. Our results show increased thermodynamic consistency
and generalization capabilities for activity coefficient predictions by
Gibbs-Duhem-informed graph neural networks and matrix completion methods. We
also find that the model architecture, particularly the activation function,
can have a strong influence on the prediction quality. The approach can be
easily extended to account for other thermodynamic consistency conditions.
\\ ( https://arxiv.org/abs/2306.07937 ,  2485kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07938 (*cross-listing*)
Date: Sun, 11 Jun 2023 03:20:00 GMT   (4604kb,D)

Title: Deep Demixing: Reconstructing the Evolution of Network Epidemics
Authors: Boning Li, Gojko \v{C}utura, Ananthram Swami, Santiago Segarra
Categories: cs.SI cs.LG eess.SP
Comments: arXiv admin note: substantial text overlap with arXiv:2011.09583
\\
 We propose the deep demixing (DDmix) model, a graph autoencoder that can
reconstruct epidemics evolving over networks from partial or aggregated
temporal information. Assuming knowledge of the network topology but not of the
epidemic model, our goal is to estimate the complete propagation path of a
disease spread. A data-driven approach is leveraged to overcome the lack of
model awareness. To solve this inverse problem, DDmix is proposed as a graph
conditional variational autoencoder that is trained from past epidemic spreads.
DDmix seeks to capture key aspects of the underlying (unknown) spreading
dynamics in its latent space. Using epidemic spreads simulated in synthetic and
real-world networks, we demonstrate the accuracy of DDmix by comparing it with
multiple (non-graph-aware) learning algorithms. The generalizability of DDmix
is highlighted across different types of networks. Finally, we showcase that a
simple post-processing extension of our proposed method can help identify
super-spreaders in the reconstructed propagation path.
\\ ( https://arxiv.org/abs/2306.07938 ,  4604kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07941 (*cross-listing*)
Date: Fri, 9 Jun 2023 15:47:22 GMT   (6363kb,D)

Title: GPT-Calls: Enhancing Call Segmentation and Tagging by Generating
 Synthetic Conversations via Large Language Models
Authors: Itzik Malkiel, Uri Alon, Yakir Yehuda, Shahar Keren, Oren Barkan, Royi
 Ronen, Noam Koenigstein
Categories: cs.CL cs.LG
\\
 Transcriptions of phone calls are of significant value across diverse fields,
such as sales, customer service, healthcare, and law enforcement. Nevertheless,
the analysis of these recorded conversations can be an arduous and
time-intensive process, especially when dealing with extended or multifaceted
dialogues. In this work, we propose a novel method, GPT-distilled Calls
Segmentation and Tagging (GPT-Calls), for efficient and accurate call
segmentation and topic extraction. GPT-Calls is composed of offline and online
phases. The offline phase is applied once to a given list of topics and
involves generating a distribution of synthetic sentences for each topic using
a GPT model and extracting anchor vectors. The online phase is applied to every
call separately and scores the similarity between the transcripted conversation
and the topic anchors found in the offline phase. Then, time domain analysis is
applied to the similarity scores to group utterances into segments and tag them
with topics. The proposed paradigm provides an accurate and efficient method
for call segmentation and topic extraction that does not require labeled data,
thus making it a versatile approach applicable to various domains. Our
algorithm operates in production under Dynamics 365 Sales Conversation
Intelligence, and our research is based on real sales conversations gathered
from various Dynamics 365 Sales tenants.
\\ ( https://arxiv.org/abs/2306.07941 ,  6363kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07948 (*cross-listing*)
Date: Tue, 6 Jun 2023 10:02:57 GMT   (108kb,AD)

Title: Optimal Inference in Contextual Stochastic Block Models
Authors: O. Duranthon and L. Zdeborov\'a
Categories: cs.SI cs.LG
\\
 The contextual stochastic block model (cSBM) was proposed for unsupervised
community detection on attributed graphs where both the graph and the
high-dimensional node information correlate with node labels. In the context of
machine learning on graphs, the cSBM has been widely used as a synthetic
dataset for evaluating the performance of graph-neural networks (GNNs) for
semi-supervised node classification. We consider a probabilistic Bayes-optimal
formulation of the inference problem and we derive a belief-propagation-based
algorithm for the semi-supervised cSBM; we conjecture it is optimal in the
considered setting and we provide its implementation. We show that there can be
a considerable gap between the accuracy reached by this algorithm and the
performance of the GNN architectures proposed in the literature. This suggests
that the cSBM, along with the comparison to the performance of the optimal
algorithm, readily accessible via our implementation, can be instrumental in
the development of more performant GNN architectures.
\\ ( https://arxiv.org/abs/2306.07948 ,  108kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07961 (*cross-listing*)
Date: Tue, 13 Jun 2023 17:56:02 GMT   (1047kb,D)

Title: Differentiating Metropolis-Hastings to Optimize Intractable Densities
Authors: Gaurav Arya, Ruben Seyer, Frank Sch\"afer, Alex Lew, Mathieu Huot,
 Vikash K. Mansinghka, Chris Rackauckas, Kartik Chandra and Moritz Schauer
Categories: stat.ML cs.LG stat.CO stat.ME
Comments: 6 pages, 6 figures
\\
 When performing inference on probabilistic models, target densities often
become intractable, necessitating the use of Monte Carlo samplers. We develop a
methodology for unbiased differentiation of the Metropolis-Hastings sampler,
allowing us to differentiate through probabilistic inference. By fusing recent
advances in stochastic differentiation with Markov chain coupling schemes, the
procedure can be made unbiased, low-variance, and automatic. This allows us to
apply gradient-based optimization to objectives expressed as expectations over
intractable target densities. We demonstrate our approach by finding an
ambiguous observation in a Gaussian mixture model and by maximizing the
specific heat in an Ising model.
\\ ( https://arxiv.org/abs/2306.07961 ,  1047kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07398 (*cross-listing*)
Date: Mon, 12 Jun 2023 19:55:10 GMT   (193kb,D)

Title: Continuity and Boundedness of Minimum-Norm CBF-Safe Controllers
Authors: Mohammed Alyaseen, Nikolay Atanasov, and Jorge Cortes
Categories: math.OC cs.SY eess.SY
\\
 The existence of a Control Barrier Function (CBF) for a control-affine system
provides a powerful design tool to ensure safety. Any controller that satisfies
the CBF condition and ensures that the trajectories of the closed-loop system
are well defined makes the zero superlevel set forward invariant. Such a
controller is referred to as safe. This paper studies the regularity properties
of the minimum-norm safe controller as a stepping stone towards the design of
general continuous safe feedback controllers. We characterize the set of points
where the minimum-norm safe controller is discontinuous and show that it
depends solely on the safe set and not on the particular CBF that describes it.
Our analysis of the controller behavior as we approach a point of discontinuity
allows us to identify sufficient conditions to ensure it grows unbounded or it
remains bounded. Examples illustrate our results, providing insight into the
conditions that lead to (un)bounded discontinuous minimum-norm controllers.
\\ ( https://arxiv.org/abs/2306.07398 ,  193kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07565 (*cross-listing*)
Date: Tue, 13 Jun 2023 06:28:40 GMT   (2801kb,D)

Title: deController: A Web3 Native Cyberspace Infrastructure Perspective
Authors: Hao Xu, Yunqing Sun, Zihao Li, Yao Sun, Lei Zhang and Xiaoshuai Zhang
Categories: cs.NI cs.SY eess.SY
\\
 Web3 brings an emerging outlook for the value of decentralization, boosting
the decentralized infrastructure. People can benefit from Web3, facilitated by
the advances in distributed ledger technology, to read, write and own web
content, services and applications more freely without revealing their real
identities. Although the features and merits of Web3 have been widely
discussed, the network architecture of Web3 and how to achieve complete
decentralization considering law compliance in Web3 are still unclear. Here, we
propose a perspective of Web3 architecture, deController, consisting of
underlay and overlay network as Web3 infrastructures to underpin services and
applications. The functions of underlay and overlay and their interactions are
illustrated. Meanwhile, the security and privacy of Web3 are analyzed based on
a novel design of three-tier identities cooperating with deController.
Furthermore, the impacts of laws on privacy and cyber sovereignty to achieve
Web3 are discussed.
\\ ( https://arxiv.org/abs/2306.07565 ,  2801kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07787 (*cross-listing*)
Date: Tue, 13 Jun 2023 14:08:23 GMT   (9708kb,D)

Title: Quantum coherent feedback control of an N-level atom with multiple
 excitations
Authors: Haijin Ding, Guofeng Zhang
Categories: quant-ph cs.SY eess.SY physics.atom-ph
\\
 The purpose of this paper is to study the coherent feedback control dynamics
based on the network that an $N$-level atom is coupled with a cavity and the
cavity is coupled with a single or multiple parallel waveguides through two
semitransparent mirrors. When initially the atom is excited at the highest
energy level, it can emit multiple photons into the cavity via the spontaneous
emission, and the photons in the cavity can be transmitted into the waveguide
and then re-interact with the cavity quantum electrodynamics (cavity-QED)
system through the feedback channel. When the cavity is coupled with a single
waveguide, the generation of multi-photon states in the waveguide can be
characterized by the exponential stability of the linear control system with
feedback delays determined by the feedback loop length. By tuning the feedback
loop length, there can be zero or multiple photons in the waveguide. Besides,
when the cavity-QED system is coupled with multiple parallel waveguides, the
emitted photons oscillate among different waveguides and this process is
influenced by the feedback loop length and coupling strengths among waveguides.
\\ ( https://arxiv.org/abs/2306.07787 ,  9708kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07852 (*cross-listing*)
Date: Tue, 13 Jun 2023 15:33:00 GMT   (278kb,D)

Title: Globally convergent homotopies for discrete-time optimal control
Authors: Willem Esterhuizen, Kathrin Fla{\ss}kamp, Matthias Hoffmann, Karl
 Worthmann
Categories: math.OC cs.SY eess.SY
Comments: 20 pages, 6 figures, under review
MSC-class: 49K15, 49M99, 90C30, 93B40, 93C55
\\
 Homotopy methods are attractive due to their capability of solving difficult
optimization and optimal control problems. The underlying idea is to construct
a homotopy, which may be considered as a continuous (zero) curve between the
difficult original problem and a related, comparatively-easy one. Then, the
solution of the easier one is continuously perturbed along the zero curve
towards the desired solution of the difficult problem. We propose a methodology
for the systematic construction of such zero curves for discrete-time optimal
control problems drawing upon the theory of globally-convergent homotopies for
nonlinear programs. This framework ensures that for almost every easy solution
there exists a suitable homotopy path that is, in addition, numerically
tractable. We demonstrate the results by solving a difficult path planning
problem.
\\ ( https://arxiv.org/abs/2306.07852 ,  278kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07888 (*cross-listing*)
Date: Tue, 13 Jun 2023 16:28:37 GMT   (28958kb,D)

Title: CAMEO: A Causal Transfer Learning Approach for Performance Optimization
 of Configurable Computer Systems
Authors: Md Shahriar Iqbal, Ziyuan Zhong, Iftakhar Ahmad, Baishakhi Ray, Pooyan
 Jamshidi
Categories: cs.PF cs.SE cs.SY eess.SY
\\
 Modern computer systems are highly-configurable, with hundreds of
configuration options interacting, resulting in enormous configuration space.
As a result, optimizing performance goals (e.g., latency) in such systems is
challenging. Worse, owing to evolving application requirements and user
specifications, these systems face frequent uncertainties in their environments
(e.g., hardware and workload change), making performance optimization even more
challenging. Recently, transfer learning has been applied to address this
problem by reusing knowledge from the offline configuration measurements of an
old environment, aka, source to a new environment, aka, target. These
approaches typically rely on predictive machine learning (ML) models to guide
the search for finding interventions to optimize performance. However, previous
empirical research showed that statistical models might perform poorly when the
deployment environment changes because the independent and identically
distributed (i.i.d.) assumption no longer holds. To address this issue, we
propose Cameo -- a method that sidesteps these limitations by identifying
invariant causal predictors under environmental changes, enabling the
optimization process to operate on a reduced search space, leading to faster
system performance optimization. We demonstrate significant performance
improvements over the state-of-the-art optimization methods on five highly
configurable computer systems, including three MLperf deep learning benchmark
systems, a video analytics pipeline, and a database system, and studied the
effectiveness in design explorations with different varieties and severity of
environmental changes and show the scalability of our approach to colossal
configuration spaces.
\\ ( https://arxiv.org/abs/2306.07888 ,  28958kb)
%%--%%--%%--%%--%%--%%--%%--%%--%%--%%--%%--%%--%%--%%--%%--%%--%%--%%--%%--%%
------------------------------------------------------------------------------
\\
arXiv:2009.00433
replaced with revised version Tue, 13 Jun 2023 08:01:42 GMT   (47kb)

Title: Solving the single-track train scheduling problem via Deep Reinforcement
 Learning
Authors: Valerio Agasucci, Giorgio Grani, Leonardo Lamorgese
Categories: cs.AI math.OC
Comments: Graph neural network added. Comparison with other methods added. 24
 pages, 5 figures (1 b&w)
MSC-class: 90B36
ACM-class: I.2.8
Journal-ref: Journal of Rail Transport Planning & Management, 26, p.100394
 (2023)
DOI: 10.1016/j.jrtpm.2023.100394
\\ ( https://arxiv.org/abs/2009.00433 ,  47kb)
------------------------------------------------------------------------------
\\
arXiv:2207.03122
replaced with revised version Tue, 13 Jun 2023 06:52:02 GMT   (1460kb,D)

Title: UIILD: A Unified Interpretable Intelligent Learning Diagnosis Framework
 for Intelligent Tutoring Systems
Authors: Zhifeng Wang, Wenxing Yan, Chunyan Zeng, Shi Dong
Categories: cs.AI cs.CY
Comments: 28 pages,5 figures
\\ ( https://arxiv.org/abs/2207.03122 ,  1460kb)
------------------------------------------------------------------------------
\\
arXiv:2207.07392
replaced with revised version Mon, 12 Jun 2023 19:47:57 GMT   (21kb)

Title: A simple declarative model of the Federal Disaster Assistance Policy --
 modelling and measuring transparency
Authors: Mark Dukes
Categories: cs.AI cs.CY
\\ ( https://arxiv.org/abs/2207.07392 ,  21kb)
------------------------------------------------------------------------------
\\
arXiv:2211.10738
replaced with revised version Tue, 13 Jun 2023 06:05:24 GMT   (2390kb,D)

Title: Knowledge Graph Contrastive Learning Based on Relation-Symmetrical
 Structure
Authors: Ke Liang, Yue Liu, Sihang Zhou, Wenxuan Tu, Yi Wen, Xihong Yang,
 Xiangjun Dong, Xinwang Liu
Categories: cs.AI cs.IR cs.LG
Comments: This work has been accepted by IEEE for publication. Early access in
 IEEE Transactions on Knowledge and Data Engineering
DOI: 10.1109/TKDE.2023.3282989
\\ ( https://arxiv.org/abs/2211.10738 ,  2390kb)
------------------------------------------------------------------------------
\\
arXiv:2211.13051
replaced with revised version Mon, 12 Jun 2023 23:43:23 GMT   (14287kb,D)

Title: Powderworld: A Platform for Understanding Generalization via Rich Task
 Distributions
Authors: Kevin Frans, Phillip Isola
Categories: cs.AI cs.LG
\\ ( https://arxiv.org/abs/2211.13051 ,  14287kb)
------------------------------------------------------------------------------
\\
arXiv:2212.00443
replaced with revised version Tue, 13 Jun 2023 11:16:50 GMT   (1696kb,D)

Title: Unbiased Heterogeneous Scene Graph Generation with Relation-aware
 Message Passing Neural Network
Authors: Kanghoon Yoon, Kibum Kim, Jinyoung Moon, Chanyoung Park
Categories: cs.AI
Comments: 9 pages; AAAI 2023
\\ ( https://arxiv.org/abs/2212.00443 ,  1696kb)
------------------------------------------------------------------------------
\\
arXiv:2304.13023
replaced with revised version Tue, 13 Jun 2023 15:14:57 GMT   (11313kb,D)

Title: Seeing is not always believing: Benchmarking Human and Model Perception
 of AI-Generated Images
Authors: Zeyu Lu, Di Huang, Lei Bai, Jingjing Qu, Chengyue Wu, Xihui Liu, Wanli
 Ouyang
Categories: cs.AI cs.CV
\\ ( https://arxiv.org/abs/2304.13023 ,  11313kb)
------------------------------------------------------------------------------
\\
arXiv:2305.18924
replaced with revised version Tue, 13 Jun 2023 06:17:56 GMT   (138kb,D)

Title: Bottom-Up Grounding in the Probabilistic Logic Programming System
 Fusemate
Authors: Peter Baumgartner, Elena Tartaglia
Categories: cs.AI cs.LO cs.PL
\\ ( https://arxiv.org/abs/2305.18924 ,  138kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04813
replaced with revised version Mon, 12 Jun 2023 23:09:30 GMT   (4345kb,D)

Title: Human in the Loop Novelty Generation
Authors: Mark Bercasio, Allison Wong, Dustin Dannenhauer
Categories: cs.AI
\\ ( https://arxiv.org/abs/2306.04813 ,  4345kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06821
replaced with revised version Tue, 13 Jun 2023 08:11:20 GMT   (1330kb)

Title: Towards end-to-end ASP computation
Authors: Taisuke Sato, Akihiro Takemura, Katsumi Inoue
Categories: cs.AI
Comments: 29 pages, 9 figures
ACM-class: I.2.4
\\ ( https://arxiv.org/abs/2306.06821 ,  1330kb)
------------------------------------------------------------------------------
\\
arXiv:2110.13107
replaced with revised version Tue, 13 Jun 2023 15:07:15 GMT   (24343kb,D)

Title: The Nuts and Bolts of Adopting Transformer in GANs
Authors: Rui Xu, Xiangyu Xu, Kai Chen, Bolei Zhou, Chen Change Loy
Categories: cs.CV
Comments: CVPR2023 Workshop AI4CC. Project Page:
 https://nbei.github.io/stransgan.html
\\ ( https://arxiv.org/abs/2110.13107 ,  24343kb)
------------------------------------------------------------------------------
\\
arXiv:2204.11161
replaced with revised version Tue, 13 Jun 2023 06:36:36 GMT   (16417kb,D)

Title: A Survey on Unsupervised Anomaly Detection Algorithms for Industrial
 Images
Authors: Yajie Cui, Zhaoxiang Liu and Shiguo Lian
Categories: cs.CV
Journal-ref: IEEE Access, vol. 11, pp. 55297-55315, 2023
DOI: 10.1109/ACCESS.2023.3282993
\\ ( https://arxiv.org/abs/2204.11161 ,  16417kb)
------------------------------------------------------------------------------
\\
arXiv:2205.05320
replaced with revised version Tue, 13 Jun 2023 15:17:51 GMT   (9836kb,D)

Title: Arbitrary Shape Text Detection via Boundary Transformer
Authors: Shi-Xue Zhang, Chun Yang, Xiaobin Zhu, Xu-Cheng Yin
Categories: cs.CV
Comments: It is an extend version (TextBPN++) to our preliminary conference
 version TextBPN(ICCV 2021), which has been accepted by IEEE Transactions on
 Multimedia (T-MM 2023). arXiv admin note: text overlap with arXiv:2107.12664
\\ ( https://arxiv.org/abs/2205.05320 ,  9836kb)
------------------------------------------------------------------------------
\\
arXiv:2206.08954
replaced with revised version Tue, 13 Jun 2023 00:48:40 GMT   (14424kb,D)

Title: Bag of Image Patch Embedding Behind the Success of Self-Supervised
 Learning
Authors: Yubei Chen, Adrien Bardes, Zengyi Li, Yann LeCun
Categories: cs.CV cs.LG
\\ ( https://arxiv.org/abs/2206.08954 ,  14424kb)
------------------------------------------------------------------------------
\\
arXiv:2211.11738
replaced with revised version Tue, 13 Jun 2023 14:32:05 GMT   (19124kb,D)

Title: SPARF: Neural Radiance Fields from Sparse and Noisy Poses
Authors: Prune Truong and Marie-Julie Rakotosaona and Fabian Manhardt and
 Federico Tombari
Categories: cs.CV
Comments: Code is released at https://github.com/google-research/sparf.
 Published at CVPR 2023 as a Highlight
\\ ( https://arxiv.org/abs/2211.11738 ,  19124kb)
------------------------------------------------------------------------------
\\
arXiv:2212.05171
replaced with revised version Mon, 12 Jun 2023 19:30:52 GMT   (1477kb,D)

Title: ULIP: Learning a Unified Representation of Language, Images, and Point
 Clouds for 3D Understanding
Authors: Le Xue, Mingfei Gao, Chen Xing, Roberto Mart\'in-Mart\'in, Jiajun Wu,
 Caiming Xiong, Ran Xu, Juan Carlos Niebles, Silvio Savarese
Categories: cs.CV
Comments: Accepted by CVPR 2023
\\ ( https://arxiv.org/abs/2212.05171 ,  1477kb)
------------------------------------------------------------------------------
\\
arXiv:2301.13591
replaced with revised version Tue, 13 Jun 2023 02:21:59 GMT   (2947kb,D)

Title: Zero3D: Semantic-Driven Multi-Category 3D Shape Generation
Authors: Bo Han, Yitong Fu, Yixuan Shen
Categories: cs.CV cs.MM
\\ ( https://arxiv.org/abs/2301.13591 ,  2947kb)
------------------------------------------------------------------------------
\\
arXiv:2302.05905
replaced with revised version Tue, 13 Jun 2023 09:30:41 GMT   (15866kb,D)

Title: Single Motion Diffusion
Authors: Sigal Raab, Inbal Leibovitch, Guy Tevet, Moab Arar, Amit H. Bermano,
 and Daniel Cohen-Or
Categories: cs.CV cs.AI cs.GR
Comments: Video: https://www.youtube.com/watch?v=zuWpVTgb_0U, Project page:
 https://sinmdm.github.io/SinMDM-page, Code: https://github.com/SinMDM/SinMDM
\\ ( https://arxiv.org/abs/2302.05905 ,  15866kb)
------------------------------------------------------------------------------
\\
arXiv:2303.03315
replaced with revised version Tue, 13 Jun 2023 16:16:16 GMT   (40540kb,D)

Title: MACARONS: Mapping And Coverage Anticipation with RGB Online
 Self-Supervision
Authors: Antoine Gu\'edon, Tom Monnier, Pascal Monasse and Vincent Lepetit
Categories: cs.CV cs.AI cs.RO
Comments: To appear at CVPR 2023. Project Webpage:
 https://imagine.enpc.fr/~guedona/MACARONS/
\\ ( https://arxiv.org/abs/2303.03315 ,  40540kb)
------------------------------------------------------------------------------
\\
arXiv:2303.07284
replaced with revised version Mon, 12 Jun 2023 18:13:44 GMT   (1435kb,D)

Title: Align and Attend: Multimodal Summarization with Dual Contrastive Losses
Authors: Bo He, Jun Wang, Jielin Qiu, Trung Bui, Abhinav Shrivastava, Zhaowen
 Wang
Categories: cs.CV
Comments: Accepted at CVPR 2023
\\ ( https://arxiv.org/abs/2303.07284 ,  1435kb)
------------------------------------------------------------------------------
\\
arXiv:2303.11403
replaced with revised version Mon, 12 Jun 2023 20:52:37 GMT   (1541kb,D)

Title: eP-ALM: Efficient Perceptual Augmentation of Language Models
Authors: Mustafa Shukor, Corentin Dancette, Matthieu Cord
Categories: cs.CV cs.CL cs.LG
Comments: New experiments and comparison with SoTA. Code:
 https://github.com/mshukor/eP-ALM
\\ ( https://arxiv.org/abs/2303.11403 ,  1541kb)
------------------------------------------------------------------------------
\\
arXiv:2303.15693
replaced with revised version Tue, 13 Jun 2023 02:31:10 GMT   (1128kb)

Title: Large-scale pretraining on pathological images for fine-tuning of small
 pathological benchmarks
Authors: Masataka Kawai, Noriaki Ota, Shinsuke Yamaoka
Categories: cs.CV cs.LG eess.IV
Comments: 20 pages, 6 figures
\\ ( https://arxiv.org/abs/2303.15693 ,  1128kb)
------------------------------------------------------------------------------
\\
arXiv:2304.05047
replaced with revised version Tue, 13 Jun 2023 06:34:37 GMT   (7986kb,D)

Title: Semi-Supervised Relational Contrastive Learning
Authors: Attiano Purpura-Pontoniere, Demetri Terzopoulos, Adam Wang,
 Abdullah-Al-Zubaer Imran
Categories: cs.CV
Comments: 10 pages, 5 figures, 2 tables
\\ ( https://arxiv.org/abs/2304.05047 ,  7986kb)
------------------------------------------------------------------------------
\\
arXiv:2305.04790
replaced with revised version Tue, 13 Jun 2023 13:31:12 GMT   (2289kb,D)

Title: MultiModal-GPT: A Vision and Language Model for Dialogue with Humans
Authors: Tao Gong, Chengqi Lyu, Shilong Zhang, Yudong Wang, Miao Zheng, Qian
 Zhao, Kuikun Liu, Wenwei Zhang, Ping Luo, Kai Chen
Categories: cs.CV cs.CL
Comments: 10 pages, 8 figures
\\ ( https://arxiv.org/abs/2305.04790 ,  2289kb)
------------------------------------------------------------------------------
\\
arXiv:2305.09996
replaced with revised version Tue, 13 Jun 2023 05:57:07 GMT   (2704kb,D)

Title: Restoring Images Captured in Arbitrary Hybrid Adverse Weather Conditions
 in One Go
Authors: Ye-Cong Wan, Ming-Wen Shao, Yuan-Shuo Cheng, Yue-Xian Liu, Zhi-Yuan
 Bao
Categories: cs.CV cs.AI
Comments: In submission
\\ ( https://arxiv.org/abs/2305.09996 ,  2704kb)
------------------------------------------------------------------------------
\\
arXiv:2305.10855
replaced with revised version Tue, 13 Jun 2023 11:13:22 GMT   (46690kb,D)

Title: TextDiffuser: Diffusion Models as Text Painters
Authors: Jingye Chen, Yupan Huang, Tengchao Lv, Lei Cui, Qifeng Chen, Furu Wei
Categories: cs.CV
\\ ( https://arxiv.org/abs/2305.10855 ,  46690kb)
------------------------------------------------------------------------------
\\
arXiv:2305.17382
replaced with revised version Tue, 13 Jun 2023 14:02:20 GMT   (3114kb,D)

Title: A Zero-/Few-Shot Anomaly Classification and Segmentation Method for CVPR
 2023 VAND Workshop Challenge Tracks 1&2: 1st Place on Zero-shot AD and 4th
 Place on Few-shot AD
Authors: Xuhai Chen, Yue Han, Jiangning Zhang
Categories: cs.CV
\\ ( https://arxiv.org/abs/2305.17382 ,  3114kb)
------------------------------------------------------------------------------
\\
arXiv:2306.00543
replaced with revised version Tue, 13 Jun 2023 05:48:42 GMT   (2200kb)

Title: A Novel Driver Distraction Behavior Detection Based on Self-Supervised
 Learning Framework with Masked Image Modeling
Authors: Yingzhi Zhang, Taiguo Li, Chao Li and Xinghong Zhou
Categories: cs.CV
\\ ( https://arxiv.org/abs/2306.00543 ,  2200kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03092
replaced with revised version Mon, 12 Jun 2023 20:50:07 GMT   (7161kb,D)

Title: Neuralangelo: High-Fidelity Neural Surface Reconstruction
Authors: Zhaoshuo Li, Thomas M\"uller, Alex Evans, Russell H. Taylor, Mathias
 Unberath, Ming-Yu Liu, Chen-Hsuan Lin
Categories: cs.CV
Comments: CVPR 2023, project page:
 https://research.nvidia.com/labs/dir/neuralangelo
\\ ( https://arxiv.org/abs/2306.03092 ,  7161kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04911
replaced with revised version Tue, 13 Jun 2023 00:37:33 GMT   (983kb,D)

Title: Test-Time Style Shifting: Handling Arbitrary Styles in Domain
 Generalization
Authors: Jungwuk Park, Dong-Jun Han, Soyeong Kim, Jaekyun Moon
Categories: cs.CV cs.AI
Comments: ICML 2023 camera-ready version
\\ ( https://arxiv.org/abs/2306.04911 ,  983kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06362
replaced with revised version Tue, 13 Jun 2023 06:38:47 GMT   (40261kb,D)

Title: Aria Digital Twin: A New Benchmark Dataset for Egocentric 3D Machine
 Perception
Authors: Xiaqing Pan, Nicholas Charron, Yongqian Yang, Scott Peters, Thomas
 Whelan, Chen Kong, Omkar Parkhi, Richard Newcombe, Carl Yuheng Ren
Categories: cs.CV cs.AI cs.LG
\\ ( https://arxiv.org/abs/2306.06362 ,  40261kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06513
replaced with revised version Tue, 13 Jun 2023 05:06:32 GMT   (18008kb,D)

Title: Learning Image-Adaptive Codebooks for Class-Agnostic Image Restoration
Authors: Kechun Liu, Yitong Jiang, Inchang Choi, Jinwei Gu
Categories: cs.CV
\\ ( https://arxiv.org/abs/2306.06513 ,  18008kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07265
replaced with revised version Tue, 13 Jun 2023 17:53:15 GMT   (165kb,D)

Title: detrex: Benchmarking Detection Transformers
Authors: Tianhe Ren, Shilong Liu, Feng Li, Hao Zhang, Ailing Zeng, Jie Yang,
 Xingyu Liao, Ding Jia, Hongyang Li, He Cao, Jianan Wang, Zhaoyang Zeng,
 Xianbiao Qi, Yuhui Yuan, Jianwei Yang, Lei Zhang
Categories: cs.CV
Comments: project link: https://github.com/IDEA-Research/detrex
\\ ( https://arxiv.org/abs/2306.07265 ,  165kb)
------------------------------------------------------------------------------
\\
arXiv:2202.10862
replaced with revised version Tue, 13 Jun 2023 17:19:24 GMT   (217kb)

Title: Asynchronous Fully-Decentralized SGD in the Cluster-Based Model
Authors: Hagit Attiya and Noa Schiller
Categories: cs.DC
Journal-ref: CIAC 13 (2023) 52-66
DOI: 10.1007/978-3-031-30448-4_5
\\ ( https://arxiv.org/abs/2202.10862 ,  217kb)
------------------------------------------------------------------------------
\\
arXiv:2304.05495
replaced with revised version Tue, 13 Jun 2023 01:06:39 GMT   (3149kb,D)

Title: EcoFed: Efficient Communication for DNN Partitioning-based Federated
 Learning
Authors: Di Wu, Rehmat Ullah, Philip Rodgers, Peter Kilpatrick, Ivor Spence,
 and Blesson Varghese
Categories: cs.DC
\\ ( https://arxiv.org/abs/2304.05495 ,  3149kb)
------------------------------------------------------------------------------
\\
arXiv:2206.13119
replaced with revised version Tue, 13 Jun 2023 11:02:24 GMT   (43kb)

Title: Optimal Private Payoff Manipulation against Commitment in Extensive-form
 Games
Authors: Yurong Chen, Xiaotie Deng, Yuhao Li
Categories: cs.GT cs.AI cs.DS econ.TH
\\ ( https://arxiv.org/abs/2206.13119 ,  43kb)
------------------------------------------------------------------------------
\\
arXiv:1307.6616
replaced with revised version Tue, 13 Jun 2023 14:21:16 GMT   (0kb,I)

Title: Does generalization performance of $l^q$ regularization learning depend
 on $q$? A negative example
Authors: Shaobo Lin, Chen Xu, Jingshan Zeng, Jian Fang
Categories: cs.LG stat.ML
Comments: There is critical wrong in the proof
\\ ( https://arxiv.org/abs/1307.6616 ,  0kb)
------------------------------------------------------------------------------
\\
arXiv:1503.02143
replaced with revised version Tue, 13 Jun 2023 14:20:25 GMT   (0kb,I)

Title: Model selection of polynomial kernel regression
Authors: Shaobo Lin, Xingping Sun, Zongben Xu, Jinshan Zeng
Categories: cs.LG
Comments: There is critical wrong in the proof
ACM-class: F.2.2
\\ ( https://arxiv.org/abs/1503.02143 ,  0kb)
------------------------------------------------------------------------------
\\
arXiv:2001.02879
replaced with revised version Tue, 13 Jun 2023 14:19:55 GMT   (0kb,I)

Title: Adaptive Stopping Rule for Kernel-based Gradient Descent Algorithms
Authors: Xiangyu Chang, Shao-Bo Lin
Categories: cs.LG stat.ML
Comments: There is a critical wrong in the proof
\\ ( https://arxiv.org/abs/2001.02879 ,  0kb)
------------------------------------------------------------------------------
\\
arXiv:2011.06167
replaced with revised version Mon, 12 Jun 2023 21:57:31 GMT   (2340kb,D)

Title: When Does Uncertainty Matter?: Understanding the Impact of Predictive
 Uncertainty in ML Assisted Decision Making
Authors: Sean McGrath, Parth Mehta, Alexandra Zytek, Isaac Lage, Himabindu
 Lakkaraju
Categories: cs.LG
Journal-ref: Transactions on Machine Learning Research, 2023
\\ ( https://arxiv.org/abs/2011.06167 ,  2340kb)
------------------------------------------------------------------------------
\\
arXiv:2012.01606
replaced with revised version Tue, 13 Jun 2023 03:57:37 GMT   (88kb,D)

Title: Domain Adaptation with Incomplete Target Domains
Authors: Zhenpeng Li, Jianan Jiang, Yuhong Guo, Tiantian Tang, Chengxiang Zhuo,
 Jieping Ye
Categories: cs.LG cs.AI
\\ ( https://arxiv.org/abs/2012.01606 ,  88kb)
------------------------------------------------------------------------------
\\
arXiv:2106.06012
replaced with revised version Tue, 13 Jun 2023 07:34:21 GMT   (177kb,D)

Title: Learning distinct features helps, provably
Authors: Firas Laakom, Jenni Raitoharju, Alexandros Iosifidis, Moncef Gabbouj
Categories: cs.LG cs.CV
Comments: 17 pages, 3 figure
\\ ( https://arxiv.org/abs/2106.06012 ,  177kb)
------------------------------------------------------------------------------
\\
arXiv:2107.10492
replaced with revised version Tue, 13 Jun 2023 05:39:46 GMT   (3943kb,D)

Title: Bandit Quickest Changepoint Detection
Authors: Aditya Gopalan, Venkatesh Saligrama and Braghadeesh Lakshminarayanan
Categories: cs.LG cs.IT math.IT stat.ML
Comments: Some typos fixed in the NeurIPS 2021 version
\\ ( https://arxiv.org/abs/2107.10492 ,  3943kb)
------------------------------------------------------------------------------
\\
arXiv:2109.08010
replaced with revised version Tue, 13 Jun 2023 09:57:23 GMT   (11422kb,D)

Title: WildWood: a new Random Forest algorithm
Authors: St\'ephane Ga\"iffas and Ibrahim Merad and Yiyang Yu
Categories: cs.LG stat.ML
\\ ( https://arxiv.org/abs/2109.08010 ,  11422kb)
------------------------------------------------------------------------------
\\
arXiv:2110.04514
replaced with revised version Tue, 13 Jun 2023 17:34:36 GMT   (2937kb,D)

Title: Towards Open-World Feature Extrapolation: An Inductive Graph Learning
 Approach
Authors: Qitian Wu, Chenxiao Yang, Junchi Yan
Categories: cs.LG cs.AI cs.IR
Comments: Accepted to NeurIPS 2021 conference. The implementation codes are
 public available at https://github.com/qitianwu/FATE
\\ ( https://arxiv.org/abs/2110.04514 ,  2937kb)
------------------------------------------------------------------------------
\\
arXiv:2110.13530
replaced with revised version Tue, 13 Jun 2023 16:02:30 GMT   (2800kb,D)

Title: An extended physics informed neural network for preliminary analysis of
 parametric optimal control problems
Authors: Nicola Demo, Maria Strazzullo and Gianluigi Rozza
Categories: cs.LG cs.NA math.NA
\\ ( https://arxiv.org/abs/2110.13530 ,  2800kb)
------------------------------------------------------------------------------
\\
arXiv:2111.11053
replaced with revised version Tue, 13 Jun 2023 17:10:22 GMT   (5276kb,D)

Title: DAPPER: Label-Free Performance Estimation after Personalization for
 Heterogeneous Mobile Sensing
Authors: Taesik Gong, Yewon Kim, Adiba Orzikulova, Yunxin Liu, Sung Ju Hwang,
 Jinwoo Shin, Sung-Ju Lee
Categories: cs.LG
Comments: Accepted to Proceedings of the ACM on Interactive, Mobile, Wearable
 and Ubiquitous Technologies (IMWUT), 2023
DOI: 10.1145/3596256
\\ ( https://arxiv.org/abs/2111.11053 ,  5276kb)
------------------------------------------------------------------------------
\\
arXiv:2111.13684
replaced with revised version Tue, 13 Jun 2023 11:56:21 GMT   (16242kb,D)

Title: Spatio-Temporal Joint Graph Convolutional Networks for Traffic
 Forecasting
Authors: Chuanpan Zheng, Xiaoliang Fan, Shirui Pan, Haibing Jin, Zhaopeng Peng,
 Zonghan Wu, Cheng Wang, Philip S. Yu
Categories: cs.LG cs.AI
\\ ( https://arxiv.org/abs/2111.13684 ,  16242kb)
------------------------------------------------------------------------------
\\
arXiv:2207.07730
replaced with revised version Tue, 13 Jun 2023 17:56:37 GMT   (8162kb,D)

Title: How to Reuse and Compose Knowledge for a Lifetime of Tasks: A Survey on
 Continual Learning and Functional Composition
Authors: Jorge A. Mendez and Eric Eaton
Categories: cs.LG cs.AI
Comments: Published in Transactions on Machine Learning Research (TMLR), June
 2023
\\ ( https://arxiv.org/abs/2207.07730 ,  8162kb)
------------------------------------------------------------------------------
\\
arXiv:2208.13898
replaced with revised version Mon, 12 Jun 2023 19:20:30 GMT   (1853kb,D)

Title: Conjugate Natural Selection
Authors: Reilly Raab, Luca de Alfaro, Yang Liu
Categories: cs.LG cs.NE stat.ML
Comments: 18 pages, 3 figures
\\ ( https://arxiv.org/abs/2208.13898 ,  1853kb)
------------------------------------------------------------------------------
\\
arXiv:2210.00107
replaced with revised version Mon, 12 Jun 2023 22:23:56 GMT   (8486kb,D)

Title: Contrastive Corpus Attribution for Explaining Representations
Authors: Chris Lin, Hugh Chen, Chanwoo Kim, Su-In Lee
Categories: cs.LG cs.AI cs.CV
Comments: Updated for the final camera-ready version of ICLR 2023
\\ ( https://arxiv.org/abs/2210.00107 ,  8486kb)
------------------------------------------------------------------------------
\\
arXiv:2210.11269
replaced with revised version Tue, 13 Jun 2023 11:50:39 GMT   (1288kb,D)

Title: Attention-based Modeling of Physical Systems: Improved Latent
 Representations
Authors: Arnaud Pannatier, Kyle Matoba, Fran\c{c}ois Fleuret
Categories: cs.LG physics.ao-ph physics.flu-dyn
\\ ( https://arxiv.org/abs/2210.11269 ,  1288kb)
------------------------------------------------------------------------------
\\
arXiv:2210.16400
replaced with revised version Tue, 13 Jun 2023 04:47:46 GMT   (2979kb,D)

Title: Flatter, faster: scaling momentum for optimal speedup of SGD
Authors: Aditya Cowsik, Tankut Can and Paolo Glorioso
Categories: cs.LG cond-mat.dis-nn cond-mat.stat-mech
Comments: v2: expanded introduction section, corrected minor typos. v1: 12+13
 pages, 3 figures
\\ ( https://arxiv.org/abs/2210.16400 ,  2979kb)
------------------------------------------------------------------------------
\\
arXiv:2211.01939
replaced with revised version Tue, 13 Jun 2023 02:05:24 GMT   (47kb)

Title: Empirical Analysis of Model Selection for Heterogeneous Causal Effect
 Estimation
Authors: Divyat Mahajan, Ioannis Mitliagkas, Brady Neal, Vasilis Syrgkanis
Categories: cs.LG cs.AI stat.ME
Comments: Preprint. Under Review
\\ ( https://arxiv.org/abs/2211.01939 ,  47kb)
------------------------------------------------------------------------------
\\
arXiv:2212.04055
replaced with revised version Tue, 13 Jun 2023 04:17:07 GMT   (481kb,D)

Title: Mitigating Memorization of Noisy Labels by Clipping the Model Prediction
Authors: Hongxin Wei, Huiping Zhuang, Renchunzi Xie, Lei Feng, Gang Niu, Bo An,
 Yixuan Li
Categories: cs.LG cs.AI
Comments: Accepted by ICML 2023
\\ ( https://arxiv.org/abs/2212.04055 ,  481kb)
------------------------------------------------------------------------------
\\
arXiv:2212.07723
replaced with revised version Tue, 13 Jun 2023 06:46:39 GMT   (2608kb,D)

Title: Physics-Informed Neural Networks for Material Model Calibration from
 Full-Field Displacement Data
Authors: David Anton, Henning Wessels
Categories: cs.LG
\\ ( https://arxiv.org/abs/2212.07723 ,  2608kb)
------------------------------------------------------------------------------
\\
arXiv:2212.13069
replaced with revised version Tue, 13 Jun 2023 15:28:27 GMT   (6731kb,D)

Title: Homophily modulates double descent generalization in graph convolution
 networks
Authors: Cheng Shi, Liming Pan, Hong Hu and Ivan Dokmani\'c
Categories: cs.LG cond-mat.dis-nn stat.ML
\\ ( https://arxiv.org/abs/2212.13069 ,  6731kb)
------------------------------------------------------------------------------
\\
arXiv:2301.06957
replaced with revised version Mon, 12 Jun 2023 22:23:55 GMT   (2388kb,D)

Title: FewSOME: One-Class Few Shot Anomaly Detection with Siamese Networks
Authors: Niamh Belton, Misgina Tsighe Hagos, Aonghus Lawlor, Kathleen M. Curran
Categories: cs.LG
\\ ( https://arxiv.org/abs/2301.06957 ,  2388kb)
------------------------------------------------------------------------------
\\
arXiv:2302.05322
replaced with revised version Tue, 13 Jun 2023 05:39:42 GMT   (5420kb)

Title: Numerical Methods For PDEs Over Manifolds Using Spectral Physics
 Informed Neural Networks
Authors: Yuval Zelig and Shai Dekel
Categories: cs.LG cs.NA math.NA
Comments: 25 pages
\\ ( https://arxiv.org/abs/2302.05322 ,  5420kb)
------------------------------------------------------------------------------
\\
arXiv:2302.06495
replaced with revised version Tue, 13 Jun 2023 15:13:25 GMT   (4522kb,D)

Title: Density-Softmax: Scalable and Calibrated Uncertainty Estimation under
 Distribution Shifts
Authors: Ha Manh Bui, Anqi Liu
Categories: cs.LG stat.ML
Comments: 37 pages, 6 tables, 22 figures
\\ ( https://arxiv.org/abs/2302.06495 ,  4522kb)
------------------------------------------------------------------------------
\\
arXiv:2302.07549
replaced with revised version Tue, 13 Jun 2023 12:24:32 GMT   (103kb,D)

Title: Deep Offline Reinforcement Learning for Real-world Treatment
 Optimization Applications
Authors: Milashini Nambiar and Supriyo Ghosh and Priscilla Ong and Yu En Chan
 and Yong Mong Bee and Pavitra Krishnaswamy
Categories: cs.LG
\\ ( https://arxiv.org/abs/2302.07549 ,  103kb)
------------------------------------------------------------------------------
\\
arXiv:2302.12902
replaced with revised version Tue, 13 Jun 2023 15:16:55 GMT   (4845kb,D)

Title: The Dormant Neuron Phenomenon in Deep Reinforcement Learning
Authors: Ghada Sokar, Rishabh Agarwal, Pablo Samuel Castro, Utku Evci
Categories: cs.LG
Comments: Oral at ICML 2023
\\ ( https://arxiv.org/abs/2302.12902 ,  4845kb)
------------------------------------------------------------------------------
\\
arXiv:2303.01179
replaced with revised version Tue, 13 Jun 2023 13:24:53 GMT   (633kb,D)

Title: SHAP-IQ: Unified Approximation of any-order Shapley Interactions
Authors: Fabian Fumagalli, Maximilian Muschalik, Patrick Kolpaczki, Eyke
 H\"ullermeier, Barbara Hammer
Categories: cs.LG cs.AI
\\ ( https://arxiv.org/abs/2303.01179 ,  633kb)
------------------------------------------------------------------------------
\\
arXiv:2303.09289
replaced with revised version Tue, 13 Jun 2023 15:00:53 GMT   (9755kb,D)

Title: Class Attribute Inference Attacks: Inferring Sensitive Class Information
 by Diffusion-Based Attribute Manipulations
Authors: Lukas Struppek, Dominik Hintersdorf, Felix Friedrich, Manuel Brack,
 Patrick Schramowski, Kristian Kersting
Categories: cs.LG cs.CR cs.CV
Comments: 46 pages, 37 figures, 5 tables
\\ ( https://arxiv.org/abs/2303.09289 ,  9755kb)
------------------------------------------------------------------------------
\\
arXiv:2304.03279
replaced with revised version Tue, 13 Jun 2023 01:01:42 GMT   (798kb,D)

Title: Do the Rewards Justify the Means? Measuring Trade-Offs Between Rewards
 and Ethical Behavior in the MACHIAVELLI Benchmark
Authors: Alexander Pan, Jun Shern Chan, Andy Zou, Nathaniel Li, Steven Basart,
 Thomas Woodside, Jonathan Ng, Hanlin Zhang, Scott Emmons, Dan Hendrycks
Categories: cs.LG cs.AI cs.CL cs.CY
Comments: ICML 2023 Oral (camera-ready); 31 pages, 5 figures
\\ ( https://arxiv.org/abs/2304.03279 ,  798kb)
------------------------------------------------------------------------------
\\
arXiv:2304.11042
replaced with revised version Mon, 12 Jun 2023 18:24:02 GMT   (31524kb,D)

Title: Backpropagation-free Training of Deep Physical Neural Networks
Authors: Ali Momeni, Babak Rahmani, Matthieu Mallejac, Philipp Del Hougne, and
 Romain Fleury
Categories: cs.LG cs.NE physics.app-ph physics.optics
Comments: 44 pages, 12 figures
\\ ( https://arxiv.org/abs/2304.11042 ,  31524kb)
------------------------------------------------------------------------------
\\
arXiv:2305.02691
replaced with revised version Tue, 13 Jun 2023 04:10:29 GMT   (899kb)

Title: PGB: A PubMed Graph Benchmark for Heterogeneous Network Representation
 Learning
Authors: Eric W Lee, Joyce C Ho
Categories: cs.LG cs.SI
\\ ( https://arxiv.org/abs/2305.02691 ,  899kb)
------------------------------------------------------------------------------
\\
arXiv:2305.05374
replaced with revised version Tue, 13 Jun 2023 02:50:12 GMT   (2788kb,D)

Title: HybridNet: Dual-Branch Fusion of Geometrical and Topological Views for
 VLSI Congestion Prediction
Authors: Yuxiang Zhao, Zhuomin Chai, Yibo Lin, Runsheng Wang, Ru Huang
Categories: cs.LG cs.AI
Journal-ref: 2023 IEEE International Symposium of EDA
\\ ( https://arxiv.org/abs/2305.05374 ,  2788kb)
------------------------------------------------------------------------------
\\
arXiv:2305.10769
replaced with revised version Tue, 13 Jun 2023 08:00:49 GMT   (16990kb,D)

Title: Catch-Up Distillation: You Only Need to Train Once for Accelerating
 Sampling
Authors: Shitong Shao, Xu Dai, Shouyi Yin, Lujun Li, Huanran Chen, Yang Hu
Categories: cs.LG cs.CV
\\ ( https://arxiv.org/abs/2305.10769 ,  16990kb)
------------------------------------------------------------------------------
\\
arXiv:2305.10898
replaced with revised version Tue, 13 Jun 2023 12:35:33 GMT   (1892kb,D)

Title: Estimation Beyond Data Reweighting: Kernel Method of Moments
Authors: Heiner Kremer, Yassine Nemmour, Bernhard Sch\"olkopf, Jia-Jie Zhu
Categories: cs.LG stat.ML
\\ ( https://arxiv.org/abs/2305.10898 ,  1892kb)
------------------------------------------------------------------------------
\\
arXiv:2305.14067
replaced with revised version Mon, 12 Jun 2023 18:55:40 GMT   (654kb,D)

Title: DIVA: A Dirichlet Process Based Incremental Deep Clustering Algorithm
 via Variational Auto-Encoder
Authors: Zhenshan Bing, Yuan Meng, Yuqi Yun, Hang Su, Xiaojie Su, Kai Huang,
 Alois Knoll
Categories: cs.LG stat.ML
Comments: update supplementary materials
\\ ( https://arxiv.org/abs/2305.14067 ,  654kb)
------------------------------------------------------------------------------
\\
arXiv:2306.01460
replaced with revised version Mon, 12 Jun 2023 18:49:29 GMT   (10070kb,D)

Title: ReLU to the Rescue: Improve Your On-Policy Actor-Critic with Positive
 Advantages
Authors: Andrew Jesson and Chris Lu and Gunshi Gupta and Angelos Filos and
 Jakob Nicolaus Foerster and Yarin Gal
Categories: cs.LG
\\ ( https://arxiv.org/abs/2306.01460 ,  10070kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04489
replaced with revised version Tue, 13 Jun 2023 10:19:13 GMT   (284kb,D)

Title: Fair Column Subset Selection
Authors: Antonis Matakos, Bruno Ordozgoiti, Suhas Thejaswi
Categories: cs.LG
\\ ( https://arxiv.org/abs/2306.04489 ,  284kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05035
replaced with revised version Tue, 13 Jun 2023 03:59:26 GMT   (1412kb,D)

Title: Does Long-Term Series Forecasting Need Complex Attention and Extra Long
 Inputs?
Authors: Daojun Liang, Haixia Zhang, Dongfeng Yuan, Xiaoyan Ma, Dongyang Li and
 Minggao Zhang
Categories: cs.LG
Comments: Under Review
\\ ( https://arxiv.org/abs/2306.05035 ,  1412kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05172
replaced with revised version Tue, 13 Jun 2023 13:41:43 GMT   (506kb,D)

Title: FLEdge: Benchmarking Federated Machine Learning Applications in Edge
 Computing Systems
Authors: Herbert Woisetschl\"ager, Alexander Isenko, Ruben Mayer, Hans-Arno
 Jacobsen
Categories: cs.LG cs.DC
Comments: Preprint. Under Review
ACM-class: I.2.11; C.2.4; C.4; D.2.8
\\ ( https://arxiv.org/abs/2306.05172 ,  506kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05189
replaced with revised version Tue, 13 Jun 2023 06:39:25 GMT   (2119kb,D)

Title: EMO: Episodic Memory Optimization for Few-Shot Meta-Learning
Authors: Yingjun Du, Jiayi Shen, Xiantong Zhen, Cees G.M. Snoek
Categories: cs.LG
Comments: Accepted by CoLLAs 2023
\\ ( https://arxiv.org/abs/2306.05189 ,  2119kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05785
replaced with revised version Tue, 13 Jun 2023 06:41:47 GMT   (465kb,D)

Title: End-to-End Neural Network Compression via $\frac{\ell_1}{\ell_2}$
 Regularized Latency Surrogates
Authors: Anshul Nasery, Hardik Shah, Arun Sai Suggala, Prateek Jain
Categories: cs.LG
\\ ( https://arxiv.org/abs/2306.05785 ,  465kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06193
replaced with revised version Tue, 13 Jun 2023 02:04:21 GMT   (8526kb,D)

Title: Consistent Explanations in the Face of Model Indeterminacy via
 Ensembling
Authors: Dan Ley, Leonard Tang, Matthew Nazari, Hongjin Lin, Suraj Srinivas,
 Himabindu Lakkaraju
Categories: cs.LG cs.AI cs.CY
\\ ( https://arxiv.org/abs/2306.06193 ,  8526kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06473
replaced with revised version Tue, 13 Jun 2023 05:23:19 GMT   (818kb,D)

Title: Interpretable Differencing of Machine Learning Models
Authors: Swagatam Haldar, Diptikalyan Saha, Dennis Wei, Rahul Nair, Elizabeth
 M. Daly
Categories: cs.LG
Comments: UAI 2023
\\ ( https://arxiv.org/abs/2306.06473 ,  818kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06777
replaced with revised version Tue, 13 Jun 2023 15:37:00 GMT   (619kb,D)

Title: Improving the Validity of Decision Trees as Explanations
Authors: Jiri Nemecek and Tomas Pevny and Jakub Marecek
Categories: cs.LG cs.AI math.OC
\\ ( https://arxiv.org/abs/2306.06777 ,  619kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07188
replaced with revised version Tue, 13 Jun 2023 15:08:01 GMT   (2637kb,D)

Title: Fair Learning to Rank with Distribution-free Risk Control
Authors: Ruocheng Guo, Jean-Fran\c{c}ois Ton, Yang Liu
Categories: cs.LG cs.CY cs.IR
Comments: 13 pages, 4 figures
\\ ( https://arxiv.org/abs/2306.07188 ,  2637kb)
------------------------------------------------------------------------------
\\
arXiv:2207.00710
replaced with revised version Mon, 12 Jun 2023 20:11:12 GMT   (41kb)

Title: Separating and Collapsing Electoral Control Types
Authors: Benjamin Carleton, Michael C. Chavrimootoo, Lane A. Hemaspaandra,
 David E. Narv\'aez, Conor Taliancich, Henry B. Welles
Categories: cs.MA cs.GT
Comments: The arXiv.org metadata abstract is an abridged version; please see
 the paper for the full abstract
ACM-class: I.2.11
\\ ( https://arxiv.org/abs/2207.00710 ,  41kb)
------------------------------------------------------------------------------
\\
arXiv:2209.08812
replaced with revised version Mon, 12 Jun 2023 21:32:58 GMT   (35929kb,D)

Title: Generative Graphical Inverse Kinematics
Authors: Oliver Limoyo, Filip Mari\'c, Matthew Giamou, Petra Alexson, Ivan
 Petrovi\'c, Jonathan Kelly
Categories: cs.RO
Comments: Submitted to IEEE Transactions on Robotics, June 2023
\\ ( https://arxiv.org/abs/2209.08812 ,  35929kb)
------------------------------------------------------------------------------
\\
arXiv:2212.12196
replaced with revised version Mon, 12 Jun 2023 20:21:27 GMT   (3725kb,D)

Title: A Manipulator-Assisted Multiple UAV Landing System for USV Subject to
 Disturbance
Authors: Ruoyu Xu, Chongfeng Liu, Zhongzhong Cao, Yuquan Wang and Huihuan Qian
Categories: cs.RO
\\ ( https://arxiv.org/abs/2212.12196 ,  3725kb)
------------------------------------------------------------------------------
\\
arXiv:2304.14391
replaced with revised version Mon, 12 Jun 2023 21:13:45 GMT   (7001kb,D)

Title: Energy-based Models are Zero-Shot Planners for Compositional Scene
 Rearrangement
Authors: Nikolaos Gkanatsios, Ayush Jain, Zhou Xian, Yunchu Zhang, Christopher
 Atkeson, Katerina Fragkiadaki
Categories: cs.RO cs.AI cs.CL cs.CV cs.LG
Comments: First two authors contributed equally | RSS 2023
\\ ( https://arxiv.org/abs/2304.14391 ,  7001kb)
------------------------------------------------------------------------------
\\
arXiv:2209.15090
replaced with revised version Tue, 13 Jun 2023 17:38:20 GMT   (653kb,D)

Title: Enforcing Hard Constraints with Soft Barriers: Safe Reinforcement
 Learning in Unknown Stochastic Environments
Authors: Yixuan Wang, Simon Sinong Zhan, Ruochen Jiao, Zhilu Wang, Wanxin Jin,
 Zhuoran Yang, Zhaoran Wang, Chao Huang, Qi Zhu
Categories: eess.SY cs.LG cs.SY
Comments: Accepted to ICML 2023
\\ ( https://arxiv.org/abs/2209.15090 ,  653kb)
------------------------------------------------------------------------------
\\
arXiv:2212.01756
replaced with revised version Mon, 12 Jun 2023 22:45:51 GMT   (5409kb,D)

Title: Connected Cruise and Traffic Control for Pairs of Connected Automated
 Vehicles
Authors: Sicong Guo, Gabor Orosz, Tamas G. Molnar
Categories: eess.SY cs.RO cs.SY math.DS
Comments: Accepted to the IEEE Transactions on Intelligent Transportation
 Systems. 11 pages, 10 figures
\\ ( https://arxiv.org/abs/2212.01756 ,  5409kb)
------------------------------------------------------------------------------
\\
arXiv:2305.02934
replaced with revised version Tue, 13 Jun 2023 17:34:10 GMT   (204kb)

Title: Switched max-plus linear-dual inequalities: cycle time analysis and
 applications
Authors: Davide Zorzenon, Jan Komenda, J\"org Raisch
Categories: eess.SY cs.DM cs.SY
Comments: 49 pages, 17 figures, journal paper, fixed typo in Remark 3, fixed
 formulas in Remarks 3 and 4
\\ ( https://arxiv.org/abs/2305.02934 ,  204kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04782
replaced with revised version Tue, 13 Jun 2023 08:44:29 GMT   (1165kb,D)

Title: Traction and Stability Control using Fuzzy-based Controller Integration
 for Electric Vehicles
Authors: Nimantha Dasanayake and Shehara Perera
Categories: eess.SY cs.SY
Comments: 10 pages, 11 figures, journal
\\ ( https://arxiv.org/abs/2306.04782 ,  1165kb)
------------------------------------------------------------------------------
\\
arXiv:2206.06744
replaced with revised version Tue, 13 Jun 2023 12:01:17 GMT   (70kb,D)

Title: Counting Markov Equivalent Directed Acyclic Graphs Consistent with
 Background Knowledge
Authors: Vidya Sagar Sharma
Categories: cs.DS cs.AI cs.CC cs.DM cs.LG
Comments: 24 pages, 1 figure, and 2 tables
Journal-ref: 39th Conference on Uncertainty in Artificial Intelligence
 (UAI-2023)
\\ ( https://arxiv.org/abs/2206.06744 ,  70kb)
------------------------------------------------------------------------------
\\
arXiv:2208.08232
replaced with revised version Mon, 12 Jun 2023 19:29:41 GMT   (6212kb,D)

Title: HELP ME THINK: A Simple Prompting Strategy for Non-experts to Create
 Customized Content with Models
Authors: Swaroop Mishra and Elnaz Nouri
Categories: cs.CL cs.AI cs.CV cs.HC cs.LG
Comments: ACL 2023 Findings
\\ ( https://arxiv.org/abs/2208.08232 ,  6212kb)
------------------------------------------------------------------------------
\\
arXiv:2210.16494
replaced with revised version Tue, 13 Jun 2023 17:45:30 GMT   (9427kb,D)

Title: Aligning Offline Metrics and Human Judgments of Value for Code
 Generation Models
Authors: Victor Dibia, Adam Fourney, Gagan Bansal, Forough Poursabzi-Sangdeh,
 Han Liu and Saleema Amershi
Categories: cs.SE cs.AI cs.HC cs.PL
Comments: Accepted at ACL 2023 (Findings)
\\ ( https://arxiv.org/abs/2210.16494 ,  9427kb)
------------------------------------------------------------------------------
\\
arXiv:2211.03933
replaced with revised version Tue, 13 Jun 2023 09:14:39 GMT   (5145kb,D)

Title: A Hypergraph-Based Machine Learning Ensemble Network Intrusion Detection
 System
Authors: Zong-Zhi Lin, Thomas D. Pike, Mark M. Bailey, Nathaniel D. Bastian
Categories: cs.CR cs.AI cs.SY eess.SY stat.ME stat.ML
Comments: This work has been submitted to the IEEE for possible publication.
 Copyright may be transferred without notice, after which this version may no
 longer be accessible
\\ ( https://arxiv.org/abs/2211.03933 ,  5145kb)
------------------------------------------------------------------------------
\\
arXiv:2212.10071
replaced with revised version Tue, 13 Jun 2023 10:55:29 GMT   (6883kb,D)

Title: Large Language Models Are Reasoning Teachers
Authors: Namgyu Ho, Laura Schmid, and Se-Young Yun
Categories: cs.CL cs.AI cs.LG
Comments: ACL 2023 camera-ready
\\ ( https://arxiv.org/abs/2212.10071 ,  6883kb)
------------------------------------------------------------------------------
\\
arXiv:2302.06584
replaced with revised version Tue, 13 Jun 2023 17:35:52 GMT   (4868kb,D)

Title: Thermodynamic AI and the fluctuation frontier
Authors: Patrick J. Coles, Collin Szczepanski, Denis Melanson, Kaelan
 Donatella, Antonio J. Martinez, Faris Sbahi
Categories: cs.ET cs.AI quant-ph
Comments: 47 pages, 18 figures, Updated authors
\\ ( https://arxiv.org/abs/2302.06584 ,  4868kb)
------------------------------------------------------------------------------
\\
arXiv:2304.02721
replaced with revised version Mon, 12 Jun 2023 21:13:14 GMT   (6993kb,D)

Title: To Asymmetry and Beyond: Structured Pruning of Sequence to Sequence
 Models for Improved Inference Efficiency
Authors: Daniel Campos, ChengXiang Zhai
Categories: cs.CL cs.AI
Comments: SustaiNLP2023 @ ACL 2023,9 pages, 6 figures, 33 tables
\\ ( https://arxiv.org/abs/2304.02721 ,  6993kb)
------------------------------------------------------------------------------
\\
arXiv:2305.02231
replaced with revised version Mon, 12 Jun 2023 21:07:11 GMT   (1626kb,D)

Title: Connecting the Dots in Trustworthy Artificial Intelligence: From AI
 Principles, Ethics, and Key Requirements to Responsible AI Systems and
 Regulation
Authors: Natalia D\'iaz-Rodr\'iguez, Javier Del Ser, Mark Coeckelbergh, Marcos
 L\'opez de Prado, Enrique Herrera-Viedma, Francisco Herrera
Categories: cs.CY cs.AI cs.LG
Comments: 30 pages, 5 figures, under second review
MSC-class: 68T01
ACM-class: I.2; K.4; K.5
\\ ( https://arxiv.org/abs/2305.02231 ,  1626kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06662
replaced with revised version Tue, 13 Jun 2023 13:47:15 GMT   (198kb,D)

Title: EaSyGuide : ESG Issue Identification Framework leveraging Abilities of
 Generative Large Language Models
Authors: Hanwool Lee, Jonghyun Choi, Sohyeon Kwon, Sungbum Jung
Categories: cs.CL cs.AI
Comments: Accepted at The IJCAI-2023 Workshop On Financial Technology and
 Natural Language Processing (FinNLP)
\\ ( https://arxiv.org/abs/2306.06662 ,  198kb)
------------------------------------------------------------------------------
\\
arXiv:2201.08279
replaced with revised version Tue, 13 Jun 2023 07:50:50 GMT   (21511kb,D)

Title: Modeling and hexahedral meshing of cerebral arterial networks from
 centerlines
Authors: M\'eghane Decroocq, Carole Frindel, Pierre Roug\'e, Makoto Ohta and
 Guillaume Lavou\'e
Categories: cs.CG cs.CV
\\ ( https://arxiv.org/abs/2201.08279 ,  21511kb)
------------------------------------------------------------------------------
\\
arXiv:2302.03791 (*cross-listing*)
replaced with revised version Tue, 13 Jun 2023 14:40:26 GMT   (9969kb,D)

Title: How to Trust Your Diffusion Model: A Convex Optimization Approach to
 Conformal Risk Control
Authors: Jacopo Teneggi, Matthew Tivnan, J. Webster Stayman, Jeremias Sulam
Categories: stat.ML cs.CV cs.LG
\\ ( https://arxiv.org/abs/2302.03791 ,  9969kb)
------------------------------------------------------------------------------
\\
arXiv:2305.02549
replaced with revised version Tue, 13 Jun 2023 04:27:14 GMT   (1547kb,D)

Title: FormNetV2: Multimodal Graph Contrastive Learning for Form Document
 Information Extraction
Authors: Chen-Yu Lee, Chun-Liang Li, Hao Zhang, Timothy Dozat, Vincent Perot,
 Guolong Su, Xiang Zhang, Kihyuk Sohn, Nikolai Glushnev, Renshen Wang, Joshua
 Ainslie, Shangbang Long, Siyang Qin, Yasuhisa Fujii, Nan Hua, Tomas Pfister
Categories: cs.CL cs.CV cs.LG
Comments: Accepted to ACL 2023
\\ ( https://arxiv.org/abs/2305.02549 ,  1547kb)
------------------------------------------------------------------------------
\\
arXiv:2305.14839
replaced with revised version Tue, 13 Jun 2023 06:31:46 GMT   (11082kb,D)

Title: PaCE: Unified Multi-modal Dialogue Pre-training with Progressive and
 Compositional Experts
Authors: Yunshui Li, Binyuan Hui, ZhiChao Yin, Min Yang, Fei Huang and Yongbin
 Li
Categories: cs.CL cs.CV
Comments: ACL 2023
\\ ( https://arxiv.org/abs/2305.14839 ,  11082kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06874
replaced with revised version Tue, 13 Jun 2023 03:30:21 GMT   (7853kb,D)

Title: VillanDiffusion: A Unified Backdoor Attack Framework for Diffusion
 Models
Authors: Sheng-Yen Chou, Pin-Yu Chen, Tsung-Yi Ho
Categories: cs.CR cs.CV cs.LG
\\ ( https://arxiv.org/abs/2306.06874 ,  7853kb)
------------------------------------------------------------------------------
\\
arXiv:1803.07890
replaced with revised version Mon, 12 Jun 2023 20:43:01 GMT   (1682kb,D)

Title: Multiple Models for Recommending Temporal Aspects of Entities
Authors: Tu Nguyen, Nattiya Kanhabua, Wolfgang Nejdl
Categories: cs.IR cs.LG
Comments: In proceedings of the 15th Extended Semantic Web Conference (ESWC
 2018)
\\ ( https://arxiv.org/abs/1803.07890 ,  1682kb)
------------------------------------------------------------------------------
\\
arXiv:1808.08316
replaced with revised version Mon, 12 Jun 2023 20:49:49 GMT   (1417kb,D)

Title: A Trio Neural Model for Dynamic Entity Relatedness Ranking
Authors: Tu Nguyen, Tuan Tran and Wolfgang Nejdl
Categories: cs.IR cs.CL cs.LG stat.ML
Comments: In Proceedings of CoNLL 2018
\\ ( https://arxiv.org/abs/1808.08316 ,  1417kb)
------------------------------------------------------------------------------
\\
arXiv:2110.01729 (*cross-listing*)
replaced with revised version Tue, 13 Jun 2023 15:22:04 GMT   (1860kb,D)

Title: Stochastic coordinate transformations with applications to robust
 machine learning
Authors: Julio Enrique Castrillon-Candas, Dingning Liu, Sicheng Yang, Mark Kon
Categories: stat.ML cs.LG
MSC-class: 62R10, 60G35, 62-08, 60G60, 65F25, 46B09
\\ ( https://arxiv.org/abs/2110.01729 ,  1860kb)
------------------------------------------------------------------------------
\\
arXiv:2110.03310 (*cross-listing*)
replaced with revised version Tue, 13 Jun 2023 10:10:54 GMT   (1520kb,D)

Title: Solving the Dirichlet problem for the Monge-Amp\`ere equation using
 neural networks
Authors: Kaj Nystr\"om, Matias Vestberg
Categories: stat.ML cs.LG cs.NA math.NA
Comments: 33 pages, 13 figures, 6 tables
MSC-class: 35J96, 65N99, 68T07
\\ ( https://arxiv.org/abs/2110.03310 ,  1520kb)
------------------------------------------------------------------------------
\\
arXiv:2204.11206 (*cross-listing*)
replaced with revised version Mon, 12 Jun 2023 20:59:08 GMT   (3363kb,D)

Title: Partial Identification of Dose Responses with Hidden Confounders
Authors: Myrl G. Marmarelis, Elizabeth Haddad, Andrew Jesson, Neda Jahanshad,
 Aram Galstyan, Greg Ver Steeg
Categories: stat.ME cs.LG stat.ML
\\ ( https://arxiv.org/abs/2204.11206 ,  3363kb)
------------------------------------------------------------------------------
\\
arXiv:2208.05830 (*cross-listing*)
replaced with revised version Tue, 13 Jun 2023 11:30:34 GMT   (3449kb,D)

Title: Speech Enhancement and Dereverberation with Diffusion-based Generative
 Models
Authors: Julius Richter, Simon Welker, Jean-Marie Lemercier, Bunlong Lay, Timo
 Gerkmann
Categories: eess.AS cs.LG cs.SD
Comments: Accepted version
\\ ( https://arxiv.org/abs/2208.05830 ,  3449kb)
------------------------------------------------------------------------------
\\
arXiv:2209.15449 (*cross-listing*)
replaced with revised version Tue, 13 Jun 2023 08:55:11 GMT   (12243kb,D)

Title: End-to-End Label Uncertainty Modeling in Speech Emotion Recognition
 using Bayesian Neural Networks and Label Distribution Learning
Authors: Navin Raj Prabhu, Nale Lehmann-Willenbrock and Timo Gerkman
Categories: eess.AS cs.LG
Comments: Accepted Paper at IEEE Transactions on Affective Computing, June
 2023. Contains main paper with supplementary material. arXiv admin note: text
 overlap with arXiv:2207.12135
Journal-ref: IEEE Transactions on Affective Computing, June 2023
DOI: 10.1109/TAFFC.2023.3283595
\\ ( https://arxiv.org/abs/2209.15449 ,  12243kb)
------------------------------------------------------------------------------
\\
arXiv:2210.02129 (*cross-listing*)
replaced with revised version Tue, 13 Jun 2023 05:04:17 GMT   (204kb,D)

Title: Decentralized Hyper-Gradient Computation over Time-Varying Directed
 Networks
Authors: Naoyuki Terashita, Satoshi Hara
Categories: stat.ML cs.LG
Comments: Under review
\\ ( https://arxiv.org/abs/2210.02129 ,  204kb)
------------------------------------------------------------------------------
\\
arXiv:2210.15009
replaced with revised version Mon, 12 Jun 2023 19:02:30 GMT   (519kb,D)

Title: Hypergraph Artificial Benchmark for Community Detection (h-ABCD)
Authors: Bogumi{\l} Kami\'nski, Pawe{\l} Pra{\l}at, Fran\c{c}ois Th\'eberge
Categories: cs.SI cs.LG math.CO
Comments: 23 pages, 6 figures, 7 tables
ACM-class: I.6.5; G.4
\\ ( https://arxiv.org/abs/2210.15009 ,  519kb)
------------------------------------------------------------------------------
\\
arXiv:2210.17376
replaced with revised version Tue, 13 Jun 2023 00:19:59 GMT   (1222kb,D)

Title: SoK: Modeling Explainability in Security Analytics for Interpretability,
 Trustworthiness, and Usability
Authors: Dipkamal Bhusal, Rosalyn Shin, Ajay Ashok Shewale, Monish Kumar
 Manikya Veerabhadran, Michael Clifford, Sara Rampazzi, Nidhi Rastogi
Categories: cs.CR cs.LG
Comments: 12 pages, 4 figures
DOI: 10.1145/3600160.3600193
\\ ( https://arxiv.org/abs/2210.17376 ,  1222kb)
------------------------------------------------------------------------------
\\
arXiv:2211.14555 (*cross-listing*)
replaced with revised version Tue, 13 Jun 2023 12:31:35 GMT   (406kb,D)

Title: Distribution Free Prediction Sets for Node Classification
Authors: Jase Clarkson
Categories: stat.ML cs.LG
Comments: To appear at ICML 2023
\\ ( https://arxiv.org/abs/2211.14555 ,  406kb)
------------------------------------------------------------------------------
\\
arXiv:2211.16583 (*cross-listing*)
replaced with revised version Mon, 12 Jun 2023 20:19:02 GMT   (1284kb,D)

Title: Offline Policy Evaluation and Optimization under Confounding
Authors: Chinmaya Kausik, Yangyi Lu, Kevin Tan, Yixin Wang, Ambuj Tewari
Categories: stat.ML cs.LG
\\ ( https://arxiv.org/abs/2211.16583 ,  1284kb)
------------------------------------------------------------------------------
\\
arXiv:2301.05749
replaced with revised version Mon, 12 Jun 2023 18:43:35 GMT   (164kb,D)

Title: Artificial Benchmark for Community Detection with Outliers (ABCD+o)
Authors: Bogumi{\l} Kami\'nski, Pawe{\l} Pra{\l}at, Fran\c{c}ois Th\'eberge
Categories: cs.SI cs.LG math.CO
Comments: 19 pages, 13 figures
ACM-class: I.6.5; G.4
Journal-ref: Kami\'nski, B., Pra{\l}at, P. & Th\'eberge, F. Artificial
 benchmark for community detection with outliers (ABCD+o). Appl Netw Sci 8, 25
 (2023)
DOI: 10.1007/s41109-023-00552-9
\\ ( https://arxiv.org/abs/2301.05749 ,  164kb)
------------------------------------------------------------------------------
\\
arXiv:2301.05955 (*cross-listing*)
replaced with revised version Tue, 13 Jun 2023 16:03:00 GMT   (1229kb,D)

Title: Hand Gesture Recognition through Reflected Infrared Light Wave Signals
Authors: Md Zobaer Islam, Li Yu, Hisham Abuella, John F. O'Hara, Christopher
 Crick, Sabit Ekin
Categories: eess.SP cs.HC cs.LG
Comments: 5 pages, 6 figures, 2 tables, Accepted, presented and camera-ready
 version submitted at ICEEE 2023 at Istanbul, Turkey. arXiv admin note:
 substantial text overlap with arXiv:2007.08178
\\ ( https://arxiv.org/abs/2301.05955 ,  1229kb)
------------------------------------------------------------------------------
\\
arXiv:2302.06869 (*cross-listing*)
replaced with revised version Tue, 13 Jun 2023 01:19:50 GMT   (28kb,D)

Title: Concentration Bounds for Discrete Distribution Estimation in KL
 Divergence
Authors: Cl\'ement L. Canonne and Ziteng Sun and Ananda Theertha Suresh
Categories: stat.ML cs.DM cs.IT cs.LG math.IT math.PR
Comments: Updated discussion of previous work
\\ ( https://arxiv.org/abs/2302.06869 ,  28kb)
------------------------------------------------------------------------------
\\
arXiv:2303.12814 (*cross-listing*)
replaced with revised version Tue, 13 Jun 2023 13:01:26 GMT   (83kb,D)

Title: Fixed points of arbitrarily deep 1-dimensional neural networks
Authors: Andrew Cook, Andy Hammerlindl and Warwick Tucker
Categories: stat.ML cs.LG math.DS
Comments: 9 pages, 3 figures
MSC-class: 37E99 (Primary) 37N99 (Secondary)
\\ ( https://arxiv.org/abs/2303.12814 ,  83kb)
------------------------------------------------------------------------------
\\
arXiv:2304.02370 (*cross-listing*)
replaced with revised version Tue, 13 Jun 2023 08:55:45 GMT   (3161kb,D)

Title: Effective control of two-dimensional Rayleigh--B\'enard convection:
 invariant multi-agent reinforcement learning is all you need
Authors: Colin Vignon, Jean Rabault, Joel Vasanth, Francisco
 Alc\'antara-\'Avila, Mikael Mortensen, Ricardo Vinuesa
Categories: physics.flu-dyn cs.LG
Comments: 34 pages, 11 figures submitted to Physics of Fluids
\\ ( https://arxiv.org/abs/2304.02370 ,  3161kb)
------------------------------------------------------------------------------
\\
arXiv:2304.05444
replaced with revised version Tue, 13 Jun 2023 17:37:27 GMT   (9817kb,D)

Title: Collaborative Machine Learning Model Building with Families Using Co-ML
Authors: Tiffany Tseng, Jennifer King Chen, Mona Abdelrahman, Mary Beth Kery,
 Fred Hohman, Adriana Hilliard, R. Benjamin Shapiro
Categories: cs.HC cs.LG
Comments: Proceedings of the 2023 IDC Conference
\\ ( https://arxiv.org/abs/2304.05444 ,  9817kb)
------------------------------------------------------------------------------
\\
arXiv:2304.10382 (*cross-listing*)
replaced with revised version Tue, 13 Jun 2023 11:49:47 GMT   (1261kb,D)

Title: Conditional Generative Models for Learning Stochastic Processes
Authors: Salvatore Certo, Anh Pham, Nicolas Robles, Andrew Vlasic
Categories: quant-ph cond-mat.mtrl-sci cs.LG q-fin.CP
\\ ( https://arxiv.org/abs/2304.10382 ,  1261kb)
------------------------------------------------------------------------------
\\
arXiv:2305.04891
replaced with revised version Tue, 13 Jun 2023 09:17:04 GMT   (4349kb,D)

Title: DELTA: Dynamic Embedding Learning with Truncated Conscious Attention for
 CTR Prediction
Authors: Chen Zhu, Liang Du, Hong Chen, Shuang Zhao, Zixun Sun, Xin Wang, Wenwu
 Zhu
Categories: cs.IR cs.LG
\\ ( https://arxiv.org/abs/2305.04891 ,  4349kb)
------------------------------------------------------------------------------
\\
arXiv:2305.06378 (*cross-listing*)
replaced with revised version Mon, 12 Jun 2023 18:51:09 GMT   (6559kb,D)

Title: Discovery of Optimal Quantum Error Correcting Codes via Reinforcement
 Learning
Authors: Vincent Paul Su, ChunJun Cao, Hong-Ye Hu, Yariv Yanay, Charles Tahan,
 Brian Swingle
Categories: quant-ph cs.LG
Comments: 10 pages + appendices; v2 figure updated and note added
\\ ( https://arxiv.org/abs/2305.06378 ,  6559kb)
------------------------------------------------------------------------------
\\
arXiv:2305.19395
replaced with revised version Tue, 13 Jun 2023 05:14:45 GMT   (2934kb,D)

Title: DyGen: Learning from Noisy Labels via Dynamics-Enhanced Generative
 Modeling
Authors: Yuchen Zhuang, Yue Yu, Lingkai Kong, Xiang Chen, Chao Zhang
Categories: cs.CL cs.LG
Comments: Accepted by KDD 2023 research track
DOI: 10.1145/3580305.3599318
\\ ( https://arxiv.org/abs/2305.19395 ,  2934kb)
------------------------------------------------------------------------------
\\
arXiv:2306.01751
replaced with revised version Tue, 13 Jun 2023 10:08:10 GMT   (10681kb)

Title: Differential Privacy with Random Projections and Sign Random Projections
Authors: Ping Li and Xiaoyun Li
Categories: cs.CR cs.LG stat.ML
\\ ( https://arxiv.org/abs/2306.01751 ,  10681kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04528
replaced with revised version Tue, 13 Jun 2023 12:44:10 GMT   (426kb,D)

Title: PromptBench: Towards Evaluating the Robustness of Large Language Models
 on Adversarial Prompts
Authors: Kaijie Zhu, Jindong Wang, Jiaheng Zhou, Zichen Wang, Hao Chen, Yidong
 Wang, Linyi Yang, Wei Ye, Neil Zhenqiang Gong, Yue Zhang, Xing Xie
Categories: cs.CL cs.CR cs.LG
Comments: Technical report; 23 pages; code is at:
 https://github.com/microsoft/promptbench
\\ ( https://arxiv.org/abs/2306.04528 ,  426kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04551
replaced with revised version Tue, 13 Jun 2023 17:28:34 GMT   (207kb,D)

Title: Multi-Task Training with In-Domain Language Models for Diagnostic
 Reasoning
Authors: Brihat Sharma, Yanjun Gao, Timothy Miller, Matthew M. Churpek, Majid
 Afshar and Dmitriy Dligach
Categories: cs.CL cs.LG
Comments: Accepted to the Proceedings of the 5th Clinical NLP Workshop at ACL
\\ ( https://arxiv.org/abs/2306.04551 ,  207kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06283 (*cross-listing*)
replaced with revised version Tue, 13 Jun 2023 07:44:32 GMT   (12598kb,D)

Title: 14 Examples of How LLMs Can Transform Materials Science and Chemistry: A
 Reflection on a Large Language Model Hackathon
Authors: Kevin Maik Jablonka, Qianxiang Ai, Alexander Al-Feghali, Shruti
 Badhwar, Joshua D. Bocarsly Andres M Bran, Stefan Bringuier, L. Catherine
 Brinson, Kamal Choudhary, Defne Circi, Sam Cox, Wibe A. de Jong, Matthew L.
 Evans, Nicolas Gastellu, Jerome Genzling, Mar\'ia Victoria Gil, Ankur K.
 Gupta, Zhi Hong, Alishba Imran, Sabine Kruschwitz, Anne Labarre, Jakub
 L\'ala, Tao Liu, Steven Ma, Sauradeep Majumdar, Garrett W. Merz, Nicolas
 Moitessier, Elias Moubarak, Beatriz Mouri\~no, Brenden Pelkie, Michael
 Pieler, Mayk Caldas Ramos, Bojana Rankovi\'c, Samuel G. Rodriques, Jacob N.
 Sanders, Philippe Schwaller, Marcus Schwarting, Jiale Shi, Berend Smit, Ben
 E. Smith, Joren Van Heck, Christoph V\"olker, Logan Ward, Sean Warren,
 Benjamin Weiser, Sylvester Zhang, Xiaoqi Zhang, Ghezal Ahmad Zia, Aristana
 Scourtas, KJ Schmidt, Ian Foster, Andrew D. White, Ben Blaiszik
Categories: cond-mat.mtrl-sci cs.LG physics.chem-ph
\\ ( https://arxiv.org/abs/2306.06283 ,  12598kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06819
replaced with revised version Tue, 13 Jun 2023 15:41:11 GMT   (216kb,D)

Title: Multimodal Audio-textual Architecture for Robust Spoken Language
 Understanding
Authors: Anderson R. Avila, Mehdi Rezagholizadeh, Chao Xing
Categories: cs.CL cs.LG eess.AS
\\ ( https://arxiv.org/abs/2306.06819 ,  216kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07056 (*cross-listing*)
replaced with revised version Tue, 13 Jun 2023 08:27:30 GMT   (2055kb,D)

Title: Kernel Random Projection Depth for Outlier Detection
Authors: Akira Tamamori
Categories: stat.ML cs.LG stat.AP stat.ME
Comments: submitted to APSIPA ASC 2023
\\ ( https://arxiv.org/abs/2306.07056 ,  2055kb)
------------------------------------------------------------------------------
\\
arXiv:2302.01972
replaced with revised version Tue, 13 Jun 2023 08:00:28 GMT   (24029kb,D)

Title: DCA: Delayed Charging Attack on the Electric Shared Mobility System
Authors: Shuocheng Guo and Hanlin Chen and Mizanur Rahman and Xinwu Qian
Categories: cs.CR cs.SY eess.SY math.DS math.OC physics.soc-ph
\\ ( https://arxiv.org/abs/2302.01972 ,  24029kb)
------------------------------------------------------------------------------
\\
arXiv:2303.08540 (*cross-listing*)
replaced with revised version Tue, 13 Jun 2023 13:23:09 GMT   (14232kb,D)

Title: Automatic scenario generation for efficient solution of robust optimal
 control problems
Authors: Marta Zagorowska, Paola Falugi, Edward O'Dwyer, and Eric C. Kerrigan
Categories: math.OC cs.SY eess.SY
Comments: arXiv admin note: substantial text overlap with arXiv:2204.14145
 (IFAC conference submission)
\\ ( https://arxiv.org/abs/2303.08540 ,  14232kb)
%%%---%%%---%%%---%%%---%%%---%%%---%%%---%%%---%%%---%%%---%%%---%%%---%%%---
