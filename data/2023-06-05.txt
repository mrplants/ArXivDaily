------------------------------------------------------------------------------
------------------------------------------------------------------------------
Send any comments regarding submissions directly to submitter.
------------------------------------------------------------------------------
Archives at http://arxiv.org/
To unsubscribe, e-mail To: cs@arXiv.org, Subject: cancel
------------------------------------------------------------------------------
Submissions to:
Artificial Intelligence
Computer Vision and Pattern Recognition
Computer Science and Game Theory
Machine Learning
Multiagent Systems
Robotics
Systems and Control
received from  Fri  2 Jun 23 18:00:00 GMT  to  Mon  5 Jun 23 18:00:00 GMT
------------------------------------------------------------------------------
------------------------------------------------------------------------------
\\
arXiv:2306.01744
Date: Sat, 13 May 2023 11:40:31 GMT   (129kb)

Title: Disproving XAI Myths with Formal Methods -- Initial Results
Authors: Joao Marques-Silva
Categories: cs.AI cs.LG
\\
 The advances in Machine Learning (ML) in recent years have been both
impressive and far-reaching. However, the deployment of ML models is still
impaired by a lack of trust in how the best-performing ML models make
predictions. The issue of lack of trust is even more acute in the uses of ML
models in high-risk or safety-critical domains. eXplainable artificial
intelligence (XAI) is at the core of ongoing efforts for delivering trustworthy
AI. Unfortunately, XAI is riddled with critical misconceptions, that foster
distrust instead of building trust. This paper details some of the most visible
misconceptions in XAI, and shows how formal methods have been used, both to
disprove those misconceptions, but also to devise practically effective
alternatives.
\\ ( https://arxiv.org/abs/2306.01744 ,  129kb)
------------------------------------------------------------------------------
\\
arXiv:2306.01746
Date: Tue, 16 May 2023 10:46:22 GMT   (536kb)

Title: An Application of Neutrosophic Sets to Decision Making
Authors: Michael Gr. Voskoglou
Categories: cs.AI
Comments: 9 pages, 4 tables
MSC-class: 03E72
Journal-ref: Neutrosophic Sets and Systems, 53, 1-9, 2023
\\
 Maji et al. introduced in 2002 a method of parametric decision making using
soft sets as tools and representing their tabular form as a binary matrix. In
cases, however, where some or all of the parameters used for the
characterization of the elements of the universal set are of fuzzy texture,
their method does not give always the best decision making solution. In order
to tackle this problem, we modified in earlier works the method of Maji et al.
by replacing the binary elements in the tabular form of the corresponding soft
set either by grey numbers or by triangular fuzzy numbers. In this work, in
order to tackle more efficiently cases in which the decision maker has doubts
about the correctness of the fuzzy/qualitative characterizations assigned to
some or all of the elements of the universal set, we replace the binary
elements of the tabular form by neutrosophic triplets. Our new, neutrosophic
decision making method is illustrated by an application concerning the choice
of a new player by a soccer club.
\\ ( https://arxiv.org/abs/2306.01746 ,  536kb)
------------------------------------------------------------------------------
\\
arXiv:2306.01750
Date: Sat, 20 May 2023 11:55:27 GMT   (2863kb,D)

Title: A Survey of Explainable AI and Proposal for a Discipline of Explanation
 Engineering
Authors: Clive Gomes, Lalitha Natraj, Shijun Liu, Anushka Datta
Categories: cs.AI cs.HC
\\
 In this survey paper, we deep dive into the field of Explainable Artificial
Intelligence (XAI). After introducing the scope of this paper, we start by
discussing what an "explanation" really is. We then move on to discuss some of
the existing approaches to XAI and build a taxonomy of the most popular
methods. Next, we also look at a few applications of these and other XAI
techniques in four primary domains: finance, autonomous driving, healthcare and
manufacturing. We end by introducing a promising discipline, "Explanation
Engineering," which includes a systematic approach for designing explainability
into AI systems.
\\ ( https://arxiv.org/abs/2306.01750 ,  2863kb)
------------------------------------------------------------------------------
\\
arXiv:2306.01769
Date: Sun, 28 May 2023 21:33:15 GMT   (2139kb)

Title: Towards a Technology-Driven Adaptive Decision Support System for
 Integrated Pavement and Maintenance strategies (TDADSS-IPM): focus on risk
 assessment framework for climate change adaptation
Authors: Shahrzad Pour, Amir Masoumi, Niels Skov Dujardin
Categories: cs.AI stat.AP
\\
 Decision Support Systems for pavement and maintenance strategies have
traditionally been designed as silos led to local optimum systems. Moreover,
since big data usage didn't exist as result of Industry 4.0 as of today, DSSs
were not initially designed adaptive to the sources of uncertainties led to
rigid decisions. Motivated by the vulnerability of the road assets to the
climate phenomena, this paper takes a visionary step towards introducing a
Technology-Driven Adaptive Decision Support System for Integrated Pavement and
Maintenance activities called TDADSS-IPM. As part of such DSS, a bottom-up risk
assessment model is met via Bayesian Belief Networks (BBN) to realize the
actual condition of the Danish roads due to weather condition. Such model fills
the gaps in the knowledge domain and develops a platform that can be trained
over time, and applied in real-time to the actual event.
\\ ( https://arxiv.org/abs/2306.01769 ,  2139kb)
------------------------------------------------------------------------------
\\
arXiv:2306.01771
Date: Mon, 29 May 2023 02:27:46 GMT   (6631kb,D)

Title: ProcessGPT: Transforming Business Process Management with Generative
 Artificial Intelligence
Authors: Amin Beheshti, Jian Yang, Quan Z. Sheng, Boualem Benatallah, Fabio
 Casati, Schahram Dustdar, Hamid Reza Motahari Nezhad, Xuyun Zhang, Shan Xue
Categories: cs.AI
Comments: Accepted in: 2023 IEEE International Conference on Web Services
 (ICWS); Corresponding author: Prof. Amin Beheshti (amin.beheshti@mq.edu.au)
\\
 Generative Pre-trained Transformer (GPT) is a state-of-the-art machine
learning model capable of generating human-like text through natural language
processing (NLP). GPT is trained on massive amounts of text data and uses deep
learning techniques to learn patterns and relationships within the data,
enabling it to generate coherent and contextually appropriate text. This
position paper proposes using GPT technology to generate new process models
when/if needed. We introduce ProcessGPT as a new technology that has the
potential to enhance decision-making in data-centric and knowledge-intensive
processes. ProcessGPT can be designed by training a generative pre-trained
transformer model on a large dataset of business process data. This model can
then be fine-tuned on specific process domains and trained to generate process
flows and make decisions based on context and user input. The model can be
integrated with NLP and machine learning techniques to provide insights and
recommendations for process improvement. Furthermore, the model can automate
repetitive tasks and improve process efficiency while enabling knowledge
workers to communicate analysis findings, supporting evidence, and make
decisions. ProcessGPT can revolutionize business process management (BPM) by
offering a powerful tool for process augmentation, automation and improvement.
Finally, we demonstrate how ProcessGPT can be a powerful tool for augmenting
data engineers in maintaining data ecosystem processes within large bank
organizations. Our scenario highlights the potential of this approach to
improve efficiency, reduce costs, and enhance the quality of business
operations through the automation of data-centric and knowledge-intensive
processes. These results underscore the promise of ProcessGPT as a
transformative technology for organizations looking to improve their process
workflows.
\\ ( https://arxiv.org/abs/2306.01771 ,  6631kb)
------------------------------------------------------------------------------
\\
arXiv:2306.01772
Date: Mon, 29 May 2023 06:17:58 GMT   (941kb,D)

Title: Re-imagining health and well-being in low resource African settings
 using an augmented AI system and a 3D digital twin
Authors: Deshendran Moodley and Christopher Seebregts
Categories: cs.AI
Comments: Submitted to Workshop on AI for Digital Twins and Cyber-physical
 applications at IJCAI 2023, August 19--21, 2023, Macau, S.A.R
ACM-class: I.2.0; I.2.1; J.3
\\
 In this paper, we discuss and explore the potential and relevance of recent
developments in artificial intelligence (AI) and digital twins for health and
well-being in low-resource African countries. Using an AI systems perspective,
we review emerging trends in AI systems and digital twins and propose an
initial augmented AI system architecture to illustrate how an AI system can
work in conjunction with a 3D digital twin. We highlight scientific knowledge
discovery, continual learning, pragmatic interoperability, and interactive
explanation and decision-making as important research challenges for AI systems
and digital twins.
\\ ( https://arxiv.org/abs/2306.01772 ,  941kb)
------------------------------------------------------------------------------
\\
arXiv:2306.01784
Date: Wed, 31 May 2023 10:36:16 GMT   (403kb)

Title: Evaluating GPT's Programming Capability through CodeWars' Katas
Authors: Zizhuo Zhang, Lian Wen, Shaoyang Zhang, David Chen, Yanfei Jiang
Categories: cs.AI cs.SE
Comments: 9 pages
\\
 In the burgeoning field of artificial intelligence (AI), understanding the
capabilities and limitations of programming-oriented models is crucial. This
paper presents a novel evaluation of the programming proficiency of Generative
Pretrained Transformer (GPT) models, specifically GPT-3.5 and GPT-4, against
coding problems of varying difficulty levels drawn from Codewars. The
experiments reveal a distinct boundary at the 3kyu level, beyond which these
GPT models struggle to provide solutions. These findings led to the proposal of
a measure for coding problem complexity that incorporates both problem
difficulty and the time required for solution. The research emphasizes the need
for validation and creative thinking capabilities in AI models to better
emulate human problem-solving techniques. Future work aims to refine this
proposed complexity measure, enhance AI models with these suggested
capabilities, and develop an objective measure for programming problem
difficulty. The results of this research offer invaluable insights for
improving AI programming capabilities and advancing the frontier of AI
problem-solving abilities.
\\ ( https://arxiv.org/abs/2306.01784 ,  403kb)
------------------------------------------------------------------------------
\\
arXiv:2306.01795
Date: Thu, 1 Jun 2023 12:28:08 GMT   (83kb)

Title: AI and the creative realm: A short review of current and future
 applications
Authors: Fabio Crimaldi, Manuele Leonelli
Categories: cs.AI cs.HC
\\
 This study explores the concept of creativity and artificial intelligence
(AI) and their recent integration. While AI has traditionally been perceived as
incapable of generating new ideas or creating art, the development of more
sophisticated AI models and the proliferation of human-computer interaction
tools have opened up new possibilities for AI in artistic creation. This study
investigates the various applications of AI in a creative context,
differentiating between the type of art, language, and algorithms used. It also
considers the philosophical implications of AI and creativity, questioning
whether consciousness can be researched in machines and AI's potential
interests and decision-making capabilities. Overall, we aim to stimulate a
reflection on AI's use and ethical implications in creative contexts.
\\ ( https://arxiv.org/abs/2306.01795 ,  83kb)
------------------------------------------------------------------------------
\\
arXiv:2306.01872
Date: Fri, 2 Jun 2023 19:00:17 GMT   (4934kb,D)

Title: Probabilistic Adaptation of Text-to-Video Models
Authors: Mengjiao Yang, Yilun Du, Bo Dai, Dale Schuurmans, Joshua B. Tenenbaum,
 Pieter Abbeel
Categories: cs.AI
Comments: Project website https://video-adapter.github.io/. First two authors
 contributed equally
\\
 Large text-to-video models trained on internet-scale data have demonstrated
exceptional capabilities in generating high-fidelity videos from arbitrary
textual descriptions. However, adapting these models to tasks with limited
domain-specific data, such as animation or robotics videos, poses a significant
computational challenge, since finetuning a pretrained large model can be
prohibitively expensive. Inspired by how a small modifiable component (e.g.,
prompts, prefix-tuning) can adapt a large language model to perform new tasks
without requiring access to the model weights, we investigate how to adapt a
large pretrained text-to-video model to a variety of downstream domains and
tasks without finetuning. In answering this question, we propose Video Adapter,
which leverages the score function of a large pretrained video diffusion model
as a probabilistic prior to guide the generation of a task-specific small video
model. Our experiments show that Video Adapter is capable of incorporating the
broad knowledge and preserving the high fidelity of a large pretrained video
model in a task-specific small video model that is able to generate
high-quality yet specialized videos on a variety of tasks such as animation,
egocentric modeling, and modeling of simulated and real-world robotics data.
More videos can be found on the website https://video-adapter.github.io/.
\\ ( https://arxiv.org/abs/2306.01872 ,  4934kb)
------------------------------------------------------------------------------
\\
arXiv:2306.01913
Date: Fri, 2 Jun 2023 20:38:43 GMT   (4022kb,D)

Title: PDT: Pretrained Dual Transformers for Time-aware Bipartite Graphs
Authors: Xin Dai, Yujie Fan, Zhongfang Zhuang, Shubham Jain, Chin-Chia Michael
 Yeh, Junpeng Wang, Liang Wang, Yan Zheng, Wei Zhang
Categories: cs.AI
\\
 Pre-training on large models is prevalent and emerging with the ever-growing
user-generated content in many machine learning application categories. It has
been recognized that learning contextual knowledge from the datasets depicting
user-content interaction plays a vital role in downstream tasks. Despite
several studies attempting to learn contextual knowledge via pre-training
methods, finding an optimal training objective and strategy for this type of
task remains a challenging problem. In this work, we contend that there are two
distinct aspects of contextual knowledge, namely the user-side and the
content-side, for datasets where user-content interaction can be represented as
a bipartite graph. To learn contextual knowledge, we propose a pre-training
method that learns a bi-directional mapping between the spaces of the user-side
and the content-side. We formulate the training goal as a contrastive learning
task and propose a dual-Transformer architecture to encode the contextual
knowledge. We evaluate the proposed method for the recommendation task. The
empirical studies have demonstrated that the proposed method outperformed all
the baselines with significant gains.
\\ ( https://arxiv.org/abs/2306.01913 ,  4022kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02019
Date: Sat, 3 Jun 2023 06:33:33 GMT   (732kb,D)

Title: Generative Adversarial Networks for Data Augmentation
Authors: Angona Biswas, MD Abdullah Al Nasim, Al Imran, Anika Tabassum Sejuty,
 Fabliha Fairooz, Sai Puppala, Sajedul Talukder
Categories: cs.AI
Comments: 13 pages, 6 figures, 1 table; Acceptance of the chapter for the
 Springer book "Data-driven approaches to medical imaging"
\\
 One way to expand the available dataset for training AI models in the medical
field is through the use of Generative Adversarial Networks (GANs) for data
augmentation. GANs work by employing a generator network to create new data
samples that are then assessed by a discriminator network to determine their
similarity to real samples. The discriminator network is taught to
differentiate between actual and synthetic samples, while the generator system
is trained to generate data that closely resemble real ones. The process is
repeated until the generator network can produce synthetic data that is
indistinguishable from genuine data. GANs have been utilized in medical image
analysis for various tasks, including data augmentation, image creation, and
domain adaptation. They can generate synthetic samples that can be used to
increase the available dataset, especially in cases where obtaining large
amounts of genuine data is difficult or unethical. However, it is essential to
note that the use of GANs in medical imaging is still an active area of
research to ensure that the produced images are of high quality and suitable
for use in clinical settings.
\\ ( https://arxiv.org/abs/2306.02019 ,  732kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02043
Date: Sat, 3 Jun 2023 07:51:57 GMT   (1110kb,D)

Title: Painsight: An Extendable Opinion Mining Framework for Detecting Pain
 Points Based on Online Customer Reviews
Authors: Yukyung Lee, Jaehee Kim, Doyoon Kim, Yookyung Kho, Younsun Kim,
 Pilsung Kang
Categories: cs.AI
Comments: WASSA at ACL 2023
\\
 As the e-commerce market continues to expand and online transactions
proliferate, customer reviews have emerged as a critical element in shaping the
purchasing decisions of prospective buyers. Previous studies have endeavored to
identify key aspects of customer reviews through the development of sentiment
analysis models and topic models. However, extracting specific dissatisfaction
factors remains a challenging task. In this study, we delineate the pain point
detection problem and propose Painsight, an unsupervised framework for
automatically extracting distinct dissatisfaction factors from customer reviews
without relying on ground truth labels. Painsight employs pre-trained language
models to construct sentiment analysis and topic models, leveraging attribution
scores derived from model gradients to extract dissatisfaction factors. Upon
application of the proposed methodology to customer review data spanning five
product categories, we successfully identified and categorized dissatisfaction
factors within each group, as well as isolated factors for each type. Notably,
Painsight outperformed benchmark methods, achieving substantial performance
enhancements and exceptional results in human evaluations.
\\ ( https://arxiv.org/abs/2306.02043 ,  1110kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02055
Date: Sat, 3 Jun 2023 09:05:35 GMT   (335kb,D)

Title: Case Studies on X-Ray Imaging, MRI and Nuclear Imaging
Authors: Shuvra Sarker, Angona Biswas, MD Abdullah Al Nasim, Md Shahin Ali, Sai
 Puppala, Sajedul Talukder
Categories: cs.AI
Comments: 14 pages, 3 figures, 4 tables; Acceptance of the chapter for the
 Springer book "Data-driven approaches to medical imaging"
\\
 The field of medical imaging is an essential aspect of the medical sciences,
involving various forms of radiation to capture images of the internal tissues
and organs of the body. These images provide vital information for clinical
diagnosis, and in this chapter, we will explore the use of X-ray, MRI, and
nuclear imaging in detecting severe illnesses. However, manual evaluation and
storage of these images can be a challenging and time-consuming process. To
address this issue, artificial intelligence (AI)-based techniques, particularly
deep learning (DL), have become increasingly popular for systematic feature
extraction and classification from imaging modalities, thereby aiding doctors
in making rapid and accurate diagnoses. In this review study, we will focus on
how AI-based approaches, particularly the use of Convolutional Neural Networks
(CNN), can assist in disease detection through medical imaging technology. CNN
is a commonly used approach for image analysis due to its ability to extract
features from raw input images, and as such, will be the primary area of
discussion in this study. Therefore, we have considered CNN as our discussion
area in this study to diagnose ailments using medical imaging technology.
\\ ( https://arxiv.org/abs/2306.02055 ,  335kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02071
Date: Sat, 3 Jun 2023 10:22:50 GMT   (3128kb,D)

Title: DU-Shapley: A Shapley Value Proxy for Efficient Dataset Valuation
Authors: Felipe Garrido-Lucero and Benjamin Heymann and Maxime Vono and Patrick
 Loiseau and Vianney Perchet
Categories: cs.AI cs.GT stat.CO stat.ML
Comments: 22 pages
\\
 Many machine learning problems require performing dataset valuation, i.e. to
quantify the incremental gain, to some relevant pre-defined utility, of
aggregating an individual dataset to others. As seminal examples, dataset
valuation has been leveraged in collaborative and federated learning to create
incentives for data sharing across several data owners. The Shapley value has
recently been proposed as a principled tool to achieve this goal due to formal
axiomatic justification. Since its computation often requires exponential time,
standard approximation strategies based on Monte Carlo integration have been
considered. Such generic approximation methods, however, remain expensive in
some cases. In this paper, we exploit the knowledge about the structure of the
dataset valuation problem to devise more efficient Shapley value estimators. We
propose a novel approximation of the Shapley value, referred to as discrete
uniform Shapley (DU-Shapley) which is expressed as an expectation under a
discrete uniform distribution with support of reasonable size. We justify the
relevancy of the proposed framework via asymptotic and non-asymptotic
theoretical guarantees and show that DU-Shapley tends towards the Shapley value
when the number of data owners is large. The benefits of the proposed framework
are finally illustrated on several dataset valuation benchmarks. DU-Shapley
outperforms other Shapley value approximations, even when the number of data
owners is small.
\\ ( https://arxiv.org/abs/2306.02071 ,  3128kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02165
Date: Sat, 3 Jun 2023 17:51:04 GMT   (684kb,D)

Title: Learning to Defend by Attacking (and Vice-Versa): Transfer of Learning
 in Cybersecurity Games
Authors: Tyler Malloy, Cleotilde Gonzalez
Categories: cs.AI cs.CR cs.LG
\\
 Designing cyber defense systems to account for cognitive biases in human
decision making has demonstrated significant success in improving performance
against human attackers. However, much of the attention in this area has
focused on relatively simple accounts of biases in human attackers, and little
is known about adversarial behavior or how defenses could be improved by
disrupting attacker's behavior. In this work, we present a novel model of human
decision-making inspired by the cognitive faculties of Instance-Based Learning
Theory, Theory of Mind, and Transfer of Learning. This model functions by
learning from both roles in a security scenario: defender and attacker, and by
making predictions of the opponent's beliefs, intentions, and actions. The
proposed model can better defend against attacks from a wide range of opponents
compared to alternatives that attempt to perform optimally without accounting
for human biases. Additionally, the proposed model performs better against a
range of human-like behavior by explicitly modeling human transfer of learning,
which has not yet been applied to cyber defense scenarios. Results from
simulation experiments demonstrate the potential usefulness of cognitively
inspired models of agents trained in attack and defense roles and how these
insights could potentially be used in real-world cybersecurity.
\\ ( https://arxiv.org/abs/2306.02165 ,  684kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02177
Date: Sat, 3 Jun 2023 19:11:34 GMT   (346kb,D)

Title: Towards Coding Social Science Datasets with Language Models
Authors: Christopher Michael Rytting, Taylor Sorensen, Lisa Argyle, Ethan
 Busby, Nancy Fulda, Joshua Gubler, David Wingate
Categories: cs.AI
\\
 Researchers often rely on humans to code (label, annotate, etc.) large sets
of texts. This kind of human coding forms an important part of social science
research, yet the coding process is both resource intensive and highly variable
from application to application. In some cases, efforts to automate this
process have achieved human-level accuracies, but to achieve this, these
attempts frequently rely on thousands of hand-labeled training examples, which
makes them inapplicable to small-scale research studies and costly for large
ones. Recent advances in a specific kind of artificial intelligence tool -
language models (LMs) - provide a solution to this problem. Work in computer
science makes it clear that LMs are able to classify text, without the cost (in
financial terms and human effort) of alternative methods. To demonstrate the
possibilities of LMs in this area of political science, we use GPT-3, one of
the most advanced LMs, as a synthetic coder and compare it to human coders. We
find that GPT-3 can match the performance of typical human coders and offers
benefits over other machine learning methods of coding text. We find this
across a variety of domains using very different coding procedures. This
provides exciting evidence that language models can serve as a critical advance
in the coding of open-ended texts in a variety of applications.
\\ ( https://arxiv.org/abs/2306.02177 ,  346kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02199
Date: Sat, 3 Jun 2023 21:14:59 GMT   (479kb,D)

Title: Shrinking Embeddings for Hyper-Relational Knowledge Graphs
Authors: Bo Xiong, Mojtaba Nayyer, Shirui Pan, Steffen Staab
Categories: cs.AI
Comments: To appear in ACL 2023
\\
 Link prediction on knowledge graphs (KGs) has been extensively studied on
binary relational KGs, wherein each fact is represented by a triple. A
significant amount of important knowledge, however, is represented by
hyper-relational facts where each fact is composed of a primal triple and a set
of qualifiers comprising a key-value pair that allows for expressing more
complicated semantics. Although some recent works have proposed to embed
hyper-relational KGs, these methods fail to capture essential inference
patterns of hyper-relational facts such as qualifier monotonicity, qualifier
implication, and qualifier mutual exclusion, limiting their generalization
capability. To unlock this, we present \emph{ShrinkE}, a geometric
hyper-relational KG embedding method aiming to explicitly model these patterns.
ShrinkE models the primal triple as a spatial-functional transformation from
the head into a relation-specific box. Each qualifier ``shrinks'' the box to
narrow down the possible answer set and, thus, realizes qualifier monotonicity.
The spatial relationships between the qualifier boxes allow for modeling core
inference patterns of qualifiers such as implication and mutual exclusion.
Experimental results demonstrate ShrinkE's superiority on three benchmarks of
hyper-relational KGs.
\\ ( https://arxiv.org/abs/2306.02199 ,  479kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02211
Date: Sat, 3 Jun 2023 23:27:38 GMT   (4651kb,D)

Title: Privacy-Preserving by Design: Indoor Positioning System Using Wi-Fi
 Passive TDOA
Authors: Mohamed Mohsen, Hamada Rizk, Moustafa Youssef
Categories: cs.AI
\\
 Indoor localization systems have become increasingly important in a wide
range of applications, including industry, security, logistics, and emergency
services. However, the growing demand for accurate localization has heightened
concerns over privacy, as many localization systems rely on active signals that
can be misused by an adversary to track users' movements or manipulate their
measurements. This paper presents PassiFi, a novel passive Wi-Fi time-based
indoor localization system that effectively balances accuracy and privacy.
PassiFi uses a passive WiFi Time Difference of Arrival (TDoA) approach that
ensures users' privacy and safeguards the integrity of their measurement data
while still achieving high accuracy. The system adopts a fingerprinting
approach to address multi-path and non-line-of-sight problems and utilizes deep
neural networks to learn the complex relationship between TDoA and location.
Evaluation in a real-world testbed demonstrates PassiFi's exceptional
performance, surpassing traditional multilateration by 128%, achieving
sub-meter accuracy on par with state-of-the-art active measurement systems, all
while preserving privacy.
\\ ( https://arxiv.org/abs/2306.02211 ,  4651kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02224
Date: Sun, 4 Jun 2023 01:07:20 GMT   (292kb,D)

Title: Auto-GPT for Online Decision Making: Benchmarks and Additional Opinions
Authors: Hui Yang, Sifu Yue, Yunzhong He
Categories: cs.AI cs.LG
\\
 Auto-GPT is an autonomous agent that leverages recent advancements in
adapting Large Language Models (LLMs) for decision-making tasks. While there
has been a growing interest in Auto-GPT stypled agents, questions remain
regarding the effectiveness and flexibility of Auto-GPT in solving real-world
decision-making tasks. Its limited capability for real-world engagement and the
absence of benchmarks contribute to these uncertainties. In this paper, we
present a comprehensive benchmark study of Auto-GPT styled agents in
decision-making tasks that simulate real-world scenarios. Our aim is to gain
deeper insights into this problem and understand the adaptability of GPT-based
agents. We compare the performance of popular LLMs such as GPT-4, GPT-3.5,
Claude, and Vicuna in Auto-GPT styled decision-making tasks. Furthermore, we
introduce the Additional Opinions algorithm, an easy and effective method that
incorporates supervised/imitation-based learners into the Auto-GPT scheme. This
approach enables lightweight supervised learning without requiring fine-tuning
of the foundational LLMs. We demonstrate through careful baseline comparisons
and ablation studies that the Additional Opinions algorithm significantly
enhances performance in online decision-making benchmarks, including WebShop
and ALFWorld.
\\ ( https://arxiv.org/abs/2306.02224 ,  292kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02257
Date: Sun, 4 Jun 2023 04:22:55 GMT   (8453kb)

Title: Learning from AI: An Interactive Learning Method Using a DNN Model
 Incorporating Expert Knowledge as a Teacher
Authors: Kohei Hattori, Tsubasa Hirakawa, Takayoshi Yamashita, Hironobu
 Fujiyoshi
Categories: cs.AI
Comments: 12 pages, 5 figures
\\
 Visual explanation is an approach for visualizing the grounds of judgment by
deep learning, and it is possible to visually interpret the grounds of a
judgment for a certain input by visualizing an attention map. As for
deep-learning models that output erroneous decision-making grounds, a method
that incorporates expert human knowledge in the model via an attention map in a
manner that improves explanatory power and recognition accuracy is proposed. In
this study, based on a deep-learning model that incorporates the knowledge of
experts, a method by which a learner "learns from AI" the grounds for its
decisions is proposed. An "attention branch network" (ABN), which has been
fine-tuned with attention maps modified by experts, is prepared as a teacher.
By using an interactive editing tool for the fine-tuned ABN and attention maps,
the learner learns by editing the attention maps and changing the inference
results. By repeatedly editing the attention maps and making inferences so that
the correct recognition results are output, the learner can acquire the grounds
for the expert's judgments embedded in the ABN. The results of an evaluation
experiment with subjects show that learning using the proposed method is more
efficient than the conventional method.
\\ ( https://arxiv.org/abs/2306.02257 ,  8453kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02342
Date: Sun, 4 Jun 2023 12:21:53 GMT   (22245kb,D)

Title: Deep Optimal Transport: A Practical Algorithm for Photo-realistic Image
 Restoration
Authors: Theo Adrai, Guy Ohayon, Tomer Michaeli and Michael Elad
Categories: cs.AI
\\
 We propose an image restoration algorithm that can control the perceptual
quality and/or the mean square error (MSE) of any pre-trained model, trading
one over the other at test time. Our algorithm is few-shot: Given about a dozen
images restored by the model, it can significantly improve the perceptual
quality and/or the MSE of the model for newly restored images without further
training. Our approach is motivated by a recent theoretical result that links
between the minimum MSE (MMSE) predictor and the predictor that minimizes the
MSE under a perfect perceptual quality constraint. Specifically, it has been
shown that the latter can be obtained by optimally transporting the output of
the former, such that its distribution matches the source data. Thus, to
improve the perceptual quality of a predictor that was originally trained to
minimize MSE, we approximate the optimal transport by a linear transformation
in the latent space of a variational auto-encoder, which we compute in
closed-form using empirical means and covariances. Going beyond the theory, we
find that applying the same procedure on models that were initially trained to
achieve high perceptual quality, typically improves their perceptual quality
even further. And by interpolating the results with the original output of the
model, we can improve their MSE on the expense of perceptual quality. We
illustrate our method on a variety of degradations applied to general content
images of arbitrary dimensions.
\\ ( https://arxiv.org/abs/2306.02342 ,  22245kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02359
Date: Sun, 4 Jun 2023 13:50:01 GMT   (1643kb,D)

Title: Addressing Domain Shift via Knowledge Space Sharing for Generalized
 Zero-Shot Industrial Fault Diagnosis
Authors: Jiancheng Zhao, Jiaqi Yue, Liangjun Feng, Chunhui Zhao, and Jinliang
 Ding
Categories: cs.AI
\\
 Fault diagnosis is a critical aspect of industrial safety, and supervised
industrial fault diagnosis has been extensively researched. However, obtaining
fault samples of all categories for model training can be challenging due to
cost and safety concerns. As a result, the generalized zero-shot industrial
fault diagnosis has gained attention as it aims to diagnose both seen and
unseen faults. Nevertheless, the lack of unseen fault data for training poses a
challenging domain shift problem (DSP), where unseen faults are often
identified as seen faults. In this article, we propose a knowledge space
sharing (KSS) model to address the DSP in the generalized zero-shot industrial
fault diagnosis task. The KSS model includes a generation mechanism (KSS-G) and
a discrimination mechanism (KSS-D). KSS-G generates samples for rare faults by
recombining transferable attribute features extracted from seen samples under
the guidance of auxiliary knowledge. KSS-D is trained in a supervised way with
the help of generated samples, which aims to address the DSP by modeling seen
categories in the knowledge space. KSS-D avoids misclassifying rare faults as
seen faults and identifies seen fault samples. We conduct generalized zero-shot
diagnosis experiments on the benchmark Tennessee-Eastman process, and our
results show that our approach outperforms state-of-the-art methods for the
generalized zero-shot industrial fault diagnosis problem.
\\ ( https://arxiv.org/abs/2306.02359 ,  1643kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02415
Date: Sun, 4 Jun 2023 17:38:06 GMT   (311kb,D)

Title: Top-Down Processing: Top-Down Network Combines Back-Propagation with
 Attention
Authors: Roy Abel, Shimon Ullman
Categories: cs.AI
\\
 Early neural network models relied exclusively on bottom-up processing going
from the input signals to higher-level representations. Many recent models also
incorporate top-down networks going in the opposite direction. Top-down
processing in deep learning models plays two primary roles: learning and
directing attention. These two roles are accomplished in current models through
distinct mechanisms. While top-down attention is often implemented by extending
the model's architecture with additional units that propagate information from
high to low levels of the network, learning is typically accomplished by an
external learning algorithm such as back-propagation. In the current work, we
present an integration of the two functions above, which appear unrelated,
using a single unified mechanism. We propose a novel symmetric bottom-up
top-down network structure that can integrate standard bottom-up networks with
a symmetric top-down counterpart, allowing each network to guide and influence
the other. The same top-down network is being used for both learning, via
back-propagating feedback signals, and at the same time also for top-down
attention, by guiding the bottom-up network to perform a selected task. We show
that our method achieves competitive performance on a standard multi-task
learning benchmark. Yet, we rely on standard single-task architectures and
optimizers, without any task-specific parameters. Additionally, our learning
algorithm addresses in a new way some neuroscience issues that arise in
biological modeling of learning in the brain.
\\ ( https://arxiv.org/abs/2306.02415 ,  311kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02487
Date: Sun, 4 Jun 2023 21:40:11 GMT   (5357kb,D)

Title: Discussion Paper: The Threat of Real Time Deepfakes
Authors: Guy Frankovits and Yisroel Mirsky
Categories: cs.AI cs.CR cs.CV
Journal-ref: FRANKOVITS, Guy; YISROEL, Mirsky. Discussion Paper: The Threat of
 Real Time Deepfakes. In: Proceedings of the 2st Workshop on Security
 Implications of Deepfakes and Cheapfakes. 2023
\\
 Generative deep learning models are able to create realistic audio and video.
This technology has been used to impersonate the faces and voices of
individuals. These ``deepfakes'' are being used to spread misinformation,
enable scams, perform fraud, and blackmail the innocent. The technology
continues to advance and today attackers have the ability to generate deepfakes
in real-time. This new capability poses a significant threat to society as
attackers begin to exploit the technology in advances social engineering
attacks. In this paper, we discuss the implications of this emerging threat,
identify the challenges with preventing these attacks and suggest a better
direction for researching stronger defences.
\\ ( https://arxiv.org/abs/2306.02487 ,  5357kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02488
Date: Sun, 4 Jun 2023 21:40:23 GMT   (591kb,D)

Title: Adversary for Social Good: Leveraging Adversarial Attacks to Protect
 Personal Attribute Privacy
Authors: Xiaoting Li, Lingwei Chen, Dinghao Wu
Categories: cs.AI
\\
 Social media has drastically reshaped the world that allows billions of
people to engage in such interactive environments to conveniently create and
share content with the public. Among them, text data (e.g., tweets, blogs)
maintains the basic yet important social activities and generates a rich source
of user-oriented information. While those explicit sensitive user data like
credentials has been significantly protected by all means, personal private
attribute (e.g., age, gender, location) disclosure due to inference attacks is
somehow challenging to avoid, especially when powerful natural language
processing (NLP) techniques have been effectively deployed to automate
attribute inferences from implicit text data. This puts users' attribute
privacy at risk. To address this challenge, in this paper, we leverage the
inherent vulnerability of machine learning to adversarial attacks, and design a
novel text-space Adversarial attack for Social Good, called Adv4SG. In other
words, we cast the problem of protecting personal attribute privacy as an
adversarial attack formulation problem over the social media text data to
defend against NLP-based attribute inference attacks. More specifically, Adv4SG
proceeds with a sequence of word perturbations under given constraints such
that the probed attribute cannot be identified correctly. Different from the
prior works, we advance Adv4SG by considering social media property, and
introducing cost-effective mechanisms to expedite attribute obfuscation over
text data under the black-box setting. Extensive experiments on real-world
social media datasets have demonstrated that our method can effectively degrade
the inference accuracy with less computational cost over different attribute
settings, which substantially helps mitigate the impacts of inference attacks
and thus achieve high performance in user attribute privacy protection.
\\ ( https://arxiv.org/abs/2306.02488 ,  591kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02519
Date: Mon, 5 Jun 2023 00:58:51 GMT   (6320kb)

Title: Transformative AGI by 2043 is <1% likely
Authors: Ari Allyn-Feuer and Ted Sanders
Categories: cs.AI
Comments: 114 pages
ACM-class: I.2.0
\\
 This paper is a submission to the Open Philanthropy AI Worldviews Contest. In
it, we estimate the likelihood of transformative artificial general
intelligence (AGI) by 2043 and find it to be <1%.
 Specifically, we argue:
 The bar is high: AGI as defined by the contest - something like AI that can
perform nearly all valuable tasks at human cost or less - which we will call
transformative AGI is a much higher bar than merely massive progress in AI, or
even the unambiguous attainment of expensive superhuman AGI or cheap but uneven
AGI.
 Many steps are needed: The probability of transformative AGI by 2043 can be
decomposed as the joint probability of a number of necessary steps, which we
group into categories of software, hardware, and sociopolitical factors.
 No step is guaranteed: For each step, we estimate a probability of success by
2043, conditional on prior steps being achieved. Many steps are quite
constrained by the short timeline, and our estimates range from 16% to 95%.
 Therefore, the odds are low: Multiplying the cascading conditional
probabilities together, we estimate that transformative AGI by 2043 is 0.4%
likely. Reaching >10% seems to require probabilities that feel unreasonably
high, and even 3% seems unlikely.
 Thoughtfully applying the cascading conditional probability approach to this
question yields lower probability values than is often supposed. This framework
helps enumerate the many future scenarios where humanity makes partial but
incomplete progress toward transformative AGI.
\\ ( https://arxiv.org/abs/2306.02519 ,  6320kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02560
Date: Mon, 5 Jun 2023 03:26:06 GMT   (2019kb,D)

Title: Tensorized Hypergraph Neural Networks
Authors: Maolin Wang, Yaoming Zhen, Yu Pan, Zenglin Xu, Ruocheng Guo, Xiangyu
 Zhao
Categories: cs.AI
\\
 Hypergraph neural networks (HGNN) have recently become attractive and
received significant attention due to their excellent performance in various
domains. However, most existing HGNNs rely on first-order approximations of
hypergraph connectivity patterns, which ignores important high-order
information. To address this issue, we propose a novel adjacency-tensor-based
Tensorized Hypergraph Neural Network (THNN). THNN is a faithful hypergraph
modeling framework through high-order outer product feature message passing and
is a natural tensor extension of the adjacency-matrix-based graph neural
networks. The proposed THNN is equivalent to an high-order polynomial
regression scheme, which enable THNN with the ability to efficiently extract
high-order information from uniform hypergraphs. Moreover, in consideration of
the exponential complexity of directly processing high-order outer product
features, we propose using a partially symmetric CP decomposition approach to
reduce model complexity to a linear degree. Additionally, we propose two simple
yet effective extensions of our method for non-uniform hypergraphs commonly
found in real-world applications. Results from experiments on two widely used
hypergraph datasets for 3-D visual object classification show the promising
performance of the proposed THNN.
\\ ( https://arxiv.org/abs/2306.02560 ,  2019kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02588
Date: Mon, 5 Jun 2023 04:32:46 GMT   (585kb)

Title: Literature-based Discovery for Landscape Planning
Authors: David Marasco, Ilya Tyagin, Justin Sybrandt, James H. Spencer, Ilya
 Safro
Categories: cs.AI
\\
 This project demonstrates how medical corpus hypothesis generation, a
knowledge discovery field of AI, can be used to derive new research angles for
landscape and urban planners. The hypothesis generation approach herein
consists of a combination of deep learning with topic modeling, a probabilistic
approach to natural language analysis that scans aggregated research databases
for words that can be grouped together based on their subject matter
commonalities; the word groups accordingly form topics that can provide
implicit connections between two general research terms. The hypothesis
generation system AGATHA was used to identify likely conceptual relationships
between emerging infectious diseases (EIDs) and deforestation, with the
objective of providing landscape planners guidelines for productive research
directions to help them formulate research hypotheses centered on deforestation
and EIDs that will contribute to the broader health field that asserts causal
roles of landscape-level issues. This research also serves as a partial
proof-of-concept for the application of medical database hypothesis generation
to medicine-adjacent hypothesis discovery.
\\ ( https://arxiv.org/abs/2306.02588 ,  585kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02593
Date: Mon, 5 Jun 2023 04:52:33 GMT   (1654kb,D)

Title: Rhythm-controllable Attention with High Robustness for Long Sentence
 Speech Synthesis
Authors: Dengfeng Ke, Yayue Deng, Yukang Jia, Jinlong Xue, Qi Luo, Ya Li,
 Jianqing Sun, Jiaen Liang, Binghuai Lin
Categories: cs.AI
Comments: 5 pages, 3 figures, Published in: 2022 13th International Symposium
 on Chinese Spoken Language Processing (ISCSLP)
DOI: 10.1109/ISCSLP57327.2022.10037822
\\
 Regressive Text-to-Speech (TTS) system utilizes attention mechanism to
generate alignment between text and acoustic feature sequence. Alignment
determines synthesis robustness (e.g, the occurence of skipping, repeating, and
collapse) and rhythm via duration control. However, current attention
algorithms used in speech synthesis cannot control rhythm using external
duration information to generate natural speech while ensuring robustness. In
this study, we propose Rhythm-controllable Attention (RC-Attention) based on
Tracotron2, which improves robustness and naturalness simultaneously. Proposed
attention adopts a trainable scalar learned from four kinds of information to
achieve rhythm control, which makes rhythm control more robust and natural,
even when synthesized sentences are extremely longer than training corpus. We
use word errors counting and AB preference test to measure robustness of
proposed method and naturalness of synthesized speech, respectively. Results
shows that RC-Attention has the lowest word error rate of nearly 0.6%, compared
with 11.8% for baseline system. Moreover, nearly 60% subjects prefer to the
speech synthesized with RC-Attention to that with Forward Attention, because
the former has more natural rhythm.
\\ ( https://arxiv.org/abs/2306.02593 ,  1654kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02684
Date: Mon, 5 Jun 2023 08:20:37 GMT   (2916kb,D)

Title: A Novel Multi-Agent Deep RL Approach for Traffic Signal Control
Authors: Shijie Wang and Shangbo Wang
Categories: cs.AI cs.MA
Comments: Accepted by PerCOM2023 Workshops
\\
 As travel demand increases and urban traffic condition becomes more
complicated, applying multi-agent deep reinforcement learning (MARL) to traffic
signal control becomes one of the hot topics. The rise of Reinforcement
Learning (RL) has opened up opportunities for solving Adaptive Traffic Signal
Control (ATSC) in complex urban traffic networks, and deep neural networks have
further enhanced their ability to handle complex data. Traditional research in
traffic signal control is based on the centralized Reinforcement Learning
technique. However, in a large-scale road network, centralized RL is infeasible
because of an exponential growth of joint state-action space. In this paper, we
propose a Friend-Deep Q-network (Friend-DQN) approach for multiple traffic
signal control in urban networks, which is based on an agent-cooperation
scheme. In particular, the cooperation between multiple agents can reduce the
state-action space and thus speed up the convergence. We use SUMO (Simulation
of Urban Transport) platform to evaluate the performance of Friend-DQN model,
and show its feasibility and superiority over other existing methods.
\\ ( https://arxiv.org/abs/2306.02684 ,  2916kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02697
Date: Mon, 5 Jun 2023 08:38:25 GMT   (168kb,D)

Title: Efficient GPT Model Pre-training using Tensor Train Matrix
 Representation
Authors: Viktoriia Chekalina, Georgii Novikov, Julia Gusak, Ivan Oseledets,
 Alexander Panchenko
Categories: cs.AI
\\
 Large-scale transformer models have shown remarkable performance in language
modelling tasks. However, such models feature billions of parameters, leading
to difficulties in their deployment and prohibitive training costs from
scratch. To reduce the number of the parameters in the GPT-2 architecture, we
replace the matrices of fully-connected layers with the corresponding Tensor
Train Matrix~(TTM) structure. Finally, we customize forward and backward
operations through the TTM-based layer for simplicity and the stableness of
further training. % The resulting GPT-2-based model stores up to 40% fewer
parameters, showing the perplexity comparable to the original model. On the
downstream tasks, including language understanding and text summarization, the
model performs similarly to the original GPT-2 model. The proposed tensorized
layers could be used to efficiently pre-training other Transformer models.
\\ ( https://arxiv.org/abs/2306.02697 ,  168kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02845
Date: Mon, 5 Jun 2023 12:57:07 GMT   (1382kb,D)

Title: Interpretable Multimodal Emotion Recognition using Facial Features and
 Physiological Signals
Authors: Puneet Kumar and Xiaobai Li
Categories: cs.AI
Comments: Accepted for Oral Presentation in DAI 2023
 (https://rbcdsai.iitm.ac.in/DAI-2023/program.html)
\\
 This paper aims to demonstrate the importance and feasibility of fusing
multimodal information for emotion recognition. It introduces a multimodal
framework for emotion understanding by fusing the information from visual
facial features and rPPG signals extracted from the input videos. An
interpretability technique based on permutation feature importance analysis has
also been implemented to compute the contributions of rPPG and visual
modalities toward classifying a given input video into a particular emotion
class. The experiments on IEMOCAP dataset demonstrate that the emotion
classification performance improves by combining the complementary information
from multiple modalities.
\\ ( https://arxiv.org/abs/2306.02845 ,  1382kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02864
Date: Mon, 5 Jun 2023 13:35:01 GMT   (1031kb)

Title: Leveraging Large Language Models for Topic Classification in the Domain
 of Public Affairs
Authors: Alejandro Pe\~na, Aythami Morales, Julian Fierrez, Ignacio Serna,
 Javier Ortega-Garcia, I\~nigo Puente, Jorge Cordova, Gonzalo Cordova
Categories: cs.AI cs.CL
Comments: Accepted in ICDAR 2023 Workshop on Automatic Domain-Adapted and
 Personalized Document Analysis
\\
 The analysis of public affairs documents is crucial for citizens as it
promotes transparency, accountability, and informed decision-making. It allows
citizens to understand government policies, participate in public discourse,
and hold representatives accountable. This is crucial, and sometimes a matter
of life or death, for companies whose operation depend on certain regulations.
Large Language Models (LLMs) have the potential to greatly enhance the analysis
of public affairs documents by effectively processing and understanding the
complex language used in such documents. In this work, we analyze the
performance of LLMs in classifying public affairs documents. As a natural
multi-label task, the classification of these documents presents important
challenges. In this work, we use a regex-powered tool to collect a database of
public affairs documents with more than 33K samples and 22.5M tokens. Our
experiments assess the performance of 4 different Spanish LLMs to classify up
to 30 different topics in the data in different configurations. The results
shows that LLMs can be of great use to process domain-specific documents, such
as those in the domain of public affairs.
\\ ( https://arxiv.org/abs/2306.02864 ,  1031kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02910
Date: Mon, 5 Jun 2023 14:14:48 GMT   (468kb,D)

Title: Action-Evolution Petri Nets: a Framework for Modeling and Solving
 Dynamic Task Assignment Problems
Authors: Riccardo Lo Bianco, Remco Dijkman, Wim Nuijten, Willem van Jaarsveld
Categories: cs.AI
\\
 Dynamic task assignment involves assigning arriving tasks to a limited number
of resources in order to minimize the overall cost of the assignments. To
achieve optimal task assignment, it is necessary to model the assignment
problem first. While there exist separate formalisms, specifically Markov
Decision Processes and (Colored) Petri Nets, to model, execute, and solve
different aspects of the problem, there is no integrated modeling technique. To
address this gap, this paper proposes Action-Evolution Petri Nets (A-E PN) as a
framework for modeling and solving dynamic task assignment problems. A-E PN
provides a unified modeling technique that can represent all elements of
dynamic task assignment problems. Moreover, A-E PN models are executable, which
means they can be used to learn close-to-optimal assignment policies through
Reinforcement Learning (RL) without additional modeling effort. To evaluate the
framework, we define a taxonomy of archetypical assignment problems. We show
for three cases that A-E PN can be used to learn close-to-optimal assignment
policies. Our results suggest that A-E PN can be used to model and solve a
broad range of dynamic task assignment problems.
\\ ( https://arxiv.org/abs/2306.02910 ,  468kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02918
Date: Mon, 5 Jun 2023 14:28:39 GMT   (1526kb,D)

Title: Adversarial Ink: Componentwise Backward Error Attacks on Deep Learning
Authors: Lucas Beerens and Desmond J. Higham
Categories: cs.AI cs.NA math.NA
MSC-class: 65F35
ACM-class: I.2.10; G.1.3
\\
 Deep neural networks are capable of state-of-the-art performance in many
classification tasks. However, they are known to be vulnerable to adversarial
attacks -- small perturbations to the input that lead to a change in
classification. We address this issue from the perspective of backward error
and condition number, concepts that have proved useful in numerical analysis.
To do this, we build on the work of Beuzeville et al. (2021). In particular, we
develop a new class of attack algorithms that use componentwise relative
perturbations. Such attacks are highly relevant in the case of handwritten
documents or printed texts where, for example, the classification of
signatures, postcodes, dates or numerical quantities may be altered by changing
only the ink consistency and not the background. This makes the perturbed
images look natural to the naked eye. Such ``adversarial ink'' attacks
therefore reveal a weakness that can have a serious impact on safety and
security. We illustrate the new attacks on real data and contrast them with
existing algorithms. We also study the use of a componentwise condition number
to quantify vulnerability.
\\ ( https://arxiv.org/abs/2306.02918 ,  1526kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02979
Date: Mon, 5 Jun 2023 15:51:38 GMT   (7185kb,D)

Title: The Chai Platform's AI Safety Framework
Authors: Xiaoding Lu, Aleksey Korshuk, Zongyi Liu, William Beauchamp
Categories: cs.AI
\\
 Chai empowers users to create and interact with customized chatbots, offering
unique and engaging experiences. Despite the exciting prospects, the work
recognizes the inherent challenges of a commitment to modern safety standards.
Therefore, this paper presents the integrated AI safety principles into Chai to
prioritize user safety, data protection, and ethical technology use. The paper
specifically explores the multidimensional domain of AI safety research,
demonstrating its application in Chai's conversational chatbot platform. It
presents Chai's AI safety principles, informed by well-established AI research
centres and adapted for chat AI. This work proposes the following safety
framework: Content Safeguarding; Stability and Robustness; and Operational
Transparency and Traceability. The subsequent implementation of these
principles is outlined, followed by an experimental analysis of Chai's AI
safety framework's real-world impact. We emphasise the significance of
conscientious application of AI safety principles and robust safety measures.
The successful implementation of the safe AI framework in Chai indicates the
practicality of mitigating potential risks for responsible and ethical use of
AI technologies. The ultimate vision is a transformative AI tool fostering
progress and innovation while prioritizing user safety and ethical standards.
\\ ( https://arxiv.org/abs/2306.02979 ,  7185kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03034
Date: Mon, 5 Jun 2023 16:51:38 GMT   (5187kb,D)

Title: Tackling Cooperative Incompatibility for Zero-Shot Human-AI Coordination
Authors: Yang Li, Shao Zhang, Jichen Sun, Wenhao Zhang, Yali Du, Ying Wen,
 Xinbing Wang, Wei Pan
Categories: cs.AI cs.HC
Comments: arXiv admin note: substantial text overlap with arXiv:2302.04831
\\
 Achieving coordination between humans and artificial intelligence in
scenarios involving previously unencountered humans remains a substantial
obstacle within Zero-Shot Human-AI Coordination, which aims to develop AI
agents capable of efficiently working alongside previously unknown human
teammates. Traditional algorithms have aimed to collaborate with humans by
optimizing fixed objectives within a population, fostering diversity in
strategies and behaviors. However, these techniques may lead to learning loss
and an inability to cooperate with specific strategies within the population, a
phenomenon named cooperative incompatibility. To mitigate this issue, we
introduce the Cooperative Open-ended LEarning (COLE) framework, which
formulates open-ended objectives in cooperative games with two players using
perspectives of graph theory to evaluate and pinpoint the cooperative capacity
of each strategy. We put forth a practical algorithm incorporating insights
from game theory and graph theory, e.g., Shapley Value and Centrality. We also
show that COLE could effectively overcome the cooperative incompatibility from
theoretical and empirical analysis. Subsequently, we created an online
Overcooked human-AI experiment platform, the COLE platform, which enables easy
customization of questionnaires, model weights, and other aspects. Utilizing
the COLE platform, we enlist 130 participants for human experiments. Our
findings reveal a preference for our approach over state-of-the-art methods
using a variety of subjective metrics. Moreover, objective experimental
outcomes in the Overcooked game environment indicate that our method surpasses
existing ones when coordinating with previously unencountered AI agents and the
human proxy model. Our code and demo are publicly available at
https://sites.google.com/view/cole-2023.
\\ ( https://arxiv.org/abs/2306.03034 ,  5187kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03048
Date: Mon, 5 Jun 2023 17:21:05 GMT   (29kb,D)

Title: From Robustness to Explainability and Back Again
Authors: Xuanxiang Huang, Joao Marques-Silva
Categories: cs.AI
\\
 In contrast with ad-hoc methods for eXplainable Artificial Intelligence
(XAI), formal explainability offers important guarantees of rigor. However,
formal explainability is hindered by poor scalability for some families of
classifiers, the most significant being neural networks. As a result, there are
concerns as to whether formal explainability might serve to complement other
approaches in delivering trustworthy AI. This paper addresses the limitation of
scalability of formal explainability, and proposes novel algorithms for
computing formal explanations. The novel algorithm computes explanations by
answering instead a number of robustness queries, and such that the number of
such queries is at most linear on the number of features. Consequently, the
proposed algorithm establishes a direct relationship between the practical
complexity of formal explainability and that of robustness. More importantly,
the paper generalizes the definition of formal explanation, thereby allowing
the use of robustness tools that are based on different distance norms, and
also by reasoning in terms of some target degree of robustness. The experiments
validate the practical efficiency of the proposed approach.
\\ ( https://arxiv.org/abs/2306.03048 ,  29kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03081
Date: Mon, 5 Jun 2023 17:55:05 GMT   (704kb,D)

Title: Sequential Monte Carlo Steering of Large Language Models using
 Probabilistic Programs
Authors: Alexander K. Lew, Tan Zhi-Xuan, Gabriel Grand, and Vikash K.
 Mansinghka
Categories: cs.AI cs.CL cs.PL stat.CO
\\
 Even after fine-tuning and reinforcement learning, large language models
(LLMs) can be difficult, if not impossible, to control reliably with prompts
alone. We propose a new inference-time approach to enforcing syntactic and
semantic constraints on the outputs of LLMs, called sequential Monte Carlo
(SMC) steering. The key idea is to specify language generation tasks as
posterior inference problems in a class of discrete probabilistic sequence
models, and replace standard decoding with sequential Monte Carlo inference.
For a computational cost similar to that of beam search, SMC can steer LLMs to
solve diverse tasks, including infilling, generation under syntactic
constraints, and prompt intersection. To facilitate experimentation with SMC
steering, we present a probabilistic programming library, LLaMPPL
(https://github.com/probcomp/LLaMPPL), for concisely specifying new generation
tasks as language model probabilistic programs, and automating steering of
LLaMA-family Transformers.
\\ ( https://arxiv.org/abs/2306.03081 ,  704kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03082
Date: Mon, 5 Jun 2023 17:55:22 GMT   (5633kb,D)

Title: InstructZero: Efficient Instruction Optimization for Black-Box Large
 Language Models
Authors: Lichang Chen, Jiuhai Chen, Tom Goldstein, Heng Huang, Tianyi Zhou
Categories: cs.AI
Comments: 15 pages; 9 figures; Our code is available at
 https://lichang-chen.github.io/InstructZero/
\\
 Large language models~(LLMs) are instruction followers, but it can be
challenging to find the best instruction for different situations, especially
for black-box LLMs on which backpropagation is forbidden. Instead of directly
optimizing the discrete instruction, we optimize a low-dimensional soft prompt
applied to an open-source LLM to generate the instruction for the black-box
LLM. On each iteration of the proposed method, which we call InstructZero, a
soft prompt is converted into an instruction using the open-source LLM, which
is then submitted to the black-box LLM for zero-shot evaluation, and the
performance is sent to Bayesian optimization to produce new soft prompts
improving the zero-shot performance. We evaluate InstructZero on different
combinations of open-source LLMs and APIs including Vicuna and ChatGPT. Our
results show that InstructZero outperforms SOTA auto-instruction methods across
a variety of downstream tasks. Our code and data are publicly available at
https://github.com/Lichang-Chen/InstructZero.
\\ ( https://arxiv.org/abs/2306.03082 ,  5633kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03088
Date: Mon, 5 Jun 2023 17:58:49 GMT   (14263kb,D)

Title: DeepGraphDMD: Interpretable Spatio-Temporal Decomposition of Non-linear
 Functional Brain Network Dynamics
Authors: Md Asadullah Turja, Martin Styner and Guorong Wu
Categories: cs.AI cs.LG
Comments: to be published in MICCAI 2023
\\
 Functional brain dynamics is supported by parallel and overlapping functional
network modes that are associated with specific neural circuits. Decomposing
these network modes from fMRI data and finding their temporal characteristics
is challenging due to their time-varying nature and the non-linearity of the
functional dynamics. Dynamic Mode Decomposition (DMD) algorithms have been
quite popular for solving this decomposition problem in recent years. In this
work, we apply GraphDMD -- an extension of the DMD for network data -- to
extract the dynamic network modes and their temporal characteristics from the
fMRI time series in an interpretable manner. GraphDMD, however, regards the
underlying system as a linear dynamical system that is sub-optimal for
extracting the network modes from non-linear functional data. In this work, we
develop a generalized version of the GraphDMD algorithm -- DeepGraphDMD --
applicable to arbitrary non-linear graph dynamical systems. DeepGraphDMD is an
autoencoder-based deep learning model that learns Koopman eigenfunctions for
graph data and embeds the non-linear graph dynamics into a latent linear space.
We show the effectiveness of our method in both simulated data and the HCP
resting-state fMRI data. In the HCP data, DeepGraphDMD provides novel insights
into cognitive brain functions by discovering two major network modes related
to fluid and crystallized intelligence.
\\ ( https://arxiv.org/abs/2306.03088 ,  14263kb)
------------------------------------------------------------------------------
\\
arXiv:2306.01747
Date: Thu, 18 May 2023 03:18:12 GMT   (3672kb)

Title: Vision-language models boost food composition compilation
Authors: Peihua Ma, Yixin Wu, Ning Yu, Yang Zhang, Michael Backes, Qin Wang,
 Cheng-I Wei
Categories: cs.CV
Comments: 31 pages, 5 figures
\\
 Nutrition information plays a pillar role in clinical dietary practice,
precision nutrition, and food industry. Currently, food composition compilation
serves as a standard paradigm to estimate food nutrition information according
to food ingredient information. However, within this paradigm, conventional
approaches are laborious and highly dependent on the experience of data
managers, they cannot keep pace with the dynamic consumer market and resulting
in lagging and missing nutrition data and earlier machine learning methods
unable to fully understand food ingredient statement information or ignored the
characteristic of food image. To this end, we developed a novel vision-language
AI model, UMDFood-VL, using front-of-package labeling and product images to
accurately estimate food composition profiles. In order to drive such large
model training, we established UMDFood-90k, the most comprehensive multimodal
food database to date. The UMDFood-VL model significantly outperformed
convolutional neural networks (CNNs) and recurrent neural networks (RNNs) on a
variety of nutrition value estimations. For instance, we achieved macro-AUCROC
up to 0.921 for fat value estimation, which satisfied the practice requirement
of food composition compilation. This performance shed the light to generalize
to other food and nutrition-related data compilation and catalyzed the
evolution of other food applications.
\\ ( https://arxiv.org/abs/2306.01747 ,  3672kb)
------------------------------------------------------------------------------
\\
arXiv:2306.01755
Date: Tue, 23 May 2023 04:54:26 GMT   (13192kb,D)

Title: Training Priors Predict Text-To-Image Model Performance
Authors: Charles Lovering and Ellie Pavlick
Categories: cs.CV cs.AI cs.CL
\\
 Text-to-image models can often generate some relations, i.e., "astronaut
riding horse", but fail to generate other relations composed of the same basic
parts, i.e., "horse riding astronaut". These failures are often taken as
evidence that the models rely on training priors rather than constructing novel
images compositionally. This paper tests this intuition directly on the
stablediffusion 2.1 text-to-image model. By looking at the subject-verb-object
(SVO) triads that form the backbone of these prompts (e.g., "astronaut",
"ride", "horse"), we find that the more often an SVO triad appears in the
training data, the better the model can generate an image aligned with that
triad. Here, by aligned we mean that each of the terms appears in the generated
image in the proper relation to each other. However, this increased frequency
also diminishes how well the model can generate an image aligned with the
flipped triad. For example, if "astronaut riding horse" appears frequently in
the training data, the image for "horse riding astronaut" will tend to be
poorly aligned. We also find that models often struggle to generate terms in
atypical roles, e.g., if "horse" is more often the semantic patient (object),
the model might struggle to visualize it as a semantic agent (subject). Our
results thus show that current models are biased to generate images aligned
with relations seen in training and provide important new data in the ongoing
debate on whether these text-to-image models employ abstract compositional
structure in a traditional sense, or rather, interpolate between relations
explicitly seen in the training data.
\\ ( https://arxiv.org/abs/2306.01755 ,  13192kb)
------------------------------------------------------------------------------
\\
arXiv:2306.01756
Date: Wed, 24 May 2023 04:02:49 GMT   (9469kb,D)

Title: CSI-Based Efficient Self-Quarantine Monitoring System Using Branchy
 Convolution Neural Network
Authors: Jingtao Guo, Ivan Wang-Hei Ho
Categories: cs.CV cs.AI cs.LG
Comments: 6 pages, 7 figures, to be published in Proceedings of the 8th IEEE
 World Forum on the Internet of Things
\\
 Nowadays, Coronavirus disease (COVID-19) has become a global pandemic because
of its fast spread in various countries. To build an anti-epidemic barrier,
self-isolation is required for people who have been to any at-risk places or
have been in close contact with infected people. However, existing camera or
wearable device-based monitoring systems may present privacy leakage risks or
cause user inconvenience in some cases. In this paper, we propose a Wi-Fi-based
device-free self-quarantine monitoring system. Specifically, we exploit channel
state information (CSI) derived from Wi-Fi signals as human activity features.
We collect CSI data in a simulated self-quarantine scenario and present
BranchyGhostNet, a lightweight convolution neural network (CNN) with an early
exit prediction branch, for the efficient joint task of room occupancy
detection (ROD) and human activity recognition (HAR). The early exiting branch
is used for ROD, and the final one is used for HAR. Our experimental results
indicate that the proposed model can achieve an average accuracy of 98.19% for
classifying five different human activities. They also confirm that after
leveraging the early exit prediction mechanism, the inference latency for ROD
can be significantly reduced by 54.04% when compared with the final exiting
branch while guaranteeing the accuracy of ROD.
\\ ( https://arxiv.org/abs/2306.01756 ,  9469kb)
------------------------------------------------------------------------------
\\
arXiv:2306.01828
Date: Fri, 2 Jun 2023 17:45:44 GMT   (7720kb,D)

Title: Unifying (Machine) Vision via Counterfactual World Modeling
Authors: Daniel M. Bear, Kevin Feigelis, Honglin Chen, Wanhee Lee, Rahul
 Venkatesh, Klemen Kotar, Alex Durango, Daniel L.K. Yamins
Categories: cs.CV cs.AI
ACM-class: I.2.10; I.4.8
\\
 Leading approaches in machine vision employ different architectures for
different tasks, trained on costly task-specific labeled datasets. This
complexity has held back progress in areas, such as robotics, where robust
task-general perception remains a bottleneck. In contrast, "foundation models"
of natural language have shown how large pre-trained neural networks can
provide zero-shot solutions to a broad spectrum of apparently distinct tasks.
Here we introduce Counterfactual World Modeling (CWM), a framework for
constructing a visual foundation model: a unified, unsupervised network that
can be prompted to perform a wide variety of visual computations. CWM has two
key components, which resolve the core issues that have hindered application of
the foundation model concept to vision. The first is structured masking, a
generalization of masked prediction methods that encourages a prediction model
to capture the low-dimensional structure in visual data. The model thereby
factors the key physical components of a scene and exposes an interface to them
via small sets of visual tokens. This in turn enables CWM's second main idea --
counterfactual prompting -- the observation that many apparently distinct
visual representations can be computed, in a zero-shot manner, by comparing the
prediction model's output on real inputs versus slightly modified
("counterfactual") inputs. We show that CWM generates high-quality readouts on
real-world images and videos for a diversity of tasks, including estimation of
keypoints, optical flow, occlusions, object segments, and relative depth. Taken
together, our results show that CWM is a promising path to unifying the
manifold strands of machine vision in a conceptually simple foundation.
\\ ( https://arxiv.org/abs/2306.01828 ,  7720kb)
------------------------------------------------------------------------------
\\
arXiv:2306.01851
Date: Fri, 2 Jun 2023 18:14:21 GMT   (32088kb,D)

Title: Open-world Text-specified Object Counting
Authors: Niki Amini-Naieni, Kiana Amini-Naieni, Tengda Han, Andrew Zisserman
Categories: cs.CV
\\
 Our objective is open-world object counting in images, where the target
object class is specified by a text description. To this end, we propose
CounTX, a class-agnostic, single-stage model using a transformer decoder
counting head on top of pre-trained joint text-image representations. CounTX is
able to count the number of instances of any class given only an image and a
text description of the target object class, and can be trained end-to-end. To
the best of our knowledge, we are the first to tackle the open-world counting
problem in this way. In addition to this model, we make the following
contributions: (i) we compare the performance of CounTX to prior work on
open-world object counting, and show that our approach exceeds the state of the
art on all measures on the FSC-147 benchmark for methods that use text to
specify the task; (ii) we present and release FSC-147-D, an enhanced version of
FSC-147 with text descriptions, so that object classes can be described with
more detailed language than their simple class names. FSC-147-D is available at
https://github.com/niki-amini-naieni/CounTX/.
\\ ( https://arxiv.org/abs/2306.01851 ,  32088kb)
------------------------------------------------------------------------------
\\
arXiv:2306.01859
Date: Fri, 2 Jun 2023 18:27:26 GMT   (8904kb,D)

Title: Spatially Resolved Gene Expression Prediction from H&E Histology Images
 via Bi-modal Contrastive Learning
Authors: Ronald Xie, Kuan Pang, Gary D. Bader, Bo Wang
Categories: cs.CV cs.AI
\\
 Histology imaging is an important tool in medical diagnosis and research,
enabling the examination of tissue structure and composition at the microscopic
level. Understanding the underlying molecular mechanisms of tissue architecture
is critical in uncovering disease mechanisms and developing effective
treatments. Gene expression profiling provides insight into the molecular
processes underlying tissue architecture, but the process can be time-consuming
and expensive. In this study, we present BLEEP (Bi-modaL Embedding for
Expression Prediction), a bi-modal embedding framework capable of generating
spatially resolved gene expression profiles of whole-slide Hematoxylin and
eosin (H&E) stained histology images. BLEEP uses a contrastive learning
framework to construct a low-dimensional joint embedding space from a reference
dataset using paired image and expression profiles at micrometer resolution.
With this framework, the gene expression of any query image patch can be
imputed using the expression profiles from the reference dataset. We
demonstrate BLEEP's effectiveness in gene expression prediction by benchmarking
its performance on a human liver tissue dataset captured via the 10x Visium
platform, where it achieves significant improvements over existing methods. Our
results demonstrate the potential of BLEEP to provide insights into the
molecular mechanisms underlying tissue architecture, with important
implications in diagnosis and research of various diseases. The proposed
framework can significantly reduce the time and cost associated with gene
expression profiling, opening up new avenues for high-throughput analysis of
histology images for both research and clinical applications.
\\ ( https://arxiv.org/abs/2306.01859 ,  8904kb)
------------------------------------------------------------------------------
\\
arXiv:2306.01875
Date: Fri, 2 Jun 2023 19:08:31 GMT   (34655kb,D)

Title: DiffECG: A Generalized Probabilistic Diffusion Model for ECG Signals
 Synthesis
Authors: Nour Neifar, Achraf Ben-Hamadou, Afef Mdhaffar, Mohamed Jmaiel
Categories: cs.CV cs.LG
Comments: under review
\\
 In recent years, deep generative models have gained attention as a promising
data augmentation solution for heart disease detection using deep learning
approaches applied to ECG signals. In this paper, we introduce a novel approach
based on denoising diffusion probabilistic models for ECG synthesis that covers
three scenarios: heartbeat generation, partial signal completion, and full
heartbeat forecasting. Our approach represents the first generalized
conditional approach for ECG synthesis, and our experimental results
demonstrate its effectiveness for various ECG-related tasks. Moreover, we show
that our approach outperforms other state-of-the-art ECG generative models and
can enhance the performance of state-of-the-art classifiers.
\\ ( https://arxiv.org/abs/2306.01875 ,  34655kb)
------------------------------------------------------------------------------
\\
arXiv:2306.01879
Date: Fri, 2 Jun 2023 19:19:43 GMT   (8563kb,D)

Title: VisualGPTScore: Visio-Linguistic Reasoning with Multimodal Generative
 Pre-Training Scores
Authors: Zhiqiu Lin, Xinyue Chen, Deepak Pathak, Pengchuan Zhang, Deva Ramanan
Categories: cs.CV cs.AI cs.CL
Comments: Website: https://linzhiqiu.github.io/papers/visual_gpt_score/ Code:
 https://github.com/linzhiqiu/visual_gpt_score/
\\
 Vision-language models (VLMs) discriminatively pre-trained with contrastive
image-text matching losses such as $P(\text{match}|\text{text}, \text{image})$
have been criticized for lacking compositional understanding. This means they
might output similar scores even if the original caption is rearranged into a
different semantic statement. To address this, we propose to use the ${\bf
V}$isual ${\bf G}$enerative ${\bf P}$re-${\bf T}$raining Score (${\bf
VisualGPTScore}$) of $P(\text{text}|\text{image})$, a $\textit{multimodal
generative}$ score that captures the likelihood of a text caption conditioned
on an image using an image-conditioned language model. Contrary to the belief
that VLMs are mere bag-of-words models, our off-the-shelf VisualGPTScore
demonstrates top-tier performance on recently proposed image-text retrieval
benchmarks like ARO and Crepe that assess compositional reasoning. Furthermore,
we factorize VisualGPTScore into a product of the $\textit{marginal}$ P(text)
and the $\textit{Pointwise Mutual Information}$ (PMI). This helps to (a)
diagnose datasets with strong language bias, and (b) debias results on other
benchmarks like Winoground using an information-theoretic framework.
VisualGPTScore provides valuable insights and serves as a strong baseline for
future evaluation of visio-linguistic compositionality.
\\ ( https://arxiv.org/abs/2306.01879 ,  8563kb)
------------------------------------------------------------------------------
\\
arXiv:2306.01891
Date: Fri, 2 Jun 2023 19:52:13 GMT   (26452kb,D)

Title: DH-PTAM: A Deep Hybrid Stereo Events-Frames Parallel Tracking And
 Mapping System
Authors: Abanob Soliman, Fabien Bonardi, D\'esir\'e Sidib\'e, Samia Bouchafa
Categories: cs.CV
Comments: Submitted for publication in IEEE RA-L
\\
 This paper presents a robust approach for a visual parallel tracking and
mapping (PTAM) system that excels in challenging environments. Our proposed
method combines the strengths of heterogeneous multi-modal visual sensors,
including stereo event-based and frame-based sensors, in a unified reference
frame through a novel spatio-temporal synchronization of stereo visual frames
and stereo event streams. We employ deep learning-based feature extraction and
description for estimation to enhance robustness further. We also introduce an
end-to-end parallel tracking and mapping optimization layer complemented by a
simple loop-closure algorithm for efficient SLAM behavior. Through
comprehensive experiments on both small-scale and large-scale real-world
sequences of VECtor and TUM-VIE benchmarks, our proposed method (DH-PTAM)
demonstrates superior performance compared to state-of-the-art methods in terms
of robustness and accuracy in adverse conditions. Our implementation's
research-based Python API is publicly available on GitHub for further research
and development: https://github.com/AbanobSoliman/DH-PTAM.
\\ ( https://arxiv.org/abs/2306.01891 ,  26452kb)
------------------------------------------------------------------------------
\\
arXiv:2306.01900
Date: Fri, 2 Jun 2023 20:09:57 GMT   (2855kb,D)

Title: Conditional Generation from Unconditional Diffusion Models using
 Denoiser Representations
Authors: Alexandros Graikos, Srikar Yellapragada, Dimitris Samaras
Categories: cs.CV
\\
 Denoising diffusion models have gained popularity as a generative modeling
technique for producing high-quality and diverse images. Applying these models
to downstream tasks requires conditioning, which can take the form of text,
class labels, or other forms of guidance. However, providing conditioning
information to these models can be challenging, particularly when annotations
are scarce or imprecise. In this paper, we propose adapting pre-trained
unconditional diffusion models to new conditions using the learned internal
representations of the denoiser network. We demonstrate the effectiveness of
our approach on various conditional generation tasks, including
attribute-conditioned generation and mask-conditioned generation. Additionally,
we show that augmenting the Tiny ImageNet training set with synthetic images
generated by our approach improves the classification accuracy of ResNet
baselines by up to 8%. Our approach provides a powerful and flexible way to
adapt diffusion models to new conditions and generate high-quality augmented
data for various conditional generation tasks.
\\ ( https://arxiv.org/abs/2306.01900 ,  2855kb)
------------------------------------------------------------------------------
\\
arXiv:2306.01902
Date: Fri, 2 Jun 2023 20:19:19 GMT   (39858kb,D)

Title: Unlearnable Examples for Diffusion Models: Protect Data from
 Unauthorized Exploitation
Authors: Zhengyue Zhao, Jinhao Duan, Xing Hu, Kaidi Xu, Chenan Wang, Rui Zhang,
 Zidong Du, Qi Guo, Yunji Chen
Categories: cs.CV
\\
 Diffusion models have demonstrated remarkable performance in image generation
tasks, paving the way for powerful AIGC applications. However, these
widely-used generative models can also raise security and privacy concerns,
such as copyright infringement, and sensitive data leakage. To tackle these
issues, we propose a method, Unlearnable Diffusion Perturbation, to safeguard
images from unauthorized exploitation. Our approach involves designing an
algorithm to generate sample-wise perturbation noise for each image to be
protected. This imperceptible protective noise makes the data almost
unlearnable for diffusion models, i.e., diffusion models trained or fine-tuned
on the protected data cannot generate high-quality and diverse images related
to the protected training data. Theoretically, we frame this as a max-min
optimization problem and introduce EUDP, a noise scheduler-based method to
enhance the effectiveness of the protective noise. We evaluate our methods on
both Denoising Diffusion Probabilistic Model and Latent Diffusion Models,
demonstrating that training diffusion models on the protected data lead to a
significant reduction in the quality of the generated images. Especially, the
experimental results on Stable Diffusion demonstrate that our method
effectively safeguards images from being used to train Diffusion Models in
various tasks, such as training specific objects and styles. This achievement
holds significant importance in real-world scenarios, as it contributes to the
protection of privacy and copyright against AI-generated content.
\\ ( https://arxiv.org/abs/2306.01902 ,  39858kb)
------------------------------------------------------------------------------
\\
arXiv:2306.01904
Date: Fri, 2 Jun 2023 20:24:55 GMT   (3525kb,D)

Title: Overcoming the Stability Gap in Continual Learning
Authors: Md Yousuf Harun and Christopher Kanan
Categories: cs.CV cs.LG
\\
 In many real-world applications, deep neural networks are retrained from
scratch as a dataset grows in size. Given the computational expense for
retraining networks, it has been argued that continual learning could make
updating networks more efficient. An obstacle to achieving this goal is the
stability gap, which refers to an observation that when updating on new data,
performance on previously learned data degrades before recovering. Addressing
this problem would enable continual learning to learn new data with fewer
network updates, resulting in increased computational efficiency. We study how
to mitigate the stability gap in rehearsal (or experience replay), a widely
employed continual learning method. We test a variety of hypotheses to
understand why the stability gap occurs. This leads us to discover a method
that vastly reduces this gap. In experiments on a large-scale incremental class
learning setting, we are able to significantly reduce the number of network
updates to recover performance. Our work has the potential to advance the
state-of-the-art in continual learning for real-world applications along with
reducing the carbon footprint required to maintain updated neural networks.
\\ ( https://arxiv.org/abs/2306.01904 ,  3525kb)
------------------------------------------------------------------------------
\\
arXiv:2306.01923
Date: Fri, 2 Jun 2023 21:26:20 GMT   (36064kb,D)

Title: The Surprising Effectiveness of Diffusion Models for Optical Flow and
 Monocular Depth Estimation
Authors: Saurabh Saxena, Charles Herrmann, Junhwa Hur, Abhishek Kar, Mohammad
 Norouzi, Deqing Sun, David J. Fleet
Categories: cs.CV
\\
 Denoising diffusion probabilistic models have transformed image generation
with their impressive fidelity and diversity. We show that they also excel in
estimating optical flow and monocular depth, surprisingly, without
task-specific architectures and loss functions that are predominant for these
tasks. Compared to the point estimates of conventional regression-based
methods, diffusion models also enable Monte Carlo inference, e.g., capturing
uncertainty and ambiguity in flow and depth. With self-supervised pre-training,
the combined use of synthetic and real data for supervised training, and
technical innovations (infilling and step-unrolled denoising diffusion
training) to handle noisy-incomplete training data, and a simple form of
coarse-to-fine refinement, one can train state-of-the-art diffusion models for
depth and optical flow estimation. Extensive experiments focus on quantitative
performance against benchmarks, ablations, and the model's ability to capture
uncertainty and multimodality, and impute missing values. Our model, DDVM
(Denoising Diffusion Vision Model), obtains a state-of-the-art relative depth
error of 0.074 on the indoor NYU benchmark and an Fl-all outlier rate of 3.26\%
on the KITTI optical flow benchmark, about 25\% better than the best published
method. For an overview see https://diffusion-vision.github.io.
\\ ( https://arxiv.org/abs/2306.01923 ,  36064kb)
------------------------------------------------------------------------------
\\
arXiv:2306.01929
Date: Fri, 2 Jun 2023 22:05:52 GMT   (8001kb,D)

Title: Recent Advances of Local Mechanisms in Computer Vision: A Survey and
 Outlook of Recent Work
Authors: Qiangchang Wang, Yilong Yin
Categories: cs.CV
\\
 Inspired by the fact that human brains can emphasize discriminative parts of
the input and suppress irrelevant ones, substantial local mechanisms have been
designed to boost the development of computer vision. They can not only focus
on target parts to learn discriminative local representations, but also process
information selectively to improve the efficiency. In terms of application
scenarios and paradigms, local mechanisms have different characteristics. In
this survey, we provide a systematic review of local mechanisms for various
computer vision tasks and approaches, including fine-grained visual
recognition, person re-identification, few-/zero-shot learning, multi-modal
learning, self-supervised learning, Vision Transformers, and so on.
Categorization of local mechanisms in each field is summarized. Then,
advantages and disadvantages for every category are analyzed deeply, leaving
room for exploration. Finally, future research directions about local
mechanisms have also been discussed that may benefit future works. To the best
our knowledge, this is the first survey about local mechanisms on computer
vision. We hope that this survey can shed light on future research in the
computer vision field.
\\ ( https://arxiv.org/abs/2306.01929 ,  8001kb)
------------------------------------------------------------------------------
\\
arXiv:2306.01936
Date: Fri, 2 Jun 2023 22:29:58 GMT   (17629kb,D)

Title: Sub-Meter Tree Height Mapping of California using Aerial Images and
 LiDAR-Informed U-Net Model
Authors: Fabien H Wagner, Sophia Roberts, Alison L Ritz, Griffin Carter,
 Ricardo Dalagnol, Samuel Favrichon, Mayumi CM Hirye, Martin Brandt, Philipe
 Ciais and Sassan Saatchi
Categories: cs.CV eess.IV
Comments: 29 pages, 9 figures, submitted to Remote Sensing in Ecology and
 Conservation (RSEC)
MSC-class: 92-08
ACM-class: I.4.9; I.5.4
\\
 Tree canopy height is one of the most important indicators of forest biomass,
productivity, and species diversity, but it is challenging to measure
accurately from the ground and from space. Here, we used a U-Net model adapted
for regression to map the canopy height of all trees in the state of California
with very high-resolution aerial imagery (60 cm) from the USDA-NAIP program.
The U-Net model was trained using canopy height models computed from aerial
LiDAR data as a reference, along with corresponding RGB-NIR NAIP images
collected in 2020. We evaluated the performance of the deep-learning model
using 42 independent 1 km$^2$ sites across various forest types and landscape
variations in California. Our predictions of tree heights exhibited a mean
error of 2.9 m and showed relatively low systematic bias across the entire
range of tree heights present in California. In 2020, trees taller than 5 m
covered ~ 19.3% of California. Our model successfully estimated canopy heights
up to 50 m without saturation, outperforming existing canopy height products
from global models. The approach we used allowed for the reconstruction of the
three-dimensional structure of individual trees as observed from nadir-looking
optical airborne imagery, suggesting a relatively robust estimation and mapping
capability, even in the presence of image distortion. These findings
demonstrate the potential of large-scale mapping and monitoring of tree height,
as well as potential biomass estimation, using NAIP imagery.
\\ ( https://arxiv.org/abs/2306.01936 ,  17629kb)
------------------------------------------------------------------------------
\\
arXiv:2306.01938
Date: Fri, 2 Jun 2023 22:39:33 GMT   (10053kb,D)

Title: Self-supervised Interest Point Detection and Description for Fisheye and
 Perspective Images
Authors: Marcela Mera-Trujillo, Shivang Patel, Yu Gu, Gianfranco Doretto
Categories: cs.CV cs.RO
Comments: CVPR Workshop on Omnidirectional Computer Vision, 2023
\\
 Keypoint detection and matching is a fundamental task in many computer vision
problems, from shape reconstruction, to structure from motion, to AR/VR
applications and robotics. It is a well-studied problem with remarkable
successes such as SIFT, and more recent deep learning approaches. While great
robustness is exhibited by these techniques with respect to noise, illumination
variation, and rigid motion transformations, less attention has been placed on
image distortion sensitivity. In this work, we focus on the case when this is
caused by the geometry of the cameras used for image acquisition, and consider
the keypoint detection and matching problem between the hybrid scenario of a
fisheye and a projective image. We build on a state-of-the-art approach and
derive a self-supervised procedure that enables training an interest point
detector and descriptor network. We also collected two new datasets for
additional training and testing in this unexplored scenario, and we demonstrate
that current approaches are suboptimal because they are designed to work in
traditional projective conditions, while the proposed approach turns out to be
the most effective.
\\ ( https://arxiv.org/abs/2306.01938 ,  10053kb)
------------------------------------------------------------------------------
\\
arXiv:2306.01988
Date: Sat, 3 Jun 2023 03:21:18 GMT   (753kb,D)

Title: Lightweight Structure-aware Transformer Network for VHR Remote Sensing
 Image Change Detection
Authors: Tao Lei, Yetong Xu, Hailong Ning, Zhiyong Lv, Chongdan Min, Yaochu Jin
 and Asoke K. Nandi
Categories: cs.CV
\\
 Popular Transformer networks have been successfully applied to remote sensing
(RS) image change detection (CD) identifications and achieve better results
than most convolutional neural networks (CNNs), but they still suffer from two
main problems. First, the computational complexity of the Transformer grows
quadratically with the increase of image spatial resolution, which is
unfavorable to very high-resolution (VHR) RS images. Second, these popular
Transformer networks tend to ignore the importance of fine-grained features,
which results in poor edge integrity and internal tightness for largely changed
objects and leads to the loss of small changed objects. To address the above
issues, this Letter proposes a Lightweight Structure-aware Transformer (LSAT)
network for RS image CD. The proposed LSAT has two advantages. First, a
Cross-dimension Interactive Self-attention (CISA) module with linear complexity
is designed to replace the vanilla self-attention in visual Transformer, which
effectively reduces the computational complexity while improving the feature
representation ability of the proposed LSAT. Second, a Structure-aware
Enhancement Module (SAEM) is designed to enhance difference features and edge
detail information, which can achieve double enhancement by difference
refinement and detail aggregation so as to obtain fine-grained features of
bi-temporal RS images. Experimental results show that the proposed LSAT
achieves significant improvement in detection accuracy and offers a better
tradeoff between accuracy and computational costs than most state-of-the-art CD
methods for VHR RS images.
\\ ( https://arxiv.org/abs/2306.01988 ,  753kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02000
Date: Sat, 3 Jun 2023 04:47:05 GMT   (4051kb,D)

Title: Context-TAP: Tracking Any Point Demands Spatial Context Features
Authors: Weikang Bian, Zhaoyang Huang, Xiaoyu Shi, Yitong Dong, Yijin Li,
 Hongsheng Li
Categories: cs.CV
Comments: Project Page: this
 $\href{https://wkbian.github.io/Projects/Context-TAP/}{webpage}$
\\
 We tackle the problem of Tracking Any Point (TAP) in videos, which
specifically aims at estimating persistent long-term trajectories of query
points in videos. Previous methods attempted to estimate these trajectories
independently to incorporate longer image sequences, therefore, ignoring the
potential benefits of incorporating spatial context features. We argue that
independent video point tracking also demands spatial context features. To this
end, we propose a novel framework Context-TAP, which effectively improves point
trajectory accuracy by aggregating spatial context features in videos.
Context-TAP contains two main modules: 1) a SOurse Feature Enhancement (SOFE)
module, and 2) a TArget Feature Aggregation (TAFA) module. Context-TAP
significantly improves PIPs all-sided, reducing 11.4% Average Trajectory Error
of Occluded Points (ATE-Occ) on CroHD and increasing 11.8% Average Percentage
of Correct Keypoint (A-PCK) on TAP-Vid-Kinectics. Demos are available at this
$\href{https://wkbian.github.io/Projects/Context-TAP/}{webpage}$.
\\ ( https://arxiv.org/abs/2306.02000 ,  4051kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02014
Date: Sat, 3 Jun 2023 06:10:20 GMT   (3667kb,D)

Title: Uncovering the Hidden Dynamics of Video Self-supervised Learning under
 Distribution Shifts
Authors: Pritam Sarkar, Ahmad Beirami, Ali Etemad
Categories: cs.CV cs.LG
Comments: 57 pages
\\
 Video self-supervised learning (VSSL) has made significant progress in recent
years. However, the exact behavior and dynamics of these models under different
forms of distribution shift are not yet known. In this paper, we
comprehensively study the behavior of six popular self-supervised methods
(v-SimCLR, v-MOCO, v-BYOL, v-SimSiam, v-DINO, v-MAE) in response to various
forms of natural distribution shift, i.e., (i) context shift, (ii) viewpoint
shift, (iii) actor shift, (iv) source shift, (v) generalizability to unknown
classes (zero-shot), and (vi) open-set recognition. To perform this extensive
study, we carefully craft a test bed consisting of $17$ in-distribution and
out-of-distribution benchmark pairs using available public datasets and a
series of evaluation protocols to stress-test the different methods under the
intended shifts. Our study uncovers a series of intriguing findings and
interesting behaviors of VSSL methods. For instance, we observe that while
video models generally struggle with context shifts, v-MAE and supervised
learning exhibit more robustness. Moreover, our study shows that v-MAE is a
strong temporal learner, whereas contrastive methods, v-SimCLR and v-MOCO,
exhibit strong performances against viewpoint shifts. When studying the notion
of open-set recognition, we notice a trade-off between closed-set and open-set
recognition performance, particularly if the pretrained VSSL encoders are used
without finetuning. We hope that our work will contribute to the development of
robust video representation learning frameworks for various real-world
scenarios.
\\ ( https://arxiv.org/abs/2306.02014 ,  3667kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02018
Date: Sat, 3 Jun 2023 06:29:02 GMT   (37962kb,D)

Title: VideoComposer: Compositional Video Synthesis with Motion Controllability
Authors: Xiang Wang, Hangjie Yuan, Shiwei Zhang, Dayou Chen, Jiuniu Wang,
 Yingya Zhang, Yujun Shen, Deli Zhao, Jingren Zhou
Categories: cs.CV
Comments: The first four authors contributed equally. Project page:
 https://videocomposer.github.io
\\
 The pursuit of controllability as a higher standard of visual content
creation has yielded remarkable progress in customizable image synthesis.
However, achieving controllable video synthesis remains challenging due to the
large variation of temporal dynamics and the requirement of cross-frame
temporal consistency. Based on the paradigm of compositional generation, this
work presents VideoComposer that allows users to flexibly compose a video with
textual conditions, spatial conditions, and more importantly temporal
conditions. Specifically, considering the characteristic of video data, we
introduce the motion vector from compressed videos as an explicit control
signal to provide guidance regarding temporal dynamics. In addition, we develop
a Spatio-Temporal Condition encoder (STC-encoder) that serves as a unified
interface to effectively incorporate the spatial and temporal relations of
sequential inputs, with which the model could make better use of temporal
conditions and hence achieve higher inter-frame consistency. Extensive
experimental results suggest that VideoComposer is able to control the spatial
and temporal patterns simultaneously within a synthesized video in various
forms, such as text description, sketch sequence, reference video, or even
simply hand-crafted motions. The code and models will be publicly available at
https://videocomposer.github.io.
\\ ( https://arxiv.org/abs/2306.02018 ,  37962kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02021
Date: Sat, 3 Jun 2023 06:34:17 GMT   (3276kb,D)

Title: Towards Black-box Adversarial Example Detection: A Data
 Reconstruction-based Method
Authors: Yifei Gao, Zhiyu Lin, Yunfan Yang, Jitao Sang
Categories: cs.CV
Comments: 14 pages, 8 figures, 13 tables
\\
 Adversarial example detection is known to be an effective adversarial defense
method. Black-box attack, which is a more realistic threat and has led to
various black-box adversarial training-based defense methods, however, does not
attract considerable attention in adversarial example detection. In this paper,
we fill this gap by positioning the problem of black-box adversarial example
detection (BAD). Data analysis under the introduced BAD settings demonstrates
(1) the incapability of existing detectors in addressing the black-box scenario
and (2) the potential of exploring BAD solutions from a data perspective. To
tackle the BAD problem, we propose a data reconstruction-based adversarial
example detection method. Specifically, we use variational auto-encoder (VAE)
to capture both pixel and frequency representations of normal examples. Then we
use reconstruction error to detect adversarial examples. Compared with existing
detection methods, the proposed method achieves substantially better detection
performance in BAD, which helps promote the deployment of adversarial example
detection-based defense solutions in real-world models.
\\ ( https://arxiv.org/abs/2306.02021 ,  3276kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02027
Date: Sat, 3 Jun 2023 07:03:15 GMT   (4714kb,D)

Title: Efficient Multi-Grained Knowledge Reuse for Class Incremental
 Segmentation
Authors: Zhihe Lu, Shuicheng Yan, Xinchao Wang
Categories: cs.CV
Comments: Technical Report. This work has been submitted to the IEEE for
 possible publication. Copyright may be transferred without notice, after
 which this version may no longer be accessible
\\
 Class Incremental Semantic Segmentation (CISS) has been a trend recently due
to its great significance in real-world applications. Although the existing
CISS methods demonstrate remarkable performance, they either leverage the
high-level knowledge (feature) only while neglecting the rich and diverse
knowledge in the low-level features, leading to poor old knowledge preservation
and weak new knowledge exploration; or use multi-level features for knowledge
distillation by retraining a heavy backbone, which is computationally
intensive. In this paper, we for the first time propose to efficiently reuse
the multi-grained knowledge for CISS by fusing multi-level features with the
frozen backbone and show a simple aggregation of varying-level features, i.e.,
naive feature pyramid, can boost the performance significantly. We further
introduce a novel densely-interactive feature pyramid (DEFY) module that
enhances the fusion of high- and low-level features by enabling their dense
interaction. Specifically, DEFY establishes a per-pixel relationship between
pairs of feature maps, allowing for multi-pair outputs to be aggregated. This
results in improved semantic segmentation by leveraging the complementary
information from multi-level features. We show that DEFY can be effortlessly
integrated into three representative methods for performance enhancement. Our
method yields a new state-of-the-art performance when combined with the current
SOTA by notably averaged mIoU gains on two widely used benchmarks, i.e., 2.5%
on PASCAL VOC 2012 and 2.3% on ADE20K.
\\ ( https://arxiv.org/abs/2306.02027 ,  4714kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02061
Date: Sat, 3 Jun 2023 09:19:24 GMT   (14282kb,D)

Title: Balancing Logit Variation for Long-tailed Semantic Segmentation
Authors: Yuchao Wang, Jingjing Fei, Haochen Wang, Wei Li, Tianpeng Bao, Liwei
 Wu, Rui Zhao, Yujun Shen
Categories: cs.CV
\\
 Semantic segmentation usually suffers from a long-tail data distribution. Due
to the imbalanced number of samples across categories, the features of those
tail classes may get squeezed into a narrow area in the feature space. Towards
a balanced feature distribution, we introduce category-wise variation into the
network predictions in the training phase such that an instance is no longer
projected to a feature point, but a small region instead. Such a perturbation
is highly dependent on the category scale, which appears as assigning smaller
variation to head classes and larger variation to tail classes. In this way, we
manage to close the gap between the feature areas of different categories,
resulting in a more balanced representation. It is noteworthy that the
introduced variation is discarded at the inference stage to facilitate a
confident prediction. Although with an embarrassingly simple implementation,
our method manifests itself in strong generalizability to various datasets and
task settings. Extensive experiments suggest that our plug-in design lends
itself well to a range of state-of-the-art approaches and boosts the
performance on top of them.
\\ ( https://arxiv.org/abs/2306.02061 ,  14282kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02064
Date: Sat, 3 Jun 2023 09:36:16 GMT   (2473kb,D)

Title: Flew Over Learning Trap: Learn Unlearnable Samples by Progressive Staged
 Training
Authors: Pucheng Dang, Xing Hu, Kaidi Xu, Jinhao Duan, Di Huang, Husheng Han,
 Rui Zhang, Zidong Du, Qi Guo, Yunji Chen
Categories: cs.CV
\\
 Unlearning techniques are proposed to prevent third parties from exploiting
unauthorized data, which generate unlearnable samples by adding imperceptible
perturbations to data for public publishing. These unlearnable samples
effectively misguide model training to learn perturbation features but ignore
image semantic features. We make the in-depth analysis and observe that models
can learn both image features and perturbation features of unlearnable samples
at an early stage, but rapidly go to the overfitting stage since the shallow
layers tend to overfit on perturbation features and make models fall into
overfitting quickly. Based on the observations, we propose Progressive Staged
Training to effectively prevent models from overfitting in learning
perturbation features. We evaluated our method on multiple model architectures
over diverse datasets, e.g., CIFAR-10, CIFAR-100, and ImageNet-mini. Our method
circumvents the unlearnability of all state-of-the-art methods in the
literature and provides a reliable baseline for further evaluation of
unlearnable techniques.
\\ ( https://arxiv.org/abs/2306.02064 ,  2473kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02080
Date: Sat, 3 Jun 2023 11:05:04 GMT   (7959kb,D)

Title: Benchmarking Robustness of Adaptation Methods on Pre-trained
 Vision-Language Models
Authors: Shuo Chen, Jindong Gu, Zhen Han, Yunpu Ma, Philip Torr, Volker Tresp
Categories: cs.CV cs.CL cs.LG
\\
 Various adaptation methods, such as LoRA, prompts, and adapters, have been
proposed to enhance the performance of pre-trained vision-language models in
specific domains. The robustness of these adaptation methods against
distribution shifts have not been studied. In this study, we assess the
robustness of 11 widely-used adaptation methods across 4 vision-language
datasets under multimodal corruptions. Concretely, we introduce 7 benchmark
datasets, including 96 visual and 87 textual corruptions, to investigate the
robustness of different adaptation methods, the impact of available adaptation
examples, and the influence of trainable parameter size during adaptation. Our
analysis reveals that: 1) Adaptation methods are more sensitive to text
corruptions than visual corruptions. 2) Full fine-tuning does not consistently
provide the highest robustness; instead, adapters can achieve better robustness
with comparable clean performance. 3) Contrary to expectations, our findings
indicate that increasing the number of adaptation data and parameters does not
guarantee enhanced robustness; instead it results in even lower robustness. We
hope this study could benefit future research in the development of robust
multimodal adaptation methods. The benchmark, code, and dataset used in this
study can be accessed at \url{https://adarobustness.github.io}.
\\ ( https://arxiv.org/abs/2306.02080 ,  7959kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02082
Date: Sat, 3 Jun 2023 11:07:56 GMT   (17713kb,D)

Title: Unsupervised Low Light Image Enhancement Using SNR-Aware Swin
 Transformer
Authors: Zhijian Luo, Jiahui Tang, Yueen Hou, Zihan Huang and Yanzeng Gao
Categories: cs.CV
\\
 Image captured under low-light conditions presents unpleasing artifacts,
which debilitate the performance of feature extraction for many upstream visual
tasks. Low-light image enhancement aims at improving brightness and contrast,
and further reducing noise that corrupts the visual quality. Recently, many
image restoration methods based on Swin Transformer have been proposed and
achieve impressive performance. However, On one hand, trivially employing Swin
Transformer for low-light image enhancement would expose some artifacts,
including over-exposure, brightness imbalance and noise corruption, etc. On the
other hand, it is impractical to capture image pairs of low-light images and
corresponding ground-truth, i.e. well-exposed image in same visual scene. In
this paper, we propose a dual-branch network based on Swin Transformer, guided
by a signal-to-noise ratio prior map which provides the spatial-varying
information for low-light image enhancement. Moreover, we leverage unsupervised
learning to construct the optimization objective based on Retinex model, to
guide the training of proposed network. Experimental results demonstrate that
the proposed model is competitive with the baseline models.
\\ ( https://arxiv.org/abs/2306.02082 ,  17713kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02083
Date: Sat, 3 Jun 2023 11:08:38 GMT   (3106kb,D)

Title: Efficient Text-Guided 3D-Aware Portrait Generation with Score
 Distillation Sampling on Distribution
Authors: Yiji Cheng, Fei Yin, Xiaoke Huang, Xintong Yu, Jiaxiang Liu, Shikun
 Feng, Yujiu Yang, Yansong Tang
Categories: cs.CV
\\
 Text-to-3D is an emerging task that allows users to create 3D content with
infinite possibilities. Existing works tackle the problem by optimizing a 3D
representation with guidance from pre-trained diffusion models. An apparent
drawback is that they need to optimize from scratch for each prompt, which is
computationally expensive and often yields poor visual fidelity. In this paper,
we propose DreamPortrait, which aims to generate text-guided 3D-aware portraits
in a single-forward pass for efficiency. To achieve this, we extend Score
Distillation Sampling from datapoint to distribution formulation, which injects
semantic prior into a 3D distribution. However, the direct extension will lead
to the mode collapse problem since the objective only pursues semantic
alignment. Hence, we propose to optimize a distribution with hierarchical
condition adapters and GAN loss regularization. For better 3D modeling, we
further design a 3D-aware gated cross-attention mechanism to explicitly let the
model perceive the correspondence between the text and the 3D-aware space.
These elaborated designs enable our model to generate portraits with robust
multi-view semantic consistency, eliminating the need for optimization-based
methods. Extensive experiments demonstrate our model's highly competitive
performance and significant speed boost against existing methods.
\\ ( https://arxiv.org/abs/2306.02083 ,  3106kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02092
Date: Sat, 3 Jun 2023 11:50:44 GMT   (1444kb,D)

Title: Relieving Triplet Ambiguity: Consensus Network for Language-Guided Image
 Retrieval
Authors: Xu Zhang, Zhedong Zheng, Xiaohan Wang, Yi Yang
Categories: cs.CV
Comments: 11 pages
\\
 Language-guided image retrieval enables users to search for images and
interact with the retrieval system more naturally and expressively by using a
reference image and a relative caption as a query. Most existing studies mainly
focus on designing image-text composition architecture to extract
discriminative visual-linguistic relations. Despite great success, we identify
an inherent problem that obstructs the extraction of discriminative features
and considerably compromises model training: \textbf{triplet ambiguity}. This
problem stems from the annotation process wherein annotators view only one
triplet at a time. As a result, they often describe simple attributes, such as
color, while neglecting fine-grained details like location and style. This
leads to multiple false-negative candidates matching the same modification
text. We propose a novel Consensus Network (Css-Net) that self-adaptively
learns from noisy triplets to minimize the negative effects of triplet
ambiguity. Inspired by the psychological finding that groups perform better
than individuals, Css-Net comprises 1) a consensus module featuring four
distinct compositors that generate diverse fused image-text embeddings and 2) a
Kullback-Leibler divergence loss, which fosters learning among the compositors,
enabling them to reduce biases learned from noisy triplets and reach a
consensus. The decisions from four compositors are weighted during evaluation
to further achieve consensus. Comprehensive experiments on three datasets
demonstrate that Css-Net can alleviate triplet ambiguity, achieving competitive
performance on benchmarks, such as $+2.77\%$ R@10 and $+6.67\%$ R@50 on
FashionIQ.
\\ ( https://arxiv.org/abs/2306.02092 ,  1444kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02094
Date: Sat, 3 Jun 2023 11:54:56 GMT   (4754kb,D)

Title: Segment Anything Meets Semantic Communication
Authors: Shehbaz Tariq, Brian Estadimas Arfeto, Chaoning Zhang, Hyundong Shin
Categories: cs.CV
Comments: Submitted to MILCOM 23
\\
 In light of the diminishing returns of traditional methods for enhancing
transmission rates, the domain of semantic communication presents promising new
frontiers. Focusing on image transmission, this paper explores the application
of foundation models, particularly the Segment Anything Model (SAM) developed
by Meta AI Research, to improve semantic communication. SAM is a promptable
image segmentation model that has gained attention for its ability to perform
zero-shot segmentation tasks without explicit training or domain-specific
knowledge. By employing SAM's segmentation capability and lightweight neural
network architecture for semantic coding, we propose a practical approach to
semantic communication. We demonstrate that this approach retains critical
semantic features, achieving higher image reconstruction quality and reducing
communication overhead. This practical solution eliminates the
resource-intensive stage of training a segmentation model and can be applied to
any semantic coding architecture, paving the way for real-world applications.
\\ ( https://arxiv.org/abs/2306.02094 ,  4754kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02095
Date: Sat, 3 Jun 2023 12:05:07 GMT   (5510kb,D)

Title: Content-aware Token Sharing for Efficient Semantic Segmentation with
 Vision Transformers
Authors: Chenyang Lu, Daan de Geus, Gijs Dubbelman
Categories: cs.CV
Comments: CVPR 2023. Project page and code: https://tue-mps.github.io/CTS/
\\
 This paper introduces Content-aware Token Sharing (CTS), a token reduction
approach that improves the computational efficiency of semantic segmentation
networks that use Vision Transformers (ViTs). Existing works have proposed
token reduction approaches to improve the efficiency of ViT-based image
classification networks, but these methods are not directly applicable to
semantic segmentation, which we address in this work. We observe that, for
semantic segmentation, multiple image patches can share a token if they contain
the same semantic class, as they contain redundant information. Our approach
leverages this by employing an efficient, class-agnostic policy network that
predicts if image patches contain the same semantic class, and lets them share
a token if they do. With experiments, we explore the critical design choices of
CTS and show its effectiveness on the ADE20K, Pascal Context and Cityscapes
datasets, various ViT backbones, and different segmentation decoders. With
Content-aware Token Sharing, we are able to reduce the number of processed
tokens by up to 44%, without diminishing the segmentation quality.
\\ ( https://arxiv.org/abs/2306.02095 ,  5510kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02098
Date: Sat, 3 Jun 2023 12:15:20 GMT   (5693kb,D)

Title: Towards Complex Real-World Safety Factory Inspection: A High-Quality
 Dataset for Safety Clothing and Helmet Detection
Authors: Fusheng Yu, Xiaoping Wang, Jiang Li, Shaojin Wu, Junjie Zhang, Zhigang
 Zeng
Categories: cs.CV
Comments: 11 pages, 7 figures
\\
 Safety clothing and helmets play a crucial role in ensuring worker safety at
construction sites. Recently, deep learning methods have garnered significant
attention in the field of computer vision for their potential to enhance safety
and efficiency in various industries. However, limited availability of
high-quality datasets has hindered the development of deep learning methods for
safety clothing and helmet detection. In this work, we present a large,
comprehensive, and realistic high-quality dataset for safety clothing and
helmet detection, which was collected from a real-world chemical plant and
annotated by professional security inspectors. Our dataset has been compared
with several existing open-source datasets, and its effectiveness has been
verified applying some classic object detection methods. The results
demonstrate that our dataset is more complete and performs better in real-world
settings. Furthermore, we have released our deployment code to the public to
encourage the adoption of our dataset and improve worker safety. We hope that
our efforts will promote the convergence of academic research and industry,
ultimately contribute to the betterment of society.
\\ ( https://arxiv.org/abs/2306.02098 ,  5693kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02099
Date: Sat, 3 Jun 2023 12:23:17 GMT   (44656kb,D)

Title: Weight-Aware Implicit Geometry Reconstruction with Curvature-Guided
 Sampling
Authors: Lu Sang and Abhishek Saroha and Maolin Gao and Daniel Cremers
Categories: cs.CV
Comments: 9 pages
\\
 Neural surface implicit representations offer numerous advantages, including
the ability to easily modify topology and surface resolution. However,
reconstructing implicit geometry representation with only limited known data is
challenging. In this paper, we present an approach that effectively
interpolates and extrapolates within training points, generating additional
training data to reconstruct a surface with superior qualitative and
quantitative results. We also introduce a technique that efficiently calculates
differentiable geometric properties, i.e., mean and Gaussian curvatures, to
enhance the sampling process during training. Additionally, we propose a
weight-aware implicit neural representation that not only streamlines surface
extraction but also extend to non-closed surfaces by depicting non-closed areas
as locally degenerated patches, thereby mitigating the drawbacks of the
previous assumption in implicit neural representations.
\\ ( https://arxiv.org/abs/2306.02099 ,  44656kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02142
Date: Sat, 3 Jun 2023 15:56:30 GMT   (2892kb,D)

Title: TransDocAnalyser: A Framework for Offline Semi-structured Handwritten
 Document Analysis in the Legal Domain
Authors: Sagar Chakraborty, Gaurav Harit and Saptarshi Ghosh
Categories: cs.CV
Comments: This paper has been accepted in 17th International Conference on
 Document Analysis and Recognition(ICDAR) as an Oral presentation
ACM-class: I.2.1
\\
 State-of-the-art offline Optical Character Recognition (OCR) frameworks
perform poorly on semi-structured handwritten domain-specific documents due to
their inability to localize and label form fields with domain-specific
semantics. Existing techniques for semi-structured document analysis have
primarily used datasets comprising invoices, purchase orders, receipts, and
identity-card documents for benchmarking. In this work, we build the first
semi-structured document analysis dataset in the legal domain by collecting a
large number of First Information Report (FIR) documents from several police
stations in India. This dataset, which we call the FIR dataset, is more
challenging than most existing document analysis datasets, since it combines a
wide variety of handwritten text with printed text. We also propose an
end-to-end framework for offline processing of handwritten semi-structured
documents, and benchmark it on our novel FIR dataset. Our framework used
Encoder-Decoder architecture for localizing and labelling the form fields and
for recognizing the handwritten content. The encoder consists of Faster-RCNN
and Vision Transformers. Further the Transformer-based decoder architecture is
trained with a domain-specific tokenizer. We also propose a post-correction
method to handle recognition errors pertaining to the domain-specific terms.
Our proposed framework achieves state-of-the-art results on the FIR dataset
outperforming several existing models
\\ ( https://arxiv.org/abs/2306.02142 ,  2892kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02143
Date: Sat, 3 Jun 2023 15:58:38 GMT   (5473kb,D)

Title: Hierarchical Multiresolution Feature- and Prior-based Graphs for
 Classification
Authors: Faezeh Fallah
Categories: cs.CV cs.LG
\\
 To incorporate spatial (neighborhood) and bidirectional hierarchical
relationships as well as features and priors of the samples into their
classification, we formulated the classification problem on three variants of
multiresolution neighborhood graphs and the graph of a hierarchical conditional
random field. Each of these graphs was weighted and undirected and could thus
incorporate the spatial or hierarchical relationships in all directions. In
addition, each variant of the proposed neighborhood graphs was composed of a
spatial feature-based subgraph and an aspatial prior-based subgraph. It
expanded on a random walker graph by using novel mechanisms to derive the edge
weights of its spatial feature-based subgraph. These mechanisms included
implicit and explicit edge detection to enhance detection of weak boundaries
between different classes in spatial domain. The implicit edge detection relied
on the outlier detection capability of the Tukey's function and the
classification reliabilities of the samples estimated by a hierarchical random
forest classifier. Similar mechanism was used to derive the edge weights and
thus the energy function of the hierarchical conditional random field. This
way, the classification problem boiled down to a system of linear equations and
a minimization of the energy function which could be done via fast and
efficient techniques.
\\ ( https://arxiv.org/abs/2306.02143 ,  5473kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02144
Date: Sat, 3 Jun 2023 16:00:57 GMT   (1122kb,D)

Title: A two-way translation system of Chinese sign language based on computer
 vision
Authors: Shengzhuo Wei and Yan Lan
Categories: cs.CV
\\
 As the main means of communication for deaf people, sign language has a
special grammatical order, so it is meaningful and valuable to develop a
real-time translation system for sign language. In the research process, we
added a TSM module to the lightweight neural network model for the large
Chinese continuous sign language dataset . It effectively improves the network
performance with high accuracy and fast recognition speed. At the same time, we
improve the Bert-Base-Chinese model to divide Chinese sentences into words and
mapping the natural word order to the statute sign language order, and finally
use the corresponding word videos in the isolated sign language dataset to
generate the sentence video, so as to achieve the function of text-to-sign
language translation. In the last of our research we built a system with sign
language recognition and translation functions, and conducted performance tests
on the complete dataset. The sign language video recognition accuracy reached
about 99.3% with a time of about 0.05 seconds, and the sign language generation
video time was about 1.3 seconds. The sign language system has good performance
performance and is feasible.
\\ ( https://arxiv.org/abs/2306.02144 ,  1122kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02204
Date: Sat, 3 Jun 2023 21:49:06 GMT   (3953kb,D)

Title: Cycle Consistency Driven Object Discovery
Authors: Aniket Didolkar, Anirudh Goyal, Yoshua Bengio
Categories: cs.CV cs.AI
\\
 Developing deep learning models that effectively learn object-centric
representations, akin to human cognition, remains a challenging task. Existing
approaches have explored slot-based methods utilizing architectural priors or
auxiliary information such as depth maps or flow maps to facilitate object
discovery by representing objects as fixed-size vectors, called ``slots'' or
``object files''. However, reliance on architectural priors introduces
unreliability and requires meticulous engineering to identify the correct
objects. Likewise, methods relying on auxiliary information are suboptimal as
such information is often unavailable for most natural scenes. To address these
limitations, we propose a method that explicitly optimizes the constraint that
each object in a scene should be mapped to a distinct slot. We formalize this
constraint by introducing consistency objectives which are cyclic in nature. We
refer to them as the \textit{cycle-consistency} objectives. By applying these
consistency objectives to various existing slot-based object-centric methods,
we demonstrate significant enhancements in object-discovery performance. These
improvements are consistent across both synthetic and real-world scenes,
highlighting the effectiveness and generalizability of the proposed approach.
Furthermore, our experiments show that the learned slots from the proposed
method exhibit superior suitability for downstream reinforcement learning (RL)
tasks.
\\ ( https://arxiv.org/abs/2306.02204 ,  3953kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02236
Date: Sun, 4 Jun 2023 02:33:12 GMT   (3016kb,D)

Title: Detector Guidance for Multi-Object Text-to-Image Generation
Authors: Luping Liu and Zijian Zhang and Yi Ren and Rongjie Huang and Xiang Yin
 and Zhou Zhao
Categories: cs.CV cs.AI cs.LG
\\
 Diffusion models have demonstrated impressive performance in text-to-image
generation. They utilize a text encoder and cross-attention blocks to infuse
textual information into images at a pixel level. However, their capability to
generate images with text containing multiple objects is still restricted.
Previous works identify the problem of information mixing in the CLIP text
encoder and introduce the T5 text encoder or incorporate strong prior knowledge
to assist with the alignment. We find that mixing problems also occur on the
image side and in the cross-attention blocks. The noisy images can cause
different objects to appear similar, and the cross-attention blocks inject
information at a pixel level, leading to leakage of global object understanding
and resulting in object mixing. In this paper, we introduce Detector Guidance
(DG), which integrates a latent object detection model to separate different
objects during the generation process. DG first performs latent object
detection on cross-attention maps (CAMs) to obtain object information. Based on
this information, DG then masks conflicting prompts and enhances related
prompts by manipulating the following CAMs. We evaluate the effectiveness of DG
using Stable Diffusion on COCO, CC, and a novel multi-related object benchmark,
MRO. Human evaluations demonstrate that DG provides an 8-22\% advantage in
preventing the amalgamation of conflicting concepts and ensuring that each
object possesses its unique region without any human involvement and additional
iterations. Our implementation is available at
\url{https://github.com/luping-liu/Detector-Guidance}.
\\ ( https://arxiv.org/abs/2306.02236 ,  3016kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02240
Date: Sun, 4 Jun 2023 02:55:25 GMT   (2969kb,D)

Title: ProTeCt: Prompt Tuning for Hierarchical Consistency
Authors: Tz-Ying Wu, Chih-Hui Ho, Nuno Vasconcelos
Categories: cs.CV
\\
 Large visual-language models, like CLIP, learn generalized representations
and have shown promising zero-shot performance. Few-shot adaptation methods,
based on prompt tuning, have also been shown to further improve performance on
downstream datasets. However, these models are not hierarchically consistent.
Frequently, they infer incorrect labels at coarser taxonomic class levels, even
when the inference at the leaf level (original class labels) is correct. This
is problematic, given their support for open set classification and, in
particular, open-grained classification, where practitioners define label sets
at various levels of granularity. To address this problem, we propose a prompt
tuning technique to calibrate the hierarchical consistency of model
predictions. A set of metrics of hierarchical consistency, the Hierarchical
Consistent Accuracy (HCA) and the Mean Treecut Accuracy (MTA), are first
proposed to benchmark model performance in the open-granularity setting. A
prompt tuning technique, denoted as Prompt Tuning for Hierarchical Consistency
(ProTeCt), is then proposed to calibrate classification across all possible
label set granularities. Results show that ProTeCt can be combined with
existing prompt tuning methods to significantly improve open-granularity
classification performance without degradation of the original classification
performance at the leaf level.
\\ ( https://arxiv.org/abs/2306.02240 ,  2969kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02243
Date: Sun, 4 Jun 2023 03:06:37 GMT   (1175kb,D)

Title: Retrieval-Enhanced Visual Prompt Learning for Few-shot Classification
Authors: Jintao Rong, Hao Chen, Tianxiao Chen, Linlin Ou, Xinyi Yu, Yifan Liu
Categories: cs.CV
\\
 Prompt learning has become a popular approach for adapting large
vision-language models, such as CLIP, to downstream tasks. Typically, prompt
learning relies on a fixed prompt token or an input-conditional token to fit a
small amount of data under full supervision. While this paradigm can generalize
to a certain range of unseen classes, it may struggle when domain gap
increases, such as in fine-grained classification and satellite image
segmentation. To address this limitation, we propose Retrieval-enhanced Prompt
learning (RePrompt), which introduces retrieval mechanisms to cache the
knowledge representations from downstream tasks. we first construct a retrieval
database from training examples, or from external examples when available. We
then integrate this retrieval-enhanced mechanism into various stages of a
simple prompt learning baseline. By referencing similar samples in the training
set, the enhanced model is better able to adapt to new tasks with few samples.
Our extensive experiments over 15 vision datasets, including 11 downstream
tasks with few-shot setting and 4 domain generalization benchmarks, demonstrate
that RePrompt achieves considerably improved performance. Our proposed approach
provides a promising solution to the challenges faced by prompt learning when
domain gap increases. The code and models will be available.
\\ ( https://arxiv.org/abs/2306.02243 ,  1175kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02245
Date: Sun, 4 Jun 2023 03:09:21 GMT   (2422kb,D)

Title: SAM3D: Zero-Shot 3D Object Detection via Segment Anything Model
Authors: Dingyuan Zhang, Dingkang Liang, Hongcheng Yang, Zhikang Zou, Xiaoqing
 Ye, Zhe Liu, Xiang Bai
Categories: cs.CV
Comments: Technical Report. The code is released at
 https://github.com/DYZhang09/SAM3D
\\
 With the development of large language models, many remarkable linguistic
systems like ChatGPT have thrived and achieved astonishing success on many
tasks, showing the incredible power of foundation models. In the spirit of
unleashing the capability of foundation models on vision tasks, the Segment
Anything Model (SAM), a vision foundation model for image segmentation, has
been proposed recently and presents strong zero-shot ability on many downstream
2D tasks. However, whether SAM can be adapted to 3D vision tasks has yet to be
explored, especially 3D object detection. With this inspiration, we explore
adapting the zero-shot ability of SAM to 3D object detection in this paper. We
propose a SAM-powered BEV processing pipeline to detect objects and get
promising results on the large-scale Waymo open dataset. As an early attempt,
our method takes a step toward 3D object detection with vision foundation
models and presents the opportunity to unleash their power on 3D vision tasks.
The code is released at https://github.com/DYZhang09/SAM3D.
\\ ( https://arxiv.org/abs/2306.02245 ,  2422kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02252
Date: Sun, 4 Jun 2023 03:51:54 GMT   (8500kb,D)

Title: MoviePuzzle: Visual Narrative Reasoning through Multimodal Order
 Learning
Authors: Jianghui Wang, Yuxuan Wang, Dongyan Zhao, Zilong Zheng
Categories: cs.CV
\\
 We introduce MoviePuzzle, a novel challenge that targets visual narrative
reasoning and holistic movie understanding. Despite the notable progress that
has been witnessed in the realm of video understanding, most prior works fail
to present tasks and models to address holistic video understanding and the
innate visual narrative structures existing in long-form videos. To tackle this
quandary, we put forth MoviePuzzle task that amplifies the temporal feature
learning and structure learning of video models by reshuffling the shot, frame,
and clip layers of movie segments in the presence of video-dialogue
information. We start by establishing a carefully refined dataset based on
MovieNet by dissecting movies into hierarchical layers and randomly permuting
the orders. Besides benchmarking the MoviePuzzle with prior arts on movie
understanding, we devise a Hierarchical Contrastive Movie Clustering (HCMC)
model that considers the underlying structure and visual semantic orders for
movie reordering. Specifically, through a pairwise and contrastive learning
approach, we train models to predict the correct order of each layer. This
equips them with the knack for deciphering the visual narrative structure of
movies and handling the disorder lurking in video data. Experiments show that
our approach outperforms existing state-of-the-art methods on the \MoviePuzzle
benchmark, underscoring its efficacy.
\\ ( https://arxiv.org/abs/2306.02252 ,  8500kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02268
Date: Sun, 4 Jun 2023 06:01:53 GMT   (23242kb,D)

Title: Revisiting Class Imbalance for End-to-end Semi-Supervised Object
 Detection
Authors: Purbayan Kar, Vishal Chudasama, Naoyuki Onoe, Pankaj Wasnik
Categories: cs.CV cs.AI cs.LG
Comments: Accepted at the Efficient Deep Learning for Computer Vision Workshop,
 CVPR 2023
\\
 Semi-supervised object detection (SSOD) has made significant progress with
the development of pseudo-label-based end-to-end methods. However, many of
these methods face challenges due to class imbalance, which hinders the
effectiveness of the pseudo-label generator. Furthermore, in the literature, it
has been observed that low-quality pseudo-labels severely limit the performance
of SSOD. In this paper, we examine the root causes of low-quality pseudo-labels
and present novel learning mechanisms to improve the label generation quality.
To cope with high false-negative and low precision rates, we introduce an
adaptive thresholding mechanism that helps the proposed network to filter out
optimal bounding boxes. We further introduce a Jitter-Bagging module to provide
accurate information on localization to help refine the bounding boxes.
Additionally, two new losses are introduced using the background and foreground
scores predicted by the teacher and student networks to improvise the
pseudo-label recall rate. Furthermore, our method applies strict supervision to
the teacher network by feeding strong & weak augmented data to generate robust
pseudo-labels so that it can detect small and complex objects. Finally, the
extensive experiments show that the proposed network outperforms
state-of-the-art methods on MS-COCO and Pascal VOC datasets and allows the
baseline network to achieve 100% supervised performance with much less (i.e.,
20%) labeled data.
\\ ( https://arxiv.org/abs/2306.02268 ,  23242kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02275
Date: Sun, 4 Jun 2023 06:42:09 GMT   (5118kb,D)

Title: USD: Unknown Sensitive Detector Empowered by Decoupled Objectness and
 Segment Anything Model
Authors: Yulin He, Wei Chen, Yusong Tan, Siqi Wang
Categories: cs.CV
\\
 Open World Object Detection (OWOD) is a novel and challenging computer vision
task that enables object detection with the ability to detect unknown objects.
Existing methods typically estimate the object likelihood with an additional
objectness branch, but ignore the conflict in learning objectness and
classification boundaries, which oppose each other on the semantic manifold and
training objective. To address this issue, we propose a simple yet effective
learning strategy, namely Decoupled Objectness Learning (DOL), which divides
the learning of these two boundaries into suitable decoder layers. Moreover,
detecting unknown objects comprehensively requires a large amount of
annotations, but labeling all unknown objects is both difficult and expensive.
Therefore, we propose to take advantage of the recent Large Vision Model (LVM),
specifically the Segment Anything Model (SAM), to enhance the detection of
unknown objects. Nevertheless, the output results of SAM contain noise,
including backgrounds and fragments, so we introduce an Auxiliary Supervision
Framework (ASF) that uses a pseudo-labeling and a soft-weighting strategies to
alleviate the negative impact of noise. Extensive experiments on popular
benchmarks, including Pascal VOC and MS COCO, demonstrate the effectiveness of
our approach. Our proposed Unknown Sensitive Detector (USD) outperforms the
recent state-of-the-art methods in terms of Unknown Recall, achieving
significant improvements of 14.3\%, 15.5\%, and 8.9\% on the M-OWODB, and
27.1\%, 29.1\%, and 25.1\% on the S-OWODB.
\\ ( https://arxiv.org/abs/2306.02275 ,  5118kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02277
Date: Sun, 4 Jun 2023 06:49:44 GMT   (3942kb,D)

Title: EfficientSRFace: An Efficient Network with Super-Resolution Enhancement
 for Accurate Face Detection
Authors: Guangtao Wang, Jun Li, Jie Xie, Jianhua Xu and Bo Yang
Categories: cs.CV
\\
 In face detection, low-resolution faces, such as numerous small faces of a
human group in a crowded scene, are common in dense face prediction tasks. They
usually contain limited visual clues and make small faces less distinguishable
from the other small objects, which poses great challenge to accurate face
detection. Although deep convolutional neural network has significantly
promoted the research on face detection recently, current deep face detectors
rarely take into account low-resolution faces and are still vulnerable to the
real-world scenarios where massive amount of low-resolution faces exist.
Consequently, they usually achieve degraded performance for low-resolution face
detection. In order to alleviate this problem, we develop an efficient detector
termed EfficientSRFace by introducing a feature-level super-resolution
reconstruction network for enhancing the feature representation capability of
the model. This module plays an auxiliary role in the training process, and can
be removed during the inference without increasing the inference time.
Extensive experiments on public benchmarking datasets, such as FDDB and WIDER
Face, show that the embedded image super-resolution module can significantly
improve the detection accuracy at the cost of a small amount of additional
parameters and computational overhead, while helping our model achieve
competitive performance compared with the state-of-the-arts methods.
\\ ( https://arxiv.org/abs/2306.02277 ,  3942kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02291
Date: Sun, 4 Jun 2023 07:50:38 GMT   (194kb,D)

Title: 3rd Place Solution for PVUW2023 VSS Track: A Large Model for Semantic
 Segmentation on VSPW
Authors: Shijie Chang, Zeqi Hao, Ben Kang, Xiaoqi Zhao, Jiawen Zhu, Zhenyu
 Chen, Lihe Zhang, Lu Zhang, Huchuan Lu
Categories: cs.CV
Comments: 3rd Place Solution for CVPR 2023 PVUW VSS Track
\\
 In this paper, we introduce 3rd place solution for PVUW2023 VSS track.
Semantic segmentation is a fundamental task in computer vision with numerous
real-world applications. We have explored various image-level visual backbones
and segmentation heads to tackle the problem of video semantic segmentation.
Through our experimentation, we find that InternImage-H as the backbone and
Mask2former as the segmentation head achieves the best performance. In
addition, we explore two post-precessing methods: CascadePSP and Segment
Anything Model (SAM). Ultimately, our approach obtains 62.60\% and 64.84\% mIoU
on the VSPW test set1 and final test set, respectively, securing the third
position in the PVUW2023 VSS track.
\\ ( https://arxiv.org/abs/2306.02291 ,  194kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02301
Date: Sun, 4 Jun 2023 08:53:28 GMT   (11575kb,D)

Title: rPPG-MAE: Self-supervised Pre-training with Masked Autoencoders for
 Remote Physiological Measurement
Authors: Xin Liu, Yuting Zhang, Zitong Yu, Hao Lu, Huanjing Yue, Jingyu Yang
Categories: cs.CV
\\
 Remote photoplethysmography (rPPG) is an important technique for perceiving
human vital signs, which has received extensive attention. For a long time,
researchers have focused on supervised methods that rely on large amounts of
labeled data. These methods are limited by the requirement for large amounts of
data and the difficulty of acquiring ground truth physiological signals. To
address these issues, several self-supervised methods based on contrastive
learning have been proposed. However, they focus on the contrastive learning
between samples, which neglect the inherent self-similar prior in physiological
signals and seem to have a limited ability to cope with noisy. In this paper, a
linear self-supervised reconstruction task was designed for extracting the
inherent self-similar prior in physiological signals. Besides, a specific
noise-insensitive strategy was explored for reducing the interference of motion
and illumination. The proposed framework in this paper, namely rPPG-MAE,
demonstrates excellent performance even on the challenging VIPL-HR dataset. We
also evaluate the proposed method on two public datasets, namely PURE and
UBFC-rPPG. The results show that our method not only outperforms existing
self-supervised methods but also exceeds the state-of-the-art (SOTA) supervised
methods. One important observation is that the quality of the dataset seems
more important than the size in self-supervised pre-training of rPPG. The
source code is released at https://github.com/linuxsino/rPPG-MAE.
\\ ( https://arxiv.org/abs/2306.02301 ,  11575kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02306
Date: Sun, 4 Jun 2023 09:03:05 GMT   (80121kb,D)

Title: Cross-CBAM: A Lightweight network for Scene Segmentation
Authors: Zhengbin Zhang, Zhenhao Xu, Xingsheng Gu, Juan Xiong
Categories: cs.CV cs.LG eess.IV
\\
 Scene parsing is a great challenge for real-time semantic segmentation.
Although traditional semantic segmentation networks have made remarkable
leap-forwards in semantic accuracy, the performance of inference speed is
unsatisfactory. Meanwhile, this progress is achieved with fairly large networks
and powerful computational resources. However, it is difficult to run extremely
large models on edge computing devices with limited computing power, which
poses a huge challenge to the real-time semantic segmentation tasks. In this
paper, we present the Cross-CBAM network, a novel lightweight network for
real-time semantic segmentation. Specifically, a Squeeze-and-Excitation Atrous
Spatial Pyramid Pooling Module(SE-ASPP) is proposed to get variable
field-of-view and multiscale information. And we propose a Cross Convolutional
Block Attention Module(CCBAM), in which a cross-multiply operation is employed
in the CCBAM module to make high-level semantic information guide low-level
detail information. Different from previous work, these works use attention to
focus on the desired information in the backbone. CCBAM uses cross-attention
for feature fusion in the FPN structure. Extensive experiments on the
Cityscapes dataset and Camvid dataset demonstrate the effectiveness of the
proposed Cross-CBAM model by achieving a promising trade-off between
segmentation accuracy and inference speed. On the Cityscapes test set, we
achieve 73.4% mIoU with a speed of 240.9FPS and 77.2% mIoU with a speed of
88.6FPS on NVIDIA GTX 1080Ti.
\\ ( https://arxiv.org/abs/2306.02306 ,  80121kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02314
Date: Sun, 4 Jun 2023 09:40:25 GMT   (9377kb,D)

Title: Using Unreliable Pseudo-Labels for Label-Efficient Semantic Segmentation
Authors: Haochen Wang and Yuchao Wang and Yujun Shen and Junsong Fan and Yuxi
 Wang and Zhaoxiang Zhang
Categories: cs.CV
\\
 The crux of label-efficient semantic segmentation is to produce high-quality
pseudo-labels to leverage a large amount of unlabeled or weakly labeled data. A
common practice is to select the highly confident predictions as the
pseudo-ground-truths for each pixel, but it leads to a problem that most pixels
may be left unused due to their unreliability. However, we argue that every
pixel matters to the model training, even those unreliable and ambiguous
pixels. Intuitively, an unreliable prediction may get confused among the top
classes, however, it should be confident about the pixel not belonging to the
remaining classes. Hence, such a pixel can be convincingly treated as a
negative key to those most unlikely categories. Therefore, we develop an
effective pipeline to make sufficient use of unlabeled data. Concretely, we
separate reliable and unreliable pixels via the entropy of predictions, push
each unreliable pixel to a category-wise queue that consists of negative keys,
and manage to train the model with all candidate pixels. Considering the
training evolution, we adaptively adjust the threshold for the
reliable-unreliable partition. Experimental results on various benchmarks and
training settings demonstrate the superiority of our approach over the
state-of-the-art alternatives.
\\ ( https://arxiv.org/abs/2306.02314 ,  9377kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02316
Date: Sun, 4 Jun 2023 09:49:43 GMT   (16220kb,D)

Title: Temporal Dynamic Quantization for Diffusion Models
Authors: Junhyuk So, Jungwon Lee, Daehyun Ahn, Hyungjun Kim, Eunhyeok Park
Categories: cs.CV
\\
 The diffusion model has gained popularity in vision applications due to its
remarkable generative performance and versatility. However, high storage and
computation demands, resulting from the model size and iterative generation,
hinder its use on mobile devices. Existing quantization techniques struggle to
maintain performance even in 8-bit precision due to the diffusion model's
unique property of temporal variation in activation. We introduce a novel
quantization method that dynamically adjusts the quantization interval based on
time step information, significantly improving output quality. Unlike
conventional dynamic quantization techniques, our approach has no computational
overhead during inference and is compatible with both post-training
quantization (PTQ) and quantization-aware training (QAT). Our extensive
experiments demonstrate substantial improvements in output quality with the
quantized diffusion model across various datasets.
\\ ( https://arxiv.org/abs/2306.02316 ,  16220kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02329
Date: Sun, 4 Jun 2023 11:08:53 GMT   (23272kb,D)

Title: Multi-CLIP: Contrastive Vision-Language Pre-training for Question
 Answering tasks in 3D Scenes
Authors: Alexandros Delitzas, Maria Parelli, Nikolas Hars, Georgios Vlassis,
 Sotirios Anagnostidis, Gregor Bachmann, Thomas Hofmann
Categories: cs.CV
Comments: The first two authors contributed equally
\\
 Training models to apply common-sense linguistic knowledge and visual
concepts from 2D images to 3D scene understanding is a promising direction that
researchers have only recently started to explore. However, it still remains
understudied whether 2D distilled knowledge can provide useful representations
for downstream 3D vision-language tasks such as 3D question answering. In this
paper, we propose a novel 3D pre-training Vision-Language method, namely
Multi-CLIP, that enables a model to learn language-grounded and transferable 3D
scene point cloud representations. We leverage the representational power of
the CLIP model by maximizing the agreement between the encoded 3D scene
features and the corresponding 2D multi-view image and text embeddings in the
CLIP space via a contrastive objective. To validate our approach, we consider
the challenging downstream tasks of 3D Visual Question Answering (3D-VQA) and
3D Situated Question Answering (3D-SQA). To this end, we develop novel
multi-modal transformer-based architectures and we demonstrate how our
pre-training method can benefit their performance. Quantitative and qualitative
experimental results show that Multi-CLIP outperforms state-of-the-art works
across the downstream tasks of 3D-VQA and 3D-SQA and leads to a well-structured
3D scene feature space.
\\ ( https://arxiv.org/abs/2306.02329 ,  23272kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02346
Date: Sun, 4 Jun 2023 12:42:45 GMT   (756kb,D)

Title: CDLT: A Dataset with Concept Drift and Long-Tailed Distribution for
 Fine-Grained Visual Categorization
Authors: Shuo Ye and Yufeng Shi and Ruxin Wang and Yu Wang and Jiamiao Xu and
 Chuanwu Yang and Xinge You
Categories: cs.CV
\\
 Data is the foundation for the development of computer vision, and the
establishment of datasets plays an important role in advancing the techniques
of fine-grained visual categorization~(FGVC). In the existing FGVC datasets
used in computer vision, it is generally assumed that each collected instance
has fixed characteristics and the distribution of different categories is
relatively balanced. In contrast, the real world scenario reveals the fact that
the characteristics of instances tend to vary with time and exhibit a
long-tailed distribution. Hence, the collected datasets may mislead the
optimization of the fine-grained classifiers, resulting in unpleasant
performance in real applications. Starting from the real-world conditions and
to promote the practical progress of fine-grained visual categorization, we
present a Concept Drift and Long-Tailed Distribution dataset. Specifically, the
dataset is collected by gathering 11195 images of 250 instances in different
species for 47 consecutive months in their natural contexts. The collection
process involves dozens of crowd workers for photographing and domain experts
for labelling. Extensive baseline experiments using the state-of-the-art
fine-grained classification models demonstrate the issues of concept drift and
long-tailed distribution existed in the dataset, which require the attention of
future researches.
\\ ( https://arxiv.org/abs/2306.02346 ,  756kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02351
Date: Sun, 4 Jun 2023 13:01:19 GMT   (8951kb,D)

Title: RSSOD-Bench: A large-scale benchmark dataset for Salient Object
 Detection in Optical Remote Sensing Imagery
Authors: Zhitong Xiong, Yanfeng Liu, Qi Wang, Xiao Xiang Zhu
Categories: cs.CV
Comments: IGARSS 2023, 4 pages
\\
 We present the RSSOD-Bench dataset for salient object detection (SOD) in
optical remote sensing imagery. While SOD has achieved success in natural scene
images with deep learning, research in SOD for remote sensing imagery (RSSOD)
is still in its early stages. Existing RSSOD datasets have limitations in terms
of scale, and scene categories, which make them misaligned with real-world
applications. To address these shortcomings, we construct the RSSOD-Bench
dataset, which contains images from four different cities in the USA. The
dataset provides annotations for various salient object categories, such as
buildings, lakes, rivers, highways, bridges, aircraft, ships, athletic fields,
and more. The salient objects in RSSOD-Bench exhibit large-scale variations,
cluttered backgrounds, and different seasons. Unlike existing datasets,
RSSOD-Bench offers uniform distribution across scene categories. We benchmark
23 different state-of-the-art approaches from both the computer vision and
remote sensing communities. Experimental results demonstrate that more research
efforts are required for the RSSOD task.
\\ ( https://arxiv.org/abs/2306.02351 ,  8951kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02374
Date: Sun, 4 Jun 2023 15:14:20 GMT   (706kb)

Title: GAN-based Deidentification of Drivers' Face Videos: An Assessment of
 Human Factors Implications in NDS Data
Authors: Surendrabikram Thapa and Abhijit Sarkar
Categories: cs.CV
Comments: Accepted in IEEE IV 2023
\\
 This paper addresses the problem of sharing drivers' face videos for
transportation research while adhering to proper ethical guidelines. The paper
first gives an overview of the multitude of problems associated with sharing
such data and then proposes a framework on how artificial intelligence-based
techniques, specifically face swapping, can be used for de-identifying drivers'
faces. Through extensive experimentation with an Oak Ridge National Laboratory
(ORNL) dataset, we demonstrate the effectiveness of face-swapping algorithms in
preserving essential attributes related to human factors research, including
eye movements, head movements, and mouth movements. The efficacy of the
framework was also tested on various naturalistic driving study data collected
at the Virginia Tech Transportation Institute. The results achieved through the
proposed techniques were evaluated qualitatively and quantitatively using
various metrics. Finally, we discuss possible measures for sharing the
de-identified videos with the greater research community.
\\ ( https://arxiv.org/abs/2306.02374 ,  706kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02395
Date: Sun, 4 Jun 2023 16:11:45 GMT   (4378kb,D)

Title: NICE-SLAM with Adaptive Feature Grids
Authors: Ganlin Zhang, Deheng Zhang, Feichi Lu, Anqi Li
Categories: cs.CV cs.GR
Comments: Course project of 3D Vision at ETH Zurich
\\
 NICE-SLAM is a dense visual SLAM system that combines the advantages of
neural implicit representations and hierarchical grid-based scene
representation. However, the hierarchical grid features are densely stored,
leading to memory explosion problems when adapting the framework to large
scenes. In our project, we present sparse NICE-SLAM, a sparse SLAM system
incorporating the idea of Voxel Hashing into NICE-SLAM framework. Instead of
initializing feature grids in the whole space, voxel features near the surface
are adaptively added and optimized. Experiments demonstrated that compared to
NICE-SLAM algorithm, our approach takes much less memory and achieves
comparable reconstruction quality on the same datasets. Our implementation is
available at
https://github.com/zhangganlin/NICE-SLAM-with-Adaptive-Feature-Grids.
\\ ( https://arxiv.org/abs/2306.02395 ,  4378kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02398
Date: Sun, 4 Jun 2023 16:17:19 GMT   (3296kb,D)

Title: Scale Guided Hypernetwork for Blind Super-Resolution Image Quality
 Assessment
Authors: Jun Fu
Categories: cs.CV eess.IV
Comments: new framework for blind super-resolution image quality assessment
\\
 With the emergence of image super-resolution (SR) algorithm, how to blindly
evaluate the quality of super-resolution images has become an urgent task.
However, existing blind SR image quality assessment (IQA) metrics merely focus
on visual characteristics of super-resolution images, ignoring the available
scale information. In this paper, we reveal that the scale factor has a
statistically significant impact on subjective quality scores of SR images,
indicating that the scale information can be used to guide the task of blind SR
IQA. Motivated by this, we propose a scale guided hypernetwork framework that
evaluates SR image quality in a scale-adaptive manner. Specifically, the blind
SR IQA procedure is divided into three stages, i.e., content perception,
evaluation rule generation, and quality prediction. After content perception, a
hypernetwork generates the evaluation rule used in quality prediction based on
the scale factor of the SR image. We apply the proposed scale guided
hypernetwork framework to existing representative blind IQA metrics, and
experimental results show that the proposed framework not only boosts the
performance of these IQA metrics but also enhances their generalization
abilities. Source code will be available at https://github.com/JunFu1995/SGH.
\\ ( https://arxiv.org/abs/2306.02398 ,  3296kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02407
Date: Sun, 4 Jun 2023 16:55:38 GMT   (11201kb,D)

Title: Heteroskedastic Geospatial Tracking with Distributed Camera Networks
Authors: Colin Samplawski, Shiwei Fang, Ziqi Wang, Deepak Ganesan, Mani
 Srivastava, Benjamin M. Marlin
Categories: cs.CV cs.AI cs.DC cs.LG
\\
 Visual object tracking has seen significant progress in recent years.
However, the vast majority of this work focuses on tracking objects within the
image plane of a single camera and ignores the uncertainty associated with
predicted object locations. In this work, we focus on the geospatial object
tracking problem using data from a distributed camera network. The goal is to
predict an object's track in geospatial coordinates along with uncertainty over
the object's location while respecting communication constraints that prohibit
centralizing raw image data. We present a novel single-object geospatial
tracking data set that includes high-accuracy ground truth object locations and
video data from a network of four cameras. We present a modeling framework for
addressing this task including a novel backbone model and explore how
uncertainty calibration and fine-tuning through a differentiable tracker affect
performance.
\\ ( https://arxiv.org/abs/2306.02407 ,  11201kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02416
Date: Sun, 4 Jun 2023 17:39:08 GMT   (4381kb,D)

Title: Training Like a Medical Resident: Universal Medical Image Segmentation
 via Context Prior Learning
Authors: Yunhe Gao, Zhuowei Li, Di Liu, Mu Zhou, Shaoting Zhang, Dimitris N.
 Meta
Categories: cs.CV
\\
 A major enduring focus of clinical workflows is disease analytics and
diagnosis, leading to medical imaging datasets where the modalities and
annotations are strongly tied to specific clinical objectives. To date,
building task-specific segmentation models is intuitive yet a restrictive
approach, lacking insights gained from widespread imaging cohorts. Inspired by
the training of medical residents, we explore universal medical image
segmentation, whose goal is to learn from diverse medical imaging sources
covering a range of clinical targets, body regions, and image modalities.
Following this paradigm, we propose Hermes, a context prior learning approach
that addresses the challenges related to the heterogeneity on data, modality,
and annotations in the proposed universal paradigm. In a collection of seven
diverse datasets, we demonstrate the appealing merits of the universal paradigm
over the traditional task-specific training paradigm. By leveraging the synergy
among various tasks, Hermes shows superior performance and model scalability.
Our in-depth investigation on two additional datasets reveals Hermes' strong
capabilities for transfer learning, incremental learning, and generalization to
different downstream tasks. The code is available:
https://github.com/yhygao/universal-medical-image-segmentation.
\\ ( https://arxiv.org/abs/2306.02416 ,  4381kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02424
Date: Sun, 4 Jun 2023 17:57:51 GMT   (8532kb,D)

Title: Sanity Checks for Saliency Methods Explaining Object Detectors
Authors: Deepan Chakravarthi Padmanabhan, Paul G. Pl\"oger, Octavio Arriaga,
 Matias Valdenegro-Toro
Categories: cs.CV cs.LG
Comments: 18 pages, 10 figures, 1st World Conference on eXplainable Artificial
 Intelligence camera ready
\\
 Saliency methods are frequently used to explain Deep Neural Network-based
models. Adebayo et al.'s work on evaluating saliency methods for classification
models illustrate certain explanation methods fail the model and data
randomization tests. However, on extending the tests for various state of the
art object detectors we illustrate that the ability to explain a model is more
dependent on the model itself than the explanation method. We perform sanity
checks for object detection and define new qualitative criteria to evaluate the
saliency explanations, both for object classification and bounding box
decisions, using Guided Backpropagation, Integrated Gradients, and their
Smoothgrad versions, together with Faster R-CNN, SSD, and EfficientDet-D0,
trained on COCO. In addition, the sensitivity of the explanation method to
model parameters and data labels varies class-wise motivating to perform the
sanity checks for each class. We find that EfficientDet-D0 is the most
interpretable method independent of the saliency method, which passes the
sanity checks with little problems.
\\ ( https://arxiv.org/abs/2306.02424 ,  8532kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02443
Date: Sun, 4 Jun 2023 19:14:44 GMT   (6684kb,D)

Title: ESTISR: Adapting Efficient Scene Text Image Super-resolution for
 Real-Scenes
Authors: Minghao Fu, Xin Man, Yihan Xu, Jie Shao
Categories: cs.CV
\\
 While scene text image super-resolution (STISR) has yielded remarkable
improvements in accurately recognizing scene text, prior methodologies have
placed excessive emphasis on optimizing performance, rather than paying due
attention to efficiency - a crucial factor in ensuring deployment of the
STISR-STR pipeline. In this work, we propose a novel Efficient Scene Text Image
Super-resolution (ESTISR) Network for resource-limited deployment platform.
ESTISR's functionality primarily depends on two critical components: a
CNN-based feature extractor and an efficient self-attention mechanism used for
decoding low-resolution images. We designed a re-parameterized inverted
residual block specifically suited for resource-limited circumstances as the
feature extractor. Meanwhile, we proposed a novel self-attention mechanism,
softmax shrinking, based on a kernel-based approach. This innovative technique
offers linear complexity while also naturally incorporating discriminating
low-level features into the self-attention structure. Extensive experiments on
TextZoom show that ESTISR retains a high image restoration quality and improved
STR accuracy of low-resolution images. Furthermore, ESTISR consistently
outperforms current methods in terms of actual running time and peak memory
consumption, while achieving a better trade-off between performance and
efficiency.
\\ ( https://arxiv.org/abs/2306.02443 ,  6684kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02500
Date: Sun, 4 Jun 2023 22:47:17 GMT   (2194kb,D)

Title: Systematic Visual Reasoning through Object-Centric Relational
 Abstraction
Authors: Taylor W. Webb, Shanka Subhra Mondal, Jonathan D. Cohen
Categories: cs.CV
\\
 Human visual reasoning is characterized by an ability to identify abstract
patterns from only a small number of examples, and to systematically generalize
those patterns to novel inputs. This capacity depends in large part on our
ability to represent complex visual inputs in terms of both objects and
relations. Recent work in computer vision has introduced models with the
capacity to extract object-centric representations, leading to the ability to
process multi-object visual inputs, but falling short of the systematic
generalization displayed by human reasoning. Other recent models have employed
inductive biases for relational abstraction to achieve systematic
generalization of learned abstract rules, but have generally assumed the
presence of object-focused inputs. Here, we combine these two approaches,
introducing Object-Centric Relational Abstraction (OCRA), a model that extracts
explicit representations of both objects and abstract relations, and achieves
strong systematic generalization in tasks involving complex visual displays.
\\ ( https://arxiv.org/abs/2306.02500 ,  2194kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02507
Date: Sun, 4 Jun 2023 23:56:53 GMT   (24537kb,D)

Title: Deep learning powered real-time identification of insects using citizen
 science data
Authors: Shivani Chiranjeevi, Mojdeh Sadaati, Zi K Deng, Jayanth Koushik,
 Talukder Z Jubery, Daren Mueller, Matthew E O Neal, Nirav Merchant, Aarti
 Singh, Asheesh K Singh, Soumik Sarkar, Arti Singh, Baskar
 Ganapathysubramanian
Categories: cs.CV
\\
 Insect-pests significantly impact global agricultural productivity and
quality. Effective management involves identifying the full insect community,
including beneficial insects and harmful pests, to develop and implement
integrated pest management strategies. Automated identification of insects
under real-world conditions presents several challenges, including
differentiating similar-looking species, intra-species dissimilarity and
inter-species similarity, several life cycle stages, camouflage, diverse
imaging conditions, and variability in insect orientation. A deep-learning
model, InsectNet, is proposed to address these challenges. InsectNet is endowed
with five key features: (a) utilization of a large dataset of insect images
collected through citizen science; (b) label-free self-supervised learning for
large models; (c) improving prediction accuracy for species with a small sample
size; (d) enhancing model trustworthiness; and (e) democratizing access through
streamlined MLOps. This approach allows accurate identification (>96% accuracy)
of over 2500 insect species, including pollinator (e.g., butterflies, bees),
parasitoid (e.g., some wasps and flies), predator species (e.g., lady beetles,
mantises, dragonflies) and harmful pest species (e.g., armyworms, cutworms,
grasshoppers, stink bugs). InsectNet can identify invasive species, provide
fine-grained insect species identification, and work effectively in challenging
backgrounds. It also can abstain from making predictions when uncertain,
facilitating seamless human intervention and making it a practical and
trustworthy tool. InsectNet can guide citizen science data collection,
especially for invasive species where early detection is crucial. Similar
approaches may transform other agricultural challenges like disease detection
and underscore the importance of data collection, particularly through citizen
science efforts..
\\ ( https://arxiv.org/abs/2306.02507 ,  24537kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02517
Date: Mon, 5 Jun 2023 00:44:39 GMT   (17653kb,D)

Title: Disaster Anomaly Detector via Deeper FCDDs for Explainable Initial
 Responses
Authors: Takato Yasuno, Masahiro Okano and Junichiro Fujii
Categories: cs.CV
Comments: 10 pages, 12 figures, 9 tables. arXiv admin note: substantial text
 overlap with arXiv:2305.05103
ACM-class: I.2.10; I.4.9; I.5.4
\\
 Urban and rural areas can often be devastated by extreme natural disasters.
Towards any disaster event, an initial response is the key to rescuing within
72 hours and prompt recovery. For the stage of initial responses, it is
important to quickly recognize the disaster damage over a wide area and
determine priority areas. Among machine learning algorithms, deep anomaly
detection is effective in detecting devastated features that are different from
ordinary vision everyday life. In addition, explainable computer vision
applications have been expected to justify the initial responses. In this
paper, we propose an anomaly detection application utilizing the deeper
fully-convolutional data descriptions (FCDDs), that enables to localize
devastated features and visualize damage-marked heatmaps. More concretely, we
show numerous training and test results to a dataset AIDER with the four
disaster categories: collapsed buildings, traffic accidents, fires, and
flooding areas. We also implement ablation studies of anomalous class imbalance
and the data scale competing against the normal class. Finally, we discuss
future works to improve more robust, explainable applications for effective
initial responses.
\\ ( https://arxiv.org/abs/2306.02517 ,  17653kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02544
Date: Mon, 5 Jun 2023 02:29:38 GMT   (4920kb,D)

Title: Fourier Test-time Adaptation with Multi-level Consistency for Robust
 Classification
Authors: Yuhao Huang, Xin Yang, Xiaoqiong Huang, Xinrui Zhou, Haozhe Chi,
 Haoran Dou, Xindi Hu, Jian Wang, Xuedong Deng, Dong Ni
Categories: cs.CV
Comments: Accepted by MICCAI 2023
\\
 Deep classifiers may encounter significant performance degradation when
processing unseen testing data from varying centers, vendors, and protocols.
Ensuring the robustness of deep models against these domain shifts is crucial
for their widespread clinical application. In this study, we propose a novel
approach called Fourier Test-time Adaptation (FTTA), which employs a
dual-adaptation design to integrate input and model tuning, thereby jointly
improving the model robustness. The main idea of FTTA is to build a reliable
multi-level consistency measurement of paired inputs for achieving
self-correction of prediction. Our contribution is two-fold. First, we
encourage consistency in global features and local attention maps between the
two transformed images of the same input. Here, the transformation refers to
Fourier-based input adaptation, which can transfer one unseen image into source
style to reduce the domain gap. Furthermore, we leverage style-interpolated
images to enhance the global and local features with learnable parameters,
which can smooth the consistency measurement and accelerate convergence.
Second, we introduce a regularization technique that utilizes style
interpolation consistency in the frequency space to encourage self-consistency
in the logit space of the model output. This regularization provides strong
self-supervised signals for robustness enhancement. FTTA was extensively
validated on three large classification datasets with different modalities and
organs. Experimental results show that FTTA is general and outperforms other
strong state-of-the-art methods.
\\ ( https://arxiv.org/abs/2306.02544 ,  4920kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02548
Date: Mon, 5 Jun 2023 02:50:06 GMT   (7604kb,D)

Title: Inflated 3D Convolution-Transformer for Weakly-supervised Carotid
 Stenosis Grading with Ultrasound Videos
Authors: Xinrui Zhou, Yuhao Huang, Wufeng Xue, Xin Yang, Yuxin Zou, Qilong
 Ying, Yuanji Zhang, Jia Liu, Jie Ren, Dong Ni
Categories: cs.CV
Comments: Accepted by MICCAI 2023
\\
 Localization of the narrowest position of the vessel and corresponding vessel
and remnant vessel delineation in carotid ultrasound (US) are essential for
carotid stenosis grading (CSG) in clinical practice. However, the pipeline is
time-consuming and tough due to the ambiguous boundaries of plaque and temporal
variation. To automatize this procedure, a large number of manual delineations
are usually required, which is not only laborious but also not reliable given
the annotation difficulty. In this study, we present the first video
classification framework for automatic CSG. Our contribution is three-fold.
First, to avoid the requirement of laborious and unreliable annotation, we
propose a novel and effective video classification network for
weakly-supervised CSG. Second, to ease the model training, we adopt an
inflation strategy for the network, where pre-trained 2D convolution weights
can be adapted into the 3D counterpart in our network. In this way, the
existing pre-trained large model can be used as an effective warm start for our
network. Third, to enhance the feature discrimination of the video, we propose
a novel attention-guided multi-dimension fusion (AMDF) transformer encoder to
model and integrate global dependencies within and across spatial and temporal
dimensions, where two lightweight cross-dimensional attention mechanisms are
designed. Our approach is extensively validated on a large clinically collected
carotid US video dataset, demonstrating state-of-the-art performance compared
with strong competitors.
\\ ( https://arxiv.org/abs/2306.02548 ,  7604kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02558
Date: Mon, 5 Jun 2023 03:14:54 GMT   (1794kb,D)

Title: Learning from Multi-View Representation for Point-Cloud Pre-Training
Authors: Siming Yan, Chen Song, Youkang Kong, Qixing Huang
Categories: cs.CV
Comments: 14 pages, 5 figures
\\
 A critical problem in the pre-training of 3D point clouds is leveraging
massive 2D data. A fundamental challenge is to address the 2D-3D domain gap.
This paper proposes a novel approach to point-cloud pre-training that enables
learning 3D representations by leveraging pre-trained 2D-based networks. In
particular, it avoids overfitting to 2D representations and potentially
discarding critical 3D features for 3D recognition tasks. The key to our
approach is a novel multi-view representation, which learns a shared 3D feature
volume consistent with deep features extracted from multiple 2D camera views.
The 2D deep features are regularized using pre-trained 2D networks through the
2D knowledge transfer loss. To prevent the resulting 3D feature representations
from discarding 3D signals, we introduce the multi-view consistency loss that
forces the projected 2D feature representations to capture pixel-wise
correspondences across different views. Such correspondences induce 3D geometry
and effectively retain 3D features in the projected 2D features. Experimental
results demonstrate that our pre-trained model can be successfully transferred
to various downstream tasks, including 3D detection and semantic segmentation,
and achieve state-of-the-art performance.
\\ ( https://arxiv.org/abs/2306.02558 ,  1794kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02562
Date: Mon, 5 Jun 2023 03:32:27 GMT   (7880kb,D)

Title: Video Diffusion Models with Local-Global Context Guidance
Authors: Siyuan Yang, Lu Zhang, Yu Liu, Zhizhuo Jiang and You He
Categories: cs.CV
Comments: Accepted for publication at IJCAI 2023. To appear
\\
 Diffusion models have emerged as a powerful paradigm in video synthesis tasks
including prediction, generation, and interpolation. Due to the limitation of
the computational budget, existing methods usually implement conditional
diffusion models with an autoregressive inference pipeline, in which the future
fragment is predicted based on the distribution of adjacent past frames.
However, only the conditions from a few previous frames can't capture the
global temporal coherence, leading to inconsistent or even outrageous results
in long-term video prediction. In this paper, we propose a Local-Global Context
guided Video Diffusion model (LGC-VD) to capture multi-perception conditions
for producing high-quality videos in both conditional/unconditional settings.
In LGC-VD, the UNet is implemented with stacked residual blocks with
self-attention units, avoiding the undesirable computational cost in 3D Conv.
We construct a local-global context guidance strategy to capture the
multi-perceptual embedding of the past fragment to boost the consistency of
future prediction. Furthermore, we propose a two-stage training strategy to
alleviate the effect of noisy frames for more stable predictions. Our
experiments demonstrate that the proposed method achieves favorable performance
on video prediction, interpolation, and unconditional video generation. We
release code at https://github.com/exisas/LGC-VD.
\\ ( https://arxiv.org/abs/2306.02562 ,  7880kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02577
Date: Mon, 5 Jun 2023 04:00:39 GMT   (9514kb,D)

Title: Exploring the Role of the Bottleneck in Slot-Based Models Through
 Covariance Regularization
Authors: Andrew Stange, Robert Lo, Abishek Sridhar, Kousik Rajesh
Categories: cs.CV cs.AI cs.LG
Comments: 14 pages, 10 figures
\\
 In this project we attempt to make slot-based models with an image
reconstruction objective competitive with those that use a feature
reconstruction objective on real world datasets. We propose a loss-based
approach to constricting the bottleneck of slot-based models, allowing
larger-capacity encoder networks to be used with Slot Attention without
producing degenerate stripe-shaped masks. We find that our proposed method
offers an improvement over the baseline Slot Attention model but does not reach
the performance of \dinosaur on the COCO2017 dataset. Throughout this project,
we confirm the superiority of a feature reconstruction objective over an image
reconstruction objective and explore the role of the architectural bottleneck
in slot-based models.
\\ ( https://arxiv.org/abs/2306.02577 ,  9514kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02582
Date: Mon, 5 Jun 2023 04:21:00 GMT   (2923kb,D)

Title: Learning from Noisy Labels Generated by Extremely Point Annotations for
 OCT Fluid Segmentation
Authors: Tengjin Weng, Yang Shen, Kai Jin, Zhiming Cheng, Yunxiang Li, Gewen
 Zhang, and Shuai Wang
Categories: cs.CV
Comments: Submission to IEEE Transactions on Biomedical Engineering
\\
 Automatic segmentation of fluid in OCT (Optical Coherence Tomography) images
is beneficial for ophthalmologists to make an accurate diagnosis. Currently,
data-driven convolutional neural networks (CNNs) have achieved great success in
OCT fluid segmentation. However, obtaining pixel-level masks of OCT images is
time-consuming and requires expertise. The popular weakly-supervised strategy
is to generate noisy pseudo-labels from weak annotations, but the noise
information introduced may mislead the model training. To address this issue,
(i) we propose a superpixel-guided method for generating noisy labels from weak
point annotations, called Point to Noisy by Superpixel (PNS), which limits the
network from over-fitting noise by assigning low confidence to suspiciously
noisy label pixels, and (ii) we propose a Two-Stage Mean-Teacher-assisted
Confident Learning (2SMTCL) method based on MTCL for multi-category OCT fluid
segmentation, which alleviates the uncertainty and computing power consumption
introduced by the real-time characterization noise of MTCL. For evaluation, we
have constructed a 2D OCT fluid segmentation dataset. Compared with other
state-of-art label-denoising methods, comprehensive experimental results
demonstrate that the proposed method can achieve excellent performance in OCT
fluid segmentation as well as label denoising. Our study provides an efficient,
accurate, and practical solution for fluid segmentation of OCT images, which is
expected to have a positive impact on the diagnosis and treatment of patients
in the field of ophthalmology.
\\ ( https://arxiv.org/abs/2306.02582 ,  2923kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02583
Date: Mon, 5 Jun 2023 04:21:43 GMT   (47678kb,D)

Title: Stable Diffusion is Untable
Authors: Chengbin Du, Yanxi Li, Zhongwei Qiu, Chang Xu
Categories: cs.CV
Comments: 22 pages, 20 figures
\\
 Recently, text-to-image models have been thriving. Despite their powerful
generative capacity, our research has uncovered a lack of robustness in this
generation process. Specifically, the introduction of small perturbations to
the text prompts can result in the blending of primary subjects with other
categories or their complete disappearance in the generated images. In this
paper, we propose Auto-attack on Text-to-image Models (ATM), a gradient-based
approach, to effectively and efficiently generate such perturbations. By
learning a Gumbel Softmax distribution, we can make the discrete process of
word replacement or extension continuous, thus ensuring the differentiability
of the perturbation generation. Once the distribution is learned, ATM can
sample multiple attack samples simultaneously. These attack samples can prevent
the generative model from generating the desired subjects without compromising
image quality. ATM has achieved a 91.1% success rate in short-text attacks and
an 81.2% success rate in long-text attacks. Further empirical analysis revealed
four attack patterns based on: 1) the variability in generation speed, 2) the
similarity of coarse-grained characteristics, 3) the polysemy of words, and 4)
the positioning of words.
\\ ( https://arxiv.org/abs/2306.02583 ,  47678kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02585
Date: Mon, 5 Jun 2023 04:24:11 GMT   (5874kb,D)

Title: MotionTrack: Learning Motion Predictor for Multiple Object Tracking
Authors: Changcheng Xiao, Qiong Cao, Yujie Zhong, Long Lan, Xiang Zhang, Huayue
 Cai, Zhigang Luo, Dacheng Tao
Categories: cs.CV
\\
 Significant advancements have been made in multi-object tracking (MOT) with
the development of detection and re-identification (ReID) techniques. Despite
these developments, the task of accurately tracking objects in scenarios with
homogeneous appearance and heterogeneous motion remains challenging due to the
insufficient discriminability of ReID features and the predominant use of
linear motion models in MOT. In this context, we present a novel learnable
motion predictor, named MotionTrack, which comprehensively incorporates two
levels of granularity of motion features to enhance the modeling of temporal
dynamics and facilitate accurate future motion prediction of individual
objects. Specifically, the proposed approach adopts a self-attention mechanism
to capture token-level information and a Dynamic MLP layer to model
channel-level features. MotionTrack is a simple, online tracking approach. Our
experimental results demonstrate that MotionTrack yields state-of-the-art
performance on demanding datasets such as SportsMOT and Dancetrack, which
feature highly nonlinear object motion. Notably, without fine-tuning on target
datasets, MotionTrack also exhibits competitive performance on conventional
benchmarks including MOT17 and MOT20.
\\ ( https://arxiv.org/abs/2306.02585 ,  5874kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02589
Date: Mon, 5 Jun 2023 04:33:32 GMT   (16561kb,D)

Title: DAGrid: Directed Accumulator Grid
Authors: Hang Zhang, Renjiu Hu, Xiang Chen, Rongguang Wang, Jinwei Zhang, and
 Jiahao Li
Categories: cs.CV cs.AI eess.IV eess.SP
Comments: 19 pages, 9 figures, 4 tables
\\
 Recent research highlights that the Directed Accumulator (DA), through its
parametrization of geometric priors into neural networks, has notably improved
the performance of medical image recognition, particularly with small and
imbalanced datasets. However, DA's potential in pixel-wise dense predictions is
unexplored. To bridge this gap, we present the Directed Accumulator Grid
(DAGrid), which allows geometric-preserving filtering in neural networks, thus
broadening the scope of DA's applications to include pixel-level dense
prediction tasks. DAGrid utilizes homogeneous data types in conjunction with
designed sampling grids to construct geometrically transformed representations,
retaining intricate geometric information and promoting long-range information
propagation within the neural networks. Contrary to its symmetric counterpart,
grid sampling, which might lose information in the sampling process, DAGrid
aggregates all pixels, ensuring a comprehensive representation in the
transformed space. The parallelization of DAGrid on modern GPUs is facilitated
using CUDA programming, and also back propagation is enabled for deep neural
network training. Empirical results show DAGrid-enhanced neural networks excel
in supervised skin lesion segmentation and unsupervised cardiac image
registration. Specifically, the network incorporating DAGrid has realized a
70.8% reduction in network parameter size and a 96.8% decrease in FLOPs, while
concurrently improving the Dice score for skin lesion segmentation by 1.0%
compared to state-of-the-art transformers. Furthermore, it has achieved
improvements of 4.4% and 8.2% in the average Dice score and Dice score of the
left ventricular mass, respectively, indicating an increase in registration
accuracy for cardiac images. The source code is available at
https://github.com/tinymilky/DeDA.
\\ ( https://arxiv.org/abs/2306.02589 ,  16561kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02602
Date: Mon, 5 Jun 2023 05:21:15 GMT   (28544kb,D)

Title: ReContrast: Domain-Specific Anomaly Detection via Contrastive
 Reconstruction
Authors: Jia Guo, Shuai Lu, Lize Jia, Weihang Zhang, Huiqi Li
Categories: cs.CV
Comments: under review
\\
 Most advanced unsupervised anomaly detection (UAD) methods rely on modeling
feature representations of frozen encoder networks pre-trained on large-scale
datasets, e.g. ImageNet. However, the features extracted from the encoders that
are borrowed from natural image domains coincide little with the features
required in the target UAD domain, such as industrial inspection and medical
imaging. In this paper, we propose a novel epistemic UAD method, namely
ReContrast, which optimizes the entire network to reduce biases towards the
pre-trained image domain and orients the network in the target domain. We start
with a feature reconstruction approach that detects anomalies from errors.
Essentially, the elements of contrastive learning are elegantly embedded in
feature reconstruction to prevent the network from training instability,
pattern collapse, and identical shortcut, while simultaneously optimizing both
the encoder and decoder on the target domain. To demonstrate our transfer
ability on various image domains, we conduct extensive experiments across two
popular industrial defect detection benchmarks and three medical image UAD
tasks, which shows our superiority over current state-of-the-art methods.
\\ ( https://arxiv.org/abs/2306.02602 ,  28544kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02623
Date: Mon, 5 Jun 2023 06:50:42 GMT   (1047kb,D)

Title: Do-GOOD: Towards Distribution Shift Evaluation for Pre-Trained Visual
 Document Understanding Models
Authors: Jiabang He, Yi Hu, Lei Wang, Xing Xu, Ning Liu, Hui Liu, Heng Tao Shen
Categories: cs.CV cs.CL cs.MM
Comments: SIGIR 2023. The code and datasets for our Do-GOOD benchmark can be
 found at https://github.com/MAEHCM/Do-GOOD
\\
 Numerous pre-training techniques for visual document understanding (VDU) have
recently shown substantial improvements in performance across a wide range of
document tasks. However, these pre-trained VDU models cannot guarantee
continued success when the distribution of test data differs from the
distribution of training data. In this paper, to investigate how robust
existing pre-trained VDU models are to various distribution shifts, we first
develop an out-of-distribution (OOD) benchmark termed Do-GOOD for the
fine-Grained analysis on Document image-related tasks specifically. The Do-GOOD
benchmark defines the underlying mechanisms that result in different
distribution shifts and contains 9 OOD datasets covering 3 VDU related tasks,
e.g., document information extraction, classification and question answering.
We then evaluate the robustness and perform a fine-grained analysis of 5 latest
VDU pre-trained models and 2 typical OOD generalization algorithms on these OOD
datasets. Results from the experiments demonstrate that there is a significant
performance gap between the in-distribution (ID) and OOD settings for document
images, and that fine-grained analysis of distribution shifts can reveal the
brittle nature of existing pre-trained VDU models and OOD generalization
algorithms. The code and datasets for our Do-GOOD benchmark can be found at
https://github.com/MAEHCM/Do-GOOD.
\\ ( https://arxiv.org/abs/2306.02623 ,  1047kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02644
Date: Mon, 5 Jun 2023 07:29:18 GMT   (2829kb,D)

Title: Learned Alternating Minimization Algorithm for Dual-domain Sparse-View
 CT Reconstruction
Authors: Chi Ding, Qingchao Zhang, Ge Wang, Xiaojing Ye and Yunmei Chen
Categories: cs.CV
\\
 We propose a novel Learned Alternating Minimization Algorithm (LAMA) for
dual-domain sparse-view CT image reconstruction. LAMA is naturally induced by a
variational model for CT reconstruction with learnable nonsmooth nonconvex
regularizers, which are parameterized as composite functions of deep networks
in both image and sinogram domains. To minimize the objective of the model, we
incorporate the smoothing technique and residual learning architecture into the
design of LAMA. We show that LAMA substantially reduces network complexity,
improves memory efficiency and reconstruction accuracy, and is provably
convergent for reliable reconstructions. Extensive numerical experiments
demonstrate that LAMA outperforms existing methods by a wide margin on multiple
benchmark CT datasets.
\\ ( https://arxiv.org/abs/2306.02644 ,  2829kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02651
Date: Mon, 5 Jun 2023 07:34:41 GMT   (8578kb,D)

Title: Dynamic Interactive Relation Capturing via Scene Graph Learning for
 Robotic Surgical Report Generation
Authors: Hongqiu Wang, Yueming Jin, Lei Zhu
Categories: cs.CV cs.LG
\\
 For robot-assisted surgery, an accurate surgical report reflects clinical
operations during surgery and helps document entry tasks, post-operative
analysis and follow-up treatment. It is a challenging task due to many complex
and diverse interactions between instruments and tissues in the surgical scene.
Although existing surgical report generation methods based on deep learning
have achieved large success, they often ignore the interactive relation between
tissues and instrumental tools, thereby degrading the report generation
performance. This paper presents a neural network to boost surgical report
generation by explicitly exploring the interactive relation between tissues and
surgical instruments. We validate the effectiveness of our method on a
widely-used robotic surgery benchmark dataset, and experimental results show
that our network can significantly outperform existing state-of-the-art
surgical report generation methods (e.g., 7.48% and 5.43% higher for BLEU-1 and
ROUGE).
\\ ( https://arxiv.org/abs/2306.02651 ,  8578kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02656
Date: Mon, 5 Jun 2023 07:42:53 GMT   (14523kb,D)

Title: Calib-Anything: Zero-training LiDAR-Camera Extrinsic Calibration Method
 Using Segment Anything
Authors: Zhaotong Luo, Guohang Yan and Yikang Li
Categories: cs.CV cs.RO
Comments: 5 pages, 4 figures
\\
 The research on extrinsic calibration between Light Detection and
Ranging(LiDAR) and camera are being promoted to a more accurate, automatic and
generic manner. Since deep learning has been employed in calibration, the
restrictions on the scene are greatly reduced. However, data driven method has
the drawback of low transfer-ability. It cannot adapt to dataset variations
unless additional training is taken. With the advent of foundation model, this
problem can be significantly mitigated. By using the Segment Anything
Model(SAM), we propose a novel LiDAR-camera calibration method, which requires
zero extra training and adapts to common scenes. With an initial guess, we
opimize the extrinsic parameter by maximizing the consistency of points that
are projected inside each image mask. The consistency includes three properties
of the point cloud: the intensity, normal vector and categories derived from
some segmentation methods. The experiments on different dataset have
demonstrated the generality and comparable accuracy of our method. The code is
available at https://github.com/OpenCalib/CalibAnything.
\\ ( https://arxiv.org/abs/2306.02656 ,  14523kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02691
Date: Mon, 5 Jun 2023 08:32:12 GMT   (14090kb,D)

Title: Cyclic Learning: Bridging Image-level Labels and Nuclei Instance
 Segmentation
Authors: Yang Zhou, Yongjian Wu, Zihua Wang, Bingzheng Wei, Maode Lai,
 Jianzhong Shou, Yubo Fan, Yan Xu
Categories: cs.CV eess.IV
Comments: This article has been accepted for publication in a future issue of
 this journal, but has not been fully edited. Content may change prior to
 final publication. Citation information: DOI
 https://doi.org/10.1109/TMI.2023.3275609, IEEE Transactions on Medical
 Imaging. Code: https://github.com/wuyongjianCODE/Cyclic
DOI: 10.1109/TMI.2023.3275609
\\
 Nuclei instance segmentation on histopathology images is of great clinical
value for disease analysis. Generally, fully-supervised algorithms for this
task require pixel-wise manual annotations, which is especially time-consuming
and laborious for the high nuclei density. To alleviate the annotation burden,
we seek to solve the problem through image-level weakly supervised learning,
which is underexplored for nuclei instance segmentation. Compared with most
existing methods using other weak annotations (scribble, point, etc.) for
nuclei instance segmentation, our method is more labor-saving. The obstacle to
using image-level annotations in nuclei instance segmentation is the lack of
adequate location information, leading to severe nuclei omission or overlaps.
In this paper, we propose a novel image-level weakly supervised method, called
cyclic learning, to solve this problem. Cyclic learning comprises a front-end
classification task and a back-end semi-supervised instance segmentation task
to benefit from multi-task learning (MTL). We utilize a deep learning
classifier with interpretability as the front-end to convert image-level labels
to sets of high-confidence pseudo masks and establish a semi-supervised
architecture as the back-end to conduct nuclei instance segmentation under the
supervision of these pseudo masks. Most importantly, cyclic learning is
designed to circularly share knowledge between the front-end classifier and the
back-end semi-supervised part, which allows the whole system to fully extract
the underlying information from image-level labels and converge to a better
optimum. Experiments on three datasets demonstrate the good generality of our
method, which outperforms other image-level weakly supervised methods for
nuclei instance segmentation, and achieves comparable performance to
fully-supervised methods.
\\ ( https://arxiv.org/abs/2306.02691 ,  14090kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02712
Date: Mon, 5 Jun 2023 09:02:48 GMT   (5855kb,D)

Title: NFTVis: Visual Analysis of NFT Performance
Authors: Fan Yan, Xumeng Wang, Ketian Mao, Wei Zhang, and Wei Chen
Categories: cs.CV cs.CE
Comments: This manuscript is accepted for publication in Proceedings of the
 16th IEEE Pacific Visualization Symposium (PacificVis '23)
\\
 A non-fungible token (NFT) is a data unit stored on the blockchain. Nowadays,
more and more investors and collectors (NFT traders), who participate in
transactions of NFTs, have an urgent need to assess the performance of NFTs.
However, there are two challenges for NFT traders when analyzing the
performance of NFT. First, the current rarity models have flaws and are
sometimes not convincing. In addition, NFT performance is dependent on multiple
factors, such as images (high-dimensional data), history transactions
(network), and market evolution (time series). It is difficult to take
comprehensive consideration and analyze NFT performance efficiently. To address
these challenges, we propose NFTVis, a visual analysis system that facilitates
assessing individual NFT performance. A new NFT rarity model is proposed to
quantify NFTs with images. Four well-coordinated views are designed to
represent the various factors affecting the performance of the NFT. Finally, we
evaluate the usefulness and effectiveness of our system using two case studies
and user studies.
\\ ( https://arxiv.org/abs/2306.02712 ,  5855kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02717
Date: Mon, 5 Jun 2023 09:09:10 GMT   (13104kb,D)

Title: User-friendly Image Editing with Minimal Text Input: Leveraging
 Captioning and Injection Techniques
Authors: Sunwoo Kim, Wooseok Jang, Hyunsu Kim, Junho Kim, Yunjey Choi,
 Seungryong Kim, Gayeong Lee
Categories: cs.CV
\\
 Recent text-driven image editing in diffusion models has shown remarkable
success. However, the existing methods assume that the user's description
sufficiently grounds the contexts in the source image, such as objects,
background, style, and their relations. This assumption is unsuitable for
real-world applications because users have to manually engineer text prompts to
find optimal descriptions for different images. From the users' standpoint,
prompt engineering is a labor-intensive process, and users prefer to provide a
target word for editing instead of a full sentence. To address this problem, we
first demonstrate the importance of a detailed text description of the source
image, by dividing prompts into three categories based on the level of semantic
details. Then, we propose simple yet effective methods by combining prompt
generation frameworks, thereby making the prompt engineering process more
user-friendly. Extensive qualitative and quantitative experiments demonstrate
the importance of prompts in text-driven image editing and our method is
comparable to ground-truth prompts.
\\ ( https://arxiv.org/abs/2306.02717 ,  13104kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02728
Date: Mon, 5 Jun 2023 09:26:33 GMT   (4022kb,D)

Title: Overcoming Weak Visual-Textual Alignment for Video Moment Retrieval
Authors: Minjoon Jung, Youwon Jang, Seongho Choi, Joochan Kim, Jin-Hwa Kim,
 Byoung-Tak Zhang
Categories: cs.CV
Comments: Under Review; Our code is available at
 https://github.com/minjoong507/BM-DETR
\\
 Video moment retrieval (VMR) aims to identify the specific moment in an
untrimmed video for a given natural language query. However, this task is prone
to suffer the weak visual-textual alignment problem from query ambiguity,
potentially limiting further performance gains and generalization capability.
Due to the complex multimodal interactions in videos, a query may not fully
cover the relevant details of the corresponding moment, and the moment may
contain misaligned and irrelevant frames. To tackle this problem, we propose a
straightforward yet effective model, called Background-aware Moment DEtection
TRansformer (BM-DETR). Given a target query and its moment, BM-DETR also takes
negative queries corresponding to different moments. Specifically, our model
learns to predict the target moment from the joint probability of the given
query and the complement of negative queries for each candidate frame. In this
way, it leverages the surrounding background to consider relative importance,
improving moment sensitivity. Extensive experiments on Charades-STA and
QVHighlights demonstrate the effectiveness of our model. Moreover, we show that
BM-DETR can perform robustly in three challenging VMR scenarios, such as
several out-of-distribution test cases, demonstrating superior generalization
ability.
\\ ( https://arxiv.org/abs/2306.02728 ,  4022kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02741
Date: Mon, 5 Jun 2023 09:41:51 GMT   (40288kb,D)

Title: ZIGNeRF: Zero-shot 3D Scene Representation with Invertible Generative
 Neural Radiance Fields
Authors: Kanghyeok Ko, Minhyeok Lee
Categories: cs.CV
\\
 Generative Neural Radiance Fields (NeRFs) have demonstrated remarkable
proficiency in synthesizing multi-view images by learning the distribution of a
set of unposed images. Despite the aptitude of existing generative NeRFs in
generating 3D-consistent high-quality random samples within data distribution,
the creation of a 3D representation of a singular input image remains a
formidable challenge. In this manuscript, we introduce ZIGNeRF, an innovative
model that executes zero-shot Generative Adversarial Network (GAN) inversion
for the generation of multi-view images from a single out-of-domain image. The
model is underpinned by a novel inverter that maps out-of-domain images into
the latent code of the generator manifold. Notably, ZIGNeRF is capable of
disentangling the object from the background and executing 3D operations such
as 360-degree rotation or depth and horizontal translation. The efficacy of our
model is validated using multiple real-image datasets: Cats, AFHQ, CelebA,
CelebA-HQ, and CompCars.
\\ ( https://arxiv.org/abs/2306.02741 ,  40288kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02744
Date: Mon, 5 Jun 2023 09:52:05 GMT   (33320kb,D)

Title: Towards Better Explanations for Object Detection
Authors: Van Binh Truong, Truong Thanh Hung Nguyen, Vo Thanh Khang Nguyen, Quoc
 Khanh Nguyen, Quoc Hung Cao
Categories: cs.CV cs.AI cs.LG
Comments: 9 pages, 10 figures
\\
 Recent advances in Artificial Intelligence (AI) technology have promoted
their use in almost every field. The growing complexity of deep neural networks
(DNNs) makes it increasingly difficult and important to explain the inner
workings and decisions of the network. However, most current techniques for
explaining DNNs focus mainly on interpreting classification tasks. This paper
proposes a method to explain the decision for any object detection model called
D-CLOSE. To closely track the model's behavior, we used multiple levels of
segmentation on the image and a process to combine them. We performed tests on
the MS-COCO dataset with the YOLOX model, which shows that our method
outperforms D-RISE and can give a better quality and less noise explanation.
\\ ( https://arxiv.org/abs/2306.02744 ,  33320kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02760
Date: Mon, 5 Jun 2023 10:28:53 GMT   (8669kb,D)

Title: A2B: Anchor to Barycentric Coordinate for Robust Correspondence
Authors: Weiyue Zhao, Hao Lu, Zhiguo Cao, Xin Li
Categories: cs.CV
Comments: Accepted by International Journal of Computer Vision
\\
 There is a long-standing problem of repeated patterns in correspondence
problems, where mismatches frequently occur because of inherent ambiguity. The
unique position information associated with repeated patterns makes coordinate
representations a useful supplement to appearance representations for improving
feature correspondences. However, the issue of appropriate coordinate
representation has remained unresolved. In this study, we demonstrate that
geometric-invariant coordinate representations, such as barycentric
coordinates, can significantly reduce mismatches between features. The first
step is to establish a theoretical foundation for geometrically invariant
coordinates. We present a seed matching and filtering network (SMFNet) that
combines feature matching and consistency filtering with a coarse-to-fine
matching strategy in order to acquire reliable sparse correspondences. We then
introduce DEGREE, a novel anchor-to-barycentric (A2B) coordinate encoding
approach, which generates multiple affine-invariant correspondence coordinates
from paired images. DEGREE can be used as a plug-in with standard descriptors,
feature matchers, and consistency filters to improve the matching quality.
Extensive experiments in synthesized indoor and outdoor datasets demonstrate
that DEGREE alleviates the problem of repeated patterns and helps achieve
state-of-the-art performance. Furthermore, DEGREE also reports competitive
performance in the third Image Matching Challenge at CVPR 2021. This approach
offers a new perspective to alleviate the problem of repeated patterns and
emphasizes the importance of choosing coordinate representations for feature
correspondences.
\\ ( https://arxiv.org/abs/2306.02760 ,  8669kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02763
Date: Mon, 5 Jun 2023 10:33:25 GMT   (5582kb,D)

Title: STAR Loss: Reducing Semantic Ambiguity in Facial Landmark Detection
Authors: Zhenglin Zhou and Huaxia Li and Hong Liu and Nanyang Wang and Gang Yu
 and Rongrong Ji
Categories: cs.CV
Comments: 14 pages, 7 figures, accepted by CVPR 2023
\\
 Recently, deep learning-based facial landmark detection has achieved
significant improvement. However, the semantic ambiguity problem degrades
detection performance. Specifically, the semantic ambiguity causes inconsistent
annotation and negatively affects the model's convergence, leading to worse
accuracy and instability prediction. To solve this problem, we propose a
Self-adapTive Ambiguity Reduction (STAR) loss by exploiting the properties of
semantic ambiguity. We find that semantic ambiguity results in the anisotropic
predicted distribution, which inspires us to use predicted distribution to
represent semantic ambiguity. Based on this, we design the STAR loss that
measures the anisotropism of the predicted distribution. Compared with the
standard regression loss, STAR loss is encouraged to be small when the
predicted distribution is anisotropic and thus adaptively mitigates the impact
of semantic ambiguity. Moreover, we propose two kinds of eigenvalue restriction
methods that could avoid both distribution's abnormal change and the model's
premature convergence. Finally, the comprehensive experiments demonstrate that
STAR loss outperforms the state-of-the-art methods on three benchmarks, i.e.,
COFW, 300W, and WFLW, with negligible computation overhead. Code is at
https://github.com/ZhenglinZhou/STAR.
\\ ( https://arxiv.org/abs/2306.02763 ,  5582kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02765
Date: Mon, 5 Jun 2023 10:41:25 GMT   (300kb,D)

Title: Differentially Private Cross-camera Person Re-identification
Authors: Lucas Maris, Yuki Matsuda, Keiichi Yasumoto
Categories: cs.CV
\\
 Camera-based person re-identification is a heavily privacy-invading task by
design, benefiting from rich visual data to match together person
representations across different cameras. This high-dimensional data can then
easily be used for other, perhaps less desirable, applications. We here
investigate the possibility of protecting such image data against uses outside
of the intended re-identification task, and introduce a differential privacy
mechanism leveraging both pixelisation and colour quantisation for this
purpose. We show its ability to distort images in such a way that adverse task
performances are significantly reduced, while retaining high re-identification
performances.
\\ ( https://arxiv.org/abs/2306.02765 ,  300kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02776
Date: Mon, 5 Jun 2023 11:01:00 GMT   (305kb,D)

Title: Cheap-fake Detection with LLM using Prompt Engineering
Authors: Guangyang Wu, Weijie Wu, Xiaohong Liu, Kele Xu, Tianjiao Wan, Wenyi
 Wang
Categories: cs.CV
Comments: ICME2023 Workshop
\\
 The misuse of real photographs with conflicting image captions in news items
is an example of the out-of-context (OOC) misuse of media. In order to detect
OOC media, individuals must determine the accuracy of the statement and
evaluate whether the triplet (~\textit{i.e.}, the image and two captions)
relates to the same event. This paper presents a novel learnable approach for
detecting OOC media in ICME'23 Grand Challenge on Detecting Cheapfakes. The
proposed method is based on the COSMOS structure, which assesses the coherence
between an image and captions, as well as between two captions. We enhance the
baseline algorithm by incorporating a Large Language Model (LLM), GPT3.5, as a
feature extractor. Specifically, we propose an innovative approach to feature
extraction utilizing prompt engineering to develop a robust and reliable
feature extractor with GPT3.5 model. The proposed method captures the
correlation between two captions and effectively integrates this module into
the COSMOS baseline model, which allows for a deeper understanding of the
relationship between captions. By incorporating this module, we demonstrate the
potential for significant improvements in cheap-fakes detection performance.
The proposed methodology holds promising implications for various applications
such as natural language processing, image captioning, and text-to-image
synthesis. Docker for submission is available at
https://hub.docker.com/repository/docker/mulns/ acmmmcheapfakes.
\\ ( https://arxiv.org/abs/2306.02776 ,  305kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02782
Date: Mon, 5 Jun 2023 11:16:50 GMT   (1681kb,D)

Title: Reassembling Broken Objects using Breaking Curves
Authors: Ali Alagrami, Luca Palmieri, Sinem Aslan, Marcello Pelillo, Sebastiano
 Vascon
Categories: cs.CV
Comments: 4 pages, accepted at 3DVR Workshop @ CVPR 2023
\\
 Reassembling 3D broken objects is a challenging task. A robust solution that
generalizes well must deal with diverse patterns associated with different
types of broken objects. We propose a method that tackles the pairwise assembly
of 3D point clouds, that is agnostic on the type of object, and that relies
solely on their geometrical information, without any prior information on the
shape of the reconstructed object. The method receives two point clouds as
input and segments them into regions using detected closed boundary contours,
known as breaking curves. Possible alignment combinations of the regions of
each broken object are evaluated and the best one is selected as the final
alignment. Experiments were carried out both on available 3D scanned objects
and on a recent benchmark for synthetic broken objects. Results show that our
solution performs well in reassembling different kinds of broken objects.
\\ ( https://arxiv.org/abs/2306.02782 ,  1681kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02815
Date: Mon, 5 Jun 2023 12:12:23 GMT   (4204kb,D)

Title: Transformer-Based UNet with Multi-Headed Cross-Attention Skip
 Connections to Eliminate Artifacts in Scanned Documents
Authors: David Kreuzer and Michael Munz
Categories: cs.CV cs.LG
\\
 The extraction of text in high quality is essential for text-based document
analysis tasks like Document Classification or Named Entity Recognition.
Unfortunately, this is not always ensured, as poor scan quality and the
resulting artifacts lead to errors in the Optical Character Recognition (OCR)
process. Current approaches using Convolutional Neural Networks show promising
results for background removal tasks but fail correcting artifacts like
pixelation or compression errors. For general images, Transformer backbones are
getting integrated more frequently in well-known neural network structures for
denoising tasks. In this work, a modified UNet structure using a Swin
Transformer backbone is presented to remove typical artifacts in scanned
documents. Multi-headed cross-attention skip connections are used to more
selectively learn features in respective levels of abstraction. The performance
of this approach is examined regarding compression errors, pixelation and
random noise. An improvement in text extraction quality with a reduced error
rate of up to 53.9% on the synthetic data is archived. The pretrained
base-model can be easily adapted to new artifacts. The cross-attention skip
connections allow to integrate textual information extracted from the encoder
or in form of commands to more selectively control the models outcome. The
latter is shown by means of an example application.
\\ ( https://arxiv.org/abs/2306.02815 ,  4204kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02850
Date: Mon, 5 Jun 2023 13:00:44 GMT   (11108kb,D)

Title: TRACE: 5D Temporal Regression of Avatars with Dynamic Cameras in 3D
 Environments
Authors: Yu Sun, Qian Bao, Wu Liu, Tao Mei, Michael J. Black
Categories: cs.CV
Comments: TRACE will appear in CVPR2023
\\
 Although the estimation of 3D human pose and shape (HPS) is rapidly
progressing, current methods still cannot reliably estimate moving humans in
global coordinates, which is critical for many applications. This is
particularly challenging when the camera is also moving, entangling human and
camera motion. To address these issues, we adopt a novel 5D representation
(space, time, and identity) that enables end-to-end reasoning about people in
scenes. Our method, called TRACE, introduces several novel architectural
components. Most importantly, it uses two new "maps" to reason about the 3D
trajectory of people over time in camera, and world, coordinates. An additional
memory unit enables persistent tracking of people even during long occlusions.
TRACE is the first one-stage method to jointly recover and track 3D humans in
global coordinates from dynamic cameras. By training it end-to-end, and using
full image information, TRACE achieves state-of-the-art performance on tracking
and HPS benchmarks. The code and dataset are released for research purposes.
\\ ( https://arxiv.org/abs/2306.02850 ,  11108kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02851
Date: Mon, 5 Jun 2023 13:01:38 GMT   (24793kb,D)

Title: Scene as Occupancy
Authors: Wenwen Tong, Chonghao Sima, Tai Wang, Silei Wu, Hanming Deng, Li Chen,
 Yi Gu, Lewei Lu, Ping Luo, Dahua Lin, Hongyang Li
Categories: cs.CV cs.RO
\\
 Human driver can easily describe the complex traffic scene by visual system.
Such an ability of precise perception is essential for driver's planning. To
achieve this, a geometry-aware representation that quantizes the physical 3D
scene into structured grid map with semantic labels per cell, termed as 3D
Occupancy, would be desirable. Compared to the form of bounding box, a key
insight behind occupancy is that it could capture the fine-grained details of
critical obstacles in the scene, and thereby facilitate subsequent tasks. Prior
or concurrent literature mainly concentrate on a single scene completion task,
where we might argue that the potential of this occupancy representation might
obsess broader impact. In this paper, we propose OccNet, a multi-view
vision-centric pipeline with a cascade and temporal voxel decoder to
reconstruct 3D occupancy. At the core of OccNet is a general occupancy
embedding to represent 3D physical world. Such a descriptor could be applied
towards a wide span of driving tasks, including detection, segmentation and
planning. To validate the effectiveness of this new representation and our
proposed algorithm, we propose OpenOcc, the first dense high-quality 3D
occupancy benchmark built on top of nuScenes. Empirical experiments show that
there are evident performance gain across multiple tasks, e.g., motion planning
could witness a collision rate reduction by 15%-58%, demonstrating the
superiority of our method.
\\ ( https://arxiv.org/abs/2306.02851 ,  24793kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02854
Date: Mon, 5 Jun 2023 13:10:48 GMT   (2427kb,D)

Title: Asymmetric Patch Sampling for Contrastive Learning
Authors: Chengchao Shen, Jianzhong Chen, Shu Wang, Hulin Kuang, Jin Liu,
 Jianxin Wang
Categories: cs.CV
\\
 Asymmetric appearance between positive pair effectively reduces the risk of
representation degradation in contrastive learning. However, there are still a
mass of appearance similarities between positive pair constructed by the
existing methods, which inhibits the further representation improvement. In
this paper, we propose a novel asymmetric patch sampling strategy for
contrastive learning, to further boost the appearance asymmetry for better
representations. Specifically, dual patch sampling strategies are applied to
the given image, to obtain asymmetric positive pairs. First, sparse patch
sampling is conducted to obtain the first view, which reduces spatial
redundancy of image and allows a more asymmetric view. Second, a selective
patch sampling is proposed to construct another view with large appearance
discrepancy relative to the first one. Due to the inappreciable appearance
similarity between positive pair, the trained model is encouraged to capture
the similarity on semantics, instead of low-level ones. Experimental results
demonstrate that our proposed method significantly outperforms the existing
self-supervised methods on both ImageNet-1K and CIFAR dataset, e.g., 2.5%
finetune accuracy improvement on CIFAR100. Furthermore, our method achieves
state-of-the-art performance on downstream tasks, object detection and instance
segmentation on COCO.Additionally, compared to other self-supervised methods,
our method is more efficient on both memory and computation during training.
The source code is available at https://github.com/visresearch/aps.
\\ ( https://arxiv.org/abs/2306.02854 ,  2427kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02878
Date: Mon, 5 Jun 2023 13:49:24 GMT   (21764kb,D)

Title: Single-Stage 3D Geometry-Preserving Depth Estimation Model Training on
 Dataset Mixtures with Uncalibrated Stereo Data
Authors: Nikolay Patakin, Mikhail Romanov, Anna Vorontsova, Mikhail Artemyev,
 Anton Konushin
Categories: cs.CV
Journal-ref: CVPR 2022
\\
 Nowadays, robotics, AR, and 3D modeling applications attract considerable
attention to single-view depth estimation (SVDE) as it allows estimating scene
geometry from a single RGB image. Recent works have demonstrated that the
accuracy of an SVDE method hugely depends on the diversity and volume of the
training data. However, RGB-D datasets obtained via depth capturing or 3D
reconstruction are typically small, synthetic datasets are not photorealistic
enough, and all these datasets lack diversity. The large-scale and diverse data
can be sourced from stereo images or stereo videos from the web. Typically
being uncalibrated, stereo data provides disparities up to unknown shift
(geometrically incomplete data), so stereo-trained SVDE methods cannot recover
3D geometry. It was recently shown that the distorted point clouds obtained
with a stereo-trained SVDE method can be corrected with additional point cloud
modules (PCM) separately trained on the geometrically complete data. On the
contrary, we propose GP$^{2}$, General-Purpose and Geometry-Preserving training
scheme, and show that conventional SVDE models can learn correct shifts
themselves without any post-processing, benefiting from using stereo data even
in the geometry-preserving setting. Through experiments on different dataset
mixtures, we prove that GP$^{2}$-trained models outperform methods relying on
PCM in both accuracy and speed, and report the state-of-the-art results in the
general-purpose geometry-preserving SVDE. Moreover, we show that SVDE models
can learn to predict geometrically correct depth even when geometrically
complete data comprises the minor part of the training set.
\\ ( https://arxiv.org/abs/2306.02878 ,  21764kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02883
Date: Mon, 5 Jun 2023 13:52:08 GMT   (3539kb,D)

Title: Unsupervised network for low-light enhancement
Authors: Praveen Kandula, Maitreya Suin, and A. N. Rajagopalan
Categories: cs.CV eess.IV
\\
 Supervised networks address the task of low-light enhancement using paired
images. However, collecting a wide variety of low-light/clean paired images is
tedious as the scene needs to remain static during imaging. In this paper, we
propose an unsupervised low-light enhancement network using contextguided
illumination-adaptive norm (CIN). Inspired by coarse to fine methods, we
propose to address this task in two stages. In stage-I, a pixel amplifier
module (PAM) is used to generate a coarse estimate with an overall improvement
in visibility and aesthetic quality. Stage-II further enhances the saturated
dark pixels and scene properties of the image using CIN. Different ablation
studies show the importance of PAM and CIN in improving the visible quality of
the image. Next, we propose a region-adaptive single input multiple output
(SIMO) model that can generate multiple enhanced images from a single lowlight
image. The objective of SIMO is to let users choose the image of their liking
from a pool of enhanced images. Human subjective analysis of SIMO results shows
that the distribution of preferred images varies, endorsing the importance of
SIMO-type models. Lastly, we propose a low-light road scene (LLRS) dataset
having an unpaired collection of low-light and clean scenes. Unlike existing
datasets, the clean and low-light scenes in LLRS are real and captured using
fixed camera settings. Exhaustive comparisons on publicly available datasets,
and the proposed dataset reveal that the results of our model outperform prior
art quantitatively and qualitatively.
\\ ( https://arxiv.org/abs/2306.02883 ,  3539kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02898
Date: Mon, 5 Jun 2023 14:06:24 GMT   (5531kb,D)

Title: Towards Unified Text-based Person Retrieval: A Large-scale
 Multi-Attribute and Language Search Benchmark
Authors: Shuyu Yang, Yinan Zhou, Yaxiong Wang, Yujiao Wu, Li Zhu, Zhedong Zheng
Categories: cs.CV cs.MM
\\
 In this paper, we introduce a large Multi-Attribute and Language Search
dataset for text-based person retrieval, called MALS, and explore the
feasibility of performing pre-training on both attribute recognition and
image-text matching tasks in one stone. In particular, MALS contains 1,510,330
image-text pairs, which is about 37.5 times larger than prevailing CUHK-PEDES,
and all images are annotated with 27 attributes. Considering the privacy
concerns and annotation costs, we leverage the off-the-shelf diffusion models
to generate the dataset. To verify the feasibility of learning from the
generated data, we develop a new joint Attribute Prompt Learning and Text
Matching Learning (APTM) framework, considering the shared knowledge between
attribute and text. As the name implies, APTM contains an attribute prompt
learning stream and a text matching learning stream. (1) The attribute prompt
learning leverages the attribute prompts for image-attribute alignment, which
enhances the text matching learning. (2) The text matching learning facilitates
the representation learning on fine-grained details, and in turn, boosts the
attribute prompt learning. Extensive experiments validate the effectiveness of
the pre-training on MALS, achieving state-of-the-art retrieval performance via
APTM on three challenging real-world benchmarks. In particular, APTM achieves a
consistent improvement of +6.60%, +7.39%, and +15.90% Recall@1 accuracy on
CUHK-PEDES, ICFG-PEDES, and RSTPReid datasets by a clear margin, respectively.
\\ ( https://arxiv.org/abs/2306.02898 ,  5531kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02900
Date: Mon, 5 Jun 2023 14:06:40 GMT   (1628kb,D)

Title: Robust Fiber ODF Estimation Using Deep Constrained Spherical
 Deconvolution for Diffusion MRI
Authors: Tianyuan Yao, Francois Rheault, Leon Y Cai, Vishwesh nath, Zuhayr
 Asad, Nancy Newlin, Can Cui, Ruining Deng, Karthik Ramadass, Andrea Shafer,
 Susan Resnick, Kurt Schilling, Bennett A. Landman, Yuankai Huo
Categories: cs.CV
Comments: 33 pages, 7 figures
\\
 Diffusion-weighted magnetic resonance imaging (DW-MRI) is a critical imaging
method for capturing and modeling tissue microarchitecture at a millimeter
scale. A common practice to model the measured DW-MRI signal is via fiber
orientation distribution function (fODF). This function is the essential first
step for the downstream tractography and connectivity analyses. With recent
advantages in data sharing, large-scale multi-site DW-MRI datasets are being
made available for multi-site studies. However, measurement variabilities
(e.g., inter- and intra-site variability, hardware performance, and sequence
design) are inevitable during the acquisition of DW-MRI. Most existing
model-based methods (e.g., constrained spherical deconvolution (CSD)) and
learning based methods (e.g., deep learning (DL)) do not explicitly consider
such variabilities in fODF modeling, which consequently leads to inferior
performance on multi-site and/or longitudinal diffusion studies. In this paper,
we propose a novel data-driven deep constrained spherical deconvolution method
to explicitly constrain the scan-rescan variabilities for a more reproducible
and robust estimation of brain microstructure from repeated DW-MRI scans.
Specifically, the proposed method introduces a new 3D volumetric
scanner-invariant regularization scheme during the fODF estimation. We study
the Human Connectome Project (HCP) young adults test-retest group as well as
the MASiVar dataset (with inter- and intra-site scan/rescan data). The
Baltimore Longitudinal Study of Aging (BLSA) dataset is employed for external
validation. From the experimental results, the proposed data-driven framework
outperforms the existing benchmarks in repeated fODF estimation. The proposed
method is assessing the downstream connectivity analysis and shows increased
performance in distinguishing subjects with different biomarkers.
\\ ( https://arxiv.org/abs/2306.02900 ,  1628kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02903
Date: Mon, 5 Jun 2023 14:10:28 GMT   (6439kb,D)

Title: Instruct-Video2Avatar: Video-to-Avatar Generation with Instructions
Authors: Shaoxu Li
Categories: cs.CV
Comments: https://github.com/lsx0101/Instruct-Video2Avatar
\\
 We propose a method for synthesizing edited photo-realistic digital avatars
with text instructions. Given a short monocular RGB video and text
instructions, our method uses an image-conditioned diffusion model to edit one
head image and uses the video stylization method to accomplish the editing of
other head images. Through iterative training and update (three times or more),
our method synthesizes edited photo-realistic animatable 3D neural head avatars
with a deformable neural radiance field head synthesis method. In quantitative
and qualitative studies on various subjects, our method outperforms
state-of-the-art methods.
\\ ( https://arxiv.org/abs/2306.02903 ,  6439kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02912
Date: Mon, 5 Jun 2023 14:15:46 GMT   (4071kb,D)

Title: Unsupervised haze removal from underwater images
Authors: Praveen Kandula and A. N. Rajagopalan
Categories: cs.CV cs.AI
\\
 Several supervised networks exist that remove haze information from
underwater images using paired datasets and pixel-wise loss functions. However,
training these networks requires large amounts of paired data which is
cumbersome, complex and time-consuming. Also, directly using adversarial and
cycle consistency loss functions for unsupervised learning is inaccurate as the
underlying mapping from clean to underwater images is one-to-many, resulting in
an inaccurate constraint on the cycle consistency loss. To address these
issues, we propose a new method to remove haze from underwater images using
unpaired data. Our model disentangles haze and content information from
underwater images using a Haze Disentanglement Network (HDN). The disentangled
content is used by a restoration network to generate a clean image using
adversarial losses. The disentangled haze is then used as a guide for
underwater image regeneration resulting in a strong constraint on cycle
consistency loss and improved performance gains. Different ablation studies
show that the haze and content from underwater images are effectively
separated. Exhaustive experiments reveal that accurate cycle consistency
constraint and the proposed network architecture play an important role in
yielding enhanced results. Experiments on UFO-120, UWNet, UWScenes, and UIEB
underwater datasets indicate that the results of our method outperform prior
art both visually and quantitatively.
\\ ( https://arxiv.org/abs/2306.02912 ,  4071kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02921
Date: Mon, 5 Jun 2023 14:34:58 GMT   (6263kb,D)

Title: Zero shot framework for satellite image restoration
Authors: Praveen Kandula and A. N. Rajagopalan
Categories: cs.CV eess.IV
\\
 Satellite images are typically subject to multiple distortions. Different
factors affect the quality of satellite images, including changes in
atmosphere, surface reflectance, sun illumination, viewing geometries etc.,
limiting its application to downstream tasks. In supervised networks, the
availability of paired datasets is a strong assumption. Consequently, many
unsupervised algorithms have been proposed to address this problem. These
methods synthetically generate a large dataset of degraded images using image
formation models. A neural network is then trained with an adversarial loss to
discriminate between images from distorted and clean domains. However, these
methods yield suboptimal performance when tested on real images that do not
necessarily conform to the generation mechanism. Also, they require a large
amount of training data and are rendered unsuitable when only a few images are
available. We propose a distortion disentanglement and knowledge distillation
framework for satellite image restoration to address these important issues.
Our algorithm requires only two images: the distorted satellite image to be
restored and a reference image with similar semantics. Specifically, we first
propose a mechanism to disentangle distortion. This enables us to generate
images with varying degrees of distortion using the disentangled distortion and
the reference image. We then propose the use of knowledge distillation to train
a restoration network using the generated image pairs. As a final step, the
distorted image is passed through the restoration network to get the final
output. Ablation studies show that our proposed mechanism successfully
disentangles distortion.
\\ ( https://arxiv.org/abs/2306.02921 ,  6263kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02928
Date: Mon, 5 Jun 2023 14:45:38 GMT   (7116kb,D)

Title: Weakly-Supervised Conditional Embedding for Referred Visual Search
Authors: Simon Lepage, J\'er\'emie Mary, David Picard
Categories: cs.CV
Comments: 20 pages, 13 figures, 4 tables
MSC-class: 68T07 (Primary) 68T45 (Secondary)
ACM-class: I.2.10
\\
 This paper presents a new approach to image similarity search in the context
of fashion, a domain with inherent ambiguity due to the multiple ways in which
images can be considered similar. We introduce the concept of Referred Visual
Search (RVS), where users provide additional information to define the desired
similarity. We present a new dataset, LAION-RVS-Fashion, consisting of 272K
fashion products with 842K images extracted from LAION, designed explicitly for
this task. We then propose an innovative method for learning conditional
embeddings using weakly-supervised training, achieving a 6% increase in Recall
at one (R@1) against a gallery with 2M distractors, compared to classical
approaches based on explicit attention and filtering. The proposed method
demonstrates robustness, maintaining similar R@1 when dealing with 2.5 times as
many distractors as the baseline methods. We believe this is a step forward in
the emerging field of Referred Visual Search both in terms of accessible data
and approach. Code, data and models are available at
https://www.github.com/Simon-Lepage/CondViT-LRVSF .
\\ ( https://arxiv.org/abs/2306.02928 ,  7116kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02930
Date: Mon, 5 Jun 2023 14:48:30 GMT   (30627kb,D)

Title: Human Spine Motion Capture using Perforated Kinesiology Tape
Authors: Hendrik Hachmann and Bodo Rosenhahn
Categories: cs.CV
\\
 In this work, we present a marker-based multi-view spine tracking method that
is specifically adjusted to the requirements for movements in sports. A maximal
focus is on the accurate detection of markers and fast usage of the system. For
this task, we take advantage of the prior knowledge of the arrangement of dots
in perforated kinesiology tape. We detect the tape and its dots using a Mask
R-CNN and a blob detector. Here, we can focus on detection only while skipping
any image-based feature encoding or matching. We conduct a reasoning in 3D by a
linear program and Markov random fields, in which the structure of the
kinesiology tape is modeled and the shape of the spine is optimized. In
comparison to state-of-the-art systems, we demonstrate that our system achieves
high precision and marker density, is robust against occlusions, and capable of
capturing fast movements.
\\ ( https://arxiv.org/abs/2306.02930 ,  30627kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02949
Date: Mon, 5 Jun 2023 15:14:47 GMT   (8088kb,D)

Title: INDigo: An INN-Guided Probabilistic Diffusion Algorithm for Inverse
 Problems
Authors: Di You, Andreas Floros, Pier Luigi Dragotti
Categories: cs.CV eess.IV
\\
 Recently it has been shown that using diffusion models for inverse problems
can lead to remarkable results. However, these approaches require a closed-form
expression of the degradation model and can not support complex degradations.
To overcome this limitation, we propose a method (INDigo) that combines
invertible neural networks (INN) and diffusion models for general inverse
problems. Specifically, we train the forward process of INN to simulate an
arbitrary degradation process and use the inverse as a reconstruction process.
During the diffusion sampling process, we impose an additional data-consistency
step that minimizes the distance between the intermediate result and the
INN-optimized result at every iteration, where the INN-optimized image is
composed of the coarse information given by the observed degraded image and the
details generated by the diffusion process. With the help of INN, our algorithm
effectively estimates the details lost in the degradation process and is no
longer limited by the requirement of knowing the closed-form expression of the
degradation model. Experiments demonstrate that our algorithm obtains
competitive results compared with recently leading methods both quantitatively
and visually. Moreover, our algorithm performs well on more complex degradation
models and real-world low-quality images.
\\ ( https://arxiv.org/abs/2306.02949 ,  8088kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02954
Date: Mon, 5 Jun 2023 15:20:44 GMT   (21985kb,D)

Title: Color-aware Deep Temporal Backdrop Duplex Matting System
Authors: Hendrik Hachmann and Bodo Rosenhahn
Categories: cs.CV
\\
 Deep learning-based alpha matting showed tremendous improvements in recent
years, yet, feature film production studios still rely on classical chroma
keying including costly post-production steps. This perceived discrepancy can
be explained by some missing links necessary for production which are currently
not adequately addressed in the alpha matting community, in particular
foreground color estimation or color spill compensation. We propose a neural
network-based temporal multi-backdrop production system that combines
beneficial features from chroma keying and alpha matting. Given two consecutive
frames with different background colors, our one-encoder-dual-decoder network
predicts foreground colors and alpha values using a patch-based overlap-blend
approach. The system is able to handle imprecise backdrops, dynamic cameras,
and dynamic foregrounds and has no restrictions on foreground colors. We
compare our method to state-of-the-art algorithms using benchmark datasets and
a video sequence captured by a demonstrator setup. We verify that a dual
backdrop input is superior to the usually applied trimap-based approach. In
addition, the proposed studio set is actor friendly, and produces high-quality,
temporal consistent alpha and color estimations that include a superior color
spill compensation.
\\ ( https://arxiv.org/abs/2306.02954 ,  21985kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02956
Date: Mon, 5 Jun 2023 15:24:33 GMT   (35475kb,D)

Title: Explicit Neural Surfaces: Learning Continuous Geometry With Deformation
 Fields
Authors: Thomas Walker, Octave Mariotti, Amir Vaxman, Hakan Bilen
Categories: cs.CV
ACM-class: I.4.5; I.2.10; I.3.5
\\
 We introduce Explicit Neural Surfaces (ENS), an efficient surface
reconstruction method that learns an explicitly defined continuous surface from
multiple views. We use a series of neural deformation fields to progressively
transform a continuous input surface to a target shape. By sampling meshes as
discrete surface proxies, we train the deformation fields through efficient
differentiable rasterization, and attain a mesh-independent and smooth surface
representation. By using Laplace-Beltrami eigenfunctions as an intrinsic
positional encoding alongside standard extrinsic Fourier features, our approach
can capture fine surface details. ENS trains 1 to 2 orders of magnitude faster
and can extract meshes of higher quality compared to implicit representations,
whilst maintaining competitive surface reconstruction performance and real-time
capabilities. Finally, we apply our approach to learn a collection of objects
in a single model, and achieve disentangled interpolations between different
shapes, their surface details, and textures.
\\ ( https://arxiv.org/abs/2306.02956 ,  35475kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02960
Date: Mon, 5 Jun 2023 15:26:02 GMT   (1816kb,D)

Title: Best of Both Worlds: Hybrid SNN-ANN Architecture for Event-based Optical
 Flow Estimation
Authors: Shubham Negi, Deepika Sharma, Adarsh Kumar Kosta and Kaushik Roy
Categories: cs.CV cs.LG
\\
 Event-based cameras offer a low-power alternative to frame-based cameras for
capturing high-speed motion and high dynamic range scenes. They provide
asynchronous streams of sparse events. Spiking Neural Networks (SNNs) with
their asynchronous event-driven compute, show great potential for extracting
the spatio-temporal features from these event streams. In contrast, the
standard Analog Neural Networks (ANNs1) fail to process event data effectively.
However, training SNNs is difficult due to additional trainable parameters
(thresholds and leaks), vanishing spikes at deeper layers, non-differentiable
binary activation function etc. Moreover, an additional data structure
"membrane potential" responsible for keeping track of temporal information,
must be fetched and updated at every timestep in SNNs. To overcome these, we
propose a novel SNN-ANN hybrid architecture that combines the strengths of
both. Specifically, we leverage the asynchronous compute capabilities of SNN
layers to effectively extract the input temporal information. While the ANN
layers offer trouble-free training and implementation on standard machine
learning hardware such as GPUs. We provide extensive experimental analysis for
assigning each layer to be spiking or analog in nature, leading to a network
configuration optimized for performance and ease of training. We evaluate our
hybrid architectures for optical flow estimation using event-data on DSEC-flow
and Mutli-Vehicle Stereo Event-Camera (MVSEC) datasets. The results indicate
that our configured hybrid architectures outperform the state-of-the-art
ANN-only, SNN-only and past hybrid architectures both in terms of accuracy and
efficiency. Specifically, our hybrid architecture exhibit a 31% and 24.8% lower
average endpoint error (AEE) at 2.1x and 3.1x lower energy, compared to an
SNN-only architecture on DSEC and MVSEC datasets, respectively.
\\ ( https://arxiv.org/abs/2306.02960 ,  1816kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03000
Date: Mon, 5 Jun 2023 16:10:21 GMT   (1652kb,D)

Title: BeyondPixels: A Comprehensive Review of the Evolution of Neural Radiance
 Fields
Authors: AKM Shahariar Azad Rabby, Chengcui Zhang
Categories: cs.CV
Comments: 22 page, 1 figure, 1 table
\\
 Neural rendering combines ideas from classical computer graphics and machine
learning to synthesize images from real-world observations. NeRF, short for
Neural Radiance Fields, is a recent innovation that uses AI algorithms to
create 3D objects from 2D images. By leveraging an interpolation approach, NeRF
can produce new 3D reconstructed views of complicated scenes. Rather than
directly restoring the whole 3D scene geometry, NeRF generates a volumetric
representation called a ``radiance field,'' which is capable of creating color
and density for every point within the relevant 3D space. The broad appeal and
notoriety of NeRF make it imperative to examine the existing research on the
topic comprehensively. While previous surveys on 3D rendering have primarily
focused on traditional computer vision-based or deep learning-based approaches,
only a handful of them discuss the potential of NeRF. However, such surveys
have predominantly focused on NeRF's early contributions and have not explored
its full potential. NeRF is a relatively new technique continuously being
investigated for its capabilities and limitations. This survey reviews recent
advances in NeRF and categorizes them according to their architectural designs,
especially in the field of novel view synthesis.
\\ ( https://arxiv.org/abs/2306.03000 ,  1652kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03002
Date: Mon, 5 Jun 2023 16:11:19 GMT   (641kb,D)

Title: Unveiling the Two-Faced Truth: Disentangling Morphed Identities for Face
 Morphing Detection
Authors: Eduarda Caldeira, Pedro C. Neto, Tiago Gon\c{c}alves, Naser Damer, Ana
 F. Sequeira, Jaime S. Cardoso
Categories: cs.CV cs.LG
Comments: Accepted at EUSIPCO 2023
\\
 Morphing attacks keep threatening biometric systems, especially face
recognition systems. Over time they have become simpler to perform and more
realistic, as such, the usage of deep learning systems to detect these attacks
has grown. At the same time, there is a constant concern regarding the lack of
interpretability of deep learning models. Balancing performance and
interpretability has been a difficult task for scientists. However, by
leveraging domain information and proving some constraints, we have been able
to develop IDistill, an interpretable method with state-of-the-art performance
that provides information on both the identity separation on morph samples and
their contribution to the final prediction. The domain information is learnt by
an autoencoder and distilled to a classifier system in order to teach it to
separate identity information. When compared to other methods in the literature
it outperforms them in three out of five databases and is competitive in the
remaining.
\\ ( https://arxiv.org/abs/2306.03002 ,  641kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03021
Date: Mon, 5 Jun 2023 16:38:11 GMT   (6227kb)

Title: Automating Style Analysis and Visualization With Explainable AI -- Case
 Studies on Brand Recognition
Authors: Yu-hsuan Chen, Levent Burak Kara, Jonathan Cagan
Categories: cs.CV cs.LG
\\
 Incorporating style-related objectives into shape design has been centrally
important to maximize product appeal. However, stylistic features such as
aesthetics and semantic attributes are hard to codify even for experts. As
such, algorithmic style capture and reuse have not fully benefited from
automated data-driven methodologies due to the challenging nature of design
describability. This paper proposes an AI-driven method to fully automate the
discovery of brand-related features. Our approach introduces BIGNet, a two-tier
Brand Identification Graph Neural Network (GNN) to classify and analyze scalar
vector graphics (SVG). First, to tackle the scarcity of vectorized product
images, this research proposes two data acquisition workflows: parametric
modeling from small curve-based datasets, and vectorization from large
pixel-based datasets. Secondly, this study constructs a novel hierarchical GNN
architecture to learn from both SVG's curve-level and chunk-level parameters.
In the first case study, BIGNet not only classifies phone brands but also
captures brand-related features across multiple scales, such as the location of
the lens, the height-width ratio, and the screen-frame gap, as confirmed by AI
evaluation. In the second study, this paper showcases the generalizability of
BIGNet learning from a vectorized car image dataset and validates the
consistency and robustness of its predictions given four scenarios. The results
match the difference commonly observed in luxury vs. economy brands in the
automobile market. Finally, this paper also visualizes the activation maps
generated from a convolutional neural network and shows BIGNet's advantage of
being a more human-friendly, explainable, and explicit style-capturing agent.
Code and dataset can be found on Github:
 1. Phone case study: github.com/parksandrecfan/bignet-phone 2. Car case
study: github.com/parksandrecfan/bignet-car
\\ ( https://arxiv.org/abs/2306.03021 ,  6227kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03022
Date: Mon, 5 Jun 2023 16:38:48 GMT   (1257kb,D)

Title: Interpretable Alzheimer's Disease Classification Via a Contrastive
 Diffusion Autoencoder
Authors: Ayodeji Ijishakin, Ahmed Abdulaal, Adamos Hadjivasiliou, Sophie
 Martin, James Cole
Categories: cs.CV cs.LG
\\
 In visual object classification, humans often justify their choices by
comparing objects to prototypical examples within that class. We may therefore
increase the interpretability of deep learning models by imbuing them with a
similar style of reasoning. In this work, we apply this principle by
classifying Alzheimer's Disease based on the similarity of images to training
examples within the latent space. We use a contrastive loss combined with a
diffusion autoencoder backbone, to produce a semantically meaningful latent
space, such that neighbouring latents have similar image-level features. We
achieve a classification accuracy comparable to black box approaches on a
dataset of 2D MRI images, whilst producing human interpretable model
explanations. Therefore, this work stands as a contribution to the pertinent
development of accurate and interpretable deep learning within medical imaging.
\\ ( https://arxiv.org/abs/2306.03022 ,  1257kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03038
Date: Mon, 5 Jun 2023 16:53:58 GMT   (41126kb,D)

Title: HeadSculpt: Crafting 3D Head Avatars with Text
Authors: Xiao Han, Yukang Cao, Kai Han, Xiatian Zhu, Jiankang Deng, Yi-Zhe
 Song, Tao Xiang, Kwan-Yee K. Wong
Categories: cs.CV
Comments: Webpage: https://brandonhan.uk/HeadSculpt/
\\
 Recently, text-guided 3D generative methods have made remarkable advancements
in producing high-quality textures and geometry, capitalizing on the
proliferation of large vision-language and image diffusion models. However,
existing methods still struggle to create high-fidelity 3D head avatars in two
aspects: (1) They rely mostly on a pre-trained text-to-image diffusion model
whilst missing the necessary 3D awareness and head priors. This makes them
prone to inconsistency and geometric distortions in the generated avatars. (2)
They fall short in fine-grained editing. This is primarily due to the inherited
limitations from the pre-trained 2D image diffusion models, which become more
pronounced when it comes to 3D head avatars. In this work, we address these
challenges by introducing a versatile coarse-to-fine pipeline dubbed HeadSculpt
for crafting (i.e., generating and editing) 3D head avatars from textual
prompts. Specifically, we first equip the diffusion model with 3D awareness by
leveraging landmark-based control and a learned textual embedding representing
the back view appearance of heads, enabling 3D-consistent head avatar
generations. We further propose a novel identity-aware editing score
distillation strategy to optimize a textured mesh with a high-resolution
differentiable rendering technique. This enables identity preservation while
following the editing instruction. We showcase HeadSculpt's superior fidelity
and editing capabilities through comprehensive experiments and comparisons with
existing methods.
\\ ( https://arxiv.org/abs/2306.03038 ,  41126kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03050
Date: Mon, 5 Jun 2023 17:22:27 GMT   (26247kb)

Title: ELEV-VISION: Automated Lowest Floor Elevation Estimation from Segmenting
 Street View Images
Authors: Yu-Hsuan Ho, Cheng-Chun Lee, Nicholas D. Diaz, Samuel D. Brody, and
 Ali Mostafavi
Categories: cs.CV
\\
 We propose an automated lowest floor elevation (LFE) estimation algorithm
based on computer vision techniques to leverage the latent information in
street view images. Flood depth-damage models use a combination of LFE and
flood depth for determining flood risk and extent of damage to properties. We
used image segmentation for detecting door bottoms and roadside edges from
Google Street View images. The characteristic of equirectangular projection
with constant spacing representation of horizontal and vertical angles allows
extraction of the pitch angle from the camera to the door bottom. The depth
from the camera to the door bottom was obtained from the depthmap paired with
the Google Street View image. LFEs were calculated from the pitch angle and the
depth. The testbed for application of the proposed method is Meyerland (Harris
County, Texas). The results show that the proposed method achieved mean
absolute error of 0.190 m (1.18 %) in estimating LFE. The height difference
between the street and the lowest floor (HDSL) was estimated to provide
information for flood damage estimation. The proposed automatic LFE estimation
algorithm using Street View images and image segmentation provides a rapid and
cost-effective method for LFE estimation compared with the surveys using total
station theodolite and unmanned aerial systems. By obtaining more accurate and
up-to-date LFE data using the proposed method, city planners, emergency
planners and insurance companies could make a more precise estimation of flood
damage.
\\ ( https://arxiv.org/abs/2306.03050 ,  26247kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03066
Date: Mon, 5 Jun 2023 17:43:50 GMT   (1441kb,D)

Title: Of Mice and Mates: Automated Classification and Modelling of Mouse
 Behaviour in Groups using a Single Model across Cages
Authors: Michael P. J. Camilleri and Rasneer S. Bains and Christopher K. I.
 Williams
Categories: cs.CV cs.LG stat.ML
\\
 Behavioural experiments often happen in specialised arenas, but this may
confound the analysis. To address this issue, we provide tools to study mice in
the homecage environment, equipping biologists with the possibility to capture
the temporal aspect of the individual's behaviour and model the interaction and
interdependence between cage-mates with minimal human intervention. We develop
the Activity Labelling Module (ALM) to automatically classify mouse behaviour
from video, and a novel Group Behaviour Model (GBM) for summarising their joint
behaviour across cages, using a permutation matrix to match the mouse
identities in each cage to the model. We also release two datasets, ABODe for
training behaviour classifiers and IMADGE for modelling behaviour.
\\ ( https://arxiv.org/abs/2306.03066 ,  1441kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03089
Date: Mon, 5 Jun 2023 17:59:05 GMT   (37283kb,D)

Title: Brain Diffusion for Visual Exploration: Cortical Discovery using Large
 Scale Generative Models
Authors: Andrew F. Luo, Margaret M. Henderson, Leila Wehbe, Michael J. Tarr
Categories: cs.CV
\\
 A long standing goal in neuroscience has been to elucidate the functional
organization of the brain. Within higher visual cortex, functional accounts
have remained relatively coarse, focusing on regions of interest (ROIs) and
taking the form of selectivity for broad categories such as faces, places,
bodies, food, or words. Because the identification of such ROIs has typically
relied on manually assembled stimulus sets consisting of isolated objects in
non-ecological contexts, exploring functional organization without robust a
priori hypotheses has been challenging. To overcome these limitations, we
introduce a data-driven approach in which we synthesize images predicted to
activate a given brain region using paired natural images and fMRI recordings,
bypassing the need for category-specific stimuli. Our approach -- Brain
Diffusion for Visual Exploration ("BrainDiVE") -- builds on recent generative
methods by combining large-scale diffusion models with brain-guided image
synthesis. Validating our method, we demonstrate the ability to synthesize
preferred images with appropriate semantic specificity for well-characterized
category-selective ROIs. We then show that BrainDiVE can characterize
differences between ROIs selective for the same high-level category. Finally we
identify novel functional subdivisions within these ROIs, validated with
behavioral data. These results advance our understanding of the fine-grained
functional organization of human visual cortex, and provide well-specified
constraints for further examination of cortical organization using
hypothesis-driven methods.
\\ ( https://arxiv.org/abs/2306.03089 ,  37283kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03092
Date: Mon, 5 Jun 2023 17:59:57 GMT   (7160kb,D)

Title: Neuralangelo: High-Fidelity Neural Surface Reconstruction
Authors: Zhaoshuo Li, Thomas M\"uller, Alex Evans, Russell H. Taylor, Mathias
 Unberath, Ming-Yu Liu, Chen-Hsuan Lin
Categories: cs.CV
Comments: CVPR 2023, project page:
 https://research.nvidia.com/labs/dir/neuralangelo
\\
 Neural surface reconstruction has been shown to be powerful for recovering
dense 3D surfaces via image-based neural rendering. However, current methods
struggle to recover detailed structures of real-world scenes. To address the
issue, we present Neuralangelo, which combines the representation power of
multi-resolution 3D hash grids with neural surface rendering. Two key
ingredients enable our approach: (1) numerical gradients for computing
higher-order derivatives as a smoothing operation and (2) coarse-to-fine
optimization on the hash grids controlling different levels of details. Even
without auxiliary inputs such as depth, Neuralangelo can effectively recover
dense 3D surface structures from multi-view images with fidelity significantly
surpassing previous methods, enabling detailed large-scale scene reconstruction
from RGB video captures.
\\ ( https://arxiv.org/abs/2306.03092 ,  7160kb)
------------------------------------------------------------------------------
\\
arXiv:2306.01799
Date: Thu, 1 Jun 2023 15:42:50 GMT   (142kb,D)

Title: Pairwise Ranking Losses of Click-Through Rates Prediction for Welfare
 Maximization in Ad Auctions
Authors: Boxiang Lyu, Zhe Feng, Zachary Robertson, Sanmi Koyejo
Categories: cs.GT cs.IR cs.LG
Comments: 25 pages, 6 figures
\\
 We study the design of loss functions for click-through rates (CTR) to
optimize (social) welfare in advertising auctions. Existing works either only
focus on CTR predictions without consideration of business objectives (e.g.,
welfare) in auctions or assume that the distribution over the participants'
expected cost-per-impression (eCPM) is known a priori, then use various
additional assumptions on the parametric form of the distribution to derive
loss functions for predicting CTRs. In this work, we bring back the welfare
objectives of ad auctions into CTR predictions and propose a novel weighted
rankloss to train the CTR model. Compared to existing literature, our approach
provides a provable guarantee on welfare but without assumptions on the eCPMs'
distribution while also avoiding the intractability of naively applying
existing learning-to-rank methods. Further, we propose a theoretically
justifiable technique for calibrating the losses using labels generated from a
teacher network, only assuming that the teacher network has bounded $\ell_2$
generalization error. Finally, we demonstrate the advantages of the proposed
loss on synthetic and real-world data.
\\ ( https://arxiv.org/abs/2306.01799 ,  142kb)
------------------------------------------------------------------------------
\\
arXiv:2306.01860
Date: Fri, 2 Jun 2023 18:29:07 GMT   (670kb,D)

Title: No Bidding, No Regret: Pairwise-Feedback Mechanisms for Digital Goods
 and Data Auctions
Authors: Zachary Robertson, Oluwasanmi Koyejo
Categories: cs.GT cs.AI cs.LG
Comments: 18 pages, 2 figures
\\
 The growing demand for data and AI-generated digital goods, such as
personalized written content and artwork, necessitates effective pricing and
feedback mechanisms that account for uncertain utility and costly production.
Motivated by these developments, this study presents a novel mechanism design
addressing a general repeated-auction setting where the utility derived from a
sold good is revealed post-sale. The mechanism's novelty lies in using pairwise
comparisons for eliciting information from the bidder, arguably easier for
humans than assigning a numerical value. Our mechanism chooses allocations
using an epsilon-greedy strategy and relies on pairwise comparisons between
realized utility from allocated goods and an arbitrary value, avoiding the
learning-to-bid problem explored in previous work. We prove this mechanism to
be asymptotically truthful, individually rational, and welfare and revenue
maximizing. The mechanism's relevance is broad, applying to any setting with
made-to-order goods of variable quality. Experimental results on multi-label
toxicity annotation data, an example of negative utilities, highlight how our
proposed mechanism could enhance social welfare in data auctions. Overall, our
focus on human factors contributes to the development of more human-aware and
efficient mechanism design.
\\ ( https://arxiv.org/abs/2306.01860 ,  670kb)
------------------------------------------------------------------------------
\\
arXiv:2306.01990
Date: Sat, 3 Jun 2023 03:30:42 GMT   (56kb,D)

Title: Incentivizing Exploration with Linear Contexts and Combinatorial Actions
Authors: Mark Sellke
Categories: cs.GT cs.LG
Comments: International Conference on Machine Learning (ICML) 2023
\\
 We advance the study of incentivized bandit exploration, in which arm choices
are viewed as recommendations and are required to be Bayesian incentive
compatible. Recent work has shown under certain independence assumptions that
after collecting enough initial samples, the popular Thompson sampling
algorithm becomes incentive compatible. We give an analog of this result for
linear bandits, where the independence of the prior is replaced by a natural
convexity condition. This opens up the possibility of efficient and
regret-optimal incentivized exploration in high-dimensional action spaces. In
the semibandit model, we also improve the sample complexity for the
pre-Thompson sampling phase of initial data collection.
\\ ( https://arxiv.org/abs/2306.01990 ,  56kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02040
Date: Sat, 3 Jun 2023 07:43:59 GMT   (429kb)

Title: Getting More by Knowing Less: Bayesian Incentive Compatible Mechanisms
 for Fair Division
Authors: Vasilis Gkatzelis, Alexandros Psomas, Xizhi Tan, and Paritosh Verma
Categories: cs.GT
Comments: 26 pages
\\
 We study fair resource allocation with strategic agents. It is well-known
that, across multiple fundamental problems in this domain, truthfulness and
fairness are incompatible. For example, when allocating indivisible goods,
there is no truthful and deterministic mechanism that guarantees envy-freeness
up to one item (EF1), even for two agents with additive valuations. Or, in
cake-cutting, no truthful and deterministic mechanism always outputs a
proportional allocation, even for two agents with piecewise-constant
valuations. Our work stems from the observation that, in the context of fair
division, truthfulness is used as a synonym for Dominant Strategy Incentive
Compatibility (DSIC), requiring that an agent prefers reporting the truth, no
matter what other agents report.
 In this paper, we instead focus on Bayesian Incentive Compatible (BIC)
mechanisms, requiring that agents are better off reporting the truth in
expectation over other agents' reports. We prove that, when agents know a bit
less about each other, a lot more is possible: using BIC mechanisms we can
overcome the aforementioned barriers that DSIC mechanisms face in both the
fundamental problems of allocation of indivisible goods and cake-cutting. We
prove that this is the case even for an arbitrary number of agents, as long as
the agents' priors about each others' types satisfy a neutrality condition. En
route to our results on BIC mechanisms, we also strengthen the state of the art
in terms of negative results for DSIC mechanisms.
\\ ( https://arxiv.org/abs/2306.02040 ,  429kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02179
Date: Sat, 3 Jun 2023 19:20:39 GMT   (322kb,D)

Title: Buying Time: Latency Racing vs. Bidding in Fair Transaction Ordering
Authors: Akaki Mamageishvili, Mahimna Kelkar, Jan Christoph Schlegel, Edward W.
 Felten
Categories: cs.GT cs.CR econ.TH
\\
 We design a practical algorithm for transaction ordering that takes into
account both transaction timestamps and bids. The algorithm guarantees that
users get their transactions published with bounded delay against a bid, while
it extracts a fair value from sophisticated users that have an edge in latency,
by moving expenditure from investment in latency improvement technology to
bidding. The algorithm creates a score from timestamps and bids, and orders
transactions based on the score. We first show that a scoring rule is the only
type of rule that satisfies the independence of latency races. We provide an
economic analysis of the protocol in an environment of private information,
where investment in latency is made ex-ante or interim stages, while bidding
happens at the interim stage where private signals have been observed. The
algorithm is useful for transaction sequencing in rollups or in other
environments where the sequencer has privileged access to order flows.
\\ ( https://arxiv.org/abs/2306.02179 ,  322kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02704
Date: Mon, 5 Jun 2023 08:55:50 GMT   (49kb)

Title: Calibrated Stackelberg Games: Learning Optimal Commitments Against
 Calibrated Agents
Authors: Nika Haghtalab, Chara Podimata, Kunhe Yang
Categories: cs.GT
\\
 In this paper, we introduce a generalization of the standard Stackelberg
Games (SGs) framework: Calibrated Stackelberg Games (CSGs). In CSGs, a
principal repeatedly interacts with an agent who (contrary to standard SGs)
does not have direct access to the principal's action but instead best-responds
to calibrated forecasts about it. CSG is a powerful modeling tool that goes
beyond assuming that agents use ad hoc and highly specified algorithms for
interacting in strategic settings and thus more robustly addresses real-life
applications that SGs were originally intended to capture. Along with CSGs, we
also introduce a stronger notion of calibration, termed adaptive calibration,
that provides fine-grained any-time calibration guarantees against adversarial
sequences. We give a general approach for obtaining adaptive calibration
algorithms and specialize them for finite CSGs. In our main technical result,
we show that in CSGs, the principal can achieve utility that converges to the
optimum Stackelberg value of the game both in finite and continuous settings,
and that no higher utility is achievable. Two prominent and immediate
applications of our results are the settings of learning in Stackelberg
Security Games and strategic classification, both against calibrated agents.
\\ ( https://arxiv.org/abs/2306.02704 ,  49kb)
------------------------------------------------------------------------------
\\
arXiv:2306.01768
Date: Sun, 28 May 2023 20:25:20 GMT   (106kb,D)

Title: A Quantitative Review on Language Model Efficiency Research
Authors: Meng Jiang, Hy Dang, Lingbo Tong
Categories: cs.LG cs.CL
Comments: 29 pages, 24 tables
\\
 Language models (LMs) are being scaled and becoming powerful. Improving their
efficiency is one of the core research topics in neural information processing
systems. Tay et al. (2022) provided a comprehensive overview of efficient
Transformers that have become an indispensable staple in the field of NLP.
However, in the section of "On Evaluation", they left an open question "which
fundamental efficient Transformer one should consider," answered by "still a
mystery" because "many research papers select their own benchmarks."
Unfortunately, there was not quantitative analysis about the performances of
Transformers on any benchmarks. Moreover, state space models (SSMs) have
demonstrated their abilities of modeling long-range sequences with
non-attention mechanisms, which were not discussed in the prior review. This
article makes a meta analysis on the results from a set of papers on efficient
Transformers as well as those on SSMs. It provides a quantitative review on LM
efficiency research and gives suggestions for future research.
\\ ( https://arxiv.org/abs/2306.01768 ,  106kb)
------------------------------------------------------------------------------
\\
arXiv:2306.01804
Date: Thu, 1 Jun 2023 17:59:12 GMT   (13043kb,D)

Title: Extracting Reward Functions from Diffusion Models
Authors: Felipe Nuti, Tim Franzmeyer, Jo\~ao F. Henriques
Categories: cs.LG cs.AI
\\
 Diffusion models have achieved remarkable results in image generation, and
have similarly been used to learn high-performing policies in sequential
decision-making tasks. Decision-making diffusion models can be trained on
lower-quality data, and then be steered with a reward function to generate
near-optimal trajectories. We consider the problem of extracting a reward
function by comparing a decision-making diffusion model that models low-reward
behavior and one that models high-reward behavior; a setting related to inverse
reinforcement learning. We first define the notion of a relative reward
function of two diffusion models and show conditions under which it exists and
is unique. We then devise a practical learning algorithm for extracting it by
aligning the gradients of a reward function -- parametrized by a neural network
-- to the difference in outputs of both diffusion models. Our method finds
correct reward functions in navigation environments, and we demonstrate that
steering the base model with the learned reward functions results in
significantly increased performance in standard locomotion benchmarks. Finally,
we demonstrate that our approach generalizes beyond sequential decision-making
by learning a reward-like function from two large-scale image generation
diffusion models. The extracted reward function successfully assigns lower
rewards to harmful images.
\\ ( https://arxiv.org/abs/2306.01804 ,  13043kb)
------------------------------------------------------------------------------
\\
arXiv:2306.01811
Date: Fri, 2 Jun 2023 07:00:42 GMT   (1727kb,D)

Title: DVFO: Dynamic Voltage, Frequency Scaling and Workload Offloading for DNN
 Edge Inference
Authors: Ziyang Zhang, Yang Zhao, Huan Li, and Jie Liu
Categories: cs.LG cs.DC cs.OS
\\
 Due to edge device resource constraints and different characteristics of deep
neural network (DNN) models, it is a big challenge to optimize DNN inference
performance in terms of energy consumption and inference latency on edge
devices. In addition to the dynamic voltage frequency scaling (DVFS) technique,
the edge-cloud architecture provides a collaborative approach to efficient DNN
inference. However, current edge-cloud collaborative inference methods have not
optimized various compute resources on edge devices. Thus, we propose DVFO, a
novel DVFS-enabled edge-cloud collaborative inference framework, which jointly
optimize DVFS and offloading parameters via deep reinforcement learning (DRL).
Specifically, DVFO automatically co-optimizes 1) CPU, GPU and memory
frequencies of edge devices, and 2) feature maps to be offloaded to cloud
servers. In addition, it leverages a thinking-while-moving concurrent mechanism
to accelerate the DRL learning process, and a spatialchannel attention
mechanism to extract DNN feature maps of secondary importance for workload
offloading. This approach improves energy efficiency and inference latency for
different DNN models under various edge-cloud network conditions. Experimental
results on different datasets show that DVFO reduces the average energy
consumption by 33% compared to state-of-the-art schemes. Moreover, DVFO
achieves up to 54% end-to-end inference latency reduction.
\\ ( https://arxiv.org/abs/2306.01811 ,  1727kb)
------------------------------------------------------------------------------
\\
arXiv:2306.01812
Date: Fri, 2 Jun 2023 07:10:45 GMT   (7800kb,D)

Title: SAPI: Surroundings-Aware Vehicle Trajectory Prediction at Intersections
Authors: Ethan Zhang, Hao Xiao, Yiqian Gan, Lei Wang
Categories: cs.LG
\\
 In this work we propose a deep learning model, i.e., SAPI, to predict vehicle
trajectories at intersections. SAPI uses an abstract way to represent and
encode surrounding environment by utilizing information from real-time map,
right-of-way, and surrounding traffic. The proposed model consists of two
convolutional network (CNN) and recurrent neural network (RNN)-based encoders
and one decoder. A refiner is proposed to conduct a look-back operation inside
the model, in order to make full use of raw history trajectory information. We
evaluate SAPI on a proprietary dataset collected in real-world intersections
through autonomous vehicles. It is demonstrated that SAPI shows promising
performance when predicting vehicle trajectories at intersection, and
outperforms benchmark methods. The average displacement error(ADE) and final
displacement error(FDE) for 6-second prediction are 1.84m and 4.32m
respectively. We also show that the proposed model can accurately predict
vehicle trajectories in different scenarios.
\\ ( https://arxiv.org/abs/2306.01812 ,  7800kb)
------------------------------------------------------------------------------
\\
arXiv:2306.01813
Date: Fri, 2 Jun 2023 09:04:45 GMT   (718kb,D)

Title: Learning the effective order of a hypergraph dynamical system
Authors: Leonie Neuh\"auser, Michael Scholkemper, Francesco Tudisco, Michael T.
 Schaub
Categories: cs.LG cs.SI physics.soc-ph
\\
 Dynamical systems on hypergraphs can display a rich set of behaviours not
observable for systems with pairwise interactions. Given a distributed
dynamical system with a putative hypergraph structure, an interesting question
is thus how much of this hypergraph structure is actually necessary to
faithfully replicate the observed dynamical behaviour. To answer this question,
we propose a method to determine the minimum order of a hypergraph necessary to
approximate the corresponding dynamics accurately. Specifically, we develop an
analytical framework that allows us to determine this order when the type of
dynamics is known. We utilize these ideas in conjunction with a hypergraph
neural network to directly learn the dynamics itself and the resulting order of
the hypergraph from both synthetic and real data sets consisting of observed
system trajectories.
\\ ( https://arxiv.org/abs/2306.01813 ,  718kb)
------------------------------------------------------------------------------
\\
arXiv:2306.01816
Date: Fri, 2 Jun 2023 11:35:58 GMT   (1994kb)

Title: Prediction of Citrus Diseases Using Machine Learning And Deep Learning:
 Classifier, Models SLR
Authors: Muhammad Shoaib Farooq, Abdullah Mehboob
Categories: cs.LG cs.AI
Comments: 13 pages, 9 figures
\\
 Citrus diseases have been major issues for citrus growing worldwide for many
years they can lead significantly reduce fruit quality. the most harmful citrus
diseases are citrus canker, citrus greening, citrus black spot, citrus leaf
miner which can have significant economic losses of citrus industry in
worldwide prevention and management strategies like chemical treatments. Citrus
diseases existing in all over the world where citrus is growing its effects the
citrus tree root, citrus tree leaf, citrus tree orange etc. Existing of citrus
diseases is highly impact on economic factor that can also produce low quality
fruits and increased the rate for diseases management. Sanitation and routine
monitoring can be effective in managing certain citrus diseases, but others may
require more intensive treatments like chemical or biological control methods.
\\ ( https://arxiv.org/abs/2306.01816 ,  1994kb)
------------------------------------------------------------------------------
\\
arXiv:2306.01817
Date: Fri, 2 Jun 2023 11:46:58 GMT   (1511kb)

Title: Heart Diseases Prediction Using Block-chain and Machine Learning
Authors: Muhammad Shoaib Farooq, Kiran Amjad
Categories: cs.LG cs.AI
Comments: page 23, figurse 19
\\
 Most people around the globe are dying due to heart disease. The main reason
behind the rapid increase in the death rate due to heart disease is that there
is no infrastructure developed for the healthcare department that can provide a
secure way of data storage and transmission. Due to redundancy in the patient
data, it is difficult for cardiac Professionals to predict the disease early
on. This rapid increase in the death rate due to heart disease can be
controlled by monitoring and eliminating some of the key attributes in the
early stages such as blood pressure, cholesterol level, body weight, and
addiction to smoking. Patient data can be monitored by cardiac Professionals
(Cp) by using the advanced framework in the healthcare departments. Blockchain
is the world's most reliable provider. The use of advanced systems in the
healthcare departments providing new ways of dealing with diseases has been
developed as well. In this article Machine Learning (ML) algorithm known as a
sine-cosine weighted k-nearest neighbor (SCA-WKNN) is used for predicting the
Hearth disease with the maximum accuracy among the existing approaches.
Blockchain technology has been used in the research to secure the data
throughout the session and can give more accurate results using this
technology. The performance of the system can be improved by using this
algorithm and the dataset proposed has been improved by using different
resources as well.
\\ ( https://arxiv.org/abs/2306.01817 ,  1511kb)
------------------------------------------------------------------------------
\\
arXiv:2306.01818
Date: Fri, 2 Jun 2023 11:59:57 GMT   (2182kb)

Title: Beta Thalassemia Carriers detection empowered federated Learning
Authors: Muhammad Shoaib Farooq, Hafiz Ali Younas
Categories: cs.LG cs.AI cs.CL
Comments: pages 17, figures 8
\\
 Thalassemia is a group of inherited blood disorders that happen when
hemoglobin, the protein in red blood cells that carries oxygen, is not made
enough. It is found all over the body and is needed for survival. If both
parents have thalassemia, a child's chance of getting it increases. Genetic
counselling and early diagnosis are essential for treating thalassemia and
stopping it from being passed on to future generations. It may be hard for
healthcare professionals to differentiate between people with thalassemia
carriers and those without. The current blood tests for beta thalassemia
carriers are too expensive, take too long, and require too much screening
equipment. The World Health Organization says there is a high death rate for
people with thalassemia. Therefore, it is essential to find thalassemia
carriers to act quickly. High-performance liquid chromatography (HPLC), the
standard test method, has problems such as cost, time, and equipment needs. So,
there must be a quick and cheap way to find people carrying the thalassemia
gene. Using federated learning (FL) techniques, this study shows a new way to
find people with the beta-thalassemia gene. FL allows data to be collected and
processed on-site while following privacy rules, making it an excellent choice
for sensitive health data. Researchers used FL to train a model for
beta-thalassemia carriers by looking at the complete blood count results and
red blood cell indices. The model was 92.38 % accurate at telling the
difference between beta-thalassemia carriers and people who did not have the
disease. The proposed FL model is better than other published methods in terms
of how well it works, how reliable it is, and how private it is. This research
shows a promising, quick, accurate, and low-cost way to find thalassemia
carriers and opens the door for screening them on a large scale.
\\ ( https://arxiv.org/abs/2306.01818 ,  2182kb)
------------------------------------------------------------------------------
\\
arXiv:2306.01820
Date: Fri, 2 Jun 2023 12:36:05 GMT   (1118kb,D)

Title: Concurrent Classifier Error Detection (CCED) in Large Scale Machine
 Learning Systems
Authors: Pedro Reviriego, Ziheng Wang, Alvaro Alonso, Zhen Gao, Farzad Niknia,
 Shanshan Liu and Fabrizio Lombardi
Categories: cs.LG
\\
 The complexity of Machine Learning (ML) systems increases each year, with
current implementations of large language models or text-to-image generators
having billions of parameters and requiring billions of arithmetic operations.
As these systems are widely utilized, ensuring their reliable operation is
becoming a design requirement. Traditional error detection mechanisms introduce
circuit or time redundancy that significantly impacts system performance. An
alternative is the use of Concurrent Error Detection (CED) schemes that operate
in parallel with the system and exploit their properties to detect errors. CED
is attractive for large ML systems because it can potentially reduce the cost
of error detection. In this paper, we introduce Concurrent Classifier Error
Detection (CCED), a scheme to implement CED in ML systems using a concurrent ML
classifier to detect errors. CCED identifies a set of check signals in the main
ML system and feeds them to the concurrent ML classifier that is trained to
detect errors. The proposed CCED scheme has been implemented and evaluated on
two widely used large-scale ML models: Contrastive Language Image Pretraining
(CLIP) used for image classification and Bidirectional Encoder Representations
from Transformers (BERT) used for natural language applications. The results
show that more than 95 percent of the errors are detected when using a simple
Random Forest classifier that is order of magnitude simpler than CLIP or BERT.
These results illustrate the potential of CCED to implement error detection in
large-scale ML models.
\\ ( https://arxiv.org/abs/2306.01820 ,  1118kb)
------------------------------------------------------------------------------
\\
arXiv:2306.01843
Date: Fri, 2 Jun 2023 18:03:03 GMT   (5079kb,D)

Title: Maximum Likelihood Training of Autoencoders
Authors: Peter Sorrenson, Felix Draxler, Armand Rousselot, Sander Hummerich,
 Lea Zimmerman and Ullrich K\"othe
Categories: cs.LG
\\
 Maximum likelihood training has favorable statistical properties and is
popular for generative modeling, especially with normalizing flows. On the
other hand, generative autoencoders promise to be more efficient than
normalizing flows due to the manifold hypothesis. In this work, we introduce
successful maximum likelihood training of unconstrained autoencoders for the
first time, bringing the two paradigms together. To do so, we identify and
overcome two challenges: Firstly, existing maximum likelihood estimators for
free-form networks are unacceptably slow, relying on iteration schemes whose
cost scales linearly with latent dimension. We introduce an improved estimator
which eliminates iteration, resulting in constant cost (roughly double the
runtime per batch of a vanilla autoencoder). Secondly, we demonstrate that
naively applying maximum likelihood to autoencoders can lead to divergent
solutions and use this insight to motivate a stable maximum likelihood training
objective. We perform extensive experiments on toy, tabular and image data,
demonstrating the competitive performance of the resulting model. We call our
model the maximum likelihood autoencoder (MLAE).
\\ ( https://arxiv.org/abs/2306.01843 ,  5079kb)
------------------------------------------------------------------------------
\\
arXiv:2306.01854
Date: Fri, 2 Jun 2023 18:16:35 GMT   (2694kb,D)

Title: Reinforcement Learning with General Utilities: Simpler Variance
 Reduction and Large State-Action Space
Authors: Anas Barakat, Ilyas Fatkhullin, Niao He
Categories: cs.LG math.OC
Comments: 48 pages, 2 figures, ICML 2023, this paper was initially submitted in
 January 26th 2023
Journal-ref: Proceedings of the Fortieth International Conference on Machine
 Learning (ICML 2023)
\\
 We consider the reinforcement learning (RL) problem with general utilities
which consists in maximizing a function of the state-action occupancy measure.
Beyond the standard cumulative reward RL setting, this problem includes as
particular cases constrained RL, pure exploration and learning from
demonstrations among others. For this problem, we propose a simpler single-loop
parameter-free normalized policy gradient algorithm. Implementing a recursive
momentum variance reduction mechanism, our algorithm achieves
$\tilde{\mathcal{O}}(\epsilon^{-3})$ and $\tilde{\mathcal{O}}(\epsilon^{-2})$
sample complexities for $\epsilon$-first-order stationarity and
$\epsilon$-global optimality respectively, under adequate assumptions. We
further address the setting of large finite state action spaces via linear
function approximation of the occupancy measure and show a
$\tilde{\mathcal{O}}(\epsilon^{-4})$ sample complexity for a simple policy
gradient method with a linear regression subroutine.
\\ ( https://arxiv.org/abs/2306.01854 ,  2694kb)
------------------------------------------------------------------------------
\\
arXiv:2306.01864
Date: Fri, 2 Jun 2023 18:41:39 GMT   (4985kb,D)

Title: Discovering COVID-19 Coughing and Breathing Patterns from Unlabeled Data
 Using Contrastive Learning with Varying Pre-Training Domains
Authors: Jinjin Cai, Sudip Vhaduri, and Xiao Luo
Categories: cs.LG cs.SD eess.AS
Comments: Accepted by Proceedings of INTERSPEECH 2023
Journal-ref: Proceedings of INTERSPEECH 2023
\\
 Rapid discovery of new diseases, such as COVID-19 can enable a timely
epidemic response, preventing the large-scale spread and protecting public
health. However, limited research efforts have been taken on this problem. In
this paper, we propose a contrastive learning-based modeling approach for
COVID-19 coughing and breathing pattern discovery from non-COVID coughs. To
validate our models, extensive experiments have been conducted using four large
audio datasets and one image dataset. We further explore the effects of
different factors, such as domain relevance and augmentation order on the
pre-trained models. Our results show that the proposed model can effectively
distinguish COVID-19 coughing and breathing from unlabeled data and labeled
non-COVID coughs with an accuracy of up to 0.81 and 0.86, respectively.
Findings from this work will guide future research to detect an outbreak of a
new disease early.
\\ ( https://arxiv.org/abs/2306.01864 ,  4985kb)
------------------------------------------------------------------------------
\\
arXiv:2306.01870
Date: Fri, 2 Jun 2023 18:57:24 GMT   (367kb,D)

Title: Layer-Wise Feedback Alignment is Conserved in Deep Neural Networks
Authors: Zachary Robertson, Oluwasanmi Koyejo
Categories: cs.LG stat.ML
Comments: 8 pages, 2 figures
\\
 In the quest to enhance the efficiency and bio-plausibility of training deep
neural networks, Feedback Alignment (FA), which replaces the backward pass
weights with random matrices in the training process, has emerged as an
alternative to traditional backpropagation. While the appeal of FA lies in its
circumvention of computational challenges and its plausible biological
alignment, the theoretical understanding of this learning rule remains partial.
This paper uncovers a set of conservation laws underpinning the learning
dynamics of FA, revealing intriguing parallels between FA and Gradient Descent
(GD). Our analysis reveals that FA harbors implicit biases akin to those
exhibited by GD, challenging the prevailing narrative that these learning
algorithms are fundamentally different. Moreover, we demonstrate that these
conservation laws elucidate sufficient conditions for layer-wise alignment with
feedback matrices in ReLU networks. We further show that this implies
over-parameterized two-layer linear networks trained with FA converge to
minimum-norm solutions. The implications of our findings offer avenues for
developing more efficient and biologically plausible alternatives to
backpropagation through an understanding of the principles governing learning
dynamics in deep networks.
\\ ( https://arxiv.org/abs/2306.01870 ,  367kb)
------------------------------------------------------------------------------
\\
arXiv:2306.01885
Date: Fri, 2 Jun 2023 19:37:38 GMT   (6926kb,D)

Title: Multifunctionality in a Connectome-Based Reservoir Computer
Authors: Jacob Morra, Andrew Flynn, Andreas Amann, Mark Daley
Categories: cs.LG cs.NE
Comments: 6 pages, 6 figures
\\
 Multifunctionality describes the capacity for a neural network to perform
multiple mutually exclusive tasks without altering its network connections; and
is an emerging area of interest in the reservoir computing machine learning
paradigm. Multifunctionality has been observed in the brains of humans and
other animals: particularly, in the lateral horn of the fruit fly. In this
work, we transplant the connectome of the fruit fly lateral horn to a reservoir
computer (RC), and investigate the extent to which this 'fruit fly RC' (FFRC)
exhibits multifunctionality using the 'seeing double' problem as a benchmark
test. We furthermore explore the dynamics of how this FFRC achieves
multifunctionality while varying the network's spectral radius. Compared to the
widely-used Erd\"os-Renyi Reservoir Computer (ERRC), we report that the FFRC
exhibits a greater capacity for multifunctionality; is multifunctional across a
broader hyperparameter range; and solves the seeing double problem far beyond
the previously observed spectral radius limit, wherein the ERRC's dynamics
become chaotic.
\\ ( https://arxiv.org/abs/2306.01885 ,  6926kb)
------------------------------------------------------------------------------
\\
arXiv:2306.01890
Date: Fri, 2 Jun 2023 19:51:48 GMT   (1111kb,D)

Title: Kernel Metric Learning for Clustering Mixed-type Data
Authors: Jesse S. Ghashti and John R. J. Thompson
Categories: cs.LG stat.CO stat.ME stat.OT
Comments: 23 pages, 5 tables, 2 figures
MSC-class: 62G07, 65D10
ACM-class: I.5.3; G.3; I.6.6
\\
 Distance-based clustering and classification are widely used in various
fields to group mixed numeric and categorical data. A predefined distance
measurement is used to cluster data points based on their dissimilarity. While
there exist numerous distance-based measures for data with pure numerical
attributes and several ordered and unordered categorical metrics, an optimal
distance for mixed-type data is an open problem. Many metrics convert numerical
attributes to categorical ones or vice versa. They handle the data points as a
single attribute type or calculate a distance between each attribute separately
and add them up. We propose a metric that uses mixed kernels to measure
dissimilarity, with cross-validated optimal kernel bandwidths. Our approach
improves clustering accuracy when utilized for existing distance-based
clustering algorithms on simulated and real-world datasets containing pure
continuous, categorical, and mixed-type data.
\\ ( https://arxiv.org/abs/2306.01890 ,  1111kb)
------------------------------------------------------------------------------
\\
arXiv:2306.01893
Date: Fri, 2 Jun 2023 19:58:14 GMT   (5565kb,D)

Title: Hierarchical Quadratic Random Forest Classifier
Authors: Faezeh Fallah
Categories: cs.LG cs.CV
\\
 In this paper, we proposed a hierarchical quadratic random forest classifier
for classifying multiresolution samples extracted from multichannel data. This
forest incorporated a penalized multivariate linear discriminant in each of its
decision nodes and processed squared features to realize quadratic decision
boundaries in the original feature space. The penalized discriminant was based
on a multiclass sparse discriminant analysis and the penalization was based on
a group Lasso regularizer which was an intermediate between the Lasso and the
ridge regularizer. The classification probabilities estimated by this forest
and the features learned by its decision nodes could be used standalone or
foster graph-based classifiers.
\\ ( https://arxiv.org/abs/2306.01893 ,  5565kb)
------------------------------------------------------------------------------
\\
arXiv:2306.01896
Date: Fri, 2 Jun 2023 20:01:09 GMT   (3023kb,D)

Title: Tackling Unbounded State Spaces in Continuing Task Reinforcement
 Learning
Authors: Brahma S. Pavse, Yudong Chen, Qiaomin Xie, Josiah P. Hanna
Categories: cs.LG
\\
 While deep reinforcement learning (RL) algorithms have been successfully
applied to many tasks, their inability to extrapolate and strong reliance on
episodic resets inhibits their applicability to many real-world settings. For
instance, in stochastic queueing problems, the state space can be unbounded and
the agent may have to learn online without the system ever being reset to
states the agent has seen before. In such settings, we show that deep RL agents
can diverge into unseen states from which they can never recover due to the
lack of resets, especially in highly stochastic environments. Towards
overcoming this divergence, we introduce a Lyapunov-inspired reward shaping
approach that encourages the agent to first learn to be stable (i.e. to achieve
bounded cost) and then to learn to be optimal. We theoretically show that our
reward shaping technique reduces the rate of divergence of the agent and
empirically find that it prevents it. We further combine our reward shaping
approach with a weight annealing scheme that gradually introduces optimality
and log-transform of state inputs, and find that these techniques enable deep
RL algorithms to learn high performing policies when learning online in
unbounded state space domains.
\\ ( https://arxiv.org/abs/2306.01896 ,  3023kb)
------------------------------------------------------------------------------
\\
arXiv:2306.01922
Date: Fri, 2 Jun 2023 21:24:13 GMT   (270kb,D)

Title: Agnostic Multi-Group Active Learning
Authors: Nick Rittler, Kamalika Chaudhuri
Categories: cs.LG
\\
 Inspired by the problem of improving classification accuracy on rare or hard
subsets of a population, there has been recent interest in models of learning
where the goal is to generalize to a collection of distributions, each
representing a ``group''. We consider a variant of this problem from the
perspective of active learning, where the learner is endowed with the power to
decide which examples are labeled from each distribution in the collection, and
the goal is to minimize the number of label queries while maintaining
PAC-learning guarantees. Our main challenge is that standard active learning
techniques such as disagreement-based active learning do not directly apply to
the multi-group learning objective. We modify existing algorithms to provide a
consistent active learning algorithm for an agnostic formulation of multi-group
learning, which given a collection of $G$ distributions and a hypothesis class
$\mathcal{H}$ with VC-dimension $d$, outputs an $\epsilon$-optimal hypothesis
using $\tilde{O}\left( (\nu^2/\epsilon^2+1) G d \theta_{\mathcal{G}}^2
\log^2(1/\epsilon) + G\log(1/\epsilon)/\epsilon^2 \right)$ label queries, where
$\theta_{\mathcal{G}}$ is the worst-case disagreement coefficient over the
collection. Roughly speaking, this guarantee improves upon the label complexity
of standard multi-group learning in regimes where disagreement-based active
learning algorithms may be expected to succeed, and the number of groups is not
too large. We also consider the special case where each distribution in the
collection is individually realizable with respect to $\mathcal{H}$, and
demonstrate $\tilde{O}\left( G d \theta_{\mathcal{G}} \log(1/\epsilon) \right)$
label queries are sufficient for learning in this case. We further give an
approximation result for the full agnostic case inspired by the group
realizable strategy.
\\ ( https://arxiv.org/abs/2306.01922 ,  270kb)
------------------------------------------------------------------------------
\\
arXiv:2306.01925
Date: Fri, 2 Jun 2023 21:30:44 GMT   (10152kb,D)

Title: Improving the generalizability and robustness of large-scale traffic
 signal control
Authors: Tianyu Shi and Francois-Xavier Devailly and Denis Larocque and Laurent
 Charlin
Categories: cs.LG
\\
 A number of deep reinforcement-learning (RL) approaches propose to control
traffic signals. In this work, we study the robustness of such methods along
two axes. First, sensor failures and GPS occlusions create missing-data
challenges and we show that recent methods remain brittle in the face of these
missing data. Second, we provide a more systematic study of the generalization
ability of RL methods to new networks with different traffic regimes. Again, we
identify the limitations of recent approaches. We then propose using a
combination of distributional and vanilla reinforcement learning through a
policy ensemble. Building upon the state-of-the-art previous model which uses a
decentralized approach for large-scale traffic signal control with graph
convolutional networks (GCNs), we first learn models using a distributional
reinforcement learning (DisRL) approach. In particular, we use implicit
quantile networks (IQN) to model the state-action return distribution with
quantile regression. For traffic signal control problems, an ensemble of
standard RL and DisRL yields superior performance across different scenarios,
including different levels of missing sensor data and traffic flow patterns.
Furthermore, the learning scheme of the resulting model can improve zero-shot
transferability to different road network structures, including both synthetic
networks and real-world networks (e.g., Luxembourg, Manhattan). We conduct
extensive experiments to compare our approach to multi-agent reinforcement
learning and traditional transportation approaches. Results show that the
proposed method improves robustness and generalizability in the face of missing
data, varying road networks, and traffic flows.
\\ ( https://arxiv.org/abs/2306.01925 ,  10152kb)
------------------------------------------------------------------------------
\\
arXiv:2306.01926
Date: Fri, 2 Jun 2023 21:45:13 GMT   (7568kb,D)

Title: RITA: Group Attention is All You Need for Timeseries Analytics
Authors: Jiaming Liang, Lei Cao, Samuel Madden, Zachary Ives, Guoliang Li
Categories: cs.LG cs.AI cs.DB
\\
 Timeseries analytics is of great importance in many real-world applications.
Recently, the Transformer model, popular in natural language processing, has
been leveraged to learn high quality feature embeddings from timeseries, core
to the performance of various timeseries analytics tasks. However, the
quadratic time and space complexities limit Transformers' scalability,
especially for long timeseries. To address these issues, we develop a
timeseries analytics tool, RITA, which uses a novel attention mechanism, named
group attention, to address this scalability issue. Group attention dynamically
clusters the objects based on their similarity into a small number of groups
and approximately computes the attention at the coarse group granularity. It
thus significantly reduces the time and space complexity, yet provides a
theoretical guarantee on the quality of the computed attention. The dynamic
scheduler of RITA continuously adapts the number of groups and the batch size
in the training process, ensuring group attention always uses the fewest groups
needed to meet the approximation quality requirement. Extensive experiments on
various timeseries datasets and analytics tasks demonstrate that RITA
outperforms the state-of-the-art in accuracy and is significantly faster --
with speedups of up to 63X.
\\ ( https://arxiv.org/abs/2306.01926 ,  7568kb)
------------------------------------------------------------------------------
\\
arXiv:2306.01937
Date: Fri, 2 Jun 2023 22:39:14 GMT   (1648kb,D)

Title: LIC-GAN: Language Information Conditioned Graph Generative GAN Model
Authors: Robert Lo, Arnhav Datar, Abishek Sridhar
Categories: cs.LG cs.AI
Comments: 15 pages, 8 figures
\\
 Deep generative models for Natural Language data offer a new angle on the
problem of graph synthesis: by optimizing differentiable models that directly
generate graphs, it is possible to side-step expensive search procedures in the
discrete and vast space of possible graphs. We introduce LIC-GAN, an implicit,
likelihood-free generative model for small graphs that circumvents the need for
expensive graph matching procedures. Our method takes as input a natural
language query and using a combination of language modelling and Generative
Adversarial Networks (GANs) and returns a graph that closely matches the
description of the query. We combine our approach with a reward network to
further enhance the graph generation with desired properties. Our experiments,
show that LIC-GAN does well on metrics such as PropMatch and Closeness getting
scores of 0.36 and 0.48. We also show that LIC-GAN performs as good as ChatGPT,
with ChatGPT getting scores of 0.40 and 0.42. We also conduct a few experiments
to demonstrate the robustness of our method, while also highlighting a few
interesting caveats of the model.
\\ ( https://arxiv.org/abs/2306.01937 ,  1648kb)
------------------------------------------------------------------------------
\\
arXiv:2306.01951
Date: Fri, 2 Jun 2023 23:23:34 GMT   (3198kb,D)

Title: GAD-NR: Graph Anomaly Detection via Neighborhood Reconstruction
Authors: Amit Roy, Juan Shu, Jia Li, Carl Yang, Olivier Elshocht, Jeroen Smeets
 and Pan Li
Categories: cs.LG
\\
 Graph Anomaly Detection (GAD) is a technique used to identify abnormal nodes
within graphs, finding applications in network security, fraud detection,
social media spam detection, and various other domains. A common method for GAD
is Graph Auto-Encoders (GAEs), which encode graph data into node
representations and identify anomalies by assessing the reconstruction quality
of the graphs based on these representations. However, existing GAE models are
primarily optimized for direct link reconstruction, resulting in nodes
connected in the graph being clustered in the latent space. As a result, they
excel at detecting cluster-type structural anomalies but struggle with more
complex structural anomalies that do not conform to clusters. To address this
limitation, we propose a novel solution called GAD-NR, a new variant of GAE
that incorporates neighborhood reconstruction for graph anomaly detection.
GAD-NR aims to reconstruct the entire neighborhood of a node, encompassing the
local structure, self-attributes, and neighbor attributes, based on the
corresponding node representation. By comparing the neighborhood reconstruction
loss between anomalous nodes and normal nodes, GAD-NR can effectively detect
any anomalies. Extensive experimentation conducted on six real-world datasets
validates the effectiveness of GAD-NR, showcasing significant improvements (by
up to 30% in AUC) over state-of-the-art competitors. The source code for GAD-NR
is openly available. Importantly, the comparative analysis reveals that the
existing methods perform well only in detecting one or two types of anomalies
out of the three types studied. In contrast, GAD-NR excels at detecting all
three types of anomalies across the datasets, demonstrating its comprehensive
anomaly detection capabilities.
\\ ( https://arxiv.org/abs/2306.01951 ,  3198kb)
------------------------------------------------------------------------------
\\
arXiv:2306.01958
Date: Fri, 2 Jun 2023 23:36:49 GMT   (1024kb,D)

Title: A Survey on Explainability of Graph Neural Networks
Authors: Jaykumar Kakkad, Jaspal Jannu, Kartik Sharma, Charu Aggarwal, Sourav
 Medya
Categories: cs.LG cs.AI
Comments: submitted to Bulletin of the IEEE Computer Society Technical
 Committee on Data Engineering
\\
 Graph neural networks (GNNs) are powerful graph-based deep-learning models
that have gained significant attention and demonstrated remarkable performance
in various domains, including natural language processing, drug discovery, and
recommendation systems. However, combining feature information and
combinatorial graph structures has led to complex non-linear GNN models.
Consequently, this has increased the challenges of understanding the workings
of GNNs and the underlying reasons behind their predictions. To address this,
numerous explainability methods have been proposed to shed light on the inner
mechanism of the GNNs. Explainable GNNs improve their security and enhance
trust in their recommendations. This survey aims to provide a comprehensive
overview of the existing explainability techniques for GNNs. We create a novel
taxonomy and hierarchy to categorize these methods based on their objective and
methodology. We also discuss the strengths, limitations, and application
scenarios of each category. Furthermore, we highlight the key evaluation
metrics and datasets commonly used to assess the explainability of GNNs. This
survey aims to assist researchers and practitioners in understanding the
existing landscape of explainability methods, identifying gaps, and fostering
further advancements in interpretable graph-based machine learning.
\\ ( https://arxiv.org/abs/2306.01958 ,  1024kb)
------------------------------------------------------------------------------
\\
arXiv:2306.01963
Date: Sat, 3 Jun 2023 00:16:27 GMT   (1386kb,D)

Title: Over-the-Air Federated Learning In Broadband Communication
Authors: Wayne Lemieux, Raphael Pinard, Mitra Hassani
Categories: cs.LG
\\
 Federated learning (FL) is a privacy-preserving distributed machine learning
paradigm that operates at the wireless edge. It enables clients to collaborate
on model training while keeping their data private from adversaries and the
central server. However, current FL approaches have limitations. Some rely on
secure multiparty computation, which can be vulnerable to inference attacks.
Others employ differential privacy, but this may lead to decreased test
accuracy when dealing with a large number of parties contributing small amounts
of data. To address these issues, this paper proposes a novel approach that
integrates federated learning seamlessly into the inner workings of MIMO
(Multiple-Input Multiple-Output) systems.
\\ ( https://arxiv.org/abs/2306.01963 ,  1386kb)
------------------------------------------------------------------------------
\\
arXiv:2306.01970
Date: Sat, 3 Jun 2023 00:38:40 GMT   (2267kb,D)

Title: Temporal-spatial Correlation Attention Network for Clinical Data
 Analysis in Intensive Care Unit
Authors: Weizhi Nie, Yuhe Yu, Chen Zhang, Dan Song, Lina Zhao, Yunpeng Bai
Categories: cs.LG cs.AI cs.CV cs.CY
\\
 In recent years, medical information technology has made it possible for
electronic health record (EHR) to store fairly complete clinical data. This has
brought health care into the era of "big data". However, medical data are often
sparse and strongly correlated, which means that medical problems cannot be
solved effectively. With the rapid development of deep learning in recent
years, it has provided opportunities for the use of big data in healthcare. In
this paper, we propose a temporal-saptial correlation attention network (TSCAN)
to handle some clinical characteristic prediction problems, such as predicting
death, predicting length of stay, detecting physiologic decline, and
classifying phenotypes. Based on the design of the attention mechanism model,
our approach can effectively remove irrelevant items in clinical data and
irrelevant nodes in time according to different tasks, so as to obtain more
accurate prediction results. Our method can also find key clinical indicators
of important outcomes that can be used to improve treatment options. Our
experiments use information from the Medical Information Mart for Intensive
Care (MIMIC-IV) database, which is open to the public. Finally, we have
achieved significant performance benefits of 2.0\% (metric) compared to other
SOTA prediction methods. We achieved a staggering 90.7\% on mortality rate,
45.1\% on length of stay. The source code can be find:
\url{https://github.com/yuyuheintju/TSCAN}.
\\ ( https://arxiv.org/abs/2306.01970 ,  2267kb)
------------------------------------------------------------------------------
\\
arXiv:2306.01977
Date: Sat, 3 Jun 2023 01:21:58 GMT   (2592kb,D)

Title: AlerTiger: Deep Learning for AI Model Health Monitoring at LinkedIn
Authors: Zhentao Xu, Ruoying Wang, Girish Balaji, Manas Bundele, Xiaofei Liu,
 Leo Liu, Tie Wang
Categories: cs.LG
ACM-class: I.2
DOI: 10.1145/3580305.3599802
\\
 Data-driven companies use AI models extensively to develop products and
intelligent business solutions, making the health of these models crucial for
business success. Model monitoring and alerting in industries pose unique
challenges, including a lack of clear model health metrics definition, label
sparsity, and fast model iterations that result in short-lived models and
features. As a product, there are also requirements for scalability,
generalizability, and explainability. To tackle these challenges, we propose
AlerTiger, a deep-learning-based MLOps model monitoring system that helps AI
teams across the company monitor their AI models' health by detecting anomalies
in models' input features and output score over time. The system consists of
four major steps: model statistics generation, deep-learning-based anomaly
detection, anomaly post-processing, and user alerting. Our solution generates
three categories of statistics to indicate AI model health, offers a two-stage
deep anomaly detection solution to address label sparsity and attain the
generalizability of monitoring new models, and provides holistic reports for
actionable alerts. This approach has been deployed to most of LinkedIn's
production AI models for over a year and has identified several model issues
that later led to significant business metric gains after fixing.
\\ ( https://arxiv.org/abs/2306.01977 ,  2592kb)
------------------------------------------------------------------------------
\\
arXiv:2306.01984
Date: Sat, 3 Jun 2023 02:46:31 GMT   (863kb,D)

Title: DYffusion: A Dynamics-informed Diffusion Model for Spatiotemporal
 Forecasting
Authors: Salva R\"uhling Cachay, Bo Zhao, Hailey James, Rose Yu
Categories: cs.LG cs.AI stat.ML
Comments: Code will be released at: https://github.com/Rose-STL-Lab/dyffusion
\\
 While diffusion models can successfully generate data and make predictions,
they are predominantly designed for static images. We propose an approach for
training diffusion models for dynamics forecasting that leverages the temporal
dynamics encoded in the data, directly coupling it with the diffusion steps in
the network. We train a stochastic, time-conditioned interpolator and a
backbone forecaster network that mimic the forward and reverse processes of
conventional diffusion models, respectively. This design choice naturally
encodes multi-step and long-range forecasting capabilities, allowing for highly
flexible, continuous-time sampling trajectories and the ability to trade-off
performance with accelerated sampling at inference time. In addition, the
dynamics-informed diffusion process imposes a strong inductive bias, allowing
for improved computational efficiency compared to traditional Gaussian
noise-based diffusion models. Our approach performs competitively on
probabilistic skill score metrics in complex dynamics forecasting of sea
surface temperatures, Navier-Stokes flows, and spring mesh systems.
\\ ( https://arxiv.org/abs/2306.01984 ,  863kb)
------------------------------------------------------------------------------
\\
arXiv:2306.01986
Date: Sat, 3 Jun 2023 02:47:46 GMT   (2678kb)

Title: A Novel Deep Knowledge-based Learning Method for Wind Speed Forecast
Authors: Yang Yang, Jin Lang, Jian Wu, Yanyan Zhang
Categories: cs.LG cs.AI cs.SY eess.SY math.OC
\\
 The increasing installation rate of wind power poses great challenges to the
global power system. In order to ensure the reliable operation of the power
system, it is necessary to accurately forecast the wind speed and power of the
wind turbines. At present, deep learning is progressively applied to the wind
speed prediction. Nevertheless, the recent deep learning methods still reflect
the embarrassment for practical applications due to model interpretability and
hardware limitation. To this end, a novel deep knowledge-based learning method
is proposed in this paper. The proposed method hybridizes pre-training method
and auto-encoder structure to improve data representation and modeling of the
deep knowledge-based learning framework. In order to form knowledge and
corresponding absorbers, the original data is preprocessed by an optimization
model based on correlation to construct multi-layer networks (knowledge) which
are absorbed by sequence to sequence (Seq2Seq) models. Specifically, new
cognition and memory units (CMU) are designed to reinforce traditional deep
learning framework. Finally, the effectiveness of the proposed method is
verified by three wind prediction cases from a wind farm in Liaoning, China.
Experimental results show that the proposed method increases the stability and
training efficiency compared to the traditional LSTM method and LSTM/GRU-based
Seq2Seq method for applications of wind speed forecasting.
\\ ( https://arxiv.org/abs/2306.01986 ,  2678kb)
------------------------------------------------------------------------------
\\
arXiv:2306.01991
Date: Sat, 3 Jun 2023 03:36:47 GMT   (2226kb)

Title: A Bio-Inspired Chaos Sensor Based on the Perceptron Neural Network:
 Concept and Application for Computational Neuro-science
Authors: Andrei Velichko, Petr Boriskov, Maksim Belyaev and Vadim Putrolaynen
Categories: cs.LG cs.AI cs.NE nlin.CD
Comments: 12 pages, 22 figures, 4 tables
\\
 The study presents a bio-inspired chaos sensor based on the perceptron neural
network. After training, the sensor on perceptron, having 50 neurons in the
hidden layer and 1 neuron at the output, approximates the fuzzy entropy of
short time series with high accuracy with a determination coefficient R2 ~ 0.9.
The Hindmarsh-Rose spike model was used to generate time series of spike
intervals, and datasets for training and testing the perceptron. The selection
of the hyperparameters of the perceptron model and the estimation of the sensor
accuracy were performed using the K-block cross-validation method. Even for a
hidden layer with 1 neuron, the model approximates the fuzzy entropy with good
results and the metric R2 ~ 0.5-0.8. In a simplified model with 1 neuron and
equal weights in the first layer, the principle of approximation is based on
the linear transformation of the average value of the time series into the
entropy value. The bio-inspired chaos sensor model based on an ensemble of
neurons is able to dynamically track the chaotic behavior of a spiked biosystem
and transmit this information to other parts of the bio-system for further
processing. The study will be useful for specialists in the field of
computational neuroscience.
\\ ( https://arxiv.org/abs/2306.01991 ,  2226kb)
------------------------------------------------------------------------------
\\
arXiv:2306.01992
Date: Sat, 3 Jun 2023 03:41:33 GMT   (10kb,D)

Title: On Size-Independent Sample Complexity of ReLU Networks
Authors: Mark Sellke
Categories: cs.LG stat.ML
Comments: 4 pages
\\
 We study the sample complexity of learning ReLU neural networks from the
point of view of generalization. Given norm constraints on the weight matrices,
a common approach is to estimate the Rademacher complexity of the associated
function class. Previously Golowich-Rakhlin-Shamir (2020) obtained a bound
independent of the network size (scaling with a product of Frobenius norms)
except for a factor of the square-root depth. We give a refinement which often
has no explicit depth-dependence at all.
\\ ( https://arxiv.org/abs/2306.01992 ,  10kb)
------------------------------------------------------------------------------
\\
arXiv:2306.01993
Date: Sat, 3 Jun 2023 03:42:30 GMT   (41kb)

Title: Provable benefits of score matching
Authors: Chirag Pabbaraju, Dhruv Rohatgi, Anish Sevekari, Holden Lee, Ankur
 Moitra, Andrej Risteski
Categories: cs.LG cs.DS stat.ML
Comments: 25 Pages
\\
 Score matching is an alternative to maximum likelihood (ML) for estimating a
probability distribution parametrized up to a constant of proportionality. By
fitting the ''score'' of the distribution, it sidesteps the need to compute
this constant of proportionality (which is often intractable). While score
matching and variants thereof are popular in practice, precise theoretical
understanding of the benefits and tradeoffs with maximum likelihood -- both
computational and statistical -- are not well understood. In this work, we give
the first example of a natural exponential family of distributions such that
the score matching loss is computationally efficient to optimize, and has a
comparable statistical efficiency to ML, while the ML loss is intractable to
optimize using a gradient-based method. The family consists of exponentials of
polynomials of fixed degree, and our result can be viewed as a continuous
analogue of recent developments in the discrete setting. Precisely, we show:
(1) Designing a zeroth-order or first-order oracle for optimizing the maximum
likelihood loss is NP-hard. (2) Maximum likelihood has a statistical efficiency
polynomial in the ambient dimension and the radius of the parameters of the
family. (3) Minimizing the score matching loss is both computationally and
statistically efficient, with complexity polynomial in the ambient dimension.
\\ ( https://arxiv.org/abs/2306.01993 ,  41kb)
------------------------------------------------------------------------------
\\
arXiv:2306.01995
Date: Sat, 3 Jun 2023 04:00:47 GMT   (39kb)

Title: Asymptotically Optimal Pure Exploration for Infinite-Armed Bandits
Authors: Xiao-Yue Gong, Mark Sellke
Categories: cs.LG stat.ML
\\
 We study pure exploration with infinitely many bandit arms generated i.i.d.
from an unknown distribution. Our goal is to efficiently select a single high
quality arm whose average reward is, with probability $1-\delta$, within
$\varepsilon$ of being among the top $\eta$-fraction of arms; this is a natural
adaptation of the classical PAC guarantee for infinite action sets. We consider
both the fixed confidence and fixed budget settings, aiming respectively for
minimal expected and fixed sample complexity.
 For fixed confidence, we give an algorithm with expected sample complexity
$O\left(\frac{\log (1/\eta)\log (1/\delta)}{\eta\varepsilon^2}\right)$. This is
optimal except for the $\log (1/\eta)$ factor, and the $\delta$-dependence
closes a quadratic gap in the literature. For fixed budget, we show the
asymptotically optimal sample complexity as $\delta\to 0$ is
$c^{-1}\log(1/\delta)\big(\log\log(1/\delta)\big)^2$ to leading order.
Equivalently, the optimal failure probability given exactly $N$ samples decays
as $\exp\big(-cN/\log^2 N\big)$, up to a factor $1\pm o_N(1)$ inside the
exponent. The constant $c$ depends explicitly on the problem parameters
(including the unknown arm distribution) through a certain Fisher information
distance. Even the strictly super-linear dependence on $\log(1/\delta)$ was not
known and resolves a question of Grossman and Moshkovitz (FOCS 2016, SIAM
Journal on Computing 2020).
\\ ( https://arxiv.org/abs/2306.01995 ,  39kb)
------------------------------------------------------------------------------
\\
arXiv:2306.01997
Date: Sat, 3 Jun 2023 04:16:31 GMT   (2466kb,D)

Title: UADB: Unsupervised Anomaly Detection Booster
Authors: Hangting Ye, Zhining Liu, Xinyi Shen, Wei Cao, Shun Zheng, Xiaofan
 Gui, Huishuai Zhang, Yi Chang, Jiang Bian
Categories: cs.LG
\\
 Unsupervised Anomaly Detection (UAD) is a key data mining problem owing to
its wide real-world applications. Due to the complete absence of supervision
signals, UAD methods rely on implicit assumptions about anomalous patterns
(e.g., scattered/sparsely/densely clustered) to detect anomalies. However,
real-world data are complex and vary significantly across different domains. No
single assumption can describe such complexity and be valid in all scenarios.
This is also confirmed by recent research that shows no UAD method is
omnipotent. Based on above observations, instead of searching for a magic
universal winner assumption, we seek to design a general UAD Booster (UADB)
that empowers any UAD models with adaptability to different data. This is a
challenging task given the heterogeneous model structures and assumptions
adopted by existing UAD methods. To achieve this, we dive deep into the UAD
problem and find that compared to normal data, anomalies (i) lack clear
structure/pattern in feature space, thus (ii) harder to learn by model without
a suitable assumption, and finally, leads to (iii) high variance between
different learners. In light of these findings, we propose to (i) distill the
knowledge of the source UAD model to an imitation learner (booster) that holds
no data assumption, then (ii) exploit the variance between them to perform
automatic correction, and thus (iii) improve the booster over the original UAD
model. We use a neural network as the booster for its strong expressive power
as a universal approximator and ability to perform flexible post-hoc tuning.
Note that UADB is a model-agnostic framework that can enhance heterogeneous UAD
models in a unified way. Extensive experiments on over 80 tabular datasets
demonstrate the effectiveness of UADB.
\\ ( https://arxiv.org/abs/2306.01997 ,  2466kb)
------------------------------------------------------------------------------
\\
arXiv:2306.01999
Date: Sat, 3 Jun 2023 04:23:49 GMT   (875kb,D)

Title: GAT-GAN : A Graph-Attention-based Time-Series Generative Adversarial
 Network
Authors: Srikrishna Iyer and Teng Teck Hou
Categories: cs.LG cs.AI
Comments: 9 pages, 1 figure, 3 tables, preprint under review
\\
 Generative Adversarial Networks (GANs) have proven to be a powerful tool for
generating realistic synthetic data. However, traditional GANs often struggle
to capture complex relationships between features which results in generation
of unrealistic multivariate time-series data. In this paper, we propose a
Graph-Attention-based Generative Adversarial Network (GAT-GAN) that explicitly
includes two graph-attention layers, one that learns temporal dependencies
while the other captures spatial relationships. Unlike RNN-based GANs that
struggle with modeling long sequences of data points, GAT-GAN generates long
time-series data of high fidelity using an adversarially trained autoencoder
architecture. Our empirical evaluations, using a variety of real-time-series
datasets, show that our framework consistently outperforms state-of-the-art
benchmarks based on \emph{Frechet Transformer distance} and \emph{Predictive
score}, that characterizes (\emph{Fidelity, Diversity}) and \emph{predictive
performance} respectively. Moreover, we introduce a Frechet Inception
distance-like (FID) metric for time-series data called Frechet Transformer
distance (FTD) score (lower is better), to evaluate the quality and variety of
generated data. We also found that low FTD scores correspond to the
best-performing downstream predictive experiments. Hence, FTD scores can be
used as a standardized metric to evaluate synthetic time-series data.
\\ ( https://arxiv.org/abs/2306.01999 ,  875kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02002
Date: Sat, 3 Jun 2023 04:56:04 GMT   (507kb,D)

Title: Can Directed Graph Neural Networks be Adversarially Robust?
Authors: Zhichao Hou, Xitong Zhang, Wei Wang, Charu C. Aggarwal, Xiaorui Liu
Categories: cs.LG cs.AI cs.CR
\\
 The existing research on robust Graph Neural Networks (GNNs) fails to
acknowledge the significance of directed graphs in providing rich information
about networks' inherent structure. This work presents the first investigation
into the robustness of GNNs in the context of directed graphs, aiming to
harness the profound trust implications offered by directed graphs to bolster
the robustness and resilience of GNNs. Our study reveals that existing directed
GNNs are not adversarially robust. In pursuit of our goal, we introduce a new
and realistic directed graph attack setting and propose an innovative,
universal, and efficient message-passing framework as a plug-in layer to
significantly enhance the robustness of GNNs. Combined with existing defense
strategies, this framework achieves outstanding clean accuracy and
state-of-the-art robust performance, offering superior defense against both
transfer and adaptive attacks. The findings in this study reveal a novel and
promising direction for this crucial research area. The code will be made
publicly available upon the acceptance of this work.
\\ ( https://arxiv.org/abs/2306.02002 ,  507kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02003
Date: Sat, 3 Jun 2023 05:01:51 GMT   (1346kb,D)

Title: On Optimal Caching and Model Multiplexing for Large Model Inference
Authors: Banghua Zhu, Ying Sheng, Lianmin Zheng, Clark Barrett, Michael I.
 Jordan, Jiantao Jiao
Categories: cs.LG cs.AI cs.PF cs.SY eess.SY stat.ML
\\
 Large Language Models (LLMs) and other large foundation models have achieved
noteworthy success, but their size exacerbates existing resource consumption
and latency challenges. In particular, the large-scale deployment of these
models is hindered by the significant resource requirements during inference.
In this paper, we study two approaches for mitigating these challenges:
employing a cache to store previous queries and learning a model multiplexer to
choose from an ensemble of models for query processing.
 Theoretically, we provide an optimal algorithm for jointly optimizing both
approaches to reduce the inference cost in both offline and online tabular
settings. By combining a caching algorithm, namely Greedy Dual Size with
Frequency (GDSF) or Least Expected Cost (LEC), with a model multiplexer, we
achieve optimal rates in both offline and online settings. Empirically,
simulations show that the combination of our caching and model multiplexing
algorithms greatly improves over the baselines, with up to $50\times$
improvement over the baseline when the ratio between the maximum cost and
minimum cost is $100$. Experiments on real datasets show a $4.3\times$
improvement in FLOPs over the baseline when the ratio for FLOPs is $10$, and a
$1.8\times$ improvement in latency when the ratio for average latency is
$1.85$.
\\ ( https://arxiv.org/abs/2306.02003 ,  1346kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02006
Date: Sat, 3 Jun 2023 05:32:19 GMT   (1021kb,D)

Title: MA2CL:Masked Attentive Contrastive Learning for Multi-Agent
 Reinforcement Learning
Authors: Haolin Song, Mingxiao Feng, Wengang Zhou, Houqiang Li
Categories: cs.LG
\\
 Recent approaches have utilized self-supervised auxiliary tasks as
representation learning to improve the performance and sample efficiency of
vision-based reinforcement learning algorithms in single-agent settings.
However, in multi-agent reinforcement learning (MARL), these techniques face
challenges because each agent only receives partial observation from an
environment influenced by others, resulting in correlated observations in the
agent dimension. So it is necessary to consider agent-level information in
representation learning for MARL. In this paper, we propose an effective
framework called \textbf{M}ulti-\textbf{A}gent \textbf{M}asked
\textbf{A}ttentive \textbf{C}ontrastive \textbf{L}earning (MA2CL), which
encourages learning representation to be both temporal and agent-level
predictive by reconstructing the masked agent observation in latent space.
Specifically, we use an attention reconstruction model for recovering and the
model is trained via contrastive learning. MA2CL allows better utilization of
contextual information at the agent level, facilitating the training of MARL
agents for cooperation tasks. Extensive experiments demonstrate that our method
significantly improves the performance and sample efficiency of different MARL
algorithms and outperforms other methods in various vision-based and
state-based scenarios. Our code can be found in
\url{https://github.com/ustchlsong/MA2CL}
\\ ( https://arxiv.org/abs/2306.02006 ,  1021kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02010
Date: Sat, 3 Jun 2023 05:45:29 GMT   (80kb,D)

Title: Memorization Capacity of Multi-Head Attention in Transformers
Authors: Sadegh Mahdavi, Renjie Liao, Christos Thrampoulidis
Categories: cs.LG
\\
 In this paper, we investigate the memorization capabilities of multi-head
attention in Transformers, motivated by the central role attention plays in
these models. Under a mild linear independence assumption on the input data, we
present a theoretical analysis demonstrating that an $H$-head attention layer
with a context size $n$, dimension $d$, and $O(Hd^2)$ parameters can memorize
$O(Hn)$ examples. We conduct experiments that verify our assumptions on the
image classification task using Vision Transformer. To validate our theoretical
findings, we perform synthetic experiments and show a linear relationship
between memorization capacity and the number of attention heads.
\\ ( https://arxiv.org/abs/2306.02010 ,  80kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02025
Date: Sat, 3 Jun 2023 06:51:22 GMT   (863kb,D)

Title: Exploring Global and Local Information for Anomaly Detection with Normal
 Samples
Authors: Fan Xu, Nan Wang, Xibin Zhao
Categories: cs.LG
Comments: 6 pages, 1 figures
\\
 Anomaly detection aims to detect data that do not conform to regular
patterns, and such data is also called outliers. The anomalies to be detected
are often tiny in proportion, containing crucial information, and are suitable
for application scenes like intrusion detection, fraud detection, fault
diagnosis, e-commerce platforms, et al. However, in many realistic scenarios,
only the samples following normal behavior are observed, while we can hardly
obtain any anomaly information. To address such problem, we propose an anomaly
detection method GALDetector which is combined of global and local information
based on observed normal samples. The proposed method can be divided into a
three-stage method. Firstly, the global similar normal scores and the local
sparsity scores of unlabeled samples are computed separately. Secondly,
potential anomaly samples are separated from the unlabeled samples
corresponding to these two scores and corresponding weights are assigned to the
selected samples. Finally, a weighted anomaly detector is trained by loads of
samples, then the detector is utilized to identify else anomalies. To evaluate
the effectiveness of the proposed method, we conducted experiments on three
categories of real-world datasets from diverse domains, and experimental
results show that our method achieves better performance when compared with
other state-of-the-art methods.
\\ ( https://arxiv.org/abs/2306.02025 ,  863kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02029
Date: Sat, 3 Jun 2023 07:16:17 GMT   (300kb,D)

Title: Model-aided Federated Reinforcement Learning for Multi-UAV Trajectory
 Planning in IoT Networks
Authors: Jichao Chen, Omid Esrafilian, Harald Bayerlein, David Gesbert, and
 Marco Caccamo
Categories: cs.LG
Comments: 7 pages, 2 figures
\\
 Deploying teams of cooperative unmanned aerial vehicles (UAVs) to harvest
data from distributed Internet of Things (IoT) devices requires efficient
trajectory planning and coordination algorithms. Multi-agent reinforcement
learning (MARL) has emerged as an effective solution, but often requires
extensive and costly real-world training data. In this paper, we propose a
novel model-aided federated MARL algorithm to coordinate multiple UAVs on a
data harvesting mission with limited knowledge about the environment,
significantly reducing the real-world training data demand. The proposed
algorithm alternates between learning an environment model from real-world
measurements and federated QMIX training in the simulated environment.
Specifically, collected measurements from the real-world environment are used
to learn the radio channel and estimate unknown IoT device locations to create
a simulated environment. Each UAV agent trains a local QMIX model in its
simulated environment and continuously consolidates it through federated
learning with other agents, accelerating the learning process and further
improving training sample efficiency. Simulation results demonstrate that our
proposed model-aided FedQMIX algorithm substantially reduces the need for
real-world training experiences while attaining similar data collection
performance as standard MARL algorithms.
\\ ( https://arxiv.org/abs/2306.02029 ,  300kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02031
Date: Sat, 3 Jun 2023 07:17:48 GMT   (2223kb,D)

Title: DOS: Diverse Outlier Sampling for Out-of-Distribution Detection
Authors: Wenyu Jiang, Hao Cheng, Mingcai Chen, Chongjun Wang, Hongxin Wei
Categories: cs.LG
\\
 Modern neural networks are known to give overconfident prediction for
out-of-distribution inputs when deployed in the open world. It is common
practice to leverage a surrogate outlier dataset to regularize the model during
training, and recent studies emphasize the role of uncertainty in designing the
sampling strategy for outlier dataset. However, the OOD samples selected solely
based on predictive uncertainty can be biased towards certain types, which may
fail to capture the full outlier distribution. In this work, we empirically
show that diversity is critical in sampling outliers for OOD detection
performance. Motivated by the observation, we propose a straightforward and
novel sampling strategy named DOS (Diverse Outlier Sampling) to select diverse
and informative outliers. Specifically, we cluster the normalized features at
each iteration, and the most informative outlier from each cluster is selected
for model training with absent category loss. With DOS, the sampled outliers
efficiently shape a globally compact decision boundary between ID and OOD data.
Extensive experiments demonstrate the superiority of DOS, reducing the average
FPR95 by up to 25.79% on CIFAR-100 with TI-300K.
\\ ( https://arxiv.org/abs/2306.02031 ,  2223kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02049
Date: Sat, 3 Jun 2023 08:24:53 GMT   (393kb,D)

Title: LambdaBeam: Neural Program Search with Higher-Order Functions and
 Lambdas
Authors: Kensen Shi, Hanjun Dai, Wen-Ding Li, Kevin Ellis, Charles Sutton
Categories: cs.LG cs.PL
\\
 Search is an important technique in program synthesis that allows for
adaptive strategies such as focusing on particular search directions based on
execution results. Several prior works have demonstrated that neural models are
effective at guiding program synthesis searches. However, a common drawback of
those approaches is the inability to handle iterative loops, higher-order
functions, or lambda functions, thus limiting prior neural searches from
synthesizing longer and more general programs. We address this gap by designing
a search algorithm called LambdaBeam that can construct arbitrary lambda
functions that compose operations within a given DSL. We create semantic vector
representations of the execution behavior of the lambda functions and train a
neural policy network to choose which lambdas to construct during search, and
pass them as arguments to higher-order functions to perform looping
computations. Our experiments show that LambdaBeam outperforms neural,
symbolic, and LLM-based techniques in an integer list manipulation domain.
\\ ( https://arxiv.org/abs/2306.02049 ,  393kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02050
Date: Sat, 3 Jun 2023 08:32:35 GMT   (3012kb,D)

Title: Provable Dynamic Fusion for Low-Quality Multimodal Data
Authors: Qingyang Zhang, Haitao Wu, Changqing Zhang, Qinghua Hu, Huazhu Fu,
 Joey Tianyi Zhou, Xi Peng
Categories: cs.LG cs.CV
Comments: Accepted by ICML 2023
\\
 The inherent challenge of multimodal fusion is to precisely capture the
cross-modal correlation and flexibly conduct cross-modal interaction. To fully
release the value of each modality and mitigate the influence of low-quality
multimodal data, dynamic multimodal fusion emerges as a promising learning
paradigm. Despite its widespread use, theoretical justifications in this field
are still notably lacking. Can we design a provably robust multimodal fusion
method? This paper provides theoretical understandings to answer this question
under a most popular multimodal fusion framework from the generalization
perspective. We proceed to reveal that several uncertainty estimation solutions
are naturally available to achieve robust multimodal fusion. Then a novel
multimodal fusion framework termed Quality-aware Multimodal Fusion (QMF) is
proposed, which can improve the performance in terms of classification accuracy
and model robustness. Extensive experimental results on multiple benchmarks can
support our findings.
\\ ( https://arxiv.org/abs/2306.02050 ,  3012kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02063
Date: Sat, 3 Jun 2023 09:27:15 GMT   (8443kb,D)

Title: Exploring the Optimal Choice for Generative Processes in Diffusion
 Models: Ordinary vs Stochastic Differential Equations
Authors: Yu Cao, Jingrun Chen, Yixin Luo, Xiang Zhou
Categories: cs.LG
\\
 The diffusion model has shown remarkable success in computer vision, but it
remains unclear whether ODE-based probability flow or SDE-based diffusion
models are superior and under what circumstances. Comparing the two is
challenging due to dependencies on data distribution, score training, and other
numerical factors. In this paper, we examine the problem mathematically by
examining two limiting scenarios: the ODE case and the large diffusion case. We
first introduce a pulse-shape error to perturb the score function and analyze
error accumulation, with a generalization to arbitrary error. Our findings
indicate that when the perturbation occurs at the end of the generative
process, the ODE model outperforms the SDE model (with a large diffusion
coefficient). However, when the perturbation occurs earlier, the SDE model
outperforms the ODE model, and we demonstrate that the error of sample
generation due to pulse-shape error can be exponentially suppressed as the
diffusion term's magnitude increases to infinity. Numerical validation of this
phenomenon is provided using toy models such as Gaussian, Gaussian mixture
models, and Swiss roll. Finally, we experiment with MNIST and observe that
varying the diffusion coefficient can improve sample quality even when the
score function is not well trained.
\\ ( https://arxiv.org/abs/2306.02063 ,  8443kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02066
Date: Sat, 3 Jun 2023 09:43:59 GMT   (9718kb,D)

Title: Variational Gaussian Process Diffusion Processes
Authors: Prakhar Verma, Vincent Adam, Arno Solin
Categories: cs.LG stat.ML
Comments: 26 pages, 11 figures
\\
 Diffusion processes are a class of stochastic differential equations (SDEs)
providing a rich family of expressive models that arise naturally in dynamic
modelling tasks. Probabilistic inference and learning under generative models
with latent processes endowed with a non-linear diffusion process prior are
intractable problems. We build upon work within variational inference
approximating the posterior process as a linear diffusion process, point out
pathologies in the approach, and propose an alternative parameterization of the
Gaussian variational process using a continuous exponential family description.
This allows us to trade a slow inference algorithm with fixed-point iterations
for a fast algorithm for convex optimization akin to natural gradient descent,
which also provides a better objective for the learning of model parameters.
\\ ( https://arxiv.org/abs/2306.02066 ,  9718kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02081
Date: Sat, 3 Jun 2023 11:07:18 GMT   (240kb,D)

Title: Message-passing selection: Towards interpretable GNNs for graph
 classification
Authors: Wenda Li, Kaixuan Chen, Shunyu Liu, Wenjie Huang, Haofei Zhang,
 Yingjie Tian, Yun Su, Mingli Song
Categories: cs.LG cs.AI
Comments: 6 pages, 1 figures
\\
 In this paper, we strive to develop an interpretable GNNs' inference
paradigm, termed MSInterpreter, which can serve as a plug-and-play scheme
readily applicable to various GNNs' baselines. Unlike the most existing
explanation methods, MSInterpreter provides a Message-passing Selection
scheme(MSScheme) to select the critical paths for GNNs' message aggregations,
which aims at reaching the self-explaination instead of post-hoc explanations.
In detail, the elaborate MSScheme is designed to calculate weight factors of
message aggregation paths by considering the vanilla structure and node
embedding components, where the structure base aims at weight factors among
node-induced substructures; on the other hand, the node embedding base focuses
on weight factors via node embeddings obtained by one-layer GNN.Finally, we
demonstrate the effectiveness of our approach on graph classification
benchmarks.
\\ ( https://arxiv.org/abs/2306.02081 ,  240kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02090
Date: Sat, 3 Jun 2023 11:45:16 GMT   (610kb,D)

Title: Deep Classifier Mimicry without Data Access
Authors: Steven Braun, Martin Mundt, Kristian Kersting
Categories: cs.LG cs.AI
Comments: 10 pages main, 4 figures, 2 tables, 2 pages appendix
\\
 Access to pre-trained models has recently emerged as a standard across
numerous machine learning domains. Unfortunately, access to the original data
the models were trained on may not equally be granted. This makes it
tremendously challenging to fine-tune, compress models, adapt continually, or
to do any other type of data-driven update. We posit that original data access
may however not be required. Specifically, we propose Contrastive Abductive
Knowledge Extraction (CAKE), a model-agnostic knowledge distillation procedure
that mimics deep classifiers without access to the original data. To this end,
CAKE generates pairs of noisy synthetic samples and diffuses them contrastively
toward a model's decision boundary. We empirically corroborate CAKE's
effectiveness using several benchmark datasets and various architectural
choices, paving the way for broad application.
\\ ( https://arxiv.org/abs/2306.02090 ,  610kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02109
Date: Sat, 3 Jun 2023 13:25:26 GMT   (1692kb,D)

Title: Encoding Time-Series Explanations through Self-Supervised Model Behavior
 Consistency
Authors: Owen Queen, Thomas Hartvigsen, Teddy Koker, Huan He, Theodoros
 Tsiligkaridis, Marinka Zitnik
Categories: cs.LG
\\
 Interpreting time series models is uniquely challenging because it requires
identifying both the location of time series signals that drive model
predictions and their matching to an interpretable temporal pattern. While
explainers from other modalities can be applied to time series, their inductive
biases do not transfer well to the inherently uninterpretable nature of time
series. We present TimeX, a time series consistency model for training
explainers. TimeX trains an interpretable surrogate to mimic the behavior of a
pretrained time series model. It addresses the issue of model faithfulness by
introducing model behavior consistency, a novel formulation that preserves
relations in the latent space induced by the pretrained model with relations in
the latent space induced by TimeX. TimeX provides discrete attribution maps
and, unlike existing interpretability methods, it learns a latent space of
explanations that can be used in various ways, such as to provide landmarks to
visually aggregate similar explanations and easily recognize temporal patterns.
We evaluate TimeX on 8 synthetic and real-world datasets and compare its
performance against state-of-the-art interpretability methods. We also conduct
case studies using physiological time series. Quantitative evaluations
demonstrate that TimeX achieves the highest or second-highest performance in
every metric compared to baselines across all datasets. Through case studies,
we show that the novel components of TimeX show potential for training
faithful, interpretable models that capture the behavior of pretrained time
series models.
\\ ( https://arxiv.org/abs/2306.02109 ,  1692kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02117
Date: Sat, 3 Jun 2023 14:12:31 GMT   (970kb,D)

Title: Scaling Up, Scaling Deep: Blockwise Graph Contrastive Learning
Authors: Jintang Li, Wangbin Sun, Ruofan Wu, Yuchang Zhu, Liang Chen, Zibin
 Zheng
Categories: cs.LG cs.AI
Comments: Preprint; Code is available at
 https://github.com/EdisonLeeeee/BlockGCL
\\
 Oversmoothing is a common phenomenon in graph neural networks (GNNs), in
which an increase in the network depth leads to a deterioration in their
performance. Graph contrastive learning (GCL) is emerging as a promising way of
leveraging vast unlabeled graph data. As a marriage between GNNs and
contrastive learning, it remains unclear whether GCL inherits the same
oversmoothing defect from GNNs. This work undertakes a fundamental analysis of
GCL from the perspective of oversmoothing on the first hand. We demonstrate
empirically that increasing network depth in GCL also leads to oversmoothing in
their deep representations, and surprisingly, the shallow ones. We refer to
this phenomenon in GCL as long-range starvation', wherein lower layers in deep
networks suffer from degradation due to the lack of sufficient guidance from
supervision (e.g., loss computing). Based on our findings, we present BlockGCL,
a remarkably simple yet effective blockwise training framework to prevent GCL
from notorious oversmoothing. Without bells and whistles, BlockGCL consistently
improves robustness and stability for well-established GCL methods with
increasing numbers of layers on real-world graph benchmarks. We believe our
work will provide insights for future improvements of scalable and deep GCL
frameworks.
\\ ( https://arxiv.org/abs/2306.02117 ,  970kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02121
Date: Sat, 3 Jun 2023 14:25:15 GMT   (3169kb,D)

Title: Identifying Subgroups of ICU Patients Using End-to-End Multivariate
 Time-Series Clustering Algorithm Based on Real-World Vital Signs Data
Authors: Tongyue Shi, Zhilong Zhang, Wentie Liu, Junhua Fang, Jianguo Hao,
 Shuai Jin, Huiying Zhao and Guilan Kong
Categories: cs.LG cs.AI cs.CY math.OC
Comments: Proceedings of Beijing Health Data Science Summit (HDSS) 2023
\\
 This study employed the MIMIC-IV database as data source to investigate the
use of dynamic, high-frequency, multivariate time-series vital signs data,
including temperature, heart rate, mean blood pressure, respiratory rate, and
SpO2, monitored first 8 hours data in the ICU stay. Various clustering
algorithms were compared, and an end-to-end multivariate time series clustering
system called Time2Feat, combined with K-Means, was chosen as the most
effective method to cluster patients in the ICU. In clustering analysis, data
of 8,080 patients admitted between 2008 and 2016 was used for model development
and 2,038 patients admitted between 2017 and 2019 for model validation. By
analyzing the differences in clinical mortality prognosis among different
categories, varying risks of ICU mortality and hospital mortality were found
between different subgroups. Furthermore, the study visualized the trajectory
of vital signs changes. The findings of this study provide valuable insights
into the potential use of multivariate time-series clustering systems in
patient management and monitoring in the ICU setting.
\\ ( https://arxiv.org/abs/2306.02121 ,  3169kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02137
Date: Sat, 3 Jun 2023 15:32:20 GMT   (13572kb,D)

Title: Inconsistent Matters: A Knowledge-guided Dual-consistency Network for
 Multi-modal Rumor Detection
Authors: Mengzhu Sun, Xi Zhang, Jianqiang Ma, Sihong Xie, Yazheng Liu, and
 Philip S. Yu
Categories: cs.LG
Journal-ref: IEEE Transactions on Knowledge and Data Engineering, 2023
DOI: 10.1109/TKDE.2023.3275586
\\
 Rumor spreaders are increasingly utilizing multimedia content to attract the
attention and trust of news consumers. Though quite a few rumor detection
models have exploited the multi-modal data, they seldom consider the
inconsistent semantics between images and texts, and rarely spot the
inconsistency among the post contents and background knowledge. In addition,
they commonly assume the completeness of multiple modalities and thus are
incapable of handling handle missing modalities in real-life scenarios.
Motivated by the intuition that rumors in social media are more likely to have
inconsistent semantics, a novel Knowledge-guided Dual-consistency Network is
proposed to detect rumors with multimedia contents. It uses two consistency
detection subnetworks to capture the inconsistency at the cross-modal level and
the content-knowledge level simultaneously. It also enables robust multi-modal
representation learning under different missing visual modality conditions,
using a special token to discriminate between posts with visual modality and
posts without visual modality. Extensive experiments on three public real-world
multimedia datasets demonstrate that our framework can outperform the
state-of-the-art baselines under both complete and incomplete modality
conditions. Our codes are available at https://github.com/MengzSun/KDCN.
\\ ( https://arxiv.org/abs/2306.02137 ,  13572kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02157
Date: Sat, 3 Jun 2023 16:56:18 GMT   (1550kb)

Title: Transforming to Yoked Neural Networks to Improve ANN Structure
Authors: Xinshun Liu and Yizhi Fang and Yichao Jiang
Categories: cs.LG
\\
 Most existing classical artificial neural networks (ANN) are designed as a
tree structure to imitate neural networks. In this paper, we argue that the
connectivity of a tree is not sufficient to characterize a neural network. The
nodes of the same level of a tree cannot be connected with each other, i.e.,
these neural unit cannot share information with each other, which is a major
drawback of ANN. Although ANN has been significantly improved in recent years
to more complex structures, such as the directed acyclic graph (DAG), these
methods also have unidirectional and acyclic bias for ANN. In this paper, we
propose a method to build a bidirectional complete graph for the nodes in the
same level of an ANN, which yokes the nodes of the same level to formulate a
neural module. We call our model as YNN in short. YNN promotes the information
transfer significantly which obviously helps in improving the performance of
the method. Our YNN can imitate neural networks much better compared with the
traditional ANN. In this paper, we analyze the existing structural bias of ANN
and propose a model YNN to efficiently eliminate such structural bias. In our
model, nodes also carry out aggregation and transformation of features, and
edges determine the flow of information. We further impose auxiliary sparsity
constraint to the distribution of connectedness, which promotes the learned
structure to focus on critical connections. Finally, based on the optimized
structure, we also design small neural module structure based on the minimum
cut technique to reduce the computational burden of the YNN model. This
learning process is compatible with the existing networks and different tasks.
The obtained quantitative experimental results reflect that the learned
connectivity is superior to the traditional NN structure.
\\ ( https://arxiv.org/abs/2306.02157 ,  1550kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02161
Date: Sat, 3 Jun 2023 17:10:33 GMT   (436kb,D)

Title: Few-Shot Open-Set Learning for On-Device Customization of KeyWord
 Spotting Systems
Authors: Manuele Rusci and Tinne Tuytelaars
Categories: cs.LG
Comments: Accepted at INTERSPEECH 2023
\\
 A personalized KeyWord Spotting (KWS) pipeline typically requires the
training of a Deep Learning model on a large set of user-defined speech
utterances, preventing fast customization directly applied on-device. To fill
this gap, this paper investigates few-shot learning methods for open-set KWS
classification by combining a deep feature encoder with a prototype-based
classifier. With user-defined keywords from 10 classes of the Google Speech
Command dataset, our study reports an accuracy of up to 76% in a 10-shot
scenario while the false acceptance rate of unknown data is kept to 5%. In the
analyzed settings, the usage of the triplet loss to train an encoder with
normalized output features performs better than the prototypical networks
jointly trained with a generator of dummy unknown-class prototypes. This design
is also more effective than encoders trained on a classification problem and
features fewer parameters than other iso-accuracy approaches.
\\ ( https://arxiv.org/abs/2306.02161 ,  436kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02192
Date: Sat, 3 Jun 2023 20:34:14 GMT   (794kb,D)

Title: Correcting auto-differentiation in neural-ODE training
Authors: Yewei Xu, Shi Chen, Qin Li and Stephen J. Wright
Categories: cs.LG cs.NA math.NA
\\
 Does the use of auto-differentiation yield reasonable updates to deep neural
networks that represent neural ODEs? Through mathematical analysis and
numerical evidence, we find that when the neural network employs high-order
forms to approximate the underlying ODE flows (such as the Linear Multistep
Method (LMM)), brute-force computation using auto-differentiation often
produces non-converging artificial oscillations. In the case of Leapfrog, we
propose a straightforward post-processing technique that effectively eliminates
these oscillations, rectifies the gradient computation and thus respects the
updates of the underlying flow.
\\ ( https://arxiv.org/abs/2306.02192 ,  794kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02208
Date: Sat, 3 Jun 2023 22:41:44 GMT   (2447kb,D)

Title: Tight Regret Bounds for Single-pass Streaming Multi-armed Bandits
Authors: Chen Wang
Categories: cs.LG cs.DS stat.ML
Comments: ICML 2023
\\
 Regret minimization in streaming multi-armed bandits (MABs) has been studied
extensively in recent years. In the single-pass setting with $K$ arms and $T$
trials, a regret lower bound of $\Omega(T^{2/3})$ has been proved for any
algorithm with $o(K)$ memory (Maiti et al. [NeurIPS'21]; Agarwal at al.
[COLT'22]). On the other hand, however, the previous best regret upper bound is
still $O(K^{1/3} T^{2/3}\log^{1/3}(T))$, which is achieved by the streaming
implementation of the simple uniform exploration. The $O(K^{1/3}\log^{1/3}(T))$
gap leaves the open question of the tight regret bound in the single-pass MABs
with sublinear arm memory.
 In this paper, we answer this open problem and complete the picture of regret
minimization in single-pass streaming MABs. We first improve the regret lower
bound to $\Omega(K^{1/3}T^{2/3})$ for algorithms with $o(K)$ memory, which
matches the uniform exploration regret up to a logarithm factor in $T$. We then
show that the $\log^{1/3}(T)$ factor is not necessary, and we can achieve
$O(K^{1/3}T^{2/3})$ regret by finding an $\varepsilon$-best arm and committing
to it in the rest of the trials. For regret minimization with high constant
probability, we can apply the single-memory $\varepsilon$-best arm algorithms
in Jin et al. [ICML'21] to obtain the optimal bound. Furthermore, for the
expected regret minimization, we design an algorithm with a single-arm memory
that achieves $O(K^{1/3} T^{2/3}\log(K))$ regret, and an algorithm with
$O(\log^{*}(n))$-memory with the optimal $O(K^{1/3} T^{2/3})$ regret following
the $\varepsilon$-best arm algorithm in Assadi and Wang [STOC'20].
 We further tested the empirical performances of our algorithms. The
simulation results show that the proposed algorithms consistently outperform
the benchmark uniform exploration algorithm by a large margin, and on occasion,
reduce the regret by up to 70%.
\\ ( https://arxiv.org/abs/2306.02208 ,  2447kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02210
Date: Sat, 3 Jun 2023 22:57:59 GMT   (1662kb,D)

Title: GPT-FL: Generative Pre-trained Model-Assisted Federated Learning
Authors: Tuo Zhang, Tiantian Feng, Samiul Alam, Mi Zhang, Shrikanth S.
 Narayanan, Salman Avestimehr
Categories: cs.LG cs.DC
\\
 In this work, we propose GPT-FL, a generative pre-trained model-assisted
federated learning (FL) framework. At its core, GPT-FL leverages generative
pre-trained models to generate diversified synthetic data. These generated data
are used to train a downstream model on the server, which is then fine-tuned
with private client data under the standard FL framework. We show that GPT-FL
consistently outperforms state-of-the-art FL methods in terms of model test
accuracy, communication efficiency, and client sampling efficiency. Through
comprehensive ablation analysis, we discover that the downstream model
generated by synthetic data plays a crucial role in controlling the direction
of gradient diversity during FL training, which enhances convergence speed and
contributes to the notable accuracy boost observed with GPT-FL. Also,
regardless of whether the target data falls within or outside the domain of the
pre-trained generative model, GPT-FL consistently achieves significant
performance gains, surpassing the results obtained by models trained solely
with FL or synthetic data.
\\ ( https://arxiv.org/abs/2306.02210 ,  1662kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02216
Date: Sat, 3 Jun 2023 23:53:57 GMT   (359kb,D)

Title: Forgettable Federated Linear Learning with Certified Data Removal
Authors: Ruinan Jin, Minghui Chen, Qiong Zhang, Xiaoxiao Li
Categories: cs.LG cs.CV
\\
 Federated learning (FL) is a trending distributed learning framework that
enables collaborative model training without data sharing. Machine learning
models trained on datasets can potentially expose the private information of
the training data, revealing details about individual data records. In this
study, we focus on the FL paradigm that grants clients the ``right to be
forgotten''. The forgettable FL framework should bleach its global model
weights as it has never seen that client and hence does not reveal any
information about the client. To this end, we propose the Forgettable Federated
Linear Learning (2F2L) framework featured with novel training and data removal
strategies. The training pipeline, named Federated linear training, employs
linear approximation on the model parameter space to enable our 2F2L framework
work for deep neural networks while achieving comparable results with canonical
neural network training. We also introduce FedRemoval, an efficient and
effective removal strategy that tackles the computational challenges in FL by
approximating the Hessian matrix using public server data from the pretrained
model. Unlike the previous uncertified and heuristic machine unlearning methods
in FL, we provide theoretical guarantees by bounding the differences of model
weights by our FedRemoval and that from retraining from scratch. Experimental
results on MNIST and Fashion-MNIST datasets demonstrate the effectiveness of
our method in achieving a balance between model accuracy and information
removal, outperforming baseline strategies and approaching retraining from
scratch.
\\ ( https://arxiv.org/abs/2306.02216 ,  359kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02223
Date: Sun, 4 Jun 2023 00:50:35 GMT   (7616kb,D)

Title: Prescriptive PCA: Dimensionality Reduction for Two-stage Stochastic
 Optimization
Authors: Long He, Ho-Yin Mak
Categories: cs.LG math.OC
\\
 In this paper, we consider the alignment between an upstream dimensionality
reduction task of learning a low-dimensional representation of a set of
high-dimensional data and a downstream optimization task of solving a
stochastic program parameterized by said representation. In this case, standard
dimensionality reduction methods (e.g., principal component analysis) may not
perform well, as they aim to maximize the amount of information retained in the
representation and do not generally reflect the importance of such information
in the downstream optimization problem. To address this problem, we develop a
prescriptive dimensionality reduction framework that aims to minimize the
degree of suboptimality in the optimization phase. For the case where the
downstream stochastic optimization problem has an expected value objective, we
show that prescriptive dimensionality reduction can be performed via solving a
distributionally-robust optimization problem, which admits a semidefinite
programming relaxation. Computational experiments based on a warehouse
transshipment problem and a vehicle repositioning problem show that our
approach significantly outperforms principal component analysis with real and
synthetic data sets.
\\ ( https://arxiv.org/abs/2306.02223 ,  7616kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02235
Date: Sun, 4 Jun 2023 02:32:12 GMT   (255kb,D)

Title: Learning Linear Causal Representations from Interventions under General
 Nonlinear Mixing
Authors: Simon Buchholz, Goutham Rajendran, Elan Rosenfeld, Bryon Aragam,
 Bernhard Sch\"olkopf, Pradeep Ravikumar
Categories: cs.LG cs.AI math.ST stat.ME stat.ML stat.TH
Comments: 38 pages
\\
 We study the problem of learning causal representations from unknown, latent
interventions in a general setting, where the latent distribution is Gaussian
but the mixing function is completely general. We prove strong identifiability
results given unknown single-node interventions, i.e., without having access to
the intervention targets. This generalizes prior works which have focused on
weaker classes, such as linear maps or paired counterfactual data. This is also
the first instance of causal identifiability from non-paired interventions for
deep neural network embeddings. Our proof relies on carefully uncovering the
high-dimensional geometric structure present in the data distribution after a
non-linear density transformation, which we capture by analyzing quadratic
forms of precision matrices of the latent distributions. Finally, we propose a
contrastive algorithm to identify the latent variables in practice and evaluate
its performance on various tasks.
\\ ( https://arxiv.org/abs/2306.02235 ,  255kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02285
Date: Sun, 4 Jun 2023 07:26:20 GMT   (7814kb,D)

Title: Clarify Confused Nodes Through Separated Learning
Authors: Shengbo Gong, Jiajun Zhou, Qi Xuan
Categories: cs.LG cs.SI
Comments: 20 pages
\\
 Graph neural networks (GNNs) have achieved remarkable advances in
graph-oriented tasks. However, real-world graphs invariably contain a certain
proportion of heterophilous nodes, challenging the homophily assumption of
classical GNNs and hindering their performance. Most existing studies continue
to design generic models with shared weights between heterophilous and
homophilous nodes. Despite the incorporation of high-order message or
multi-channel architectures, these efforts often fall short. A minority of
studies attempt to train different node groups separately, but suffering from
inappropriate separation metric and low efficiency. In this paper, we first
propose a new metric, termed Neighborhood Confusion (NC), to facilitate a more
reliable separation of nodes. We observe that node groups with different levels
of NC values exhibit certain differences in intra-group accuracy and visualized
embeddings. These pave a way for Neighborhood Confusion-guided Graph
Convolutional Network (NCGCN), in which nodes are grouped by their NC values
and accept intra-group weight sharing and message passing. Extensive
experiments on both homophilous and heterophilous benchmarks demonstrate that
NCGCN can effectively separate nodes and offers significant performance
improvement compared to latest methods.
\\ ( https://arxiv.org/abs/2306.02285 ,  7814kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02312
Date: Sun, 4 Jun 2023 09:34:41 GMT   (33kb,D)

Title: (Un)reasonable Allure of Ante-hoc Interpretability for High-stakes
 Domains: Transparency Is Necessary but Insufficient for Explainability
Authors: Kacper Sokol and Julia E. Vogt
Categories: cs.LG cs.AI
\\
 Ante-hoc interpretability has become the holy grail of explainable machine
learning for high-stakes domains such as healthcare; however, this notion is
elusive, lacks a widely-accepted definition and depends on the deployment
context. It can refer to predictive models whose structure adheres to
domain-specific constraints, or ones that are inherently transparent. The
latter notion assumes observers who judge this quality, whereas the former
presupposes them to have technical and domain expertise, in certain cases
rendering such models unintelligible. Additionally, its distinction from the
less desirable post-hoc explainability, which refers to methods that construct
a separate explanatory model, is vague given that transparent predictors may
still require (post-)processing to yield satisfactory explanatory insights.
Ante-hoc interpretability is thus an overloaded concept that comprises a range
of implicit properties, which we unpack in this paper to better understand what
is needed for its safe deployment across high-stakes domains. To this end, we
outline model- and explainer-specific desiderata that allow us to navigate its
distinct realisations in view of the envisaged application and audience.
\\ ( https://arxiv.org/abs/2306.02312 ,  33kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02325
Date: Sun, 4 Jun 2023 10:50:13 GMT   (2484kb,D)

Title: Random Feedback Alignment Algorithms to train Neural Networks: Why do
 they Align?
Authors: Dominique Chu, Florian Bacho
Categories: cs.LG cs.AI
\\
 Feedback alignment algorithms are an alternative to backpropagation to train
neural networks, whereby some of the partial derivatives that are required to
compute the gradient are replaced by random terms. This essentially transforms
the update rule into a random walk in weight space. Surprisingly, learning
still works with those algorithms, including training of deep neural networks.
This is generally attributed to an alignment of the update of the random walker
with the true gradient - the eponymous gradient alignment -- which drives an
approximate gradient descend. The mechanism that leads to this alignment
remains unclear, however. In this paper, we use mathematical reasoning and
simulations to investigate gradient alignment. We observe that the feedback
alignment update rule has fixed points, which correspond to extrema of the loss
function. We show that gradient alignment is a stability criterion for those
fixed points. It is only a necessary criterion for algorithm performance.
Experimentally, we demonstrate that high levels of gradient alignment can lead
to poor algorithm performance and that the alignment is not always driving the
gradient descend.
\\ ( https://arxiv.org/abs/2306.02325 ,  2484kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02326
Date: Sun, 4 Jun 2023 10:50:52 GMT   (3201kb,D)

Title: Cross-LKTCN: Modern Convolution Utilizing Cross-Variable Dependency for
 Multivariate Time Series Forecasting Dependency for Multivariate Time Series
 Forecasting
Authors: Donghao Luo, Xue Wang
Categories: cs.LG
\\
 The past few years have witnessed the rapid development in multivariate time
series forecasting. The key to accurate forecasting results is capturing the
long-term dependency between each time step (cross-time dependency) and
modeling the complex dependency between each variable (cross-variable
dependency) in multivariate time series. However, recent methods mainly focus
on the cross-time dependency but seldom consider the cross-variable dependency.
To fill this gap, we find that convolution, a traditional technique but
recently losing steam in time series forecasting, meets the needs of
respectively capturing the cross-time and cross-variable dependency. Based on
this finding, we propose a modern pure convolution structure, namely
Cross-LKTCN, to better utilize both cross-time and cross-variable dependency
for time series forecasting. Specifically in each Cross-LKTCN block, a
depth-wise large kernel convolution with large receptive field is proposed to
capture cross-time dependency, and then two successive point-wise group
convolution feed forward networks are proposed to capture cross-variable
dependency. Experimental results on real-world benchmarks show that Cross-LKTCN
achieves state-of-the-art forecasting performance and improves the forecasting
accuracy significantly compared with existing convolutional-based models and
cross-variable methods.
\\ ( https://arxiv.org/abs/2306.02326 ,  3201kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02335
Date: Sun, 4 Jun 2023 11:52:59 GMT   (44kb)

Title: Towards Robust Feature Learning with t-vFM Similarity for Continual
 Learning
Authors: Bilan Gao, YoungBin Kim
Categories: cs.LG cs.CV
\\
 Continual learning has been developed using standard supervised contrastive
loss from the perspective of feature learning. Due to the data imbalance during
the training, there are still challenges in learning better representations. In
this work, we suggest using a different similarity metric instead of cosine
similarity in supervised contrastive loss in order to learn more robust
representations. We validate the our method on one of the image classification
datasets Seq-CIFAR-10 and the results outperform recent continual learning
baselines.
\\ ( https://arxiv.org/abs/2306.02335 ,  44kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02368
Date: Sun, 4 Jun 2023 14:27:50 GMT   (1052kb,D)

Title: Revisiting Data-Free Knowledge Distillation with Poisoned Teachers
Authors: Junyuan Hong, Yi Zeng, Shuyang Yu, Lingjuan Lyu, Ruoxi Jia, Jiayu Zhou
Categories: cs.LG cs.CR
Comments: Accepted to ICML 2023
\\
 Data-free knowledge distillation (KD) helps transfer knowledge from a
pre-trained model (known as the teacher model) to a smaller model (known as the
student model) without access to the original training data used for training
the teacher model. However, the security of the synthetic or
out-of-distribution (OOD) data required in data-free KD is largely unknown and
under-explored. In this work, we make the first effort to uncover the security
risk of data-free KD w.r.t. untrusted pre-trained models. We then propose
Anti-Backdoor Data-Free KD (ABD), the first plug-in defensive method for
data-free KD methods to mitigate the chance of potential backdoors being
transferred. We empirically evaluate the effectiveness of our proposed ABD in
diminishing transferred backdoor knowledge while maintaining compatible
downstream performances as the vanilla KD. We envision this work as a milestone
for alarming and mitigating the potential backdoors in data-free KD. Codes are
released at https://github.com/illidanlab/ABD.
\\ ( https://arxiv.org/abs/2306.02368 ,  1052kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02376
Date: Sun, 4 Jun 2023 15:19:44 GMT   (2283kb,D)

Title: Towards Deep Attention in Graph Neural Networks: Problems and Remedies
Authors: Soo Yong Lee, Fanchen Bu, Jaemin Yoo, Kijung Shin
Categories: cs.LG cs.AI
Comments: 22 pages, 6 figures, conference paper, published in International
 Conference on Machine Learning. PMLR, 2023
\\
 Graph neural networks (GNNs) learn the representation of graph-structured
data, and their expressiveness can be further enhanced by inferring node
relations for propagation. Attention-based GNNs infer neighbor importance to
manipulate the weight of its propagation. Despite their popularity, the
discussion on deep graph attention and its unique challenges has been limited.
In this work, we investigate some problematic phenomena related to deep graph
attention, including vulnerability to over-smoothed features and smooth
cumulative attention. Through theoretical and empirical analyses, we show that
various attention-based GNNs suffer from these problems. Motivated by our
findings, we propose AEROGNN, a novel GNN architecture designed for deep graph
attention. AERO-GNN provably mitigates the proposed problems of deep graph
attention, which is further empirically demonstrated with (a) its adaptive and
less smooth attention functions and (b) higher performance at deep layers (up
to 64). On 9 out of 12 node classification benchmarks, AERO-GNN outperforms the
baseline GNNs, highlighting the advantages of deep graph attention. Our code is
available at https://github.com/syleeheal/AERO-GNN.
\\ ( https://arxiv.org/abs/2306.02376 ,  2283kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02389
Date: Sun, 4 Jun 2023 15:48:09 GMT   (5896kb,D)

Title: Fast Continual Multi-View Clustering with Incomplete Views
Authors: Xinhang Wan, Bin Xiao, Xinwang Liu, Jiyuan Liu, Weixuan Liang, En Zhu
Categories: cs.LG cs.AI
\\
 Multi-view clustering (MVC) has gained broad attention owing to its capacity
to exploit consistent and complementary information across views. This paper
focuses on a challenging issue in MVC called the incomplete continual data
problem (ICDP). In specific, most existing algorithms assume that views are
available in advance and overlook the scenarios where data observations of
views are accumulated over time. Due to privacy considerations or memory
limitations, previous views cannot be stored in these situations. Some works
are proposed to handle it, but all fail to address incomplete views. Such an
incomplete continual data problem (ICDP) in MVC is tough to solve since
incomplete information with continual data increases the difficulty of
extracting consistent and complementary knowledge among views. We propose Fast
Continual Multi-View Clustering with Incomplete Views (FCMVC-IV) to address it.
Specifically, it maintains a consensus coefficient matrix and updates knowledge
with the incoming incomplete view rather than storing and recomputing all the
data matrices. Considering that the views are incomplete, the newly collected
view might contain samples that have yet to appear; two indicator matrices and
a rotation matrix are developed to match matrices with different dimensions.
Besides, we design a three-step iterative algorithm to solve the resultant
problem in linear complexity with proven convergence. Comprehensive experiments
on various datasets show the superiority of FCMVC-IV.
\\ ( https://arxiv.org/abs/2306.02389 ,  5896kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02399
Date: Sun, 4 Jun 2023 16:24:19 GMT   (67kb,D)

Title: Regret Bounds for Risk-sensitive Reinforcement Learning with Lipschitz
 Dynamic Risk Measures
Authors: Hao Liang, Zhi-quan Luo
Categories: cs.LG cs.AI stat.ML
\\
 We study finite episodic Markov decision processes incorporating dynamic risk
measures to capture risk sensitivity. To this end, we present two model-based
algorithms applied to \emph{Lipschitz} dynamic risk measures, a wide range of
risk measures that subsumes spectral risk measure, optimized certainty
equivalent, distortion risk measures among others. We establish both regret
upper bounds and lower bounds. Notably, our upper bounds demonstrate optimal
dependencies on the number of actions and episodes, while reflecting the
inherent trade-off between risk sensitivity and sample complexity.
Additionally, we substantiate our theoretical results through numerical
experiments.
\\ ( https://arxiv.org/abs/2306.02399 ,  67kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02400
Date: Sun, 4 Jun 2023 16:29:30 GMT   (4089kb,D)

Title: Perceptual Kalman Filters: Online State Estimation under a Perfect
 Perceptual-Quality Constraint
Authors: Dror Freirich and Tomer Michaeli and Ron Meir
Categories: cs.LG cs.IT math.IT stat.ML
\\
 Many practical settings call for the reconstruction of temporal signals from
corrupted or missing data. Classic examples include decoding, tracking, signal
enhancement and denoising. Since the reconstructed signals are ultimately
viewed by humans, it is desirable to achieve reconstructions that are pleasing
to human perception. Mathematically, perfect perceptual-quality is achieved
when the distribution of restored signals is the same as that of natural
signals, a requirement which has been heavily researched in static estimation
settings (i.e. when a whole signal is processed at once). Here, we study the
problem of optimal causal filtering under a perfect perceptual-quality
constraint, which is a task of fundamentally different nature. Specifically, we
analyze a Gaussian Markov signal observed through a linear noisy
transformation. In the absence of perceptual constraints, the Kalman filter is
known to be optimal in the MSE sense for this setting. Here, we show that
adding the perfect perceptual quality constraint (i.e. the requirement of
temporal consistency), introduces a fundamental dilemma whereby the filter may
have to "knowingly" ignore new information revealed by the observations in
order to conform to its past decisions. This often comes at the cost of a
significant increase in the MSE (beyond that encountered in static settings).
Our analysis goes beyond the classic innovation process of the Kalman filter,
and introduces the novel concept of an unutilized information process. Using
this tool, we present a recursive formula for perceptual filters, and
demonstrate the qualitative effects of perfect perceptual-quality estimation on
a video reconstruction problem.
\\ ( https://arxiv.org/abs/2306.02400 ,  4089kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02418
Date: Sun, 4 Jun 2023 17:50:20 GMT   (926kb,D)

Title: ContraBAR: Contrastive Bayes-Adaptive Deep RL
Authors: Era Choshen, Aviv Tamar
Categories: cs.LG cs.AI stat.ML
Comments: ICML 2023. Pytorch code available at
 https://github.com/ec2604/ContraBAR
\\
 In meta reinforcement learning (meta RL), an agent seeks a Bayes-optimal
policy -- the optimal policy when facing an unknown task that is sampled from
some known task distribution. Previous approaches tackled this problem by
inferring a belief over task parameters, using variational inference methods.
Motivated by recent successes of contrastive learning approaches in RL, such as
contrastive predictive coding (CPC), we investigate whether contrastive methods
can be used for learning Bayes-optimal behavior. We begin by proving that
representations learned by CPC are indeed sufficient for Bayes optimality.
Based on this observation, we propose a simple meta RL algorithm that uses CPC
in lieu of variational belief inference. Our method, ContraBAR, achieves
comparable performance to state-of-the-art in domains with state-based
observation and circumvents the computational toll of future observation
reconstruction, enabling learning in domains with image-based observations. It
can also be combined with image augmentations for domain randomization and used
seamlessly in both online and offline meta RL settings.
\\ ( https://arxiv.org/abs/2306.02418 ,  926kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02419
Date: Sun, 4 Jun 2023 17:51:37 GMT   (699kb,D)

Title: Bad Habits: Policy Confounding and Out-of-Trajectory Generalization in
 RL
Authors: Miguel Suau, Matthijs T. J. Spaan, Frans A. Oliehoek
Categories: cs.LG
\\
 Reinforcement learning agents may sometimes develop habits that are effective
only when specific policies are followed. After an initial exploration phase in
which agents try out different actions, they eventually converge toward a
particular policy. When this occurs, the distribution of state-action
trajectories becomes narrower, and agents start experiencing the same
transitions again and again. At this point, spurious correlations may arise.
Agents may then pick up on these correlations and learn state representations
that do not generalize beyond the agent's trajectory distribution. In this
paper, we provide a mathematical characterization of this phenomenon, which we
refer to as policy confounding, and show, through a series of examples, when
and how it occurs in practice.
\\ ( https://arxiv.org/abs/2306.02419 ,  699kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02420
Date: Sun, 4 Jun 2023 17:52:49 GMT   (623kb,D)

Title: Complexity of Block Coordinate Descent with Proximal Regularization and
 Applications to Wasserstein CP-dictionary Learning
Authors: Dohyun Kwon, Hanbaek Lyu
Categories: cs.LG cs.AI cs.NA math.NA math.OC
Comments: Proceedings of the 40th International Conference on Machine Learning
\\
 We consider the block coordinate descent methods of Gauss-Seidel type with
proximal regularization (BCD-PR), which is a classical method of minimizing
general nonconvex objectives under constraints that has a wide range of
practical applications. We theoretically establish the worst-case complexity
bound for this algorithm. Namely, we show that for general nonconvex smooth
objectives with block-wise constraints, the classical BCD-PR algorithm
converges to an epsilon-stationary point within O(1/epsilon) iterations. Under
a mild condition, this result still holds even if the algorithm is executed
inexactly in each step. As an application, we propose a provable and efficient
algorithm for `Wasserstein CP-dictionary learning', which seeks a set of
elementary probability distributions that can well-approximate a given set of
d-dimensional joint probability distributions. Our algorithm is a version of
BCD-PR that operates in the dual space, where the primal problem is regularized
both entropically and proximally.
\\ ( https://arxiv.org/abs/2306.02420 ,  623kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02426
Date: Sun, 4 Jun 2023 18:14:18 GMT   (371kb,D)

Title: Resilient Constrained Learning
Authors: Ignacio Hounie, Alejandro Ribeiro, Luiz F. O. Chamon
Categories: cs.LG stat.ML
\\
 When deploying machine learning solutions, they must satisfy multiple
requirements beyond accuracy, such as fairness, robustness, or safety. These
requirements are imposed during training either implicitly, using penalties, or
explicitly, using constrained optimization methods based on Lagrangian duality.
Either way, specifying requirements is hindered by the presence of compromises
and limited prior knowledge about the data. Furthermore, their impact on
performance can often only be evaluated by actually solving the learning
problem. This paper presents a constrained learning approach that adapts the
requirements while simultaneously solving the learning task. To do so, it
relaxes the learning constraints in a way that contemplates how much they
affect the task at hand by balancing the performance gains obtained from the
relaxation against a user-defined cost of that relaxation. We call this
approach resilient constrained learning after the term used to describe
ecological systems that adapt to disruptions by modifying their operation. We
show conditions under which this balance can be achieved and introduce a
practical algorithm to compute it, for which we derive approximation and
generalization guarantees. We showcase the advantages of this resilient
learning method in image classification tasks involving multiple potential
invariances and in heterogeneous federated learning.
\\ ( https://arxiv.org/abs/2306.02426 ,  371kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02447
Date: Sun, 4 Jun 2023 19:30:28 GMT   (2985kb,D)

Title: Active Inference-Based Optimization of Discriminative Neural Network
 Classifiers
Authors: Faezeh Fallah
Categories: cs.LG cs.AI
\\
 Commonly used objective functions (losses) for a supervised optimization of
discriminative neural network classifiers were either distribution-based or
metric-based. The distribution-based losses could compromise the generalization
or cause classification biases towards the dominant classes of an imbalanced
class-sample distribution. The metric-based losses could make the network model
independent of any distribution and thus improve its generalization. However,
they could still be biased towards the dominant classes and could suffer from
discrepancies when a class was absent in both the reference (ground truth) and
the predicted labels. In this paper, we proposed a novel optimization process
which not only tackled the unbalancedness of the class-sample distribution of
the training samples but also provided a mechanism to tackle errors in the
reference labels of the training samples. This was achieved by proposing a
novel algorithm to find candidate classification labels of the training samples
from their prior probabilities and the currently estimated posteriors on the
network and a novel objective function for the optimizations. The algorithm was
the result of casting the generalized Kelly criterion for optimal betting into
a multiclass classification problem. The proposed objective function was the
expected free energy of a prospective active inference and could incorporate
the candidate labels, the original reference labels, and the priors of the
training samples while still being distribution-based. The incorporation of the
priors into the optimization not only helped to tackle errors in the reference
labels but also allowed to reduce classification biases towards the dominant
classes by focusing the attention of the neural network on important but
minority foreground classes.
\\ ( https://arxiv.org/abs/2306.02447 ,  2985kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02449
Date: Sun, 4 Jun 2023 19:43:54 GMT   (426kb,D)

Title: The Power Of Simplicity: Why Simple Linear Models Outperform Complex
 Machine Learning Techniques -- Case Of Breast Cancer Diagnosis
Authors: Muhammad Arbab Arshad, Sakib Shahriar, Khizar Anjum
Categories: cs.LG
Comments: 15 pages, 6 figures, conference or journal
\\
 This research paper investigates the effectiveness of simple linear models
versus complex machine learning techniques in breast cancer diagnosis,
emphasizing the importance of interpretability and computational efficiency in
the medical domain. We focus on Logistic Regression (LR), Decision Trees (DT),
and Support Vector Machines (SVM) and optimize their performance using the UCI
Machine Learning Repository dataset. Our findings demonstrate that the simpler
linear model, LR, outperforms the more complex DT and SVM techniques, with a
test score mean of 97.28%, a standard deviation of 1.62%, and a computation
time of 35.56 ms. In comparison, DT achieved a test score mean of 93.73%, and
SVM had a test score mean of 96.44%. The superior performance of LR can be
attributed to its simplicity and interpretability, which provide a clear
understanding of the relationship between input features and the outcome. This
is particularly valuable in the medical domain, where interpretability is
crucial for decision-making. Moreover, the computational efficiency of LR
offers advantages in terms of scalability and real-world applicability. The
results of this study highlight the power of simplicity in the context of
breast cancer diagnosis and suggest that simpler linear models like LR can be
more effective, interpretable, and computationally efficient than their complex
counterparts, making them a more suitable choice for medical applications.
\\ ( https://arxiv.org/abs/2306.02449 ,  426kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02451
Date: Sun, 4 Jun 2023 19:47:46 GMT   (26761kb,D)

Title: For SALE: State-Action Representation Learning for Deep Reinforcement
 Learning
Authors: Scott Fujimoto, Wei-Di Chang, Edward J. Smith, Shixiang Shane Gu,
 Doina Precup, David Meger
Categories: cs.LG cs.AI stat.ML
\\
 In the field of reinforcement learning (RL), representation learning is a
proven tool for complex image-based tasks, but is often overlooked for
environments with low-level states, such as physical control problems. This
paper introduces SALE, a novel approach for learning embeddings that model the
nuanced interaction between state and action, enabling effective representation
learning from low-level states. We extensively study the design space of these
embeddings and highlight important design considerations. We integrate SALE and
an adaptation of checkpoints for RL into TD3 to form the TD7 algorithm, which
significantly outperforms existing continuous control algorithms. On OpenAI gym
benchmark tasks, TD7 has an average performance gain of 276.7% and 50.7% over
TD3 at 300k and 5M time steps, respectively, and works in both the online and
offline settings.
\\ ( https://arxiv.org/abs/2306.02451 ,  26761kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02459
Date: Sun, 4 Jun 2023 20:22:14 GMT   (40671kb,D)

Title: Multi-Predict: Few Shot Predictors For Efficient Neural Architecture
 Search
Authors: Yash Akhauri, Mohamed S. Abdelfattah
Categories: cs.LG cs.AR cs.CV cs.PF
\\
 Many hardware-aware neural architecture search (NAS) methods have been
developed to optimize the topology of neural networks (NN) with the joint
objectives of higher accuracy and lower latency. Recently, both accuracy and
latency predictors have been used in NAS with great success, achieving high
sample efficiency and accurate modeling of hardware (HW) device latency
respectively. However, a new accuracy predictor needs to be trained for every
new NAS search space or NN task, and a new latency predictor needs to be
additionally trained for every new HW device. In this paper, we explore methods
to enable multi-task, multi-search-space, and multi-HW adaptation of accuracy
and latency predictors to reduce the cost of NAS. We introduce a novel
search-space independent NN encoding based on zero-cost proxies that achieves
sample-efficient prediction on multiple tasks and NAS search spaces, improving
the end-to-end sample efficiency of latency and accuracy predictors by over an
order of magnitude in multiple scenarios. For example, our NN encoding enables
multi-search-space transfer of latency predictors from NASBench-201 to FBNet
(and vice-versa) in under 85 HW measurements, a 400$\times$ improvement in
sample efficiency compared to a recent meta-learning approach. Our method also
improves the total sample efficiency of accuracy predictors by over an order of
magnitude. Finally, we demonstrate the effectiveness of our method for
multi-search-space and multi-task accuracy prediction on 28 NAS search spaces
and tasks.
\\ ( https://arxiv.org/abs/2306.02459 ,  40671kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02479
Date: Sun, 4 Jun 2023 20:55:13 GMT   (465kb,D)

Title: Contagion Effect Estimation Using Proximal Embeddings
Authors: Zahra Fatemi, Elena Zheleva
Categories: cs.LG
\\
 Contagion effect refers to the causal effect of peers' behavior on the
outcome of an individual in social networks. While prominent methods for
estimating contagion effects in observational studies often assume that there
are no unmeasured confounders, contagion can be confounded due to latent
homophily: nodes in a homophilous network tend to have ties to peers with
similar attributes and can behave similarly without influencing one another.
One way to account for latent homophily is by considering proxies for the
unobserved confounders. However, in the presence of high-dimensional proxies,
proxy-based methods can lead to substantially biased estimation of contagion
effects, as we demonstrate in this paper. To tackle this issue, we introduce
the novel Proximal Embeddings (ProEmb), a framework which integrates
Variational Autoencoders (VAEs) and adversarial networks to generate balanced
low-dimensional representations of high-dimensional proxies for different
treatment groups and identifies contagion effects in the presence of unobserved
network confounders. We empirically show that our method significantly
increases the accuracy of contagion effect estimation in observational network
data compared to state-of-the-art methods.
\\ ( https://arxiv.org/abs/2306.02479 ,  465kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02497
Date: Sun, 4 Jun 2023 22:16:49 GMT   (2475kb,D)

Title: Learning on Bandwidth Constrained Multi-Source Data with MIMO-inspired
 DPP MAP Inference
Authors: Xiwen Chen, Huayu Li, Rahul Amin, Abolfazl Razi
Categories: cs.LG cs.IT math.IT
\\
 This paper proposes a distributed version of Determinant Point Processing
(DPP) inference to enhance multi-source data diversification under limited
communication bandwidth. DPP is a popular probabilistic approach that improves
data diversity by enforcing the repulsion of elements in the selected subsets.
The well-studied Maximum A Posteriori (MAP) inference in DPP aims to identify
the subset with the highest diversity quantified by DPP. However, this approach
is limited by the presumption that all data samples are available at one point,
which hinders its applicability to real-world applications such as traffic
datasets where data samples are distributed across sources and communication
between them is band-limited.
 Inspired by the techniques used in Multiple-Input Multiple-Output (MIMO)
communication systems, we propose a strategy for performing MAP inference among
distributed sources. Specifically, we show that a lower bound of the
diversity-maximized distributed sample selection problem can be treated as a
power allocation problem in MIMO systems. A determinant-preserved sparse
representation of selected samples is used to perform sample precoding in local
sources to be processed by DPP. Our method does not require raw data exchange
among sources, but rather a band-limited feedback channel to send lightweight
diversity measures, analogous to the CSI message in MIMO systems, from the
center to data sources. The experiments show that our scalable approach can
outperform baseline methods, including random selection, uninformed individual
DPP with no feedback, and DPP with SVD-based feedback, in both i.i.d and
non-i.i.d setups. Specifically, it achieves 1 to 6 log-difference diversity
gain in the latent representation of CIFAR-10, CIFAR-100, StanfordCars, and
GTSRB datasets.
\\ ( https://arxiv.org/abs/2306.02497 ,  2475kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02508
Date: Mon, 5 Jun 2023 00:01:17 GMT   (10078kb,D)

Title: Graph Fourier MMD for Signals on Graphs
Authors: Samuel Leone, Aarthi Venkat, Guillaume Huguet, Alexander Tong, Guy
 Wolf, Smita Krishnaswamy
Categories: cs.LG stat.ML
\\
 While numerous methods have been proposed for computing distances between
probability distributions in Euclidean space, relatively little attention has
been given to computing such distances for distributions on graphs. However,
there has been a marked increase in data that either lies on graph (such as
protein interaction networks) or can be modeled as a graph (single cell data),
particularly in the biomedical sciences. Thus, it becomes important to find
ways to compare signals defined on such graphs. Here, we propose Graph Fourier
MMD (GFMMD), a novel distance between distributions and signals on graphs.
GFMMD is defined via an optimal witness function that is both smooth on the
graph and maximizes difference in expectation between the pair of distributions
on the graph. We find an analytical solution to this optimization problem as
well as an embedding of distributions that results from this method. We also
prove several properties of this method including scale invariance and
applicability to disconnected graphs. We showcase it on graph benchmark
datasets as well on single cell RNA-sequencing data analysis. In the latter, we
use the GFMMD-based gene embeddings to find meaningful gene clusters. We also
propose a novel type of score for gene selection called "gene localization
score" which helps select genes for cellular state space characterization.
\\ ( https://arxiv.org/abs/2306.02508 ,  10078kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02516
Date: Mon, 5 Jun 2023 00:43:37 GMT   (8867kb,D)

Title: SamToNe: Improving Contrastive Loss for Dual Encoder Retrieval Models
 with Same Tower Negatives
Authors: Fedor Moiseev, Gustavo Hernandez Abrego, Peter Dornbach, Imed Zitouni,
 Enrique Alfonseca, Zhe Dong
Categories: cs.LG cs.IR
Comments: ACL 2023 Findings
\\
 Dual encoders have been used for retrieval tasks and representation learning
with good results. A standard way to train dual encoders is using a contrastive
loss with in-batch negatives. In this work, we propose an improved contrastive
learning objective by adding queries or documents from the same encoder towers
to the negatives, for which we name it as "contrastive loss with SAMe TOwer
NEgatives" (SamToNe). By evaluating on question answering retrieval benchmarks
from MS MARCO and MultiReQA, and heterogenous zero-shot information retrieval
benchmarks (BEIR), we demonstrate that SamToNe can effectively improve the
retrieval quality for both symmetric and asymmetric dual encoders. By directly
probing the embedding spaces of the two encoding towers via the t-SNE algorithm
(van der Maaten and Hinton, 2008), we observe that SamToNe ensures the
alignment between the embedding spaces from the two encoder towers. Based on
the analysis of the embedding distance distributions of the top-$1$ retrieved
results, we further explain the efficacy of the method from the perspective of
regularisation.
\\ ( https://arxiv.org/abs/2306.02516 ,  8867kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02532
Date: Mon, 5 Jun 2023 01:41:23 GMT   (733kb,D)

Title: R-Mixup: Riemannian Mixup for Biological Networks
Authors: Xuan Kan, Zimu Li, Hejie Cui, Yue Yu, Ran Xu, Shaojun Yu, Zilong
 Zhang, Ying Guo, Carl Yang
Categories: cs.LG cs.AI q-bio.QM
Comments: Accepted to KDD 2023
MSC-class: 68T07, 68T05
ACM-class: I.2.6; J.3
DOI: 10.1145/3580305.3599483
\\
 Biological networks are commonly used in biomedical and healthcare domains to
effectively model the structure of complex biological systems with interactions
linking biological entities. However, due to their characteristics of high
dimensionality and low sample size, directly applying deep learning models on
biological networks usually faces severe overfitting. In this work, we propose
R-MIXUP, a Mixup-based data augmentation technique that suits the symmetric
positive definite (SPD) property of adjacency matrices from biological networks
with optimized training efficiency. The interpolation process in R-MIXUP
leverages the log-Euclidean distance metrics from the Riemannian manifold,
effectively addressing the swelling effect and arbitrarily incorrect label
issues of vanilla Mixup. We demonstrate the effectiveness of R-MIXUP with five
real-world biological network datasets on both regression and classification
tasks. Besides, we derive a commonly ignored necessary condition for
identifying the SPD matrices of biological networks and empirically study its
influence on the model performance. The code implementation can be found in
Appendix E.
\\ ( https://arxiv.org/abs/2306.02532 ,  733kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02533
Date: Mon, 5 Jun 2023 01:45:22 GMT   (1258kb)

Title: On Emergence of Clean-Priority Learning in Early Stopped Neural Networks
Authors: Chaoyue Liu, Amirhesam Abedsoltan, Mikhail Belkin
Categories: cs.LG stat.ML
\\
 When random label noise is added to a training dataset, the prediction error
of a neural network on a label-noise-free test dataset initially improves
during early training but eventually deteriorates, following a U-shaped
dependence on training time. This behaviour is believed to be a result of
neural networks learning the pattern of clean data first and fitting the noise
later in the training, a phenomenon that we refer to as clean-priority
learning. In this study, we aim to explore the learning dynamics underlying
this phenomenon. We theoretically demonstrate that, in the early stage of
training, the update direction of gradient descent is determined by the clean
subset of training data, leaving the noisy subset has minimal to no impact,
resulting in a prioritization of clean learning. Moreover, we show both
theoretically and experimentally, as the clean-priority learning goes on, the
dominance of the gradients of clean samples over those of noisy samples
diminishes, and finally results in a termination of the clean-priority learning
and fitting of the noisy samples.
\\ ( https://arxiv.org/abs/2306.02533 ,  1258kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02543
Date: Mon, 5 Jun 2023 02:28:19 GMT   (2397kb,D)

Title: Addressing Budget Allocation and Revenue Allocation in Data Market
 Environments Using an Adaptive Sampling Algorithm
Authors: Boxin Zhao, Boxiang Lyu, Raul Castro Fernandez, Mladen Kolar
Categories: cs.LG
Comments: Published on International Conference on Machine Learning (ICML) 2023
\\
 High-quality machine learning models are dependent on access to high-quality
training data. When the data are not already available, it is tedious and
costly to obtain them. Data markets help with identifying valuable training
data: model consumers pay to train a model, the market uses that budget to
identify data and train the model (the budget allocation problem), and finally
the market compensates data providers according to their data contribution
(revenue allocation problem). For example, a bank could pay the data market to
access data from other financial institutions to train a fraud detection model.
Compensating data contributors requires understanding data's contribution to
the model; recent efforts to solve this revenue allocation problem based on the
Shapley value are inefficient to lead to practical data markets.
 In this paper, we introduce a new algorithm to solve budget allocation and
revenue allocation problems simultaneously in linear time. The new algorithm
employs an adaptive sampling process that selects data from those providers who
are contributing the most to the model. Better data means that the algorithm
accesses those providers more often, and more frequent accesses corresponds to
higher compensation. Furthermore, the algorithm can be deployed in both
centralized and federated scenarios, boosting its applicability. We provide
theoretical guarantees for the algorithm that show the budget is used
efficiently and the properties of revenue allocation are similar to Shapley's.
Finally, we conduct an empirical evaluation to show the performance of the
algorithm in practical scenarios and when compared to other baselines. Overall,
we believe that the new algorithm paves the way for the implementation of
practical data markets.
\\ ( https://arxiv.org/abs/2306.02543 ,  2397kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02555
Date: Mon, 5 Jun 2023 03:05:43 GMT   (268kb)

Title: Barriers for the performance of graph neural networks (GNN) in discrete
 random structures. A comment
 on~\cite{schuetz2022combinatorial},\cite{angelini2023modern},\cite{schuetz2023reply}
Authors: David Gamarnik
Categories: cs.LG cs.AI cs.DM
Comments: 5 pages
\\
 Recently graph neural network (GNN) based algorithms were proposed to solve a
variety of combinatorial optimization problems, including Maximum Cut problem,
Maximum Independent Set problem and similar other
problems~\cite{schuetz2022combinatorial},\cite{schuetz2022graph}.
 The publication~\cite{schuetz2022combinatorial} stirred a debate whether GNN
based method was adequately benchmarked against best prior methods. In
particular, critical commentaries~\cite{angelini2023modern}
and~\cite{boettcher2023inability} point out that simple greedy algorithm
performs better than GNN in the setting of random graphs, and in fact stronger
algorithmic performance can be reached with more sophisticated methods. A
response from the authors~\cite{schuetz2023reply} pointed out that GNN
performance can be improved further by tuning up the parameters better.
 We do not intend to discuss the merits of arguments and counter-arguments
in~\cite{schuetz2022combinatorial},\cite{angelini2023modern},\cite{boettcher2023inability},\cite{schuetz2023reply}.
Rather in this note we establish a fundamental limitation for running GNN on
random graphs considered in these references, for a broad range of choices of
GNN architecture. These limitations arise from the presence of the Overlap Gap
Property (OGP) phase transition, which is a barrier for many algorithms, both
classical and quantum. As we demonstrate in this paper, it is also a barrier to
GNN due to its local structure. We note that at the same time known algorithms
ranging from simple greedy algorithms to more sophisticated algorithms based on
message passing, provide best results for these problems \emph{up to} the OGP
phase transition. This leaves very little space for GNN to outperform the known
algorithms, and based on this we side with the conclusions made
in~\cite{angelini2023modern} and~\cite{boettcher2023inability}.
\\ ( https://arxiv.org/abs/2306.02555 ,  268kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02556
Date: Mon, 5 Jun 2023 03:08:29 GMT   (131kb,D)

Title: Improved Active Multi-Task Representation Learning via Lasso
Authors: Yiping Wang, Yifang Chen, Kevin Jamieson, Simon S. Du
Categories: cs.LG cs.AI
Comments: Accepted by ICML 2023
\\
 To leverage the copious amount of data from source tasks and overcome the
scarcity of the target task samples, representation learning based on
multi-task pretraining has become a standard approach in many applications.
However, up until now, most existing works design a source task selection
strategy from a purely empirical perspective. Recently, \citet{chen2022active}
gave the first active multi-task representation learning (A-MTRL) algorithm
which adaptively samples from source tasks and can provably reduce the total
sample complexity using the L2-regularized-target-source-relevance parameter
$\nu^2$. But their work is theoretically suboptimal in terms of total source
sample complexity and is less practical in some real-world scenarios where
sparse training source task selection is desired. In this paper, we address
both issues. Specifically, we show the strict dominance of the
L1-regularized-relevance-based ($\nu^1$-based) strategy by giving a lower bound
for the $\nu^2$-based strategy. When $\nu^1$ is unknown, we propose a practical
algorithm that uses the LASSO program to estimate $\nu^1$. Our algorithm
successfully recovers the optimal result in the known case. In addition to our
sample complexity results, we also characterize the potential of our
$\nu^1$-based strategy in sample-cost-sensitive settings. Finally, we provide
experiments on real-world computer vision datasets to illustrate the
effectiveness of our proposed method.
\\ ( https://arxiv.org/abs/2306.02556 ,  131kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02563
Date: Mon, 5 Jun 2023 03:33:26 GMT   (913kb,D)

Title: Large-Scale Distributed Learning via Private On-Device
 Locality-Sensitive Hashing
Authors: Tahseen Rabbani, Marco Bornstein, Furong Huang
Categories: cs.LG cs.CR cs.DC
Comments: 18 pages, 10 figures
\\
 Locality-sensitive hashing (LSH) based frameworks have been used efficiently
to select weight vectors in a dense hidden layer with high cosine similarity to
an input, enabling dynamic pruning. While this type of scheme has been shown to
improve computational training efficiency, existing algorithms require repeated
randomized projection of the full layer weight, which is impractical for
computational- and memory-constrained devices. In a distributed setting,
deferring LSH analysis to a centralized host is (i) slow if the device cluster
is large and (ii) requires access to input data which is forbidden in a
federated context. Using a new family of hash functions, we develop one of the
first private, personalized, and memory-efficient on-device LSH frameworks. Our
framework enables privacy and personalization by allowing each device to
generate hash tables, without the help of a central host, using device-specific
hashing hyper-parameters (e.g. number of hash tables or hash length). Hash
tables are generated with a compressed set of the full weights, and can be
serially generated and discarded if the process is memory-intensive. This
allows devices to avoid maintaining (i) the fully-sized model and (ii) large
amounts of hash tables in local memory for LSH analysis. We prove several
statistical and sensitivity properties of our hash functions, and
experimentally demonstrate that our framework is competitive in training
large-scale recommender networks compared to other LSH frameworks which assume
unrestricted on-device capacity.
\\ ( https://arxiv.org/abs/2306.02563 ,  913kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02564
Date: Mon, 5 Jun 2023 03:36:01 GMT   (7938kb,D)

Title: Spatial Implicit Neural Representations for Global-Scale Species Mapping
Authors: Elijah Cole, Grant Van Horn, Christian Lange, Alexander Shepard,
 Patrick Leary, Pietro Perona, Scott Loarie, Oisin Mac Aodha
Categories: cs.LG cs.CV
Comments: ICML 2023
\\
 Estimating the geographical range of a species from sparse observations is a
challenging and important geospatial prediction problem. Given a set of
locations where a species has been observed, the goal is to build a model to
predict whether the species is present or absent at any location. This problem
has a long history in ecology, but traditional methods struggle to take
advantage of emerging large-scale crowdsourced datasets which can include tens
of millions of records for hundreds of thousands of species. In this work, we
use Spatial Implicit Neural Representations (SINRs) to jointly estimate the
geographical range of 47k species simultaneously. We find that our approach
scales gracefully, making increasingly better predictions as we increase the
number of species and the amount of data per species when training. To make
this problem accessible to machine learning researchers, we provide four new
benchmarks that measure different aspects of species range estimation and
spatial representation learning. Using these benchmarks, we demonstrate that
noisy and biased crowdsourced data can be combined with implicit neural
representations to approximate expert-developed range maps for many species.
\\ ( https://arxiv.org/abs/2306.02564 ,  7938kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02570
Date: Mon, 5 Jun 2023 03:51:14 GMT   (162kb,D)

Title: When Decentralized Optimization Meets Federated Learning
Authors: Hongchang Gao, My T. Thai, Jie Wu
Categories: cs.LG math.OC
Comments: Accepted to IEEE Network
\\
 Federated learning is a new learning paradigm for extracting knowledge from
distributed data. Due to its favorable properties in preserving privacy and
saving communication costs, it has been extensively studied and widely applied
to numerous data analysis applications. However, most existing federated
learning approaches concentrate on the centralized setting, which is vulnerable
to a single-point failure. An alternative strategy for addressing this issue is
the decentralized communication topology. In this article, we systematically
investigate the challenges and opportunities when renovating decentralized
optimization for federated learning. In particular, we discussed them from the
model, data, and communication sides, respectively, which can deepen our
understanding about decentralized federated learning.
\\ ( https://arxiv.org/abs/2306.02570 ,  162kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02572
Date: Mon, 5 Jun 2023 03:55:26 GMT   (1104kb,D)

Title: Introduction to Latent Variable Energy-Based Models: A Path Towards
 Autonomous Machine Intelligence
Authors: Anna Dawid, Yann LeCun
Categories: cs.LG cond-mat.dis-nn stat.ML
Comments: 23 pages + 1-page appendix, 11 figures. These notes follow the
 content of three lectures given by Yann LeCun during the Les Houches Summer
 School on Statistical Physics and Machine Learning in 2022. Feedback and
 comments are most welcome!
\\
 Current automated systems have crucial limitations that need to be addressed
before artificial intelligence can reach human-like levels and bring new
technological revolutions. Among others, our societies still lack Level 5
self-driving cars, domestic robots, and virtual assistants that learn reliable
world models, reason, and plan complex action sequences. In these notes, we
summarize the main ideas behind the architecture of autonomous intelligence of
the future proposed by Yann LeCun. In particular, we introduce energy-based and
latent variable models and combine their advantages in the building block of
LeCun's proposal, that is, in the hierarchical joint embedding predictive
architecture (H-JEPA).
\\ ( https://arxiv.org/abs/2306.02572 ,  1104kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02587
Date: Mon, 5 Jun 2023 04:28:04 GMT   (3525kb,D)

Title: Jammer classification with Federated Learning
Authors: Peng Wu, Helena Calatrava, Tales Imbiriba, Pau Closas
Categories: cs.LG cs.CR
\\
 Jamming signals can jeopardize the operation of GNSS receivers until denying
its operation. Given their ubiquity, jamming mitigation and localization
techniques are of crucial importance, for which jammer classification is of
help. Data-driven models have been proven useful in detecting these threats,
while their training using crowdsourced data still poses challenges when it
comes to private data sharing. This article investigates the use of federated
learning to train jamming signal classifiers locally on each device, with model
updates aggregated and averaged at the central server. This allows for
privacy-preserving training procedures that do not require centralized data
storage or access to client local data. The used framework FedAvg is assessed
on a dataset consisting of spectrogram images of simulated interfered GNSS
signal. Six different jammer types are effectively classified with comparable
results to a fully centralized solution that requires vast amounts of data
communication and involves privacy-preserving concerns.
\\ ( https://arxiv.org/abs/2306.02587 ,  3525kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02595
Date: Mon, 5 Jun 2023 04:58:41 GMT   (429kb,D)

Title: Explore and Exploit the Diverse Knowledge in Model Zoo for Domain
 Generalization
Authors: Yimeng Chen, Tianyang Hu, Fengwei Zhou, Zhenguo Li, Zhiming Ma
Categories: cs.LG stat.ML
Comments: Accepted to ICML 2023
\\
 The proliferation of pretrained models, as a result of advancements in
pretraining techniques, has led to the emergence of a vast zoo of publicly
available models. Effectively utilizing these resources to obtain models with
robust out-of-distribution generalization capabilities for downstream tasks has
become a crucial area of research. Previous research has primarily focused on
identifying the most powerful models within the model zoo, neglecting to fully
leverage the diverse inductive biases contained within. This paper argues that
the knowledge contained in weaker models is valuable and presents a method for
leveraging the diversity within the model zoo to improve out-of-distribution
generalization capabilities. Specifically, we investigate the behaviors of
various pretrained models across different domains of downstream tasks by
characterizing the variations in their encoded representations in terms of two
dimensions: diversity shift and correlation shift. This characterization
enables us to propose a new algorithm for integrating diverse pretrained
models, not limited to the strongest models, in order to achieve enhanced
out-of-distribution generalization performance. Our proposed method
demonstrates state-of-the-art empirical results on a variety of datasets, thus
validating the benefits of utilizing diverse knowledge.
\\ ( https://arxiv.org/abs/2306.02595 ,  429kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02601
Date: Mon, 5 Jun 2023 05:21:01 GMT   (355kb,D)

Title: Aiming towards the minimizers: fast convergence of SGD for
 overparametrized problems
Authors: Chaoyue Liu, Dmitriy Drusvyatskiy, Mikhail Belkin, Damek Davis, Yi-An
 Ma
Categories: cs.LG math.OC stat.ML
\\
 Modern machine learning paradigms, such as deep learning, occur in or close
to the interpolation regime, wherein the number of model parameters is much
larger than the number of data samples. In this work, we propose a regularity
condition within the interpolation regime which endows the stochastic gradient
method with the same worst-case iteration complexity as the deterministic
gradient method, while using only a single sampled gradient (or a minibatch) in
each iteration. In contrast, all existing guarantees require the stochastic
gradient method to take small steps, thereby resulting in a much slower linear
rate of convergence. Finally, we demonstrate that our condition holds when
training sufficiently wide feedforward neural networks with a linear output
layer.
\\ ( https://arxiv.org/abs/2306.02601 ,  355kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02617
Date: Mon, 5 Jun 2023 06:31:14 GMT   (73kb,D)

Title: Permutation Decision Trees
Authors: Harikrishnan N B and Nithin Nagaraj
Categories: cs.LG
Comments: 10 pages, 8 figures
\\
 Decision Tree is a well understood Machine Learning model that is based on
minimizing impurities in the internal nodes. The most common impurity measures
are Shannon entropy and Gini impurity. These impurity measures are insensitive
to the order of training data and hence the final tree obtained is invariant to
any permutation of the data. This leads to a serious limitation in modeling
data instances that have order dependencies. In this work, we propose the use
of Effort-To-Compress (ETC) - a complexity measure, for the first time, as an
impurity measure. Unlike Shannon entropy and Gini impurity, structural impurity
based on ETC is able to capture order dependencies in the data, thus obtaining
potentially different decision trees for different permutations of the same
data instances (Permutation Decision Trees). We then introduce the notion of
Permutation Bagging achieved using permutation decision trees without the need
for random feature selection and sub-sampling. We compare the performance of
the proposed permutation bagged decision trees with Random Forests. Our model
does not assume that the data instances are independent and identically
distributed. Potential applications include scenarios where a temporal order
present in the data instances is to be respected.
\\ ( https://arxiv.org/abs/2306.02617 ,  73kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02618
Date: Mon, 5 Jun 2023 06:36:18 GMT   (3752kb)

Title: Enhance Diffusion to Improve Robust Generalization
Authors: Jianhui Sun and Sanchit Sinha and Aidong Zhang
Categories: cs.LG cs.AI
Comments: Accepted at KDD 2023
DOI: 10.1145/3580305.3599333
\\
 Deep neural networks are susceptible to human imperceptible adversarial
perturbations. One of the strongest defense mechanisms is \emph{Adversarial
Training} (AT). In this paper, we aim to address two predominant problems in
AT. First, there is still little consensus on how to set hyperparameters with a
performance guarantee for AT research, and customized settings impede a fair
comparison between different model designs in AT research. Second, the robustly
trained neural networks struggle to generalize well and suffer from tremendous
overfitting. This paper focuses on the primary AT framework - Projected
Gradient Descent Adversarial Training (PGD-AT). We approximate the dynamic of
PGD-AT by a continuous-time Stochastic Differential Equation (SDE), and show
that the diffusion term of this SDE determines the robust generalization. An
immediate implication of this theoretical finding is that robust generalization
is positively correlated with the ratio between learning rate and batch size.
We further propose a novel approach, \emph{Diffusion Enhanced Adversarial
Training} (DEAT), to manipulate the diffusion term to improve robust
generalization with virtually no extra computational burden. We theoretically
show that DEAT obtains a tighter generalization bound than PGD-AT. Our
empirical investigation is extensive and firmly attests that DEAT universally
outperforms PGD-AT by a significant margin.
\\ ( https://arxiv.org/abs/2306.02618 ,  3752kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02622
Date: Mon, 5 Jun 2023 06:50:09 GMT   (254kb,D)

Title: What Makes Entities Similar? A Similarity Flooding Perspective for
 Multi-sourced Knowledge Graph Embeddings
Authors: Zequn Sun and Jiacheng Huang and Xiaozhou Xu and Qijin Chen and Weijun
 Ren and Wei Hu
Categories: cs.LG cs.AI cs.CL
Comments: Accepted in the 40th International Conference on Machine Learning
 (ICML 2023)
\\
 Joint representation learning over multi-sourced knowledge graphs (KGs)
yields transferable and expressive embeddings that improve downstream tasks.
Entity alignment (EA) is a critical step in this process. Despite recent
considerable research progress in embedding-based EA, how it works remains to
be explored. In this paper, we provide a similarity flooding perspective to
explain existing translation-based and aggregation-based EA models. We prove
that the embedding learning process of these models actually seeks a fixpoint
of pairwise similarities between entities. We also provide experimental
evidence to support our theoretical analysis. We propose two simple but
effective methods inspired by the fixpoint computation in similarity flooding,
and demonstrate their effectiveness on benchmark datasets. Our work bridges the
gap between recent embedding-based models and the conventional similarity
flooding algorithm. It would improve our understanding of and increase our
faith in embedding-based EA.
\\ ( https://arxiv.org/abs/2306.02622 ,  254kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02639
Date: Mon, 5 Jun 2023 07:15:54 GMT   (103kb,D)

Title: Evaluating robustness of support vector machines with the Lagrangian
 dual approach
Authors: Yuting Liu, Hong Gu, Pan Qin
Categories: cs.LG cs.AI
\\
 Adversarial examples bring a considerable security threat to support vector
machines (SVMs), especially those used in safety-critical applications. Thus,
robustness verification is an essential issue for SVMs, which can provide
provable robustness against various kinds of adversary attacks. The evaluation
results obtained through the robustness verification can provide a safe
guarantee for the use of SVMs. The existing verification method does not often
perform well in verifying SVMs with nonlinear kernels. To this end, we propose
a method to improve the verification performance for SVMs with nonlinear
kernels. We first formalize the adversarial robustness evaluation of SVMs as an
optimization problem. Then a lower bound of the original problem is obtained by
solving the Lagrangian dual problem of the original problem. Finally, the
adversarial robustness of SVMs is evaluated concerning the lower bound. We
evaluate the adversarial robustness of SVMs with linear and nonlinear kernels
on the MNIST and Fashion-MNIST datasets. The experimental results show that the
percentage of provable robustness obtained by our method on the test set is
better than that of the state-of-the-art.
\\ ( https://arxiv.org/abs/2306.02639 ,  103kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02652
Date: Mon, 5 Jun 2023 07:38:13 GMT   (11259kb,D)

Title: Towards Anytime Classification in Early-Exit Architectures by Enforcing
 Conditional Monotonicity
Authors: Metod Jazbec, James Urquhart Allingham, Dan Zhang, Eric Nalisnick
Categories: cs.LG cs.AI stat.ML
\\
 Modern predictive models are often deployed to environments in which
computational budgets are dynamic. Anytime algorithms are well-suited to such
environments as, at any point during computation, they can output a prediction
whose quality is a function of computation time. Early-exit neural networks
have garnered attention in the context of anytime computation due to their
capability to provide intermediate predictions at various stages throughout the
network. However, we demonstrate that current early-exit networks are not
directly applicable to anytime settings, as the quality of predictions for
individual data points is not guaranteed to improve with longer computation. To
address this shortcoming, we propose an elegant post-hoc modification, based on
the Product-of-Experts, that encourages an early-exit network to become
gradually confident. This gives our deep models the property of conditional
monotonicity in the prediction quality -- an essential stepping stone towards
truly anytime predictive modeling using early-exit architectures. Our empirical
results on standard image-classification tasks demonstrate that such behaviors
can be achieved while preserving competitive accuracy on average.
\\ ( https://arxiv.org/abs/2306.02652 ,  11259kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02658
Date: Mon, 5 Jun 2023 07:47:30 GMT   (5915kb,D)

Title: Faster Training of Diffusion Models and Improved Density Estimation via
 Parallel Score Matching
Authors: Etrit Haxholli, Marco Lorenzi
Categories: cs.LG stat.ML
\\
 In Diffusion Probabilistic Models (DPMs), the task of modeling the score
evolution via a single time-dependent neural network necessitates extended
training periods and may potentially impede modeling flexibility and capacity.
To counteract these challenges, we propose leveraging the independence of
learning tasks at different time points inherent to DPMs. More specifically, we
partition the learning task by utilizing independent networks, each dedicated
to learning the evolution of scores within a specific time sub-interval.
Further, inspired by residual flows, we extend this strategy to its logical
conclusion by employing separate networks to independently model the score at
each individual time point. As empirically demonstrated on synthetic and image
datasets, our approach not only significantly accelerates the training process
by introducing an additional layer of parallelization atop data
parallelization, but it also enhances density estimation performance when
compared to the conventional training methodology for DPMs.
\\ ( https://arxiv.org/abs/2306.02658 ,  5915kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02664
Date: Mon, 5 Jun 2023 07:53:52 GMT   (9297kb,D)

Title: Structure-free Graph Condensation: From Large-scale Graphs to Condensed
 Graph-free Data
Authors: Xin Zheng, Miao Zhang, Chunyang Chen, Quoc Viet Hung Nguyen, Xingquan
 Zhu, Shirui Pan
Categories: cs.LG cs.SI
Comments: 9 pages, 3 figures
\\
 Graph condensation, which reduces the size of a large-scale graph by
synthesizing a small-scale condensed graph as its substitution, has immediate
benefits for various graph learning tasks. However, existing graph condensation
methods rely on the joint optimization of nodes and structures in the condensed
graph, and overlook critical issues in effectiveness and generalization
ability. In this paper, we advocate a new Structure-Free Graph Condensation
paradigm, named SFGC, to distill a large-scale graph into a small-scale graph
node set without explicit graph structures, i.e., graph-free data. Our idea is
to implicitly encode topology structure information into the node attributes in
the synthesized graph-free data, whose topology is reduced to an identity
matrix. Specifically, SFGC contains two collaborative components: (1) a
training trajectory meta-matching scheme for effectively synthesizing
small-scale graph-free data; (2) a graph neural feature score metric for
dynamically evaluating the quality of the condensed data. Through training
trajectory meta-matching, SFGC aligns the long-term GNN learning behaviors
between the large-scale graph and the condensed small-scale graph-free data,
ensuring comprehensive and compact transfer of informative knowledge to the
graph-free data. Afterward, the underlying condensed graph-free data would be
dynamically evaluated with the graph neural feature score, which is a
closed-form metric for ensuring the excellent expressiveness of the condensed
graph-free data. Extensive experiments verify the superiority of SFGC across
different condensation ratios.
\\ ( https://arxiv.org/abs/2306.02664 ,  9297kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02677
Date: Mon, 5 Jun 2023 08:11:44 GMT   (2062kb,D)

Title: A Privacy-Preserving Federated Learning Approach for Kernel methods
Authors: Anika Hannemann, Ali Burak \"Unal, Arjhun Swaminathan, Erik Buchmann,
 Mete Akg\"un
Categories: cs.LG cs.CR
Comments: Preprint version of the full paper with supplementary material
ACM-class: I.2; I.2; K.6.5; E.3
\\
 It is challenging to implement Kernel methods, if the data sources are
distributed and cannot be joined at a trusted third party for privacy reasons.
It is even more challenging, if the use case rules out privacy-preserving
approaches that introduce noise. An example for such a use case is machine
learning on clinical data. To realize exact privacy preserving computation of
kernel methods, we propose FLAKE, a Federated Learning Approach for KErnel
methods on horizontally distributed data. With FLAKE, the data sources mask
their data so that a centralized instance can compute a Gram matrix without
compromising privacy. The Gram matrix allows to calculate many kernel matrices,
which can be used to train kernel-based machine learning algorithms such as
Support Vector Machines. We prove that FLAKE prevents an adversary from
learning the input data or the number of input features under a semi-honest
threat model. Experiments on clinical and synthetic data confirm that FLAKE is
outperforming the accuracy and efficiency of comparable methods. The time
needed to mask the data and to compute the Gram matrix is several orders of
magnitude less than the time a Support Vector Machine needs to be trained.
Thus, FLAKE can be applied to many use cases.
\\ ( https://arxiv.org/abs/2306.02677 ,  2062kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02685
Date: Mon, 5 Jun 2023 08:22:18 GMT   (1350kb,D)

Title: Predicting malaria dynamics in Burundi using deep Learning Models
Authors: Daxelle Sakubu, Kelly Joelle Gatore Sinigirira, David Niyukuri
Categories: cs.LG cs.AI
\\
 Malaria continues to be a major public health problem on the African
continent, particularly in Sub-Saharan Africa. Nonetheless, efforts are
ongoing, and significant progress has been made. In Burundi, malaria is among
the main public health concerns. In the literature, there are limited
prediction models for Burundi. We know that such tools are much needed for
interventions design. In our study, we built machine-learning based models to
estimates malaria cases in Burundi. The forecast was carried out at province
level, allowing us to estimate malaria cases on a national scale as well. Long
short term memory (LSTM) model, a type of deep learning model has been used to
achieve best results using climate-change related factors such as temperature,
rainfal, and relative humidity, together with malaria historical data and human
population. The results showed that at country level different tuning of
parameters can be used in order to determine the minimum and maximum expected
malaria
\\ ( https://arxiv.org/abs/2306.02685 ,  1350kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02688
Date: Mon, 5 Jun 2023 08:28:42 GMT   (923kb,D)

Title: Meta-SAGE: Scale Meta-Learning Scheduled Adaptation with Guided
 Exploration for Mitigating Scale Shift on Combinatorial Optimization
Authors: Jiwoo Son, Minsu Kim, Hyeonah Kim, Jinkyoo Park
Categories: cs.LG stat.ML
Comments: 18 pages, 9 figures, International Conference on Machine Learning
 (ICML) 2023
\\
 This paper proposes Meta-SAGE, a novel approach for improving the scalability
of deep reinforcement learning models for combinatorial optimization (CO)
tasks. Our method adapts pre-trained models to larger-scale problems in test
time by suggesting two components: a scale meta-learner (SML) and scheduled
adaptation with guided exploration (SAGE). First, SML transforms the context
embedding for subsequent adaptation of SAGE based on scale information. Then,
SAGE adjusts the model parameters dedicated to the context embedding for a
specific instance. SAGE introduces locality bias, which encourages selecting
nearby locations to determine the next location. The locality bias gradually
decays as the model is adapted to the target instance. Results show that
Meta-SAGE outperforms previous adaptation methods and significantly improves
scalability in representative CO tasks. Our source code is available at
https://github.com/kaist-silab/meta-sage
\\ ( https://arxiv.org/abs/2306.02688 ,  923kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02689
Date: Mon, 5 Jun 2023 08:29:55 GMT   (2106kb,D)

Title: Solving NP-hard Min-max Routing Problems as Sequential Generation with
 Equity Context
Authors: Jiwoo Son, Minsu Kim, Sanghyeok Choi, Jinkyoo Park
Categories: cs.LG math.OC stat.ML
Comments: 18 pages, 7 figures
\\
 Min-max routing problems aim to minimize the maximum tour length among agents
as they collaboratively visit all cities, i.e., the completion time. These
problems include impactful real-world applications but are known as NP-hard.
Existing methods are facing challenges, particularly in large-scale problems
that require the coordination of numerous agents to cover thousands of cities.
This paper proposes a new deep-learning framework to solve large-scale min-max
routing problems. We model the simultaneous decision-making of multiple agents
as a sequential generation process, allowing the utilization of scalable
deep-learning models for sequential decision-making. In the sequentially
approximated problem, we propose a scalable contextual Transformer model,
Equity-Transformer, which generates sequential actions considering an equitable
workload among other agents. The effectiveness of Equity-Transformer is
demonstrated through its superior performance in two representative min-max
routing tasks: the min-max multiple traveling salesman problem (min-max mTSP)
and the min-max multiple pick-up and delivery problem (min-max mPDP). Notably,
our method achieves significant reductions of runtime, approximately 335 times,
and cost values of about 53% compared to a competitive heuristic (LKH3) in the
case of 100 vehicles with 1,000 cities of mTSP. We provide reproducible source
code: https://github.com/kaist-silab/equity-transformer
\\ ( https://arxiv.org/abs/2306.02689 ,  2106kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02701
Date: Mon, 5 Jun 2023 08:45:44 GMT   (668kb,D)

Title: Unlocking the Potential of Federated Learning for Deeper Models
Authors: Haolin Wang, Xuefeng Liu, Jianwei Niu, Shaojie Tang, Jiaxing Shen
Categories: cs.LG cs.AI
Comments: 16 pages, 8 figures
\\
 Federated learning (FL) is a new paradigm for distributed machine learning
that allows a global model to be trained across multiple clients without
compromising their privacy. Although FL has demonstrated remarkable success in
various scenarios, recent studies mainly utilize shallow and small neural
networks. In our research, we discover a significant performance decline when
applying the existing FL framework to deeper neural networks, even when client
data are independently and identically distributed (i.i.d.). Our further
investigation shows that the decline is due to the continuous accumulation of
dissimilarities among client models during the layer-by-layer back-propagation
process, which we refer to as "divergence accumulation." As deeper models
involve a longer chain of divergence accumulation, they tend to manifest
greater divergence, subsequently leading to performance decline. Both
theoretical derivations and empirical evidence are proposed to support the
existence of divergence accumulation and its amplified effects in deeper
models. To address this issue, we propose several technical guidelines based on
reducing divergence, such as using wider models and reducing the receptive
field. These approaches can greatly improve the accuracy of FL on deeper
models. For example, the application of these guidelines can boost the
ResNet101 model's performance by as much as 43\% on the Tiny-ImageNet dataset.
\\ ( https://arxiv.org/abs/2306.02701 ,  668kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02709
Date: Mon, 5 Jun 2023 09:01:38 GMT   (714kb)

Title: Comparative Study on Semi-supervised Learning Applied for Anomaly
 Detection in Hydraulic Condition Monitoring System
Authors: Yongqi Dong, Kejia Chen, Zhiyuan Ma
Categories: cs.LG stat.ML
Comments: 7 pages, 8 figures, accepted by 2023 IEEE International Conference on
 Systems, Man, and Cybernetics (SMC 2023) https://ieeesmc2023.org/
\\
 Condition-based maintenance is becoming increasingly important in hydraulic
systems. However, anomaly detection for these systems remains challenging,
especially since that anomalous data is scarce and labeling such data is
tedious and even dangerous. Therefore, it is advisable to make use of
unsupervised or semi-supervised methods, especially for semi-supervised
learning which utilizes unsupervised learning as a feature extraction mechanism
to aid the supervised part when only a small number of labels are available.
This study systematically compares semi-supervised learning methods applied for
anomaly detection in hydraulic condition monitoring systems. Firstly, thorough
data analysis and feature learning were carried out to understand the
open-sourced hydraulic condition monitoring dataset. Then, various methods were
implemented and evaluated including traditional stand-alone semi-supervised
learning models (e.g., one-class SVM, Robust Covariance), ensemble models
(e.g., Isolation Forest), and deep neural network based models (e.g.,
autoencoder, Hierarchical Extreme Learning Machine (HELM)). Typically, this
study customized and implemented an extreme learning machine based
semi-supervised HELM model and verified its superiority over other
semi-supervised methods. Extensive experiments show that the customized HELM
model obtained state-of-the-art performance with the highest accuracy (99.5%),
the lowest false positive rate (0.015), and the best F1-score (0.985) beating
other semi-supervised methods.
\\ ( https://arxiv.org/abs/2306.02709 ,  714kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02729
Date: Mon, 5 Jun 2023 09:26:38 GMT   (830kb,D)

Title: Gibbs Sampling the Posterior of Neural Networks
Authors: Giovanni Piccioli, Emanuele Troiani and Lenka Zdeborov\'a
Categories: cs.LG stat.ML
\\
 In this paper, we study sampling from a posterior derived from a neural
network. We propose a new probabilistic model consisting of adding noise at
every pre- and post-activation in the network, arguing that the resulting
posterior can be sampled using an efficient Gibbs sampler. The Gibbs sampler
attains similar performances as the state-of-the-art Monte Carlo Markov chain
methods, such as the Hamiltonian Monte Carlo or the Metropolis adjusted
Langevin algorithm, both on real and synthetic data. By framing our analysis in
the teacher-student setting, we introduce a thermalization criterion that
allows us to detect when an algorithm, when run on data with synthetic labels,
fails to sample from the posterior. The criterion is based on the fact that in
the teacher-student setting we can initialize an algorithm directly at
equilibrium.
\\ ( https://arxiv.org/abs/2306.02729 ,  830kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02731
Date: Mon, 5 Jun 2023 09:27:28 GMT   (1390kb,D)

Title: Enhanced Distribution Modelling via Augmented Architectures For Neural
 ODE Flows
Authors: Etrit Haxholli, Marco Lorenzi
Categories: cs.LG
\\
 While the neural ODE formulation of normalizing flows such as in FFJORD
enables us to calculate the determinants of free form Jacobians in O(D) time,
the flexibility of the transformation underlying neural ODEs has been shown to
be suboptimal. In this paper, we present AFFJORD, a neural ODE-based
normalizing flow which enhances the representation power of FFJORD by defining
the neural ODE through special augmented transformation dynamics which preserve
the topology of the space. Furthermore, we derive the Jacobian determinant of
the general augmented form by generalizing the chain rule in the continuous
sense into the Cable Rule, which expresses the forward sensitivity of ODEs with
respect to their initial conditions. The cable rule gives an explicit
expression for the Jacobian of a neural ODE transformation, and provides an
elegant proof of the instantaneous change of variable. Our experimental results
on density estimation in synthetic and high dimensional data, such as MNIST,
CIFAR-10 and CelebA 32x32, show that AFFJORD outperforms the baseline FFJORD
through the improved flexibility of the underlying vector field.
\\ ( https://arxiv.org/abs/2306.02731 ,  1390kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02738
Date: Mon, 5 Jun 2023 09:33:39 GMT   (2182kb,D)

Title: A Large-Scale Study of Probabilistic Calibration in Neural Network
 Regression
Authors: Victor Dheur and Souhaib Ben Taieb
Categories: cs.LG
\\
 Accurate probabilistic predictions are essential for optimal decision making.
While neural network miscalibration has been studied primarily in
classification, we investigate this in the less-explored domain of regression.
We conduct the largest empirical study to date to assess the probabilistic
calibration of neural networks. We also analyze the performance of
recalibration, conformal, and regularization methods to enhance probabilistic
calibration. Additionally, we introduce novel differentiable recalibration and
regularization methods, uncovering new insights into their effectiveness. Our
findings reveal that regularization methods offer a favorable tradeoff between
calibration and sharpness. Post-hoc methods exhibit superior probabilistic
calibration, which we attribute to the finite-sample coverage guarantee of
conformal prediction. Furthermore, we demonstrate that quantile recalibration
can be considered as a specific case of conformal prediction. Our study is
fully reproducible and implemented in a common code base for fair comparisons.
\\ ( https://arxiv.org/abs/2306.02738 ,  2182kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02747
Date: Mon, 5 Jun 2023 10:05:43 GMT   (1313kb,D)

Title: Tackling Non-Stationarity in Reinforcement Learning via Causal-Origin
 Representation
Authors: Wanpeng Zhang, Yilin Li, Boyu Yang, Zongqing Lu
Categories: cs.LG
\\
 In real-world scenarios, the application of reinforcement learning is
significantly challenged by complex non-stationarity. Most existing methods
attempt to model the changes of the environment explicitly, often requiring
impractical prior knowledge. In this paper, we propose a new perspective,
positing that non-stationarity can propagate and accumulate through complex
causal relationships during state transitions, thereby compounding its
sophistication and affecting policy learning. We believe that this challenge
can be more effectively addressed by tracing the causal origin of
non-stationarity. To this end, we introduce the Causal-Origin REPresentation
(COREP) algorithm. COREP primarily employs a guided updating mechanism to learn
a stable graph representation for states termed as causal-origin
representation. By leveraging this representation, the learned policy exhibits
impressive resilience to non-stationarity. We supplement our approach with a
theoretical analysis grounded in the causal interpretation for non-stationary
reinforcement learning, advocating for the validity of the causal-origin
representation. Experimental results further demonstrate the superior
performance of COREP over existing methods in tackling non-stationarity.
\\ ( https://arxiv.org/abs/2306.02747 ,  1313kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02781
Date: Mon, 5 Jun 2023 11:14:18 GMT   (570kb)

Title: A survey of Generative AI Applications
Authors: Roberto Gozalo-Brizuela, Eduardo C. Garrido-Merch\'an
Categories: cs.LG cs.AI
\\
 Generative AI has experienced remarkable growth in recent years, leading to a
wide array of applications across diverse domains. In this paper, we present a
comprehensive survey of more than 350 generative AI applications, providing a
structured taxonomy and concise descriptions of various unimodal and even
multimodal generative AIs. The survey is organized into sections, covering a
wide range of unimodal generative AI applications such as text, images, video,
gaming and brain information. Our survey aims to serve as a valuable resource
for researchers and practitioners to navigate the rapidly expanding landscape
of generative AI, facilitating a better understanding of the current
state-of-the-art and fostering further innovation in the field.
\\ ( https://arxiv.org/abs/2306.02781 ,  570kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02786
Date: Mon, 5 Jun 2023 11:26:46 GMT   (769kb,D)

Title: Navigating Explanatory Multiverse Through Counterfactual Path Geometry
Authors: Kacper Sokol and Edward Small and Yueqing Xuan
Categories: cs.LG cs.AI
\\
 Counterfactual explanations are the de facto standard when tasked with
interpreting decisions of (opaque) predictive models. Their generation is often
subject to algorithmic and domain-specific constraints -- such as density-based
feasibility for the former and attribute (im)mutability or directionality of
change for the latter -- that aim to maximise their real-life utility. In
addition to desiderata with respect to the counterfactual instance itself, the
existence of a viable path connecting it with the factual data point, known as
algorithmic recourse, has become an important technical consideration. While
both of these requirements ensure that the steps of the journey as well as its
destination are admissible, current literature neglects the multiplicity of
such counterfactual paths. To address this shortcoming we introduce the novel
concept of explanatory multiverse that encompasses all the possible
counterfactual journeys and shows how to navigate, reason about and compare the
geometry of these paths -- their affinity, branching, divergence and possible
future convergence -- with two methods: vector spaces and graphs. Implementing
this (interactive) explanatory process grants explainees more agency by
allowing them to select counterfactuals based on the properties of the journey
leading to them in addition to their absolute differences.
\\ ( https://arxiv.org/abs/2306.02786 ,  769kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02806
Date: Mon, 5 Jun 2023 11:58:07 GMT   (23007kb,D)

Title: A Data-driven Region Generation Framework for Spatiotemporal
 Transportation Service Management
Authors: Liyue Chen, Jiangyi Fang, Zhe Yu, Yongxin Tong, Shaosheng Cao, Leye
 Wang
Categories: cs.LG cs.DB
DOI: 10.1145/3580305.3599760
\\
 MAUP (modifiable areal unit problem) is a fundamental problem for spatial
data management and analysis. As an instantiation of MAUP in online
transportation platforms, region generation (i.e., specifying the areal unit
for service operations) is the first and vital step for supporting
spatiotemporal transportation services such as ride-sharing and freight
transport. Most existing region generation methods are manually specified
(e.g., fixed-size grids), suffering from poor spatial semantic meaning and
inflexibility to meet service operation requirements. In this paper, we propose
RegionGen, a data-driven region generation framework that can specify regions
with key characteristics (e.g., good spatial semantic meaning and
predictability) by modeling region generation as a multi-objective optimization
problem. First, to obtain good spatial semantic meaning, RegionGen segments the
whole city into atomic spatial elements based on road networks and obstacles
(e.g., rivers). Then, it clusters the atomic spatial elements into regions by
maximizing various operation characteristics, which is formulated as a
multi-objective optimization problem. For this optimization problem, we propose
a multi-objective co-optimization algorithm. Extensive experiments verify that
RegionGen can generate more suitable regions than traditional methods for
spatiotemporal service management.
\\ ( https://arxiv.org/abs/2306.02806 ,  23007kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02807
Date: Mon, 5 Jun 2023 11:58:25 GMT   (5185kb,D)

Title: On Tail Decay Rate Estimation of Loss Function Distributions
Authors: Etrit Haxholli, Marco Lorenzi
Categories: cs.LG
\\
 The study of loss function distributions is critical to characterize a
model's behaviour on a given machine learning problem. For example, while the
quality of a model is commonly determined by the average loss assessed on a
testing set, this quantity does not reflect the existence of the true mean of
the loss distribution. Indeed, the finiteness of the statistical moments of the
loss distribution is related to the thickness of its tails, which are generally
unknown. Since typical cross-validation schemes determine a family of testing
loss distributions conditioned on the training samples, the total loss
distribution must be recovered by marginalizing over the space of training
sets. As we show in this work, the finiteness of the sampling procedure
negatively affects the reliability and efficiency of classical tail estimation
methods from the Extreme Value Theory, such as the Peaks-Over-Threshold
approach. In this work we tackle this issue by developing a novel general
theory for estimating the tails of marginal distributions, when there exists a
large variability between locations of the individual conditional distributions
underlying the marginal. To this end, we demonstrate that under some regularity
conditions, the shape parameter of the marginal distribution is the maximum
tail shape parameter of the family of conditional distributions. We term this
estimation approach as Cross Tail Estimation (CTE). We test cross-tail
estimation in a series of experiments on simulated and real data, showing the
improved robustness and quality of tail estimation as compared to classical
approaches, and providing evidence for the relationship between overfitting and
loss distribution tail thickness.
\\ ( https://arxiv.org/abs/2306.02807 ,  5185kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02808
Date: Mon, 5 Jun 2023 12:00:12 GMT   (1369kb,D)

Title: Deep Active Learning with Structured Neural Depth Search
Authors: Xiaoyun Zhang, Xieyi Ping and Jianwei Zhang
Categories: cs.LG cs.AI
Comments: 10 pages, 8 figures, prepare for TNNLS
\\
 Previous work optimizes traditional active learning (AL) processes with
incremental neural network architecture search (Active-iNAS) based on data
complexity change, which improves the accuracy and learning efficiency.
However, Active-iNAS trains several models and selects the model with the best
generalization performance for querying the subsequent samples after each
active learning cycle. The independent training processes lead to an
insufferable computational budget, which is significantly inefficient and
limits search flexibility and final performance. To address this issue, we
propose a novel active strategy with the method called structured variational
inference (SVI) or structured neural depth search (SNDS) whereby we could use
the gradient descent method in neural network depth search during AL processes.
At the same time, we theoretically demonstrate that the current VI-based
methods based on the mean-field assumption could lead to poor performance. We
apply our strategy using three querying techniques and three datasets and show
that our strategy outperforms current methods.
\\ ( https://arxiv.org/abs/2306.02808 ,  1369kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02816
Date: Mon, 5 Jun 2023 12:12:59 GMT   (1000kb,D)

Title: MultiAdam: Parameter-wise Scale-invariant Optimizer for Multiscale
 Training of Physics-informed Neural Networks
Authors: Jiachen Yao, Chang Su, Zhongkai Hao, Songming Liu, Hang Su, Jun Zhu
Categories: cs.LG cs.NA math.NA
\\
 Physics-informed Neural Networks (PINNs) have recently achieved remarkable
progress in solving Partial Differential Equations (PDEs) in various fields by
minimizing a weighted sum of PDE loss and boundary loss. However, there are
several critical challenges in the training of PINNs, including the lack of
theoretical frameworks and the imbalance between PDE loss and boundary loss. In
this paper, we present an analysis of second-order non-homogeneous PDEs, which
are classified into three categories and applicable to various common problems.
We also characterize the connections between the training loss and actual
error, guaranteeing convergence under mild conditions. The theoretical analysis
inspires us to further propose MultiAdam, a scale-invariant optimizer that
leverages gradient momentum to parameter-wisely balance the loss terms.
Extensive experiment results on multiple problems from different physical
domains demonstrate that our MultiAdam solver can improve the predictive
accuracy by 1-2 orders of magnitude compared with strong baselines.
\\ ( https://arxiv.org/abs/2306.02816 ,  1000kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02822
Date: Mon, 5 Jun 2023 12:20:40 GMT   (5201kb,D)

Title: Discovering Dynamic Causal Space for DAG Structure Learning
Authors: Fangfu Liu, Wenchang Ma, An Zhang, Xiang Wang, Yueqi Duan, Tat-Seng
 Chua
Categories: cs.LG stat.ML
Comments: Accepted by KDD 2023
\\
 Discovering causal structure from purely observational data (i.e., causal
discovery), aiming to identify causal relationships among variables, is a
fundamental task in machine learning. The recent invention of differentiable
score-based DAG learners is a crucial enabler, which reframes the combinatorial
optimization problem into a differentiable optimization with a DAG constraint
over directed graph space. Despite their great success, these cutting-edge DAG
learners incorporate DAG-ness independent score functions to evaluate the
directed graph candidates, lacking in considering graph structure. As a result,
measuring the data fitness alone regardless of DAG-ness inevitably leads to
discovering suboptimal DAGs and model vulnerabilities. Towards this end, we
propose a dynamic causal space for DAG structure learning, coined CASPER, that
integrates the graph structure into the score function as a new measure in the
causal space to faithfully reflect the causal distance between estimated and
ground truth DAG. CASPER revises the learning process as well as enhances the
DAG structure learning via adaptive attention to DAG-ness. Grounded by
empirical visualization, CASPER, as a space, satisfies a series of desired
properties, such as structure awareness and noise robustness. Extensive
experiments on both synthetic and real-world datasets clearly validate the
superiority of our CASPER over the state-of-the-art causal discovery methods in
terms of accuracy and robustness.
\\ ( https://arxiv.org/abs/2306.02822 ,  5201kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02824
Date: Mon, 5 Jun 2023 12:21:42 GMT   (390kb,D)

Title: COMET: Learning Cardinality Constrained Mixture of Experts with Trees
 and Local Search
Authors: Shibal Ibrahim, Wenyu Chen, Hussein Hazimeh, Natalia Ponomareva, Zhe
 Zhao, Rahul Mazumder
Categories: cs.LG
Comments: Accepted in KDD 2023
DOI: 10.1145/3580305.3599278
\\
 The sparse Mixture-of-Experts (Sparse-MoE) framework efficiently scales up
model capacity in various domains, such as natural language processing and
vision. Sparse-MoEs select a subset of the "experts" (thus, only a portion of
the overall network) for each input sample using a sparse, trainable gate.
Existing sparse gates are prone to convergence and performance issues when
training with first-order optimization methods. In this paper, we introduce two
improvements to current MoE approaches. First, we propose a new sparse gate:
COMET, which relies on a novel tree-based mechanism. COMET is differentiable,
can exploit sparsity to speed up computation, and outperforms state-of-the-art
gates. Second, due to the challenging combinatorial nature of sparse expert
selection, first-order methods are typically prone to low-quality solutions. To
deal with this challenge, we propose a novel, permutation-based local search
method that can complement first-order methods in training any sparse gate,
e.g., Hash routing, Top-k, DSelect-k, and COMET. We show that local search can
help networks escape bad initializations or solutions. We performed large-scale
experiments on various domains, including recommender systems, vision, and
natural language processing. On standard vision and recommender systems
benchmarks, COMET+ (COMET with local search) achieves up to 13% improvement in
ROC AUC over popular gates, e.g., Hash routing and Top-k, and up to 9% over
prior differentiable gates e.g., DSelect-k. When Top-k and Hash gates are
combined with local search, we see up to $100\times$ reduction in the budget
needed for hyperparameter tuning. Moreover, for language modeling, our approach
improves over the state-of-the-art MoEBERT model for distilling BERT on 5/7
GLUE benchmarks as well as SQuAD dataset.
\\ ( https://arxiv.org/abs/2306.02824 ,  390kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02834
Date: Mon, 5 Jun 2023 12:29:34 GMT   (200kb,D)

Title: Computational Complexity of Detecting Proximity to Losslessly
 Compressible Neural Network Parameters
Authors: Matthew Farrugia-Roberts (The University of Melbourne)
Categories: cs.LG cs.CC
Comments: 9 pages paper, 31 pages total, 9 figures, 3 tables
\\
 To better understand complexity in neural networks, we theoretically
investigate the idealised phenomenon of lossless network compressibility,
whereby an identical function can be implemented with a smaller network. We
give an efficient formal algorithm for optimal lossless compression in the
setting of single-hidden-layer hyperbolic tangent networks. To measure lossless
compressibility, we define the rank of a parameter as the minimum number of
hidden units required to implement the same function. Losslessly compressible
parameters are atypical, but their existence has implications for nearby
parameters. We define the proximate rank of a parameter as the rank of the most
compressible parameter within a small $L^\infty$ neighbourhood. Unfortunately,
detecting nearby losslessly compressible parameters is not so easy: we show
that bounding the proximate rank is an NP-complete problem, using a reduction
from Boolean satisfiability via a geometric problem involving covering points
in the plane with small squares. These results underscore the computational
complexity of measuring neural network complexity, laying a foundation for
future theoretical and empirical work in this direction.
\\ ( https://arxiv.org/abs/2306.02834 ,  200kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02848
Date: Mon, 5 Jun 2023 12:58:13 GMT   (570kb,D)

Title: HireVAE: An Online and Adaptive Factor Model Based on Hierarchical and
 Regime-Switch VAE
Authors: Zikai Wei, Anyi Rao, Bo Dai, Dahua Lin
Categories: cs.LG cs.CV q-fin.PM
Comments: Accepted to IJCAI 2023
\\
 Factor model is a fundamental investment tool in quantitative investment,
which can be empowered by deep learning to become more flexible and efficient
in practical complicated investing situations. However, it is still an open
question to build a factor model that can conduct stock prediction in an online
and adaptive setting, where the model can adapt itself to match the current
market regime identified based on only point-in-time market information. To
tackle this problem, we propose the first deep learning based online and
adaptive factor model, HireVAE, at the core of which is a hierarchical latent
space that embeds the underlying relationship between the market situation and
stock-wise latent factors, so that HireVAE can effectively estimate useful
latent factors given only historical market information and subsequently
predict accurate stock returns. Across four commonly used real stock market
benchmarks, the proposed HireVAE demonstrate superior performance in terms of
active returns over previous methods, verifying the potential of such online
and adaptive factor model.
\\ ( https://arxiv.org/abs/2306.02848 ,  570kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02859
Date: Mon, 5 Jun 2023 13:24:03 GMT   (2051kb,D)

Title: Local Boosting for Weakly-Supervised Learning
Authors: Rongzhi Zhang, Yue Yu, Jiaming Shen, Xiquan Cui, Chao Zhang
Categories: cs.LG
Comments: Accepted by KDD 2023 Research Track
DOI: 10.1145/3580305.3599417
\\
 Boosting is a commonly used technique to enhance the performance of a set of
base models by combining them into a strong ensemble model. Though widely
adopted, boosting is typically used in supervised learning where the data is
labeled accurately. However, in weakly supervised learning, where most of the
data is labeled through weak and noisy sources, it remains nontrivial to design
effective boosting approaches. In this work, we show that the standard
implementation of the convex combination of base learners can hardly work due
to the presence of noisy labels. Instead, we propose $\textit{LocalBoost}$, a
novel framework for weakly-supervised boosting. LocalBoost iteratively boosts
the ensemble model from two dimensions, i.e., intra-source and inter-source.
The intra-source boosting introduces locality to the base learners and enables
each base learner to focus on a particular feature regime by training new base
learners on granularity-varying error regions. For the inter-source boosting,
we leverage a conditional function to indicate the weak source where the sample
is more likely to appear. To account for the weak labels, we further design an
estimate-then-modify approach to compute the model weights. Experiments on
seven datasets show that our method significantly outperforms vanilla boosting
methods and other weakly-supervised methods.
\\ ( https://arxiv.org/abs/2306.02859 ,  2051kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02865
Date: Mon, 5 Jun 2023 13:38:14 GMT   (34018kb,D)

Title: Seizing Serendipity: Exploiting the Value of Past Success in Off-Policy
 Actor-Critic
Authors: Tianying Ji, Yu Luo, Fuchun Sun, Xianyuan Zhan, Jianwei Zhang, Huazhe
 Xu
Categories: cs.LG cs.AI
\\
 Learning high-quality Q-value functions plays a key role in the success of
many modern off-policy deep reinforcement learning (RL) algorithms. Previous
works focus on addressing the value overestimation issue, an outcome of
adopting function approximators and off-policy learning. Deviating from the
common viewpoint, we observe that Q-values are indeed underestimated in the
latter stage of the RL training process, primarily related to the use of
inferior actions from the current policy in Bellman updates as compared to the
more optimal action samples in the replay buffer. We hypothesize that this
long-neglected phenomenon potentially hinders policy learning and reduces
sample efficiency. Our insight to address this issue is to incorporate
sufficient exploitation of past successes while maintaining exploration
optimism. We propose the Blended Exploitation and Exploration (BEE) operator, a
simple yet effective approach that updates Q-value using both historical
best-performing actions and the current policy. The instantiations of our
method in both model-free and model-based settings outperform state-of-the-art
methods in various continuous control tasks and achieve strong performance in
failure-prone scenarios and real-world robot tasks.
\\ ( https://arxiv.org/abs/2306.02865 ,  34018kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02866
Date: Mon, 5 Jun 2023 13:40:54 GMT   (795kb,D)

Title: Learning Probabilistic Symmetrization for Architecture Agnostic
 Equivariance
Authors: Jinwoo Kim, Tien Dat Nguyen, Ayhan Suleymanzade, Hyeokjun An,
 Seunghoon Hong
Categories: cs.LG cs.AI
Comments: 25 pages, 3 figures
\\
 We present a novel framework to overcome the limitations of equivariant
architectures in learning functions with group symmetries. In contrary to
equivariant architectures, we use an arbitrary base model (such as an MLP or a
transformer) and symmetrize it to be equivariant to the given group by
employing a small equivariant network that parameterizes the probabilistic
distribution underlying the symmetrization. The distribution is end-to-end
trained with the base model which can maximize performance while reducing
sample complexity of symmetrization. We show that this approach ensures not
only equivariance to given group but also universal approximation capability in
expectation. We implement our method on a simple patch-based transformer that
can be initialized from pretrained vision transformers, and test it for a wide
range of symmetry groups including permutation and Euclidean groups and their
combinations. Empirical tests show competitive results against tailored
equivariant architectures, suggesting the potential for learning equivariant
functions for diverse groups using a non-equivariant universal base
architecture. We further show evidence of enhanced learning in symmetric
modalities, like graphs, when pretrained from non-symmetric modalities, like
vision. Our implementation will be open-sourced at
https://github.com/jw9730/lps.
\\ ( https://arxiv.org/abs/2306.02866 ,  795kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02869
Date: Mon, 5 Jun 2023 13:43:34 GMT   (40603kb,D)

Title: Data-Driven Regret Balancing for Online Model Selection in Bandits
Authors: Aldo Pacchiano, Christoph Dann, Claudio Gentile
Categories: cs.LG cs.AI stat.ML
\\
 We consider model selection for sequential decision making in stochastic
environments with bandit feedback, where a meta-learner has at its disposal a
pool of base learners, and decides on the fly which action to take based on the
policies recommended by each base learner. Model selection is performed by
regret balancing but, unlike the recent literature on this subject, we do not
assume any prior knowledge about the base learners like candidate regret
guarantees; instead, we uncover these quantities in a data-driven manner. The
meta-learner is therefore able to leverage the realized regret incurred by each
base learner for the learning environment at hand (as opposed to the expected
regret), and single out the best such regret. We design two model selection
algorithms operating with this more ambitious notion of regret and, besides
proving model selection guarantees via regret balancing, we experimentally
demonstrate the compelling practical benefits of dealing with actual regrets
instead of candidate regret bounds.
\\ ( https://arxiv.org/abs/2306.02869 ,  40603kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02879
Date: Mon, 5 Jun 2023 13:50:56 GMT   (2694kb,D)

Title: Neuron Activation Coverage: Rethinking Out-of-distribution Detection and
 Generalization
Authors: Yibing Liu, Chris Xing Tian, Haoliang Li, Lei Ma, Shiqi Wang
Categories: cs.LG
\\
 The out-of-distribution (OOD) problem generally arises when neural networks
encounter data that significantly deviates from the training data distribution,
\ie, in-distribution (InD). In this paper, we study the OOD problem from a
neuron activation view. We first formulate neuron activation states by
considering both the neuron output and its influence on model decisions. Then,
we propose the concept of \textit{neuron activation coverage} (NAC), which
characterizes the neuron behaviors under InD and OOD data. Leveraging our NAC,
we show that 1) InD and OOD inputs can be naturally separated based on the
neuron behavior, which significantly eases the OOD detection problem and
achieves a record-breaking performance of 0.03% FPR95 on ResNet-50,
outperforming the previous best method by 20.67%; 2) a positive correlation
between NAC and model generalization ability consistently holds across
architectures and datasets, which enables a NAC-based criterion for evaluating
model robustness. By comparison with the traditional validation criterion, we
show that NAC-based criterion not only can select more robust models, but also
has a stronger correlation with OOD test performance.
\\ ( https://arxiv.org/abs/2306.02879 ,  2694kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02896
Date: Mon, 5 Jun 2023 14:05:04 GMT   (145kb,D)

Title: Representational Strengths and Limitations of Transformers
Authors: Clayton Sanford, Daniel Hsu, Matus Telgarsky
Categories: cs.LG stat.ML
\\
 Attention layers, as commonly used in transformers, form the backbone of
modern deep learning, yet there is no mathematical description of their
benefits and deficiencies as compared with other architectures. In this work we
establish both positive and negative results on the representation power of
attention layers, with a focus on intrinsic complexity parameters such as
width, depth, and embedding dimension. On the positive side, we present a
sparse averaging task, where recurrent networks and feedforward networks all
have complexity scaling polynomially in the input size, whereas transformers
scale merely logarithmically in the input size; furthermore, we use the same
construction to show the necessity and role of a large embedding dimension in a
transformer. On the negative side, we present a triple detection task, where
attention layers in turn have complexity scaling linearly in the input size; as
this scenario seems rare in practice, we also present natural variants that can
be efficiently solved by attention layers. The proof techniques emphasize the
value of communication complexity in the analysis of transformers and related
models, and the role of sparse averaging as a prototypical attention task,
which even finds use in the analysis of triple detection.
\\ ( https://arxiv.org/abs/2306.02896 ,  145kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02913
Date: Mon, 5 Jun 2023 14:19:52 GMT   (2039kb,D)

Title: Decentralized SGD and Average-direction SAM are Asymptotically
 Equivalent
Authors: Tongtian Zhu, Fengxiang He, Kaixuan Chen, Mingli Song, Dacheng Tao
Categories: cs.LG cs.CY cs.DC cs.SY eess.SY stat.ML
Comments: Accepted for publication in the 40th International Conference on
 Machine Learning (ICML 2023)
\\
 Decentralized stochastic gradient descent (D-SGD) allows collaborative
learning on massive devices simultaneously without the control of a central
server. However, existing theories claim that decentralization invariably
undermines generalization. In this paper, we challenge the conventional belief
and present a completely new perspective for understanding decentralized
learning. We prove that D-SGD implicitly minimizes the loss function of an
average-direction Sharpness-aware minimization (SAM) algorithm under general
non-convex non-$\beta$-smooth settings. This surprising asymptotic equivalence
reveals an intrinsic regularization-optimization trade-off and three advantages
of decentralization: (1) there exists a free uncertainty evaluation mechanism
in D-SGD to improve posterior estimation; (2) D-SGD exhibits a gradient
smoothing effect; and (3) the sharpness regularization effect of D-SGD does not
decrease as total batch size increases, which justifies the potential
generalization benefit of D-SGD over centralized SGD (C-SGD) in large-batch
scenarios.
\\ ( https://arxiv.org/abs/2306.02913 ,  2039kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02939
Date: Mon, 5 Jun 2023 15:03:01 GMT   (311kb)

Title: Improved Stability and Generalization Analysis of the Decentralized SGD
 Algorithm
Authors: Batiste Le Bars, Aur\'elien Bellet, Marc Tommasi
Categories: cs.LG stat.ML
\\
 This paper presents a new generalization error analysis for the Decentralized
Stochastic Gradient Descent (D-SGD) algorithm based on algorithmic stability.
The obtained results largely improve upon state-of-the-art results, and even
invalidate their claims that the communication graph has a detrimental effect
on generalization. For instance, we show that in convex settings, D-SGD has the
same generalization bounds as the classical SGD algorithm, no matter the choice
of graph. We exhibit that this counter-intuitive result comes from considering
the average of local parameters, which hides a final global averaging step
incompatible with the decentralized scenario. In light of this observation, we
advocate to analyze the supremum over local parameters and show that in this
case, the graph does have an impact on the generalization. Unlike prior
results, our analysis yields non-vacuous bounds even for non-connected graphs.
\\ ( https://arxiv.org/abs/2306.02939 ,  311kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02947
Date: Mon, 5 Jun 2023 15:11:59 GMT   (2744kb,D)

Title: Continual Learning with Pretrained Backbones by Tuning in the Input
 Space
Authors: Simone Marullo and Matteo Tiezzi and Marco Gori and Stefano Melacci
 and Tinne Tuytelaars
Categories: cs.LG cs.CV
\\
 The intrinsic difficulty in adapting deep learning models to non-stationary
environments limits the applicability of neural networks to real-world tasks.
This issue is critical in practical supervised learning settings, such as the
ones in which a pre-trained model computes projections toward a latent space
where different task predictors are sequentially learned over time. As a matter
of fact, incrementally fine-tuning the whole model to better adapt to new tasks
usually results in catastrophic forgetting, with decreasing performance over
the past experiences and losing valuable knowledge from the pre-training stage.
In this paper, we propose a novel strategy to make the fine-tuning procedure
more effective, by avoiding to update the pre-trained part of the network and
learning not only the usual classification head, but also a set of
newly-introduced learnable parameters that are responsible for transforming the
input data. This process allows the network to effectively leverage the
pre-training knowledge and find a good trade-off between plasticity and
stability with modest computational efforts, thus especially suitable for
on-the-edge settings. Our experiments on four image classification problems in
a continual learning setting confirm the quality of the proposed approach when
compared to several fine-tuning procedures and to popular continual learning
methods.
\\ ( https://arxiv.org/abs/2306.02947 ,  2744kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02957
Date: Mon, 5 Jun 2023 15:24:39 GMT   (3038kb,D)

Title: Complex Preferences for Different Convergent Priors in Discrete Graph
 Diffusion
Authors: Alex M. Tseng, Nathaniel Diamant, Tommaso Biancalani, Gabriele Scalia
Categories: cs.LG stat.ML
\\
 Diffusion models have achieved state-of-the-art performance in generating
many different kinds of data, including images, text, and videos. Despite their
success, there has been limited research on how the underlying diffusion
process and the final convergent prior can affect generative performance; this
research has also been limited to continuous data types and a score-based
diffusion framework. To fill this gap, we explore how different discrete
diffusion kernels (which converge to different prior distributions) affect the
performance of diffusion models for graphs. To this end, we developed a novel
formulation of a family of discrete diffusion kernels which are easily
adjustable to converge to different Bernoulli priors, and we study the effect
of these different kernels on generative performance. We show that the quality
of generated graphs is sensitive to the prior used, and that the optimal choice
cannot be explained by obvious statistics or metrics, which challenges the
intuitions which previous works have suggested.
\\ ( https://arxiv.org/abs/2306.02957 ,  3038kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02968
Date: Mon, 5 Jun 2023 15:31:18 GMT   (68kb,D)

Title: Time Interpret: a Unified Model Interpretability Library for Time Series
Authors: Joseph Enguehard
Categories: cs.LG cs.AI
Comments: 7 pages, 1 figure. Code available at
 https://github.com/josephenguehard/time_interpret
\\
 We introduce $\texttt{time_interpret}$, a library designed as an extension of
Captum, with a specific focus on temporal data. As such, this library
implements several feature attribution methods that can be used to explain
predictions made by any Pytorch model. $\texttt{time_interpret}$ also provides
several synthetic and real world time series datasets, various PyTorch models,
as well as a set of methods to evaluate feature attributions. Moreover, while
being primarily developed to explain predictions based on temporal data, some
of its components have a different application, including for instance methods
explaining predictions made by language models. In this paper, we give a
general introduction of this library. We also present several previously
unpublished feature attribution methods, which have been developed along with
$\texttt{time_interpret}$.
\\ ( https://arxiv.org/abs/2306.02968 ,  68kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02971
Date: Mon, 5 Jun 2023 15:35:00 GMT   (73kb,D)

Title: Online Learning with Feedback Graphs: The True Shape of Regret
Authors: Tom\'a\v{s} Koc\'ak and Alexandra Carpentier
Categories: cs.LG cs.IT math.IT math.ST stat.TH
\\
 Sequential learning with feedback graphs is a natural extension of the
multi-armed bandit problem where the problem is equipped with an underlying
graph structure that provides additional information - playing an action
reveals the losses of all the neighbors of the action. This problem was
introduced by \citet{mannor2011} and received considerable attention in recent
years. It is generally stated in the literature that the minimax regret rate
for this problem is of order $\sqrt{\alpha T}$, where $\alpha$ is the
independence number of the graph, and $T$ is the time horizon. However, this is
proven only when the number of rounds $T$ is larger than $\alpha^3$, which
poses a significant restriction for the usability of this result in large
graphs. In this paper, we define a new quantity $R^*$, called the \emph{problem
complexity}, and prove that the minimax regret is proportional to $R^*$ for any
graph and time horizon $T$. Introducing an intricate exploration strategy, we
define the \mainAlgorithm algorithm that achieves the minimax optimal regret
bound and becomes the first provably optimal algorithm for this setting, even
if $T$ is smaller than $\alpha^3$.
\\ ( https://arxiv.org/abs/2306.02971 ,  73kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02996
Date: Mon, 5 Jun 2023 16:06:39 GMT   (1387kb,D)

Title: Over-the-Air Federated Learning in Satellite systems
Authors: Edward Akito Carlos, Raphael Pinard, Mitra Hassani
Categories: cs.LG eess.IV
\\
 Federated learning in satellites offers several advantages. Firstly, it
ensures data privacy and security, as sensitive data remains on the satellites
and is not transmitted to a central location. This is particularly important
when dealing with sensitive or classified information. Secondly, federated
learning allows satellites to collectively learn from a diverse set of data
sources, benefiting from the distributed knowledge across the satellite
network. Lastly, the use of federated learning reduces the communication
bandwidth requirements between satellites and the central server, as only model
updates are exchanged instead of raw data. By leveraging federated learning,
satellites can collaborate and continuously improve their machine learning
models while preserving data privacy and minimizing communication overhead.
This enables the development of more intelligent and efficient satellite
systems for various applications, such as Earth observation, weather
forecasting, and space exploration.
\\ ( https://arxiv.org/abs/2306.02996 ,  1387kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03007
Date: Mon, 5 Jun 2023 16:19:07 GMT   (7762kb,D)

Title: Nonparametric Iterative Machine Teaching
Authors: Chen Zhang, Xiaofeng Cao, Weiyang Liu, Ivor Tsang, James Kwok
Categories: cs.LG cs.AI cs.CV
Comments: ICML 2023 (20 pages, 10 figures)
\\
 In this paper, we consider the problem of Iterative Machine Teaching (IMT),
where the teacher provides examples to the learner iteratively such that the
learner can achieve fast convergence to a target model. However, existing IMT
algorithms are solely based on parameterized families of target models. They
mainly focus on convergence in the parameter space, resulting in difficulty
when the target models are defined to be functions without dependency on
parameters. To address such a limitation, we study a more general task --
Nonparametric Iterative Machine Teaching (NIMT), which aims to teach
nonparametric target models to learners in an iterative fashion. Unlike
parametric IMT that merely operates in the parameter space, we cast NIMT as a
functional optimization problem in the function space. To solve it, we propose
both random and greedy functional teaching algorithms. We obtain the iterative
teaching dimension (ITD) of the random teaching algorithm under proper
assumptions, which serves as a uniform upper bound of ITD in NIMT. Further, the
greedy teaching algorithm has a significantly lower ITD, which reaches a
tighter upper bound of ITD in NIMT. Finally, we verify the correctness of our
theoretical findings with extensive experiments in nonparametric scenarios.
\\ ( https://arxiv.org/abs/2306.03007 ,  7762kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03010
Date: Mon, 5 Jun 2023 16:25:33 GMT   (6452kb,D)

Title: Interval Load Forecasting for Individual Households in the Presence of
 Electric Vehicle Charging
Authors: Raiden Skala, Mohamed Ahmed T. A. Elgalhud, Katarina Grolinger, and
 Syed Mir
Categories: cs.LG cs.AI
Journal-ref: Energies 2023, 16(10)
DOI: 10.3390/en16104093
\\
 The transition to Electric Vehicles (EV) in place of traditional internal
combustion engines is increasing societal demand for electricity. The ability
to integrate the additional demand from EV charging into forecasting
electricity demand is critical for maintaining the reliability of electricity
generation and distribution. Load forecasting studies typically exclude
households with home EV charging, focusing on offices, schools, and public
charging stations. Moreover, they provide point forecasts which do not offer
information about prediction uncertainty. Consequently, this paper proposes the
Long Short-Term Memory Bayesian Neural Networks (LSTM-BNNs) for household load
forecasting in presence of EV charging. The approach takes advantage of the
LSTM model to capture the time dependencies and uses the dropout layer with
Bayesian inference to generate prediction intervals. Results show that the
proposed LSTM-BNNs achieve accuracy similar to point forecasts with the
advantage of prediction intervals. Moreover, the impact of lockdowns related to
the COVID-19 pandemic on the load forecasting model is examined, and the
analysis shows that there is no major change in the model performance as, for
the considered households, the randomness of the EV charging outweighs the
change due to pandemic.
\\ ( https://arxiv.org/abs/2306.03010 ,  6452kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03018
Date: Mon, 5 Jun 2023 16:35:01 GMT   (2441kb,D)

Title: Quantification of Uncertainties in Deep Learning-based Environment
 Perception
Authors: Marco Braun, Moritz Luszek, Jan Siegemund, Kevin Kollek, Anton Kummert
Categories: cs.LG cs.AI
Comments: 2021 IEEE International Conference on Omni-Layer Intelligent Systems
 (COINS), Barcelona, Spain, 2021
DOI: 10.1109/COINS51742.2021.9524106
\\
 In this work, we introduce a novel Deep Learning-based method to perceive the
environment of a vehicle based on radar scans while accounting for
uncertainties in its predictions. The environment of the host vehicle is
segmented into equally sized grid cells which are classified individually.
Complementary to the segmentation output, our Deep Learning-based algorithm is
capable of differentiating uncertainties in its predictions as being related to
an inadequate model (epistemic uncertainty) or noisy data (aleatoric
uncertainty). To this end, weights are described as probability distributions
accounting for uncertainties in the model parameters. Distributions are learned
in a supervised fashion using gradient descent. We prove that uncertainties in
the model output correlate with the precision of its predictions. Compared to
previous concepts, we show superior performance of our approach to reliably
perceive the environment of a vehicle.
\\ ( https://arxiv.org/abs/2306.03018 ,  2441kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03042
Date: Mon, 5 Jun 2023 17:06:23 GMT   (1177kb,D)

Title: SERT: A Transfomer Based Model for Spatio-Temporal Sensor Data with
 Missing Values for Environmental Monitoring
Authors: Amin Shoari Nejad, Roc\'io Alaiz-Rodr\'iguez, Gerard D. McCarthy,
 Brian Kelleher, Anthony Grey, Andrew Parnell
Categories: cs.LG cs.AI
Comments: 11 pages, 7 figures
\\
 Environmental monitoring is crucial to our understanding of climate change,
biodiversity loss and pollution. The availability of large-scale
spatio-temporal data from sources such as sensors and satellites allows us to
develop sophisticated models for forecasting and understanding key drivers.
However, the data collected from sensors often contain missing values due to
faulty equipment or maintenance issues. The missing values rarely occur
simultaneously leading to data that are multivariate misaligned sparse time
series. We propose two models that are capable of performing multivariate
spatio-temporal forecasting while handling missing data naturally without the
need for imputation. The first model is a transformer-based model, which we
name SERT (Spatio-temporal Encoder Representations from Transformers). The
second is a simpler model named SST-ANN (Sparse Spatio-Temporal Artificial
Neural Network) which is capable of providing interpretable results. We conduct
extensive experiments on two different datasets for multivariate
spatio-temporal forecasting and show that our models have competitive or
superior performance to those at the state-of-the-art.
\\ ( https://arxiv.org/abs/2306.03042 ,  1177kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03052
Date: Mon, 5 Jun 2023 17:23:26 GMT   (1324kb,D)

Title: Forecasting Crude Oil Prices Using Reservoir Computing Models
Authors: Kaushal Kumar
Categories: cs.LG
Comments: 14 pages, 4 figures
\\
 Accurate crude oil price prediction is crucial for financial decision-making.
We propose a novel reservoir computing model for forecasting crude oil prices.
It outperforms popular deep learning methods in most scenarios, as demonstrated
through rigorous evaluation using daily closing price data from major stock
market indices. Our model's competitive advantage is further validated by
comparing it with recent deep-learning approaches. This study introduces
innovative reservoir computing models for predicting crude oil prices, with
practical implications for financial practitioners. By leveraging advanced
techniques, market participants can enhance decision-making and gain valuable
insights into crude oil market dynamics.
\\ ( https://arxiv.org/abs/2306.03052 ,  1324kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03065
Date: Mon, 5 Jun 2023 17:43:46 GMT   (6593kb,D)

Title: LibAUC: A Deep Learning Library for X-Risk Optimization
Authors: Zhuoning Yuan, Dixian Zhu, Zi-Hao Qiu, Gang Li, Xuanhui Wang, Tianbao
 Yang
Categories: cs.LG cs.AI math.OC stat.ML
Comments: Accepted by KDD2023
DOI: 10.1145/3580305.3599861
\\
 This paper introduces the award-winning deep learning (DL) library called
LibAUC for implementing state-of-the-art algorithms towards optimizing a family
of risk functions named X-risks. X-risks refer to a family of compositional
functions in which the loss function of each data point is defined in a way
that contrasts the data point with a large number of others. They have broad
applications in AI for solving classical and emerging problems, including but
not limited to classification for imbalanced data (CID), learning to rank
(LTR), and contrastive learning of representations (CLR). The motivation of
developing LibAUC is to address the convergence issues of existing libraries
for solving these problems. In particular, existing libraries may not converge
or require very large mini-batch sizes in order to attain good performance for
these problems, due to the usage of the standard mini-batch technique in the
empirical risk minimization (ERM) framework. Our library is for deep X-risk
optimization (DXO) that has achieved great success in solving a variety of
tasks for CID, LTR and CLR. The contributions of this paper include: (1) It
introduces a new mini-batch based pipeline for implementing DXO algorithms,
which differs from existing DL pipeline in the design of controlled data
samplers and dynamic mini-batch losses; (2) It provides extensive benchmarking
experiments for ablation studies and comparison with existing libraries. The
LibAUC library features scalable performance for millions of items to be
contrasted, faster and better convergence than existing libraries for
optimizing X-risks, seamless PyTorch deployment and versatile APIs for various
loss optimization. Our library is available to the open source community at
https://github.com/Optimization-AI/LibAUC, to facilitate further academic
research and industrial applications.
\\ ( https://arxiv.org/abs/2306.03065 ,  6593kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03072
Date: Mon, 5 Jun 2023 17:49:43 GMT   (11013kb,D)

Title: Explore to Generalize in Zero-Shot RL
Authors: Ev Zisselman, Itai Lavie, Daniel Soudry, Aviv Tamar
Categories: cs.LG
\\
 We study zero-shot generalization in reinforcement learning - optimizing a
policy on a set of training tasks such that it will perform well on a similar
but unseen test task. To mitigate overfitting, previous work explored different
notions of invariance to the task. However, on problems such as the ProcGen
Maze, an adequate solution that is invariant to the task visualization does not
exist, and therefore invariance-based approaches fail. Our insight is that
learning a policy that $\textit{explores}$ the domain effectively is harder to
memorize than a policy that maximizes reward for a specific task, and therefore
we expect such learned behavior to generalize well; we indeed demonstrate this
empirically on several domains that are difficult for invariance-based
approaches. Our $\textit{Explore to Generalize}$ algorithm (ExpGen) builds on
this insight: We train an additional ensemble of agents that optimize reward.
At test time, either the ensemble agrees on an action, and we generalize well,
or we take exploratory actions, which are guaranteed to generalize and drive us
to a novel part of the state space, where the ensemble may potentially agree
again. We show that our approach is the state-of-the-art on several tasks in
the ProcGen challenge that have so far eluded effective generalization. For
example, we demonstrate a success rate of $82\%$ on the Maze task and $74\%$ on
Heist with $200$ training levels.
\\ ( https://arxiv.org/abs/2306.03072 ,  11013kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03074
Date: Mon, 5 Jun 2023 17:50:29 GMT   (206kb)

Title: A General Perspective on Objectives of Reinforcement Learning
Authors: Long Yang
Categories: cs.LG
\\
 In this lecture, we present a general perspective on reinforcement learning
(RL) objectives, where we show three versions of objectives. The first version
is the standard definition of objective in RL literature. Then we extend the
standard definition to the $\lambda$-return version, which unifies the standard
definition of objective. Finally, we propose a general objective that unifies
the previous two versions. The last version provides a high level to understand
of RL's objective, where it shows a fundamental formulation that connects some
widely used RL techniques (e.g., TD$(\lambda)$ and GAE), and this objective can
be potentially applied to extensive RL algorithms.
\\ ( https://arxiv.org/abs/2306.03074 ,  206kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03076
Date: Mon, 5 Jun 2023 17:52:44 GMT   (779kb,D)

Title: Sensitivity-Aware Finetuning for Accuracy Recovery on Deep Learning
 Hardware
Authors: Lakshmi Nair and Darius Bunandar
Categories: cs.LG cs.AR
Comments: 7 pages, 2 figures
\\
 Existing methods to recover model accuracy on analog-digital hardware in the
presence of quantization and analog noise include noise-injection training.
However, it can be slow in practice, incurring high computational costs, even
when starting from pretrained models. We introduce the Sensitivity-Aware
Finetuning (SAFT) approach that identifies noise sensitive layers in a model,
and uses the information to freeze specific layers for noise-injection
training. Our results show that SAFT achieves comparable accuracy to
noise-injection training and is 2x to 8x faster.
\\ ( https://arxiv.org/abs/2306.03076 ,  779kb)
------------------------------------------------------------------------------
\\
arXiv:2306.01920
Date: Fri, 2 Jun 2023 21:22:27 GMT   (1833kb,D)

Title: Context-Aware Bayesian Network Actor-Critic Methods for Cooperative
 Multi-Agent Reinforcement Learning
Authors: Dingyang Chen, Qi Zhang
Categories: cs.MA cs.AI cs.GT cs.LG
\\
 Executing actions in a correlated manner is a common strategy for human
coordination that often leads to better cooperation, which is also potentially
beneficial for cooperative multi-agent reinforcement learning (MARL). However,
the recent success of MARL relies heavily on the convenient paradigm of purely
decentralized execution, where there is no action correlation among agents for
scalability considerations. In this work, we introduce a Bayesian network to
inaugurate correlations between agents' action selections in their joint
policy. Theoretically, we establish a theoretical justification for why action
dependencies are beneficial by deriving the multi-agent policy gradient formula
under such a Bayesian network joint policy and proving its global convergence
to Nash equilibria under tabular softmax policy parameterization in cooperative
Markov games. Further, by equipping existing MARL algorithms with a recent
method of differentiable directed acyclic graphs (DAGs), we develop practical
algorithms to learn the context-aware Bayesian network policies in scenarios
with partial observability and various difficulty. We also dynamically decrease
the sparsity of the learned DAG throughout the training process, which leads to
weakly or even purely independent policies for decentralized execution.
Empirical results on a range of MARL benchmarks show the benefits of our
approach.
\\ ( https://arxiv.org/abs/2306.01920 ,  1833kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02430
Date: Sun, 4 Jun 2023 18:26:25 GMT   (610kb,D)

Title: A Unified Framework for Factorizing Distributional Value Functions for
 Multi-Agent Reinforcement Learning
Authors: Wei-Fang Sun, Cheng-Kuang Lee, Simon See, and Chun-Yi Lee
Categories: cs.MA cs.LG
Comments: JMLR 2023. Extended version of arXiv:2102.07936
\\
 In fully cooperative multi-agent reinforcement learning (MARL) settings,
environments are highly stochastic due to the partial observability of each
agent and the continuously changing policies of other agents. To address the
above issues, we proposed a unified framework, called DFAC, for integrating
distributional RL with value function factorization methods. This framework
generalizes expected value function factorization methods to enable the
factorization of return distributions. To validate DFAC, we first demonstrate
its ability to factorize the value functions of a simple matrix game with
stochastic rewards. Then, we perform experiments on all Super Hard maps of the
StarCraft Multi-Agent Challenge and six self-designed Ultra Hard maps, showing
that DFAC is able to outperform a number of baselines.
\\ ( https://arxiv.org/abs/2306.02430 ,  610kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02766
Date: Mon, 5 Jun 2023 10:45:39 GMT   (809kb,D)

Title: Networked Communication for Decentralised Agents in Mean-Field Games
Authors: Patrick Benjamin and Alessandro Abate
Categories: cs.MA cs.AI cs.LG cs.SI cs.SY eess.SY
\\
 We introduce networked communication to the mean-field game framework. In
particular, we look at oracle-free settings where $N$ decentralised agents
learn along a single, non-episodic evolution path of the empirical system, such
as we may encounter for a large range of many-agent cooperation problems in the
real-world. We provide theoretical evidence that by spreading improved policies
through the network in a decentralised fashion, our sample guarantees are
upper-bounded by those of the purely independent-learning case. Moreover, we
show empirically that our networked method can give faster convergence in
practice, while removing the reliance on a centralised controller. We also
demonstrate that our decentralised communication architecture brings
significant benefits over both the centralised and independent alternatives in
terms of robustness and flexibility to unexpected learning failures and changes
in population size. For comparison purposes with our new architecture, we
modify recent algorithms for the centralised and independent cases to make
their practical convergence feasible: while contributing the first empirical
demonstrations of these algorithms in our setting of $N$ agents learning along
a single system evolution with only local state observability, we additionally
display the empirical benefits of our new, networked approach.
\\ ( https://arxiv.org/abs/2306.02766 ,  809kb)
------------------------------------------------------------------------------
\\
arXiv:2306.01741
Date: Wed, 10 May 2023 10:14:16 GMT   (733kb,D)

Title: GPT Models Meet Robotic Applications: Co-Speech Gesturing Chat System
Authors: Naoki Wake, Atsushi Kanehira, Kazuhiro Sasabuchi, Jun Takamatsu,
 Katsushi Ikeuchi
Categories: cs.RO
\\
 This technical paper introduces a chatting robot system that utilizes recent
advancements in large-scale language models (LLMs) such as GPT-3 and ChatGPT.
The system is integrated with a co-speech gesture generation system, which
selects appropriate gestures based on the conceptual meaning of speech. Our
motivation is to explore ways of utilizing the recent progress in LLMs for
practical robotic applications, which benefits the development of both chatbots
and LLMs. Specifically, it enables the development of highly responsive chatbot
systems by leveraging LLMs and adds visual effects to the user interface of
LLMs as an additional value. The source code for the system is available on
GitHub for our in-house robot
(https://github.com/microsoft/LabanotationSuite/tree/master/MSRAbotChatSimulation)
and GitHub for Toyota HSR
(https://github.com/microsoft/GPT-Enabled-HSR-CoSpeechGestures).
\\ ( https://arxiv.org/abs/2306.01741 ,  733kb)
------------------------------------------------------------------------------
\\
arXiv:2306.01748
Date: Thu, 18 May 2023 06:09:28 GMT   (1885kb)

Title: Bio-inspired Dual-auger Self-burrowing Robots in Granular Media
Authors: Md Ragib Shaharear
Categories: cs.RO
Comments: Master's thesis, 62 pages, 40 figures, ProQuest
Journal-ref: Order No. 30485358 Arizona State University, 2023 United States --
 ArizonaProQuest. 17 May 2023
\\
 It has been found that certain biological organisms, such as Erodium seeds
and Scincus scincus, are capable of effectively and efficiently burying
themselves in soil. Biological Organisms employ various locomotion modes,
including coiling and uncoiling motions, asymmetric body twisting, and
undulating movements that generate motion waves. The coiling-uncoiling motion
drives a seed awn to bury itself like a corkscrew, while sandfish skinks use
undulatory swimming, which can be thought of as a 2D version of helical motion.
Studying burrowing behavior aims to understand how animals navigate
underground, whether in their natural burrows or underground habitats, and to
implement this knowledge in solving geotechnical penetration problems.
Underground horizontal burrowing is challenging due to overcoming the
resistance of interaction forces of granular media to move forward. Inspired by
the burrowing behavior of seed-awn and sandfish skink, a horizontal
self-burrowing robot is developed. The robot is driven by two augers and
stabilized by a fin structure. The robot's burrowing behavior is studied in a
laboratory setting. It is found that rotation and propulsive motion along the
axis of the auger's helical shape significantly reduce granular media's
resistance against horizontal penetration by breaking kinematic symmetry or
granular media boundary. Additional thrusting and dragging tests were performed
to examine the propulsive and resistive forces and unify the observed burrowing
behaviors. The tests revealed that the rotation of an auger not only reduces
the resistive force and generates a propulsive force, which is influenced by
the auger geometry, rotational speed, and direction. As a result, the burrowing
behavior of the robot can be predicted using the geometry-rotation-force
relations.
\\ ( https://arxiv.org/abs/2306.01748 ,  1885kb)
------------------------------------------------------------------------------
\\
arXiv:2306.01780
Date: Tue, 30 May 2023 20:36:03 GMT   (645kb,D)

Title: Simulation of a first prototypical 3D solution for Indoor Localization
 based on Directed and Reflected Signals
Authors: Sneha Mohanty and Milan M\"uller and Christian Schindelhauer
Categories: cs.RO
Comments: 16 pages
\\
 We introduce a solution for a specific case of Indoor Localization which
involves a directed signal, a reflected signal from the wall and the time
difference between them. This solution includes robust localization with a
given wall, finding the right wall from a group of walls, obtaining the
reflecting wall from measurements, using averaging techniques for improving
measurements with errors and successfully grouping measurements regarding
reflecting walls. It also includes performing self-calibration by computation
of wall distance and direction introducing algorithms such as All pairs,
Disjoint pairs and Overlapping pairs and clustering walls based on Inversion
and Gnomonic Projection. Several of these algorithms are then compared in order
to ameliorate the effects of measurement errors.
\\ ( https://arxiv.org/abs/2306.01780 ,  645kb)
------------------------------------------------------------------------------
\\
arXiv:2306.01839
Date: Fri, 2 Jun 2023 18:00:33 GMT   (6431kb,D)

Title: Efficient Multi-Task and Transfer Reinforcement Learning with
 Parameter-Compositional Framework
Authors: Lingfeng Sun, Haichao Zhang, Wei Xu, Masayoshi Tomizuka
Categories: cs.RO cs.LG
Comments: 8 pages, accepted by IEEE Robotics and Automation Letters (RA-L)
\\
 In this work, we investigate the potential of improving multi-task training
and also leveraging it for transferring in the reinforcement learning setting.
We identify several challenges towards this goal and propose a transferring
approach with a parameter-compositional formulation. We investigate ways to
improve the training of multi-task reinforcement learning which serves as the
foundation for transferring. Then we conduct a number of transferring
experiments on various manipulation tasks. Experimental results demonstrate
that the proposed approach can have improved performance in the multi-task
training stage, and further show effective transferring in terms of both sample
efficiency and performance.
\\ ( https://arxiv.org/abs/2306.01839 ,  6431kb)
------------------------------------------------------------------------------
\\
arXiv:2306.01871
Date: Fri, 2 Jun 2023 18:59:42 GMT   (3383kb,D)

Title: Optimal Control of Connected Automated Vehicles with Event-Triggered
 Control Barrier Functions: a Test Bed for Safe Optimal Merging
Authors: Ehsan Sabouni, H.M.Sabbir Ahmad, Wei Xiao, Christos G. Cassandras and
 Wenchao Li
Categories: cs.RO
Comments: arXiv admin note: substantial text overlap with arXiv:2203.12089,
 arXiv:2209.13053
\\
 We address the problem of controlling Connected and Automated Vehicles (CAVs)
in conflict areas of a traffic network subject to hard safety constraints. It
has been shown that such problems can be solved through a combination of
tractable optimal control problems and Control Barrier Functions (CBFs) that
guarantee the satisfaction of all constraints. These solutions can be reduced
to a sequence of Quadratic Programs (QPs) which are efficiently solved on line
over discrete time steps. However, guaranteeing the feasibility of the
CBF-based QP method within each discretized time interval requires the careful
selection of time steps which need to be sufficiently small. This creates
computational requirements and communication rates between agents which may
hinder the controller's application to real CAVs. In this paper, we overcome
this limitation by adopting an event-triggered approach for CAVs in a conflict
area such that the next QP is triggered by properly defined events with a
safety guarantee. We present a laboratory-scale test bed we have developed to
emulate merging roadways using mobile robots as CAVs which can be used to
demonstrate how the event-triggered scheme is computationally efficient and can
handle measurement uncertainties and noise compared to time-driven control
while guaranteeing safety.
\\ ( https://arxiv.org/abs/2306.01871 ,  3383kb)
------------------------------------------------------------------------------
\\
arXiv:2306.01874
Date: Fri, 2 Jun 2023 19:07:52 GMT   (6575kb,D)

Title: SACSoN: Scalable Autonomous Data Collection for Social Navigation
Authors: Noriaki Hirose, Dhruv Shah, Ajay Sridhar, Sergey Levine
Categories: cs.RO cs.CV cs.LG
Comments: 9 pages, 12 figures, 4 tables
\\
 Machine learning provides a powerful tool for building socially compliant
robotic systems that go beyond simple predictive models of human behavior. By
observing and understanding human interactions from past experiences, learning
can enable effective social navigation behaviors directly from data. However,
collecting navigation data in human-occupied environments may require
teleoperation or continuous monitoring, making the process prohibitively
expensive to scale. In this paper, we present a scalable data collection system
for vision-based navigation, SACSoN, that can autonomously navigate around
pedestrians in challenging real-world environments while encouraging rich
interactions. SACSoN uses visual observations to observe and react to humans in
its vicinity. It couples this visual understanding with continual learning and
an autonomous collision recovery system that limits the involvement of a human
operator, allowing for better dataset scaling. We use a this system to collect
the SACSoN dataset, the largest-of-its-kind visual navigation dataset of
autonomous robots operating in human-occupied spaces, spanning over 75 hours
and 4000 rich interactions with humans. Our experiments show that collecting
data with a novel objective that encourages interactions, leads to significant
improvements in downstream tasks such as inferring pedestrian dynamics and
learning socially compliant navigation behaviors. We make videos of our
autonomous data collection system and the SACSoN dataset publicly available on
our project page.
\\ ( https://arxiv.org/abs/2306.01874 ,  6575kb)
------------------------------------------------------------------------------
\\
arXiv:2306.01881
Date: Fri, 2 Jun 2023 19:23:51 GMT   (1147kb)

Title: Hardware-in-the-Loop and Road Testing of RLVW and GLOSA Connected
 Vehicle Applications
Authors: Ozgenur Kavas-Torris, Mustafa Ridvan Cantas, Sukru Yaren Gelbal, and
 Levent Guvenc
Categories: cs.RO cs.SY eess.SY
\\
 This paper presents an evaluation of two different Vehicle to Infrastructure
(V2I) applications, namely Red Light Violation Warning (RLVW) and Green Light
Optimized Speed Advisory (GLOSA). The evaluation method is to first develop and
use Hardware-in-the-Loop (HIL) simulator testing, followed by extension of the
HIL testing to road testing using an experimental connected vehicle. The HIL
simulator used in the testing is a state-of-the-art simulator that consists of
the same hardware like the road side unit and traffic cabinet as is used in
real intersections and allows testing of numerous different traffic and
intersection geometry and timing scenarios realistically. First, the RLVW V2I
algorithm is tested in the HIL simulator and then implemented in an
On-Board-Unit (OBU) in our experimental vehicle and tested at real world
intersections. This same approach of HIL testing followed by testing in real
intersections using our experimental vehicle is later extended to the GLOSA
application. The GLOSA application that is tested in this paper has both an
optimal speed advisory for passing at the green light and also includes a red
light violation warning system. The paper presents the HIL and experimental
vehicle evaluation systems, information about RLVW and GLOSA and HIL simulation
and road testing results and their interpretations.
\\ ( https://arxiv.org/abs/2306.01881 ,  1147kb)
------------------------------------------------------------------------------
\\
arXiv:2306.01889
Date: Fri, 2 Jun 2023 19:50:38 GMT   (1520kb)

Title: Cooperative Collision Avoidance in a Connected Vehicle Environment
Authors: Sukru Yaren Gelbal, Sheng Zhu, Gokul Arvind Anantharaman, Bilin Aksun
 Guvenc, and Levent Guvenc
Categories: cs.RO
\\
 Connected vehicle (CV) technology is among the most heavily researched areas
in both the academia and industry. The vehicle to vehicle (V2V), vehicle to
infrastructure (V2I) and vehicle to pedestrian (V2P) communication capabilities
enable critical situational awareness. In some cases, these vehicle
communication safety capabilities can overcome the shortcomings of other sensor
safety capabilities because of external conditions such as 'No Line of Sight'
(NLOS) or very harsh weather conditions. Connected vehicles will help cities
and states reduce traffic congestion, improve fuel efficiency and improve the
safety of the vehicles and pedestrians. On the road, cars will be able to
communicate with one another, automatically transmitting data such as speed,
position, and direction, and send alerts to each other if a crash seems
imminent. The main focus of this paper is the implementation of Cooperative
Collision Avoidance (CCA) for connected vehicles. It leverages the Vehicle to
Everything (V2X) communication technology to create a real-time implementable
collision avoidance algorithm along with decision-making for a vehicle that
communicates with other vehicles. Four distinct collision risk environments are
simulated on a cost effective Connected Autonomous Vehicle (CAV) Hardware in
the Loop (HIL) simulator to test the overall algorithm in real-time with real
electronic control and communication hardware.
\\ ( https://arxiv.org/abs/2306.01889 ,  1520kb)
------------------------------------------------------------------------------
\\
arXiv:2306.01898
Date: Fri, 2 Jun 2023 20:05:26 GMT   (271kb,D)

Title: Exploring the Boundaries: Thorough Software Testing for Safety-Critical
 Driving Scenarios Based on Kinematics in the Context of Autonomous Driving
Authors: Nico Schick
Categories: cs.RO
\\
 This scientific publication focuses on the efficient application of boundary
value analysis in the testing of corner cases for kinematic-based
safety-critical driving scenarios within the domain of autonomous driving.
Corner cases, which represent infrequent and crucial situations, present
notable obstacles to the reliability and safety of autonomous driving systems.
This paper emphasizes the significance of employing boundary value analysis, a
systematic technique for identifying critical boundaries and values, to achieve
comprehensive testing coverage. By identifying and testing extreme and boundary
conditions, such as minimum distances, this publication aims to improve the
performance and robustness of autonomous driving systems in safety-critical
scenarios. The insights and methodologies presented in this paper can serve as
a guide for researchers, developers, and regulators in effectively addressing
the challenges posed by corner cases and ensuring the reliability and safety of
autonomous driving systems under real-world driving conditions.
\\ ( https://arxiv.org/abs/2306.01898 ,  271kb)
------------------------------------------------------------------------------
\\
arXiv:2306.01899
Date: Fri, 2 Jun 2023 20:09:55 GMT   (1786kb)

Title: Discrete-time Robust PD Controlled System with DOB/CDOB Compensation for
 High Speed Autonomous Vehicle Path Following
Authors: Haoan Wang, Levent Guvenc
Categories: cs.RO
\\
 Autonomous vehicle path following performance is one of significant
consideration. This paper presents discrete time design of robust PD controlled
system with disturbance observer (DOB) and communication disturbance observer
(CDOB) compensation to enhance autonomous vehicle path following performance.
Although always implemented on digital devices, DOB and CDOB structure are
usually designed in continuous time in the literature and also in our previous
work. However, it requires high sampling rate for continuous-time design block
diagram to automatically convert to corresponding discrete-time controller
using rapid controller prototyping systems. In this paper, direct discrete time
design is carried out. Digital PD feedback controller is designed based on the
nominal plant using the proposed parameter space approach. Zero order hold
method is applied to discretize the nominal plant, DOB and CDOB structure in
continuous domain. Discrete time DOB is embedded into the steering to path
following error loop for model regulation in the presence of uncertainty in
vehicle parameters such as vehicle mass, vehicle speed and road-tire friction
coefficient and rejecting external disturbance like crosswind force. On the
other hand, time delay from CAN bus based sensor and actuator command
interfaces results in degradation of system performance since large negative
phase angles are added to the plant frequency response. Discrete time CDOB
compensated control system can be used for time delay compensation where the
accurate knowledge of delay time value is not necessary. A validated model of
our lab Ford Fusion hybrid automated driving research vehicle is used for the
simulation analysis while the vehicle is driving at high speed. Simulation
results successfully demonstrate the improvement of autonomous vehicle path
following performance with the proposed discrete time DOB and CDOB structure.
\\ ( https://arxiv.org/abs/2306.01899 ,  1786kb)
------------------------------------------------------------------------------
\\
arXiv:2306.01906
Date: Fri, 2 Jun 2023 20:31:33 GMT   (3795kb,D)

Title: Synaptic motor adaptation: A three-factor learning rule for adaptive
 robotic control in spiking neural networks
Authors: Samuel Schmidgall, Joe Hays
Categories: cs.RO cs.AI cs.LG cs.NE
\\
 Legged robots operating in real-world environments must possess the ability
to rapidly adapt to unexpected conditions, such as changing terrains and
varying payloads. This paper introduces the Synaptic Motor Adaptation (SMA)
algorithm, a novel approach to achieving real-time online adaptation in
quadruped robots through the utilization of neuroscience-derived rules of
synaptic plasticity with three-factor learning. To facilitate rapid adaptation,
we meta-optimize a three-factor learning rule via gradient descent to adapt to
uncertainty by approximating an embedding produced by privileged information
using only locally accessible onboard sensing data. Our algorithm performs
similarly to state-of-the-art motor adaptation algorithms and presents a clear
path toward achieving adaptive robotics with neuromorphic hardware.
\\ ( https://arxiv.org/abs/2306.01906 ,  3795kb)
------------------------------------------------------------------------------
\\
arXiv:2306.01934
Date: Fri, 2 Jun 2023 22:28:04 GMT   (18696kb,D)

Title: Optimal Control for Articulated Soft Robots
Authors: Saroj Prasad Chhatoi, Michele Pierallini, Franco Angelini, Carlos
 Mastalli, Manolo Garabini
Categories: cs.RO
Comments: 14 pages, 15 figures, IEEE Transaction on Robotics (TRO)
\\
 Soft robots can execute tasks with safer interactions. However, control
techniques that can effectively exploit the systems' capabilities are still
missing. Differential dynamic programming (DDP) has emerged as a promising tool
for achieving highly dynamic tasks. But most of the literature deals with
applying DDP to articulated soft robots by using numerical differentiation, in
addition to using pure feed-forward control to perform explosive tasks.
Further, underactuated compliant robots are known to be difficult to control
and the use of DDP-based algorithms to control them is not yet addressed. We
propose an efficient DDP-based algorithm for trajectory optimization of
articulated soft robots that can optimize the state trajectory, input torques,
and stiffness profile. We provide an efficient method to compute the forward
dynamics and the analytical derivatives of series elastic actuators
(SEA)/variable stiffness actuators (VSA) and underactuated compliant robots. We
present a state-feedback controller that uses locally optimal feedback policies
obtained from DDP. We show through simulations and experiments that the use of
feedback is crucial in improving the performance and stabilization properties
of various tasks. We also show that the proposed method can be used to plan and
control underactuated compliant robots, with varying degrees of underactuation
effectively.
\\ ( https://arxiv.org/abs/2306.01934 ,  18696kb)
------------------------------------------------------------------------------
\\
arXiv:2306.01980
Date: Sat, 3 Jun 2023 02:23:04 GMT   (15554kb,D)

Title: Milestones in Autonomous Driving and Intelligent Vehicles Part II:
 Perception and Planning
Authors: Long Chen, Siyu Teng, Bai Li, Xiaoxiang Na, Yuchen Li, Zixuan Li,
 Jinjun Wang, Dongpu Cao, Nanning Zheng, and Fei-Yue Wang
Categories: cs.RO cs.AI
Comments: 17pages, 6figures. IEEE Transactions on Systems, Man, and
 Cybernetics: Systems
DOI: 10.1109/TSMC.2023.3283021.
\\
 Growing interest in autonomous driving (AD) and intelligent vehicles (IVs) is
fueled by their promise for enhanced safety, efficiency, and economic benefits.
While previous surveys have captured progress in this field, a comprehensive
and forward-looking summary is needed. Our work fills this gap through three
distinct articles. The first part, a "Survey of Surveys" (SoS), outlines the
history, surveys, ethics, and future directions of AD and IV technologies. The
second part, "Milestones in Autonomous Driving and Intelligent Vehicles Part I:
Control, Computing System Design, Communication, HD Map, Testing, and Human
Behaviors" delves into the development of control, computing system,
communication, HD map, testing, and human behaviors in IVs. This part, the
third part, reviews perception and planning in the context of IVs. Aiming to
provide a comprehensive overview of the latest advancements in AD and IVs, this
work caters to both newcomers and seasoned researchers. By integrating the SoS
and Part I, we offer unique insights and strive to serve as a bridge between
past achievements and future possibilities in this dynamic field.
\\ ( https://arxiv.org/abs/2306.01980 ,  15554kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02167
Date: Sat, 3 Jun 2023 18:09:44 GMT   (12398kb,D)

Title: The effects of increasing velocity on the tractive performance of
 planetary rovers
Authors: David Rodr\'iguez-Mart\'inez, Fabian Buse, Michel Van Winnendael,
 Kazuya Yoshida
Categories: cs.RO astro-ph.EP astro-ph.IM
Comments: 15th International Society for Terrain Vehicle Systems (ISTVS)
 Conference, Prague, Czech Republic, 2019
\\
 An emerging paradigm is being embraced in the conceptualization of future
planetary exploration missions. Ambitious objectives and increasingly demanding
mission constraints stress the importance associated with faster surface
mobility. Driving speeds approaching or surpassing 1 m/s have been rarely used
and their effect on performance is today unclear. This study presents
experimental evidence and preliminary observations on the impact that
increasing velocity has on the tractive performance of planetary rovers.
Single-wheel driving tests were conducted using two different metallic,
grousered wheels-one rigid and one flexible-over two different soils, olivine
sand and CaCO3-based silty soil. Experiments were conducted at speeds between
0.01-1 m/s throughout an ample range of slip ratios (5-90%). Three performance
metrics were evaluated: drawbar pull coefficient, wheel sinkage, and tractive
efficiency. Results showed similar data trends among all the cases
investigated. Drawbar pull and tractive efficiency considerably decreased for
speeds beyond 0.2 m/s. Wheel sinkage, unlike what published evidence suggested,
increased with increasing velocities. The flexible wheel performed the best at
1m/s, exhibiting 2 times higher drawbar pull and efficiency with 18% lower
sinkage under low slip conditions. Although similar data trends were obtained,
a different wheel-soil interactive behavior was observed when driving over the
different soils. Overall, despite the performance reduction experienced at
higher velocities, a speed in the range of 0.2-0.3 m/s would enable 5-10 times
faster traverses, compared to current rovers driving capability, while only
diminishing drawbar pull and efficiency by 7%. The measurements collected and
the analysis presented here lay the groundwork for initial stages in the
development of new locomotion subsystems for planetary surface exploration. At
the same time...
\\ ( https://arxiv.org/abs/2306.02167 ,  12398kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02261
Date: Sun, 4 Jun 2023 04:55:02 GMT   (14013kb,D)

Title: Online estimation of the hand-eye transformation from surgical scenes
Authors: Krittin Pachtrachai, Francisco Vasconcelos, and Danail Stoyanov
Categories: cs.RO cs.LG
Comments: 6 pages, 4 main figures
\\
 Hand-eye calibration algorithms are mature and provide accurate
transformation estimations for an effective camera-robot link but rely on a
sufficiently wide range of calibration data to avoid errors and degenerate
configurations. To solve the hand-eye problem in robotic-assisted minimally
invasive surgery and also simplify the calibration procedure by using neural
network method cooporating with the new objective function. We present a neural
network-based solution that estimates the transformation from a sequence of
images and kinematic data which significantly simplifies the calibration
procedure. The network utilises the long short-term memory architecture to
extract temporal information from the data and solve the hand-eye problem. The
objective function is derived from the linear combination of remote centre of
motion constraint, the re-projection error and its derivative to induce a small
change in the hand-eye transformation. The method is validated with the data
from da Vinci Si and the result shows that the estimated hand-eye matrix is
able to re-project the end-effector from the robot coordinate to the camera
coordinate within 10 to 20 pixels of accuracy in both testing dataset. The
calibration performance is also superior to the previous neural network-based
hand-eye method. The proposed algorithm shows that the calibration procedure
can be simplified by using deep learning techniques and the performance is
improved by the assumption of non-static hand-eye transformations.
\\ ( https://arxiv.org/abs/2306.02261 ,  14013kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02393
Date: Sun, 4 Jun 2023 16:05:26 GMT   (7900kb,D)

Title: Accessible Robot Control in Mixed Reality
Authors: Ganlin Zhang, Deheng Zhang, Longteng Duan, Guo Han
Categories: cs.RO cs.CV
Comments: Course Project of Mixed Reality at ETH Zurich
\\
 A novel method to control the Spot robot of Boston Dynamics by Hololens 2 is
proposed. This method is mainly designed for people with physical disabilities,
users can control the robot's movement and robot arm without using their hands.
The eye gaze tracking and head motion tracking technologies of Hololens 2 are
utilized for sending control commands. The movement of the robot would follow
the eye gaze and the robot arm would mimic the pose of the user's head. Through
our experiment, our method is comparable with the traditional control method by
joystick in both time efficiency and user experience. Demo can be found on our
project webpage: https://zhangganlin.github.io/Holo-Spot-Page/index.html
\\ ( https://arxiv.org/abs/2306.02393 ,  7900kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02413
Date: Sun, 4 Jun 2023 17:14:49 GMT   (24585kb,D)

Title: Evaluating Continual Learning on a Home Robot
Authors: Sam Powers, Abhinav Gupta, Chris Paxton
Categories: cs.RO cs.AI
\\
 Robots in home environments need to be able to learn new skills continuously
as data becomes available, becoming ever more capable over time while using as
little real-world data as possible. However, traditional robot learning
approaches typically assume large amounts of iid data, which is inconsistent
with this goal. In contrast, continual learning methods like CLEAR and SANE
allow autonomous agents to learn off of a stream of non-iid samples; they,
however, have not previously been demonstrated on real robotics platforms. In
this work, we show how continual learning methods can be adapted for use on a
real, low-cost home robot, and in particular look at the case where we have
extremely small numbers of examples, in a task-id-free setting. Specifically,
we propose SANER, a method for continuously learning a library of skills, and
ABIP (Attention-Based Interaction Policies) as the backbone to support it. We
learn four sequential kitchen tasks on a low-cost home robot, using only a
handful of demonstrations per task.
\\ ( https://arxiv.org/abs/2306.02413 ,  24585kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02437
Date: Sun, 4 Jun 2023 18:48:32 GMT   (16705kb,D)

Title: Data Quality in Imitation Learning
Authors: Suneel Belkhale, Yuchen Cui, Dorsa Sadigh
Categories: cs.RO cs.LG
\\
 In supervised learning, the question of data quality and curation has been
over-shadowed in recent years by increasingly more powerful and expressive
models that can ingest internet-scale data. However, in offline learning for
robotics, we simply lack internet scale data, and so high quality datasets are
a necessity. This is especially true in imitation learning (IL), a sample
efficient paradigm for robot learning using expert demonstrations. Policies
learned through IL suffer from state distribution shift at test time due to
compounding errors in action prediction, which leads to unseen states that the
policy cannot recover from. Instead of designing new algorithms to address
distribution shift, an alternative perspective is to develop new ways of
assessing and curating datasets. There is growing evidence that the same IL
algorithms can have substantially different performance across different
datasets. This calls for a formalism for defining metrics of "data quality"
that can further be leveraged for data curation. In this work, we take the
first step toward formalizing data quality for imitation learning through the
lens of distribution shift: a high quality dataset encourages the policy to
stay in distribution at test time. We propose two fundamental properties that
shape the quality of a dataset: i) action divergence: the mismatch between the
expert and learned policy at certain states; and ii) transition diversity: the
noise present in the system for a given state and action. We investigate the
combined effect of these two key properties in imitation learning
theoretically, and we empirically analyze models trained on a variety of
different data sources. We show that state diversity is not always beneficial,
and we demonstrate how action divergence and transition diversity interact in
practice.
\\ ( https://arxiv.org/abs/2306.02437 ,  16705kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02454
Date: Sun, 4 Jun 2023 20:10:39 GMT   (353kb,D)

Title: Ergonomic Collaboration between Humans and Robots: An Energy-Aware
 Signal Temporal Logic Perspective
Authors: Giuseppe Silano, Amr Afifi, Martin Saska, Antonio Franchi
Categories: cs.RO
Comments: 2 pages, 2 figures, Accepted for presentation to the "Energy
 Efficient Aerial Robotic Systems" Workshop at ICRA'23, ExCeL, London, UK
\\
 This paper presents a method for designing energy-aware collaboration tasks
between humans and robots, and generating corresponding trajectories to carry
out those tasks. The method involves using high-level specifications expressed
as Signal Temporal Logic (STL) specifications to automatically synthesize task
assignments and trajectories. The focus is on a specific task where a
Multi-Rotor Aerial Vehicle (MRAV) performs object handovers in a power line
setting. The motion planner takes into account constraints such as payload
capacity and refilling, while ensuring that the generated trajectories are
feasible. The approach also allows users to specify robot behaviors that
prioritize human comfort, including ergonomics and user preferences. The method
is validated through numerical analyses in MATLAB and realistic Gazebo
simulations in a mock-up scenario.
\\ ( https://arxiv.org/abs/2306.02454 ,  353kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02524
Date: Mon, 5 Jun 2023 01:18:38 GMT   (1556kb,D)

Title: Kinodynamic FMT* with Dimensionality Reduction Heuristics and Neural
 Network Controllers
Authors: Dongliang Zheng and Panagiotis Tsiotras
Categories: cs.RO
\\
 This paper proposes a new sampling-based kinodynamic motion planning
algorithm, called FMT*PFF, for nonlinear systems. It exploits the novel idea of
dimensionality reduction using partial-final-state-free (PFF) optimal
controllers.With the proposed dimensionality reduction heuristic, the search
space is restricted within a subspace, thus faster convergence is achieved
compared to a regular kinodynamic FMT*. The dimensionality reduction heuristic
can be viewed as a sampling strategy and asymptotic optimality is preserved
when combined with uniform full-state sampling. Another feature of FMT*PFF is
the ability to deal with a steering function with inexact steering, which is
vital when using learning-based steering functions. Learning-based methods
allow us to solve the steering problem for nonlinear systems efficiently.
However, learning-based methods often fail to reach the exact goal state. For
nonlinear systems, we train a neural network controller using supervised
learning to generate the steering commands. We show that FMT*PFF with a
learning-based steering function is efficient and generates dynamically
feasible motion plans. We compare our algorithm with previous algorithms and
show superior performance in various simulations.
\\ ( https://arxiv.org/abs/2306.02524 ,  1556kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02551
Date: Mon, 5 Jun 2023 02:55:17 GMT   (866kb,D)

Title: Conformal Predictive Safety Filter for RL Controllers in Dynamic
 Environments
Authors: Kegan J. Strawn, Nora Ayanian and Lars Lindemann
Categories: cs.RO
\\
 The interest in using reinforcement learning (RL) controllers in
safety-critical applications such as robot navigation around pedestrians
motivates the development of additional safety mechanisms. Running RL-enabled
systems among uncertain dynamic agents may result in high counts of collisions
and failures to reach the goal. The system could be safer if the pre-trained RL
policy was uncertainty-informed. For that reason, we propose conformal
predictive safety filters that: 1) predict the other agents' trajectories, 2)
use statistical techniques to provide uncertainty intervals around these
predictions, and 3) learn an additional safety filter that closely follows the
RL controller but avoids the uncertainty intervals. We use conformal prediction
to learn uncertainty-informed predictive safety filters, which make no
assumptions about the agents' distribution. The framework is modular and
outperforms the existing controllers in simulation. We demonstrate our approach
with multiple experiments in a collision avoidance gym environment and show
that our approach minimizes the number of collisions without making
overly-conservative predictions.
\\ ( https://arxiv.org/abs/2306.02551 ,  866kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02586
Date: Mon, 5 Jun 2023 04:26:16 GMT   (34kb,D)

Title: Internet of Things Meets Robotics: A Survey of Cloud-based Robots
Authors: Chrisantus Eze
Categories: cs.RO cs.NI
\\
 This work presents a survey of existing literature on the fusion of the
Internet of Things (IoT) with robotics and explores the integration of these
technologies for the development of the Internet of Robotics Things (IoRT). The
survey focuses on the applications of IoRT in healthcare and agriculture, while
also addressing key concerns regarding the adoption of IoT and robotics.
Additionally, an on-line survey was conducted to examine how companies utilize
IoT technology in their organizations. The findings highlight the benefits of
IoT in improving customer experience, reducing costs, and accelerating product
development. However, concerns regarding unauthorized access, data breaches,
and privacy need to be addressed for successful IoT deployment. Organizations
must prioritize protecting users and their data while harnessing the potential
of IoT.
\\ ( https://arxiv.org/abs/2306.02586 ,  34kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02631
Date: Mon, 5 Jun 2023 06:59:42 GMT   (14992kb,D)

Title: Bridging the Domain Gap between Synthetic and Real-World Data for
 Autonomous Driving
Authors: Xiangyu Bai, Yedi Luo, Le Jiang, Aniket Gupta, Pushyami Kaveti,
 Hanumant Singh, and Sarah Ostadabbas
Categories: cs.RO
\\
 Modern autonomous systems require extensive testing to ensure reliability and
build trust in ground vehicles. However, testing these systems in the
real-world is challenging due to the lack of large and diverse datasets,
especially in edge cases. Therefore, simulations are necessary for their
development and evaluation. However, existing open-source simulators often
exhibit a significant gap between synthetic and real-world domains, leading to
deteriorated mobility performance and reduced platform reliability when using
simulation data. To address this issue, our Scoping Autonomous Vehicle
Simulation (SAVeS) platform benchmarks the performance of simulated
environments for autonomous ground vehicle testing between synthetic and
real-world domains. Our platform aims to quantify the domain gap and enable
researchers to develop and test autonomous systems in a controlled environment.
Additionally, we propose using domain adaptation technologies to address the
domain gap between synthetic and real-world data with our SAVeS$^+$ extension.
Our results demonstrate that SAVeS$^+$ is effective in helping to close the gap
between synthetic and real-world domains and yields comparable performance for
models trained with processed synthetic datasets to those trained on real-world
datasets of same scale. This paper highlights our efforts to quantify and
address the domain gap between synthetic and real-world data for autonomy
simulation. By enabling researchers to develop and test autonomous systems in a
controlled environment, we hope to bring autonomy simulation one step closer to
realization.
\\ ( https://arxiv.org/abs/2306.02631 ,  14992kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02632
Date: Mon, 5 Jun 2023 07:04:45 GMT   (5303kb,D)

Title: Music Mode: Transforming Robot Movement into Music Increases Likability
 and Perceived Intelligence
Authors: Catie Cuan, Emre Fisher, Allison Okamura, and Tom Engbersen
Categories: cs.RO
\\
 As robots enter everyday spaces like offices, the sounds they create affect
how they are perceived. We present "Music Mode", a novel mapping between a
robot's joint motions and sounds, programmed by artists and engineers to make
the robot generate music as it moves. Two experiments were designed to
characterize the effect of this musical augmentation on human users. In the
first experiment, a robot performed three tasks while playing three different
sound mappings. Results showed that participants observing the robot perceived
it as more safe, animate, intelligent, anthropomorphic, and likable when
playing the Music Mode Orchestral software. To test whether the results of the
first experiment were due to the Music Mode algorithm, rather than music alone,
we conducted a second experiment. Here the robot performed the same three
tasks, while a participant observed via video, but the Orchestral music was
either linked to its movement or random. Participants rated the robots as more
intelligent when the music was linked to the movement. Robots using Music Mode
logged approximately two hundred hours of operation while navigating, wiping
tables, and sorting trash, and bystander comments made during this operating
time served as an embedded case study. The contributions are: (1) an
interdisciplinary choreographic, musical, and coding design process to develop
a real-world robot sound feature, (2) a technical implementation for
movement-based sound generation, and (3) two experiments and an embedded case
study of robots running this feature during daily work activities that resulted
in increased likeability and perceived intelligence of the robot.
\\ ( https://arxiv.org/abs/2306.02632 ,  5303kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02659
Date: Mon, 5 Jun 2023 07:48:28 GMT   (4603kb,D)

Title: Hybrid Trajectory Optimization for Autonomous Terrain Traversal of
 Articulated Tracked Robots
Authors: Zhengzhe Xu, Yanbo Chen, Zhuozhu Jian, Xueqian Wang, Bin Liang
Categories: cs.RO
Comments: Submitted to IEEE Robotics and Automation Letters (RA-L)
\\
 Autonomous terrain traversal of articulated tracked robots can reduce
operator cognitive load to enhance task efficiency and facilitate extensive
deployment. We present a novel hybrid trajectory optimization method aimed at
generating smooth, stable, and efficient traversal motions. To achieve this, we
develop a planar robot-terrain interaction model and partition the robot's
motion into hybrid modes of driving and traversing. By using a generalized
coordinate description, the configuration space dimension is reduced, which
provides real-time planning capability. The hybrid trajectory optimization is
transcribed into a nonlinear programming problem and solved in a
receding-horizon planning fashion. Mode switching is facilitated by associating
optimized motion durations with a predefined traversal sequence. A
multi-objective cost function is formulated to further improve the traversal
performance. Additionally, map sampling, terrain simplification, and tracking
controller modules are integrated into the autonomous terrain traversal system.
Our approach is validated in simulation and real-world experiments with the
Searcher robotic platform, effectively achieving smooth and stable motion with
high time and energy efficiency compared to expert operator control.
\\ ( https://arxiv.org/abs/2306.02659 ,  4603kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02694
Date: Mon, 5 Jun 2023 08:36:30 GMT   (634kb,D)

Title: Social Robots As Companions for Lonely Hearts: The Role of
 Anthropomorphism and Robot Appearances
Authors: Yoonwon Jung, Sowon Hahn
Categories: cs.RO cs.HC
Comments: Accepted for oral presentation at the 32nd IEEE International
 Conference on Robot and Human Interactive Communication(RO-MAN 2023)
\\
 Loneliness is a distressing personal experience and a growing social issue.
Social robots could alleviate the pain of loneliness, particularly for those
who lack in-person interaction. This paper investigated how the effect of
loneliness on anthropomorphizing social robots differs by robot appearances,
and how it leads to the purchase intention of social robots. Participants
viewed a video of one of the three robots(machine-like, animal-like, and
human-like) moving and interacting with a human counterpart. The results
revealed that when individuals were lonelier, the tendency to anthropomorphize
human-like robots increased more than that of animal-like robots. The
moderating effect remained significant after covariates were included. The
increase in anthropomorphic tendency predicted the heightened purchase intent.
The findings imply that human-like robots induce lonely individuals' desire to
replenish the sense of connectedness from robots more than animal-like robots,
and that anthropomorphic tendency reveals the potential of social robots as
real-life companions of lonely individuals.
\\ ( https://arxiv.org/abs/2306.02694 ,  634kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02705
Date: Mon, 5 Jun 2023 08:56:55 GMT   (2634kb,D)

Title: Situational Adaptive Motion Prediction for Firefighting Squads in Indoor
 Search and Rescue
Authors: Nils Mandischer, Frederik Schicks, Burkhard Corves
Categories: cs.RO
Comments: published in 5th Workshop on Long-term Human Motion Prediction (LHMP)
 at International Conference on Robotics and Automation (ICRA) 2023
\\
 Firefighting is a complex, yet low automated task. To mitigate ergonomic and
safety related risks on the human operators, robots could be deployed in a
collaborative approach. To allow human-robot teams in firefighting, important
basics are missing. Amongst other aspects, the robot must predict the human
motion as occlusion is ever-present. In this work, we propose a novel motion
prediction pipeline for firefighters' squads in indoor search and rescue. The
squad paths are generated with an optimal graph-based planning approach
representing firefighters' tactics. Paths are generated per room which allows
to dynamically adapt the path locally without global re-planning. The motion of
singular agents is simulated using a modification of the headed social force
model. We evaluate the pipeline for feasibility with a novel data set generated
from real footage and show the computational efficiency.
\\ ( https://arxiv.org/abs/2306.02705 ,  2634kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02739
Date: Mon, 5 Jun 2023 09:37:53 GMT   (32694kb,D)

Title: Knowledge-Driven Robot Program Synthesis from Human VR Demonstrations
Authors: Benjamin Alt, Franklin Kenghagho Kenfack, Andrei Haidu, Darko Katic,
 Rainer J\"akel, Michael Beetz
Categories: cs.RO cs.AI
Comments: 10 pages, 11 figures, accepted at the 20th International Conference
 on Principles of Knowledge Representation and Reasoning (KR2023,
 https://kr.org/KR2023)
MSC-class: 68T30
ACM-class: D.1; F.3; I.2
\\
 Aging societies, labor shortages and increasing wage costs call for
assistance robots capable of autonomously performing a wide array of real-world
tasks. Such open-ended robotic manipulation requires not only powerful
knowledge representations and reasoning (KR&R) algorithms, but also methods for
humans to instruct robots what tasks to perform and how to perform them. In
this paper, we present a system for automatically generating executable robot
control programs from human task demonstrations in virtual reality (VR). We
leverage common-sense knowledge and game engine-based physics to semantically
interpret human VR demonstrations, as well as an expressive and general task
representation and automatic path planning and code generation, embedded into a
state-of-the-art cognitive architecture. We demonstrate our approach in the
context of force-sensitive fetch-and-place for a robotic shopping assistant.
The source code is available at
https://github.com/ease-crc/vr-program-synthesis.
\\ ( https://arxiv.org/abs/2306.02739 ,  32694kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02742
Date: Mon, 5 Jun 2023 09:50:34 GMT   (43931kb,D)

Title: Motion Control based on Disturbance Estimation and Time-Varying Gain for
 Robotic Manipulators
Authors: Xinyu Jia, Jun Yang, Kaixin Lu, Haoyong Yu
Categories: cs.RO
Comments: This work has been submitted to the IEEE for possible publication.
 Copyright may be transferred without notice, after which this version may no
 longer be accessible
\\
 To achieve high-accuracy manipulation in the presence of unknown dynamics and
external disturbance, we propose an efficient and robust motion controller
(named TvUDE) for robotic manipulators. The controller incorporates a
disturbance estimation mechanism that utilizes reformulated robot dynamics and
filtering operations to obtain uncertainty and disturbance without requiring
measurement of acceleration. Furthermore, we design a time-varying control
input gain to enhance the control system's robustness. Finally, we analyze the
boundness of the control signal and the stability of the closed-loop system,
and conduct a set of experiments on a six-DOF robotic manipulator. The
experimental results verify the effectiveness of TvUDE in handling internal
uncertainty and external static or transient disturbance.
\\ ( https://arxiv.org/abs/2306.02742 ,  43931kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02843
Date: Mon, 5 Jun 2023 12:49:52 GMT   (1099kb,D)

Title: Robot Patrol: Using Crowdsourcing and Robotic Systems to Provide Indoor
 Navigation Guidance to The Visually Impaired
Authors: Ike Obi, Ruiqi Wang, Prakash Shukla, Byung-Cheol Min
Categories: cs.RO cs.CY
\\
 Indoor navigation is a challenging activity for persons with disabilities,
particularly, for those with low vision and visual impairment. Researchers have
explored numerous solutions to resolve these challenges; however, several
issues remain unsolved, particularly around providing dynamic and contextual
information about potential obstacles in indoor environments. In this paper, we
developed Robot Patrol, an integrated system that employs a combination of
crowdsourcing, computer vision, and robotic frameworks to provide contextual
information to the visually impaired to empower them to navigate indoor spaces
safely. In particular, the system is designed to provide information to the
visually impaired about 1) potential obstacles on the route to their indoor
destination, 2) information about indoor events on their route which they may
wish to avoid or attend, and 3) any other contextual information that might
support them to navigate to their indoor destinations safely and effectively.
Findings from the Wizard of Oz experiment of our demo system provide insights
into the benefits and limitations of the system. We provide a concise
discussion on the implications of our findings.
\\ ( https://arxiv.org/abs/2306.02843 ,  1099kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02994
Date: Mon, 5 Jun 2023 16:05:57 GMT   (13422kb,D)

Title: Long-range UAV Thermal Geo-localization with Satellite Imagery
Authors: Jiuhong Xiao, Daniel Tortei, Eloy Roura, Giuseppe Loianno
Categories: cs.RO cs.CV
Comments: 8 pages, 6 figures
\\
 Onboard sensors, such as cameras and thermal sensors, have emerged as
effective alternatives to Global Positioning System (GPS) for geo-localization
in Unmanned Aerial Vehicle (UAV) navigation. Since GPS can suffer from signal
loss and spoofing problems, researchers have explored camera-based techniques
such as Visual Geo-localization (VG) using satellite imagery. Additionally,
thermal geo-localization (TG) has become crucial for long-range UAV flights in
low-illumination environments. This paper proposes a novel thermal
geo-localization framework using satellite imagery, which includes multiple
domain adaptation methods to address the limited availability of paired thermal
and satellite images. The experimental results demonstrate the effectiveness of
the proposed approach in achieving reliable thermal geo-localization
performance, even in thermal images with indistinct self-similar features. We
evaluate our approach on real data collected onboard a UAV. We also release the
code and \textit{Boson-nighttime}, a dataset of paired satellite-thermal and
unpaired satellite images for thermal geo-localization with satellite imagery.
To the best of our knowledge, this work is the first to propose a thermal
geo-localization method using satellite imagery in long-range flights.
\\ ( https://arxiv.org/abs/2306.02994 ,  13422kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03083
Date: Mon, 5 Jun 2023 17:55:52 GMT   (4124kb,D)

Title: MotionDiffuser: Controllable Multi-Agent Motion Prediction using
 Diffusion
Authors: Chiyu Max Jiang, Andre Cornman, Cheolho Park, Ben Sapp, Yin Zhou,
 Dragomir Anguelov
Categories: cs.RO cs.AI
Comments: Accepted as a highlight paper in CVPR 2023. Walkthrough video:
 https://youtu.be/IfGTZwm1abg
\\
 We present MotionDiffuser, a diffusion based representation for the joint
distribution of future trajectories over multiple agents. Such representation
has several key advantages: first, our model learns a highly multimodal
distribution that captures diverse future outcomes. Second, the simple
predictor design requires only a single L2 loss training objective, and does
not depend on trajectory anchors. Third, our model is capable of learning the
joint distribution for the motion of multiple agents in a permutation-invariant
manner. Furthermore, we utilize a compressed trajectory representation via PCA,
which improves model performance and allows for efficient computation of the
exact sample log probability. Subsequently, we propose a general constrained
sampling framework that enables controlled trajectory sampling based on
differentiable cost functions. This strategy enables a host of applications
such as enforcing rules and physical priors, or creating tailored simulation
scenarios. MotionDiffuser can be combined with existing backbone architectures
to achieve top motion forecasting results. We obtain state-of-the-art results
for multi-agent motion prediction on the Waymo Open Motion Dataset.
\\ ( https://arxiv.org/abs/2306.03083 ,  4124kb)
------------------------------------------------------------------------------
\\
arXiv:2306.01914
Date: Fri, 2 Jun 2023 20:43:38 GMT   (456kb,D)

Title: Smooth Model Predictive Control with Applications to Statistical
 Learning
Authors: Kwangjun Ahn, Daniel Pfrommer, Jack Umenberger, Tobia Marcucci, Zak
 Mhammedi and Ali Jadbabaie
Categories: eess.SY cs.LG cs.SY
Comments: 15 pages, 1 figure
\\
 Statistical learning theory and high dimensional statistics have had a
tremendous impact on Machine Learning theory and have impacted a variety of
domains including systems and control theory. Over the past few years we have
witnessed a variety of applications of such theoretical tools to help answer
questions such as: how many state-action pairs are needed to learn a static
control policy to a given accuracy? Recent results have shown that continuously
differentiable and stabilizing control policies can be well-approximated using
neural networks with hard guarantees on performance, yet often even the
simplest constrained control problems are not smooth. To address this void, in
this paper we study smooth approximations of linear Model Predictive Control
(MPC) policies, in which hard constraints are replaced by barrier functions,
a.k.a. barrier MPC. In particular, we show that barrier MPC inherits the
exponential stability properties of the original non-smooth MPC policy. Using a
careful analysis of the proposed barrier MPC, we show that its smoothness
constant can be carefully controlled, thereby paving the way for new sample
complexity results for approximating MPC policies from sampled state-action
pairs.
\\ ( https://arxiv.org/abs/2306.01914 ,  456kb)
------------------------------------------------------------------------------
\\
arXiv:2306.01971
Date: Sat, 3 Jun 2023 00:49:46 GMT   (1317kb)

Title: Impact of Different Desired Velocity Profiles and Controller Gains on
 Convoy Driveability of Cooperative Adaptive Cruise Control Operated Platoons
Authors: Santhosh Tamilarasan, Levent Guvenc
Categories: eess.SY cs.SY
\\
 As the development of autonomous vehicles rapidly advances, the use of
convoying/platooning becomes a more widely explored technology option for
saving fuel and increasing the efficiency of traffic. In cooperative adaptive
cruise control (CACC), the vehicles in a convoy follow each other under
adaptive cruise control (ACC) that is augmented by the sharing of preceding
vehicle acceleration through the vehicle to vehicle communication in a
feedforward control path. In general, the desired velocity optimization for
vehicles in the convoy is based on fuel economy optimization, rather than
driveability. This paper is a preliminary study on the impact of the desired
velocity profile on the driveability characteristics of a convoy of vehicles
and the controller gain impact on the driveability. A simple low-level
longitudinal model of the vehicle has been used along with a PD type cruise
controller and a generic spacing policy for ACC/CACC. The acceleration of the
previous vehicle is available to the next vehicle as input, and the simulations
are performed as Cooperative Adaptive Cruise Control of a convoy of vehicles.
Individual vehicle acceleration profiles have been analyzed for driveability
for two different velocity profiles that are followed in a stretch of 720 m
between stop signs. The controller gains have been re-tuned based on the
parameter space robust control PID approach for driveability and compared with
the original gains. The US06 SFTP drive cycle has also been used for the
comparison of the two different controller gain sets.
\\ ( https://arxiv.org/abs/2306.01971 ,  1317kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02016
Date: Sat, 3 Jun 2023 06:23:17 GMT   (303kb)

Title: Converse negative imaginary theorems
Authors: Sei Zhen Khong, Di Zhao, and Alexander Lanzon
Categories: eess.SY cs.SY math.OC
Comments: This paper has been submitted for possible publication at Automatica
\\
 Converse negative imaginary theorems for linear time-invariant systems are
derived. In particular, we provide necessary and sufficient conditions for a
feedback system to be robustly stable against various types of negative
imaginary (NI) uncertainty. Both marginally stable and exponentially stable
uncertain NI systems with restrictions on their static or instantaneous gains
are considered. It is shown that robust stability against the former class
entails the well-known strict NI property, whereas the latter class entails a
new type of output strict NI property that is hitherto unexplored. We also
establish a non-existence result that no stable system can robustly stabilise
all marginally stable NI uncertainty, thereby showing that the uncertainty
class of NI systems is too large as far as robust feedback stability is
concerned, thus justifying the consideration of subclasses of NI systems with
constrained static or instantaneous gains.
\\ ( https://arxiv.org/abs/2306.02016 ,  303kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02017
Date: Sat, 3 Jun 2023 06:26:07 GMT   (375kb,D)

Title: Resilient Distributed Parameter Estimation in Sensor Networks
Authors: Jiaqi Yan, Kuo Li, and Hideaki Ishii
Categories: eess.SY cs.SY
\\
 In this paper, we study the problem of parameter estimation in a sensor
network, where the measurements and updates of some sensors might be
arbitrarily manipulated by adversaries. Despite the presence of such
misbehaviors, normally behaving sensors make successive observations of an
unknown $d$-dimensional vector parameter and aim to infer its true value by
cooperating with their neighbors over a directed communication graph. To this
end, by leveraging the so-called dynamic regressor extension and mixing
procedure, we transform the problem of estimating the vector parameter to that
of estimating $d$ scalar ones. For each of the scalar problem, we propose a
resilient combine-then-adapt diffusion algorithm, where each normal sensor
performs a resilient combination to discard the suspicious estimates in its
neighborhood and to fuse the remaining values, alongside an adaptation step to
process its streaming observations. With a low computational cost, this
estimator guarantees that each normal sensor exponentially infers the true
parameter even if some of them are not sufficiently excited.
\\ ( https://arxiv.org/abs/2306.02017 ,  375kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02020
Date: Sat, 3 Jun 2023 06:34:06 GMT   (9299kb)

Title: Replay Attack Detection Based on Parity Space Method for Cyber-Physical
 Systems
Authors: Dong Zhao, Yang Shi, Steven X. Ding, Yueyang Li, Fangzhou Fu
Categories: eess.SY cs.SY
\\
 The replay attack detection problem is studied from a new perspective based
on parity space method in this paper. The proposed detection methods have the
ability to distinguish system fault and replay attack, handle both input and
output data replay, maintain certain control performance, and can be
implemented conveniently and efficiently. First, the replay attack effect on
the residual is derived and analyzed. The residual change induced by replay
attack is characterized explicitly and the detection performance analysis based
on two different test statistics are given. Second, based on the replay attack
effect characterization, targeted passive and active design for detection
performance enhancement are proposed. Regarding the passive design, four
optimization schemes regarding different cost functions are proposed with
optimal parity matrix solutions, and the unified solution to the passive
optimization schemes is obtained; the active design is enabled by a marginally
stable filter so as to enlarge the replay attack effect on the residual for
detection. Simulations and comparison studies are given to show the
effectiveness of the proposed methods.
\\ ( https://arxiv.org/abs/2306.02020 ,  9299kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02070
Date: Sat, 3 Jun 2023 10:19:18 GMT   (5845kb)

Title: Adaptive Approximation-Based Control for Nonlinear Systems: A Unified
 Solution with Accurate and Inaccurate Measurements
Authors: Dong Zhao
Categories: eess.SY cs.SY
\\
 A unified solution to adaptive approximation-based control for nonlinear
systems with accurate and inaccurate state measurement is synthesized in this
study. Starting from the standard adaptive approximation-based controller with
accurate state measurement, its corresponding physical interpretation,
stability conclusion, and learning ability are rigorously addressed when facing
additive measurement inaccuracy, and explicit answers are obtained in the
framework of both controller matching and system matching. Finally, it proves
that, with a certain condition, the standard adaptive approximation-based
controller works as a unified solution for the cases with accurate and
inaccurate measurement, and the solution can be extended to the nonlinear
system control problems with extra unknown dynamics or faults in actuator
and/or process dynamics. A single-link robot arm example is used for the
simulation demonstration of the unified solution.
\\ ( https://arxiv.org/abs/2306.02070 ,  5845kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02187
Date: Sat, 3 Jun 2023 19:50:22 GMT   (27kb)

Title: Zeroing the Output of a Nonlinear System Without Relative Degree
Authors: W. Steven Gray, Kurusch Ebrahimi-Fard, Alexander Schmeding
Categories: eess.SY cs.SY math.CO
MSC-class: 93C10 (Primary), 68R15 (Secondary)
\\
 The goal of this paper is to establish some facts concerning the problem of
zeroing the output of an input-output system that does not have relative
degree. The approach taken is to work with systems that have a Chen-Fliess
series representation. The main result is that a class of generating series
called primely nullable series provides the building blocks for solving this
problem using the shuffle algebra. It is shown that the shuffle algebra on the
set of generating polynomials is a unique factorization domain so that any
polynomial can be uniquely factored modulo a permutation into its irreducible
elements for the purpose of identifying nullable factors. This is achieved
using the fact that this shuffle algebra is isomorphic to the symmetric algebra
over the vector space spanned by Lyndon words. A specific algorithm for
factoring generating polynomials into its irreducible factors is presented
based on the Chen-Fox-Lyndon factorization of words.
\\ ( https://arxiv.org/abs/2306.02187 ,  27kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02278
Date: Sun, 4 Jun 2023 06:51:47 GMT   (1552kb,D)

Title: Payoff Mechanism Design for Coordination in Multi-Agent Task Allocation
 Games
Authors: Shinkyu Park and Julian Barreiro-Gomez
Categories: eess.SY cs.SY
\\
 We investigate a multi-agent decision-making problem where a large population
of agents are responsible for carrying out a set of assigned tasks. The amount
of jobs in each task varies over time governed by a dynamical system model.
Each agent needs to select one of available strategies to take on one or more
tasks. Since each strategy allows an agent to perform multiple tasks at a time,
possibly at distinct rates, the strategy selection of the agents need to be
coordinated. The main objective of this work is to design a decentralized
decision-making model that coordinates the agents in selecting strategies and
allows them to asymptotically adopt the optimal strategies, e.g., the
strategies that minimize remaining jobs in all assigned tasks.
 We formulate the problem using the population game formalism and refer to it
as the task allocation game. We discuss the design of a decision-making model
that incentivizes the agents to coordinate in the strategy selection process.
As key contributions, we propose a method to find a payoff-driven
decision-making model, and discuss how the model allows the strategy selection
of the agents to be responsive to the amount of remaining jobs in each task
while asymptotically attaining the optimal strategies. Leveraging analytical
tools from feedback control theory, we derive technical conditions that the
model needs to satisfy, which are used to construct a numerical approach to
compute the model. We validate our solution through simulations to highlight
how the proposed approach coordinates the agents in task allocation games.
\\ ( https://arxiv.org/abs/2306.02278 ,  1552kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02309
Date: Sun, 4 Jun 2023 09:30:04 GMT   (4017kb,D)

Title: Synchronization of multiple rigid body systems: a survey
Authors: X. Jin, Daniel W. C. Ho, and Y. Tang
Categories: eess.SY cs.SY
\\
 The multi-agent system has been a hot topic in the past few decades owing to
its lower cost, higher robustness, and higher flexibility. As a particular
multi-agent system, the multiple rigid body system received a growing interest
since its wide applications in transportation, aerospace, and ocean
exploration. Due to the non-Euclidean configuration space of attitudes and the
inherent nonlinearity of the dynamics of rigid body systems, synchronization of
multiple rigid body systems is quite challenging. This paper aims to present an
overview of the recent progress in synchronization of multiple rigid body
systems from the view of two fundamental problems. The first problem focuses on
attitude synchronization, while the second one focuses on cooperative motion
control in that rotation and translation dynamics are coupled. Finally, a
summary and future directions are given in the conclusion.
\\ ( https://arxiv.org/abs/2306.02309 ,  4017kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02318
Date: Sun, 4 Jun 2023 10:00:57 GMT   (695kb,D)

Title: Distributionally robust uncertainty quantification via data-driven
 stochastic optimal control
Authors: Guanru Pan and Timm Faulwasser
Categories: eess.SY cs.SY
Comments: 6 pages,2 figures
\\
 This paper studies optimal control problems of unknown linear systems subject
to stochastic disturbances of uncertain distribution. Uncertainty about the
stochastic disturbances is usually described via ambiguity sets of probability
measures or distributions. Typically, stochastic optimal control requires
knowledge of underlying dynamics and is as such challenging. Relying on a
stochastic fundamental lemma from data-driven control and on the framework of
polynomial chaos expansions, we propose an approach to reformulate
distributionally robust optimal control problems with ambiguity sets as
uncertain conic programs in a finite-dimensional vector space. We show how to
construct these programs from previously recorded data and how to relax the
uncertain conic program to numerically tractable convex programs via
appropriate sampling of the underlying distributions. The efficacy of our
method is illustrated via a numerical example.
\\ ( https://arxiv.org/abs/2306.02318 ,  695kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02435
Date: Sun, 4 Jun 2023 18:39:19 GMT   (563kb,D)

Title: On the complexity of linear systems: an approach via rate distortion
 theory and emulating systems
Authors: Eric Wendel, John Baillieul, and Joseph Hollmann
Categories: eess.SY cs.IT cs.SY math.IT
Comments: To appear, American Controls Conference 2023, San Diego, CA
\\
 We define the complexity of a continuous-time linear system to be the minimum
number of bits required to describe its forward increments to a desired level
of fidelity, and compute this quantity using the rate distortion function of a
Gaussian source of uncertainty in those increments. The complexity of a linear
system has relevance in control-communications contexts requiring local and
dynamic decision-making based on sampled data representations. We relate this
notion of complexity to the design of attention-varying controllers, and
demonstrate a novel methodology for constructing source codes via the endpoint
maps of so-called emulating systems, with potential for non-parametric,
data-based simulation and analysis of unknown dynamical systems.
\\ ( https://arxiv.org/abs/2306.02435 ,  563kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02482
Date: Sun, 4 Jun 2023 21:15:03 GMT   (3276kb,D)

Title: Aerial Swarm Defense using Interception and Herding Strategies
Authors: Vishnu S. Chipade, Dimitra Panagou
Categories: eess.SY cs.SY
Comments: 17 pages, 13 figures
\\
 This paper presents a multi-mode solution to the problem of defending a
circular protected area (target) from a wide range of attacks by swarms of
risk-taking and/or risk-averse attacking agents (attackers). The proposed
multi-mode solution combines two defense strategies, namely: 1) an interception
strategy for a team of defenders to intercept multiple risk-taking attackers
while ensuring that the defenders do not collide with each other, 2) a herding
strategy to herd a swarm of risk-averse attackers to a safe area. In
particular, we develop mixed integer programs (MIPs) and geometry-inspired
heuristics to distribute and assign and/or reassign the defenders to
interception and herding tasks under different spatiotemporal behaviors by the
attackers such as splitting into smaller swarms to evade defenders easily or
high-speed maneuvers by some risk-taking attackers to maximize damage to the
protected area. We provide theoretical as well as numerical comparisons of the
computational costs of these MIPs and the heuristics, and demonstrate the
overall approach in simulations.
\\ ( https://arxiv.org/abs/2306.02482 ,  3276kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02574
Date: Mon, 5 Jun 2023 03:57:16 GMT   (777kb,D)

Title: Bayesian Learning of Optimal Policies in Markov Decision Processes with
 Countably Infinite State-Space
Authors: Saghar Adler, Vijay Subramanian
Categories: eess.SY cs.LG cs.SY
\\
 Models of many real-life applications, such as queuing models of
communication networks or computing systems, have a countably infinite
state-space. Algorithmic and learning procedures that have been developed to
produce optimal policies mainly focus on finite state settings, and do not
directly apply to these models. To overcome this lacuna, in this work we study
the problem of optimal control of a family of discrete-time countable
state-space Markov Decision Processes (MDPs) governed by an unknown parameter
$\theta\in\Theta$, and defined on a countably-infinite state space $\mathcal
X=\mathbb{Z}_+^d$, with finite action space $\mathcal A$, and an unbounded cost
function. We take a Bayesian perspective with the random unknown parameter
$\boldsymbol{\theta}^*$ generated via a given fixed prior distribution on
$\Theta$. To optimally control the unknown MDP, we propose an algorithm based
on Thompson sampling with dynamically-sized episodes: at the beginning of each
episode, the posterior distribution formed via Bayes' rule is used to produce a
parameter estimate, which then decides the policy applied during the episode.
To ensure the stability of the Markov chain obtained by following the policy
chosen for each parameter, we impose ergodicity assumptions. From this
condition and using the solution of the average cost Bellman equation, we
establish an $\tilde O(\sqrt{|\mathcal A|T})$ upper bound on the Bayesian
regret of our algorithm, where $T$ is the time-horizon. Finally, to elucidate
the applicability of our algorithm, we consider two different queuing models
with unknown dynamics, and show that our algorithm can be applied to develop
approximately optimal control algorithms.
\\ ( https://arxiv.org/abs/2306.02574 ,  777kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02802
Date: Mon, 5 Jun 2023 11:56:43 GMT   (3131kb,D)

Title: Residential flexibility characterization and control using global
 forecasting models
Authors: Lorenzo Nespoli and Vasco Medici
Categories: eess.SY cs.SY
\\
 In this paper, we propose a general and practical approach to estimate the
amount of flexibility of deferrable loads in a Distribution System Operator's
(DSO) grid and obtain an optimal control policy from day zero, without relying
on historical observations. We achieve this by simulating the flexible devices
and learning their response to random control signals, using a non-parametric
global forecasting model. This model is then included in an optimization
problem defining the control policy. We suggest a method to preserve the
thermal comfort of houses equipped with a heat pump based on estimating their
energy signature. We apply this method to control electric water heaters and
heat pumps operated through ripple control and show how flexibility, including
rebound effects, can be characterized. Finally, we show that the forecaster's
accuracy in terms of the objective function is sufficient to completely bypass
the simulations and directly use the forecaster as an emulator.
\\ ( https://arxiv.org/abs/2306.02802 ,  3131kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02820
Date: Mon, 5 Jun 2023 12:19:13 GMT   (1320kb,D)

Title: Time Dependent Inverse Optimal Control using Trigonometric Basis
 Functions
Authors: Rahel Rickenbach, Elena Arcari, Melanie N. Zeilinger
Categories: eess.SY cs.SY
\\
 The choice of objective is critical for the performance of an optimal
controller. When control requirements vary during operation, e.g. due to
changes in the environment with which the system is interacting, these
variations should be reflected in the cost function. In this paper we consider
the problem of identifying a time dependent cost function from given
trajectories. We propose a strategy for explicitly representing time dependency
in the cost function, i.e. decomposing it into the product of an unknown time
dependent parameter vector and a known state and input dependent vector,
modelling the former via a linear combination of trigonometric basis functions.
These are incorporated within an inverse optimal control framework that uses
the Karush-Kuhn-Tucker (KKT) conditions for ensuring optimality, and allows for
formulating an optimization problem with respect to a finite set of basis
function hyperparameters. Results are shown for two systems in simulation and
evaluated against state-of-the-art approaches.
\\ ( https://arxiv.org/abs/2306.02820 ,  1320kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02944
Date: Mon, 5 Jun 2023 15:05:57 GMT   (15539kb,D)

Title: Beyond Nyquist in Frequency Response Function Identification: Applied to
 Slow-Sampled Systems
Authors: Max van Haren, Leonid Mirkin, Lennart Blanken and Tom Oomen
Categories: eess.SY cs.SY
\\
 Fast-sampled models are essential for control design, e.g., to address
intersample behavior. The aim of this paper is to develop a non-parametric
identification technique for fast-sampled models of systems that have relevant
dynamics and actuation above the Nyquist frequency of the sensor, such as
vision-in-the-loop systems. The developed method assumes smoothness of the
frequency response function, which allows to disentangle aliased components
through local models over multiple frequency bands. The method identifies
fast-sampled models of slowly-sampled systems accurately in a single
identification experiment. Finally, an experimental example demonstrates the
effectiveness of the technique.
\\ ( https://arxiv.org/abs/2306.02944 ,  15539kb)
%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-
------------------------------------------------------------------------------
\\
arXiv:2306.01739 (*cross-listing*)
Date: Tue, 18 Apr 2023 02:20:43 GMT   (714kb)

Title: Comparative study on Judgment Text Classification for Transformer Based
 Models
Authors: Stanley Kingston, Prassanth, Shrinivas A V, Balamurugan MS, Manoj
 Kumar Rajagopal
Categories: cs.CL cs.AI
Comments: 28 pages with 9 figures
\\
 This work involves the usage of various NLP models to predict the winner of a
particular judgment by the means of text extraction and summarization from a
judgment document. These documents are useful when it comes to legal
proceedings. One such advantage is that these can be used for citations and
precedence reference in Lawsuits and cases which makes a strong argument for
their case by the ones using it. When it comes to precedence, it is necessary
to refer to an ample number of documents in order to collect legal points with
respect to the case. However, reviewing these documents takes a long time to
analyze due to the complex word structure and the size of the document. This
work involves the comparative study of 6 different self-attention-based
transformer models and how they perform when they are being tweaked in 4
different activation functions. These models which are trained with 200
judgement contexts and their results are being judged based on different
benchmark parameters. These models finally have a confidence level up to 99%
while predicting the judgment. This can be used to get a particular judgment
document without spending too much time searching relevant cases and reading
them completely.
\\ ( https://arxiv.org/abs/2306.01739 ,  714kb)
------------------------------------------------------------------------------
\\
arXiv:2306.01745 (*cross-listing*)
Date: Mon, 15 May 2023 08:47:56 GMT   (7103kb,D)

Title: Biomarker Discovery with Quantum Neural Networks: A Case-study in
 CTLA4-Activation Pathways
Authors: Nam Nguyen
Categories: q-bio.QM cs.AI
\\
 Biomarker discovery is a challenging task due to the massive search space.
Quantum computing and quantum Artificial Intelligence (quantum AI) can be used
to address the computational problem of biomarker discovery tasks. We propose a
Quantum Neural Networks (QNNs) architecture to discover biomarkers for input
activation pathways. The Maximum Relevance, Minimum Redundancy (mRMR) criteria
is used to score biomarker candidate sets. Our proposed model is economical
since the neural solution can be delivered on constrained hardware. We
demonstrate the proof of concept on four activation pathways associated with
CTLA4, including (1) CTLA4-activation stand-alone, (2) CTLA4-CD8A-CD8B
co-activation, (3) CTLA4-CD2 co-activation, and (4)
CTLA4-CD2-CD48-CD53-CD58-CD84 co-activation. The model indicates new biomarkers
associated with the mutational activation of CLTA4-associated pathways,
including 20 genes: CLIC4, CPE, ETS2, FAM107A, GPR116, HYOU1, LCN2, MACF1,
MT1G, NAPA, NDUFS5, PAK1, PFN1, PGAP3, PPM1G, PSMD8, RNF213, SLC25A3, UBA1, and
WLS. We open source the implementation at:
https://github.com/namnguyen0510/Biomarker-Discovery-with-Quantum-Neural-Networks.
\\ ( https://arxiv.org/abs/2306.01745 ,  7103kb)
------------------------------------------------------------------------------
\\
arXiv:2306.01753 (*cross-listing*)
Date: Mon, 22 May 2023 16:57:52 GMT   (2369kb,D)

Title: Preconditioned Visual Language Inference with Weak Supervision
Authors: Ehsan Qasemi, Amani R. Maina-Kilaas, Devadutta Dash, Khalid Alsaggaf,
 Muhao Chen
Categories: cs.CL cs.AI cs.CV
\\
 Humans can infer the affordance of objects by extracting related contextual
preconditions for each scenario. For example, upon seeing an image of a broken
cup, we can infer that this precondition prevents the cup from being used for
drinking. Reasoning with preconditions of commonsense is studied in NLP where
the model explicitly gets the contextual precondition. However, it is unclear
if SOTA visual language models (VLMs) can extract such preconditions and infer
the affordance of objects with them. In this work, we introduce the task of
preconditioned visual language inference and rationalization (PVLIR). We
propose a learning resource based on three strategies to retrieve weak
supervision signals for the task and develop a human-verified test set for
evaluation. Our results reveal the shortcomings of SOTA VLM models in the task
and draw a road map to address the challenges ahead in improving them.
\\ ( https://arxiv.org/abs/2306.01753 ,  2369kb)
------------------------------------------------------------------------------
\\
arXiv:2306.01754 (*cross-listing*)
Date: Tue, 23 May 2023 01:21:55 GMT   (2250kb,D)

Title: Transformer-based Vulnerability Detection in Code at EditTime:
 Zero-shot, Few-shot, or Fine-tuning?
Authors: Aaron Chan, Anant Kharkar, Roshanak Zilouchian Moghaddam, Yevhen
 Mohylevskyy, Alec Helyar, Eslam Kamal, Mohamed Elkamhawy, Neel Sundaresan
Categories: cs.CR cs.AI cs.LG
\\
 Software vulnerabilities bear enterprises significant costs. Despite
extensive efforts in research and development of software vulnerability
detection methods, uncaught vulnerabilities continue to put software owners and
users at risk. Many current vulnerability detection methods require that code
snippets can compile and build before attempting detection. This,
unfortunately, introduces a long latency between the time a vulnerability is
injected to the time it is removed, which can substantially increases the cost
of fixing a vulnerability. We recognize that the current advances in machine
learning can be used to detect vulnerable code patterns on syntactically
incomplete code snippets as the developer is writing the code at EditTime. In
this paper we present a practical system that leverages deep learning on a
large-scale data set of vulnerable code patterns to learn complex
manifestations of more than 250 vulnerability types and detect vulnerable code
patterns at EditTime. We discuss zero-shot, few-shot, and fine-tuning
approaches on state of the art pre-trained Large Language Models (LLMs). We
show that in comparison with state of the art vulnerability detection models
our approach improves the state of the art by 10%. We also evaluate our
approach to detect vulnerability in auto-generated code by code LLMs.
Evaluation on a benchmark of high-risk code scenarios shows a reduction of up
to 90% vulnerability reduction.
\\ ( https://arxiv.org/abs/2306.01754 ,  2250kb)
------------------------------------------------------------------------------
\\
arXiv:2306.01760 (*cross-listing*)
Date: Thu, 25 May 2023 14:47:19 GMT   (4890kb,D)

Title: Nonparametric Identification and Estimation of Earnings Dynamics using a
 Hidden Markov Model: Evidence from the PSID
Authors: Tong Zhou
Categories: stat.AP cs.AI
\\
 This paper presents a hidden Markov model designed to investigate the complex
nature of earnings persistence. The proposed model assumes that the residuals
of log-earnings consist of a persistent component and a transitory component,
both following general Markov processes. Nonparametric identification is
achieved through spectral decomposition of linear operators, and a modified
stochastic EM algorithm is introduced for model estimation. Applying the
framework to the Panel Study of Income Dynamics (PSID) dataset, we find that
the earnings process displays nonlinear persistence, conditional skewness, and
conditional kurtosis. Additionally, the transitory component is found to
possess non-Gaussian properties, resulting in a significantly asymmetric
distributional impact when high-earning households face negative shocks or
low-earning households encounter positive shocks. Our empirical findings also
reveal the presence of ARCH effects in earnings at horizons ranging from 2 to 8
years, further highlighting the complex dynamics of earnings persistence.
\\ ( https://arxiv.org/abs/2306.01760 ,  4890kb)
------------------------------------------------------------------------------
\\
arXiv:2306.01761 (*cross-listing*)
Date: Fri, 26 May 2023 09:27:43 GMT   (582kb,D)

Title: Distinguishing Human Generated Text From ChatGPT Generated Text Using
 Machine Learning
Authors: Niful Islam, Debopom Sutradhar, Humaira Noor, Jarin Tasnim Raya,
 Monowara Tabassum Maisha, Dewan Md Farid
Categories: cs.CL cs.AI cs.LG
\\
 ChatGPT is a conversational artificial intelligence that is a member of the
generative pre-trained transformer of the large language model family. This
text generative model was fine-tuned by both supervised learning and
reinforcement learning so that it can produce text documents that seem to be
written by natural intelligence. Although there are numerous advantages of this
generative model, it comes with some reasonable concerns as well. This paper
presents a machine learning-based solution that can identify the ChatGPT
delivered text from the human written text along with the comparative analysis
of a total of 11 machine learning and deep learning algorithms in the
classification process. We have tested the proposed model on a Kaggle dataset
consisting of 10,000 texts out of which 5,204 texts were written by humans and
collected from news and social media. On the corpus generated by GPT-3.5, the
proposed algorithm presents an accuracy of 77%.
\\ ( https://arxiv.org/abs/2306.01761 ,  582kb)
------------------------------------------------------------------------------
\\
arXiv:2306.01762 (*cross-listing*)
Date: Sat, 27 May 2023 06:00:51 GMT   (1745kb,D)

Title: Pre-trained transformer for adversarial purification
Authors: Kai Wu, Yujian Betterest Li, Xiaoyu Zhang, Handing Wang, Jing Liu
Categories: cs.CR cs.AI cs.CV cs.LG
\\
 With more and more deep neural networks being deployed as various daily
services, their reliability is essential. It's frightening that deep neural
networks are vulnerable and sensitive to adversarial attacks, the most common
one of which for the services is evasion-based. Recent works usually strengthen
the robustness by adversarial training or leveraging the knowledge of an amount
of clean data. However, in practical terms, retraining and redeploying the
model need a large computational budget, leading to heavy losses to the online
service. In addition, when adversarial examples of a certain attack are
detected, only limited adversarial examples are available for the service
provider, while much clean data may not be accessible. Given the mentioned
problems, we propose a new scenario, RaPiD (Rapid Plug-in Defender), which is
to rapidly defend against a certain attack for the frozen original service
model with limitations of few clean and adversarial examples. Motivated by the
generalization and the universal computation ability of pre-trained transformer
models, we come up with a new defender method, CeTaD, which stands for
Considering Pre-trained Transformers as Defenders. In particular, we evaluate
the effectiveness and the transferability of CeTaD in the case of one-shot
adversarial examples and explore the impact of different parts of CeTaD as well
as training data conditions. CeTaD is flexible, able to be embedded into an
arbitrary differentiable model, and suitable for various types of attacks.
\\ ( https://arxiv.org/abs/2306.01762 ,  1745kb)
------------------------------------------------------------------------------
\\
arXiv:2306.01763 (*cross-listing*)
Date: Sat, 27 May 2023 10:28:27 GMT   (95kb,D)

Title: Optimization for truss design using Bayesian optimization
Authors: Bhawani Sandeep, Surjeet Singh, Sumit Kumar
Categories: stat.AP cs.AI
\\
 In this work, geometry optimization of mechanical truss using computer-aided
finite element analysis is presented. The shape of the truss is a dominant
factor in determining the capacity of load it can bear. At a given parameter
space, our goal is to find the parameters of a hull that maximize the
load-bearing capacity and also don't yield to the induced stress. We rely on
finite element analysis, which is a computationally costly design analysis tool
for design evaluation. For such expensive to-evaluate functions, we chose
Bayesian optimization as our optimization framework which has empirically
proven sample efficient than other simulation-based optimization methods.
 By utilizing Bayesian optimization algorithms, the truss design involves
iteratively evaluating a set of candidate truss designs and updating a
probabilistic model of the design space based on the results. The model is used
to predict the performance of each candidate design, and the next candidate
design is selected based on the prediction and an acquisition function that
balances exploration and exploitation of the design space. Our result can be
used as a baseline for future study on AI-based optimization in expensive
engineering domains especially in finite element Analysis.
\\ ( https://arxiv.org/abs/2306.01763 ,  95kb)
------------------------------------------------------------------------------
\\
arXiv:2306.01774 (*cross-listing*)
Date: Mon, 29 May 2023 11:57:07 GMT   (159kb,D)

Title: RE-centric Recommendations for the Development of Trustworthy(er)
 Autonomous Systems
Authors: Krishna Ronanki, Beatriz Cabrero-Daniel, Jennifer Horkoff, Christian
 Berger
Categories: cs.CY cs.AI cs.SE
Comments: Accepted at [TAS '23]{First International Symposium on Trustworthy
 Autonomous Systems}
DOI: 10.1145/3597512.3599697
\\
 Complying with the EU AI Act (AIA) guidelines while developing and
implementing AI systems will soon be mandatory within the EU. However,
practitioners lack actionable instructions to operationalise ethics during AI
systems development. A literature review of different ethical guidelines
revealed inconsistencies in the principles addressed and the terminology used
to describe them. Furthermore, requirements engineering (RE), which is
identified to foster trustworthiness in the AI development process from the
early stages was observed to be absent in a lot of frameworks that support the
development of ethical and trustworthy AI. This incongruous phrasing combined
with a lack of concrete development practices makes trustworthy AI development
harder. To address this concern, we formulated a comparison table for the
terminology used and the coverage of the ethical AI principles in major ethical
AI guidelines. We then examined the applicability of ethical AI development
frameworks for performing effective RE during the development of trustworthy AI
systems. A tertiary review and meta-analysis of literature discussing ethical
AI frameworks revealed their limitations when developing trustworthy AI. Based
on our findings, we propose recommendations to address such limitations during
the development of trustworthy AI.
\\ ( https://arxiv.org/abs/2306.01774 ,  159kb)
------------------------------------------------------------------------------
\\
arXiv:2306.01779 (*cross-listing*)
Date: Tue, 30 May 2023 19:32:39 GMT   (1183kb)

Title: Conceptual Design Generation Using Large Language Models
Authors: Kevin Ma, Daniele Grandi, Christopher McComb, Kosa Goucher-Lambert
Categories: cs.CL cs.AI
Comments: Proceedings of the ASME 2023 International Design Engineering
 Technical Conferences and Computers and Information in Engineering
 Conferences
\\
 Concept generation is a creative step in the conceptual design phase, where
designers often turn to brainstorming, mindmapping, or crowdsourcing design
ideas to complement their own knowledge of the domain. Recent advances in
natural language processing (NLP) and machine learning (ML) have led to the
rise of Large Language Models (LLMs) capable of generating seemingly creative
outputs from textual prompts. The success of these models has led to their
integration and application across a variety of domains, including art,
entertainment, and other creative work. In this paper, we leverage LLMs to
generate solutions for a set of 12 design problems and compare them to a
baseline of crowdsourced solutions. We evaluate the differences between
generated and crowdsourced design solutions through multiple perspectives,
including human expert evaluations and computational metrics. Expert
evaluations indicate that the LLM-generated solutions have higher average
feasibility and usefulness while the crowdsourced solutions have more novelty.
We experiment with prompt engineering and find that leveraging few-shot
learning can lead to the generation of solutions that are more similar to the
crowdsourced solutions. These findings provide insight into the quality of
design solutions generated with LLMs and begins to evaluate prompt engineering
techniques that could be leveraged by practitioners to generate higher-quality
design solutions synergistically with LLMs.
\\ ( https://arxiv.org/abs/2306.01779 ,  1183kb)
------------------------------------------------------------------------------
\\
arXiv:2306.01787 (*cross-listing*)
Date: Wed, 31 May 2023 14:11:51 GMT   (5471kb,D)

Title: Power Control with QoS Guarantees: A Differentiable Projection-based
 Unsupervised Learning Framework
Authors: Mehrazin Alizadeh and Hina Tabassum
Categories: cs.NI cs.AI cs.LG
Comments: accepted in IEEE Transactions on Communications
\\
 Deep neural networks (DNNs) are emerging as a potential solution to solve
NP-hard wireless resource allocation problems. However, in the presence of
intricate constraints, e.g., users' quality-of-service (QoS) constraints,
guaranteeing constraint satisfaction becomes a fundamental challenge. In this
paper, we propose a novel unsupervised learning framework to solve the
classical power control problem in a multi-user interference channel, where the
objective is to maximize the network sumrate under users' minimum data rate or
QoS requirements and power budget constraints. Utilizing a differentiable
projection function, two novel deep learning (DL) solutions are pursued. The
first is called Deep Implicit Projection Network (DIPNet), and the second is
called Deep Explicit Projection Network (DEPNet). DIPNet utilizes a
differentiable convex optimization layer to implicitly define a projection
function. On the other hand, DEPNet uses an explicitly-defined projection
function, which has an iterative nature and relies on a differentiable
correction process. DIPNet requires convex constraints; whereas, the DEPNet
does not require convexity and has a reduced computational complexity. To
enhance the sum-rate performance of the proposed models even further,
Frank-Wolfe algorithm (FW) has been applied to the output of the proposed
models. Extensive simulations depict that the proposed DNN solutions not only
improve the achievable data rate but also achieve zero constraint violation
probability, compared to the existing DNNs. The proposed solutions outperform
the classic optimization methods in terms of computation time complexity.
\\ ( https://arxiv.org/abs/2306.01787 ,  5471kb)
------------------------------------------------------------------------------
\\
arXiv:2306.01788 (*cross-listing*)
Date: Wed, 31 May 2023 15:47:12 GMT   (350kb,D)

Title: Responsible Design Patterns for Machine Learning Pipelines
Authors: Saud Hakem Al Harbi, Lionel Nganyewou Tidjon and Foutse Khomh
Categories: cs.SE cs.AI cs.LG
Comments: 20 pages, 4 figures, 5 tables
\\
 Integrating ethical practices into the AI development process for artificial
intelligence (AI) is essential to ensure safe, fair, and responsible operation.
AI ethics involves applying ethical principles to the entire life cycle of AI
systems. This is essential to mitigate potential risks and harms associated
with AI, such as algorithm biases. To achieve this goal, responsible design
patterns (RDPs) are critical for Machine Learning (ML) pipelines to guarantee
ethical and fair outcomes. In this paper, we propose a comprehensive framework
incorporating RDPs into ML pipelines to mitigate risks and ensure the ethical
development of AI systems. Our framework comprises new responsible AI design
patterns for ML pipelines identified through a survey of AI ethics and data
management experts and validated through real-world scenarios with expert
feedback. The framework guides AI developers, data scientists, and
policy-makers to implement ethical practices in AI development and deploy
responsible AI systems in production.
\\ ( https://arxiv.org/abs/2306.01788 ,  350kb)
------------------------------------------------------------------------------
\\
arXiv:2306.01792 (*cross-listing*)
Date: Thu, 1 Jun 2023 08:10:03 GMT   (349kb,D)

Title: Task Relation-aware Continual User Representation Learning
Authors: Sein Kim, Namkyeong Lee, Donghyun Kim, Minchul Yang, Chanyoung Park
Categories: cs.IR cs.AI cs.LG
Comments: KDD 2023
DOI: 10.1145/3580305.3599516
\\
 User modeling, which learns to represent users into a low-dimensional
representation space based on their past behaviors, got a surge of interest
from the industry for providing personalized services to users. Previous
efforts in user modeling mainly focus on learning a task-specific user
representation that is designed for a single task. However, since learning
task-specific user representations for every task is infeasible, recent studies
introduce the concept of universal user representation, which is a more
generalized representation of a user that is relevant to a variety of tasks.
Despite their effectiveness, existing approaches for learning universal user
representations are impractical in real-world applications due to the data
requirement, catastrophic forgetting and the limited learning capability for
continually added tasks. In this paper, we propose a novel continual user
representation learning method, called TERACON, whose learning capability is
not limited as the number of learned tasks increases while capturing the
relationship between the tasks. The main idea is to introduce an embedding for
each task, i.e., task embedding, which is utilized to generate task-specific
soft masks that not only allow the entire model parameters to be updated until
the end of training sequence, but also facilitate the relationship between the
tasks to be captured. Moreover, we introduce a novel knowledge retention module
with pseudo-labeling strategy that successfully alleviates the long-standing
problem of continual learning, i.e., catastrophic forgetting. Extensive
experiments on public and proprietary real-world datasets demonstrate the
superiority and practicality of TERACON. Our code is available at
https://github.com/Sein-Kim/TERACON.
\\ ( https://arxiv.org/abs/2306.01792 ,  349kb)
------------------------------------------------------------------------------
\\
arXiv:2306.01798 (*cross-listing*)
Date: Thu, 1 Jun 2023 14:52:28 GMT   (1618kb)

Title: Exploring EFL students' prompt engineering in human-AI story writing: an
 Activity Theory perspective
Authors: David James Woo, Kai Guo, Hengky Susanto
Categories: cs.CY cs.AI
Comments: 38 pages, 9 figures
\\
 This study applies Activity Theory to investigate how English as a foreign
language (EFL) students prompt generative artificial intelligence (AI) tools
during short story writing. Sixty-seven Hong Kong secondary school students
created generative-AI tools using open-source language models and wrote short
stories with them. The study collected and analyzed the students' generative-AI
tools, short stories, and written reflections on their conditions or purposes
for prompting. The research identified three main themes regarding the purposes
for which students prompt generative-AI tools during short story writing: a
lack of awareness of purposes, overcoming writer's block, and developing,
expanding, and improving the story. The study also identified common
characteristics of students' activity systems, including the sophistication of
their generative-AI tools, the quality of their stories, and their school's
overall academic achievement level, for their prompting of generative-AI tools
for the three purposes during short story writing. The study's findings suggest
that teachers should be aware of students' purposes for prompting generative-AI
tools to provide tailored instructions and scaffolded guidance. The findings
may also help designers provide differentiated instructions for users at
various levels of story development when using a generative-AI tool.
\\ ( https://arxiv.org/abs/2306.01798 ,  1618kb)
------------------------------------------------------------------------------
\\
arXiv:2306.01800 (*cross-listing*)
Date: Thu, 1 Jun 2023 16:12:55 GMT   (89kb)

Title: The ethical ambiguity of AI data enrichment: Measuring gaps in research
 ethics norms and practices
Authors: Will Hawkins and Brent Mittelstadt
Categories: cs.CY cs.AI
Comments: 10 pages
MSC-class: N/A
ACM-class: K.4.1
Journal-ref: 2023 ACM Conference on Fairness, Accountability, and Transparency
DOI: 10.1145/3593013.3593995.
\\
 The technical progression of artificial intelligence (AI) research has been
built on breakthroughs in fields such as computer science, statistics, and
mathematics. However, in the past decade AI researchers have increasingly
looked to the social sciences, turning to human interactions to solve the
challenges of model development. Paying crowdsourcing workers to generate or
curate data, or data enrichment, has become indispensable for many areas of AI
research, from natural language processing to reinforcement learning from human
feedback (RLHF). Other fields that routinely interact with crowdsourcing
workers, such as Psychology, have developed common governance requirements and
norms to ensure research is undertaken ethically. This study explores how, and
to what extent, comparable research ethics requirements and norms have
developed for AI research and data enrichment. We focus on the approach taken
by two leading conferences: ICLR and NeurIPS, and journal publisher Springer.
In a longitudinal study of accepted papers, and via a comparison with
Psychology and CHI papers, this work finds that leading AI venues have begun to
establish protocols for human data collection, but these are are inconsistently
followed by authors. Whilst Psychology papers engaging with crowdsourcing
workers frequently disclose ethics reviews, payment data, demographic data and
other information, similar disclosures are far less common in leading AI venues
despite similar guidance. The work concludes with hypotheses to explain these
gaps in research ethics practices and considerations for its implications.
\\ ( https://arxiv.org/abs/2306.01800 ,  89kb)
------------------------------------------------------------------------------
\\
arXiv:2306.01805 (*cross-listing*)
Date: Thu, 1 Jun 2023 18:49:47 GMT   (542kb,D)

Title: Cook-Gen: Robust Generative Modeling of Cooking Actions from Recipes
Authors: Revathy Venkataramanan, Kaushik Roy, Kanak Raj, Renjith Prasad, Yuxin
 Zi, Vignesh Narayanan, Amit Sheth
Categories: cs.CL cs.AI cs.IR
\\
 As people become more aware of their food choices, food computation models
have become increasingly popular in assisting people in maintaining healthy
eating habits. For example, food recommendation systems analyze recipe
instructions to assess nutritional contents and provide recipe recommendations.
The recent and remarkable successes of generative AI methods, such as
auto-regressive large language models, can lead to robust methods for a more
comprehensive understanding of recipes for healthy food recommendations beyond
surface-level nutrition content assessments. In this study, we explore the use
of generative AI methods to extend current food computation models, primarily
involving the analysis of nutrition and ingredients, to also incorporate
cooking actions (e.g., add salt, fry the meat, boil the vegetables, etc.).
Cooking actions are notoriously hard to model using statistical learning
methods due to irregular data patterns - significantly varying natural language
descriptions for the same action (e.g., marinate the meat vs. marinate the meat
and leave overnight) and infrequently occurring patterns (e.g., add salt occurs
far more frequently than marinating the meat). The prototypical approach to
handling irregular data patterns is to increase the volume of data that the
model ingests by orders of magnitude. Unfortunately, in the cooking domain,
these problems are further compounded with larger data volumes presenting a
unique challenge that is not easily handled by simply scaling up. In this work,
we propose novel aggregation-based generative AI methods, Cook-Gen, that
reliably generate cooking actions from recipes, despite difficulties with
irregular data patterns, while also outperforming Large Language Models and
other strong baselines.
\\ ( https://arxiv.org/abs/2306.01805 ,  542kb)
------------------------------------------------------------------------------
\\
arXiv:2306.01807 (*cross-listing*)
Date: Fri, 2 Jun 2023 01:00:44 GMT   (398kb)

Title: Word Embeddings for Banking Industry
Authors: Avnish Patel
Categories: cs.CL cs.AI
Comments: 7 pages, 10 figures/tables
\\
 Applications of Natural Language Processing (NLP) are plentiful, from
sentiment analysis to text classification. Practitioners rely on static word
embeddings (e.g. Word2Vec or GloVe) or static word representation from
contextual models (e.g. BERT or ELMo) to perform many of these NLP tasks. These
widely available word embeddings are built from large amount of text, so they
are likely to have captured most of the vocabulary in different context.
However, how well would they capture domain-specific semantics and word
relatedness? This paper explores this idea by creating a bank-specific word
embeddings and evaluates them against other sources of word embeddings such as
GloVe and BERT. Not surprising that embeddings built from bank-specific corpora
does a better job of capturing the bank-specific semantics and word
relatedness. This finding suggests that bank-specific word embeddings could be
a good stand-alone source or a complement to other widely available embeddings
when performing NLP tasks specific to the banking industry.
\\ ( https://arxiv.org/abs/2306.01807 ,  398kb)
------------------------------------------------------------------------------
\\
arXiv:2306.01809 (*cross-listing*)
Date: Fri, 2 Jun 2023 03:11:32 GMT   (2492kb,D)

Title: Adversarial Attack Based on Prediction-Correction
Authors: Chen Wan, Fangjun Huang
Categories: cs.CR cs.AI cs.CV cs.LG
Comments: This manuscript was submitted to CVPR 2022
\\
 Deep neural networks (DNNs) are vulnerable to adversarial examples obtained
by adding small perturbations to original examples. The added perturbations in
existing attacks are mainly determined by the gradient of the loss function
with respect to the inputs. In this paper, the close relationship between
gradient-based attacks and the numerical methods for solving ordinary
differential equation (ODE) is studied for the first time. Inspired by the
numerical solution of ODE, a new prediction-correction (PC) based adversarial
attack is proposed. In our proposed PC-based attack, some existing attack can
be selected to produce a predicted example first, and then the predicted
example and the current example are combined together to determine the added
perturbations. The proposed method possesses good extensibility and can be
applied to all available gradient-based attacks easily. Extensive experiments
demonstrate that compared with the state-of-the-art gradient-based adversarial
attacks, our proposed PC-based attacks have higher attack success rates, and
exhibit better transferability.
\\ ( https://arxiv.org/abs/2306.01809 ,  2492kb)
------------------------------------------------------------------------------
\\
arXiv:2306.01819 (*cross-listing*)
Date: Fri, 2 Jun 2023 12:28:13 GMT   (1416kb)

Title: Comparative Analysis of Widely use Object-Oriented Languages
Authors: Muhammad Shoaib Farooq, Taymour zaman Khan
Categories: cs.PL cs.AI
Comments: 30 pages, figures 2
\\
 Programming is an integral part of computer science discipline. Every day the
programming environment is not only rapidly growing but also changing and
languages are constantly evolving. Learning of object-oriented paradigm is
compulsory in every computer science major so the choice of language to teach
object-oriented principles is very important. Due to large pool of
object-oriented languages, it is difficult to choose which should be the first
programming language in order to teach object-oriented principles. Many studies
shown which should be the first language to tech object-oriented concepts but
there is no method to compare and evaluate these languages. In this article we
proposed a comprehensive framework to evaluate the widely used object-oriented
languages. The languages are evaluated basis of their technical and
environmental features.
\\ ( https://arxiv.org/abs/2306.01819 ,  1416kb)
------------------------------------------------------------------------------
\\
arXiv:2306.01855 (*cross-listing*)
Date: Fri, 2 Jun 2023 18:17:52 GMT   (361kb,D)

Title: 5IDER: Unified Query Rewriting for Steering, Intent Carryover,
 Disfluencies, Entity Carryover and Repair
Authors: Jiarui Lu, Bo-Hsiang Tseng, Joel Ruben Antony Moniz, Site Li, Xueyun
 Zhu, Hong Yu, Murat Akbacak
Categories: cs.CL cs.AI cs.LG
Comments: Interspeech 2023
\\
 Providing voice assistants the ability to navigate multi-turn conversations
is a challenging problem. Handling multi-turn interactions requires the system
to understand various conversational use-cases, such as steering, intent
carryover, disfluencies, entity carryover, and repair. The complexity of this
problem is compounded by the fact that these use-cases mix with each other,
often appearing simultaneously in natural language. This work proposes a
non-autoregressive query rewriting architecture that can handle not only the
five aforementioned tasks, but also complex compositions of these use-cases. We
show that our proposed model has competitive single task performance compared
to the baseline approach, and even outperforms a fine-tuned T5 model in
use-case compositions, despite being 15 times smaller in parameters and 25
times faster in latency.
\\ ( https://arxiv.org/abs/2306.01855 ,  361kb)
------------------------------------------------------------------------------
\\
arXiv:2306.01930 (*cross-listing*)
Date: Fri, 2 Jun 2023 22:09:46 GMT   (4907kb,D)

Title: Large Language Models Converge on Brain-Like Word Representations
Authors: Jiaang Li, Antonia Karamolegkou, Yova Kementchedjhieva, Mostafa Abdou,
 Sune Lehmann, Anders S{\o}gaard
Categories: cs.CL cs.AI
Comments: Work in process
\\
 One of the greatest puzzles of all time is how understanding arises from
neural mechanics. Our brains are networks of billions of biological neurons
transmitting chemical and electrical signals along their connections. Large
language models are networks of millions or billions of digital neurons,
implementing functions that read the output of other functions in complex
networks. The failure to see how meaning would arise from such mechanics has
led many cognitive scientists and philosophers to various forms of dualism --
and many artificial intelligence researchers to dismiss large language models
as stochastic parrots or jpeg-like compressions of text corpora. We show that
human-like representations arise in large language models. Specifically, the
larger neural language models get, the more their representations are
structurally similar to neural response measurements from brain imaging.
\\ ( https://arxiv.org/abs/2306.01930 ,  4907kb)
------------------------------------------------------------------------------
\\
arXiv:2306.01931 (*cross-listing*)
Date: Fri, 2 Jun 2023 22:12:05 GMT   (446kb,D)

Title: Exploring semantic information in disease: Simple Data Augmentation
 Techniques for Chinese Disease Normalization
Authors: Wenqian Cui and Shaohui Liu and Xiangling Fu and Xien Liu and Ji Wu
Categories: cs.CL cs.AI
\\
 The disease is a core concept in the medical field, and the task of
normalizing disease names is the basis of all disease-related tasks. However,
due to the multi-axis and multi-grain nature of disease names, incorrect
information is often injected and harms the performance when using general text
data augmentation techniques. To address the above problem, we propose a set of
data augmentation techniques that work together as an augmented training task
for disease normalization. Our data augmentation methods are based on both the
clinical disease corpus and standard disease corpus derived from ICD-10 coding.
Extensive experiments are conducted to show the effectiveness of our proposed
methods. The results demonstrate that our methods can have up to 3\%
performance gain compared to non-augmented counterparts, and they can work even
better on smaller datasets.
\\ ( https://arxiv.org/abs/2306.01931 ,  446kb)
------------------------------------------------------------------------------
\\
arXiv:2306.01941 (*cross-listing*)
Date: Fri, 2 Jun 2023 22:51:26 GMT   (410kb,D)

Title: AI Transparency in the Age of LLMs: A Human-Centered Research Roadmap
Authors: Q. Vera Liao and Jennifer Wortman Vaughan
Categories: cs.HC cs.AI cs.CY
\\
 The rise of powerful large language models (LLMs) brings about tremendous
opportunities for innovation but also looming risks for individuals and society
at large. We have reached a pivotal moment for ensuring that LLMs and
LLM-infused applications are developed and deployed responsibly. However, a
central pillar of responsible AI -- transparency -- is largely missing from the
current discourse around LLMs. It is paramount to pursue new approaches to
provide transparency for LLMs, and years of research at the intersection of AI
and human-computer interaction (HCI) highlight that we must do so with a
human-centered perspective: Transparency is fundamentally about supporting
appropriate human understanding, and this understanding is sought by different
stakeholders with different goals in different contexts. In this new era of
LLMs, we must develop and design approaches to transparency by considering the
needs of stakeholders in the emerging LLM ecosystem, the novel types of
LLM-infused applications being built, and the new usage patterns and challenges
around LLMs, all while building on lessons learned about how people process,
interact with, and make use of information. We reflect on the unique challenges
that arise in providing transparency for LLMs, along with lessons learned from
HCI and responsible AI research that has taken a human-centered perspective on
AI transparency. We then lay out four common approaches that the community has
taken to achieve transparency -- model reporting, publishing evaluation
results, providing explanations, and communicating uncertainty -- and call out
open questions around how these approaches may or may not be applied to LLMs.
We hope this provides a starting point for discussion and a useful roadmap for
future research.
\\ ( https://arxiv.org/abs/2306.01941 ,  410kb)
------------------------------------------------------------------------------
\\
arXiv:2306.01944 (*cross-listing*)
Date: Fri, 2 Jun 2023 23:04:01 GMT   (2060kb,D)

Title: EdGCon: Auto-assigner of Iconicity Ratings Grounded by Lexical
 Properties to Aid in Generation of Technical Gestures
Authors: Sameena Hossain, Payal Kamboj, Aranyak Maity, Tamiko Azuma, Ayan
 Banerjee, Sandeep K. S. Gupta
Categories: cs.HC cs.AI cs.CL
Comments: Accepted for publication in ACM SAC 2023
Report-no: ILTR-2023-1
\\
 Gestures that share similarities in their forms and are related in their
meanings, should be easier for learners to recognize and incorporate into their
existing lexicon. In that regard, to be more readily accepted as standard by
the Deaf and Hard of Hearing community, technical gestures in American Sign
Language (ASL) will optimally share similar in forms with their lexical
neighbors. We utilize a lexical database of ASL, ASL-LEX, to identify lexical
relations within a set of technical gestures. We use automated identification
for 3 unique sub-lexical properties in ASL- location, handshape and movement.
EdGCon assigned an iconicity rating based on the lexical property similarities
of the new gesture with an existing set of technical gestures and the
relatedness of the meaning of the new technical word to that of the existing
set of technical words. We collected 30 ad hoc crowdsourced technical gestures
from different internet websites and tested them against 31 gestures from the
DeafTEC technical corpus. We found that EdGCon was able to correctly
auto-assign the iconicity ratings 80.76% of the time.
\\ ( https://arxiv.org/abs/2306.01944 ,  2060kb)
------------------------------------------------------------------------------
\\
arXiv:2306.01953 (*cross-listing*)
Date: Fri, 2 Jun 2023 23:29:28 GMT   (5721kb,D)

Title: Generative Autoencoders as Watermark Attackers: Analyses of
 Vulnerabilities and Threats
Authors: Xuandong Zhao, Kexun Zhang, Yu-Xiang Wang, Lei Li
Categories: cs.CR cs.AI cs.CV
\\
 Invisible watermarks safeguard images' copyrights by embedding hidden
messages detectable by owners. It also prevents people from misusing images,
especially those generated by AI models. Malicious adversaries can violate
these rights by removing the watermarks. In order to remove watermarks without
damaging the visual quality, the adversary needs to erase them while retaining
the essential information in the image. This is analogous to the encoding and
decoding process of generative autoencoders, especially variational
autoencoders (VAEs) and diffusion models. We propose a framework using
generative autoencoders to remove invisible watermarks and test it using VAEs
and diffusions. Our results reveal that, even without specific training,
off-the-shelf Stable Diffusion effectively removes most watermarks, surpassing
all current attackers. The result underscores the vulnerabilities in existing
watermarking schemes and calls for more robust methods for copyright
protection.
\\ ( https://arxiv.org/abs/2306.01953 ,  5721kb)
------------------------------------------------------------------------------
\\
arXiv:2306.01981 (*cross-listing*)
Date: Sat, 3 Jun 2023 02:27:08 GMT   (485kb,D)

Title: SGEM: Test-Time Adaptation for Automatic Speech Recognition via
 Sequential-Level Generalized Entropy Minimization
Authors: Changhun Kim, Joonhyung Park, Hajin Shim and Eunho Yang
Categories: eess.AS cs.AI cs.LG
Comments: Accepted to INTERSPEECH 2023
\\
 Automatic speech recognition (ASR) models are frequently exposed to data
distribution shifts in many real-world scenarios, leading to erroneous
predictions. To tackle this issue, an existing test-time adaptation (TTA)
method has recently been proposed to adapt the pre-trained ASR model on
unlabeled test instances without source data. Despite decent performance gain,
this work relies solely on naive greedy decoding and performs adaptation across
timesteps at a frame level, which may not be optimal given the sequential
nature of the model output. Motivated by this, we propose a novel TTA
framework, dubbed SGEM, for general ASR models. To treat the sequential output,
SGEM first exploits beam search to explore candidate output logits and selects
the most plausible one. Then, it utilizes generalized entropy minimization and
negative sampling as unsupervised objectives to adapt the model. SGEM achieves
state-of-the-art performance for three mainstream ASR models under various
domain shifts.
\\ ( https://arxiv.org/abs/2306.01981 ,  485kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02038 (*cross-listing*)
Date: Sat, 3 Jun 2023 07:32:25 GMT   (1082kb)

Title: Span Identification of Epistemic Stance-Taking in Academic Written
 English
Authors: Masaki Eguchi and Kristopher Kyle
Categories: cs.CL cs.AI cs.LG
Comments: The 18th Workshop on Innovative Use of NLP for Building Educational
 Applications
\\
 Responding to the increasing need for automated writing evaluation (AWE)
systems to assess language use beyond lexis and grammar (Burstein et al.,
2016), we introduce a new approach to identify rhetorical features of stance in
academic English writing. Drawing on the discourse-analytic framework of
engagement in the Appraisal analysis (Martin & White, 2005), we manually
annotated 4,688 sentences (126,411 tokens) for eight rhetorical stance
categories (e.g., PROCLAIM, ATTRIBUTION) and additional discourse elements. We
then report an experiment to train machine learning models to identify and
categorize the spans of these stance expressions. The best-performing model
(RoBERTa + LSTM) achieved macro-averaged F1 of .7208 in the span identification
of stance-taking expressions, slightly outperforming the intercoder reliability
estimates before adjudication (F1 = .6629).
\\ ( https://arxiv.org/abs/2306.02038 ,  1082kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02051 (*cross-listing*)
Date: Sat, 3 Jun 2023 08:39:25 GMT   (1601kb,D)

Title: A Comprehensive Survey on Deep Learning for Relation Extraction: Recent
 Advances and New Frontiers
Authors: Zhao Xiaoyan, Deng Yang, Yang Min, Wang Lingzhi, Zhang Rui, Cheng
 Hong, Lam Wai, Shen Ying, Xu Ruifeng
Categories: cs.CL cs.AI
\\
 Relation extraction (RE) involves identifying the relations between entities
from unstructured texts. RE serves as the foundation for many natural language
processing (NLP) applications, such as knowledge graph completion, question
answering, and information retrieval. In recent years, deep neural networks
have dominated the field of RE and made noticeable progress. Subsequently, the
large pre-trained language models (PLMs) have taken the state-of-the-art of RE
to a new level. This survey provides a comprehensive review of existing deep
learning techniques for RE. First, we introduce RE resources, including RE
datasets and evaluation metrics. Second, we propose a new taxonomy to
categorize existing works from three perspectives (text representation, context
encoding, and triplet prediction). Third, we discuss several important
challenges faced by RE and summarize potential techniques to tackle these
challenges. Finally, we outline some promising future directions and prospects
in this field. This survey is expected to facilitate researchers' collaborative
efforts to tackle the challenges of real-life RE systems.
\\ ( https://arxiv.org/abs/2306.02051 ,  1601kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02069 (*cross-listing*)
Date: Sat, 3 Jun 2023 10:10:38 GMT   (9587kb,D)

Title: MultiLegalPile: A 689GB Multilingual Legal Corpus
Authors: Joel Niklaus, Veton Matoshi, Matthias St\"urmer, Ilias Chalkidis,
 Daniel E. Ho
Categories: cs.CL cs.AI cs.LG
MSC-class: 68T50
ACM-class: I.2
\\
 Large, high-quality datasets are crucial for training \acp{LLM}. However, so
far, there are few datasets available for specialized critical domains such as
law and the available ones are often only for the English language. We curate
and release \textsc{MultiLegalPile}, a 689GB corpus in 24 languages from 17
jurisdictions. The \textsc{MultiLegalPile} corpus, which includes diverse legal
data sources with varying licenses, allows for pretraining NLP models under
fair use, with more permissive licenses for the Eurlex Resources and Legal mC4
subsets. We pretrain two RoBERTa models and one Longformer multilingually, and
24 monolingual models on each of the language-specific subsets and evaluate
them on LEXTREME. Additionally, we evaluate the English and multilingual models
on LexGLUE. Our multilingual models set a new SotA on LEXTREME and our English
models on LexGLUE. We release the dataset, the trained models, and all of the
code under the most open possible licenses.
\\ ( https://arxiv.org/abs/2306.02069 ,  9587kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02078 (*cross-listing*)
Date: Sat, 3 Jun 2023 10:56:44 GMT   (755kb,D)

Title: Incorporating Deep Syntactic and Semantic Knowledge for Chinese Sequence
 Labeling with GCN
Authors: Xuemei Tang, Jun Wang, Qi Su
Categories: cs.CL cs.AI
Comments: 10 pages,3 Figures, 6 Tables
\\
 Recently, it is quite common to integrate Chinese sequence labeling results
to enhance syntactic and semantic parsing. However, little attention has been
paid to the utility of hierarchy and structure information encoded in syntactic
and semantic features for Chinese sequence labeling tasks. In this paper, we
propose a novel framework to encode syntactic structure features and semantic
information for Chinese sequence labeling tasks with graph convolutional
networks (GCN). Experiments on five benchmark datasets, including Chinese word
segmentation and part-of-speech tagging, demonstrate that our model can
effectively improve the performance of Chinese labeling tasks.
\\ ( https://arxiv.org/abs/2306.02078 ,  755kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02174 (*cross-listing*)
Date: Sat, 3 Jun 2023 18:36:12 GMT   (5746kb,D)

Title: Training Data Attribution for Diffusion Models
Authors: Zheng Dai and David K Gifford
Categories: stat.ML cs.AI cs.LG
Comments: 14 pages, 6 figures
\\
 Diffusion models have become increasingly popular for synthesizing
high-quality samples based on training datasets. However, given the oftentimes
enormous sizes of the training datasets, it is difficult to assess how training
data impact the samples produced by a trained diffusion model. The difficulty
of relating diffusion model inputs and outputs poses significant challenges to
model explainability and training data attribution. Here we propose a novel
solution that reveals how training data influence the output of diffusion
models through the use of ensembles. In our approach individual models in an
encoded ensemble are trained on carefully engineered splits of the overall
training data to permit the identification of influential training examples.
The resulting model ensembles enable efficient ablation of training data
influence, allowing us to assess the impact of training data on model outputs.
We demonstrate the viability of these ensembles as generative models and the
validity of our approach to assessing influence.
\\ ( https://arxiv.org/abs/2306.02174 ,  5746kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02207 (*cross-listing*)
Date: Sat, 3 Jun 2023 22:35:27 GMT   (330kb,D)

Title: SpeechGen: Unlocking the Generative Power of Speech Language Models with
 Prompts
Authors: Haibin Wu, Kai-Wei Chang, Yuan-Kuei Wu, Hung-yi Lee
Categories: eess.AS cs.AI cs.CL cs.LG
Comments: Work in progress. The first three authors contributed equally
\\
 Large language models (LLMs) have gained considerable attention for
Artificial Intelligence Generated Content (AIGC), particularly with the
emergence of ChatGPT. However, the direct adaptation of continuous speech to
LLMs that process discrete tokens remains an unsolved challenge, hindering the
application of LLMs for speech generation. The advanced speech LMs are in the
corner, as that speech signals encapsulate a wealth of information, including
speaker and emotion, beyond textual data alone. Prompt tuning has demonstrated
notable gains in parameter efficiency and competitive performance on some
speech classification tasks. However, the extent to which prompts can
effectively elicit generation tasks from speech LMs remains an open question.
In this paper, we present pioneering research that explores the application of
prompt tuning to stimulate speech LMs for various generation tasks, within a
unified framework called SpeechGen, with around 10M trainable parameters. The
proposed unified framework holds great promise for efficiency and
effectiveness, particularly with the imminent arrival of advanced speech LMs,
which will significantly enhance the capabilities of the framework. The code
and demos of SpeechGen will be available on the project website:
\url{https://ga642381.github.io/SpeechPrompt/speechgen}
\\ ( https://arxiv.org/abs/2306.02207 ,  330kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02221 (*cross-listing*)
Date: Sun, 4 Jun 2023 00:32:45 GMT   (6095kb,D)

Title: ATEM: A Topic Evolution Model for the Detection of Emerging Topics in
 Scientific Archives
Authors: Hamed Rahimi, Hubert Naacke, Camelia Constantin, Bernd Amann
Categories: cs.IR cs.AI
\\
 This paper presents ATEM, a novel framework for studying topic evolution in
scientific archives. ATEM is based on dynamic topic modeling and dynamic graph
embedding techniques that explore the dynamics of content and citations of
documents within a scientific corpus. ATEM explores a new notion of contextual
emergence for the discovery of emerging interdisciplinary research topics based
on the dynamics of citation links in topic clusters. Our experiments show that
ATEM can efficiently detect emerging cross-disciplinary topics within the DBLP
archive of over five million computer science articles.
\\ ( https://arxiv.org/abs/2306.02221 ,  6095kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02231 (*cross-listing*)
Date: Sun, 4 Jun 2023 01:59:40 GMT   (114kb,D)

Title: Fine-Tuning Language Models with Advantage-Induced Policy Alignment
Authors: Banghua Zhu, Hiteshi Sharma, Felipe Vieira Frujeri, Shi Dong,
 Chenguang Zhu, Michael I. Jordan, Jiantao Jiao
Categories: cs.CL cs.AI cs.LG cs.SY eess.SY
\\
 Reinforcement learning from human feedback (RLHF) has emerged as a reliable
approach to aligning large language models (LLMs) to human preferences. Among
the plethora of RLHF techniques, proximal policy optimization (PPO) is of the
most widely used methods. Despite its popularity, however, PPO may suffer from
mode collapse, instability, and poor sample efficiency. We show that these
issues can be alleviated by a novel algorithm that we refer to as
Advantage-Induced Policy Alignment (APA), which leverages a squared error loss
function based on the estimated advantages. We demonstrate empirically that APA
consistently outperforms PPO in language tasks by a large margin, when a
separate reward model is employed as the evaluator. In addition, compared with
PPO, APA offers a more stable form of control over the deviation from the
model's initial policy, ensuring that the model improves its performance
without collapsing to deterministic output. In addition to empirical results,
we also provide a theoretical justification supporting the design of our loss
function.
\\ ( https://arxiv.org/abs/2306.02231 ,  114kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02242 (*cross-listing*)
Date: Sun, 4 Jun 2023 03:05:25 GMT   (203kb,D)

Title: Extract and Attend: Improving Entity Translation in Neural Machine
 Translation
Authors: Zixin Zeng, Rui Wang, Yichong Leng, Junliang Guo, Xu Tan, Tao Qin,
 Tie-yan Liu
Categories: cs.CL cs.AI
\\
 While Neural Machine Translation(NMT) has achieved great progress in recent
years, it still suffers from inaccurate translation of entities (e.g.,
person/organization name, location), due to the lack of entity training
instances. When we humans encounter an unknown entity during translation, we
usually first look up in a dictionary and then organize the entity translation
together with the translations of other parts to form a smooth target sentence.
Inspired by this translation process, we propose an Extract-and-Attend approach
to enhance entity translation in NMT, where the translation candidates of
source entities are first extracted from a dictionary and then attended to by
the NMT model to generate the target sentence. Specifically, the translation
candidates are extracted by first detecting the entities in a source sentence
and then translating the entities through looking up in a dictionary. Then, the
extracted candidates are added as a prefix of the decoder input to be attended
to by the decoder when generating the target sentence through self-attention.
Experiments conducted on En-Zh and En-Ru demonstrate that the proposed method
is effective on improving both the translation accuracy of entities and the
overall translation quality, with up to 35% reduction on entity error rate and
0.85 gain on BLEU and 13.8 gain on COMET.
\\ ( https://arxiv.org/abs/2306.02242 ,  203kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02247 (*cross-listing*)
Date: Sun, 4 Jun 2023 03:26:43 GMT   (6424kb,D)

Title: Sen2Pro: A Probabilistic Perspective to Sentence Embedding from
 Pre-trained Language Model
Authors: Lingfeng Shen, Haiyun Jiang, Lemao Liu, Shuming Shi
Categories: cs.CL cs.AI
Comments: Accepted to ACL2023 workshop Rep4NLP
\\
 Sentence embedding is one of the most fundamental tasks in Natural Language
Processing and plays an important role in various tasks. The recent
breakthrough in sentence embedding is achieved by pre-trained language models
(PLMs). Despite its success, an embedded vector (Sen2Vec) representing a point
estimate does not naturally express uncertainty in a taskagnostic way. This
paper thereby proposes an efficient framework on probabilistic sentence
embedding (Sen2Pro) from PLMs, and it represents a sentence as a probability
density distribution in an embedding space to reflect both model uncertainty
and data uncertainty (i.e., many-to-one nature) in the sentence representation.
The proposed framework performs in a plug-and-play way without retraining PLMs
anymore, and it is easy to implement and generally applied on top of any PLM.
The superiority of Sen2Pro over Sen2Vec has been theoretically verified and
practically illustrated on different NLP tasks.
\\ ( https://arxiv.org/abs/2306.02247 ,  6424kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02282 (*cross-listing*)
Date: Sun, 4 Jun 2023 07:01:30 GMT   (10829kb,D)

Title: Exploring and Verbalizing Academic Ideas by Concept Co-occurrence
Authors: Yi Xu, Shuqian Sheng, Bo Xue, Luoyi Fu, Xinbing Wang, Chenghu Zhou
Categories: cs.CL cs.AI
Comments: Accepted by ACL 2023
\\
 Researchers usually come up with new ideas only after thoroughly
comprehending vast quantities of literature. The difficulty of this procedure
is exacerbated by the fact that the number of academic publications is growing
exponentially. In this study, we devise a framework based on concept
co-occurrence for academic idea inspiration, which has been integrated into a
research assistant system. From our perspective, the fusion of two concepts
that co-occur in an academic paper can be regarded as an important way of the
emergence of a new idea. We construct evolving concept graphs according to the
co-occurrence relationship of concepts from 20 disciplines or topics. Then we
design a temporal link prediction method based on masked language model to
explore potential connections between different concepts. To verbalize the
newly discovered connections, we also utilize the pretrained language model to
generate a description of an idea based on a new data structure called
co-occurrence citation quintuple. We evaluate our proposed system using both
automatic metrics and human assessment. The results demonstrate that our system
has broad prospects and can assist researchers in expediting the process of
discovering new ideas.
\\ ( https://arxiv.org/abs/2306.02282 ,  10829kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02296 (*cross-listing*)
Date: Sun, 4 Jun 2023 08:13:33 GMT   (931kb)

Title: Onsite Job Scheduling by Adaptive Genetic Algorithm
Authors: Avijit Basak, Subhas Acharya
Categories: math.OC cs.AI cs.NE
\\
 Onsite Job Scheduling is a specialized variant of Vehicle Routing Problem
(VRP) with multiple depots. The objective of this problem is to execute jobs
requested by customers, belonging to different geographic locations by a
limited number of technicians, with minimum travel and overtime of technicians.
Each job is expected to be completed within a specified time limit according to
the service level agreement with customers. Each technician is assumed to start
from a base location, serve several customers and return to the starting place.
Technicians are allotted jobs based on their skill sets, expertise levels of
each skill and availability slots. Although there are considerable number of
literatures on VRP we do not see any explicit work related to Onsite Job
Scheduling. In this paper we have proposed an Adaptive Genetic Algorithm to
solve the scheduling problem. We found an optimized travel route for a
substantial number of jobs and technicians, minimizing travel distance,
overtime duration as well as meeting constraints related to SLA.
\\ ( https://arxiv.org/abs/2306.02296 ,  931kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02307 (*cross-listing*)
Date: Sun, 4 Jun 2023 09:16:39 GMT   (8202kb,D)

Title: Finding the SWEET Spot: Analysis and Improvement of Adaptive Inference
 in Low Resource Settings
Authors: Daniel Rotem, Michael Hassid, Jonathan Mamou, Roy Schwartz
Categories: cs.CL cs.AI cs.LG
Comments: Proceedings of ACL 2023
\\
 Adaptive inference is a simple method for reducing inference costs. The
method works by maintaining multiple classifiers of different capacities, and
allocating resources to each test instance according to its difficulty. In this
work, we compare the two main approaches for adaptive inference, Early-Exit and
Multi-Model, when training data is limited. First, we observe that for models
with the same architecture and size, individual Multi-Model classifiers
outperform their Early-Exit counterparts by an average of 2.3%. We show that
this gap is caused by Early-Exit classifiers sharing model parameters during
training, resulting in conflicting gradient updates of model weights. We find
that despite this gap, Early-Exit still provides a better speed-accuracy
trade-off due to the overhead of the Multi-Model approach. To address these
issues, we propose SWEET (Separating Weights in Early Exit Transformers), an
Early-Exit fine-tuning method that assigns each classifier its own set of
unique model weights, not updated by other classifiers. We compare SWEET's
speed-accuracy curve to standard Early-Exit and Multi-Model baselines and find
that it outperforms both methods at fast speeds while maintaining comparable
scores to Early-Exit at slow speeds. Moreover, SWEET individual classifiers
outperform Early-Exit ones by 1.1% on average. SWEET enjoys the benefits of
both methods, paving the way for further reduction of inference costs in NLP.
\\ ( https://arxiv.org/abs/2306.02307 ,  8202kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02317 (*cross-listing*)
Date: Sun, 4 Jun 2023 10:00:12 GMT   (1015kb,D)

Title: SpellMapper: A non-autoregressive neural spellchecker for ASR
 customization with candidate retrieval based on n-gram mappings
Authors: Alexandra Antonova, Evelina Bakhturina, Boris Ginsburg
Categories: cs.CL cs.AI cs.SD eess.AS
Comments: Accepted by INTERSPEECH 2023
\\
 Contextual spelling correction models are an alternative to shallow fusion to
improve automatic speech recognition (ASR) quality given user vocabulary. To
deal with large user vocabularies, most of these models include candidate
retrieval mechanisms, usually based on minimum edit distance between fragments
of ASR hypothesis and user phrases. However, the edit-distance approach is
slow, non-trainable, and may have low recall as it relies only on common
letters. We propose: 1) a novel algorithm for candidate retrieval, based on
misspelled n-gram mappings, which gives up to 90% recall with just the top 10
candidates on Spoken Wikipedia; 2) a non-autoregressive neural model based on
BERT architecture, where the initial transcript and ten candidates are combined
into one input. The experiments on Spoken Wikipedia show 21.4% word error rate
improvement compared to a baseline ASR system.
\\ ( https://arxiv.org/abs/2306.02317 ,  1015kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02320 (*cross-listing*)
Date: Sun, 4 Jun 2023 10:10:54 GMT   (1979kb,D)

Title: Arbitrary Few Parameters are Good Enough for Adapting Large-scale
 Pre-trained Language Models
Authors: Yusheng Su, Chi-Min Chan, Jiali Cheng, Yujia Qin, Yankai Lin,
 Shengding Hu, Zonghan Yang, Ning Ding, Zhiyuan Liu, Maosong Sun
Categories: cs.CL cs.AI
\\
 Parameter-efficient tuning (PET) methods can effectively drive extremely
large pre-trained language models (PLMs) by only training minimal parameters.
Different PET methods utilize different manually designed modules. In a small
PLM, there are usually noticeable performance differences among PET methods.
Nevertheless, when a PLM's scale grows up to tens of billions of parameters,
all PET methods achieve almost the same performance and even perform on par
with the full-parameter fine-tuning method. Hence, we hypothesize that model
scaling can mitigate the design differences (the module structures and the
number of trainable parameters) among PET methods. To study this hypothesis, we
introduce a more flexible PET method - arbitrary PET (APET) method - to be
compatible with arbitrary module structures and any number of trainable
parameters. Then, we experiment on $11$ NLP tasks of $5$ types and $2$
representative PLMs. From our investigations, we find that the model scaling
(1) mitigates the effects of the arbitrary module structure on the performance
of tuning methods, and (2) enables the tuning methods to optimize fewer
parameters to achieve the full-parameter fine-tuning performance. Intriguingly,
we also observe that all tuning methods require almost the same number of
trainable parameters to drive PLMs. We discuss this phenomenon and the above
two findings collectively from optimization perspectives to fathom the
mechanisms behind them. These conclusions not only demonstrate the positive
impact of model scaling on tuning methods but disclose its mechanisms, which
help us design more effective and efficient tuning methods on larger-scale
PLMs.
\\ ( https://arxiv.org/abs/2306.02320 ,  1979kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02388 (*cross-listing*)
Date: Sun, 4 Jun 2023 15:44:51 GMT   (10036kb,D)

Title: Commonsense Knowledge Transfer for Pre-trained Language Models
Authors: Wangchunshu Zhou, Ronan Le Bras, Yejin Choi
Categories: cs.CL cs.AI cs.LG
Comments: ACL 2023 Findings
\\
 Despite serving as the foundation models for a wide range of NLP benchmarks,
pre-trained language models have shown limited capabilities of acquiring
implicit commonsense knowledge from self-supervision alone, compared to
learning linguistic and factual knowledge that appear more explicitly in the
surface patterns in text. In this work, we introduce commonsense knowledge
transfer, a framework to transfer the commonsense knowledge stored in a neural
commonsense knowledge model to a general-purpose pre-trained language model. It
first exploits general texts to form queries for extracting commonsense
knowledge from the neural commonsense knowledge model and then refines the
language model with two self-supervised objectives: commonsense mask infilling
and commonsense relation prediction, which align human language with the
underlying commonsense knowledge. Empirical results show that our approach
consistently improves the model's performance on downstream tasks that require
commonsense reasoning. Moreover, we find that the improvement is more
significant in the few-shot setting. This suggests that our approach helps
language models better transfer to downstream tasks without extensive
supervision by injecting commonsense knowledge into their parameters.
\\ ( https://arxiv.org/abs/2306.02388 ,  10036kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02411 (*cross-listing*)
Date: Sun, 4 Jun 2023 17:08:41 GMT   (1038kb,D)

Title: A Topological Approach to Measuring Training Data Quality
Authors: \'Alvaro Torras-Casas, Eduardo Paluzo-Hidalgo, Rocio Gonzalez-Diaz
Categories: math.AT cs.AI cs.LG
\\
 Data quality is crucial for the successful training, generalization and
performance of artificial intelligence models. Furthermore, it is known that
the leading approaches in artificial intelligence are notoriously data-hungry.
In this paper, we propose the use of small training datasets towards faster
training. Specifically, we provide a novel topological method based on
morphisms between persistence modules to measure the training data quality with
respect to the complete dataset. This way, we can provide an explanation of why
the chosen training dataset will lead to poor performance.
\\ ( https://arxiv.org/abs/2306.02411 ,  1038kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02428 (*cross-listing*)
Date: Sun, 4 Jun 2023 18:21:44 GMT   (1113kb)

Title: Taught by the Internet, Exploring Bias in OpenAIs GPT3
Authors: Ali Ayaz, Aditya Nawalgaria, Ruilian Yin
Categories: cs.CL cs.AI
\\
 This research delves into the current literature on bias in Natural Language
Processing Models and the techniques proposed to mitigate the problem of bias,
including why it is important to tackle bias in the first place. Additionally,
these techniques are further analysed in the light of newly developed models
that tower in size over past editions. To achieve those aims, the authors of
this paper conducted their research on GPT3 by OpenAI, the largest NLP model
available to consumers today. With 175 billion parameters in contrast to BERTs
340 million, GPT3 is the perfect model to test the common pitfalls of NLP
models. Tests were conducted through the development of an Applicant Tracking
System using GPT3. For the sake of feasibility and time constraints, the tests
primarily focused on gender bias, rather than all or multiple types of bias.
Finally, current mitigation techniques are considered and tested to measure
their degree of functionality.
\\ ( https://arxiv.org/abs/2306.02428 ,  1113kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02457 (*cross-listing*)
Date: Sun, 4 Jun 2023 20:18:40 GMT   (2783kb,D)

Title: Adaptive and Personalized Exercise Generation for Online Language
 Learning
Authors: Peng Cui, Mrinmaya Sachan
Categories: cs.CL cs.AI
Comments: To appear at ACL 2023
\\
 Adaptive learning aims to provide customized educational activities (e.g.,
exercises) to address individual learning needs. However, manual construction
and delivery of such activities is a laborious process. Thus, in this paper, we
study a novel task of adaptive and personalized exercise generation for online
language learning. To this end, we combine a knowledge tracing model that
estimates each student's evolving knowledge states from their learning history
and a controlled text generation model that generates exercise sentences based
on the student's current estimated knowledge state and instructor requirements
of desired properties (e.g., domain knowledge and difficulty). We train and
evaluate our model on real-world learner interaction data from Duolingo and
demonstrate that LMs guided by student states can generate superior exercises.
Then, we discuss the potential use of our model in educational applications
using various simulations. These simulations show that our model can adapt to
students' individual abilities and can facilitate their learning efficiency by
personalizing learning sequences.
\\ ( https://arxiv.org/abs/2306.02457 ,  2783kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02520 (*cross-listing*)
Date: Mon, 5 Jun 2023 01:01:12 GMT   (308kb,D)

Title: A Study of Situational Reasoning for Traffic Understanding
Authors: Jiarui Zhang, Filip Ilievski, Kaixin Ma, Aravinda Kollaa, Jonathan
 Francis, Alessandro Oltramari
Categories: cs.CL cs.AI cs.LG
Comments: 11 pages, 6 figures, 5 tables, camera ready version of SIGKDD 2023
DOI: 10.1145/3580305.3599246
\\
 Intelligent Traffic Monitoring (ITMo) technologies hold the potential for
improving road safety/security and for enabling smart city infrastructure.
Understanding traffic situations requires a complex fusion of perceptual
information with domain-specific and causal commonsense knowledge. Whereas
prior work has provided benchmarks and methods for traffic monitoring, it
remains unclear whether models can effectively align these information sources
and reason in novel scenarios. To address this assessment gap, we devise three
novel text-based tasks for situational reasoning in the traffic domain: i)
BDD-QA, which evaluates the ability of Language Models (LMs) to perform
situational decision-making, ii) TV-QA, which assesses LMs' abilities to reason
about complex event causality, and iii) HDT-QA, which evaluates the ability of
models to solve human driving exams. We adopt four knowledge-enhanced methods
that have shown generalization capability across language reasoning tasks in
prior work, based on natural language inference, commonsense knowledge-graph
self-supervision, multi-QA joint training, and dense retrieval of domain
information. We associate each method with a relevant knowledge source,
including knowledge graphs, relevant benchmarks, and driving manuals. In
extensive experiments, we benchmark various knowledge-aware methods against the
three datasets, under zero-shot evaluation; we provide in-depth analyses of
model performance on data partitions and examine model predictions
categorically, to yield useful insights on traffic understanding, given
different background knowledge and reasoning strategies.
\\ ( https://arxiv.org/abs/2306.02520 ,  308kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02521 (*cross-listing*)
Date: Mon, 5 Jun 2023 01:10:23 GMT   (270kb)

Title: Connecting Proof Theory and Knowledge Representation: Sequent Calculi
 and the Chase with Existential Rules
Authors: Tim S. Lyon and Piotr Ostropolski-Nalewaja
Categories: cs.LO cs.AI cs.DB math.LO
Comments: Appended version of paper accepted to KR 2023
\\
 Chase algorithms are indispensable in the domain of knowledge base querying,
which enable the extraction of implicit knowledge from a given database via
applications of rules from a given ontology. Such algorithms have proved
beneficial in identifying logical languages which admit decidable query
entailment. Within the discipline of proof theory, sequent calculi have been
used to write and design proof-search algorithms to identify decidable classes
of logics. In this paper, we show that the chase mechanism in the context of
existential rules is in essence the same as proof-search in an extension of
Gentzen's sequent calculus for first-order logic. Moreover, we show that
proof-search generates universal models of knowledge bases, a feature also
exhibited by the chase. Thus, we formally connect a central tool for
establishing decidability proof-theoretically with a central decidability tool
in the context of knowledge representation.
\\ ( https://arxiv.org/abs/2306.02521 ,  270kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02549 (*cross-listing*)
Date: Mon, 5 Jun 2023 02:52:54 GMT   (160kb,D)

Title: Evaluation of AI Chatbots for Patient-Specific EHR Questions
Authors: Alaleh Hamidi and Kirk Roberts
Categories: cs.CL cs.AI cs.IR
\\
 This paper investigates the use of artificial intelligence chatbots for
patient-specific question answering (QA) from clinical notes using several
large language model (LLM) based systems: ChatGPT (versions 3.5 and 4), Google
Bard, and Claude. We evaluate the accuracy, relevance, comprehensiveness, and
coherence of the answers generated by each model using a 5-point Likert scale
on a set of patient-specific questions.
\\ ( https://arxiv.org/abs/2306.02549 ,  160kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02552 (*cross-listing*)
Date: Mon, 5 Jun 2023 02:58:35 GMT   (1324kb,D)

Title: RecAgent: A Novel Simulation Paradigm for Recommender Systems
Authors: Lei Wang and Jingsen Zhang and Xu Chen and Yankai Lin and Ruihua Song
 and Wayne Xin Zhao and Ji-Rong Wen
Categories: cs.IR cs.AI
Comments: 12 pages, 2 figures
\\
 Recommender system has deeply revolutionized people's daily life and
production, bringing a large amount of business value. In the recommendation
domain, simulation and real data-based studies are two typical research
paradigms, with each having different advantages. Previously, real data-based
studies occupy more important positions, since accurately simulating the user
preference is quite difficult. Recently, large language models (LLM) have shown
great potential to achieve human-like intelligence, which provides new
opportunities to overcome the shortcomings of simulation-based studies and thus
highlight their advantages, such as much more application scenarios and cheaper
data acquisition strategies. To shed lights on this direction, in this paper,
we introduce an LLM-based recommender simulator called RecAgent. Our simulator
is composed of two modules: (1) the user module and (2) the recommender module.
The user module can browse the recommendation website, communicate with other
users and broadcast messages on the social media. The recommender module is
designed to provide search or recommendation lists to the users, and one can
design different models to implement the recommender. All the users take
actions based on LLMs, and can freely evolve like in the real world. We present
several case studies to demonstrate that the users in our simulator can indeed
behave in a reasonable manner as expected. Our project has been released at
https://github.com/RUC-GSAI/YuLan-Rec.
\\ ( https://arxiv.org/abs/2306.02552 ,  1324kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02557 (*cross-listing*)
Date: Mon, 5 Jun 2023 03:12:11 GMT   (1034kb,D)

Title: Detecting individual-level infections using sparse group-testing through
 graph-coupled hidden Markov models
Authors: Zahra Gholamalian, Zeinab Maleki, MasoudReza Hashemi, Pouria Ramazi
Categories: stat.AP cs.AI
\\
 Identifying the infection status of each individual during infectious
diseases informs public health management. However, performing frequent
individual-level tests may not be feasible. Instead, sparse and sometimes
group-level tests are performed. Determining the infection status of
individuals using sparse group-level tests remains an open problem. We have
tackled this problem by extending graph-coupled hidden Markov models with
individuals infection statuses as the hidden states and the group test results
as the observations. We fitted the model to simulation datasets using the Gibbs
sampling method. The model performed about 0.55 AUC for low testing frequencies
and increased to 0.80 AUC in the case where the groups were tested every day.
The model was separately tested on a daily basis case to predict the statuses
over time and after 15 days of the beginning of the spread, which resulted in
0.98 AUC at day 16 and remained above 0.80 AUC until day 128. Therefore,
although dealing with sparse tests remains unsolved, the results open the
possibility of using initial group screenings during pandemics to accurately
estimate individuals infection statuses.
\\ ( https://arxiv.org/abs/2306.02557 ,  1034kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02561 (*cross-listing*)
Date: Mon, 5 Jun 2023 03:32:26 GMT   (3429kb,D)

Title: LLM-Blender: Ensembling Large Language Models with Pairwise Ranking and
 Generative Fusion
Authors: Dongfu Jiang, Xiang Ren, Bill Yuchen Lin
Categories: cs.CL cs.AI cs.LG
Comments: ACL 2023 (Main conference). Project website:
 https://yuchenlin.xyz/LLM-Blender/
\\
 We present LLM-Blender, an ensembling framework designed to attain
consistently superior performance by leveraging the diverse strengths of
multiple open-source large language models (LLMs). Our framework consists of
two modules: PairRanker and GenFuser, addressing the observation that optimal
LLMs for different examples can significantly vary. PairRanker employs a
specialized pairwise comparison method to distinguish subtle differences
between candidate outputs. It jointly encodes the input text and a pair of
candidates, using cross-attention encoders to determine the superior one. Our
results demonstrate that PairRanker exhibits the highest correlation with
ChatGPT-based ranking. Then, GenFuser aims to merge the top-ranked candidates,
generating an improved output by capitalizing on their strengths and mitigating
their weaknesses. To facilitate large-scale evaluation, we introduce a
benchmark dataset, MixInstruct, which is a mixture of multiple instruction
datasets featuring oracle pairwise comparisons. Our LLM-Blender significantly
outperform individual LLMs and baseline methods across various metrics,
establishing a substantial performance gap.
\\ ( https://arxiv.org/abs/2306.02561 ,  3429kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02592 (*cross-listing*)
Date: Mon, 5 Jun 2023 04:46:44 GMT   (3410kb,D)

Title: Graph-Aware Language Model Pre-Training on a Large Graph Corpus Can Help
 Multiple Graph Applications
Authors: Han Xie, Da Zheng, Jun Ma, Houyu Zhang, Vassilis N. Ioannidis, Xiang
 Song, Qing Ping, Sheng Wang, Carl Yang, Yi Xu, Belinda Zeng, Trishul Chilimbi
Categories: cs.CL cs.AI cs.LG
Comments: To be published in the KDD 2023 proceedings as a full paper
\\
 Model pre-training on large text corpora has been demonstrated effective for
various downstream applications in the NLP domain. In the graph mining domain,
a similar analogy can be drawn for pre-training graph models on large graphs in
the hope of benefiting downstream graph applications, which has also been
explored by several recent studies. However, no existing study has ever
investigated the pre-training of text plus graph models on large heterogeneous
graphs with abundant textual information (a.k.a. large graph corpora) and then
fine-tuning the model on different related downstream applications with
different graph schemas. To address this problem, we propose a framework of
graph-aware language model pre-training (GALM) on a large graph corpus, which
incorporates large language models and graph neural networks, and a variety of
fine-tuning methods on downstream applications. We conduct extensive
experiments on Amazon's real internal datasets and large public datasets.
Comprehensive empirical results and in-depth analysis demonstrate the
effectiveness of our proposed methods along with lessons learned.
\\ ( https://arxiv.org/abs/2306.02592 ,  3410kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02608 (*cross-listing*)
Date: Mon, 5 Jun 2023 05:43:35 GMT   (1093kb,D)

Title: Computing Education in the Era of Generative AI
Authors: Paul Denny and James Prather and Brett A. Becker and James
 Finnie-Ansley and Arto Hellas and Juho Leinonen and Andrew Luxton-Reilly and
 Brent N. Reeves and Eddie Antonio Santos and Sami Sarsa
Categories: cs.CY cs.AI cs.HC
Comments: Accepted for publication as a Contributed Article in Communications
 of the ACM (CACM)
\\
 The computing education community has a rich history of pedagogical
innovation designed to support students in introductory courses, and to support
teachers in facilitating student learning. Very recent advances in artificial
intelligence have resulted in code generation models that can produce source
code from natural language problem descriptions -- with impressive accuracy in
many cases. The wide availability of these models and their ease of use has
raised concerns about potential impacts on many aspects of society, including
the future of computing education. In this paper, we discuss the challenges and
opportunities such models present to computing educators, with a focus on
introductory programming classrooms. We summarize the results of two recent
articles, the first evaluating the performance of code generation models on
typical introductory-level programming problems, and the second exploring the
quality and novelty of learning resources generated by these models. We
consider likely impacts of such models upon pedagogical practice in the context
of the most recent advances at the time of writing.
\\ ( https://arxiv.org/abs/2306.02608 ,  1093kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02611 (*cross-listing*)
Date: Mon, 5 Jun 2023 05:54:56 GMT   (283kb,D)

Title: Stochastic Population Update Can Provably Be Helpful in Multi-Objective
 Evolutionary Algorithms
Authors: Chao Bian, Yawen Zhou, Miqing Li, Chao Qian
Categories: cs.NE cs.AI
\\
 Evolutionary algorithms (EAs) have been widely and successfully applied to
solve multi-objective optimization problems, due to their nature of
population-based search. Population update is a key component in
multi-objective EAs (MOEAs), and it is performed in a greedy, deterministic
manner. That is, the next-generation population is formed by selecting the
first population-size ranked solutions (based on some selection criteria, e.g.,
non-dominated sorting, crowdedness and indicators) from the collections of the
current population and newly-generated solutions. In this paper, we question
this practice. We analytically present that introducing randomness into the
population update procedure in MOEAs can be beneficial for the search. More
specifically, we prove that the expected running time of a well-established
MOEA (SMS-EMOA) for solving a commonly studied bi-objective problem,
OneJumpZeroJump, can be exponentially decreased if replacing its deterministic
population update mechanism by a stochastic one. Empirical studies also verify
the effectiveness of the proposed stochastic population update method. This
work is an attempt to challenge a common practice for the population update in
MOEAs. Its positive results, which might hold more generally, should encourage
the exploration of developing new MOEAs in the area.
\\ ( https://arxiv.org/abs/2306.02611 ,  283kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02613 (*cross-listing*)
Date: Mon, 5 Jun 2023 06:14:08 GMT   (2440kb,D)

Title: Controllable Lyrics-to-Melody Generation
Authors: Zhe Zhang, Yi Yu, Atsuhiro Takasu
Categories: cs.SD cs.AI eess.AS
\\
 Lyrics-to-melody generation is an interesting and challenging topic in AI
music research field. Due to the difficulty of learning the correlations
between lyrics and melody, previous methods suffer from low generation quality
and lack of controllability. Controllability of generative models enables human
interaction with models to generate desired contents, which is especially
important in music generation tasks towards human-centered AI that can
facilitate musicians in creative activities. To address these issues, we
propose a controllable lyrics-to-melody generation network, ConL2M, which is
able to generate realistic melodies from lyrics in user-desired musical style.
Our work contains three main novelties: 1) To model the dependencies of music
attributes cross multiple sequences, inter-branch memory fusion (Memofu) is
proposed to enable information flow between multi-branch stacked LSTM
architecture; 2) Reference style embedding (RSE) is proposed to improve the
quality of generation as well as control the musical style of generated
melodies; 3) Sequence-level statistical loss (SeqLoss) is proposed to help the
model learn sequence-level features of melodies given lyrics. Verified by
evaluation metrics for music quality and controllability, initial study of
controllable lyrics-to-melody generation shows better generation quality and
the feasibility of interacting with users to generate the melodies in desired
musical styles when given lyrics.
\\ ( https://arxiv.org/abs/2306.02613 ,  2440kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02769 (*cross-listing*)
Date: Mon, 5 Jun 2023 10:53:27 GMT   (124kb,D)

Title: On simple expectations and observations of intelligent agents: A
 complexity study
Authors: Sourav Chakraborty, Avijeet Ghosh, Sujata Ghosh and Fran\c{c}ois
 Schwarzentruber
Categories: cs.LO cs.AI cs.CC
Comments: Accepted in KR 2023
\\
 Public observation logic (POL) reasons about agent expectations and agent
observations in various real world situations. The expectations of agents take
shape based on certain protocols about the world around and they remove those
possible scenarios where their expectations and observations do not match. This
in turn influences the epistemic reasoning of these agents. In this work, we
study the computational complexity of the satisfaction problems of various
fragments of POL. In the process, we also highlight the inevitable link that
these fragments have with the well-studied Public announcement logic.
\\ ( https://arxiv.org/abs/2306.02769 ,  124kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02771 (*cross-listing*)
Date: Mon, 5 Jun 2023 10:55:15 GMT   (24kb,D)

Title: Identifying the style by a qualified reader on a short fragment of
 generated poetry
Authors: Boris Orekhov
Categories: cs.CL cs.AI cs.LG
Comments: 6 pages, 2 tables
\\
 Style is an important concept in today's challenges in natural language
generating. After the success in the field of image style transfer, the task of
text style transfer became actual and attractive. Researchers are also
interested in the tasks of style reproducing in generation of the poetic text.
Evaluation of style reproducing in natural poetry generation remains a problem.
I used 3 character-based LSTM-models to work with style reproducing assessment.
All three models were trained on the corpus of texts by famous Russian-speaking
poets. Samples were shown to the assessors and 4 answer options were offered,
the style of which poet this sample reproduces. In addition, the assessors were
asked how well they were familiar with the work of the poet they had named.
Students studying history of literature were the assessors, 94 answers were
received. It has appeared that accuracy of definition of style increases if the
assessor can quote the poet by heart. Each model showed at least 0.7
macro-average accuracy. The experiment showed that it is better to involve a
professional rather than a naive reader in the evaluation of style in the tasks
of poetry generation, while lstm models are good at reproducing the style of
Russian poets even on a limited training corpus.
\\ ( https://arxiv.org/abs/2306.02771 ,  24kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02790 (*cross-listing*)
Date: Mon, 5 Jun 2023 11:35:40 GMT   (6949kb,D)

Title: Exploring the Relationship between Alignment and Cross-lingual Transfer
 in Multilingual Transformers
Authors: F\'elix Gaschi, Patricio Cerda, Parisa Rastin and Yannick Toussaint
Categories: cs.CL cs.AI
\\
 Without any explicit cross-lingual training data, multilingual language
models can achieve cross-lingual transfer. One common way to improve this
transfer is to perform realignment steps before fine-tuning, i.e., to train the
model to build similar representations for pairs of words from translated
sentences. But such realignment methods were found to not always improve
results across languages and tasks, which raises the question of whether
aligned representations are truly beneficial for cross-lingual transfer. We
provide evidence that alignment is actually significantly correlated with
cross-lingual transfer across languages, models and random seeds. We show that
fine-tuning can have a significant impact on alignment, depending mainly on the
downstream task and the model. Finally, we show that realignment can, in some
instances, improve cross-lingual transfer, and we identify conditions in which
realignment methods provide significant improvements. Namely, we find that
realignment works better on tasks for which alignment is correlated with
cross-lingual transfer when generalizing to a distant language and with smaller
models, as well as when using a bilingual dictionary rather than FastAlign to
extract realignment pairs. For example, for POS-tagging, between English and
Arabic, realignment can bring a +15.8 accuracy improvement on distilmBERT, even
outperforming XLM-R Large by 1.7. We thus advocate for further research on
realignment methods for smaller multilingual models as an alternative to
scaling.
\\ ( https://arxiv.org/abs/2306.02790 ,  6949kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02797 (*cross-listing*)
Date: Mon, 5 Jun 2023 11:46:45 GMT   (667kb,D)

Title: Modeling Human-like Concept Learning with Bayesian Inference over
 Natural Language
Authors: Kevin Ellis
Categories: cs.CL cs.AI cs.LG
\\
 We model learning of abstract symbolic concepts by performing Bayesian
inference over utterances in natural language. For efficient inference, we use
a large language model as a proposal distribution. We fit a prior to human data
to better model human learners, and evaluate on both generative and logical
concepts.
\\ ( https://arxiv.org/abs/2306.02797 ,  667kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02826 (*cross-listing*)
Date: Mon, 5 Jun 2023 12:22:46 GMT   (64kb)

Title: Near-Optimal Quantum Coreset Construction Algorithms for Clustering
Authors: Yecheng Xue, Xiaoyu Chen, Tongyang Li, Shaofeng H.-C. Jiang
Categories: quant-ph cs.AI cs.DS cs.LG stat.ML
Comments: Comments: 32 pages, 0 figures, 1 table. To appear in the Fortieth
 International Conference on Machine Learning (ICML 2023)
\\
 $k$-Clustering in $\mathbb{R}^d$ (e.g., $k$-median and $k$-means) is a
fundamental machine learning problem. While near-linear time approximation
algorithms were known in the classical setting for a dataset with cardinality
$n$, it remains open to find sublinear-time quantum algorithms. We give quantum
algorithms that find coresets for $k$-clustering in $\mathbb{R}^d$ with
$\tilde{O}(\sqrt{nk}d^{3/2})$ query complexity. Our coreset reduces the input
size from $n$ to $\mathrm{poly}(k\epsilon^{-1}d)$, so that existing
$\alpha$-approximation algorithms for clustering can run on top of it and yield
$(1 + \epsilon)\alpha$-approximation. This eventually yields a quadratic
speedup for various $k$-clustering approximation algorithms. We complement our
algorithm with a nearly matching lower bound, that any quantum algorithm must
make $\Omega(\sqrt{nk})$ queries in order to achieve even $O(1)$-approximation
for $k$-clustering.
\\ ( https://arxiv.org/abs/2306.02826 ,  64kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02889 (*cross-listing*)
Date: Mon, 5 Jun 2023 13:58:10 GMT   (295kb)

Title: Operationalising the Definition of General Purpose AI Systems: Assessing
 Four Approaches
Authors: Risto Uuk, Carlos Ignacio Gutierrez, Alex Tamkin
Categories: cs.CY cs.AI
\\
 The European Union's Artificial Intelligence (AI) Act is set to be a landmark
legal instrument for regulating AI technology. While stakeholders have
primarily focused on the governance of fixed purpose AI applications (also
known as narrow AI), more attention is required to understand the nature of
highly and broadly capable systems. As of the beginning of 2023, several
definitions for General Purpose AI Systems (GPAIS) exist in relation to the AI
Act, attempting to distinguish between systems with and without a fixed
purpose. In this article, we operationalise these differences through the
concept of "distinct tasks" and examine four approaches (quantity, performance,
adaptability, and emergence) to determine whether an AI system should be
classified as a GPAIS. We suggest that EU stakeholders use the four approaches
as a starting point to discriminate between fixed-purpose and GPAIS.
\\ ( https://arxiv.org/abs/2306.02889 ,  295kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02978 (*cross-listing*)
Date: Mon, 5 Jun 2023 15:50:57 GMT   (239kb,D)

Title: Which Argumentative Aspects of Hate Speech in Social Media can be
 reliably identified?
Authors: Dami\'an Furman, Pablo Torres, Jos\'e A. Rodr\'iguez, Diego Letzen,
 Vanina Mart\'inez, Laura Alonso Alemany
Categories: cs.CL cs.AI
Comments: 9 Pages plus reference and appendix
\\
 With the increasing diversity of use cases of large language models, a more
informative treatment of texts seems necessary. An argumentative analysis could
foster a more reasoned usage of chatbots, text completion mechanisms or other
applications. However, it is unclear which aspects of argumentation can be
reliably identified and integrated in language models. In this paper, we
present an empirical assessment of the reliability with which different
argumentative aspects can be automatically identified in hate speech in social
media. We have enriched the Hateval corpus (Basile et al. 2019) with a manual
annotation of some argumentative components, adapted from Wagemans (2016)'s
Periodic Table of Arguments. We show that some components can be identified
with reasonable reliability. For those that present a high error ratio, we
analyze the patterns of disagreement between expert annotators and errors in
automatic procedures, and we propose adaptations of those categories that can
be more reliably reproduced.
\\ ( https://arxiv.org/abs/2306.02978 ,  239kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02980 (*cross-listing*)
Date: Mon, 5 Jun 2023 15:51:58 GMT   (230kb,D)

Title: KNOW How to Make Up Your Mind! Adversarially Detecting and Alleviating
 Inconsistencies in Natural Language Explanations
Authors: Myeongjun Jang, Bodhisattwa Prasad Majumder, Julian McAuley, Thomas
 Lukasiewicz, Oana-Maria Camburu
Categories: cs.CL cs.AI
Comments: Short paper, ACL 2023
Journal-ref: The 61st Annual Meeting of the Association for Computational
 Linguistics (ACL 2023)
\\
 While recent works have been considerably improving the quality of the
natural language explanations (NLEs) generated by a model to justify its
predictions, there is very limited research in detecting and alleviating
inconsistencies among generated NLEs. In this work, we leverage external
knowledge bases to significantly improve on an existing adversarial attack for
detecting inconsistent NLEs. We apply our attack to high-performing NLE models
and show that models with higher NLE quality do not necessarily generate fewer
inconsistencies. Moreover, we propose an off-the-shelf mitigation method to
alleviate inconsistencies by grounding the model into external background
knowledge. Our method decreases the inconsistencies of previous high-performing
NLE models as detected by our attack.
\\ ( https://arxiv.org/abs/2306.02980 ,  230kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03032 (*cross-listing*)
Date: Mon, 5 Jun 2023 16:50:34 GMT   (8378kb,D)

Title: Classification of Edge-dependent Labels of Nodes in Hypergraphs
Authors: Minyoung Choe, Sunwoo Kim, Jaemin Yoo, Kijung Shin
Categories: cs.SI cs.AI
Comments: Accepted to KDD 2023
DOI: 10.1145/3580305.3599274
\\
 A hypergraph is a data structure composed of nodes and hyperedges, where each
hyperedge is an any-sized subset of nodes. Due to the flexibility in hyperedge
size, hypergraphs represent group interactions (e.g., co-authorship by more
than two authors) more naturally and accurately than ordinary graphs.
Interestingly, many real-world systems modeled as hypergraphs contain
edge-dependent node labels, i.e., node labels that vary depending on
hyperedges. For example, on co-authorship datasets, the same author (i.e., a
node) can be the primary author in a paper (i.e., a hyperedge) but the
corresponding author in another paper (i.e., another hyperedge).
 In this work, we introduce a classification of edge-dependent node labels as
a new problem. This problem can be used as a benchmark task for hypergraph
neural networks, which recently have attracted great attention, and also the
usefulness of edge-dependent node labels has been verified in various
applications. To tackle this problem, we propose WHATsNet, a novel hypergraph
neural network that represents the same node differently depending on the
hyperedges it participates in by reflecting its varying importance in the
hyperedges. To this end, WHATsNet models the relations between nodes within
each hyperedge, using their relative centrality as positional encodings. In our
experiments, we demonstrate that WHATsNet significantly and consistently
outperforms ten competitors on six real-world hypergraphs, and we also show
successful applications of WHATsNet to (a) ranking aggregation, (b) node
clustering, and (c) product return prediction.
\\ ( https://arxiv.org/abs/2306.03032 ,  8378kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03040 (*cross-listing*)
Date: Mon, 5 Jun 2023 17:03:10 GMT   (2234kb,D)

Title: Learning Similarity among Users for Personalized Session-Based
 Recommendation from hierarchical structure of User-Session-Item
Authors: Jisoo Cha, Haemin Jeong, Wooju Kim
Categories: cs.IR cs.AI cs.LG
Comments: 7 pages, 5 figures
MSC-class: 68P20
\\
 The task of the session-based recommendation is to predict the next
interaction of the user based on the anonymized user's behavior pattern. And
personalized version of this system is a promising research field due to its
availability to deal with user information. However, there's a problem that the
user's preferences and historical sessions were not considered in the typical
session-based recommendation since it concentrates only on user-item
interaction. In addition, the existing personalized session-based
recommendation model has a limited capability in that it only considers the
preference of the current user without considering those of similar users. It
means there can be the loss of information included within the hierarchical
data structure of the user-session-item. To tackle with this problem, we
propose USP-SBR(abbr. of User Similarity Powered - Session Based Recommender).
To model global historical sessions of users, we propose UserGraph that has two
types of nodes - ItemNode and UserNode. We then connect the nodes with three
types of edges. The first type of edges connects ItemNode as chronological
order, and the second connects ItemNode to UserNode, and the last connects
UserNode to ItemNode. With these user embeddings, we propose additional
contrastive loss, that makes users with similar intention be close to each
other in the vector space. we apply graph neural network on these UserGraph and
update nodes. Experimental results on two real-world datasets demonstrate that
our method outperforms some state-of-the-art approaches.
\\ ( https://arxiv.org/abs/2306.03040 ,  2234kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03061 (*cross-listing*)
Date: Mon, 5 Jun 2023 17:32:35 GMT   (9829kb,D)

Title: Structured Voronoi Sampling
Authors: Afra Amini, Li Du, Ryan Cotterell
Categories: cs.CL cs.AI
\\
 Recently, there has been a growing interest in the development of
gradient-based sampling algorithms for text generation, especially in the
context of controlled generation. However, there exists a lack of theoretically
grounded and principled approaches for this task. In this paper, we take an
important step toward building a principled approach for sampling from language
models with gradient-based methods. We use discrete distributions given by
language models to define densities and develop an algorithm based on
Hamiltonian Monte Carlo to sample from them. We name our gradient-based
technique Structured Voronoi Sampling (SVS). In an experimental setup where the
reference distribution is known, we show that the empirical distribution of SVS
samples is closer to the reference distribution compared to alternative
sampling schemes. Furthermore, in a controlled generation task, SVS is able to
generate fluent and diverse samples while following the control targets
significantly better than other methods.
\\ ( https://arxiv.org/abs/2306.03061 ,  9829kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03067 (*cross-listing*)
Date: Mon, 5 Jun 2023 17:43:53 GMT   (8655kb,D)

Title: Interactive Editing for Text Summarization
Authors: Yujia Xie, Xun Wang, Si-Qing Chen, Wayne Xiong, Pengcheng He
Categories: cs.CL cs.AI
\\
 Summarizing lengthy documents is a common and essential task in our daily
lives. Although recent advancements in neural summarization models can assist
in crafting general-purpose summaries, human writers often have specific
requirements that call for a more customized approach. To address this need, we
introduce REVISE (Refinement and Editing via Iterative Summarization
Enhancement), an innovative framework designed to facilitate iterative editing
and refinement of draft summaries by human writers. Within our framework,
writers can effortlessly modify unsatisfactory segments at any location or
length and provide optional starting phrases -- our system will generate
coherent alternatives that seamlessly integrate with the existing summary. At
its core, REVISE incorporates a modified fill-in-the-middle model with the
encoder-decoder architecture while developing novel evaluation metrics tailored
for the summarization task. In essence, our framework empowers users to create
high-quality, personalized summaries by effectively harnessing both human
expertise and AI capabilities, ultimately transforming the summarization
process into a truly collaborative and adaptive experience.
\\ ( https://arxiv.org/abs/2306.03067 ,  8655kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03090 (*cross-listing*)
Date: Mon, 5 Jun 2023 17:59:21 GMT   (3138kb,D)

Title: Is ChatGPT a Good Teacher Coach? Measuring Zero-Shot Performance For
 Scoring and Providing Actionable Insights on Classroom Instruction
Authors: Rose E. Wang, Dorottya Demszky
Categories: cs.CL cs.AI
Comments: In the Proceedings of Innovative Use of NLP for Building Educational
 Applications 2023; The code and model outputs are open-sourced here:
 https://github.com/rosewang2008/zero-shot-teacher-feedback
\\
 Coaching, which involves classroom observation and expert feedback, is a
widespread and fundamental part of teacher training. However, the majority of
teachers do not have access to consistent, high quality coaching due to limited
resources and access to expertise. We explore whether generative AI could
become a cost-effective complement to expert feedback by serving as an
automated teacher coach. In doing so, we propose three teacher coaching tasks
for generative AI: (A) scoring transcript segments based on classroom
observation instruments, (B) identifying highlights and missed opportunities
for good instructional strategies, and (C) providing actionable suggestions for
eliciting more student reasoning. We recruit expert math teachers to evaluate
the zero-shot performance of ChatGPT on each of these tasks for elementary math
classroom transcripts. Our results reveal that ChatGPT generates responses that
are relevant to improving instruction, but they are often not novel or
insightful. For example, 82% of the model's suggestions point to places in the
transcript where the teacher is already implementing that suggestion. Our work
highlights the challenges of producing insightful, novel and truthful feedback
for teachers while paving the way for future research to address these
obstacles and improve the capacity of generative AI to coach teachers.
\\ ( https://arxiv.org/abs/2306.03090 ,  3138kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03091 (*cross-listing*)
Date: Mon, 5 Jun 2023 17:59:41 GMT   (642kb,D)

Title: RepoBench: Benchmarking Repository-Level Code Auto-Completion Systems
Authors: Tianyang Liu, Canwen Xu, Julian McAuley
Categories: cs.CL cs.AI cs.SE
\\
 Large Language Models (LLMs) have greatly advanced code auto-completion
systems, with a potential for substantial productivity enhancements for
developers. However, current benchmarks mainly focus on single-file tasks,
leaving an assessment gap for more complex, real-world, multi-file programming
scenarios. To fill this gap, we introduce RepoBench, a new benchmark
specifically designed for evaluating repository-level code auto-completion
systems. RepoBench consists of three interconnected evaluation tasks:
RepoBench-R (Retrieval), RepoBench-C (Code Completion), and RepoBench-P
(Pipeline). Each task respectively measures the system's ability to retrieve
the most relevant code snippets from other files as cross-file context, predict
the next line of code with cross-file and in-file context, and handle complex
tasks that require a combination of both retrieval and next-line prediction.
RepoBench aims to facilitate a more complete comparison of performance and
encouraging continuous improvement in auto-completion systems. RepoBench is
publicly available at https://github.com/Leolty/repobench.
\\ ( https://arxiv.org/abs/2306.03091 ,  642kb)
------------------------------------------------------------------------------
\\
arXiv:2306.01752 (*cross-listing*)
Date: Mon, 22 May 2023 16:56:07 GMT   (658kb,D)

Title: Handling Label Uncertainty on the Example of Automatic Detection of
 Shepherd's Crook RCA in Coronary CT Angiography
Authors: Felix Denzinger, Michael Wels, Oliver Taubmann, Florian Kordon, Fabian
 Wagner, Stephanie Mehltretter, Mehmet A. G\"uls\"un, Max Sch\"obinger,
 Florian Andr\'e, Sebastian Buss, Johannes G\"orich, Michael S\"uhling,
 Andreas Maier
Categories: eess.IV cs.CV cs.LG
Comments: Accepted at ISBI 2023
\\
 Coronary artery disease (CAD) is often treated minimally invasively with a
catheter being inserted into the diseased coronary vessel. If a patient
exhibits a Shepherd's Crook (SC) Right Coronary Artery (RCA) - an anatomical
norm variant of the coronary vasculature - the complexity of this procedure is
increased. Automated reporting of this variant from coronary CT angiography
screening would ease prior risk assessment. We propose a 1D convolutional
neural network which leverages a sequence of residual dilated convolutions to
automatically determine this norm variant from a prior extracted vessel
centerline. As the SC RCA is not clearly defined with respect to concrete
measurements, labeling also includes qualitative aspects. Therefore, 4.23%
samples in our dataset of 519 RCA centerlines were labeled as unsure SC RCAs,
with 5.97% being labeled as sure SC RCAs. We explore measures to handle this
label uncertainty, namely global/model-wise random assignment, exclusion, and
soft label assignment. Furthermore, we evaluate how this uncertainty can be
leveraged for the determination of a rejection class. With our best
configuration, we reach an area under the receiver operating characteristic
curve (AUC) of 0.938 on confident labels. Moreover, we observe an increase of
up to 0.020 AUC when rejecting 10% of the data and leveraging the labeling
uncertainty information in the exclusion process.
\\ ( https://arxiv.org/abs/2306.01752 ,  658kb)
------------------------------------------------------------------------------
\\
arXiv:2306.01808 (*cross-listing*)
Date: Fri, 2 Jun 2023 01:52:35 GMT   (15473kb,D)

Title: The optimal connection model for blood vessels segmentation and the
 MEA-Net
Authors: Yuntao Zhu, Yuxuan Qiao, Xiaoping Yang
Categories: eess.IV cs.CV
Comments: 19 pages
\\
 Vascular diseases have long been regarded as a significant health concern.
Accurately detecting the location, shape, and afflicted regions of blood
vessels from a diverse range of medical images has proven to be a major
challenge. Obtaining blood vessels that retain their correct topological
structures is currently a crucial research issue. Numerous efforts have sought
to reinforce neural networks' learning of vascular geometric features,
including measures to ensure the correct topological structure of the
segmentation result's vessel centerline. Typically, these methods extract
topological features from the network's segmentation result and then apply
regular constraints to reinforce the accuracy of critical components and the
overall topological structure. However, as blood vessels are three-dimensional
structures, it is essential to achieve complete local vessel segmentation,
which necessitates enhancing the segmentation of vessel boundaries.
Furthermore, current methods are limited to handling 2D blood vessel
fragmentation cases. Our proposed boundary attention module directly extracts
boundary voxels from the network's segmentation result. Additionally, we have
established an optimal connection model based on minimal surfaces to determine
the connection order between blood vessels. Our method achieves
state-of-the-art performance in 3D multi-class vascular segmentation tasks, as
evidenced by the high values of Dice Similarity Coefficient (DSC) and
Normalized Surface Dice (NSD) metrics. Furthermore, our approach improves the
Betti error, LR error, and BR error indicators of vessel richness and
structural integrity by more than 10% compared to other methods, and
effectively addresses vessel fragmentation and yields blood vessels with a more
precise topological structure.
\\ ( https://arxiv.org/abs/2306.01808 ,  15473kb)
------------------------------------------------------------------------------
\\
arXiv:2306.01853 (*cross-listing*)
Date: Fri, 2 Jun 2023 18:16:21 GMT   (12373kb,D)

Title: Multi-Contrast Computed Tomography Atlas of Healthy Pancreas
Authors: Yinchi Zhou, Ho Hin Lee, Yucheng Tang, Xin Yu, Qi Yang, Shunxing Bao,
 Jeffrey M. Spraggins, Yuankai Huo, and Bennett A. Landman
Categories: eess.IV cs.CV
\\
 With the substantial diversity in population demographics, such as
differences in age and body composition, the volumetric morphology of pancreas
varies greatly, resulting in distinctive variations in shape and appearance.
Such variations increase the difficulty at generalizing population-wide
pancreas features. A volumetric spatial reference is needed to adapt the
morphological variability for organ-specific analysis. Here, we proposed a
high-resolution computed tomography (CT) atlas framework specifically optimized
for the pancreas organ across multi-contrast CT. We introduce a deep
learning-based pre-processing technique to extract the abdominal region of
interests (ROIs) and leverage a hierarchical registration pipeline to align the
pancreas anatomy across populations. Briefly, DEEDs affine and non-rigid
registration are performed to transfer patient abdominal volumes to a fixed
high-resolution atlas template. To generate and evaluate the pancreas atlas
template, multi-contrast modality CT scans of 443 subjects (without reported
history of pancreatic disease, age: 15-50 years old) are processed. Comparing
with different registration state-of-the-art tools, the combination of DEEDs
affine and non-rigid registration achieves the best performance for the
pancreas label transfer across all contrast phases. We further perform external
evaluation with another research cohort of 100 de-identified portal venous
scans with 13 organs labeled, having the best label transfer performance of
0.504 Dice score in unsupervised setting. The qualitative representation (e.g.,
average mapping) of each phase creates a clear boundary of pancreas and its
distinctive contrast appearance. The deformation surface renderings across
scales (e.g., small to large volume) further illustrate the generalizability of
the proposed atlas template.
\\ ( https://arxiv.org/abs/2306.01853 ,  12373kb)
------------------------------------------------------------------------------
\\
arXiv:2306.01940 (*cross-listing*)
Date: Fri, 2 Jun 2023 22:47:18 GMT   (2427kb,D)

Title: Sampling binary sparse coding QUBO models using a spiking neuromorphic
 processor
Authors: Kyle Henke, Elijah Pelofske, Georg Hahn, Garrett T. Kenyon
Categories: cs.NE cs.CV cs.ET cs.LG
Report-no: LA-UR-23-25877
\\
 We consider the problem of computing a sparse binary representation of an
image. To be precise, given an image and an overcomplete, non-orthonormal
basis, we aim to find a sparse binary vector indicating the minimal set of
basis vectors that when added together best reconstruct the given input. We
formulate this problem with an $L_2$ loss on the reconstruction error, and an
$L_0$ (or, equivalently, an $L_1$) loss on the binary vector enforcing
sparsity. This yields a so-called Quadratic Unconstrained Binary Optimization
(QUBO) problem, whose solution is generally NP-hard to find. The contribution
of this work is twofold. First, the method of unsupervised and unnormalized
dictionary feature learning for a desired sparsity level to best match the data
is presented. Second, the binary sparse coding problem is then solved on the
Loihi 1 neuromorphic chip by the use of stochastic networks of neurons to
traverse the non-convex energy landscape. The solutions are benchmarked against
the classical heuristic simulated annealing. We demonstrate neuromorphic
computing is suitable for sampling low energy solutions of binary sparse coding
QUBO models, and although Loihi 1 is capable of sampling very sparse solutions
of the QUBO models, there needs to be improvement in the implementation in
order to be competitive with simulated annealing.
\\ ( https://arxiv.org/abs/2306.01940 ,  2427kb)
------------------------------------------------------------------------------
\\
arXiv:2306.01983 (*cross-listing*)
Date: Sat, 3 Jun 2023 02:33:38 GMT   (417kb)

Title: Mitigating Backdoor Attack Via Prerequisite Transformation
Authors: Han Gao
Categories: cs.CR cs.CV
Comments: 7 pages,7 figures,2 tables
\\
 In recent years, with the successful application of DNN in fields such as NLP
and CV, its security has also received widespread attention. (Author) proposed
the method of backdoor attack in Badnet. Switch implanted backdoor into the
model by poisoning the training samples. The model with backdoor did not
exhibit any abnormalities on the normal validation sample set, but in the input
with trigger, they were mistakenly classified as the attacker's designated
category or randomly classified as a different category from the ground truth,
This attack method seriously threatens the normal application of DNN in real
life, such as autonomous driving, object detection, etc.This article proposes a
new method to combat backdoor attacks. We refer to the features in the area
covered by the trigger as trigger features, and the remaining areas as normal
features. By introducing prerequisite calculation conditions during the
training process, these conditions have little impact on normal features and
trigger features, and can complete the training of a standard backdoor model.
The model trained under these prerequisite calculation conditions can, In the
verification set D'val with the same premise calculation conditions, the
performance is consistent with that of the ordinary backdoor model. However, in
the verification set Dval without the premise calculation conditions, the
verification accuracy decreases very little (7%~12%), while the attack success
rate (ASR) decreases from 90% to about 8%.Author call this method Prerequisite
Transformation(PT).
\\ ( https://arxiv.org/abs/2306.01983 ,  417kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02074 (*cross-listing*)
Date: Sat, 3 Jun 2023 10:35:04 GMT   (745kb)

Title: A Conditional Generative Chatbot using Transformer Model
Authors: Nura Esfandiari, Kourosh Kiani, Razieh Rastgoo
Categories: cs.CL cs.CV
\\
 A Chatbot serves as a communication tool between a human user and a machine
to achieve an appropriate answer based on the human input. In more recent
approaches, a combination of Natural Language Processing and sequential models
are used to build a generative Chatbot. The main challenge of these models is
their sequential nature, which leads to less accurate results. To tackle this
challenge, in this paper, a novel end-to-end architecture is proposed using
conditional Wasserstein Generative Adversarial Networks and a transformer model
for answer generation in Chatbots. While the generator of the proposed model
consists of a full transformer model to generate an answer, the discriminator
includes only the encoder part of a transformer model followed by a classifier.
To the best of our knowledge, this is the first time that a generative Chatbot
is proposed using the embedded transformer in both generator and discriminator
models. Relying on the parallel computing of the transformer model, the results
of the proposed model on the Cornell Movie-Dialog corpus and the Chit-Chat
datasets confirm the superiority of the proposed model compared to
state-of-the-art alternatives using different evaluation metrics.
\\ ( https://arxiv.org/abs/2306.02074 ,  745kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02115 (*cross-listing*)
Date: Sat, 3 Jun 2023 14:01:54 GMT   (11220kb,D)

Title: Table and Image Generation for Investigating Knowledge of Entities in
 Pre-trained Vision and Language Models
Authors: Hidetaka Kamigaito, Katsuhiko Hayashi, Taro Watanabe
Categories: cs.CL cs.CV cs.LG
Comments: Accepted at ACL 2023
\\
 In this paper, we propose a table and image generation task to verify how the
knowledge about entities acquired from natural language is retained in Vision &
Language (V & L) models. This task consists of two parts: the first is to
generate a table containing knowledge about an entity and its related image,
and the second is to generate an image from an entity with a caption and a
table containing related knowledge of the entity. In both tasks, the model must
know the entities used to perform the generation properly. We created the
Wikipedia Table and Image Generation (WikiTIG) dataset from about 200,000
infoboxes in English Wikipedia articles to perform the proposed tasks. We
evaluated the performance on the tasks with respect to the above research
question using the V & L model OFA, which has achieved state-of-the-art results
in multiple tasks. Experimental results show that OFA forgets part of its
entity knowledge by pre-training as a complement to improve the performance of
image related tasks.
\\ ( https://arxiv.org/abs/2306.02115 ,  11220kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02133 (*cross-listing*)
Date: Sat, 3 Jun 2023 15:06:12 GMT   (27kb)

Title: Graph Mover's Distance: An Efficiently Computable Distance Measure for
 Geometric Graphs
Authors: Sushovan Majhi
Categories: cs.CG cs.CV
\\
 Many applications in pattern recognition represent patterns as a geometric
graph. The geometric graph distance (GGD) has recently been studied as a
meaningful measure of similarity between two geometric graphs. Since computing
the GGD is known to be $\mathcal{NP}$-hard, the distance measure proves an
impractical choice for applications. As a computationally tractable
alternative, we propose in this paper the Graph Mover's Distance (GMD), which
has been formulated as an instance of the earth mover's distance. The
computation of the GMD between two geometric graphs with at most $n$ vertices
takes only $O(n^3)$-time. Alongside studying the metric properties of the GMD,
we investigate the stability of the GGD and GMD. The GMD also demonstrates
extremely promising empirical evidence at recognizing letter drawings from the
{\tt LETTER} dataset \cite{da_vitoria_lobo_iam_2008}.
\\ ( https://arxiv.org/abs/2306.02133 ,  27kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02176 (*cross-listing*)
Date: Sat, 3 Jun 2023 19:06:06 GMT   (509kb,D)

Title: TransRUPNet for Improved Out-of-Distribution Generalization in Polyp
 Segmentation
Authors: Debesh Jha, Nikhil Kumar Tomar, Ulas Bagci
Categories: eess.IV cs.CV
\\
 Out-of-distribution (OOD) generalization is a critical challenge in deep
learning. It is specifically important when the test samples are drawn from a
different distribution than the training data. We develop a novel real-time
deep learning based architecture, TransRUPNet that is based on a Transformer
and residual upsampling network for colorectal polyp segmentation to improve
OOD generalization. The proposed architecture, TransRUPNet, is an
encoder-decoder network that consists of three encoder blocks, three decoder
blocks, and some additional upsampling blocks at the end of the network. With
the image size of $256\times256$, the proposed method achieves an excellent
real-time operation speed of \textbf{47.07} frames per second with an average
mean dice coefficient score of 0.7786 and mean Intersection over Union of
0.7210 on the out-of-distribution polyp datasets. The results on the publicly
available PolypGen dataset (OOD dataset in our case) suggest that TransRUPNet
can give real-time feedback while retaining high accuracy for in-distribution
dataset. Furthermore, we demonstrate the generalizability of the proposed
method by showing that it significantly improves performance on OOD datasets
compared to the existing methods.
\\ ( https://arxiv.org/abs/2306.02176 ,  509kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02263 (*cross-listing*)
Date: Sun, 4 Jun 2023 05:00:12 GMT   (957kb,D)

Title: MAVD: The First Open Large-Scale Mandarin Audio-Visual Dataset with
 Depth Information
Authors: Jianrong Wang, Yuchen Huo, Li Liu, Tianyi Xu, Qi Li, Sen Li
Categories: cs.SD cs.CV
\\
 Audio-visual speech recognition (AVSR) gains increasing attention from
researchers as an important part of human-computer interaction. However, the
existing available Mandarin audio-visual datasets are limited and lack the
depth information. To address this issue, this work establishes the MAVD, a new
large-scale Mandarin multimodal corpus comprising 12,484 utterances spoken by
64 native Chinese speakers. To ensure the dataset covers diverse real-world
scenarios, a pipeline for cleaning and filtering the raw text material has been
developed to create a well-balanced reading material. In particular, the latest
data acquisition device of Microsoft, Azure Kinect is used to capture depth
information in addition to the traditional audio signals and RGB images during
data acquisition. We also provide a baseline experiment, which could be used to
evaluate the effectiveness of the dataset. The dataset and code will be
released at https://github.com/SpringHuo/MAVD.
\\ ( https://arxiv.org/abs/2306.02263 ,  957kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02596 (*cross-listing*)
Date: Mon, 5 Jun 2023 05:03:11 GMT   (5390kb,D)

Title: A Novel Interpretable and Generalizable Re-synchronization Model for
 Cued Speech based on a Multi-Cuer Corpus
Authors: Lufei Gao, Shan Huang and Li Liu
Categories: eess.AS cs.CL cs.CV
Comments: 5 pages, 4 figures, Accepted to INTERSPEECH2023
\\
 Cued Speech (CS) is a multi-modal visual coding system combining lip reading
with several hand cues at the phonetic level to make the spoken language
visible to the hearing impaired. Previous studies solved asynchronous problems
between lip and hand movements by a cuer\footnote{The people who perform Cued
Speech are called the cuer.}-dependent piecewise linear model for English and
French CS. In this work, we innovatively propose three statistical measure on
the lip stream to build an interpretable and generalizable model for predicting
hand preceding time (HPT), which achieves cuer-independent by a proper
normalization. Particularly, we build the first Mandarin CS corpus comprising
annotated videos from five speakers including three normal and two hearing
impaired individuals. Consequently, we show that the hand preceding phenomenon
exists in Mandarin CS production with significant differences between normal
and hearing impaired people. Extensive experiments demonstrate that our model
outperforms the baseline and the previous state-of-the-art methods.
\\ ( https://arxiv.org/abs/2306.02596 ,  5390kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02634 (*cross-listing*)
Date: Mon, 5 Jun 2023 07:09:21 GMT   (43586kb,D)

Title: Computational 3D topographic microscopy from terabytes of data per
 sample
Authors: Kevin C. Zhou, Mark Harfouche, Maxwell Zheng, Joakim J\"onsson, Kyung
 Chul Lee, Ron Appel, Paul Reamey, Thomas Doman, Veton Saliu, Gregor
 Horstmeyer, and Roarke Horstmeyer
Categories: physics.optics cs.CV cs.LG eess.IV
\\
 We present a large-scale computational 3D topographic microscope that enables
6-gigapixel profilometric 3D imaging at micron-scale resolution across $>$110
cm$^2$ areas over multi-millimeter axial ranges. Our computational microscope,
termed STARCAM (Scanning Topographic All-in-focus Reconstruction with a
Computational Array Microscope), features a parallelized, 54-camera
architecture with 3-axis translation to capture, for each sample of interest, a
multi-dimensional, 2.1-terabyte (TB) dataset, consisting of a total of 224,640
9.4-megapixel images. We developed a self-supervised neural network-based
algorithm for 3D reconstruction and stitching that jointly estimates an
all-in-focus photometric composite and 3D height map across the entire field of
view, using multi-view stereo information and image sharpness as a focal
metric. The memory-efficient, compressed differentiable representation offered
by the neural network effectively enables joint participation of the entire
multi-TB dataset during the reconstruction process. To demonstrate the broad
utility of our new computational microscope, we applied STARCAM to a variety of
decimeter-scale objects, with applications ranging from cultural heritage to
industrial inspection.
\\ ( https://arxiv.org/abs/2306.02634 ,  43586kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02648 (*cross-listing*)
Date: Mon, 5 Jun 2023 07:32:47 GMT   (10449kb,D)

Title: Continuous Cartesian Genetic Programming based representation for
 Multi-Objective Neural Architecture Search
Authors: Cosijopii Garcia-Garcia and Alicia Morales-Reyes and Hugo Jair
 Escalante
Categories: cs.NE cs.CV
\\
 We propose a novel approach for the challenge of designing less complex yet
highly effective convolutional neural networks (CNNs) through the use of
cartesian genetic programming (CGP) for neural architecture search (NAS). Our
approach combines real-based and block-chained CNNs representations based on
CGP for optimization in the continuous domain using multi-objective
evolutionary algorithms (MOEAs). Two variants are introduced that differ in the
granularity of the search space they consider. The proposed CGP-NASV1 and
CGP-NASV2 algorithms were evaluated using the non-dominated sorting genetic
algorithm II (NSGA-II) on the CIFAR-10 and CIFAR-100 datasets. The empirical
analysis was extended to assess the crossover operator from differential
evolution (DE), the multi-objective evolutionary algorithm based on
decomposition (MOEA/D) and S metric selection evolutionary multi-objective
algorithm (SMS-EMOA) using the same representation. Experimental results
demonstrate that our approach is competitive with state-of-the-art proposals in
terms of classification performance and model complexity.
\\ ( https://arxiv.org/abs/2306.02648 ,  10449kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02673 (*cross-listing*)
Date: Mon, 5 Jun 2023 08:07:01 GMT   (6561kb,D)

Title: Cross-Modal Vertical Federated Learning for MRI Reconstruction
Authors: Yunlu Yan, Hong Wang, Yawen Huang, Nanjun He, Lei Zhu, Yuexiang Li,
 Yong Xu, Yefeng Zheng
Categories: eess.IV cs.CV cs.LG
Comments: 12 pages, 7 figures
\\
 Federated learning enables multiple hospitals to cooperatively learn a shared
model without privacy disclosure. Existing methods often take a common
assumption that the data from different hospitals have the same modalities.
However, such a setting is difficult to fully satisfy in practical
applications, since the imaging guidelines may be different between hospitals,
which makes the number of individuals with the same set of modalities limited.
To this end, we formulate this practical-yet-challenging cross-modal vertical
federated learning task, in which shape data from multiple hospitals have
different modalities with a small amount of multi-modality data collected from
the same individuals. To tackle such a situation, we develop a novel framework,
namely Federated Consistent Regularization constrained Feature Disentanglement
(Fed-CRFD), for boosting MRI reconstruction by effectively exploring the
overlapping samples (individuals with multi-modalities) and solving the domain
shift problem caused by different modalities. Particularly, our Fed-CRFD
involves an intra-client feature disentangle scheme to decouple data into
modality-invariant and modality-specific features, where the modality-invariant
features are leveraged to mitigate the domain shift problem. In addition, a
cross-client latent representation consistency constraint is proposed
specifically for the overlapping samples to further align the
modality-invariant features extracted from different modalities. Hence, our
method can fully exploit the multi-source data from hospitals while alleviating
the domain shift problem. Extensive experiments on two typical MRI datasets
demonstrate that our network clearly outperforms state-of-the-art MRI
reconstruction methods. The source code will be publicly released upon the
publication of this work.
\\ ( https://arxiv.org/abs/2306.02673 ,  6561kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02800 (*cross-listing*)
Date: Mon, 5 Jun 2023 11:55:57 GMT   (831kb)

Title: Using Multiple Dermoscopic Photographs of One Lesion Improves Melanoma
 Classification via Deep Learning: A Prognostic Diagnostic Accuracy Study
Authors: Achim Hekler, Roman C. Maron, Sarah Haggenm\"uller, Max Schmitt,
 Christoph Wies, Jochen S. Utikal, Friedegund Meier, Sarah Hobelsberger, Frank
 F. Gellrich, Mildred Sergon, Axel Hauschild, Lars E. French, Lucie
 Heinzerling, Justin G. Schlager, Kamran Ghoreschi, Max Schlaak, Franz J.
 Hilke, Gabriela Poch, S\"oren Korsing, Carola Berking, Markus V. Heppt,
 Michael Erdmann, Sebastian Haferkamp, Konstantin Drexler, Dirk Schadendorf,
 Wiebke Sondermann, Matthias Goebeler, Bastian Schilling, Jakob N. Kather, Eva
 Krieghoff-Henning, Titus J. Brinker
Categories: eess.IV cs.CV cs.LG
\\
 Background: Convolutional neural network (CNN)-based melanoma classifiers
face several challenges that limit their usefulness in clinical practice.
Objective: To investigate the impact of multiple real-world dermoscopic views
of a single lesion of interest on a CNN-based melanoma classifier.
 Methods: This study evaluated 656 suspected melanoma lesions. Classifier
performance was measured using area under the receiver operating characteristic
curve (AUROC), expected calibration error (ECE) and maximum confidence change
(MCC) for (I) a single-view scenario, (II) a multiview scenario using multiple
artificially modified images per lesion and (III) a multiview scenario with
multiple real-world images per lesion.
 Results: The multiview approach with real-world images significantly
increased the AUROC from 0.905 (95% CI, 0.879-0.929) in the single-view
approach to 0.930 (95% CI, 0.909-0.951). ECE and MCC also improved
significantly from 0.131 (95% CI, 0.105-0.159) to 0.072 (95% CI: 0.052-0.093)
and from 0.149 (95% CI, 0.125-0.171) to 0.115 (95% CI: 0.099-0.131),
respectively. Comparing multiview real-world to artificially modified images
showed comparable diagnostic accuracy and uncertainty estimation, but
significantly worse robustness for the latter.
 Conclusion: Using multiple real-world images is an inexpensive method to
positively impact the performance of a CNN-based melanoma classifier.
\\ ( https://arxiv.org/abs/2306.02800 ,  831kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02858 (*cross-listing*)
Date: Mon, 5 Jun 2023 13:17:27 GMT   (2864kb,D)

Title: Video-LLaMA: An Instruction-tuned Audio-Visual Language Model for Video
 Understanding
Authors: Hang Zhang, Xin Li, Lidong Bing
Categories: cs.CL cs.CV cs.SD eess.AS
Comments: Technical Report
\\
 We present Video-LLaMA, a multi-modal framework that empowers Large Language
Models (LLMs) with the capability of understanding both visual and auditory
content in the video. Video-LLaMA bootstraps cross-modal training from the
frozen pre-trained visual \& audio encoders and the frozen LLMs. Unlike
previous vision- LLMs that focus on static image comprehensions such as
MiniGPT-4~\citep{zhu2023minigpt} and LLaVA~\citep{liu2023visualit}, Video-LLaMA
tackles two challenges in video understanding: (1) capturing the temporal
changes in visual scenes, (2) integrating audio-visual signals. For the first
challenge, we propose Video Q-former to extend the pre-trained image encoder to
a video encoder and introduce a video-to-text generation task to learn
video-language correspondence. For the second challenge, we leverage
ImageBind~\citep{girdhar2023imagebind} as the pre-trained audio encoder which
performs exceptionally well in aligning different modalities to a common
embedding space. And then introduce an Audio Q-former to learn auditory query
tokens. To align the output of both visual \& audio encoder with LLM's
embedding space, we train Video-LLaMA on a large-scale vision caption dataset
and a hign-quantity vision-instruction-tuning dataset. We found Video-LLaMA
showcases the ability to perceive and comprehend video content, generating
meaningful responses that are grounded in the visual and auditory information
present in the videos. This highlights the potential of Video-LLaMA as a
promising prototype for audio-visual AI assistants. Our code, pre-trained
model, and demo are available at
\url{https://github.com/DAMO-NLP-SG/Video-LLaMA}.
\\ ( https://arxiv.org/abs/2306.02858 ,  2864kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02886 (*cross-listing*)
Date: Mon, 5 Jun 2023 13:53:57 GMT   (2456kb)

Title: Image Reconstruction for Accelerated MR Scan with Faster Fourier
 Convolutional Neural Networks
Authors: Xiaohan Liu, Yanwei Pang, Xuebin Sun, Yiming Liu, Yonghong Hou,
 Zhenchang Wang, Xuelong Li
Categories: eess.IV cs.CV cs.LG
\\
 Partial scan is a common approach to accelerate Magnetic Resonance Imaging
(MRI) data acquisition in both 2D and 3D settings. However, accurately
reconstructing images from partial scan data (i.e., incomplete k-space
matrices) remains challenging due to lack of an effectively global receptive
field in both spatial and k-space domains. To address this problem, we propose
the following: (1) a novel convolutional operator called Faster Fourier
Convolution (FasterFC) to replace the two consecutive convolution operations
typically used in convolutional neural networks (e.g., U-Net, ResNet). Based on
the spectral convolution theorem in Fourier theory, FasterFC employs
alternating kernels of size 1 in 3D case) in different domains to extend the
dual-domain receptive field to the global and achieves faster calculation speed
than traditional Fast Fourier Convolution (FFC). (2) A 2D accelerated MRI
method, FasterFC-End-to-End-VarNet, which uses FasterFC to improve the
sensitivity maps and reconstruction quality. (3) A multi-stage 3D accelerated
MRI method called FasterFC-based Single-to-group Network (FAS-Net) that
utilizes a single-to-group algorithm to guide k-space domain reconstruction,
followed by FasterFC-based cascaded convolutional neural networks to expand the
effective receptive field in the dual-domain. Experimental results on the
fastMRI and Stanford MRI Data datasets demonstrate that FasterFC improves the
quality of both 2D and 3D reconstruction. Moreover, FAS-Net, as a 3D
high-resolution multi-coil (eight) accelerated MRI method, achieves superior
reconstruction performance in both qualitative and quantitative results
compared with state-of-the-art 2D and 3D methods.
\\ ( https://arxiv.org/abs/2306.02886 ,  2456kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02901 (*cross-listing*)
Date: Mon, 5 Jun 2023 14:06:43 GMT   (2107kb,D)

Title: A Vessel-Segmentation-Based CycleGAN for Unpaired Multi-modal Retinal
 Image Synthesis
Authors: Aline Sindel, Andreas Maier, Vincent Christlein
Categories: eess.IV cs.CV
Comments: Accepted to BVM 2023
Journal-ref: BVM 2023
DOI: 10.1007/978-3-658-41657-7_11
\\
 Unpaired image-to-image translation of retinal images can efficiently
increase the training dataset for deep-learning-based multi-modal retinal
registration methods. Our method integrates a vessel segmentation network into
the image-to-image translation task by extending the CycleGAN framework. The
segmentation network is inserted prior to a UNet vision transformer generator
network and serves as a shared representation between both domains. We
reformulate the original identity loss to learn the direct mapping between the
vessel segmentation and the real image. Additionally, we add a segmentation
loss term to ensure shared vessel locations between fake and real images. In
the experiments, our method shows a visually realistic look and preserves the
vessel structures, which is a prerequisite for generating multi-modal training
data for image registration.
\\ ( https://arxiv.org/abs/2306.02901 ,  2107kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02986 (*cross-listing*)
Date: Mon, 5 Jun 2023 15:56:30 GMT   (3306kb,D)

Title: Brain tumor segmentation using synthetic MR images -- A comparison of
 GANs and diffusion models
Authors: Muhammad Usman Akbar, M{\aa}ns Larsson, Anders Eklund
Categories: eess.IV cs.CV cs.LG
Comments: 20 Pages
\\
 Large annotated datasets are required for training deep learning models, but
in medical imaging data sharing is often complicated due to ethics,
anonymization and data protection legislation (e.g. the general data protection
regulation (GDPR)). Generative AI models, such as generative adversarial
networks (GANs) and diffusion models, can today produce very realistic
synthetic images, and can potentially facilitate data sharing as GDPR should
not apply for medical images which do not belong to a specific person. However,
in order to share synthetic images it must first be demonstrated that they can
be used for training different networks with acceptable performance. Here, we
therefore comprehensively evaluate four GANs (progressive GAN, StyleGAN 1-3)
and a diffusion model for the task of brain tumor segmentation. Our results
show that segmentation networks trained on synthetic images reach Dice scores
that are 80\% - 90\% of Dice scores when training with real images, but that
memorization of the training images can be a problem for diffusion models if
the original dataset is too small. Furthermore, we demonstrate that common
metrics for evaluating synthetic images, Fr\'echet inception distance (FID) and
inception score (IS), do not correlate well with the obtained performance when
using the synthetic images for training segmentation networks.
\\ ( https://arxiv.org/abs/2306.02986 ,  3306kb)
------------------------------------------------------------------------------
\\
arXiv:2306.01796 (*cross-listing*)
Date: Thu, 1 Jun 2023 12:35:27 GMT   (1553kb,D)

Title: Extragradient SVRG for Variational Inequalities: Error Bounds and
 Increasing Iterate Averaging
Authors: Tianlong Nan, Yuan Gao, Christian Kroer
Categories: math.OC cs.GT
\\
 We study variance reduction methods for extragradient (EG) algorithms for a
class of variational inequalities satisfying a classical error-bound condition.
Previously, linear convergence was only known to hold under strong
monotonicity. The error-bound condition is much weaker than strong monotonicity
and captures a larger class of problems, including bilinear saddle-point
problems such as those arising from two-player zero-sum Nash equilibrium
computation. We show that EG algorithms with SVRG-style variance reduction
(SVRG-EG) achieve linear convergence under the error-bound condition. In
addition, motivated by the empirical success of increasing iterate averaging
techniques in solving saddle-point problems, we also establish new convergence
results for variance-reduced EG with increasing iterate averaging. Finally, we
conduct numerical experiments to demonstrate the advantage of SVRG-EG, with and
without increasing iterate averaging, over deterministic EG.
\\ ( https://arxiv.org/abs/2306.01796 ,  1553kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02135 (*cross-listing*)
Date: Sat, 3 Jun 2023 15:19:02 GMT   (924kb,D)

Title: The conflict between self-interaction and updating passivity in the
 evolution of cooperation
Authors: Chaoqian Wang, Wenqiang Zhu, Attila Szolnoki
Categories: cond-mat.stat-mech cs.GT nlin.CG physics.soc-ph
Comments: 17 two-column pages, 7 figures, accepted for publication in Chaos,
 Solitons and Fractals
\\
 In social dilemmas under weak selection, the capacity for a player to exhibit
updating passivity or interact with its own strategy can lead to conflicting
outcomes. The central question is which effect is stronger and how their
simultaneous presence influences the evolution of cooperation. We introduce a
model that considers both effects using different weight factors. We derive
theoretical solutions for the conditions of cooperation success and the
cooperation level under weak selection, scanning the complete parameter space.
When the weight factors are equally strong, the promoting effect of
self-interaction to cooperation surpasses the inhibitory effect of updating
passivity. Intriguingly, however, we identify non-monotonous
cooperation-supporting effects when the weight of updating passivity increases
more rapidly. Our findings are corroborated by Monte Carlo simulations and
demonstrate robustness across various game types, including the prisoner's
dilemma, stag-hunt, and snowdrift games.
\\ ( https://arxiv.org/abs/2306.02135 ,  924kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02817 (*cross-listing*)
Date: Mon, 5 Jun 2023 12:13:11 GMT   (172kb,D)

Title: Integer Programming Games: A Gentle Computational Overview
Authors: Margarida Carvalho, Gabriele Dragotto, Andrea Lodi, Sriram
 Sankaranarayan
Categories: math.OC cs.GT
Comments: To appear in INFORMS TutORials in Operations Research 2023
\\
 In this tutorial, we present a computational overview on computing Nash
equilibria in Integer Programming Games ($IPG$s), $i.e.$, how to compute
solutions for a class of non-cooperative and nonconvex games where each player
solves a mixed-integer optimization problem. $IPG$s are a broad class of games
extending the modeling power of mixed-integer optimization to multi-agent
settings. This class of games includes, for instance, any finite game and any
multi-agent extension of traditional combinatorial optimization problems. After
providing some background motivation and context of applications, we
systematically review and classify the state-of-the-art algorithms to compute
Nash equilibria. We propose an essential taxonomy of the algorithmic
ingredients needed to compute equilibria, and we describe the theoretical and
practical challenges associated with equilibria computation. Finally, we
quantitatively and qualitatively compare a sequential Stackelberg game with a
simultaneous $IPG$ to highlight the different properties of their solutions.
\\ ( https://arxiv.org/abs/2306.02817 ,  172kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03045 (*cross-listing*)
Date: Mon, 5 Jun 2023 17:15:26 GMT   (51kb)

Title: Designing Equilibria in Concurrent Games with Social Welfare and
 Temporal Logic Constraints
Authors: Julian Gutierrez and Muhammad Najib and Giuseppe Perelli and Michael
 Wooldridge
Categories: cs.LO cs.GT cs.MA
Comments: The manuscript is going to be submitted to the Journal on Logical
 Methods in Computer Science. arXiv admin note: substantial text overlap with
 arXiv:2106.10192
\\
 In game theory, mechanism design is concerned with the design of incentives
so that a desired outcome of the game can be achieved. In this paper, we
explore the concept of equilibrium design, where incentives are designed to
obtain a desirable equilibrium that satisfies a specific temporal logic
property. Our study is based on a framework where system specifications are
represented as temporal logic formulae, games as quantitative concurrent game
structures, and players' goals as mean-payoff objectives. We consider system
specifications given by LTL and GR(1) formulae, and show that designing
incentives to ensure that a given temporal logic property is satisfied on
some/every Nash equilibrium of the game can be achieved in PSPACE for LTL
properties and in NP/{\Sigma}P 2 for GR(1) specifications. We also examine the
complexity of related decision and optimisation problems, such as optimality
and uniqueness of solutions, as well as considering social welfare, and show
that the complexities of these problems lie within the polynomial hierarchy.
Equilibrium design can be used as an alternative solution to rational synthesis
and verification problems for concurrent games with mean-payoff objectives when
no solution exists or as a technique to repair concurrent games with
undesirable Nash equilibria in an optimal way.
\\ ( https://arxiv.org/abs/2306.03045 ,  51kb)
------------------------------------------------------------------------------
\\
arXiv:2306.01742 (*cross-listing*)
Date: Wed, 10 May 2023 18:38:48 GMT   (47kb)

Title: Beyond Negativity: Re-Analysis and Follow-Up Experiments on Hope Speech
 Detection
Authors: Neemesh Yadav, Mohammad Aflah Khan, Diksha Sethi and Raghav Sahni
Categories: cs.CL cs.LG
Comments: Published as a Tiny Paper at ICLR 2023, 7 Pages
\\
 Health experts assert that hope plays a crucial role in enhancing
individuals' physical and mental well-being, facilitating their recovery, and
promoting restoration. Hope speech refers to comments, posts and other social
media messages that offer support, reassurance, suggestions, inspiration, and
insight. The detection of hope speech involves the analysis of such textual
content, with the aim of identifying messages that invoke positive emotions in
people. Our study aims to find computationally efficient yet
comparable/superior methods for hope speech detection. We also make our
codebase public at https://github.com/aflah02/Hope_Speech_Detection
\\ ( https://arxiv.org/abs/2306.01742 ,  47kb)
------------------------------------------------------------------------------
\\
arXiv:2306.01751 (*cross-listing*)
Date: Mon, 22 May 2023 16:33:23 GMT   (10681kb)

Title: Differential Privacy with Random Projections and Sign Random Projections
Authors: Ping Li and Xiaoyun Li
Categories: cs.CR cs.LG stat.ML
\\
 In this paper, we develop a series of differential privacy (DP) algorithms
from a family of random projections (RP), for general applications in machine
learning, data mining, and information retrieval. Among the presented
algorithms, \textbf{iDP-SignRP} is remarkably effective under the setting of
``individual differential privacy'' (iDP), based on sign random projections
(SignRP). Also, \textbf{DP-SignOPORP} considerably improves existing algorithms
in the literature under the standard DP setting, using ``one permutation + one
random projection'' (OPORP), where OPORP is a variant of the celebrated
count-sketch method with fixed-length binning and normalization. Without taking
signs, among the DP-RP family, \textbf{DP-OPORP} achieves the best performance.
 The concept of iDP (individual differential privacy) is defined only on a
particular dataset of interest. While iDP is not strictly DP, iDP might be
useful in certain applications, such as releasing a dataset (including sharing
embeddings across companies or countries). In our study, we find that
\textbf{iDP-SignRP} is remarkably effective for search and machine learning
applications, in that the utilities are exceptionally good even at a very small
privacy parameter $\epsilon$ (e.g., $\epsilon<0.5$).
\\ ( https://arxiv.org/abs/2306.01751 ,  10681kb)
------------------------------------------------------------------------------
\\
arXiv:2306.01776 (*cross-listing*)
Date: Mon, 29 May 2023 18:20:28 GMT   (8620kb,D)

Title: Generative Diffusion for 3D Turbulent Flows
Authors: Marten Lienen, Jan Hansen-Palmus, David L\"udke, Stephan G\"unnemann
Categories: physics.flu-dyn cs.LG
\\
 Turbulent flows are well known to be chaotic and hard to predict; however,
their dynamics differ between two and three dimensions. While 2D turbulence
tends to form large, coherent structures, in three dimensions vortices cascade
to smaller and smaller scales. This cascade creates many fast-changing,
small-scale structures and amplifies the unpredictability, making
regression-based methods infeasible. We propose the first generative model for
forced turbulence in arbitrary 3D geometries and introduce a sample quality
metric for turbulent flows based on the Wasserstein distance of the generated
velocity-vorticity distribution. In several experiments, we show that our
generative diffusion model circumvents the unpredictability of turbulent flows
and produces high-quality samples based solely on geometric information.
Furthermore, we demonstrate that our model beats an industrial-grade numerical
solver in the time to generate a turbulent flow field from scratch by an order
of magnitude.
\\ ( https://arxiv.org/abs/2306.01776 ,  8620kb)
------------------------------------------------------------------------------
\\
arXiv:2306.01785 (*cross-listing*)
Date: Wed, 31 May 2023 12:01:02 GMT   (3257kb,D)

Title: Beyond Rankings: Exploring the Impact of SERP Features on Organic
 Click-through Rates
Authors: Erik Fubel and Niclas Michael Groll and Patrick Gundlach and Qiwei Han
 and Maximilian Kaiser
Categories: cs.IR cs.LG cs.SI
Comments: submitted IEEE DSAA conference, 14 pages, 5 figures, 2 tables
\\
 Search Engine Result Pages (SERPs) serve as the digital gateways to the vast
expanse of the internet. Past decades have witnessed a surge in research
primarily centered on the influence of website ranking on these pages, to
determine the click-through rate (CTR). However, during this period, the
landscape of SERPs has undergone a dramatic evolution: SERP features,
encompassing elements such as knowledge panels, media galleries, FAQs, and
more, have emerged as an increasingly prominent facet of these result pages.
Our study examines the crucial role of these features, revealing them to be not
merely aesthetic components, but strongly influence CTR and the associated
behavior of internet users. We demonstrate how these features can significantly
modulate web traffic, either amplifying or attenuating it. We dissect these
intricate interaction effects leveraging a unique dataset of 67,000 keywords
and their respective Google SERPs, spanning over 40 distinct US-based
e-commerce domains, generating over 6 million clicks from 24 million views.
This cross-website dataset, unprecedented in its scope, enables us to assess
the impact of 24 different SERP features on organic CTR. Through an ablation
study modeling CTR, we illustrate the incremental predictive power these
features hold.
\\ ( https://arxiv.org/abs/2306.01785 ,  3257kb)
------------------------------------------------------------------------------
\\
arXiv:2306.01794 (*cross-listing*)
Date: Thu, 1 Jun 2023 09:22:09 GMT   (27092kb,D)

Title: DiffPack: A Torsional Diffusion Model for Autoregressive Protein
 Side-Chain Packing
Authors: Yangtian Zhan, Zuobai Zhang, Bozitao Zhong, Sanchit Misra, Jian Tang
Categories: q-bio.QM cs.LG
Comments: Under review
\\
 Proteins play a critical role in carrying out biological functions, and their
3D structures are essential in determining their functions. Accurately
predicting the conformation of protein side-chains given their backbones is
important for applications in protein structure prediction, design and
protein-protein interactions. Traditional methods are computationally intensive
and have limited accuracy, while existing machine learning methods treat the
problem as a regression task and overlook the restrictions imposed by the
constant covalent bond lengths and angles. In this work, we present DiffPack, a
torsional diffusion model that learns the joint distribution of side-chain
torsional angles, the only degrees of freedom in side-chain packing, by
diffusing and denoising on the torsional space. To avoid issues arising from
simultaneous perturbation of all four torsional angles, we propose
autoregressively generating the four torsional angles from \c{hi}1 to \c{hi}4
and training diffusion models for each torsional angle. We evaluate the method
on several benchmarks for protein side-chain packing and show that our method
achieves improvements of 11.9% and 13.5% in angle accuracy on CASP13 and
CASP14, respectively, with a significantly smaller model size (60x fewer
parameters). Additionally, we show the effectiveness of our method in enhancing
side-chain predictions in the AlphaFold2 model. Code will be available upon the
accept.
\\ ( https://arxiv.org/abs/2306.01794 ,  27092kb)
------------------------------------------------------------------------------
\\
arXiv:2306.01802 (*cross-listing*)
Date: Thu, 1 Jun 2023 16:31:36 GMT   (13535kb,D)

Title: Linear Time GPs for Inferring Latent Trajectories from Neural Spike
 Trains
Authors: Matthew Dowling, Yuan Zhao, Il Memming Park
Categories: q-bio.NC cs.LG stat.AP stat.ML
Comments: Published at ICML 2023
\\
 Latent Gaussian process (GP) models are widely used in neuroscience to
uncover hidden state evolutions from sequential observations, mainly in neural
activity recordings. While latent GP models provide a principled and powerful
solution in theory, the intractable posterior in non-conjugate settings
necessitates approximate inference schemes, which may lack scalability. In this
work, we propose cvHM, a general inference framework for latent GP models
leveraging Hida-Mat\'ern kernels and conjugate computation variational
inference (CVI). With cvHM, we are able to perform variational inference of
latent neural trajectories with linear time complexity for arbitrary
likelihoods. The reparameterization of stationary kernels using Hida-Mat\'ern
GPs helps us connect the latent variable models that encode prior assumptions
through dynamical systems to those that encode trajectory assumptions through
GPs. In contrast to previous work, we use bidirectional information filtering,
leading to a more concise implementation. Furthermore, we employ the Whittle
approximate likelihood to achieve highly efficient hyperparameter learning.
\\ ( https://arxiv.org/abs/2306.01802 ,  13535kb)
------------------------------------------------------------------------------
\\
arXiv:2306.01814 (*cross-listing*)
Date: Fri, 2 Jun 2023 09:33:19 GMT   (2048kb,D)

Title: Fast Interactive Search with a Scale-Free Comparison Oracle
Authors: Daniyar Chumbalov, Lars Klein, Lucas Maystre, Matthias Grossglauser
Categories: cs.IR cs.HC cs.LG
\\
 A comparison-based search algorithm lets a user find a target item $t$ in a
database by answering queries of the form, ``Which of items $i$ and $j$ is
closer to $t$?'' Instead of formulating an explicit query (such as one or
several keywords), the user navigates towards the target via a sequence of such
(typically noisy) queries.
 We propose a scale-free probabilistic oracle model called $\gamma$-CKL for
such similarity triplets $(i,j;t)$, which generalizes the CKL triplet model
proposed in the literature. The generalization affords independent control over
the discriminating power of the oracle and the dimension of the feature space
containing the items.
 We develop a search algorithm with provably exponential rate of convergence
under the $\gamma$-CKL oracle, thanks to a backtracking strategy that deals
with the unavoidable errors in updating the belief region around the target.
 We evaluate the performance of the algorithm both over the posited oracle and
over several real-world triplet datasets. We also report on a comprehensive
user study, where human subjects navigate a database of face portraits.
\\ ( https://arxiv.org/abs/2306.01814 ,  2048kb)
------------------------------------------------------------------------------
\\
arXiv:2306.01822 (*cross-listing*)
Date: Fri, 2 Jun 2023 13:41:47 GMT   (450kb)

Title: ErfReLU: Adaptive Activation Function for Deep Neural Network
Authors: Ashish Rajanand, Pradeep Singh
Categories: cs.NE cs.LG
\\
 Recent research has found that the activation function (AF) selected for
adding non-linearity into the output can have a big impact on how effectively
deep learning networks perform. Developing activation functions that can adapt
simultaneously with learning is a need of time. Researchers recently started
developing activation functions that can be trained throughout the learning
process, known as trainable, or adaptive activation functions (AAF). Research
on AAF that enhance the outcomes is still in its early stages. In this paper, a
novel activation function 'ErfReLU' has been developed based on the erf
function and ReLU. This function exploits the ReLU and the error function (erf)
to its advantage. State of art activation functions like Sigmoid, ReLU, Tanh,
and their properties have been briefly explained. Adaptive activation functions
like Tanhsoft1, Tanhsoft2, Tanhsoft3, TanhLU, SAAF, ErfAct, Pserf, Smish, and
Serf have also been described. Lastly, performance analysis of 9 trainable
activation functions along with the proposed one namely Tanhsoft1, Tanhsoft2,
Tanhsoft3, TanhLU, SAAF, ErfAct, Pserf, Smish, and Serf has been shown by
applying these activation functions in MobileNet, VGG16, and ResNet models on
CIFAR-10, MNIST, and FMNIST benchmark datasets.
\\ ( https://arxiv.org/abs/2306.01822 ,  450kb)
------------------------------------------------------------------------------
\\
arXiv:2306.01824 (*cross-listing*)
Date: Fri, 2 Jun 2023 14:13:50 GMT   (6541kb,D)

Title: Enhancing the Protein Tertiary Structure Prediction by Multiple Sequence
 Alignment Generation
Authors: Le Zhang, Jiayang Chen, Tao Shen, Yu Li, Siqi Sun
Categories: q-bio.QM cs.CE cs.LG q-bio.BM
\\
 The field of protein folding research has been greatly advanced by deep
learning methods, with AlphaFold2 (AF2) demonstrating exceptional performance
and atomic-level precision. As co-evolution is integral to protein structure
prediction, AF2's accuracy is significantly influenced by the depth of multiple
sequence alignment (MSA), which requires extensive exploration of a large
protein database for similar sequences. However, not all protein sequences
possess abundant homologous families, and consequently, AF2's performance can
degrade on such queries, at times failing to produce meaningful results. To
address this, we introduce a novel generative language model, MSA-Augmenter,
which leverages protein-specific attention mechanisms and large-scale MSAs to
generate useful, novel protein sequences not currently found in databases.
These sequences supplement shallow MSAs, enhancing the accuracy of structural
property predictions. Our experiments on CASP14 demonstrate that MSA-Augmenter
can generate de novo sequences that retain co-evolutionary information from
inferior MSAs, thereby improving protein structure prediction quality on top of
strong AF2.
\\ ( https://arxiv.org/abs/2306.01824 ,  6541kb)
------------------------------------------------------------------------------
\\
arXiv:2306.01869 (*cross-listing*)
Date: Fri, 2 Jun 2023 18:55:27 GMT   (770kb,D)

Title: Fast $(1+\varepsilon)$-Approximation Algorithms for Binary Matrix
 Factorization
Authors: Ameya Velingker, Maximilian V\"otsch, David P. Woodruff, Samson Zhou
Categories: cs.DS cs.LG
Comments: ICML 2023
\\
 We introduce efficient $(1+\varepsilon)$-approximation algorithms for the
binary matrix factorization (BMF) problem, where the inputs are a matrix
$\mathbf{A}\in\{0,1\}^{n\times d}$, a rank parameter $k>0$, as well as an
accuracy parameter $\varepsilon>0$, and the goal is to approximate $\mathbf{A}$
as a product of low-rank factors $\mathbf{U}\in\{0,1\}^{n\times k}$ and
$\mathbf{V}\in\{0,1\}^{k\times d}$. Equivalently, we want to find $\mathbf{U}$
and $\mathbf{V}$ that minimize the Frobenius loss $\|\mathbf{U}\mathbf{V} -
\mathbf{A}\|_F^2$. Before this work, the state-of-the-art for this problem was
the approximation algorithm of Kumar et. al. [ICML 2019], which achieves a
$C$-approximation for some constant $C\ge 576$. We give the first
$(1+\varepsilon)$-approximation algorithm using running time singly exponential
in $k$, where $k$ is typically a small integer. Our techniques generalize to
other common variants of the BMF problem, admitting bicriteria
$(1+\varepsilon)$-approximation algorithms for $L_p$ loss functions and the
setting where matrix operations are performed in $\mathbb{F}_2$. Our approach
can be implemented in standard big data models, such as the streaming or
distributed models.
\\ ( https://arxiv.org/abs/2306.01869 ,  770kb)
------------------------------------------------------------------------------
\\
arXiv:2306.01916 (*cross-listing*)
Date: Fri, 2 Jun 2023 21:02:51 GMT   (1191kb,D)

Title: In-the-wild Speech Emotion Conversion Using Disentangled Self-Supervised
 Representations and Neural Vocoder-based Resynthesis
Authors: Navin Raj Prabhu, Nale Lehmann-Willenbrock and Timo Gerkmann
Categories: eess.AS cs.HC cs.LG
Comments: Submitted to 15th ITG Conference on Speech Communication
\\
 Speech emotion conversion aims to convert the expressed emotion of a spoken
utterance to a target emotion while preserving the lexical information and the
speaker's identity. In this work, we specifically focus on in-the-wild emotion
conversion where parallel data does not exist, and the problem of disentangling
lexical, speaker, and emotion information arises. In this paper, we introduce a
methodology that uses self-supervised networks to disentangle the lexical,
speaker, and emotional content of the utterance, and subsequently uses a
HiFiGAN vocoder to resynthesise the disentangled representations to a speech
signal of the targeted emotion. For better representation and to achieve
emotion intensity control, we specifically focus on the aro\-usal dimension of
continuous representations, as opposed to performing emotion conversion on
categorical representations. We test our methodology on the large in-the-wild
MSP-Podcast dataset. Results reveal that the proposed approach is aptly
conditioned on the emotional content of input speech and is capable of
synthesising natural-sounding speech for a target emotion. Results further
reveal that the methodology better synthesises speech for mid-scale arousal (2
to 6) than for extreme arousal (1 and 7).
\\ ( https://arxiv.org/abs/2306.01916 ,  1191kb)
------------------------------------------------------------------------------
\\
arXiv:2306.01945 (*cross-listing*)
Date: Fri, 2 Jun 2023 23:04:19 GMT   (336kb,D)

Title: Efficient Spoken Language Recognition via Multilabel Classification
Authors: Oriol Nieto, Zeyu Jin, Franck Dernoncourt, Justin Salamon
Categories: cs.CL cs.LG
Comments: Accepted to InterSpeech 2023
\\
 Spoken language recognition (SLR) is the task of automatically identifying
the language present in a speech signal. Existing SLR models are either too
computationally expensive or too large to run effectively on devices with
limited resources. For real-world deployment, a model should also gracefully
handle unseen languages outside of the target language set, yet prior work has
focused on closed-set classification where all input languages are known
a-priori. In this paper we address these two limitations: we explore efficient
model architectures for SLR based on convolutional networks, and propose a
multilabel training strategy to handle non-target languages at inference time.
Using the VoxLingua107 dataset, we show that our models obtain competitive
results while being orders of magnitude smaller and faster than current
state-of-the-art methods, and that our multilabel strategy is more robust to
unseen non-target languages compared to multiclass classification.
\\ ( https://arxiv.org/abs/2306.01945 ,  336kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02015 (*cross-listing*)
Date: Sat, 3 Jun 2023 06:19:20 GMT   (1078kb,D)

Title: Machine learning enabled experimental design and parameter estimation
 for ultrafast spin dynamics
Authors: Zhantao Chen, Cheng Peng, Alexander N. Petsch, Sathya R. Chitturi,
 Alana Okullo, Sugata Chowdhury, Chun Hong Yoon, Joshua J. Turner
Categories: cond-mat.mtrl-sci cs.LG physics.comp-ph physics.data-an
\\
 Advanced experimental measurements are crucial for driving theoretical
developments and unveiling novel phenomena in condensed matter and material
physics, which often suffer from the scarcity of facility resources and
increasing complexities. To address the limitations, we introduce a methodology
that combines machine learning with Bayesian optimal experimental design
(BOED), exemplified with x-ray photon fluctuation spectroscopy (XPFS)
measurements for spin fluctuations. Our method employs a neural network model
for large-scale spin dynamics simulations for precise distribution and utility
calculations in BOED. The capability of automatic differentiation from the
neural network model is further leveraged for more robust and accurate
parameter estimation. Our numerical benchmarks demonstrate the superior
performance of our method in guiding XPFS experiments, predicting model
parameters, and yielding more informative measurements within limited
experimental time. Although focusing on XPFS and spin fluctuations, our method
can be adapted to other experiments, facilitating more efficient data
collection and accelerating scientific discoveries.
\\ ( https://arxiv.org/abs/2306.02015 ,  1078kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02108 (*cross-listing*)
Date: Sat, 3 Jun 2023 13:16:17 GMT   (10190kb,D)

Title: Random matrix theory and the loss surfaces of neural networks
Authors: Nicholas P Baskerville
Categories: math-ph cs.LG math.MP math.PR
Comments: 320 pages, PhD thesis
\\
 Neural network models are one of the most successful approaches to machine
learning, enjoying an enormous amount of development and research over recent
years and finding concrete real-world applications in almost any conceivable
area of science, engineering and modern life in general. The theoretical
understanding of neural networks trails significantly behind their practical
success and the engineering heuristics that have grown up around them. Random
matrix theory provides a rich framework of tools with which aspects of neural
network phenomenology can be explored theoretically. In this thesis, we
establish significant extensions of prior work using random matrix theory to
understand and describe the loss surfaces of large neural networks,
particularly generalising to different architectures. Informed by the
historical applications of random matrix theory in physics and elsewhere, we
establish the presence of local random matrix universality in real neural
networks and then utilise this as a modeling assumption to derive powerful and
novel results about the Hessians of neural network loss surfaces and their
spectra. In addition to these major contributions, we make use of random matrix
models for neural network loss surfaces to shed light on modern neural network
training approaches and even to derive a novel and effective variant of a
popular optimisation algorithm.
 Overall, this thesis provides important contributions to cement the place of
random matrix theory in the theoretical study of modern neural networks,
reveals some of the limits of existing approaches and begins the study of an
entirely new role for random matrix theory in the theory of deep learning with
important experimental discoveries and novel theoretical results based on local
random matrix universality.
\\ ( https://arxiv.org/abs/2306.02108 ,  10190kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02149 (*cross-listing*)
Date: Sat, 3 Jun 2023 16:34:25 GMT   (425kb,D)

Title: Infomorphic networks: Locally learning neural networks derived from
 partial information decomposition
Authors: Marcel Graetz, Abdullah Makkeh, Andreas C. Schneider, David A.
 Ehrlich, Viola Priesemann and Michael Wibral
Categories: cs.IT cs.LG cs.NE math.IT
Comments: 31 pages, 5 figures
\\
 Understanding the intricate cooperation among individual neurons in
performing complex tasks remains a challenge to this date. In this paper, we
propose a novel type of model neuron that emulates the functional
characteristics of biological neurons by optimizing an abstract local
information processing goal. We have previously formulated such a goal function
based on principles from partial information decomposition (PID). Here, we
present a corresponding parametric local learning rule which serves as the
foundation of "infomorphic networks" as a novel concrete model of neural
networks. We demonstrate the versatility of these networks to perform tasks
from supervised, unsupervised and memory learning. By leveraging the
explanatory power and interpretable nature of the PID framework, these
infomorphic networks represent a valuable tool to advance our understanding of
cortical function.
\\ ( https://arxiv.org/abs/2306.02149 ,  425kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02150 (*cross-listing*)
Date: Sat, 3 Jun 2023 16:36:43 GMT   (7810kb,D)

Title: An information field theory approach to Bayesian state and parameter
 estimation in dynamical systems
Authors: Kairui Hao, Ilias Bilionis
Categories: physics.data-an cs.LG
\\
 Dynamical system state estimation and parameter calibration problems are
ubiquitous across science and engineering. Bayesian approaches to the problem
are the gold standard as they allow for the quantification of uncertainties and
enable the seamless fusion of different experimental modalities. When the
dynamics are discrete and stochastic, one may employ powerful techniques such
as Kalman, particle, or variational filters. Practitioners commonly apply these
methods to continuous-time, deterministic dynamical systems after discretizing
the dynamics and introducing fictitious transition probabilities. However,
approaches based on time-discretization suffer from the curse of dimensionality
since the number of random variables grows linearly with the number of
time-steps. Furthermore, the introduction of fictitious transition
probabilities is an unsatisfactory solution because it increases the number of
model parameters and may lead to inference bias. To address these drawbacks,
the objective of this paper is to develop a scalable Bayesian approach to state
and parameter estimation suitable for continuous-time, deterministic dynamical
systems. Our methodology builds upon information field theory. Specifically, we
construct a physics-informed prior probability measure on the function space of
system responses so that functions that satisfy the physics are more likely.
This prior allows us to quantify model form errors. We connect the system's
response to observations through a probabilistic model of the measurement
process. The joint posterior over the system responses and all parameters is
given by Bayes' rule. To approximate the intractable posterior, we develop a
stochastic variational inference algorithm. In summary, the developed
methodology offers a powerful framework for Bayesian estimation in dynamical
systems.
\\ ( https://arxiv.org/abs/2306.02150 ,  7810kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02153 (*cross-listing*)
Date: Sat, 3 Jun 2023 16:44:21 GMT   (479kb)

Title: Acoustic Word Embeddings for Untranscribed Target Languages with
 Continued Pretraining and Learned Pooling
Authors: Ramon Sanabria, Ondrej Klejch, Hao Tang, Sharon Goldwater
Categories: cs.CL cs.LG cs.SD eess.AS
Comments: Accepted to Interspeech 2023
\\
 Acoustic word embeddings are typically created by training a pooling function
using pairs of word-like units. For unsupervised systems, these are mined using
k-nearest neighbor (KNN) search, which is slow. Recently, mean-pooled
representations from a pre-trained self-supervised English model were suggested
as a promising alternative, but their performance on target languages was not
fully competitive. Here, we explore improvements to both approaches: we use
continued pre-training to adapt the self-supervised model to the target
language, and we use a multilingual phone recognizer (MPR) to mine phone n-gram
pairs for training the pooling function. Evaluating on four languages, we show
that both methods outperform a recent approach on word discrimination.
Moreover, the MPR method is orders of magnitude faster than KNN, and is highly
data efficient. We also show a small improvement from performing learned
pooling on top of the continued pre-trained representations.
\\ ( https://arxiv.org/abs/2306.02153 ,  479kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02169 (*cross-listing*)
Date: Sat, 3 Jun 2023 18:22:01 GMT   (1774kb,D)

Title: Probabilistic Solar Proxy Forecasting with Neural Network Ensembles
Authors: Joshua D. Daniell and Piyush M. Mehta
Categories: physics.space-ph cs.LG
Comments: 23 pages, 12 figures, 5 Tables
\\
 Space weather indices are used commonly to drive forecasts of thermosphere
density, which directly affects objects in low-Earth orbit (LEO) through
atmospheric drag. One of the most commonly used space weather proxies, $F_{10.7
cm}$, correlates well with solar extreme ultra-violet (EUV) energy deposition
into the thermosphere. Currently, the USAF contracts Space Environment
Technologies (SET), which uses a linear algorithm to forecast $F_{10.7 cm}$. In
this work, we introduce methods using neural network ensembles with multi-layer
perceptrons (MLPs) and long-short term memory (LSTMs) to improve on the SET
predictions. We make predictions only from historical $F_{10.7 cm}$ values, but
also investigate data manipulation to improve forecasting. We investigate data
manipulation methods (backwards averaging and lookback) as well as multi step
and dynamic forecasting. This work shows an improvement over the baseline when
using ensemble methods. The best models found in this work are ensemble
approaches using multi step or a combination of multi step and dynamic
predictions. Nearly all approaches offer an improvement, with the best models
improving between 45 and 55\% on relative MSE. Other relative error metrics
were shown to improve greatly when ensembles methods were used. We were also
able to leverage the ensemble approach to provide a distribution of predicted
values; allowing an investigation into forecast uncertainty. Our work found
models that produced less biased predictions at elevated and high solar
activity levels. Uncertainty was also investigated through the use of a
calibration error score metric (CES), our best ensemble reached similar CES as
other work.
\\ ( https://arxiv.org/abs/2306.02169 ,  1774kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02193 (*cross-listing*)
Date: Sat, 3 Jun 2023 20:37:46 GMT   (611kb,D)

Title: LDEB -- Label Digitization with Emotion Binarization and Machine
 Learning for Emotion Recognition in Conversational Dialogues
Authors: Amitabha Dey, Shan Suthaharan
Categories: cs.CL cs.LG
Comments: 10 pages, 3 figures, 4 tables
\\
 Emotion recognition in conversations (ERC) is vital to the advancements of
conversational AI and its applications. Therefore, the development of an
automated ERC model using the concepts of machine learning (ML) would be
beneficial. However, the conversational dialogues present a unique problem
where each dialogue depicts nested emotions that entangle the association
between the emotional feature descriptors and emotion type (or label). This
entanglement that can be multiplied with the presence of data paucity is an
obstacle for a ML model. To overcome this problem, we proposed a novel approach
called Label Digitization with Emotion Binarization (LDEB) that disentangles
the twists by utilizing the text normalization and 7-bit digital encoding
techniques and constructs a meaningful feature space for a ML model to be
trained. We also utilized the publicly available dataset called the
FETA-DailyDialog dataset for feature learning and developed a hierarchical ERC
model using random forest (RF) and artificial neural network (ANN) classifiers.
Simulations showed that the ANN-based ERC model was able to predict emotion
with the best accuracy and precision scores of about 74% and 76%, respectively.
Simulations also showed that the ANN-model could reach a training accuracy
score of about 98% with 60 epochs. On the other hand, the RF-based ERC model
was able to predict emotions with the best accuracy and precision scores of
about 78% and 75%, respectively.
\\ ( https://arxiv.org/abs/2306.02193 ,  611kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02206 (*cross-listing*)
Date: Sat, 3 Jun 2023 22:30:45 GMT   (4740kb)

Title: Mitigating Molecular Aggregation in Drug Discovery with Predictive
 Insights from Explainable AI
Authors: Hunter Sturm, Jonas Teufel, Kaitlin A. Isfeld, Pascal Friederich,
 Rebecca L. Davis
Categories: q-bio.BM cond-mat.soft cs.LG
Comments: 17 pages, plus SI
\\
 As the importance of high-throughput screening (HTS) continues to grow due to
its value in early stage drug discovery and data generation for training
machine learning models, there is a growing need for robust methods for
pre-screening compounds to identify and prevent false-positive hits. Small,
colloidally aggregating molecules are one of the primary sources of
false-positive hits in high-throughput screens, making them an ideal candidate
to target for removal from libraries using predictive pre-screening tools.
However, a lack of understanding of the causes of molecular aggregation
introduces difficulty in the development of predictive tools for detecting
aggregating molecules. Herein, we present an examination of the molecular
features differentiating datasets of aggregating and non-aggregating molecules,
as well as a machine learning approach to predicting molecular aggregation. Our
method uses explainable graph neural networks and counterfactuals to reliably
predict and explain aggregation, giving additional insights and design rules
for future screening. The integration of this method in HTS approaches will
help combat false positives, providing better lead molecules more rapidly and
thus accelerating drug discovery cycles.
\\ ( https://arxiv.org/abs/2306.02206 ,  4740kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02212 (*cross-listing*)
Date: Sat, 3 Jun 2023 23:31:27 GMT   (327kb,D)

Title: Accelerated Quasi-Newton Proximal Extragradient: Faster Rate for Smooth
 Convex Optimization
Authors: Ruichen Jiang and Aryan Mokhtari
Categories: math.OC cs.LG stat.ML
Comments: 44 pages, 1 figure
\\
 In this paper, we propose an accelerated quasi-Newton proximal extragradient
(A-QPNE) method for solving unconstrained smooth convex optimization problems.
With access only to the gradients of the objective, we prove that our method
can achieve a convergence rate of ${O}\bigl(\min\{\frac{1}{k^2},
\frac{\sqrt{d\log k}}{k^{2.5}}\}\bigr)$, where $d$ is the problem dimension and
$k$ is the number of iterations. In particular, in the regime where $k =
{O}(d)$, our method matches the optimal rate of ${O}(\frac{1}{k^2})$ by
Nesterov's accelerated gradient (NAG). Moreover, in the the regime where $k =
\Omega(d \log d)$, it outperforms NAG and converges at a faster rate of
${O}\bigl(\frac{\sqrt{d\log k}}{k^{2.5}}\bigr)$. To the best of our knowledge,
this result is the first to demonstrate a provable gain of a quasi-Newton-type
method over NAG in the convex setting. To achieve such results, we build our
method on a recent variant of the Monteiro-Svaiter acceleration framework and
adopt an online learning perspective to update the Hessian approximation
matrices, in which we relate the convergence rate of our method to the dynamic
regret of a specific online convex optimization problem in the space of
matrices.
\\ ( https://arxiv.org/abs/2306.02212 ,  327kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02271 (*cross-listing*)
Date: Sun, 4 Jun 2023 06:30:13 GMT   (7541kb,D)

Title: SubspaceNet: Deep Learning-Aided Subspace Methods for DoA Estimation
Authors: Dor H. Shmuel, Julian P. Merkofer, Guy Revach, Ruud J. G. van Sloun,
 and Nir Shlezinger
Categories: eess.SP cs.LG
Comments: Under review for publication in the IEEE
\\
 Direction of arrival (DoA) estimation is a fundamental task in array
processing. A popular family of DoA estimation algorithms are subspace methods,
which operate by dividing the measurements into distinct signal and noise
subspaces. Subspace methods, such as Multiple Signal Classification (MUSIC) and
Root-MUSIC, rely on several restrictive assumptions, including narrowband
non-coherent sources and fully calibrated arrays, and their performance is
considerably degraded when these do not hold. In this work we propose
SubspaceNet; a data-driven DoA estimator which learns how to divide the
observations into distinguishable subspaces. This is achieved by utilizing a
dedicated deep neural network to learn the empirical autocorrelation of the
input, by training it as part of the Root-MUSIC method, leveraging the inherent
differentiability of this specific DoA estimator, while removing the need to
provide a ground-truth decomposable autocorrelation matrix. Once trained, the
resulting SubspaceNet serves as a universal surrogate covariance estimator that
can be applied in combination with any subspace-based DoA estimation method,
allowing its successful application in challenging setups. SubspaceNet is shown
to enable various DoA estimation algorithms to cope with coherent sources,
wideband signals, low SNR, array mismatches, and limited snapshots, while
preserving the interpretability and the suitability of classic subspace
methods.
\\ ( https://arxiv.org/abs/2306.02271 ,  7541kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02283 (*cross-listing*)
Date: Sun, 4 Jun 2023 07:01:31 GMT   (867kb,D)

Title: Matrix Completion from General Deterministic Sampling Patterns
Authors: Hanbyul Lee, Rahul Mazumder, Qifan Song, Jean Honorio
Categories: stat.ML cs.LG
\\
 Most of the existing works on provable guarantees for low-rank matrix
completion algorithms rely on some unrealistic assumptions such that matrix
entries are sampled randomly or the sampling pattern has a specific structure.
In this work, we establish theoretical guarantee for the exact and approximate
low-rank matrix completion problems which can be applied to any deterministic
sampling schemes. For this, we introduce a graph having observed entries as its
edge set, and investigate its graph properties involving the performance of the
standard constrained nuclear norm minimization algorithm. We theoretically and
experimentally show that the algorithm can be successful as the observation
graph is well-connected and has similar node degrees. Our result can be viewed
as an extension of the works by Bhojanapalli and Jain [2014] and Burnwal and
Vidyasagar [2020], in which the node degrees of the observation graph were
assumed to be the same. In particular, our theory significantly improves their
results when the underlying matrix is symmetric.
\\ ( https://arxiv.org/abs/2306.02283 ,  867kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02294 (*cross-listing*)
Date: Sun, 4 Jun 2023 08:09:26 GMT   (60kb)

Title: Exposing Bias in Online Communities through Large-Scale Language Models
Authors: Celine Wald and Lukas Pfahler
Categories: cs.CL cs.CY cs.LG
\\
 Progress in natural language generation research has been shaped by the
ever-growing size of language models. While large language models pre-trained
on web data can generate human-sounding text, they also reproduce social biases
and contribute to the propagation of harmful stereotypes. This work utilises
the flaw of bias in language models to explore the biases of six different
online communities. In order to get an insight into the communities'
viewpoints, we fine-tune GPT-Neo 1.3B with six social media datasets. The bias
of the resulting models is evaluated by prompting the models with different
demographics and comparing the sentiment and toxicity values of these
generations. Together, these methods reveal that bias differs in type and
intensity for the various models. This work not only affirms how easily bias is
absorbed from training data but also presents a scalable method to identify and
compare the bias of different datasets or communities. Additionally, the
examples generated for this work demonstrate the limitations of using automated
sentiment and toxicity classifiers in bias research.
\\ ( https://arxiv.org/abs/2306.02294 ,  60kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02295 (*cross-listing*)
Date: Sun, 4 Jun 2023 08:12:34 GMT   (33kb)

Title: A Mathematical Abstraction for Balancing the Trade-off Between
 Creativity and Reality in Large Language Models
Authors: Ritwik Sinha, Zhao Song, Tianyi Zhou
Categories: cs.CL cs.LG
\\
 Large Language Models have become popular for their remarkable capabilities
in human-oriented tasks and traditional natural language processing tasks. Its
efficient functioning is attributed to the attention mechanism in the
Transformer architecture, enabling it to concentrate on particular aspects of
the input.
 LLMs are increasingly being used in domains such as generating prose, poetry
or art, which require the model to be creative (e.g. Adobe firefly). LLMs
possess advanced language generation abilities that enable them to generate
distinctive and captivating content. This utilization of LLMs in generating
narratives shows their flexibility and potential for use in domains that extend
beyond conventional natural language processing duties.
 In different contexts, we may expect the LLM to generate factually correct
answers, that match reality; e.g., question-answering systems or online
assistants. In such situations, being correct is critical to LLMs being trusted
in practice. The Bing Chatbot provides its users with the flexibility to select
one of the three output modes: creative, balanced, and precise. Each mode
emphasizes creativity and factual accuracy differently.
 In this work, we provide a mathematical abstraction to describe creativity
and reality based on certain losses. A model trained on these losses balances
the trade-off between the creativity and reality of the model.
\\ ( https://arxiv.org/abs/2306.02295 ,  33kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02300 (*cross-listing*)
Date: Sun, 4 Jun 2023 08:53:27 GMT   (29609kb,D)

Title: How neural networks learn to classify chaotic time series
Authors: Alessandro Corbetta, Thomas Geert de Jong
Categories: math.DS cs.LG
MSC-class: 37M10, 68T07
\\
 Neural networks are increasingly employed to model, analyze and control
non-linear dynamical systems ranging from physics to biology. Owing to their
universal approximation capabilities, they regularly outperform
state-of-the-art model-driven methods in terms of accuracy, computational
speed, and/or control capabilities. On the other hand, neural networks are very
often they are taken as black boxes whose explainability is challenged, among
others, by huge amounts of trainable parameters. In this paper, we tackle the
outstanding issue of analyzing the inner workings of neural networks trained to
classify regular-versus-chaotic time series. This setting, well-studied in
dynamical systems, enables thorough formal analyses. We focus specifically on a
family of networks dubbed Large Kernel Convolutional Neural Networks (LKCNN),
recently introduced by Boull\'{e} et al. (2021). These non-recursive networks
have been shown to outperform other established architectures (e.g. residual
networks, shallow neural networks and fully convolutional networks) at this
classification task. Furthermore, they outperform ``manual'' classification
approaches based on direct reconstruction of the Lyapunov exponent. We find
that LKCNNs use qualitative properties of the input sequence. In particular, we
show that the relation between input periodicity and activation periodicity is
key for the performance of LKCNN models. Low performing models show, in fact,
analogous periodic activations to random untrained models. This could give very
general criteria for identifying, a priori, trained models that have poor
accuracy.
\\ ( https://arxiv.org/abs/2306.02300 ,  29609kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02349 (*cross-listing*)
Date: Sun, 4 Jun 2023 12:54:00 GMT   (404kb,D)

Title: bgGLUE: A Bulgarian General Language Understanding Evaluation Benchmark
Authors: Momchil Hardalov, Pepa Atanasova, Todor Mihaylov, Galia Angelova,
 Kiril Simov, Petya Osenova, Ves Stoyanov, Ivan Koychev, Preslav Nakov,
 Dragomir Radev
Categories: cs.CL cs.IR cs.LG
Comments: Accepted to ACL 2023 (Main Conference)
MSC-class: 68T50
ACM-class: F.2.2; I.2.7
\\
 We present bgGLUE (Bulgarian General Language Understanding Evaluation), a
benchmark for evaluating language models on Natural Language Understanding
(NLU) tasks in Bulgarian. Our benchmark includes NLU tasks targeting a variety
of NLP problems (e.g., natural language inference, fact-checking, named entity
recognition, sentiment analysis, question answering, etc.) and machine learning
tasks (sequence labeling, document-level classification, and regression). We
run the first systematic evaluation of pre-trained language models for
Bulgarian, comparing and contrasting results across the nine tasks in the
benchmark. The evaluation results show strong performance on sequence labeling
tasks, but there is a lot of room for improvement for tasks that require more
complex reasoning. We make bgGLUE publicly available together with the
fine-tuning and the evaluation code, as well as a public leaderboard at
https://bgglue.github.io/, and we hope that it will enable further advancements
in developing NLU models for Bulgarian.
\\ ( https://arxiv.org/abs/2306.02349 ,  404kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02379 (*cross-listing*)
Date: Sun, 4 Jun 2023 15:26:28 GMT   (1156kb,D)

Title: Modular Transformers: Compressing Transformers into Modularized Layers
 for Flexible Efficient Inference
Authors: Wangchunshu Zhou, Ronan Le Bras, Yejin Choi
Categories: cs.CL cs.LG
Comments: ACL 2023 Findings
\\
 Pre-trained Transformer models like T5 and BART have advanced the state of
the art on a wide range of text generation tasks. Compressing these models into
smaller ones has become critically important for practical use. Common neural
network compression techniques such as knowledge distillation or quantization
are limited to static compression where the compression ratio is fixed. In this
paper, we introduce Modular Transformers, a modularized encoder-decoder
framework for flexible sequence-to-sequence model compression. Modular
Transformers train modularized layers that have the same function of two or
more consecutive layers in the original model via module replacing and
knowledge distillation. After training, the modularized layers can be flexibly
assembled into sequence-to-sequence models that meet different
performance-efficiency trade-offs. Experimental results show that after a
single training phase, by simply varying the assembling strategy, Modular
Transformers can achieve flexible compression ratios from 1.1x to 6x with
little to moderate relative performance drop.
\\ ( https://arxiv.org/abs/2306.02379 ,  1156kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02383 (*cross-listing*)
Date: Sun, 4 Jun 2023 15:33:16 GMT   (3053kb)

Title: Evolution of Efficient Symbolic Communication Codes
Authors: Anton Kolonin
Categories: cs.CL cs.IT cs.LG math.IT
Comments: 9 pages, 6 figures
\\
 The paper explores how the human natural language structure can be seen as a
product of evolution of inter-personal communication code, targeting
maximisation of such culture-agnostic and cross-lingual metrics such as
anti-entropy, compression factor and cross-split F1 score. The exploration is
done as part of a larger unsupervised language learning effort, the attempt is
made to perform meta-learning in a space of hyper-parameters maximising F1
score based on the "ground truth" language structure, by means of maximising
the metrics mentioned above. The paper presents preliminary results of
cross-lingual word-level segmentation tokenisation study for Russian, Chinese
and English as well as subword segmentation or morphological parsing study for
English. It is found that language structure form the word-level segmentation
or tokenisation can be found as driven by all of these metrics, anti-entropy
being more relevant to English and Russian while compression factor more
specific for Chinese. The study for subword segmentation or morphological
parsing on English lexicon has revealed straight connection between the
compression been found to be associated with compression factor, while,
surprising, the same connection with anti-entropy has turned to be the inverse.
\\ ( https://arxiv.org/abs/2306.02383 ,  3053kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02421 (*cross-listing*)
Date: Sun, 4 Jun 2023 17:53:30 GMT   (12481kb,D)

Title: Auto-Validate by-History: Auto-Program Data Quality Constraints to
 Validate Recurring Data Pipelines
Authors: Dezhan Tu, Yeye He, Weiwei Cui, Song Ge, Haidong Zhang, Han Shi,
 Dongmei Zhang, Surajit Chaudhuri
Categories: cs.DB cs.LG
Comments: full version of a paper accepted to KDD 2023
\\
 Data pipelines are widely employed in modern enterprises to power a variety
of Machine-Learning (ML) and Business-Intelligence (BI) applications.
Crucially, these pipelines are \emph{recurring} (e.g., daily or hourly) in
production settings to keep data updated so that ML models can be re-trained
regularly, and BI dashboards refreshed frequently. However, data quality (DQ)
issues can often creep into recurring pipelines because of upstream schema and
data drift over time. As modern enterprises operate thousands of recurring
pipelines, today data engineers have to spend substantial efforts to
\emph{manually} monitor and resolve DQ issues, as part of their DataOps and
MLOps practices.
 Given the high human cost of managing large-scale pipeline operations, it is
imperative that we can \emph{automate} as much as possible. In this work, we
propose Auto-Validate-by-History (AVH) that can automatically detect DQ issues
in recurring pipelines, leveraging rich statistics from historical executions.
We formalize this as an optimization problem, and develop constant-factor
approximation algorithms with provable precision guarantees. Extensive
evaluations using 2000 production data pipelines at Microsoft demonstrate the
effectiveness and efficiency of AVH.
\\ ( https://arxiv.org/abs/2306.02421 ,  12481kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02422 (*cross-listing*)
Date: Sun, 4 Jun 2023 17:54:11 GMT   (1908kb,D)

Title: A Generalized Alternating Method for Bilevel Optimization under the
 Polyak-{\L}ojasiewicz Condition
Authors: Quan Xiao, Songtao Lu, Tianyi Chen
Categories: math.OC cs.LG
\\
 Bilevel optimization has recently regained interest owing to its applications
in emerging machine learning fields such as hyperparameter optimization,
meta-learning, and reinforcement learning. Recent results have shown that
simple alternating (implicit) gradient-based algorithms can achieve the same
convergence rate of single-level gradient descent (GD) for bilevel problems
with a strongly convex lower-level objective. However, it remains unclear
whether this result can be generalized to bilevel problems beyond this basic
setting. In this paper, we propose a Generalized ALternating mEthod for bilevel
opTimization (GALET) with a nonconvex lower-level objective that satisfies the
Polyak-{\L}ojasiewicz (PL) condition. We first introduce a stationary metric
for the considered bilevel problems, which generalizes the existing metric. We
then establish that GALET achieves an $\epsilon$-stationary metric for the
considered problem within $\tilde{\cal O}(\epsilon^{-1})$ iterations, which
matches the iteration complexity of GD for smooth nonconvex problems.
\\ ( https://arxiv.org/abs/2306.02422 ,  1908kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02433 (*cross-listing*)
Date: Sun, 4 Jun 2023 18:32:50 GMT   (2567kb,D)

Title: Riemannian Low-Rank Model Compression for Federated Learning with
 Over-the-Air Aggregation
Authors: Ye Xue, Vincent Lau
Categories: eess.SP cs.LG
Comments: This paper has been accepted for publication as a REGULAR paper in
 the IEEE Transactions on Signal Processing
\\
 Low-rank model compression is a widely used technique for reducing the
computational load when training machine learning models. However, existing
methods often rely on relaxing the low-rank constraint of the model weights
using a regularized nuclear norm penalty, which requires an appropriate
hyperparameter that can be difficult to determine in practice. Furthermore,
existing compression techniques are not directly applicable to efficient
over-the-air (OTA) aggregation in federated learning (FL) systems for
distributed Internet-of-Things (IoT) scenarios. In this paper, we propose a
novel manifold optimization formulation for low-rank model compression in FL
that does not relax the low-rank constraint. Our optimization is conducted
directly over the low-rank manifold, guaranteeing that the model is exactly
low-rank. We also introduce a consensus penalty in the optimization formulation
to support OTA aggregation. Based on our optimization formulation, we propose
an alternating Riemannian optimization algorithm with a precoder that enables
efficient OTA aggregation of low-rank local models without sacrificing training
performance. Additionally, we provide convergence analysis in terms of key
system parameters and conduct extensive experiments with real-world datasets to
demonstrate the effectiveness of our proposed Riemannian low-rank model
compression scheme compared to various state-of-the-art baselines.
\\ ( https://arxiv.org/abs/2306.02433 ,  2567kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02473 (*cross-listing*)
Date: Sun, 4 Jun 2023 20:45:14 GMT   (2582kb,D)

Title: Anomaly Detection Techniques in Smart Grid Systems: A Review
Authors: Shampa Banik and Sohag Kumar Saha and Trapa Banik and S M Mostaq
 Hossain
Categories: cs.CR cs.LG
Comments: 7 pages, 3 figures and conference paper (accepted for publication in
 2023 IEEE World AI IOT Congress (AIIOT)
Report-no: #149 (1570906937
Journal-ref: 2023 IEEE World AI IOT Congress (AIIOT)
\\
 Smart grid data can be evaluated for anomaly detection in numerous fields,
including cyber-security, fault detection, electricity theft, etc. The strange
anomalous behaviors may have been caused by various reasons, including peculiar
consumption patterns of the consumers, malfunctioning grid infrastructures,
outages, external cyber-attacks, or energy fraud. Recently, anomaly detection
of the smart grid has attracted a large amount of interest from researchers,
and it is widely applied in a number of high-impact fields. One of the most
significant challenges within the smart grid is the implementation of efficient
anomaly detection for multiple forms of aberrant behaviors. In this paper, we
provide a scoping review of research from the recent advancements in anomaly
detection in the context of smart grids. We categorize our study from numerous
aspects for deep understanding and inspection of the research challenges so
far. Finally, after analyzing the gap in the reviewed paper, the direction for
future research on anomaly detection in smart-grid systems has been provided
briefly.
\\ ( https://arxiv.org/abs/2306.02473 ,  2582kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02527 (*cross-listing*)
Date: Mon, 5 Jun 2023 01:23:49 GMT   (2426kb,D)

Title: Searching for Optimal Per-Coordinate Step-sizes with Multidimensional
 Backtracking
Authors: Frederik Kunstner, Victor S. Portella, Mark Schmidt and Nick Harvey
Categories: math.OC cs.LG
\\
 The backtracking line-search is an effective technique to automatically tune
the step-size in smooth optimization. It guarantees similar performance to
using the theoretically optimal step-size. Many approaches have been developed
to instead tune per-coordinate step-sizes, also known as diagonal
preconditioners, but none of the existing methods are provably competitive with
the optimal per-coordinate stepsizes. We propose multidimensional backtracking,
an extension of the backtracking line-search to find good diagonal
preconditioners for smooth convex problems. Our key insight is that the
gradient with respect to the step-sizes, also known as hypergradients, yields
separating hyperplanes that let us search for good preconditioners using
cutting-plane methods. As black-box cutting-plane approaches like the ellipsoid
method are computationally prohibitive, we develop an efficient algorithm
tailored to our setting. Multidimensional backtracking is provably competitive
with the best diagonal preconditioner and requires no manual tuning.
\\ ( https://arxiv.org/abs/2306.02527 ,  2426kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02534 (*cross-listing*)
Date: Mon, 5 Jun 2023 01:55:33 GMT   (83kb,D)

Title: Incorporating L2 Phonemes Using Articulatory Features for Robust Speech
 Recognition
Authors: Jisung Wang, Haram Lee, Myungwoo Oh
Categories: cs.CL cs.LG cs.SD eess.AS
Comments: Accepted at INTERSPEECH 2023
\\
 The limited availability of non-native speech datasets presents a major
challenge in automatic speech recognition (ASR) to narrow the performance gap
between native and non-native speakers. To address this, the focus of this
study is on the efficient incorporation of the L2 phonemes, which in this work
refer to Korean phonemes, through articulatory feature analysis. This not only
enables accurate modeling of pronunciation variants but also allows for the
utilization of both native Korean and English speech datasets. We employ the
lattice-free maximum mutual information (LF-MMI) objective in an end-to-end
manner, to train the acoustic model to align and predict one of multiple
pronunciation candidates. Experimental results show that the proposed method
improves ASR accuracy for Korean L2 speech by training solely on L1 speech
data. Furthermore, fine-tuning on L2 speech improves recognition accuracy for
both L1 and L2 speech without performance trade-offs.
\\ ( https://arxiv.org/abs/2306.02534 ,  83kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02565 (*cross-listing*)
Date: Mon, 5 Jun 2023 03:36:31 GMT   (11312kb,D)

Title: Coupled Variational Autoencoder
Authors: Xiaoran Hao, Patrick Shafto
Categories: stat.ML cs.LG
Comments: ICML 2023
\\
 Variational auto-encoders are powerful probabilistic models in generative
tasks but suffer from generating low-quality samples which are caused by the
holes in the prior. We propose the Coupled Variational Auto-Encoder (C-VAE),
which formulates the VAE problem as one of Optimal Transport (OT) between the
prior and data distributions. The C-VAE allows greater flexibility in priors
and natural resolution of the prior hole problem by enforcing coupling between
the prior and the data distribution and enables flexible optimization through
the primal, dual, and semi-dual formulations of entropic OT. Simulations on
synthetic and real data show that the C-VAE outperforms alternatives including
VAE, WAE, and InfoVAE in fidelity to the data, quality of the latent
representation, and in quality of generated samples.
\\ ( https://arxiv.org/abs/2306.02565 ,  11312kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02568 (*cross-listing*)
Date: Mon, 5 Jun 2023 03:47:59 GMT   (1172kb,D)

Title: Latent Optimal Paths by Gumbel Propagation for Variational Bayesian
 Dynamic Programming
Authors: Xinlei Niu, Christian Walder, Jing Zhang, Charles Patrick Martin
Categories: stat.ML cs.LG
\\
 We propose a unified approach to obtain structured sparse optimal paths in
the latent space of a variational autoencoder (VAE) using dynamic programming
and Gumbel propagation. We solve the classical optimal path problem by a
probability softening solution, called the stochastic optimal path, and
transform a wide range of DP problems into directed acyclic graphs in which all
possible paths follow a Gibbs distribution. We show the equivalence of the
Gibbs distribution to a message-passing algorithm by the properties of the
Gumbel distribution and give all the ingredients required for variational
Bayesian inference. Our approach obtaining latent optimal paths enables
end-to-end training for generative tasks in which models rely on the
information of unobserved structural features. We validate the behavior of our
approach and showcase its applicability in two real-world applications:
text-to-speech and singing voice synthesis.
\\ ( https://arxiv.org/abs/2306.02568 ,  1172kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02628 (*cross-listing*)
Date: Mon, 5 Jun 2023 06:55:39 GMT   (90kb,D)

Title: Active Ranking of Experts Based on their Performances in Many Tasks
Authors: El Mehdi Saad (MISTEA), Nicolas Verzelen (MISTEA), Alexandra
 Carpentier
Categories: stat.ML cs.LG
\\
 We consider the problem of ranking n experts based on their performances on d
tasks. We make a monotonicity assumption stating that for each pair of experts,
one outperforms the other on all tasks. We consider the sequential setting
where in each round, the learner has access to noisy evaluations of actively
chosen pair of expert-task, given the information available up to the actual
round. Given a confidence parameter $\delta$ $\in$ (0, 1), we provide
strategies allowing to recover the correct ranking of experts and develop a
bound on the total number of queries made by our algorithm that hold with
probability at least 1 -- $\delta$. We show that our strategy is adaptive to
the complexity of the problem (our bounds are instance dependent), and develop
matching lower bounds up to a poly-logarithmic factor. Finally, we adapt our
strategy to the relaxed problem of best expert identification and provide
numerical simulation consistent with our theoretical results.
\\ ( https://arxiv.org/abs/2306.02628 ,  90kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02630 (*cross-listing*)
Date: Mon, 5 Jun 2023 06:57:09 GMT   (93kb,D)

Title: Covariance Adaptive Best Arm Identification
Authors: El Mehdi Saad (MISTEA), Gilles Blanchard (LMO, DATASHAPE), Nicolas
 Verzelen (MISTEA)
Categories: stat.ML cs.LG
\\
 We consider the problem of best arm identification in the multi-armed bandit
model, under fixed confidence. Given a confidence input $\delta$, the goal is
to identify the arm with the highest mean reward with a probability of at least
1 -- $\delta$, while minimizing the number of arm pulls. While the literature
provides solutions to this problem under the assumption of independent arms
distributions, we propose a more flexible scenario where arms can be dependent
and rewards can be sampled simultaneously. This framework allows the learner to
estimate the covariance among the arms distributions, enabling a more efficient
identification of the best arm. The relaxed setting we propose is relevant in
various applications, such as clinical trials, where similarities between
patients or drugs suggest underlying correlations in the outcomes. We introduce
new algorithms that adapt to the unknown covariance of the arms and demonstrate
through theoretical guarantees that substantial improvement can be achieved
over the standard setting. Additionally, we provide new lower bounds for the
relaxed setting and present numerical simulations that support their
theoretical findings.
\\ ( https://arxiv.org/abs/2306.02630 ,  93kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02679 (*cross-listing*)
Date: Mon, 5 Jun 2023 08:11:59 GMT   (3561kb,D)

Title: Joint Pre-training and Local Re-training: Transferable Representation
 Learning on Multi-source Knowledge Graphs
Authors: Zequn Sun and Jiacheng Huang and Jinghao Lin and Xiaozhou Xu and Qijin
 Chen and Wei Hu
Categories: cs.CL cs.LG
Comments: Accepted in the 29th ACM SIGKDD International Conference on Knowledge
 Discovery and Data Mining (KDD 2023)
\\
 In this paper, we present the ``joint pre-training and local re-training''
framework for learning and applying multi-source knowledge graph (KG)
embeddings. We are motivated by the fact that different KGs contain
complementary information to improve KG embeddings and downstream tasks. We
pre-train a large teacher KG embedding model over linked multi-source KGs and
distill knowledge to train a student model for a task-specific KG. To enable
knowledge transfer across different KGs, we use entity alignment to build a
linked subgraph for connecting the pre-trained KGs and the target KG. The
linked subgraph is re-trained for three-level knowledge distillation from the
teacher to the student, i.e., feature knowledge distillation, network knowledge
distillation, and prediction knowledge distillation, to generate more
expressive embeddings. The teacher model can be reused for different target KGs
and tasks without having to train from scratch. We conduct extensive
experiments to demonstrate the effectiveness and efficiency of our framework.
\\ ( https://arxiv.org/abs/2306.02679 ,  3561kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02680 (*cross-listing*)
Date: Mon, 5 Jun 2023 08:12:17 GMT   (1653kb,D)

Title: BeAts: Bengali Speech Acts Recognition using Multimodal Attention Fusion
Authors: Ahana Deb, Sayan Nag, Ayan Mahapatra, Soumitri Chattopadhyay, Aritra
 Marik, Pijush Kanti Gayen, Shankha Sanyal, Archi Banerjee, Samir Karmakar
Categories: cs.CL cs.LG cs.SD eess.AS
Comments: Accepted at INTERSPEECH 2023
\\
 Spoken languages often utilise intonation, rhythm, intensity, and structure,
to communicate intention, which can be interpreted differently depending on the
rhythm of speech of their utterance. These speech acts provide the foundation
of communication and are unique in expression to the language. Recent
advancements in attention-based models, demonstrating their ability to learn
powerful representations from multilingual datasets, have performed well in
speech tasks and are ideal to model specific tasks in low resource languages.
Here, we develop a novel multimodal approach combining two models, wav2vec2.0
for audio and MarianMT for text translation, by using multimodal attention
fusion to predict speech acts in our prepared Bengali speech corpus. We also
show that our model BeAts ($\underline{\textbf{Be}}$ngali speech acts
recognition using Multimodal $\underline{\textbf{At}}$tention
Fu$\underline{\textbf{s}}$ion) significantly outperforms both the unimodal
baseline using only speech data and a simpler bimodal fusion using both speech
and text data. Project page: https://soumitri2001.github.io/BeAts
\\ ( https://arxiv.org/abs/2306.02680 ,  1653kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02707 (*cross-listing*)
Date: Mon, 5 Jun 2023 08:58:39 GMT   (1659kb,D)

Title: Orca: Progressive Learning from Complex Explanation Traces of GPT-4
Authors: Subhabrata Mukherjee, Arindam Mitra, Ganesh Jawahar, Sahaj Agarwal,
 Hamid Palangi, Ahmed Awadallah
Categories: cs.CL cs.LG
\\
 Recent research has focused on enhancing the capability of smaller models
through imitation learning, drawing on the outputs generated by large
foundation models (LFMs). A number of issues impact the quality of these
models, ranging from limited imitation signals from shallow LFM outputs; small
scale homogeneous training data; and most notably a lack of rigorous evaluation
resulting in overestimating the small model's capability as they tend to learn
to imitate the style, but not the reasoning process of LFMs. To address these
challenges, we develop Orca (We are working with our legal team to publicly
release a diff of the model weights in accordance with LLaMA's release policy
to be published at https://aka.ms/orca-lm), a 13-billion parameter model that
learns to imitate the reasoning process of LFMs. Orca learns from rich signals
from GPT-4 including explanation traces; step-by-step thought processes; and
other complex instructions, guided by teacher assistance from ChatGPT. To
promote this progressive learning, we tap into large-scale and diverse
imitation data with judicious sampling and selection. Orca surpasses
conventional state-of-the-art instruction-tuned models such as Vicuna-13B by
more than 100% in complex zero-shot reasoning benchmarks like Big-Bench Hard
(BBH) and 42% on AGIEval. Moreover, Orca reaches parity with ChatGPT on the BBH
benchmark and shows competitive performance (4 pts gap with optimized system
message) in professional and academic examinations like the SAT, LSAT, GRE, and
GMAT, both in zero-shot settings without CoT; while trailing behind GPT-4. Our
research indicates that learning from step-by-step explanations, whether these
are generated by humans or more advanced AI models, is a promising direction to
improve model capabilities and skills.
\\ ( https://arxiv.org/abs/2306.02707 ,  1659kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02715 (*cross-listing*)
Date: Mon, 5 Jun 2023 09:08:24 GMT   (311kb,D)

Title: Federated Intrusion Detection System based on Deep Belief Networks
Authors: Othmane Belarbi, Theodoros Spyridopoulos, Eirini Anthi, Ioannis
 Mavromatis, Pietro Carnelli, Aftab Khan
Categories: cs.CR cs.LG
Comments: 14 pages, 5 figues, 3 tables
\\
 The vast increase of IoT technologies and the ever-evolving attack vectors
and threat actors have increased cyber-security risks dramatically. Novel
attacks can compromise IoT devices to gain access to sensitive data or control
them to deploy further malicious activities. The detection of novel attacks
often relies upon AI solutions. A common approach to implementing AI-based IDS
in distributed IoT systems is in a centralised manner. However, this approach
may violate data privacy and secrecy. In addition, centralised data collection
prohibits the scale-up of IDSs. Therefore, intrusion detection solutions in IoT
ecosystems need to move towards a decentralised direction. FL has attracted
significant interest in recent years due to its ability to perform
collaborative learning while preserving data confidentiality and locality.
Nevertheless, most FL-based IDS for IoT systems are designed under unrealistic
data distribution conditions. To that end, we design an experiment
representative of the real world and evaluate the performance of two FL IDS
implementations, one based on DNNs and another on our previous work on DBNs.
For our experiments, we rely on TON-IoT, a realistic IoT network traffic
dataset, associating each IP address with a single FL client. Additionally, we
explore pre-training and investigate various aggregation methods to mitigate
the impact of data heterogeneity. Lastly, we benchmark our approach against a
centralised solution. The comparison shows that the heterogeneous nature of the
data has a considerable negative impact on the model performance when trained
in a distributed manner. However, in the case of a pre-trained initial global
FL model, we demonstrate a performance improvement of over 20% (F1-score) when
compared against a randomly initiated global model.
\\ ( https://arxiv.org/abs/2306.02715 ,  311kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02719 (*cross-listing*)
Date: Mon, 5 Jun 2023 09:12:34 GMT   (66kb)

Title: Multiple output samples for each input in a single-output Gaussian
 process
Authors: Jeremy H. M. Wong, Huayun Zhang, and Nancy F. Chen
Categories: cs.CL cs.LG cs.SD eess.AS
\\
 The standard Gaussian Process (GP) only considers a single output sample per
input in the training set. Datasets for subjective tasks, such as spoken
language assessment, may be annotated with output labels from multiple human
raters per input. This paper proposes to generalise the GP to allow for these
multiple output samples in the training set, and thus make use of available
output uncertainty information. This differs from a multi-output GP, as all
output samples are from the same task here. The output density function is
formulated to be the joint likelihood of observing all output samples, and
latent variables are not repeated to reduce computation cost. The test set
predictions are inferred similarly to a standard GP, with a difference being in
the optimised hyper-parameters. This is evaluated on speechocean762, showing
that it allows the GP to compute a test set output distribution that is more
similar to the collection of reference outputs from the multiple human raters.
\\ ( https://arxiv.org/abs/2306.02719 ,  66kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02732 (*cross-listing*)
Date: Mon, 5 Jun 2023 09:28:03 GMT   (1481kb,D)

Title: Conformal Prediction with Missing Values
Authors: Margaux Zaffran, Aymeric Dieuleveut, Julie Josse, Yaniv Romano
Categories: stat.ML cs.LG
Comments: Code for our experiments can be found at
 https://github.com/mzaffran/ConformalPredictionMissingValues . To be
 published in the proceedings of the 40th International Conference on Machine
 Learning, Honolulu, Hawaii, USA
\\
 Conformal prediction is a theoretically grounded framework for constructing
predictive intervals. We study conformal prediction with missing values in the
covariates -- a setting that brings new challenges to uncertainty
quantification. We first show that the marginal coverage guarantee of conformal
prediction holds on imputed data for any missingness distribution and almost
all imputation functions. However, we emphasize that the average coverage
varies depending on the pattern of missing values: conformal methods tend to
construct prediction intervals that under-cover the response conditionally to
some missing patterns. This motivates our novel generalized conformalized
quantile regression framework, missing data augmentation, which yields
prediction intervals that are valid conditionally to the patterns of missing
values, despite their exponential number. We then show that a universally
consistent quantile regression algorithm trained on the imputed data is Bayes
optimal for the pinball risk, thus achieving valid coverage conditionally to
any given data point. Moreover, we examine the case of a linear model, which
demonstrates the importance of our proposal in overcoming the
heteroskedasticity induced by missing values. Using synthetic and data from
critical care, we corroborate our theory and report improved performance of our
methods.
\\ ( https://arxiv.org/abs/2306.02732 ,  1481kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02733 (*cross-listing*)
Date: Mon, 5 Jun 2023 09:29:46 GMT   (1001kb,D)

Title: Realising Synthetic Active Inference Agents, Part II: Variational
 Message Updates
Authors: Thijs van de Laar, Magnus Koudahl and Bert de Vries
Categories: stat.ML cs.LG
\\
 The Free Energy Principle (FEP) describes (biological) agents as minimising a
variational Free Energy (FE) with respect to a generative model of their
environment. Active Inference (AIF) is a corollary of the FEP that describes
how agents explore and exploit their environment by minimising an expected FE
objective. In two related papers, we describe a scalable, epistemic approach to
synthetic AIF agents, by message passing on free-form Forney-style Factor
Graphs (FFGs). A companion paper (part I) introduces a Constrained FFG (CFFG)
notation that visually represents (generalised) FE objectives for AIF. The
current paper (part II) derives message passing algorithms that minimise
(generalised) FE objectives on a CFFG by variational calculus. A comparison
between simulated Bethe and generalised FE agents illustrates how synthetic AIF
induces epistemic behaviour on a T-maze navigation task. With a full message
passing account of synthetic AIF agents, it becomes possible to derive and
reuse message updates across models and move closer to industrial applications
of synthetic AIF.
\\ ( https://arxiv.org/abs/2306.02733 ,  1001kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02775 (*cross-listing*)
Date: Mon, 5 Jun 2023 11:00:11 GMT   (122kb,D)

Title: Input gradient diversity for neural network ensembles
Authors: Trung Trinh, Markus Heinonen, Luigi Acerbi, Samuel Kaski
Categories: stat.ML cs.LG
Comments: Under review
\\
 Deep Ensembles (DEs) demonstrate improved accuracy, calibration and
robustness to perturbations over single neural networks partly due to their
functional diversity. Particle-based variational inference (ParVI) methods
enhance diversity by formalizing a repulsion term based on a network similarity
kernel. However, weight-space repulsion is inefficient due to
over-parameterization, while direct function-space repulsion has been found to
produce little improvement over DEs. To sidestep these difficulties, we propose
First-order Repulsive Deep Ensemble (FoRDE), an ensemble learning method based
on ParVI, which performs repulsion in the space of first-order input gradients.
As input gradients uniquely characterize a function up to translation and are
much smaller in dimension than the weights, this method guarantees that
ensemble members are functionally different. Intuitively, diversifying the
input gradients encourages each network to learn different features, which is
expected to improve the robustness of an ensemble. Experiments on image
classification datasets show that FoRDE significantly outperforms the
gold-standard DEs and other ensemble methods in accuracy and calibration under
covariate shift due to input perturbations.
\\ ( https://arxiv.org/abs/2306.02775 ,  122kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02798 (*cross-listing*)
Date: Mon, 5 Jun 2023 11:51:04 GMT   (1841kb,D)

Title: Enhancing naive classifier for positive unlabeled data based on logistic
 regression approach
Authors: Mateusz P{\l}atek and Jan Mielniczuk
Categories: stat.ML cs.LG
\\
 We argue that for analysis of Positive Unlabeled (PU) data under Selected
Completely At Random (SCAR) assumption it is fruitful to view the problem as
fitting of misspecified model to the data. Namely, we show that the results on
misspecified fit imply that in the case when posterior probability of the
response is modelled by logistic regression, fitting the logistic regression to
the observable PU data which {\it does not} follow this model, still yields the
vector of estimated parameters approximately colinear with the true vector of
parameters. This observation together with choosing the intercept of the
classifier based on optimisation of analogue of F1 measure yields a classifier
which performs on par or better than its competitors on several real data sets
considered.
\\ ( https://arxiv.org/abs/2306.02798 ,  1841kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02831 (*cross-listing*)
Date: Mon, 5 Jun 2023 12:27:22 GMT   (1051kb,D)

Title: MM-DAG: Multi-task DAG Learning for Multi-modal Data -- with Application
 for Traffic Congestion Analysis
Authors: Tian Lan, Ziyue Li, Zhishuai Li, Lei Bai, Man Li, Fugee Tsung,
 Wolfgang Ketter, Rui Zhao, Chen Zhang
Categories: stat.ML cs.LG
Comments: Accepted in SIGKDD 2023
\\
 This paper proposes to learn Multi-task, Multi-modal Direct Acyclic Graphs
(MM-DAGs), which are commonly observed in complex systems, e.g., traffic,
manufacturing, and weather systems, whose variables are multi-modal with
scalars, vectors, and functions. This paper takes the traffic congestion
analysis as a concrete case, where a traffic intersection is usually regarded
as a DAG. In a road network of multiple intersections, different intersections
can only have some overlapping and distinct variables observed. For example, a
signalized intersection has traffic light-related variables, whereas
unsignalized ones do not. This encourages the multi-task design: with each DAG
as a task, the MM-DAG tries to learn the multiple DAGs jointly so that their
consensus and consistency are maximized. To this end, we innovatively propose a
multi-modal regression for linear causal relationship description of different
variables. Then we develop a novel Causality Difference (CD) measure and its
differentiable approximator. Compared with existing SOTA measures, CD can
penalize the causal structural difference among DAGs with distinct nodes and
can better consider the uncertainty of causal orders. We rigidly prove our
design's topological interpretation and consistency properties. We conduct
thorough simulations and one case study to show the effectiveness of our
MM-DAG. The code is available under https://github.com/Lantian72/MM-DAG
\\ ( https://arxiv.org/abs/2306.02831 ,  1051kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02833 (*cross-listing*)
Date: Mon, 5 Jun 2023 12:29:13 GMT   (544kb)

Title: The $L^\infty$ Learnability of Reproducing Kernel Hilbert Spaces
Authors: Hongrui Chen, Jihao Long, Lei Wu
Categories: stat.ML cs.LG math.ST stat.TH
Comments: 20 pages
\\
 In this work, we analyze the learnability of reproducing kernel Hilbert
spaces (RKHS) under the $L^\infty$ norm, which is critical for understanding
the performance of kernel methods and random feature models in safety- and
security-critical applications. Specifically, we relate the $L^\infty$
learnability of a RKHS to the spectrum decay of the associate kernel and both
lower bounds and upper bounds of the sample complexity are established. In
particular, for dot-product kernels on the sphere, we identify conditions when
the $L^\infty$ learning can be achieved with polynomial samples. Let $d$ denote
the input dimension and assume the kernel spectrum roughly decays as
$\lambda_k\sim k^{-1-\beta}$ with $\beta>0$. We prove that if $\beta$ is
independent of the input dimension $d$, then functions in the RKHS can be
learned efficiently under the $L^\infty$ norm, i.e., the sample complexity
depends polynomially on $d$. In contrast, if $\beta=1/\mathrm{poly}(d)$, then
the $L^\infty$ learning requires exponentially many samples.
\\ ( https://arxiv.org/abs/2306.02833 ,  544kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02840 (*cross-listing*)
Date: Mon, 5 Jun 2023 12:44:18 GMT   (9103kb,D)

Title: Learning to Substitute Spans towards Improving Compositional
 Generalization
Authors: Zhaoyi Li, Ying Wei and Defu Lian
Categories: cs.CL cs.LG
Comments: accepted by ACL 2023
\\
 Despite the rising prevalence of neural sequence models, recent empirical
evidences suggest their deficiency in compositional generalization. One of the
current de-facto solutions to this problem is compositional data augmentation,
aiming to incur additional compositional inductive bias. Nonetheless, the
improvement offered by existing handcrafted augmentation strategies is limited
when successful systematic generalization of neural sequence models requires
multi-grained compositional bias (i.e., not limited to either lexical or
structural biases only) or differentiation of training sequences in an
imbalanced difficulty distribution. To address the two challenges, we first
propose a novel compositional augmentation strategy dubbed \textbf{Span}
\textbf{Sub}stitution (SpanSub) that enables multi-grained composition of
substantial substructures in the whole training set. Over and above that, we
introduce the \textbf{L}earning \textbf{to} \textbf{S}ubstitute \textbf{S}pan
(L2S2) framework which empowers the learning of span substitution probabilities
in SpanSub in an end-to-end manner by maximizing the loss of neural sequence
models, so as to outweigh those challenging compositions with elusive concepts
and novel surroundings. Our empirical results on three standard compositional
generalization benchmarks, including SCAN, COGS and GeoQuery (with an
improvement of at most 66.5\%, 10.3\%, 1.2\%, respectively), demonstrate the
superiority of SpanSub, %the learning framework L2S2 and their combination.
\\ ( https://arxiv.org/abs/2306.02840 ,  9103kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02895 (*cross-listing*)
Date: Mon, 5 Jun 2023 14:04:53 GMT   (926kb,D)

Title: Evading Black-box Classifiers Without Breaking Eggs
Authors: Edoardo Debenedetti, Nicholas Carlini and Florian Tram\`er
Categories: cs.CR cs.LG stat.ML
Comments: Code at https://github.com/ethz-privsec/realistic-adv-examples
\\
 Decision-based evasion attacks repeatedly query a black-box classifier to
generate adversarial examples. Prior work measures the cost of such attacks by
the total number of queries made to the classifier. We argue this metric is
flawed. Most security-critical machine learning systems aim to weed out "bad"
data (e.g., malware, harmful content, etc). Queries to such systems carry a
fundamentally asymmetric cost: queries detected as "bad" come at a higher cost
because they trigger additional security filters, e.g., usage throttling or
account suspension. Yet, we find that existing decision-based attacks issue a
large number of "bad" queries, which likely renders them ineffective against
security-critical systems. We then design new attacks that reduce the number of
bad queries by $1.5$-$7.3\times$, but often at a significant increase in total
(non-bad) queries. We thus pose it as an open problem to build black-box
attacks that are more effective under realistic cost metrics.
\\ ( https://arxiv.org/abs/2306.02895 ,  926kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02899 (*cross-listing*)
Date: Mon, 5 Jun 2023 14:06:35 GMT   (73kb)

Title: Learning nonparametric latent causal graphs with unknown interventions
Authors: Yibo Jiang, Bryon Aragam
Categories: stat.ML cs.LG
\\
 We establish conditions under which latent causal graphs are
nonparametrically identifiable and can be reconstructed from unknown
interventions in the latent space. Our primary focus is the identification of
the latent structure in a measurement model, i.e. causal graphical models where
dependence between observed variables is insignificant compared to dependence
between latent representations, without making parametric assumptions such as
linearity or Gaussianity. Moreover, we do not assume the number of hidden
variables is known, and we show that at most one unknown intervention per
hidden variable is needed. This extends a recent line of work on learning
causal representations from observations and interventions. The proofs are
constructive and introduce two new graphical concepts -- imaginary subsets and
isolated edges -- that may be useful in their own right. As a matter of
independent interest, the proofs also involve a novel characterization of the
limits of edge orientations within the equivalence class of DAGs induced by
unknown interventions. Experiments confirm that the latent graph can be
recovered from data using our theoretical results. These are the first results
to characterize the conditions under which causal representations are
identifiable without making any parametric assumptions in a general setting
with unknown interventions and without faithfulness.
\\ ( https://arxiv.org/abs/2306.02899 ,  73kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02931 (*cross-listing*)
Date: Mon, 5 Jun 2023 14:51:05 GMT   (228kb,D)

Title: Causal Discovery using Bayesian Model Selection
Authors: Anish Dhir and Mark van der Wilk
Categories: stat.ML cs.LG
\\
 With only observational data on two variables, and without other assumptions,
it is not possible to infer which one causes the other. Much of the causal
literature has focused on guaranteeing identifiability of causal direction in
statistical models for datasets where strong assumptions hold, such as additive
noise or restrictions on parameter count. These methods are then subsequently
tested on realistic datasets, most of which violate their assumptions. Building
on previous attempts, we show how to use causal assumptions within the Bayesian
framework. This allows us to specify models with realistic assumptions, while
also encoding independent causal mechanisms, leading to an asymmetry between
the causal directions. Identifying causal direction then becomes a Bayesian
model selection problem. We analyse why Bayesian model selection works for
known identifiable cases and flexible model classes, while also providing
correctness guarantees about its behaviour. To demonstrate our approach, we
construct a Bayesian non-parametric model that can flexibly model the joint. We
then outperform previous methods on a wide range of benchmark datasets with
varying data generating assumptions showing the usefulness of our method.
\\ ( https://arxiv.org/abs/2306.02931 ,  228kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02948 (*cross-listing*)
Date: Mon, 5 Jun 2023 15:14:34 GMT   (49kb,D)

Title: Random Distribution Shift in Refugee Placement: Strategies for Building
 Robust Models
Authors: Kirk Bansak, Elisabeth Paulson, Dominik Rothenh\"ausler
Categories: stat.ML cs.LG stat.AP stat.ME
\\
 Algorithmic assignment of refugees and asylum seekers to locations within
host countries has gained attention in recent years, with implementations in
the US and Switzerland. These approaches use data on past arrivals to generate
machine learning models that can be used (along with assignment algorithms) to
match families to locations, with the goal of maximizing a policy-relevant
integration outcome such as employment status after a certain duration.
Existing implementations and research train models to predict the policy
outcome directly, and use these predictions in the assignment procedure.
However, the merits of this approach, particularly in non-stationary settings,
has not been previously explored. This study proposes and compares three
different modeling strategies: the standard approach described above, an
approach that uses newer data and proxy outcomes, and a hybrid approach. We
show that the hybrid approach is robust to both distribution shift and weak
proxy relationships -- the failure points of the other two methods,
respectively. We compare these approaches empirically using data on asylum
seekers in the Netherlands. Surprisingly, we find that both the proxy and
hybrid approaches out-perform the standard approach in practice. These insights
support the development of a real-world recommendation tool currently used by
NGOs and government agencies.
\\ ( https://arxiv.org/abs/2306.02948 ,  49kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02955 (*cross-listing*)
Date: Mon, 5 Jun 2023 15:23:55 GMT   (1092kb,D)

Title: A Simple and Flexible Modeling for Mental Disorder Detection by Learning
 from Clinical Questionnaires
Authors: Hoyun Song, Jisu Shin, Huije Lee, Jong C. Park
Categories: cs.CL cs.LG
Comments: ACL 2023, 15 pages, 11 tables, 4 figures
\\
 Social media is one of the most highly sought resources for analyzing
characteristics of the language by its users. In particular, many researchers
utilized various linguistic features of mental health problems from social
media. However, existing approaches to detecting mental disorders face critical
challenges, such as the scarcity of high-quality data or the trade-off between
addressing the complexity of models and presenting interpretable results
grounded in expert domain knowledge. To address these challenges, we design a
simple but flexible model that preserves domain-based interpretability. We
propose a novel approach that captures the semantic meanings directly from the
text and compares them to symptom-related descriptions. Experimental results
demonstrate that our model outperforms relevant baselines on various mental
disorder detection tasks. Our detailed analysis shows that the proposed model
is effective at leveraging domain knowledge, transferable to other mental
disorders, and providing interpretable detection results.
\\ ( https://arxiv.org/abs/2306.02955 ,  1092kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02972 (*cross-listing*)
Date: Mon, 5 Jun 2023 15:35:19 GMT   (225kb,D)

Title: Simultaneous or Sequential Training? How Speech Representations
 Cooperate in a Multi-Task Self-Supervised Learning System
Authors: Khazar Khorrami, Mar\'ia Andrea Cruz Bland\'on, Tuomas Virtanen, Okko
 R\"as\"anen
Categories: eess.AS cs.LG
Comments: 5 pages, accepted by EUSIPCO 2023
\\
 Speech representation learning with self-supervised algorithms has resulted
in notable performance boosts in many downstream tasks. Recent work combined
self-supervised learning (SSL) and visually grounded speech (VGS) processing
mechanisms for representation learning. The joint training with SSL and VGS
mechanisms provides the opportunity to utilize both unlabeled speech and
speech-related visual information based on data availability. This has shown to
enhance the quality of learned representations, especially at encoding
semantic- and lexical-level knowledge. In this work, we further study the joint
optimization of wav2vec 2.0-based SSL and transformer-based VGS as a multi-task
learning system. We explore a set of training scenarios to understand how
speech representations are shared or transferred between the two tasks, and
what is the optimal training strategy for cross-modal semantic retrieval and
phoneme discrimination performance. As a result, we find that sequential
training with wav2vec 2.0 first and VGS next provides higher performance on
audio-visual retrieval compared to simultaneous optimization of both learning
mechanisms. However, the parallel SSL-VGS training reduces the effects of
catastrophic forgetting when switching between optimization criteria. Moreover,
the results suggest that phonemic representations learned through the VGS
mechanism may generalize better across datasets compared to those learned with
SSL.
\\ ( https://arxiv.org/abs/2306.02972 ,  225kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02984 (*cross-listing*)
Date: Mon, 5 Jun 2023 15:53:56 GMT   (1939kb,D)

Title: A Deep Learning Approach Utilizing Covariance Matrix Analysis for the
 ISBI Edited MRS Reconstruction Challenge
Authors: Julian P. Merkofer, Dennis M. J. van de Sande, Sina Amirrajab, Gerhard
 S. Drenthen, Mitko Veta, Jacobus F. A. Jansen, Marcel Breeuwer, and Ruud J.
 G. van Sloun
Categories: physics.med-ph cs.LG eess.IV
\\
 This work proposes a method to accelerate the acquisition of high-quality
edited magnetic resonance spectroscopy (MRS) scans using machine learning
models taking the sample covariance matrix as input. The method is invariant to
the number of transients and robust to noisy input data for both synthetic as
well as in-vivo scenarios.
\\ ( https://arxiv.org/abs/2306.02984 ,  1939kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02990 (*cross-listing*)
Date: Mon, 5 Jun 2023 16:01:33 GMT   (1148kb,D)

Title: Integrated Sensing, Computation, and Communication for UAV-assisted
 Federated Edge Learning
Authors: Yao Tang, Guangxu Zhu, Wei Xu, Man Hon Cheung, Tat-Ming Lok, Shuguang
 Cui
Categories: cs.IT cs.LG eess.SP math.IT
\\
 Federated edge learning (FEEL) enables privacy-preserving model training
through periodic communication between edge devices and the server. Unmanned
Aerial Vehicle (UAV)-mounted edge devices are particularly advantageous for
FEEL due to their flexibility and mobility in efficient data collection. In
UAV-assisted FEEL, sensing, computation, and communication are coupled and
compete for limited onboard resources, and UAV deployment also affects sensing
and communication performance. Therefore, the joint design of UAV deployment
and resource allocation is crucial to achieving the optimal training
performance. In this paper, we address the problem of joint UAV deployment
design and resource allocation for FEEL via a concrete case study of human
motion recognition based on wireless sensing. We first analyze the impact of
UAV deployment on the sensing quality and identify a threshold value for the
sensing elevation angle that guarantees a satisfactory quality of data samples.
Due to the non-ideal sensing channels, we consider the probabilistic sensing
model, where the successful sensing probability of each UAV is determined by
its position. Then, we derive the upper bound of the FEEL training loss as a
function of the sensing probability. Theoretical results suggest that the
convergence rate can be improved if UAVs have a uniform successful sensing
probability. Based on this analysis, we formulate a training time minimization
problem by jointly optimizing UAV deployment, integrated sensing, computation,
and communication (ISCC) resources under a desirable optimality gap constraint.
To solve this challenging mixed-integer non-convex problem, we apply the
alternating optimization technique, and propose the bandwidth, batch size, and
position optimization (BBPO) scheme to optimize these three decision variables
alternately.
\\ ( https://arxiv.org/abs/2306.02990 ,  1148kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03009 (*cross-listing*)
Date: Mon, 5 Jun 2023 16:19:48 GMT   (3846kb,D)

Title: Using Sequences of Life-events to Predict Human Lives
Authors: Germans Savcisens, Tina Eliassi-Rad, Lars Kai Hansen, Laust Mortensen,
 Lau Lilleholt, Anna Rogers, Ingo Zettler, Sune Lehmann
Categories: stat.ML cs.LG stat.AP
DOI: 10.21203/rs.3.rs-2975478/v1
\\
 Over the past decade, machine learning has revolutionized computers' ability
to analyze text through flexible computational models. Due to their structural
similarity to written language, transformer-based architectures have also shown
promise as tools to make sense of a range of multi-variate sequences from
protein-structures, music, electronic health records to weather-forecasts. We
can also represent human lives in a way that shares this structural similarity
to language. From one perspective, lives are simply sequences of events: People
are born, visit the pediatrician, start school, move to a new location, get
married, and so on. Here, we exploit this similarity to adapt innovations from
natural language processing to examine the evolution and predictability of
human lives based on detailed event sequences. We do this by drawing on
arguably the most comprehensive registry data in existence, available for an
entire nation of more than six million individuals across decades. Our data
include information about life-events related to health, education, occupation,
income, address, and working hours, recorded with day-to-day resolution. We
create embeddings of life-events in a single vector space showing that this
embedding space is robust and highly structured. Our models allow us to predict
diverse outcomes ranging from early mortality to personality nuances,
outperforming state-of-the-art models by a wide margin. Using methods for
interpreting deep learning models, we probe the algorithm to understand the
factors that enable our predictions. Our framework allows researchers to
identify new potential mechanisms that impact life outcomes and associated
possibilities for personalized interventions.
\\ ( https://arxiv.org/abs/2306.03009 ,  3846kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03013 (*cross-listing*)
Date: Mon, 5 Jun 2023 16:29:54 GMT   (693kb,D)

Title: Hiding in Plain Sight: Disguising Data Stealing Attacks in Federated
 Learning
Authors: Kostadin Garov, Dimitar I. Dimitrov, Nikola Jovanovi\'c, Martin Vechev
Categories: cs.CR cs.LG
ACM-class: I.2.11
\\
 Malicious server (MS) attacks have enabled the scaling of data stealing in
federated learning to large batch sizes and secure aggregation, settings
previously considered private. However, many concerns regarding client-side
detectability of MS attacks were raised, questioning their practicality once
they are publicly known. In this work, for the first time, we thoroughly study
the problem of client-side detectability.We demonstrate that most prior MS
attacks, which fundamentally rely on one of two key principles, are detectable
by principled client-side checks. Further, we formulate desiderata for
practical MS attacks and propose SEER, a novel attack framework that satisfies
all desiderata, while stealing user data from gradients of realistic networks,
even for large batch sizes (up to 512 in our experiments) and under secure
aggregation. The key insight of SEER is the use of a secret decoder, which is
jointly trained with the shared model. Our work represents a promising first
step towards more principled treatment of MS attacks, paving the way for
realistic data stealing that can compromise user privacy in real-world
deployments.
\\ ( https://arxiv.org/abs/2306.03013 ,  693kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03014 (*cross-listing*)
Date: Mon, 5 Jun 2023 16:30:17 GMT   (113kb,D)

Title: On the Behavior of Intrusive and Non-intrusive Speech Enhancement
 Metrics in Predictive and Generative Settings
Authors: Danilo de Oliveira, Julius Richter, Jean-Marie Lemercier, Tal Peer,
 Timo Gerkmann
Categories: eess.AS cs.LG cs.SD
Comments: Submitted to ITG Conference on Speech Communication
\\
 Since its inception, the field of deep speech enhancement has been dominated
by predictive (discriminative) approaches, such as spectral mapping or masking.
Recently, however, novel generative approaches have been applied to speech
enhancement, attaining good denoising performance with high subjective quality
scores. At the same time, advances in deep learning also allowed for the
creation of neural network-based metrics, which have desirable traits such as
being able to work without a reference (non-intrusively). Since generatively
enhanced speech tends to exhibit radically different residual distortions, its
evaluation using instrumental speech metrics may behave differently compared to
predictively enhanced speech. In this paper, we evaluate the performance of the
same speech enhancement backbone trained under predictive and generative
paradigms on a variety of metrics and show that intrusive and non-intrusive
measures correlate differently for each paradigm. This analysis motivates the
search for metrics that can together paint a complete and unbiased picture of
speech enhancement performance, irrespective of the model's training process.
\\ ( https://arxiv.org/abs/2306.03014 ,  113kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03025 (*cross-listing*)
Date: Mon, 5 Jun 2023 16:45:39 GMT   (1747kb)

Title: AI Techniques for Cone Beam Computed Tomography in Dentistry: Trends and
 Practices
Authors: Saba Sarwar, Suraiya Jabin
Categories: eess.IV cs.LG
Comments: Recent Advances in Electrical, Electronics & Digital Healthcare
 Technologies REEDCON 2023
ACM-class: I.5.1; I.4.6; I.4.7; I.4.8
\\
 Cone-beam computed tomography (CBCT) is a popular imaging modality in
dentistry for diagnosing and planning treatment for a variety of oral diseases
with the ability to produce detailed, three-dimensional images of the teeth,
jawbones, and surrounding structures. CBCT imaging has emerged as an essential
diagnostic tool in dentistry. CBCT imaging has seen significant improvements in
terms of its diagnostic value, as well as its accuracy and efficiency, with the
most recent development of artificial intelligence (AI) techniques. This paper
reviews recent AI trends and practices in dental CBCT imaging. AI has been used
for lesion detection, malocclusion classification, measurement of buccal bone
thickness, and classification and segmentation of teeth, alveolar bones,
mandibles, landmarks, contours, and pharyngeal airways using CBCT images.
Mainly machine learning algorithms, deep learning algorithms, and
super-resolution techniques are used for these tasks. This review focuses on
the potential of AI techniques to transform CBCT imaging in dentistry, which
would improve both diagnosis and treatment planning. Finally, we discuss the
challenges and limitations of artificial intelligence in dentistry and CBCT
imaging.
\\ ( https://arxiv.org/abs/2306.03025 ,  1747kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03054 (*cross-listing*)
Date: Mon, 5 Jun 2023 17:25:45 GMT   (687kb,D)

Title: Discriminative Adversarial Privacy: Balancing Accuracy and Membership
 Privacy in Neural Networks
Authors: Eugenio Lomurno, Alberto Archetti, Francesca Ausonio, Matteo Matteucci
Categories: cs.CR cs.LG
\\
 The remarkable proliferation of deep learning across various industries has
underscored the importance of data privacy and security in AI pipelines. As the
evolution of sophisticated Membership Inference Attacks (MIAs) threatens the
secrecy of individual-specific information used for training deep learning
models, Differential Privacy (DP) raises as one of the most utilized techniques
to protect models against malicious attacks. However, despite its proven
theoretical properties, DP can significantly hamper model performance and
increase training time, turning its use impractical in real-world scenarios.
Tackling this issue, we present Discriminative Adversarial Privacy (DAP), a
novel learning technique designed to address the limitations of DP by achieving
a balance between model performance, speed, and privacy. DAP relies on
adversarial training based on a novel loss function able to minimise the
prediction error while maximising the MIA's error. In addition, we introduce a
novel metric named Accuracy Over Privacy (AOP) to capture the
performance-privacy trade-off. Finally, to validate our claims, we compare DAP
with diverse DP scenarios, providing an analysis of the results from
performance, time, and privacy preservation perspectives.
\\ ( https://arxiv.org/abs/2306.03054 ,  687kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03078 (*cross-listing*)
Date: Mon, 5 Jun 2023 17:53:28 GMT   (3986kb,D)

Title: SpQR: A Sparse-Quantized Representation for Near-Lossless LLM Weight
 Compression
Authors: Tim Dettmers, Ruslan Svirschevski, Vage Egiazarian, Denis Kuznedelev,
 Elias Frantar, Saleh Ashkboos, Alexander Borzunov, Torsten Hoefler, Dan
 Alistarh
Categories: cs.CL cs.LG
Comments: Extended preprint
\\
 Recent advances in large language model (LLM) pretraining have led to
high-quality LLMs with impressive abilities. By compressing such LLMs via
quantization to 3-4 bits per parameter, they can fit into memory-limited
devices such as laptops and mobile phones, enabling personalized use. However,
quantization down to 3-4 bits per parameter usually leads to moderate-to-high
accuracy losses, especially for smaller models in the 1-10B parameter range,
which are well-suited for edge deployments. To address this accuracy issue, we
introduce the Sparse-Quantized Representation (SpQR), a new compressed format
and quantization technique which enables for the first time near-lossless
compression of LLMs across model scales, while reaching similar compression
levels to previous methods. SpQR works by identifying and isolating outlier
weights, which cause particularly-large quantization errors, and storing them
in higher precision, while compressing all other weights to 3-4 bits, and
achieves relative accuracy losses of less than 1% in perplexity for
highly-accurate LLaMA and Falcon LLMs. This makes it possible to run 33B
parameter LLM on a single 24 GB consumer GPU without any performance
degradation at 15% speedup thus making powerful LLMs available to consumer
without any downsides. SpQR comes with efficient algorithms for both encoding
weights into its format, as well as decoding them efficiently at runtime.
Specifically, we provide an efficient GPU inference algorithm for SpQR which
yields faster inference than 16-bit baselines at similar accuracy, while
enabling memory compression gains of more than 4x.
\\ ( https://arxiv.org/abs/2306.03078 ,  3986kb)
------------------------------------------------------------------------------
\\
arXiv:2306.01757 (*cross-listing*)
Date: Wed, 24 May 2023 20:13:38 GMT   (7892kb)

Title: State estimation for one-dimensional agro-hydrological processes with
 model mismatch
Authors: Zhuangyu Liu, Jinfeng Liu (University of Alberta), Shunyi Zhao, Xiaoli
 Luan, Fei Liu
Categories: stat.AP cs.SY eess.SY math.DS
\\
 The importance of accurate soil moisture data for the development of modern
closed-loop irrigation systems cannot be overstated. Due to the diversity of
soil, it is difficult to obtain an accurate model for agro-hydrological system.
In this study, soil moisture estimation in 1D agro-hydrological systems with
model mismatch is the focus. To address the problem of model mismatch, a
nonlinear state-space model derived from the Richards equation is utilized,
along with additive unknown inputs. The determination of the number of sensors
required is achieved through sensitivity analysis and the orthogonalization
projection method. To estimate states and unknown inputs in real-time, a
recursive expectation maximization (EM) algorithm derived from the conventional
EM algorithm is employed. During the E-step, the extended Kalman filter (EKF)
is used to compute states and covariance in the recursive Q-function, while in
the M-step, unknown inputs are updated by locally maximizing the recursive
Q-function. The estimation performance is evaluated using comprehensive
simulations. Through this method, accurate soil moisture estimation can be
obtained, even in the presence of model mismatch.
\\ ( https://arxiv.org/abs/2306.01757 ,  7892kb)
------------------------------------------------------------------------------
\\
arXiv:2306.01952 (*cross-listing*)
Date: Fri, 2 Jun 2023 23:26:41 GMT   (141kb,D)

Title: Online Control with Adversarial Disturbance for Continuous-time Linear
 Systems
Authors: Jingwei Li, Jing Dong, Baoxiang Wang, Jingzhao Zhang
Categories: math.OC cs.SY eess.SY
\\
 We study online control for continuous-time linear systems with finite
sampling rates, where the objective is to design an online procedure that
learns under non-stochastic noise and performs comparably to a fixed optimal
linear controller. We present a novel two-level online algorithm, by
integrating a higher-level learning strategy and a lower-level feedback control
strategy. This method offers a practical and robust solution for online
control, which achieves sublinear regret. Our work provides one of the first
nonasymptotic results for controlling continuous-time linear systems a with
finite number of interactions with the system.
\\ ( https://arxiv.org/abs/2306.01952 ,  141kb)
------------------------------------------------------------------------------
\\
arXiv:2306.01998 (*cross-listing*)
Date: Sat, 3 Jun 2023 04:17:47 GMT   (2019kb)

Title: Environmental management and restoration under unified risk and
 uncertainty using robustified dynamic Orlicz risk
Authors: Hidekazu Yoshioka, Motoh Tsujimura, Futoshi Aranishi, and Tomomi
 Tanaka
Categories: math.OC cs.SY eess.SY math.PR
\\
 Environmental management and restoration should be designed such that the
risk and uncertainty owing to nonlinear stochastic systems can be successfully
addressed. We apply the robustified dynamic Orlicz risk to the modeling and
analysis of environmental management and restoration to consider both the risk
and uncertainty within a unified theory. We focus on the control of a
jump-driven hybrid stochastic system that represents macrophyte dynamics. The
dynamic programming equation based on the Orlicz risk is first obtained
heuristically, from which the associated Hamilton-Jacobi-Bellman (HJB) equation
is derived. In the proposed Orlicz risk, the risk aversion of the
decision-maker is represented by a power coefficient that resembles a certainty
equivalence, whereas the uncertainty aversion is represented by the
Kullback-Leibler divergence, in which the risk and uncertainty are handled
consistently and separately. The HJB equation includes a new state-dependent
discount factor that arises from the uncertainty aversion, which leads to a
unique, nonlinear, and nonlocal term. The link between the proposed and
classical stochastic control problems is discussed with a focus on
control-dependent discount rates. We propose a finite difference method for
computing the HJB equation. Finally, the proposed model is applied to an
optimal harvesting problem for macrophytes in a brackish lake that contains
both growing and drifting populations.
\\ ( https://arxiv.org/abs/2306.01998 ,  2019kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02072 (*cross-listing*)
Date: Sat, 3 Jun 2023 10:23:02 GMT   (236kb,D)

Title: Dynamic Programming for Positive Linear Systems with Linear Costs
Authors: Yuchao Li
Categories: math.OC cs.SY eess.SY
\\
 Recent work by Rantzer [Ran22] formulated a class of optimal control problems
involving positive linear systems, linear stage costs, and linear constraints.
It was shown that the associated Bellman's equation can be characterized by a
finite-dimensional nonlinear equation, which is solved by linear programming.
In this work, we report complementary theories for the same class of problems.
In particular, we provide conditions under which the solution is unique,
investigate properties of the optimal policy, study the convergence of value
iteration, policy iteration, and optimistic policy iteration applied to such
problems, and analyze the boundedness of the solution to the associated linear
program. Apart from a form of the Frobenius-Perron theorem, the majority of our
results are built upon generic dynamic programming theory applicable to
problems involving nonnegative stage costs.
\\ ( https://arxiv.org/abs/2306.02072 ,  236kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02107 (*cross-listing*)
Date: Sat, 3 Jun 2023 13:14:36 GMT   (811kb,D)

Title: Achievable Sum Rate Optimization on NOMA-aided Cell-Free Massive MIMO
 with Finite Blocklength Coding
Authors: Baolin Chong, Hancheng Lu, Yuang Chen, Langtian Qin and Fengqian Guo
Categories: cs.IT cs.SY eess.SY math.IT
\\
 Non-orthogonal multiple access (NOMA)-aided cell-free massive multiple-input
multiple-output (CFmMIMO) has been considered as a promising technology to
fulfill strict quality of service requirements for ultra-reliable low-latency
communications (URLLC). However, finite blocklength coding (FBC) in URLLC makes
it challenging to achieve the optimal performance in the NOMA-aided CFmMIMO
system. In this paper, we investigate the performance of the NOMA-aided CFmMIMO
system with FBC in terms of achievable sum rate (ASR). Firstly, we derive a
lower bound (LB) on the ergodic data rate. Then, we formulate an ASR
maximization problem by jointly considering power allocation and user equipment
(UE) clustering. To tackle such an intractable problem, we decompose it into
two sub-problems, i.e., the power allocation problem and the UE clustering
problem. A successive convex approximation (SCA) algorithm is proposed to solve
the power allocation problem by transforming it into a series of geometric
programming problems. Meanwhile, two algorithms based on graph theory are
proposed to solve the UE clustering problem by identifying negative loops.
Finally, alternative optimization is performed to find the maximum ASR of the
NOMA-aided CFmMIMO system with FBC. The simulation results demonstrate that the
proposed algorithms significantly outperform the benchmark algorithms in terms
of ASR under various scenarios.
\\ ( https://arxiv.org/abs/2306.02107 ,  811kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02132 (*cross-listing*)
Date: Sat, 3 Jun 2023 15:06:01 GMT   (230kb)

Title: Formation Control with Unknown Directions and General Coupling
 Coefficients
Authors: Zhen Li and Yang Tang and Yongqing Fan and Tingwen Huang
Categories: math.OC cs.SY eess.SY
\\
 Generally, the normal displacement-based formation control has a sensing mode
that requires the agent not only to have certain knowledge of its direction,
but also to gather its local information characterized by nonnegative coupling
coefficients. However, the direction may be unknown in the sensing processes,
and the coupling coefficients may also involve negative ones due to some
circumstances. This paper introduces these phenomena into a class of
displacement-based formation control problem. Then, a geometric approach have
been employed to overcome the difficulty of analysis on the introduced
phenomena. The purpose of this approach is to construct some convex polytopes
for containing the effects caused by the unknown direction, and to analyze the
non-convexity by admitting the negative coupling coefficients in a certain
range. Under the actions of these phenomena, the constructed polytopes are
shown to be invariant in view of the contractive set method. It means that the
convergence of formation shape can be guaranteed. Subsequently, an example is
given to examine the applicability of derived result.
\\ ( https://arxiv.org/abs/2306.02132 ,  230kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02427 (*cross-listing*)
Date: Sun, 4 Jun 2023 18:19:04 GMT   (4958kb,D)

Title: Towards Efficient Controller Synthesis Techniques for Logical LTL Games
Authors: Stanly Samuel and Deepak D'Souza and Raghavan Komondoor
Categories: cs.LO cs.FL cs.SC cs.SY eess.SY
\\
 Two-player games are a fruitful way to represent and reason about several
important synthesis tasks. These tasks include controller synthesis (where one
asks for a controller for a given plant such that the controlled plant
satisfies a given temporal specification), program repair (setting values of
variables to avoid exceptions), and synchronization synthesis (adding
lock/unlock statements in multi-threaded programs to satisfy safety
assertions). In all these applications, a solution directly corresponds to a
winning strategy for one of the players in the induced game. In turn,
\emph{logically-specified} games offer a powerful way to model these tasks for
large or infinite-state systems. Much of the techniques proposed for solving
such games typically rely on abstraction-refinement or template-based
solutions. In this paper, we show how to apply classical fixpoint algorithms,
that have hitherto been used in explicit, finite-state, settings, to a symbolic
logical setting. We implement our techniques in a tool called GenSys-LTL and
show that they are not only effective in synthesizing valid controllers for a
variety of challenging benchmarks from the literature, but often compute
maximal winning regions and maximally-permissive controllers. We achieve
\textbf{46.38X speed-up} over the state of the art and also scale well for
non-trivial LTL specifications.
\\ ( https://arxiv.org/abs/2306.02427 ,  4958kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02832 (*cross-listing*)
Date: Mon, 5 Jun 2023 12:27:34 GMT   (535kb,D)

Title: Probabilistic Region-of-Attraction Estimation with Scenario Optimization
 and Converse Theorems
Authors: Torbj{\o}rn Cunis
Categories: math.OC cs.SY eess.SY
Comments: Submitted to IEEE Transactions of Automatic Control
\\
 The region of attraction characterizes well-behaved and safe operation of a
nonlinear system and is hence sought after for verification. In this paper, a
framework for probabilistic region of attraction estimation is developed that
combines scenario optimization and converse theorems. With this approach, the
probability of an unstable condition being included in the estimate is
independent of the system's complexity, while convergence in probability to the
true region of attraction is proven. Numerical examples demonstrate the
effectiveness for optimization-based control applications. Combining systems
theory and sampling, the complexity of Monte--Carlo-based verification
techniques can be reduced. The results can be extended to arbitrary level sets
of which the defining function can be sampled, such as finite-horizon
viability. Thus, the proposed approach is applicable and/or adaptable to
verification of a wide range of safety-related properties for nonlinear systems
including feedback laws based on optimization or learning.
\\ ( https://arxiv.org/abs/2306.02832 ,  535kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02987 (*cross-listing*)
Date: Mon, 5 Jun 2023 16:00:22 GMT   (1837kb,D)

Title: Frequency Regulation with Storage: On Losses and Profits
Authors: Dirk Lauinger, Fran\c{c}ois Vuille, Daniel Kuhn
Categories: math.OC cs.SY econ.GN eess.SY q-fin.EC
\\
 Low-carbon societies will need to store vast amounts of electricity to
balance intermittent generation from wind and solar energy, for example,
through frequency regulation. Here, we derive an analytical solution to the
decision-making problem of storage operators who sell frequency regulation
power to grid operators and trade electricity on day-ahead markets.
Mathematically, we treat future frequency deviation trajectories as functional
uncertainties in a receding horizon robust optimization problem. We constrain
the expected terminal state-of-charge to be equal to some target to allow
storage operators to make good decisions not only for the present but also the
future. Thanks to this constraint, the amount of electricity traded on
day-ahead markets is an implicit function of the regulation power sold to grid
operators. The implicit function quantifies the amount of power that needs to
be purchased to cover the expected energy loss that results from providing
frequency regulation. We show how the marginal cost associated with the
expected energy loss decreases with roundtrip efficiency and increases with
frequency deviation dispersion. We find that the profits from frequency
regulation over the lifetime of energy-constrained storage devices are roughly
inversely proportional to the length of time for which regulation power must be
committed.
\\ ( https://arxiv.org/abs/2306.02987 ,  1837kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03027 (*cross-listing*)
Date: Mon, 5 Jun 2023 16:46:13 GMT   (10420kb)

Title: Explicit feedback synthesis driven by quasi-interpolation for nonlinear
 robust model predictive control
Authors: Siddhartha Ganguly and Debasish Chatterjee
Categories: math.OC cs.SY eess.SY
Comments: 26 Pages
\\
 We present QuIFS (Quasi-Interpolation driven Feedback Synthesis) -- an
offline feedback synthesis algorithm for explicit nonlinear robust minmax model
predictive control (MPC) problems with guaranteed quality of approximation. The
underlying technique is driven by a particular type of grid-based
quasi-interpolation scheme. The QuIFS algorithm departs drastically from
conventional approximation algorithms that are employed in the MPC industry (in
particular, it is neither based on multi-parametric programming tools nor does
it involve kernel methods), and the essence of their point of departure is
encoded in the following challenge-answer approach: Given an error margin
$\varepsilon>0$, compute a feasible feedback policy that is uniformly
$\varepsilon$-close to the optimal MPC feedback policy for a given nonlinear
system subjected to hard constraints and bounded uncertainties. Conditions for
closed-loop stability and recursive feasibility under the approximate feedback
policy are also established. We provide a library of numerical examples to
illustrate our results.
\\ ( https://arxiv.org/abs/2306.03027 ,  10420kb)
%%--%%--%%--%%--%%--%%--%%--%%--%%--%%--%%--%%--%%--%%--%%--%%--%%--%%--%%--%%
------------------------------------------------------------------------------
\\
arXiv:2205.13028
replaced with revised version Fri, 2 Jun 2023 22:51:09 GMT   (73kb,D)

Title: Formalizing Preferences Over Runtime Distributions
Authors: Devon R. Graham, Kevin Leyton-Brown, Tim Roughgarden
Categories: cs.AI cs.GT cs.LG cs.PF
\\ ( https://arxiv.org/abs/2205.13028 ,  73kb)
------------------------------------------------------------------------------
\\
arXiv:2209.13885
replaced with revised version Sat, 3 Jun 2023 18:02:16 GMT   (479kb,D)

Title: UCEpic: Unifying Aspect Planning and Lexical Constraints for Generating
 Explanations in Recommendation
Authors: Jiacheng Li, Zhankui He, Jingbo Shang, Julian McAuley
Categories: cs.AI cs.CL
Comments: Accepted to KDD 2023
\\ ( https://arxiv.org/abs/2209.13885 ,  479kb)
------------------------------------------------------------------------------
\\
arXiv:2210.05015
replaced with revised version Mon, 5 Jun 2023 05:26:33 GMT   (2867kb,D)

Title: Optimality Guarantees for Particle Belief Approximation of POMDPs
Authors: Michael H. Lim, Tyler J. Becker, Mykel J. Kochenderfer, Claire J.
 Tomlin, Zachary N. Sunberg
Categories: cs.AI cs.RO cs.SY eess.SY stat.ML
\\ ( https://arxiv.org/abs/2210.05015 ,  2867kb)
------------------------------------------------------------------------------
\\
arXiv:2211.15368
replaced with revised version Sun, 4 Jun 2023 19:01:10 GMT   (1256kb,D)

Title: Arbitrarily Large Labelled Random Satisfiability Formulas for Machine
 Learning Training
Authors: Dimitris Achlioptas, Amrit Daswaney, Periklis A. Papakonstantinou
Categories: cs.AI cs.LG
\\ ( https://arxiv.org/abs/2211.15368 ,  1256kb)
------------------------------------------------------------------------------
\\
arXiv:2212.08966
replaced with revised version Sat, 3 Jun 2023 18:36:37 GMT   (2019kb,D)

Title: Graph Learning and Its Applications: A Holistic Survey
Authors: Shaopeng Wei, Yu Zhao, Xingyan Chen, Qing Li, Fuzhen Zhuang, Ji Liu,
 Gang Kou
Categories: cs.AI
Comments: 20 pages, 8 figures, 3 tables
\\ ( https://arxiv.org/abs/2212.08966 ,  2019kb)
------------------------------------------------------------------------------
\\
arXiv:2301.05412
replaced with revised version Sat, 3 Jun 2023 05:59:42 GMT   (1372kb,D)

Title: Evolve Path Tracer: Early Detection of Malicious Addresses in
 Cryptocurrency
Authors: Ling Cheng, Feida Zhu, Yong Wang, Ruicheng Liang, Huiwen Liu
Categories: cs.AI
Comments: In Proceedings of the 29th ACM SIGKDD Conference on Knowledge
 Discovery and Data Mining (KDD23)
DOI: 10.1145/3580305.3599817
\\ ( https://arxiv.org/abs/2301.05412 ,  1372kb)
------------------------------------------------------------------------------
\\
arXiv:2302.04831
replaced with revised version Mon, 5 Jun 2023 16:44:38 GMT   (11122kb,D)

Title: Cooperative Open-ended Learning Framework for Zero-shot Coordination
Authors: Yang Li, Shao Zhang, Jichen Sun, Yali Du, Ying Wen, Xinbing Wang, Wei
 Pan
Categories: cs.AI cs.LG
Comments: 15 pages with 9 pages main body
\\ ( https://arxiv.org/abs/2302.04831 ,  11122kb)
------------------------------------------------------------------------------
\\
arXiv:2303.02927
replaced with revised version Fri, 2 Jun 2023 21:57:13 GMT   (29304kb,D)

Title: LIDA: A Tool for Automatic Generation of Grammar-Agnostic Visualizations
 and Infographics using Large Language Models
Authors: Victor Dibia
Categories: cs.AI cs.HC cs.PL
Comments: Accepted at ACL 2023 (Demonstration track)
\\ ( https://arxiv.org/abs/2303.02927 ,  29304kb)
------------------------------------------------------------------------------
\\
arXiv:2305.10201
replaced with revised version Mon, 5 Jun 2023 17:08:36 GMT   (4981kb)

Title: Echoes of Biases: How Stigmatizing Language Affects AI Performance
Authors: Yizhi Liu, Weiguang Wang, Guodong Gordon Gao, Ritu Agarwal
Categories: cs.AI cs.CY
Comments: 54 pages, 9 figures
\\ ( https://arxiv.org/abs/2305.10201 ,  4981kb)
------------------------------------------------------------------------------
\\
arXiv:2305.13823
replaced with revised version Mon, 5 Jun 2023 07:53:23 GMT   (1807kb,D)

Title: XRoute Environment: A Novel Reinforcement Learning Environment for
 Routing
Authors: Zhanwen Zhou, Hankz Hankui Zhuo, Xiaowu Zhang, Qiyuan Deng
Categories: cs.AI
Comments: arXiv admin note: text overlap with arXiv:1907.11180 by other authors
\\ ( https://arxiv.org/abs/2305.13823 ,  1807kb)
------------------------------------------------------------------------------
\\
arXiv:2305.14449
replaced with revised version Sat, 3 Jun 2023 12:42:45 GMT   (2207kb,D)

Title: Graph Meets LLM: A Novel Approach to Collaborative Filtering for Robust
 Conversational Understanding
Authors: Zheng Chen, Ziyan Jiang, Fan Yang, Eunah Cho, Xing Fan, Xiaojiang
 Huang, Yanbin Lu, Aram Galstyan
Categories: cs.AI cs.IR cs.LG
ACM-class: F.2.2; I.2.7
\\ ( https://arxiv.org/abs/2305.14449 ,  2207kb)
------------------------------------------------------------------------------
\\
arXiv:2305.17291
replaced with revised version Sun, 4 Jun 2023 04:28:15 GMT   (5239kb,D)

Title: Convex Risk Bounded Continuous-Time Trajectory Planning and Tube Design
 in Uncertain Nonconvex Environments
Authors: Ashkan Jasour, Weiqiao Han, and Brian Williams
Categories: cs.AI cs.RO math.OC
Comments: Accepted by IJRR (extension of RSS 2021 paper arXiv:2106.05489
 invited to IJRR)
\\ ( https://arxiv.org/abs/2305.17291 ,  5239kb)
------------------------------------------------------------------------------
\\
arXiv:2305.17626
replaced with revised version Mon, 5 Jun 2023 06:57:29 GMT   (769kb,D)

Title: In-Context Analogical Reasoning with Pre-Trained Language Models
Authors: Xiaoyang Hu, Shane Storks, Richard L. Lewis, Joyce Chai
Categories: cs.AI cs.CL cs.LG
\\ ( https://arxiv.org/abs/2305.17626 ,  769kb)
------------------------------------------------------------------------------
\\
arXiv:2306.00249
replaced with revised version Fri, 2 Jun 2023 22:58:35 GMT   (1061kb,D)

Title: BetaZero: Belief-State Planning for Long-Horizon POMDPs using Learned
 Approximations
Authors: Robert J. Moss, Anthony Corso, Jef Caers, Mykel J. Kochenderfer
Categories: cs.AI
Comments: 20 pages
\\ ( https://arxiv.org/abs/2306.00249 ,  1061kb)
------------------------------------------------------------------------------
\\
arXiv:2306.00937
replaced with revised version Mon, 5 Jun 2023 17:58:30 GMT   (5425kb,D)

Title: STEVE-1: A Generative Model for Text-to-Behavior in Minecraft
Authors: Shalev Lifshitz, Keiran Paster, Harris Chan, Jimmy Ba, Sheila
 McIlraith
Categories: cs.AI cs.LG
\\ ( https://arxiv.org/abs/2306.00937 ,  5425kb)
------------------------------------------------------------------------------
\\
arXiv:2104.13764
replaced with revised version Sun, 4 Jun 2023 01:20:22 GMT   (14121kb,D)

Title: Segmentation-Based Bounding Box Generation for Omnidirectional
 Pedestrian Detection
Authors: Masato Tamura, Tomoaki Yoshinaga
Categories: cs.CV
Comments: Pre-print version of a paper accepted to The Visual Computer
\\ ( https://arxiv.org/abs/2104.13764 ,  14121kb)
------------------------------------------------------------------------------
\\
arXiv:2112.04107
replaced with revised version Mon, 5 Jun 2023 10:07:34 GMT   (4160kb,D)

Title: Fully Context-Aware Image Inpainting with a Learned Semantic Pyramid
Authors: Wendong Zhang, Yunbo Wang, Bingbing Ni, Xiaokang Yang
Categories: cs.CV
Comments: Accepted by Pattern Recognition, 2023
\\ ( https://arxiv.org/abs/2112.04107 ,  4160kb)
------------------------------------------------------------------------------
\\
arXiv:2203.07390
replaced with revised version Fri, 2 Jun 2023 18:34:44 GMT   (2977kb,D)

Title: What's the Difference? The potential for Convolutional Neural Networks
 for transient detection without template subtraction
Authors: Tatiana Acero-Cuellar, Federica Bianco, Gregory Dobler, Masao Sako and
 Helen Qu
Categories: cs.CV astro-ph.IM
\\ ( https://arxiv.org/abs/2203.07390 ,  2977kb)
------------------------------------------------------------------------------
\\
arXiv:2204.01297
replaced with revised version Sat, 3 Jun 2023 05:36:56 GMT   (13714kb,D)

Title: Learning Constrained Dynamic Correlations in Spatiotemporal Graphs for
 Motion Prediction
Authors: Jiajun Fu, Fuxing Yang, Yonghao Dang, Xiaoli Liu, Jianqin Yin
Categories: cs.CV
Comments: Accepted by TNNLS. Codes are available at
 https://github.com/Jaakk0F/DSTD-GCN
DOI: 10.1109/TNNLS.2023.3277476
\\ ( https://arxiv.org/abs/2204.01297 ,  13714kb)
------------------------------------------------------------------------------
\\
arXiv:2204.10965
replaced with revised version Mon, 5 Jun 2023 17:49:40 GMT   (40326kb,D)

Title: CLIP-Dissect: Automatic Description of Neuron Representations in Deep
 Vision Networks
Authors: Tuomas Oikarinen, Tsui-Wei Weng
Categories: cs.CV cs.AI cs.LG
Comments: Published in ICLR 2023 Conference (Spotlight). New v5(5 June 2023) -
 Added crowdsourced user study in Appendix B, not included in ICLR publication
\\ ( https://arxiv.org/abs/2204.10965 ,  40326kb)
------------------------------------------------------------------------------
\\
arXiv:2205.13042
replaced with revised version Sat, 3 Jun 2023 23:01:34 GMT   (13550kb,D)

Title: How explainable are adversarially-robust CNNs?
Authors: Mehdi Nourelahi, Lars Kotthoff, Peijie Chen, Anh Nguyen
Categories: cs.CV cs.AI cs.HC
\\ ( https://arxiv.org/abs/2205.13042 ,  13550kb)
------------------------------------------------------------------------------
\\
arXiv:2207.02466
replaced with revised version Sat, 3 Jun 2023 02:24:06 GMT   (31995kb,D)

Title: GLENet: Boosting 3D Object Detectors with Generative Label Uncertainty
 Estimation
Authors: Yifan Zhang, Qijian Zhang, Zhiyu Zhu, Junhui Hou and Yixuan Yuan
Categories: cs.CV
\\ ( https://arxiv.org/abs/2207.02466 ,  31995kb)
------------------------------------------------------------------------------
\\
arXiv:2207.13963
replaced with revised version Sat, 3 Jun 2023 05:08:14 GMT   (22950kb,D)

Title: Meta-Learning based Degradation Representation for Blind
 Super-Resolution
Authors: Bin Xia, Yapeng Tian, Yulun Zhang, Yucheng Hang, Wenming Yang, Qingmin
 Liao
Categories: cs.CV
Comments: This paper is accepted by TIP 2023, and code will be released at
 https://github.com/Zj-BinXia/MRDA
\\ ( https://arxiv.org/abs/2207.13963 ,  22950kb)
------------------------------------------------------------------------------
\\
arXiv:2208.00777
replaced with revised version Sat, 3 Jun 2023 11:48:54 GMT   (7300kb,D)

Title: D3Former: Debiased Dual Distilled Transformer for Incremental Learning
Authors: Abdelrahman Mohamed, Rushali Grandhe, K J Joseph, Salman Khan, Fahad
 Khan
Categories: cs.CV cs.LG
Comments: Accepted to CLVision at CVPR 2023
\\ ( https://arxiv.org/abs/2208.00777 ,  7300kb)
------------------------------------------------------------------------------
\\
arXiv:2208.02676
replaced with revised version Sat, 3 Jun 2023 07:37:08 GMT   (5136kb,D)

Title: Single-view 3D Mesh Reconstruction for Seen and Unseen Categories
Authors: Xianghui Yang, Guosheng Lin, Luping Zhou
Categories: cs.CV
Comments: Published in IEEE Transactions on Image Processing (TIP)
DOI: 10.1109/TIP.2023.3279661
\\ ( https://arxiv.org/abs/2208.02676 ,  5136kb)
------------------------------------------------------------------------------
\\
arXiv:2209.00128
replaced with revised version Sat, 3 Jun 2023 21:15:47 GMT   (20010kb,D)

Title: Archangel: A Hybrid UAV-based Human Detection Benchmark with Position
 and Pose Metadata
Authors: Yi-Ting Shen, Yaesop Lee, Heesung Kwon, Damon M. Conover, Shuvra S.
 Bhattacharyya, Nikolas Vale, Joshua D. Gray, G. Jeremy Leong, Kenneth
 Evensen, Frank Skirlo
Categories: cs.CV
Comments: Submission to IEEE Access
\\ ( https://arxiv.org/abs/2209.00128 ,  20010kb)
------------------------------------------------------------------------------
\\
arXiv:2209.06794
replaced with revised version Mon, 5 Jun 2023 17:55:12 GMT   (1667kb,D)

Title: PaLI: A Jointly-Scaled Multilingual Language-Image Model
Authors: Xi Chen, Xiao Wang, Soravit Changpinyo, AJ Piergiovanni, Piotr
 Padlewski, Daniel Salz, Sebastian Goodman, Adam Grycner, Basil Mustafa, Lucas
 Beyer, Alexander Kolesnikov, Joan Puigcerver, Nan Ding, Keran Rong, Hassan
 Akbari, Gaurav Mishra, Linting Xue, Ashish Thapliyal, James Bradbury,
 Weicheng Kuo, Mojtaba Seyedhosseini, Chao Jia, Burcu Karagol Ayan, Carlos
 Riquelme, Andreas Steiner, Anelia Angelova, Xiaohua Zhai, Neil Houlsby, Radu
 Soricut
Categories: cs.CV cs.CL
Comments: ICLR 2023 (Notable-top-5%)
\\ ( https://arxiv.org/abs/2209.06794 ,  1667kb)
------------------------------------------------------------------------------
\\
arXiv:2210.04183
replaced with revised version Mon, 5 Jun 2023 14:35:59 GMT   (32404kb,D)

Title: MAMO: Masked Multimodal Modeling for Fine-Grained Vision-Language
 Representation Learning
Authors: Zijia Zhao, Longteng Guo, Xingjian He, Shuai Shao, Zehuan Yuan, Jing
 Liu
Categories: cs.CV cs.CL cs.LG cs.MM
Comments: SIGIR 2023, 10 pages
DOI: 10.1145/3539618.3591721
\\ ( https://arxiv.org/abs/2210.04183 ,  32404kb)
------------------------------------------------------------------------------
\\
arXiv:2210.07181
replaced with revised version Sun, 4 Jun 2023 07:17:39 GMT   (10244kb,D)

Title: MonoNeRF: Learning Generalizable NeRFs from Monocular Videos without
 Camera Pose
Authors: Yang Fu, Ishan Misra, Xiaolong Wang
Categories: cs.CV cs.LG cs.RO
Comments: ICML 2023 camera ready version. Project page:
 https://oasisyang.github.io/mononerf
\\ ( https://arxiv.org/abs/2210.07181 ,  10244kb)
------------------------------------------------------------------------------
\\
arXiv:2210.12513
replaced with revised version Mon, 5 Jun 2023 10:09:54 GMT   (6950kb,D)

Title: Learning Point-Language Hierarchical Alignment for 3D Visual Grounding
Authors: Jiaming Chen, Weixin Luo, Ran Song, Xiaolin Wei, Lin Ma, Wei Zhang
Categories: cs.CV
Comments: Champion on ECCV 2022 ScanRefer Challenge
\\ ( https://arxiv.org/abs/2210.12513 ,  6950kb)
------------------------------------------------------------------------------
\\
arXiv:2210.16467
replaced with revised version Mon, 5 Jun 2023 09:20:38 GMT   (11809kb)

Title: ImplantFormer: Vision Transformer based Implant Position Regression
 Using Dental CBCT Data
Authors: Xinquan Yang and Xuguang Li and Xuechen Li and Peixi Wu and Linlin
 Shen and Yongqiang Deng
Categories: cs.CV
\\ ( https://arxiv.org/abs/2210.16467 ,  11809kb)
------------------------------------------------------------------------------
\\
arXiv:2211.11255
replaced with revised version Sun, 4 Jun 2023 02:06:29 GMT   (924kb,D)

Title: Diffusion Denoising Process for Perceptron Bias in Out-of-distribution
 Detection
Authors: Luping Liu and Yi Ren and Xize Cheng and Rongjie Huang and Chongxuan
 Li and Zhou Zhao
Categories: cs.CV cs.AI cs.LG stat.ML
\\ ( https://arxiv.org/abs/2211.11255 ,  924kb)
------------------------------------------------------------------------------
\\
arXiv:2211.17091
replaced with revised version Sun, 4 Jun 2023 22:19:27 GMT   (30373kb,D)

Title: Refining Generative Process with Discriminator Guidance in Score-based
 Diffusion Models
Authors: Dongjun Kim, Yeongmin Kim, Se Jung Kwon, Wanmo Kang, Il-Chul Moon
Categories: cs.CV cs.AI cs.LG
Comments: International Conference on Machine Learning (ICML23)
\\ ( https://arxiv.org/abs/2211.17091 ,  30373kb)
------------------------------------------------------------------------------
\\
arXiv:2212.06079
replaced with revised version Sun, 4 Jun 2023 01:02:57 GMT   (24905kb,D)

Title: Robust Perception through Equivariance
Authors: Chengzhi Mao, Lingyu Zhang, Abhishek Joshi, Junfeng Yang, Hao Wang,
 Carl Vondrick
Categories: cs.CV
Comments: Published in ICML 2023
\\ ( https://arxiv.org/abs/2212.06079 ,  24905kb)
------------------------------------------------------------------------------
\\
arXiv:2212.10950
replaced with revised version Sun, 4 Jun 2023 04:16:42 GMT   (11820kb,D)

Title: Incremental Neural Implicit Representation with Uncertainty-Filtered
 Knowledge Distillation
Authors: Mengqi Guo, Chen Li, Hanlin Chen, Gim Hee Lee
Categories: cs.CV
\\ ( https://arxiv.org/abs/2212.10950 ,  11820kb)
------------------------------------------------------------------------------
\\
arXiv:2212.11409
replaced with revised version Sun, 4 Jun 2023 18:03:15 GMT   (7570kb,D)

Title: DExT: Detector Explanation Toolkit
Authors: Deepan Chakravarthi Padmanabhan, Paul G. Pl\"oger, Octavio Arriaga,
 Matias Valdenegro-Toro
Categories: cs.CV cs.LG
Comments: 24 pages, with appendix. 1st World Conference on eXplainable
 Artificial Intelligence camera ready
\\ ( https://arxiv.org/abs/2212.11409 ,  7570kb)
------------------------------------------------------------------------------
\\
arXiv:2301.02364
replaced with revised version Mon, 5 Jun 2023 05:40:56 GMT   (11572kb,D)

Title: Object as Query: Lifting any 2D Object Detector to 3D Detection
Authors: Zitian Wang, Zehao Huang, Jiahui Fu, Naiyan Wang, Si Liu
Categories: cs.CV
Comments: technical report
\\ ( https://arxiv.org/abs/2301.02364 ,  11572kb)
------------------------------------------------------------------------------
\\
arXiv:2301.03041
replaced with revised version Mon, 5 Jun 2023 11:58:22 GMT   (5398kb,D)

Title: Learning the Relation between Similarity Loss and Clustering Loss in
 Self-Supervised Learning
Authors: Jidong Ge, Yuxiang Liu, Jie Gui, Lanting Fang, Ming Lin, James Tin-Yau
 Kwok, LiGuo Huang, Bin Luo
Categories: cs.CV cs.LG
Comments: This paper is accepted by IEEE Transactions on Image Processing
\\ ( https://arxiv.org/abs/2301.03041 ,  5398kb)
------------------------------------------------------------------------------
\\
arXiv:2301.12159
replaced with revised version Mon, 5 Jun 2023 08:56:05 GMT   (132kb)

Title: ClusterFuG: Clustering Fully connected Graphs by Multicut
Authors: Ahmed Abbas and Paul Swoboda
Categories: cs.CV cs.LG
Comments: ICML 2023
\\ ( https://arxiv.org/abs/2301.12159 ,  132kb)
------------------------------------------------------------------------------
\\
arXiv:2302.00491
replaced with revised version Mon, 5 Jun 2023 13:58:47 GMT   (3556kb,D)

Title: Learning Prototype Classifiers for Long-Tailed Recognition
Authors: Saurabh Sharma, Yongqin Xian, Ning Yu, Ambuj Singh
Categories: cs.CV cs.LG
Comments: Accepted at IJCAI-23
\\ ( https://arxiv.org/abs/2302.00491 ,  3556kb)
------------------------------------------------------------------------------
\\
arXiv:2302.05757
replaced with revised version Sat, 3 Jun 2023 21:39:19 GMT   (13724kb,D)

Title: Multispectral Contrastive Learning with Viewmaker Networks
Authors: Jasmine Bayrooti, Noah Goodman, Alex Tamkin
Categories: cs.CV cs.AI
Comments: Appearing in CVPR-PBVS 2023
\\ ( https://arxiv.org/abs/2302.05757 ,  13724kb)
------------------------------------------------------------------------------
\\
arXiv:2302.08674
replaced with revised version Sun, 4 Jun 2023 11:28:48 GMT   (24127kb,D)

Title: EnfoMax: Domain Entropy and Mutual Information Maximization for Domain
 Generalized Face Anti-spoofing
Authors: Tianyi Zheng
Categories: cs.CV
\\ ( https://arxiv.org/abs/2302.08674 ,  24127kb)
------------------------------------------------------------------------------
\\
arXiv:2302.10279
replaced with revised version Mon, 5 Jun 2023 09:50:48 GMT   (4465kb,D)

Title: Image Reconstruction via Deep Image Prior Subspaces
Authors: Riccardo Barbano, Javier Antor\'an, Johannes Leuschner, Jos\'e Miguel
 Hern\'andez-Lobato, Bangti Jin, \v{Z}eljko Kereta
Categories: cs.CV eess.IV
\\ ( https://arxiv.org/abs/2302.10279 ,  4465kb)
------------------------------------------------------------------------------
\\
arXiv:2302.13002
replaced with revised version Mon, 5 Jun 2023 09:10:36 GMT   (7305kb,D)

Title: Introducing Depth into Transformer-based 3D Object Detection
Authors: Hao Zhang, Hongyang Li, Ailing Zeng, Feng Li, Shilong Liu, Xingyu
 Liao, Lei Zhang
Categories: cs.CV
Comments: revision
\\ ( https://arxiv.org/abs/2302.13002 ,  7305kb)
------------------------------------------------------------------------------
\\
arXiv:2303.04341
replaced with revised version Sat, 3 Jun 2023 07:54:13 GMT   (35828kb,D)

Title: Neural Vector Fields: Implicit Representation by Explicit Learning
Authors: Xianghui Yang, Guosheng Lin, Zhenghao Chen, Luping Zhou
Categories: cs.CV cs.AI cs.GR
Comments: Accepted by CVPR2023. Video:
 https://www.youtube.com/watch?v=GMXKoJfmHrU
\\ ( https://arxiv.org/abs/2303.04341 ,  35828kb)
------------------------------------------------------------------------------
\\
arXiv:2303.04935
replaced with revised version Mon, 5 Jun 2023 04:33:07 GMT   (8234kb,D)

Title: X-Pruner: eXplainable Pruning for Vision Transformers
Authors: Lu Yu, Wei Xiang
Categories: cs.CV
\\ ( https://arxiv.org/abs/2303.04935 ,  8234kb)
------------------------------------------------------------------------------
\\
arXiv:2303.06138
replaced with revised version Mon, 5 Jun 2023 06:37:21 GMT   (2518kb,D)

Title: Learning Object-Centric Neural Scattering Functions for Free-viewpoint
 Relighting and Scene Composition
Authors: Hong-Xing Yu, Michelle Guo, Alireza Fathi, Yen-Yu Chang, Eric Ryan
 Chan, Ruohan Gao, Thomas Funkhouser, Jiajun Wu
Categories: cs.CV cs.GR
Comments: Project website: https://kovenyu.com/osf/ Journal extension of
 arXiv:2012.08503. The first two authors contributed equally to this work
\\ ( https://arxiv.org/abs/2303.06138 ,  2518kb)
------------------------------------------------------------------------------
\\
arXiv:2303.06500
replaced with revised version Mon, 5 Jun 2023 11:03:32 GMT   (24093kb,D)

Title: Diffusion-Based Hierarchical Multi-Label Object Detection to Analyze
 Panoramic Dental X-rays
Authors: Ibrahim Ethem Hamamci and Sezgin Er and Enis Simsar and Anjany
 Sekuboyina and Mustafa Gundogar and Bernd Stadlinger and Albert Mehl and
 Bjoern Menze
Categories: cs.CV
Comments: MICCAI 2023
\\ ( https://arxiv.org/abs/2303.06500 ,  24093kb)
------------------------------------------------------------------------------
\\
arXiv:2303.10644
replaced with revised version Mon, 5 Jun 2023 04:49:34 GMT   (266kb,D)

Title: Spatio-Temporal AU Relational Graph Representation Learning For Facial
 Action Units Detection
Authors: Zihan Wang, Siyang Song, Cheng Luo, Yuzhi Zhou, Shiling Wu, Weicheng
 Xie, Linlin Shen
Categories: cs.CV
MSC-class: 68T40
\\ ( https://arxiv.org/abs/2303.10644 ,  266kb)
------------------------------------------------------------------------------
\\
arXiv:2303.11702
replaced with revised version Mon, 5 Jun 2023 15:11:43 GMT   (864kb,D)

Title: Linking generative semi-supervised learning and generative open-set
 recognition
Authors: Emile Reyn Engelbrecht, Johan du Preez
Categories: cs.CV cs.AI cs.LG
\\ ( https://arxiv.org/abs/2303.11702 ,  864kb)
------------------------------------------------------------------------------
\\
arXiv:2303.13294
replaced with revised version Mon, 5 Jun 2023 12:24:26 GMT   (1713kb,D)

Title: Considerations on the Evaluation of Biometric Quality Assessment
 Algorithms
Authors: Torsten Schlett, Christian Rathgeb, Juan Tapia, Christoph Busch
Categories: cs.CV
\\ ( https://arxiv.org/abs/2303.13294 ,  1713kb)
------------------------------------------------------------------------------
\\
arXiv:2303.14302
replaced with revised version Fri, 2 Jun 2023 18:57:30 GMT   (8626kb,D)

Title: VILA: Learning Image Aesthetics from User Comments with Vision-Language
 Pretraining
Authors: Junjie Ke, Keren Ye, Jiahui Yu, Yonghui Wu, Peyman Milanfar, Feng Yang
Categories: cs.CV
Comments: CVPR 2023,
 https://github.com/google-research/google-research/tree/master/vila
\\ ( https://arxiv.org/abs/2303.14302 ,  8626kb)
------------------------------------------------------------------------------
\\
arXiv:2303.14730
replaced with revised version Mon, 5 Jun 2023 02:22:18 GMT   (2737kb,D)

Title: Joint fMRI Decoding and Encoding with Latent Embedding Alignment
Authors: Xuelin Qian, Yikai Wang, Yanwei Fu, Xinwei Sun, Xiangyang Xue,
 Jianfeng Feng
Categories: cs.CV
Comments: 12 pages, 5 figures
\\ ( https://arxiv.org/abs/2303.14730 ,  2737kb)
------------------------------------------------------------------------------
\\
arXiv:2303.15754
replaced with revised version Mon, 5 Jun 2023 07:25:12 GMT   (242kb,D)

Title: Transferable Adversarial Attacks on Vision Transformers with Token
 Gradient Regularization
Authors: Jianping Zhang, Yizhan Huang, Weibin Wu, Michael R. Lyu
Categories: cs.CV
Comments: CVPR 2023, Code is available at https://github.com/jpzhang1810/TGR
\\ ( https://arxiv.org/abs/2303.15754 ,  242kb)
------------------------------------------------------------------------------
\\
arXiv:2303.17783
replaced with revised version Sun, 4 Jun 2023 05:41:36 GMT   (30954kb,D)

Title: SOSR: Source-Free Image Super-Resolution with Wavelet Augmentation
 Transformer
Authors: Yuang Ai, Xiaoqiang Zhou, Huaibo Huang, Lei Zhang, Ran He
Categories: cs.CV
Comments: 15 pages, 9 figures, 10 tables
\\ ( https://arxiv.org/abs/2303.17783 ,  30954kb)
------------------------------------------------------------------------------
\\
arXiv:2303.17967
replaced with revised version Sun, 4 Jun 2023 15:07:55 GMT   (2307kb,D)

Title: Learning with Explicit Shape Priors for Medical Image Segmentation
Authors: Xin You, Junjun He, Jie Yang, and Yun Gu
Categories: cs.CV
Comments: 10 pages, 10 figures
\\ ( https://arxiv.org/abs/2303.17967 ,  2307kb)
------------------------------------------------------------------------------
\\
arXiv:2304.01611
replaced with revised version Mon, 5 Jun 2023 05:17:55 GMT   (9549kb,D)

Title: Q2ATransformer: Improving Medical VQA via an Answer Querying Decoder
Authors: Yunyi Liu, Zhanyu Wang, Dong Xu, and Luping Zhou
Categories: cs.CV cs.AI
\\ ( https://arxiv.org/abs/2304.01611 ,  9549kb)
------------------------------------------------------------------------------
\\
arXiv:2304.02744
replaced with revised version Fri, 2 Jun 2023 19:41:14 GMT   (19055kb,D)

Title: StyleGAN Salon: Multi-View Latent Optimization for Pose-Invariant
 Hairstyle Transfer
Authors: Sasikarn Khwanmuang, Pakkapon Phongthawee, Patsorn Sangkloy, Supasorn
 Suwajanakorn
Categories: cs.CV
Comments: Accepted to CVPR2023
\\ ( https://arxiv.org/abs/2304.02744 ,  19055kb)
------------------------------------------------------------------------------
\\
arXiv:2304.11379
replaced with revised version Mon, 5 Jun 2023 03:56:19 GMT   (7396kb,D)

Title: LiDAR2Map: In Defense of LiDAR-Based Semantic Map Construction Using
 Online Camera Distillation
Authors: Song Wang and Wentong Li and Wenyu Liu and Xiaolu Liu and Jianke Zhu
Categories: cs.CV cs.RO
Comments: Accepted by CVPR2023
\\ ( https://arxiv.org/abs/2304.11379 ,  7396kb)
------------------------------------------------------------------------------
\\
arXiv:2304.12637
replaced with revised version Mon, 5 Jun 2023 11:19:28 GMT   (3263kb,D)

Title: Generalist Vision Foundation Models for Medical Imaging: A Case Study of
 Segment Anything Model on Zero-Shot Medical Segmentation
Authors: Peilun Shi, Jianing Qiu, Sai Mu Dalike Abaxi, Hao Wei, Frank P.-W. Lo,
 Wu Yuan
Categories: cs.CV
Comments: Published in Diagnostics
Journal-ref: Diagnostics 2023
DOI: 10.3390/diagnostics13111947
\\ ( https://arxiv.org/abs/2304.12637 ,  3263kb)
------------------------------------------------------------------------------
\\
arXiv:2305.03716
replaced with revised version Mon, 5 Jun 2023 17:35:33 GMT   (29380kb,D)

Title: DSPDet3D: Dynamic Spatial Pruning for 3D Small Object Detection
Authors: Xiuwei Xu, Zhihao Sun, Ziwei Wang, Hongmin Liu, Jie Zhou, Jiwen Lu
Categories: cs.CV
Comments: Code is available at: https://github.com/xuxw98/DSPDet3D
\\ ( https://arxiv.org/abs/2305.03716 ,  29380kb)
------------------------------------------------------------------------------
\\
arXiv:2305.04379
replaced with revised version Sat, 3 Jun 2023 19:23:08 GMT   (0kb,I)

Title: Data Efficient Training with Imbalanced Label Sample Distribution for
 Fashion Detection
Authors: Xin Shen, Praful Agrawal, Zhongwei Cheng
Categories: cs.CV cs.AI
Comments: We have identified a substantial error in the experimental results
 and a potentially misleading explanation of the algorithm. We kindly request
 that you consider withdrawing this version to mitigate the risk of
 disseminating inaccurate information
\\ ( https://arxiv.org/abs/2305.04379 ,  0kb)
------------------------------------------------------------------------------
\\
arXiv:2305.10044
replaced with revised version Sat, 3 Jun 2023 05:08:28 GMT   (5772kb)

Title: Two-Stream Regression Network for Dental Implant Position Prediction
Authors: Xinquan Yang and Xuguang Li and Xuechen Li and Wenting Chen and Linlin
 Shen and Xin Li and Yongqiang Deng
Categories: cs.CV
\\ ( https://arxiv.org/abs/2305.10044 ,  5772kb)
------------------------------------------------------------------------------
\\
arXiv:2305.10132
replaced with revised version Sun, 4 Jun 2023 15:57:55 GMT   (5096kb,D)

Title: Automatic 3D Registration of Dental CBCT and Face Scan Data using 2D
 Projection images
Authors: Hyoung Suk Park and Chang Min Hyun and Sang-Hwy Lee and Jin Keun Seo
 and Kiwan Jeon
Categories: cs.CV
Comments: 8 pages, 6 figures, 2 tables
MSC-class: 92C55, 15A04, 62F10
\\ ( https://arxiv.org/abs/2305.10132 ,  5096kb)
------------------------------------------------------------------------------
\\
arXiv:2305.12497
replaced with revised version Mon, 5 Jun 2023 04:43:41 GMT   (39686kb,D)

Title: PanoContext-Former: Panoramic Total Scene Understanding with a
 Transformer
Authors: Yuan Dong, Chuan Fang, Liefeng Bo, Zilong Dong, Ping Tan
Categories: cs.CV
\\ ( https://arxiv.org/abs/2305.12497 ,  39686kb)
------------------------------------------------------------------------------
\\
arXiv:2305.12673
replaced with revised version Sat, 3 Jun 2023 03:34:00 GMT   (13916kb,D)

Title: Efficient Bilateral Cross-Modality Cluster Matching for Unsupervised
 Visible-Infrared Person ReID
Authors: De cheng, Lingfeng He, Nannan Wang, Shizhou Zhang, Zhen Wang and Xinbo
 Gao
Categories: cs.CV cs.AI
\\ ( https://arxiv.org/abs/2305.12673 ,  13916kb)
------------------------------------------------------------------------------
\\
arXiv:2305.12711
replaced with revised version Sat, 3 Jun 2023 03:30:46 GMT   (6264kb,D)

Title: Unsupervised Visible-Infrared Person ReID by Collaborative Learning with
 Neighbor-Guided Label Refinement
Authors: De Cheng, Xiaojian Huang, Nannan Wang, Lingfeng He, Zhihui Li and
 Xinbo Gao
Categories: cs.CV cs.AI
\\ ( https://arxiv.org/abs/2305.12711 ,  6264kb)
------------------------------------------------------------------------------
\\
arXiv:2305.14668
replaced with revised version Mon, 5 Jun 2023 17:39:03 GMT   (4633kb,D)

Title: Robust 3D-aware Object Classification via Discriminative
 Render-and-Compare
Authors: Artur Jesslen, Guofeng Zhang, Angtian Wang, Alan Yuille, Adam
 Kortylewski
Categories: cs.CV
\\ ( https://arxiv.org/abs/2305.14668 ,  4633kb)
------------------------------------------------------------------------------
\\
arXiv:2305.14742
replaced with revised version Mon, 5 Jun 2023 10:34:05 GMT   (11820kb,D)

Title: ChatFace: Chat-Guided Real Face Editing via Diffusion Latent Space
 Manipulation
Authors: Dongxu Yue, Qin Guo, Munan Ning, Jiaxi Cui, Yuesheng Zhu, Li Yuan
Categories: cs.CV
\\ ( https://arxiv.org/abs/2305.14742 ,  11820kb)
------------------------------------------------------------------------------
\\
arXiv:2305.14955
replaced with revised version Mon, 5 Jun 2023 04:15:26 GMT   (15309kb,D)

Title: DC-Net: Divide-and-Conquer for Salient Object Detection
Authors: Jiayi Zhu, Xuebin Qin, Abdulmotaleb Elsaddik
Categories: cs.CV
\\ ( https://arxiv.org/abs/2305.14955 ,  15309kb)
------------------------------------------------------------------------------
\\
arXiv:2305.15426
replaced with revised version Fri, 2 Jun 2023 19:09:40 GMT   (757kb,D)

Title: Transcending Grids: Point Clouds and Surface Representations Powering
 Neurological Processing
Authors: Kishore Babu Nampalle, Pradeep Singh, Vivek Narayan Uppala, Sumit
 Gangwar, Rajesh Singh Negi, Balasubramanian Raman
Categories: cs.CV cs.LG
\\ ( https://arxiv.org/abs/2305.15426 ,  757kb)
------------------------------------------------------------------------------
\\
arXiv:2305.16304
replaced with revised version Mon, 5 Jun 2023 11:14:41 GMT   (6754kb,D)

Title: Candidate Set Re-ranking for Composed Image Retrieval with Dual
 Multi-modal Encoder
Authors: Zheyuan Liu, Weixuan Sun, Damien Teney, Stephen Gould
Categories: cs.CV cs.IR cs.LG
Comments: 14 pages
\\ ( https://arxiv.org/abs/2305.16304 ,  6754kb)
------------------------------------------------------------------------------
\\
arXiv:2305.16649
replaced with revised version Mon, 5 Jun 2023 07:31:49 GMT   (1567kb,D)

Title: FSD: Fully-Specialized Detector via Neural Architecture Search
Authors: Zhe Huang and Yudian Li
Categories: cs.CV
\\ ( https://arxiv.org/abs/2305.16649 ,  1567kb)
------------------------------------------------------------------------------
\\
arXiv:2305.17220
replaced with revised version Sun, 4 Jun 2023 14:22:17 GMT   (16683kb,D)

Title: VoxDet: Voxel Learning for Novel Instance Detection
Authors: Bowen Li, Jiashun Wang, Yaoyu Hu, Chen Wang, Sebastian Scherer
Categories: cs.CV
Comments: 17 pages, 10 figures
\\ ( https://arxiv.org/abs/2305.17220 ,  16683kb)
------------------------------------------------------------------------------
\\
arXiv:2305.17303
replaced with revised version Fri, 2 Jun 2023 19:05:36 GMT   (6470kb,D)

Title: Distilling BlackBox to Interpretable models for Efficient Transfer
 Learning
Authors: Shantanu Ghosh, Ke Yu, Kayhan Batmanghelich
Categories: cs.CV cs.LG
Comments: MICCAI, 2023, Early accept
\\ ( https://arxiv.org/abs/2305.17303 ,  6470kb)
------------------------------------------------------------------------------
\\
arXiv:2305.19406
replaced with revised version Sun, 4 Jun 2023 17:05:56 GMT   (8525kb,D)

Title: PaintSeg: Training-free Segmentation via Painting
Authors: Xiang Li, Chung-Ching Lin, Yinpeng Chen, Zicheng Liu, Jinglu Wang,
 Bhiksha Raj
Categories: cs.CV
\\ ( https://arxiv.org/abs/2305.19406 ,  8525kb)
------------------------------------------------------------------------------
\\
arXiv:2305.19725
replaced with revised version Sun, 4 Jun 2023 12:38:10 GMT   (4638kb,D)

Title: Direct Learning-Based Deep Spiking Neural Networks: A Review
Authors: Yufei Guo, Xuhui Huang, Zhe Ma
Categories: cs.CV
Comments: Accepted by Frontiers in Neuroscience. If your relevant work is
 omitted, feel free to email me at yfguo@pku.edu.cn
\\ ( https://arxiv.org/abs/2305.19725 ,  4638kb)
------------------------------------------------------------------------------
\\
arXiv:2306.00114
replaced with revised version Sun, 4 Jun 2023 23:54:02 GMT   (7257kb,D)

Title: The Canadian Cropland Dataset: A New Land Cover Dataset for
 Multitemporal Deep Learning Classification in Agriculture
Authors: Amanda A. Boatswain Jacques and Abdoulaye Banir\'e Diallo and Etienne
 Lord
Categories: cs.CV cs.AI cs.LG
Comments: 24 pages, 5 figures, dataset descriptor
\\ ( https://arxiv.org/abs/2306.00114 ,  7257kb)
------------------------------------------------------------------------------
\\
arXiv:2306.00630
replaced with revised version Sat, 3 Jun 2023 11:12:28 GMT   (2162kb,D)

Title: Class Anchor Margin Loss for Content-Based Image Retrieval
Authors: Alexandru Ghita and Radu Tudor Ionescu
Categories: cs.CV cs.IR cs.LG
\\ ( https://arxiv.org/abs/2306.00630 ,  2162kb)
------------------------------------------------------------------------------
\\
arXiv:2306.00974
replaced with revised version Sun, 4 Jun 2023 16:06:47 GMT   (13626kb,D)

Title: Intriguing Properties of Text-guided Diffusion Models
Authors: Qihao Liu, Adam Kortylewski, Yutong Bai, Song Bai, and Alan Yuille
Categories: cs.CV
Comments: Code will be available at: https://github.com/qihao067/SAGE
\\ ( https://arxiv.org/abs/2306.00974 ,  13626kb)
------------------------------------------------------------------------------
\\
arXiv:2306.00980
replaced with revised version Sat, 3 Jun 2023 13:53:48 GMT   (39910kb,D)

Title: SnapFusion: Text-to-Image Diffusion Model on Mobile Devices within Two
 Seconds
Authors: Yanyu Li, Huan Wang, Qing Jin, Ju Hu, Pavlo Chemerys, Yun Fu, Yanzhi
 Wang, Sergey Tulyakov, Jian Ren
Categories: cs.CV cs.AI cs.LG
Comments: Our project webpage: https://snap-research.github.io/SnapFusion/
\\ ( https://arxiv.org/abs/2306.00980 ,  39910kb)
------------------------------------------------------------------------------
\\
arXiv:2306.01205
replaced with revised version Mon, 5 Jun 2023 07:32:22 GMT   (2046kb,D)

Title: SelFLoc: Selective Feature Fusion for Large-scale Point Cloud-based
 Place Recognition
Authors: Qibo Qiu, Haiming Gao, Wenxiao Wang, Zhiyi Su, Tian Xie, Wei Hua, and
 Xiaofei He
Categories: cs.CV
\\ ( https://arxiv.org/abs/2306.01205 ,  2046kb)
------------------------------------------------------------------------------
\\
arXiv:2306.01594
replaced with revised version Mon, 5 Jun 2023 04:45:36 GMT   (1336kb,D)

Title: A Novel Vision Transformer with Residual in Self-attention for
 Biomedical Image Classification
Authors: Arun K. Sharma and Nishchal K. Verma
Categories: cs.CV
\\ ( https://arxiv.org/abs/2306.01594 ,  1336kb)
------------------------------------------------------------------------------
\\
arXiv:2201.06021
replaced with revised version Mon, 5 Jun 2023 00:06:56 GMT   (698kb,D)

Title: Rawlsian Fairness in Online Bipartite Matching: Two-sided, Group, and
 Individual
Authors: Seyed A. Esmaeili, Sharmila Duppala, Davidson Cheng, Vedant Nanda,
 Aravind Srinivasan, and John P. Dickerson
Categories: cs.GT cs.AI cs.DS
Comments: Accepted to AAAI 2023
\\ ( https://arxiv.org/abs/2201.06021 ,  698kb)
------------------------------------------------------------------------------
\\
arXiv:2203.00544
replaced with revised version Mon, 5 Jun 2023 17:23:38 GMT   (8596kb,D)

Title: Discovering Opportunities in New York City's Discovery Program:
 Disadvantaged Students in Highly Competitive Markets
Authors: Yuri Faenza, Swati Gupta, Xuan Zhang
Categories: cs.GT econ.TH
\\ ( https://arxiv.org/abs/2203.00544 ,  8596kb)
------------------------------------------------------------------------------
\\
arXiv:2302.14234
replaced with revised version Mon, 5 Jun 2023 15:31:57 GMT   (290kb,D)

Title: Bicriteria Multidimensional Mechanism Design with Side Information
Authors: Maria-Florina Balcan, Siddharth Prasad, Tuomas Sandholm
Categories: cs.GT econ.TH
\\ ( https://arxiv.org/abs/2302.14234 ,  290kb)
------------------------------------------------------------------------------
\\
arXiv:2303.12506
replaced with revised version Sun, 4 Jun 2023 00:28:11 GMT   (128kb)

Title: Leximin Approximation: From Single-Objective to Multi-Objective
Authors: Eden Hartman, Avinatan Hassidim, Yonatan Aumann and Erel Segal-Halevi
Categories: cs.GT cs.DS cs.MA
\\ ( https://arxiv.org/abs/2303.12506 ,  128kb)
------------------------------------------------------------------------------
\\
arXiv:2303.16385
replaced with revised version Sat, 3 Jun 2023 22:41:48 GMT   (1718kb,D)

Title: Geometric Convergence of Distributed Heavy-Ball Nash Equilibrium
 Algorithm over Time-Varying Digraphs with Unconstrained Actions
Authors: Duong Thuy Anh Nguyen, Duong Tung Nguyen, Angelia Nedich
Categories: cs.GT
\\ ( https://arxiv.org/abs/2303.16385 ,  1718kb)
------------------------------------------------------------------------------
\\
arXiv:1910.04332
replaced with revised version Mon, 5 Jun 2023 05:40:41 GMT   (181kb,D)

Title: Sparse tree search optimality guarantees in POMDPs with continuous
 observation spaces
Authors: Michael H. Lim, Claire J. Tomlin, Zachary N. Sunberg
Categories: cs.LG cs.RO cs.SY eess.SY stat.ML
DOI: 10.24963/ijcai.2020/572
\\ ( https://arxiv.org/abs/1910.04332 ,  181kb)
------------------------------------------------------------------------------
\\
arXiv:1910.08145
replaced with revised version Sat, 3 Jun 2023 21:11:07 GMT   (2370kb)

Title: Proposing a Model for Predicting Passenger Origin-Destination in Online
 Taxi-Hailing Systems
Authors: Pouria Golshanrad, Hamid Mahini, Behnam Bahrak
Categories: cs.LG eess.SP stat.ML
Comments: 30 pages, 21 figures
MSC-class: 68T01
ACM-class: I.2.1
\\ ( https://arxiv.org/abs/1910.08145 ,  2370kb)
------------------------------------------------------------------------------
\\
arXiv:1910.13601
replaced with revised version Mon, 5 Jun 2023 15:05:13 GMT   (229kb,D)

Title: Deep Weakly-supervised Anomaly Detection
Authors: Guansong Pang, Chunhua Shen, Huidong Jin, Anton van den Hengel
Categories: cs.LG stat.ML
Comments: Accepted to KDD 2023
\\ ( https://arxiv.org/abs/1910.13601 ,  229kb)
------------------------------------------------------------------------------
\\
arXiv:2006.10916
replaced with revised version Fri, 2 Jun 2023 20:04:45 GMT   (1732kb,D)

Title: Probabilistic Fair Clustering
Authors: Seyed A. Esmaeili, Brian Brubach, Leonidas Tsepenekas, John P.
 Dickerson
Categories: cs.LG cs.AI cs.DS stat.ML
\\ ( https://arxiv.org/abs/2006.10916 ,  1732kb)
------------------------------------------------------------------------------
\\
arXiv:2106.07451
replaced with revised version Sat, 3 Jun 2023 01:42:37 GMT   (979kb,D)

Title: Noise-robust Graph Learning by Estimating and Leveraging Pairwise
 Interactions
Authors: Xuefeng Du, Tian Bian, Yu Rong, Bo Han, Tongliang Liu, Tingyang Xu,
 Wenbing Huang, Yixuan Li, Junzhou Huang
Categories: cs.LG
Comments: accepted to TMLR
\\ ( https://arxiv.org/abs/2106.07451 ,  979kb)
------------------------------------------------------------------------------
\\
arXiv:2108.01005
replaced with revised version Mon, 5 Jun 2023 14:10:00 GMT   (1348kb,D)

Title: Sequoia: A Software Framework to Unify Continual Learning Research
Authors: Fabrice Normandin, Florian Golemo, Oleksiy Ostapenko, Pau Rodriguez,
 Matthew D Riemer, Julio Hurtado, Khimya Khetarpal, Ryan Lindeborg, Lucas
 Cecchi, Timoth\'ee Lesort, Laurent Charlin, Irina Rish, Massimo Caccia
Categories: cs.LG
\\ ( https://arxiv.org/abs/2108.01005 ,  1348kb)
------------------------------------------------------------------------------
\\
arXiv:2108.06988
replaced with revised version Mon, 5 Jun 2023 08:09:57 GMT   (1989kb,D)

Title: A diffusion-map-based algorithm for gradient computation on manifolds
 and applications
Authors: Alvaro Almeida Gomez, Ant\^onio J. Silva Neto, Jorge P. Zubelli
Categories: cs.LG
Comments: New version with applications in inverse problems
MSC-class: 49N45, 65K05, 90C53, 65J22, 94A08, 68T01, 68T20
\\ ( https://arxiv.org/abs/2108.06988 ,  1989kb)
------------------------------------------------------------------------------
\\
arXiv:2108.12988
replaced with revised version Mon, 5 Jun 2023 09:30:00 GMT   (9683kb,D)

Title: Learning Meta Representations for Agents in Multi-Agent Reinforcement
 Learning
Authors: Shenao Zhang, Li Shen, Lei Han, Li Shen
Categories: cs.LG cs.MA
Comments: Published at CoLLAs
\\ ( https://arxiv.org/abs/2108.12988 ,  9683kb)
------------------------------------------------------------------------------
\\
arXiv:2110.03922
replaced with revised version Fri, 2 Jun 2023 22:44:00 GMT   (916kb,D)

Title: The Eigenlearning Framework: A Conservation Law Perspective on Kernel
 Regression and Wide Neural Networks
Authors: James B. Simon, Madeline Dickens, Dhruva Karkada, Michael R. DeWeese
Categories: cs.LG stat.ML
Comments: 12 pages (main text) + 25 pages (refs + appendices). A previous
 version of this manuscript was entitled "Neural Tangent Kernel Eigenvalues
 Accurately Predict Generalization."
\\ ( https://arxiv.org/abs/2110.03922 ,  916kb)
------------------------------------------------------------------------------
\\
arXiv:2112.04571
replaced with revised version Mon, 5 Jun 2023 16:32:55 GMT   (853kb,D)

Title: Ambiguous Dynamic Treatment Regimes: A Reinforcement Learning Approach
Authors: Soroush Saghafian
Categories: cs.LG math.OC math.ST stat.ML stat.TH
\\ ( https://arxiv.org/abs/2112.04571 ,  853kb)
------------------------------------------------------------------------------
\\
arXiv:2202.03483
replaced with revised version Sun, 4 Jun 2023 22:03:42 GMT   (6738kb,D)

Title: MAML and ANIL Provably Learn Representations
Authors: Liam Collins, Aryan Mokhtari, Sewoong Oh and Sanjay Shakkottai
Categories: cs.LG
\\ ( https://arxiv.org/abs/2202.03483 ,  6738kb)
------------------------------------------------------------------------------
\\
arXiv:2202.12968
replaced with revised version Sat, 3 Jun 2023 21:27:27 GMT   (36536kb,D)

Title: Does Label Differential Privacy Prevent Label Inference Attacks?
Authors: Ruihan Wu, Jin Peng Zhou, Kilian Q. Weinberger and Chuan Guo
Categories: cs.LG
\\ ( https://arxiv.org/abs/2202.12968 ,  36536kb)
------------------------------------------------------------------------------
\\
arXiv:2202.13426
replaced with revised version Fri, 2 Jun 2023 18:20:36 GMT   (4449kb,D)

Title: Bayesian Active Learning for Discrete Latent Variable Models
Authors: Aditi Jha, Zoe C. Ashwood, Jonathan W. Pillow
Categories: cs.LG q-bio.NC stat.ML
Comments: 38 pages (including references and an appendix), 7 figures in main
 text
\\ ( https://arxiv.org/abs/2202.13426 ,  4449kb)
------------------------------------------------------------------------------
\\
arXiv:2203.02034
replaced with revised version Sun, 4 Jun 2023 22:42:00 GMT   (37545kb,D)

Title: Data-Efficient and Interpretable Tabular Anomaly Detection
Authors: Chun-Hao Chang, Jinsung Yoon, Sercan Arik, Madeleine Udell, Tomas
 Pfister
Categories: cs.LG
Comments: Accepted in 2023 KDD
\\ ( https://arxiv.org/abs/2203.02034 ,  37545kb)
------------------------------------------------------------------------------
\\
arXiv:2203.02928
replaced with revised version Mon, 5 Jun 2023 13:10:22 GMT   (6905kb,D)

Title: Evaluation of Interpretability Methods and Perturbation Artifacts in
 Deep Neural Networks
Authors: Lennart Brocki, Neo Christopher Chung
Categories: cs.LG cs.CV
Comments: 11 pages, 5 figures
\\ ( https://arxiv.org/abs/2203.02928 ,  6905kb)
------------------------------------------------------------------------------
\\
arXiv:2204.02241
replaced with revised version Sun, 4 Jun 2023 20:56:01 GMT   (5286kb,D)

Title: A Set Membership Approach to Discovering Feature Relevance and
 Explaining Neural Classifier Decisions
Authors: Stavros P. Adam, Aristidis C. Likas
Categories: cs.LG cs.AI
Comments: Revised description in Section 2 (The Proposed Approach) results
 unchanged
\\ ( https://arxiv.org/abs/2204.02241 ,  5286kb)
------------------------------------------------------------------------------
\\
arXiv:2205.09990
replaced with revised version Sat, 3 Jun 2023 16:48:41 GMT   (1324kb,D)

Title: Set-based Meta-Interpolation for Few-Task Meta-Learning
Authors: Seanie Lee, Bruno Andreis, Kenji Kawaguchi, Juho Lee, Sung Ju Hwang
Categories: cs.LG cs.AI
Comments: First two authors contributed equally. Name order decided by a coin
 toss
\\ ( https://arxiv.org/abs/2205.09990 ,  1324kb)
------------------------------------------------------------------------------
\\
arXiv:2205.14358
replaced with revised version Sun, 4 Jun 2023 23:50:08 GMT   (4057kb,D)

Title: Fair Labeled Clustering
Authors: Seyed A. Esmaeili, Sharmila Duppala, John P. Dickerson, Brian Brubach
Categories: cs.LG cs.AI cs.DS
Comments: Accepted to KDD 2022
\\ ( https://arxiv.org/abs/2205.14358 ,  4057kb)
------------------------------------------------------------------------------
\\
arXiv:2205.14846
replaced with revised version Sat, 3 Jun 2023 00:15:12 GMT   (222kb,D)

Title: Precise Learning Curves and Higher-Order Scaling Limits for Dot Product
 Kernel Regression
Authors: Lechao Xiao, Hong Hu, Theodor Misiakiewicz, Yue M. Lu, Jeffrey
 Pennington
Categories: cs.LG stat.ML
Comments: 32 pages; 4 + 3 figures
MSC-class: 68T07
\\ ( https://arxiv.org/abs/2205.14846 ,  222kb)
------------------------------------------------------------------------------
\\
arXiv:2205.15171
replaced with revised version Sun, 4 Jun 2023 14:40:45 GMT   (12604kb,D)

Title: Modular and On-demand Bias Mitigation with Attribute-Removal Subnetworks
Authors: Lukas Hauzenberger, Shahed Masoudian, Deepak Kumar, Markus Schedl,
 Navid Rekabsaz
Categories: cs.LG cs.CL cs.CY
Comments: Accepted in Findings of ACL 2023
\\ ( https://arxiv.org/abs/2205.15171 ,  12604kb)
------------------------------------------------------------------------------
\\
arXiv:2205.15752
replaced with revised version Sun, 4 Jun 2023 09:07:56 GMT   (3553kb,D)

Title: Hierarchies of Reward Machines
Authors: Daniel Furelos-Blanco, Mark Law, Anders Jonsson, Krysia Broda,
 Alessandra Russo
Categories: cs.LG cs.AI
Comments: Preprint accepted for publication to the 40th International
 Conference on Machine Learning (ICML-23)
\\ ( https://arxiv.org/abs/2205.15752 ,  3553kb)
------------------------------------------------------------------------------
\\
arXiv:2205.15953
replaced with revised version Sun, 4 Jun 2023 23:59:39 GMT   (1817kb,D)

Title: Timing is Everything: Learning to Act Selectively with Costly Actions
 and Budgetary Constraints
Authors: David Mguni, Aivar Sootla, Juliusz Ziomek, Oliver Slumbers, Zipeng
 Dai, Kun Shao, Jun Wang
Categories: cs.LG
\\ ( https://arxiv.org/abs/2205.15953 ,  1817kb)
------------------------------------------------------------------------------
\\
arXiv:2206.03787
replaced with revised version Mon, 5 Jun 2023 16:21:56 GMT   (3605kb,D)

Title: Action Noise in Off-Policy Deep Reinforcement Learning: Impact on
 Exploration and Performance
Authors: Jakob Hollenstein, Sayantan Auddy, Matteo Saveriano, Erwan Renaudo,
 Justus Piater
Categories: cs.LG cs.AI
Comments: Published in Transactions on Machine Learning Research (11/2022)
 https://openreview.net/forum?id=NljBlZ6hmG
\\ ( https://arxiv.org/abs/2206.03787 ,  3605kb)
------------------------------------------------------------------------------
\\
arXiv:2206.04740
replaced with revised version Mon, 5 Jun 2023 15:38:01 GMT   (90kb,D)

Title: XAudit : A Theoretical Look at Auditing with Explanations
Authors: Chhavi Yadav, Michal Moshkovitz, Kamalika Chaudhuri
Categories: cs.LG
\\ ( https://arxiv.org/abs/2206.04740 ,  90kb)
------------------------------------------------------------------------------
\\
arXiv:2206.05262
replaced with revised version Fri, 2 Jun 2023 21:45:43 GMT   (9819kb,D)

Title: Meta Optimal Transport
Authors: Brandon Amos, Samuel Cohen, Giulia Luise, Ievgen Redko
Categories: cs.LG cs.AI stat.ML
Comments: ICML 2023
\\ ( https://arxiv.org/abs/2206.05262 ,  9819kb)
------------------------------------------------------------------------------
\\
arXiv:2206.10032
replaced with revised version Sat, 3 Jun 2023 15:22:55 GMT   (179kb,D)

Title: Communication-Efficient Federated Learning With Data and Client
 Heterogeneity
Authors: Hossein Zakerinia, Shayan Talaei, Giorgi Nadiradze, Dan Alistarh
Categories: cs.LG
\\ ( https://arxiv.org/abs/2206.10032 ,  179kb)
------------------------------------------------------------------------------
\\
arXiv:2206.15269
replaced with revised version Mon, 5 Jun 2023 13:59:05 GMT   (11234kb,D)

Title: Deep Reinforcement Learning with Swin Transformers
Authors: Li Meng, Morten Goodwin, Anis Yazidi, Paal Engelstad
Categories: cs.LG
\\ ( https://arxiv.org/abs/2206.15269 ,  11234kb)
------------------------------------------------------------------------------
\\
arXiv:2207.11353
replaced with revised version Mon, 5 Jun 2023 01:29:22 GMT   (1470kb,D)

Title: A Supervised Tensor Dimension Reduction-Based Prognostics Model for
 Applications with Incomplete Imaging Data
Authors: Chengyu Zhou and Xiaolei Fang
Categories: cs.LG eess.IV stat.ML
Comments: 42 pages, 17 figures
\\ ( https://arxiv.org/abs/2207.11353 ,  1470kb)
------------------------------------------------------------------------------
\\
arXiv:2207.12062
replaced with revised version Sat, 3 Jun 2023 17:15:55 GMT   (2858kb,D)

Title: Adaptive Asynchronous Control Using Meta-learned Neural Ordinary
 Differential Equations
Authors: Achkan Salehi, Steffen R\"uhl, Stephane Doncieux
Categories: cs.LG cs.RO
Comments: 16 double column pages, 14 figures, 3 tables
\\ ( https://arxiv.org/abs/2207.12062 ,  2858kb)
------------------------------------------------------------------------------
\\
arXiv:2208.00755
replaced with revised version Mon, 5 Jun 2023 13:32:48 GMT   (8332kb,D)

Title: Mitigating Off-Policy Bias in Actor-Critic Methods with One-Step
 Q-learning: A Novel Correction Approach
Authors: Baturay Saglam, Dogan C. Cicek, Furkan B. Mutlu, Suleyman S. Kozat
Categories: cs.LG cs.AI
\\ ( https://arxiv.org/abs/2208.00755 ,  8332kb)
------------------------------------------------------------------------------
\\
arXiv:2209.10931
replaced with revised version Sat, 3 Jun 2023 08:39:23 GMT   (742kb,D)

Title: Robust Collaborative Learning with Linear Gradient Overhead
Authors: Sadegh Farhadkhani, Rachid Guerraoui, Nirupam Gupta, L\^e Nguy\^en
 Hoang, Rafael Pinot, John Stephan
Categories: cs.LG cs.DC
Comments: Accepted paper at ICML 2023
\\ ( https://arxiv.org/abs/2209.10931 ,  742kb)
------------------------------------------------------------------------------
\\
arXiv:2209.12753
replaced with revised version Sun, 4 Jun 2023 15:13:43 GMT   (7046kb,D)

Title: On Investigating the Conservative Property of Score-Based Generative
 Models
Authors: Chen-Hao Chao, Wei-Fang Sun, Bo-Wun Cheng, Chun-Yi Lee
Categories: cs.LG cs.CV
Comments: ICML 2023
\\ ( https://arxiv.org/abs/2209.12753 ,  7046kb)
------------------------------------------------------------------------------
\\
arXiv:2209.12782
replaced with revised version Sat, 3 Jun 2023 17:39:46 GMT   (12215kb,D)

Title: Learning GFlowNets from partial episodes for improved convergence and
 stability
Authors: Kanika Madan, Jarrid Rector-Brooks, Maksym Korablyov, Emmanuel Bengio,
 Moksh Jain, Andrei Nica, Tom Bosc, Yoshua Bengio, Nikolay Malkin
Categories: cs.LG stat.ML
Comments: ICML 2023
\\ ( https://arxiv.org/abs/2209.12782 ,  12215kb)
------------------------------------------------------------------------------
\\
arXiv:2210.01212
replaced with revised version Mon, 5 Jun 2023 15:32:06 GMT   (4931kb,D)

Title: \textit{spred}: Solving $L_1$ Penalty with SGD
Authors: Liu Ziyin, Zihao Wang
Categories: cs.LG stat.ML
Comments: ICML 2023, 16 pages, 10 figures, and 2 tables
\\ ( https://arxiv.org/abs/2210.01212 ,  4931kb)
------------------------------------------------------------------------------
\\
arXiv:2210.02097
replaced with revised version Sun, 4 Jun 2023 14:49:21 GMT   (571kb,D)

Title: Teaching Yourself: Graph Self-Distillation on Neighborhood for Node
 Classification
Authors: Lirong Wu, Jun Xia, Haitao Lin, Zhangyang Gao, Zicheng Liu, Guojiang
 Zhao, Stan Z. Li
Categories: cs.LG
\\ ( https://arxiv.org/abs/2210.02097 ,  571kb)
------------------------------------------------------------------------------
\\
arXiv:2210.03971
replaced with revised version Sun, 4 Jun 2023 15:09:14 GMT   (516kb,D)

Title: An Ordinal Latent Variable Model of Conflict Intensity
Authors: Niklas Stoehr, Lucas Torroba Hennigen, Josef Valvoda, Robert West,
 Ryan Cotterell, Aaron Schein
Categories: cs.LG stat.AP
Comments: Long Paper at ACL 2023
\\ ( https://arxiv.org/abs/2210.03971 ,  516kb)
------------------------------------------------------------------------------
\\
arXiv:2210.04166
replaced with revised version Sat, 3 Jun 2023 21:34:49 GMT   (144kb)

Title: Test-time Recalibration of Conformal Predictors Under Distribution Shift
 Based on Unlabeled Examples
Authors: Fatih Furkan Yilmaz and Reinhard Heckel
Categories: cs.LG stat.ML
\\ ( https://arxiv.org/abs/2210.04166 ,  144kb)
------------------------------------------------------------------------------
\\
arXiv:2210.05801
replaced with revised version Mon, 5 Jun 2023 14:52:42 GMT   (389kb,D)

Title: Linkless Link Prediction via Relational Distillation
Authors: Zhichun Guo, William Shiao, Shichang Zhang, Yozen Liu, Nitesh V.
 Chawla, Neil Shah, Tong Zhao
Categories: cs.LG
\\ ( https://arxiv.org/abs/2210.05801 ,  389kb)
------------------------------------------------------------------------------
\\
arXiv:2210.06274
replaced with revised version Mon, 5 Jun 2023 17:35:53 GMT   (23065kb,D)

Title: Centralized Training with Hybrid Execution in Multi-Agent Reinforcement
 Learning
Authors: Pedro P. Santos, Diogo S. Carvalho, Miguel Vasco, Alberto Sardinha,
 Pedro A. Santos, Ana Paiva, Francisco S. Melo
Categories: cs.LG
\\ ( https://arxiv.org/abs/2210.06274 ,  23065kb)
------------------------------------------------------------------------------
\\
arXiv:2210.08781
replaced with revised version Sat, 3 Jun 2023 21:49:35 GMT   (2063kb,D)

Title: Stochastic Differentially Private and Fair Learning
Authors: Andrew Lowy, Devansh Gupta, Meisam Razaviyayn
Categories: cs.LG cs.CR
Comments: ICLR 2023
\\ ( https://arxiv.org/abs/2210.08781 ,  2063kb)
------------------------------------------------------------------------------
\\
arXiv:2210.10782
replaced with revised version Mon, 5 Jun 2023 15:01:43 GMT   (2307kb)

Title: Topology Optimization via Machine Learning and Deep Learning: A Review
Authors: Seungyeon Shin, Dongju Shin, Namwoo Kang
Categories: cs.LG
\\ ( https://arxiv.org/abs/2210.10782 ,  2307kb)
------------------------------------------------------------------------------
\\
arXiv:2210.14396
replaced with revised version Sat, 3 Jun 2023 15:00:59 GMT   (1016kb,D)

Title: FeDXL: Provable Federated Learning for Deep X-Risk Optimization
Authors: Zhishuai Guo, Rong Jin, Jiebo Luo, Tianbao Yang
Categories: cs.LG cs.DC math.OC stat.ML
Comments: International Conference on Machine Learning, 2023
\\ ( https://arxiv.org/abs/2210.14396 ,  1016kb)
------------------------------------------------------------------------------
\\
arXiv:2211.01528
replaced with revised version Mon, 5 Jun 2023 04:40:54 GMT   (532kb,D)

Title: Fair and Optimal Classification via Post-Processing
Authors: Ruicheng Xian, Lang Yin, Han Zhao
Categories: cs.LG cs.AI cs.CY stat.ML
Comments: ICML 2023. Code is at https://github.com/rxian/fair-classification.
 Comparison to v2: corrected proof of Theorem 4.4
\\ ( https://arxiv.org/abs/2211.01528 ,  532kb)
------------------------------------------------------------------------------
\\
arXiv:2211.01842
replaced with revised version Mon, 5 Jun 2023 12:22:19 GMT   (2504kb,D)

Title: Construction of Hierarchical Neural Architecture Search Spaces based on
 Context-free Grammars
Authors: Simon Schrodi, Danny Stoll, Binxin Ru, Rhea Sukthanker, Thomas Brox,
 Frank Hutter
Categories: cs.LG cs.AI cs.CV stat.ML
\\ ( https://arxiv.org/abs/2211.01842 ,  2504kb)
------------------------------------------------------------------------------
\\
arXiv:2211.04088
replaced with revised version Fri, 2 Jun 2023 20:26:54 GMT   (1916kb,D)

Title: A Decentralized Alternating Gradient Method for Communication-Efficient
 Bilevel Programming
Authors: Parvin Nazari, Ahmad Mousavi, Davoud Ataee Tarzanagh, and George
 Michailidis
Categories: cs.LG cs.DC math.OC
\\ ( https://arxiv.org/abs/2211.04088 ,  1916kb)
------------------------------------------------------------------------------
\\
arXiv:2211.05551
replaced with revised version Mon, 5 Jun 2023 09:48:33 GMT   (670kb,D)

Title: Causal Counterfactuals for Improving the Robustness of Reinforcement
 Learning
Authors: Tom He, Jasmina Gajcin and Ivana Dusparic
Categories: cs.LG cs.AI cs.RO
Comments: Accepted to ARMS-2023 (ARMS-2023: AAMAS 2023 Workshop on Autonomous
 Robots and Multirobot Systems)
\\ ( https://arxiv.org/abs/2211.05551 ,  670kb)
------------------------------------------------------------------------------
\\
arXiv:2211.10773
replaced with revised version Fri, 2 Jun 2023 20:13:01 GMT   (500kb,D)

Title: A Two-Stage Active Learning Algorithm for $k$-Nearest Neighbors
Authors: Nick Rittler and Kamalika Chaudhuri
Categories: cs.LG
\\ ( https://arxiv.org/abs/2211.10773 ,  500kb)
------------------------------------------------------------------------------
\\
arXiv:2211.11965
replaced with revised version Mon, 5 Jun 2023 02:57:41 GMT   (2104kb)

Title: Predicting adverse outcomes following catheter ablation treatment for
 atrial fibrillation
Authors: Juan C. Quiroz, David Brieger, Louisa Jorm, Raymond W Sy, Benjumin
 Hsu, Blanca Gallego
Categories: cs.LG q-bio.QM stat.OT
Comments: Under journal review; updated in response to reviewer comments
ACM-class: J.3; G.3
\\ ( https://arxiv.org/abs/2211.11965 ,  2104kb)
------------------------------------------------------------------------------
\\
arXiv:2211.12507
replaced with revised version Mon, 5 Jun 2023 13:22:12 GMT   (1048kb,D)

Title: OpenFE: Automated Feature Generation with Expert-level Performance
Authors: Tianping Zhang, Zheyu Zhang, Zhiyuan Fan, Haoyan Luo, Fengyuan Liu,
 Qian Liu, Wei Cao, Jian Li
Categories: cs.LG
Comments: 22 pages, 3 figures, accepted by ICML2023
\\ ( https://arxiv.org/abs/2211.12507 ,  1048kb)
------------------------------------------------------------------------------
\\
arXiv:2212.09034
replaced with revised version Mon, 5 Jun 2023 12:02:49 GMT   (1373kb,D)

Title: Graph Neural Networks are Inherently Good Generalizers: Insights by
 Bridging GNNs and MLPs
Authors: Chenxiao Yang, Qitian Wu, Jiahua Wang, Junchi Yan
Categories: cs.LG
Comments: Accepted to ICLR 2023. Codes in https://github.com/chr26195/PMLP
\\ ( https://arxiv.org/abs/2212.09034 ,  1373kb)
------------------------------------------------------------------------------
\\
arXiv:2301.08203
replaced with revised version Sun, 4 Jun 2023 19:54:21 GMT   (4663kb,D)

Title: An SDE for Modeling SAM: Theory and Insights
Authors: Enea Monzio Compagnoni, Luca Biggio, Antonio Orvieto, Frank Norbert
 Proske, Hans Kersting, Aurelien Lucchi
Categories: cs.LG math.OC
Comments: Accepted at ICML 2023 (Poster)
\\ ( https://arxiv.org/abs/2301.08203 ,  4663kb)
------------------------------------------------------------------------------
\\
arXiv:2301.09308
replaced with revised version Sat, 3 Jun 2023 20:14:57 GMT   (739kb,D)

Title: On the Expressive Power of Geometric Graph Neural Networks
Authors: Chaitanya K. Joshi, Cristian Bodnar, Simon V. Mathis, Taco Cohen,
 Pietro Li\`o
Categories: cs.LG math.GR stat.ML
Comments: ICML 2023
\\ ( https://arxiv.org/abs/2301.09308 ,  739kb)
------------------------------------------------------------------------------
\\
arXiv:2301.10886
replaced with revised version Sat, 3 Jun 2023 10:01:32 GMT   (1355kb,D)

Title: Automatic Intrinsic Reward Shaping for Exploration in Deep Reinforcement
 Learning
Authors: Mingqi Yuan, Bo Li, Xin Jin, Wenjun Zeng
Categories: cs.LG cs.AI
Comments: 24 pages, 16 figures
\\ ( https://arxiv.org/abs/2301.10886 ,  1355kb)
------------------------------------------------------------------------------
\\
arXiv:2301.11167
replaced with revised version Sat, 3 Jun 2023 18:34:05 GMT   (33550kb,D)

Title: Neural Inverse Operators for Solving PDE Inverse Problems
Authors: Roberto Molinaro, Yunan Yang, Bj\"orn Engquist, Siddhartha Mishra
Categories: cs.LG math-ph math.AP math.MP
\\ ( https://arxiv.org/abs/2301.11167 ,  33550kb)
------------------------------------------------------------------------------
\\
arXiv:2301.11342
replaced with revised version Mon, 5 Jun 2023 14:13:40 GMT   (468kb,D)

Title: A Robust Optimisation Perspective on Counterexample-Guided Repair of
 Neural Networks
Authors: David Boetius, Stefan Leue, Tobias Sutter
Categories: cs.LG math.OC
Comments: Accepted at ICML 2023. 9 pages + 13 pages appendix, 8 figures
\\ ( https://arxiv.org/abs/2301.11342 ,  468kb)
------------------------------------------------------------------------------
\\
arXiv:2301.11989
replaced with revised version Sun, 4 Jun 2023 19:13:04 GMT   (1211kb,D)

Title: Practical Differentially Private Hyperparameter Tuning with Subsampling
Authors: Antti Koskela and Tejas Kulkarni
Categories: cs.LG cs.CR
Comments: 26 pages, 6 figures
\\ ( https://arxiv.org/abs/2301.11989 ,  1211kb)
------------------------------------------------------------------------------
\\
arXiv:2301.11990
replaced with revised version Sun, 4 Jun 2023 15:01:39 GMT   (1233kb,D)

Title: Alignment with human representations supports robust few-shot learning
Authors: Ilia Sucholutsky, Thomas L. Griffiths
Categories: cs.LG cs.AI cs.CV cs.HC stat.ML
\\ ( https://arxiv.org/abs/2301.11990 ,  1233kb)
------------------------------------------------------------------------------
\\
arXiv:2301.13195
replaced with revised version Sat, 3 Jun 2023 06:19:23 GMT   (410kb,D)

Title: Adaptive Computation with Elastic Input Sequence
Authors: Fuzhao Xue, Valerii Likhosherstov, Anurag Arnab, Neil Houlsby, Mostafa
 Dehghani, Yang You
Categories: cs.LG cs.AI cs.CV
\\ ( https://arxiv.org/abs/2301.13195 ,  410kb)
------------------------------------------------------------------------------
\\
arXiv:2301.13501
replaced with revised version Mon, 5 Jun 2023 07:37:19 GMT   (2149kb,D)

Title: Auxiliary Learning as an Asymmetric Bargaining Game
Authors: Aviv Shamsian, Aviv Navon, Neta Glazer, Kenji Kawaguchi, Gal Chechik,
 Ethan Fetaya
Categories: cs.LG
Comments: ICML 2023
\\ ( https://arxiv.org/abs/2301.13501 ,  2149kb)
------------------------------------------------------------------------------
\\
arXiv:2302.00236
replaced with revised version Sun, 4 Jun 2023 00:13:53 GMT   (2630kb,D)

Title: Generative Adversarial Symmetry Discovery
Authors: Jianke Yang, Robin Walters, Nima Dehmamy, Rose Yu
Categories: cs.LG
\\ ( https://arxiv.org/abs/2302.00236 ,  2630kb)
------------------------------------------------------------------------------
\\
arXiv:2302.01425
replaced with revised version Sun, 4 Jun 2023 07:58:10 GMT   (1682kb,D)

Title: Fast, Differentiable and Sparse Top-k: a Convex Analysis Perspective
Authors: Michael E. Sander, Joan Puigcerver, Josip Djolonga, Gabriel Peyr\'e
 and Mathieu Blondel
Categories: cs.LG stat.ML
Comments: ICML 2023 18 pages
\\ ( https://arxiv.org/abs/2302.01425 ,  1682kb)
------------------------------------------------------------------------------
\\
arXiv:2302.01677
replaced with revised version Mon, 5 Jun 2023 08:35:02 GMT   (26707kb,D)

Title: Revisiting Personalized Federated Learning: Robustness Against Backdoor
 Attacks
Authors: Zeyu Qin, Liuyi Yao, Daoyuan Chen, Yaliang Li, Bolin Ding, Minhao
 Cheng
Categories: cs.LG cs.CR
Comments: KDD 2023
\\ ( https://arxiv.org/abs/2302.01677 ,  26707kb)
------------------------------------------------------------------------------
\\
arXiv:2302.02904
replaced with revised version Mon, 5 Jun 2023 10:01:48 GMT   (375kb,D)

Title: Rethinking Gauss-Newton for learning over-parameterized models
Authors: Michael Arbel and Romain Menegaux and Pierre Wolinski
Categories: cs.LG math.OC
\\ ( https://arxiv.org/abs/2302.02904 ,  375kb)
------------------------------------------------------------------------------
\\
arXiv:2302.03020
replaced with revised version Mon, 5 Jun 2023 13:55:19 GMT   (24517kb,D)

Title: RLSbench: Domain Adaptation Under Relaxed Label Shift
Authors: Saurabh Garg, Nick Erickson, James Sharpnack, Alex Smola, Sivaraman
 Balakrishnan, Zachary C. Lipton
Categories: cs.LG cs.CV stat.ML
Comments: Accepted at ICML 2023. Paper website:
 https://sites.google.com/view/rlsbench/
\\ ( https://arxiv.org/abs/2302.03020 ,  24517kb)
------------------------------------------------------------------------------
\\
arXiv:2302.03884
replaced with revised version Sat, 3 Jun 2023 12:39:11 GMT   (1424kb,D)

Title: DIFF2: Differential Private Optimization via Gradient Differences for
 Nonconvex Distributed Learning
Authors: Tomoya Murata and Taiji Suzuki
Categories: cs.LG cs.CR math.OC stat.ML
Comments: 26 pages
\\ ( https://arxiv.org/abs/2302.03884 ,  1424kb)
------------------------------------------------------------------------------
\\
arXiv:2302.03921
replaced with revised version Sat, 3 Jun 2023 23:38:06 GMT   (1724kb,D)

Title: Predictable MDP Abstraction for Unsupervised Model-Based RL
Authors: Seohong Park, Sergey Levine
Categories: cs.LG cs.AI
Comments: ICML 2023
\\ ( https://arxiv.org/abs/2302.03921 ,  1724kb)
------------------------------------------------------------------------------
\\
arXiv:2302.06079
replaced with revised version Sun, 4 Jun 2023 12:58:35 GMT   (360kb,D)

Title: Byzantine-Robust Learning on Heterogeneous Data via Gradient Splitting
Authors: Yuchen Liu, Chen Chen, Lingjuan Lyu, Fangzhao Wu, Sai Wu, Gang Chen
Categories: cs.LG cs.AI cs.CR
\\ ( https://arxiv.org/abs/2302.06079 ,  360kb)
------------------------------------------------------------------------------
\\
arXiv:2302.06576
replaced with revised version Sat, 3 Jun 2023 18:02:08 GMT   (8592kb,D)

Title: GFlowNet-EM for learning compositional latent variable models
Authors: Edward J. Hu, Nikolay Malkin, Moksh Jain, Katie Everett, Alexandros
 Graikos, Yoshua Bengio
Categories: cs.LG stat.ML
Comments: ICML 2023; code: https://github.com/GFNOrg/GFlowNet-EM
\\ ( https://arxiv.org/abs/2302.06576 ,  8592kb)
------------------------------------------------------------------------------
\\
arXiv:2302.06599
replaced with revised version Mon, 5 Jun 2023 17:58:24 GMT   (1849kb,D)

Title: FilFL: Client Filtering for Optimized Client Participation in Federated
 Learning
Authors: Fares Fourati, Salma Kharrat, Vaneet Aggarwal, Mohamed-Slim Alouini,
 Marco Canini
Categories: cs.LG cs.AI cs.DC
\\ ( https://arxiv.org/abs/2302.06599 ,  1849kb)
------------------------------------------------------------------------------
\\
arXiv:2302.09048
replaced with revised version Mon, 5 Jun 2023 15:26:26 GMT   (1609kb,D)

Title: MiDi: Mixed Graph and 3D Denoising Diffusion for Molecule Generation
Authors: Clement Vignac, Nagham Osman, Laura Toni, Pascal Frossard
Categories: cs.LG
Comments: 22 pages. Under review
\\ ( https://arxiv.org/abs/2302.09048 ,  1609kb)
------------------------------------------------------------------------------
\\
arXiv:2302.09339
replaced with revised version Sun, 4 Jun 2023 13:35:45 GMT   (8046kb,D)

Title: Efficient Exploration via Epistemic-Risk-Seeking Policy Optimization
Authors: Brendan O'Donoghue
Categories: cs.LG cs.AI
\\ ( https://arxiv.org/abs/2302.09339 ,  8046kb)
------------------------------------------------------------------------------
\\
arXiv:2302.09826
replaced with revised version Mon, 5 Jun 2023 07:08:21 GMT   (63kb,D)

Title: On the Expressivity of Persistent Homology in Graph Learning
Authors: Bastian Rieck
Categories: cs.LG math.AT stat.ML
MSC-class: 55N31 (Primary) 62R40, 68T09 (Secondary)
\\ ( https://arxiv.org/abs/2302.09826 ,  63kb)
------------------------------------------------------------------------------
\\
arXiv:2302.11552
replaced with revised version Mon, 5 Jun 2023 15:40:57 GMT   (20516kb,D)

Title: Reduce, Reuse, Recycle: Compositional Generation with Energy-Based
 Diffusion Models and MCMC
Authors: Yilun Du, Conor Durkan, Robin Strudel, Joshua B. Tenenbaum, Sander
 Dieleman, Rob Fergus, Jascha Sohl-Dickstein, Arnaud Doucet, Will Grathwohl
Categories: cs.LG cs.AI cs.CV stat.ML
Comments: ICML 2023, Project Webpage:
 https://energy-based-model.github.io/reduce-reuse-recycle/
\\ ( https://arxiv.org/abs/2302.11552 ,  20516kb)
------------------------------------------------------------------------------
\\
arXiv:2302.11556
replaced with revised version Sun, 4 Jun 2023 08:14:37 GMT   (1457kb,D)

Title: Equivariant Polynomials for Graph Neural Networks
Authors: Omri Puny, Derek Lim, Bobak T. Kiani, Haggai Maron, Yaron Lipman
Categories: cs.LG cs.AI
\\ ( https://arxiv.org/abs/2302.11556 ,  1457kb)
------------------------------------------------------------------------------
\\
arXiv:2302.13335
replaced with revised version Mon, 5 Jun 2023 04:39:08 GMT   (7944kb,D)

Title: Diffusion Model-Augmented Behavioral Cloning
Authors: Hsiang-Chun Wang, Shang-Fu Chen, Ming-Hao Hsu, Chun-Mao Lai, Shao-Hua
 Sun
Categories: cs.LG cs.AI cs.RO
\\ ( https://arxiv.org/abs/2302.13335 ,  7944kb)
------------------------------------------------------------------------------
\\
arXiv:2302.13875
replaced with revised version Mon, 5 Jun 2023 10:39:41 GMT   (24362kb,D)

Title: Evaluating Robustness and Uncertainty of Graph Models Under Structural
 Distributional Shifts
Authors: Gleb Bazhenov, Denis Kuznedelev, Andrey Malinin, Artem Babenko,
 Liudmila Prokhorenkova
Categories: cs.LG stat.ML
\\ ( https://arxiv.org/abs/2302.13875 ,  24362kb)
------------------------------------------------------------------------------
\\
arXiv:2302.14260
replaced with revised version Mon, 5 Jun 2023 01:40:49 GMT   (1466kb,D)

Title: A Closer Look at the Intervention Procedure of Concept Bottleneck Models
Authors: Sungbin Shin, Yohan Jo, Sungsoo Ahn, Namhoon Lee
Categories: cs.LG
Comments: ICML 2023
\\ ( https://arxiv.org/abs/2302.14260 ,  1466kb)
------------------------------------------------------------------------------
\\
arXiv:2302.14471
replaced with revised version Mon, 5 Jun 2023 11:59:36 GMT   (668kb)

Title: Safe Peeling for L0-Regularized Least-Squares with supplementary
 material
Authors: Th\'eo Guyard, Gilles Monnoyer, Cl\'ement Elvira, C\'edric Herzet
Categories: cs.LG math.OC stat.ML
\\ ( https://arxiv.org/abs/2302.14471 ,  668kb)
------------------------------------------------------------------------------
\\
arXiv:2303.00883
replaced with revised version Fri, 2 Jun 2023 23:35:16 GMT   (609kb,D)

Title: Variance-reduced Clipping for Non-convex Optimization
Authors: Amirhossein Reisizadeh, Haochuan Li, Subhro Das, Ali Jadbabaie
Categories: cs.LG math.OC stat.ML
\\ ( https://arxiv.org/abs/2303.00883 ,  609kb)
------------------------------------------------------------------------------
\\
arXiv:2303.03918
replaced with revised version Mon, 5 Jun 2023 07:40:27 GMT   (10532kb,D)

Title: Error convergence and engineering-guided hyperparameter search of PINNs:
 towards optimized I-FENN performance
Authors: Panos Pantidis, Habiba Eldababy, Christopher Miguel Tagle, Mostafa E.
 Mobasher
Categories: cs.LG
\\ ( https://arxiv.org/abs/2303.03918 ,  10532kb)
------------------------------------------------------------------------------
\\
arXiv:2303.04630
replaced with revised version Fri, 2 Jun 2023 22:25:26 GMT   (15199kb)

Title: Contribution of clinical course to outcome after traumatic brain injury:
 mining patient trajectories from European intensive care unit data
Authors: Shubhayu Bhattacharyay, Pier Francesco Caruso, Cecilia {\AA}kerlund,
 Lindsay Wilson, Robert D Stevens, David K Menon, Ewout W Steyerberg, David W
 Nelson, Ari Ercole, the CENTER-TBI investigators/participants
Categories: cs.LG q-bio.QM stat.AP
\\ ( https://arxiv.org/abs/2303.04630 ,  15199kb)
------------------------------------------------------------------------------
\\
arXiv:2303.05911
replaced with revised version Sun, 4 Jun 2023 15:57:19 GMT   (5756kb,D)

Title: Lifelong Machine Learning Potentials
Authors: Marco Eckhoff and Markus Reiher
Categories: cs.LG cond-mat.dis-nn physics.chem-ph physics.comp-ph
Comments: 20 pages, 6 figures
\\ ( https://arxiv.org/abs/2303.05911 ,  5756kb)
------------------------------------------------------------------------------
\\
arXiv:2303.07925
replaced with revised version Mon, 5 Jun 2023 15:32:48 GMT   (122kb,D)

Title: Robust incremental learning pipelines for temporal tabular datasets with
 distribution shifts
Authors: Thomas Wong, Mauricio Barahona
Categories: cs.LG q-fin.MF
\\ ( https://arxiv.org/abs/2303.07925 ,  122kb)
------------------------------------------------------------------------------
\\
arXiv:2303.10472
replaced with revised version Sun, 4 Jun 2023 00:26:01 GMT   (1915kb)

Title: Practical and Matching Gradient Variance Bounds for Black-Box
 Variational Bayesian Inference
Authors: Kyurae Kim, Kaiwen Wu, Jisu Oh, Jacob R. Gardner
Categories: cs.LG math.OC stat.CO stat.ML
Comments: Accepted to ICML'23 for live oral presentation
\\ ( https://arxiv.org/abs/2303.10472 ,  1915kb)
------------------------------------------------------------------------------
\\
arXiv:2303.11453
replaced with revised version Sun, 4 Jun 2023 09:19:32 GMT   (713kb,D)

Title: Greedy Pruning with Group Lasso Provably Generalizes for Matrix Sensing
Authors: Nived Rajaraman, Devvrit, Aryan Mokhtari, Kannan Ramchandran
Categories: cs.LG stat.ML
Comments: 49 pages, 2 figures
\\ ( https://arxiv.org/abs/2303.11453 ,  713kb)
------------------------------------------------------------------------------
\\
arXiv:2303.14633
replaced with revised version Mon, 5 Jun 2023 03:31:01 GMT   (1052kb,D)

Title: An Evaluation of Memory Optimization Methods for Training Neural
 Networks
Authors: Xiaoxuan Liu, Siddharth Jha, Alvin Cheung
Categories: cs.LG cs.PF
\\ ( https://arxiv.org/abs/2303.14633 ,  1052kb)
------------------------------------------------------------------------------
\\
arXiv:2303.15821
replaced with revised version Mon, 5 Jun 2023 12:50:32 GMT   (1136kb,D)

Title: Scaling Multi-Objective Security Games Provably via Space Discretization
 Based Evolutionary Search
Authors: Yu-Peng Wu, Hong Qian, Rong-Jun Qin, Yi Chen, Aimin Zhou
Categories: cs.LG cs.GT cs.NE
\\ ( https://arxiv.org/abs/2303.15821 ,  1136kb)
------------------------------------------------------------------------------
\\
arXiv:2303.16132
replaced with revised version Mon, 5 Jun 2023 16:42:44 GMT   (945kb,D)

Title: Transformer and Snowball Graph Convolution Learning for Brain functional
 network Classification
Authors: Jinlong Hu, Yangmin Huang, Shoubin Dong
Categories: cs.LG cs.AI
Comments: Prepared for submitting to HBP
\\ ( https://arxiv.org/abs/2303.16132 ,  945kb)
------------------------------------------------------------------------------
\\
arXiv:2303.17727
replaced with revised version Sat, 3 Jun 2023 20:31:20 GMT   (2818kb,D)

Title: BOLT: An Automated Deep Learning Framework for Training and Deploying
 Large-Scale Search and Recommendation Models on Commodity CPU Hardware
Authors: Nicholas Meisburger, Vihan Lakshman, Benito Geordie, Joshua Engels,
 David Torres Ramos, Pratik Pranav, Benjamin Coleman, Benjamin Meisburger,
 Shubh Gupta, Yashwanth Adunukota, Tharun Medini, Anshumali Shrivastava
Categories: cs.LG
Comments: 6 pages, 5 tables, 3 figures
\\ ( https://arxiv.org/abs/2303.17727 ,  2818kb)
------------------------------------------------------------------------------
\\
arXiv:2304.01203
replaced with revised version Fri, 2 Jun 2023 21:29:21 GMT   (6358kb,D)

Title: Optimal Goal-Reaching Reinforcement Learning via Quasimetric Learning
Authors: Tongzhou Wang, Antonio Torralba, Phillip Isola, Amy Zhang
Categories: cs.LG
Comments: Project Page: https://www.tongzhouwang.info/quasimetric_rl/
Journal-ref: International Conference on Machine Learning (ICML) 2023
\\ ( https://arxiv.org/abs/2304.01203 ,  6358kb)
------------------------------------------------------------------------------
\\
arXiv:2304.02396
replaced with revised version Mon, 5 Jun 2023 06:00:17 GMT   (21450kb,D)

Title: AutoRL Hyperparameter Landscapes
Authors: Aditya Mohan, Carolin Benjamins, Konrad Wienecke, Alexander Dockhorn,
 Marius Lindauer
Categories: cs.LG cs.AI cs.RO cs.SY eess.SY
Comments: Version updated after acceptance
\\ ( https://arxiv.org/abs/2304.02396 ,  21450kb)
------------------------------------------------------------------------------
\\
arXiv:2304.04033
replaced with revised version Mon, 5 Jun 2023 15:23:05 GMT   (472kb,D)

Title: Exploring the Connection between Robust and Generative Models
Authors: Senad Beadini and Iacopo Masi
Categories: cs.LG cs.CR cs.CV
Comments: Italian Conference on AI - AI per Cybersecurity, 6 pages, 6 figures
\\ ( https://arxiv.org/abs/2304.04033 ,  472kb)
------------------------------------------------------------------------------
\\
arXiv:2304.06129
replaced with revised version Mon, 5 Jun 2023 17:33:43 GMT   (13501kb,D)

Title: Label-Free Concept Bottleneck Models
Authors: Tuomas Oikarinen, Subhro Das, Lam M. Nguyen, Tsui-Wei Weng
Categories: cs.LG cs.CV
Comments: Published at ICLR 2023. New v2(5 June 2023): added crowdsourced human
 study in Appendix B
\\ ( https://arxiv.org/abs/2304.06129 ,  13501kb)
------------------------------------------------------------------------------
\\
arXiv:2304.08996
replaced with revised version Sun, 4 Jun 2023 11:53:28 GMT   (905kb)

Title: Joint Age-based Client Selection and Resource Allocation for
 Communication-Efficient Federated Learning over NOMA Networks
Authors: Bibo Wu, Fang Fang, and Xianbin Wang
Categories: cs.LG cs.NI
\\ ( https://arxiv.org/abs/2304.08996 ,  905kb)
------------------------------------------------------------------------------
\\
arXiv:2305.00097
replaced with revised version Sat, 3 Jun 2023 00:33:21 GMT   (638kb,D)

Title: NNSplitter: An Active Defense Solution for DNN Model via Automated
 Weight Obfuscation
Authors: Tong Zhou, Yukui Luo, Shaolei Ren, Xiaolin Xu
Categories: cs.LG cs.CR
Comments: To appear at ICML 2023
\\ ( https://arxiv.org/abs/2305.00097 ,  638kb)
------------------------------------------------------------------------------
\\
arXiv:2305.00650
replaced with revised version Mon, 5 Jun 2023 09:06:38 GMT   (22399kb,D)

Title: Discover and Cure: Concept-aware Mitigation of Spurious Correlation
Authors: Shirley Wu, Mert Yuksekgonul, Linjun Zhang, James Zou
Categories: cs.LG cs.CV eess.IV
Comments: ICML 2023
\\ ( https://arxiv.org/abs/2305.00650 ,  22399kb)
------------------------------------------------------------------------------
\\
arXiv:2305.00664
replaced with revised version Fri, 2 Jun 2023 21:35:22 GMT   (516kb,D)

Title: Dynamic Transfer Learning across Graphs
Authors: Haohui Wang, Yuzhen Mao, Jianhui Sun, Si Zhang, Yonghui Fan, Dawei
 Zhou
Categories: cs.LG
\\ ( https://arxiv.org/abs/2305.00664 ,  516kb)
------------------------------------------------------------------------------
\\
arXiv:2305.01034
replaced with revised version Fri, 2 Jun 2023 23:03:46 GMT   (991kb,D)

Title: Model-agnostic Measure of Generalization Difficulty
Authors: Akhilan Boopathy, Kevin Liu, Jaedong Hwang, Shu Ge, Asaad
 Mohammedsaleh, Ila Fiete
Categories: cs.LG cs.AI stat.ML
Comments: Published at ICML 2023, 28 pages, 6 figures
\\ ( https://arxiv.org/abs/2305.01034 ,  991kb)
------------------------------------------------------------------------------
\\
arXiv:2305.01610
replaced with revised version Fri, 2 Jun 2023 21:52:17 GMT   (8030kb,D)

Title: Finding Neurons in a Haystack: Case Studies with Sparse Probing
Authors: Wes Gurnee, Neel Nanda, Matthew Pauly, Katherine Harvey, Dmitrii
 Troitskii, Dimitris Bertsimas
Categories: cs.LG cs.AI
\\ ( https://arxiv.org/abs/2305.01610 ,  8030kb)
------------------------------------------------------------------------------
\\
arXiv:2305.03063
replaced with revised version Fri, 2 Jun 2023 20:42:30 GMT   (3606kb,D)

Title: Neuro-symbolic model for cantilever beams damage detection
Authors: Darian Onchis and Gilbert-Rainer Gillich and Eduard Hogea and Cristian
 Tufisi
Categories: cs.LG cs.AI
\\ ( https://arxiv.org/abs/2305.03063 ,  3606kb)
------------------------------------------------------------------------------
\\
arXiv:2305.04392
replaced with revised version Mon, 5 Jun 2023 02:40:42 GMT   (4122kb,D)

Title: Disentangled Multi-Fidelity Deep Bayesian Active Learning
Authors: Dongxia Wu, Ruijia Niu, Matteo Chinazzi, Yian Ma, Rose Yu
Categories: cs.LG
\\ ( https://arxiv.org/abs/2305.04392 ,  4122kb)
------------------------------------------------------------------------------
\\
arXiv:2305.04492
replaced with revised version Mon, 5 Jun 2023 02:56:28 GMT   (7177kb,D)

Title: MGR: Multi-generator Based Rationalization
Authors: Wei Liu, Haozhao Wang, Jun Wang, Ruixuan Li, Xinyang Li, Yuankai
 Zhang, Yang Qiu
Categories: cs.LG cs.CL
Comments: Accepted as a main conference paper of ACL 2023. arXiv admin note:
 text overlap with arXiv:2209.08285
\\ ( https://arxiv.org/abs/2305.04492 ,  7177kb)
------------------------------------------------------------------------------
\\
arXiv:2305.04837
replaced with revised version Mon, 5 Jun 2023 13:12:04 GMT   (558kb)

Title: Scalable Optimal Margin Distribution Machine
Authors: Yilin Wang, Nan Cao, Teng Zhang, Xuanhua Shi and Hai Jin
Categories: cs.LG
\\ ( https://arxiv.org/abs/2305.04837 ,  558kb)
------------------------------------------------------------------------------
\\
arXiv:2305.06167
replaced with revised version Sat, 3 Jun 2023 19:26:26 GMT   (20252kb,D)

Title: K-SpecPart: Supervised embedding algorithms and cut overlay for improved
 hypergraph partitioning
Authors: Ismail Bustany, Andrew B. Kahng, Ioannis Koutis, Bodhisatta Pramanik
 and Zhiang Wang
Categories: cs.LG
\\ ( https://arxiv.org/abs/2305.06167 ,  20252kb)
------------------------------------------------------------------------------
\\
arXiv:2305.06395
replaced with revised version Mon, 5 Jun 2023 11:50:38 GMT   (2788kb,D)

Title: ACTC: Active Threshold Calibration for Cold-Start Knowledge Graph
 Completion
Authors: Anastasiia Sedova, Benjamin Roth
Categories: cs.LG cs.AI
Comments: Accepted to ACL'23
\\ ( https://arxiv.org/abs/2305.06395 ,  2788kb)
------------------------------------------------------------------------------
\\
arXiv:2305.07247
replaced with revised version Sat, 3 Jun 2023 16:39:43 GMT   (5066kb,D)

Title: Provably Convergent Schr\"odinger Bridge with Applications to
 Probabilistic Time Series Imputation
Authors: Yu Chen and Wei Deng and Shikai Fang and Fengpei Li and Nicole
 Tianjiao Yang and Yikai Zhang and Kashif Rasul and Shandian Zhe and Anderson
 Schneider and Yuriy Nevmyvaka
Categories: cs.LG
Comments: Accepted by ICML 2023
\\ ( https://arxiv.org/abs/2305.07247 ,  5066kb)
------------------------------------------------------------------------------
\\
arXiv:2305.09938
replaced with revised version Fri, 2 Jun 2023 21:37:09 GMT   (313kb,D)

Title: Characterizing Long-Tail Categories on Graphs
Authors: Haohui Wang, Baoyu Jing, Kaize Ding, Yada Zhu, Liqing Zhang, Dawei
 Zhou
Categories: cs.LG cs.SI
\\ ( https://arxiv.org/abs/2305.09938 ,  313kb)
------------------------------------------------------------------------------
\\
arXiv:2305.10133
replaced with revised version Mon, 5 Jun 2023 05:32:25 GMT   (4725kb,D)

Title: Lingo3DMol: Generation of a Pocket-based 3D Molecule using a Language
 Model
Authors: Lvwei Wang (1), Zaiyun Lin (1), Yanhao Zhu (1), Rong Bai (1), Wei Feng
 (1), Huting Wang (1), Jielong Zhou (1), Wei Peng (2), Bo Huang (1), Wenbiao
 Zhou (1) ((1) Beijing StoneWise Technology Co Ltd (2) Innovation Center for
 Pathogen Research Guangzhou Laboratory)
Categories: cs.LG q-bio.BM
\\ ( https://arxiv.org/abs/2305.10133 ,  4725kb)
------------------------------------------------------------------------------
\\
arXiv:2305.10638
replaced with revised version Fri, 2 Jun 2023 21:08:25 GMT   (4218kb,D)

Title: Disentangled Causal Graph Learning for Online Unsupervised Root Cause
 Analysis
Authors: Dongjie Wang, Zhengzhang Chen, Yanjie Fu, Yanchi Liu, Haifeng Chen
Categories: cs.LG cs.AI
\\ ( https://arxiv.org/abs/2305.10638 ,  4218kb)
------------------------------------------------------------------------------
\\
arXiv:2305.10758
replaced with revised version Sun, 4 Jun 2023 14:48:07 GMT   (789kb,D)

Title: Extracting Low-/High- Frequency Knowledge from Graph Neural Networks and
 Injecting it into MLPs: An Effective GNN-to-MLP Distillation Framework
Authors: Lirong Wu, Haitao Lin, Yufei Huang, Tianyu Fan, and Stan Z. Li
Categories: cs.LG
\\ ( https://arxiv.org/abs/2305.10758 ,  789kb)
------------------------------------------------------------------------------
\\
arXiv:2305.10838
replaced with revised version Fri, 2 Jun 2023 22:27:27 GMT   (0kb,I)

Title: ProgSG: Cross-Modality Representation Learning for Programs in
 Electronic Design Automation
Authors: Yunsheng Bai, Atefeh Sohrabizadeh, Zongyue Qin, Ziniu Hu, Yizhou Sun,
 Jason Cong
Categories: cs.LG cs.PL
Comments: Requires further polishing
\\ ( https://arxiv.org/abs/2305.10838 ,  0kb)
------------------------------------------------------------------------------
\\
arXiv:2305.10964
replaced with revised version Mon, 5 Jun 2023 09:52:19 GMT   (591kb,D)

Title: Learning Activation Functions for Sparse Neural Networks
Authors: Mohammad Loni, Aditya Mohan, Mehdi Asadi, Marius Lindauer
Categories: cs.LG cs.NE
\\ ( https://arxiv.org/abs/2305.10964 ,  591kb)
------------------------------------------------------------------------------
\\
arXiv:2305.12432
replaced with revised version Sat, 3 Jun 2023 07:56:53 GMT   (222kb,D)

Title: Many or Few Samples? Comparing Transfer, Contrastive and Meta-Learning
 in Encrypted Traffic Classification
Authors: Idio Guarino, Chao Wang, Alessandro Finamore, Antonio Pescape, Dario
 Rossi
Categories: cs.LG cs.NI
Comments: to appear in Traffic Measurements and Analysis (TMA) 2023
\\ ( https://arxiv.org/abs/2305.12432 ,  222kb)
------------------------------------------------------------------------------
\\
arXiv:2305.13164
replaced with revised version Mon, 5 Jun 2023 05:00:25 GMT   (1119kb,D)

Title: INVICTUS: Optimizing Boolean Logic Circuit Synthesis via Synergistic
 Learning and Search
Authors: Animesh Basak Chowdhury, Marco Romanelli, Benjamin Tan, Ramesh Karri,
 Siddharth Garg
Categories: cs.LG cs.AR
Comments: 20 pages, 8 figures and 15 tables
\\ ( https://arxiv.org/abs/2305.13164 ,  1119kb)
------------------------------------------------------------------------------
\\
arXiv:2305.13664
replaced with revised version Sun, 4 Jun 2023 01:25:48 GMT   (32495kb,D)

Title: Layer-wise Adaptive Step-Sizes for Stochastic First-Order Methods for
 Deep Learning
Authors: Achraf Bahamou, Donald Goldfarb
Categories: cs.LG math.OC
\\ ( https://arxiv.org/abs/2305.13664 ,  32495kb)
------------------------------------------------------------------------------
\\
arXiv:2305.15148
replaced with revised version Sat, 3 Jun 2023 12:35:57 GMT   (1621kb,D)

Title: Theoretically Principled Federated Learning for Balancing Privacy and
 Utility
Authors: Xiaojin Zhang, Wenjie Li, Kai Chen, Shutao Xia, Qiang Yang
Categories: cs.LG cs.AI cs.CR
\\ ( https://arxiv.org/abs/2305.15148 ,  1621kb)
------------------------------------------------------------------------------
\\
arXiv:2305.15877
replaced with revised version Mon, 5 Jun 2023 13:05:59 GMT   (4645kb,D)

Title: Exponential Smoothing for Off-Policy Learning
Authors: Imad Aouali, Victor-Emmanuel Brunel, David Rohde, Anna Korba
Categories: cs.LG cs.AI stat.ML
Comments: ICML 2023 (Oral and Poster)
\\ ( https://arxiv.org/abs/2305.15877 ,  4645kb)
------------------------------------------------------------------------------
\\
arXiv:2305.16817
replaced with revised version Fri, 2 Jun 2023 18:21:38 GMT   (7652kb,D)

Title: Selective Mixup Helps with Distribution Shifts, But Not (Only) because
 of Mixup
Authors: Damien Teney, Jindong Wang, Ehsan Abbasnejad
Categories: cs.LG
\\ ( https://arxiv.org/abs/2305.16817 ,  7652kb)
------------------------------------------------------------------------------
\\
arXiv:2305.17535
replaced with revised version Mon, 5 Jun 2023 17:05:51 GMT   (11409kb,D)

Title: PFNs4BO: In-Context Learning for Bayesian Optimization
Authors: Samuel M\"uller, Matthias Feurer, Noah Hollmann, Frank Hutter
Categories: cs.LG stat.ML
Comments: Accepted at ICML 2023
\\ ( https://arxiv.org/abs/2305.17535 ,  11409kb)
------------------------------------------------------------------------------
\\
arXiv:2305.17537
replaced with revised version Fri, 2 Jun 2023 21:49:22 GMT   (7935kb,D)

Title: Modeling Dynamic Environments with Scene Graph Memory
Authors: Andrey Kurenkov, Michael Lingelbach, Tanmay Agarwal, Chengshu Li,
 Emily Jin, Ruohan Zhang, Fei-Fei Li, Jiajun Wu, Silvio Savarese, Roberto
 Mart\'in-Mart\'in
Categories: cs.LG cs.AI
\\ ( https://arxiv.org/abs/2305.17537 ,  7935kb)
------------------------------------------------------------------------------
\\
arXiv:2305.18402
replaced with revised version Sat, 3 Jun 2023 03:38:02 GMT   (26260kb,D)

Title: Neural Sculpting: Uncovering hierarchically modular task structure
 through pruning and network analysis
Authors: Shreyas Malakarjun Patil, Loizos Michael, Constantine Dovrolis
Categories: cs.LG
Comments: 9 pages
\\ ( https://arxiv.org/abs/2305.18402 ,  26260kb)
------------------------------------------------------------------------------
\\
arXiv:2305.18444
replaced with revised version Sat, 3 Jun 2023 16:49:24 GMT   (4261kb,D)

Title: Continual Task Allocation in Meta-Policy Network via Sparse Prompting
Authors: Yijun Yang, Tianyi Zhou, Jing Jiang, Guodong Long, Yuhui Shi
Categories: cs.LG cs.AI
Comments: Accepted by ICML 2023
\\ ( https://arxiv.org/abs/2305.18444 ,  4261kb)
------------------------------------------------------------------------------
\\
arXiv:2305.18477
replaced with revised version Mon, 5 Jun 2023 08:33:25 GMT   (464kb)

Title: Beyond the Meta: Leveraging Game Design Parameters for Patch-Agnostic
 Esport Analytics
Authors: Alan Pedrassoli Chitayat, Florian Block, James Walker, Anders Drachen
Categories: cs.LG cs.AI
\\ ( https://arxiv.org/abs/2305.18477 ,  464kb)
------------------------------------------------------------------------------
\\
arXiv:2305.19591
replaced with revised version Sun, 4 Jun 2023 10:54:15 GMT   (1941kb,D)

Title: Traffic Prediction using Artificial Intelligence: Review of Recent
 Advances and Emerging Opportunities
Authors: Maryam Shaygan, Collin Meese, Wanxin Li, Xiaolong Zhao, Mark Nejad
Categories: cs.LG cs.AI
Comments: Published in Transportation Research Part C: Emerging Technologies
 (TR_C), Volume 145, 2022
DOI: 10.1016/j.trc.2022.103921
\\ ( https://arxiv.org/abs/2305.19591 ,  1941kb)
------------------------------------------------------------------------------
\\
arXiv:2305.19663
replaced with revised version Mon, 5 Jun 2023 10:35:57 GMT   (20723kb,D)

Title: Vandermonde Neural Operators
Authors: Levi Lingsch and Mike Michelis and Sirani M. Perera and Robert K.
 Katzschmann and Siddartha Mishra
Categories: cs.LG cs.NA math.NA
Comments: 21 pages, 10 figures
\\ ( https://arxiv.org/abs/2305.19663 ,  20723kb)
------------------------------------------------------------------------------
\\
arXiv:2305.20003
replaced with revised version Sat, 3 Jun 2023 00:38:33 GMT   (3018kb)

Title: A Novel Black Box Process Quality Optimization Approach based on Hit
 Rate
Authors: Yang Yang, Jian Wu, Xiangman Song, Derun Wu, Lijie Su, Lixin Tang
Categories: cs.LG cs.SY eess.SY math.OC
\\ ( https://arxiv.org/abs/2305.20003 ,  3018kb)
------------------------------------------------------------------------------
\\
arXiv:2306.00488
replaced with revised version Sun, 4 Jun 2023 21:25:25 GMT   (661kb,D)

Title: Reconstructing Graph Diffusion History from a Single Snapshot
Authors: Ruizhong Qiu, Dingsu Wang, Lei Ying, H. Vincent Poor, Yifang Zhang,
 Hanghang Tong
Categories: cs.LG cs.SI
Comments: Full version of the KDD 2023 paper (including the appendix)
DOI: 10.1145/3580305.3599488
\\ ( https://arxiv.org/abs/2306.00488 ,  661kb)
------------------------------------------------------------------------------
\\
arXiv:2306.01121
replaced with revised version Mon, 5 Jun 2023 13:45:21 GMT   (607kb,D)

Title: Differentially Private Episodic Reinforcement Learning with Heavy-tailed
 Rewards
Authors: Yulian Wu, Xingyu Zhou, Sayak Ray Chowdhury and Di Wang
Categories: cs.LG cs.AI
Comments: ICML 2023
\\ ( https://arxiv.org/abs/2306.01121 ,  607kb)
------------------------------------------------------------------------------
\\
arXiv:2306.01474
replaced with revised version Mon, 5 Jun 2023 02:43:23 GMT   (722kb,D)

Title: Generalist Equivariant Transformer Towards 3D Molecular Interaction
 Learning
Authors: Xiangzhe Kong, Wenbing Huang, Yang Liu
Categories: cs.LG q-bio.BM
Comments: preprint
\\ ( https://arxiv.org/abs/2306.01474 ,  722kb)
------------------------------------------------------------------------------
\\
arXiv:2301.01649
replaced with revised version Sat, 3 Jun 2023 05:25:41 GMT   (27796kb,D)

Title: Attention-Based Recurrence for Multi-Agent Reinforcement Learning under
 Stochastic Partial Observability
Authors: Thomy Phan and Fabian Ritz and Philipp Altmann and Maximilian Zorn and
 Jonas N\"u{\ss}lein and Michael K\"olle and Thomas Gabor and Claudia
 Linnhoff-Popien
Categories: cs.MA
Comments: Accepted at ICML 2023
\\ ( https://arxiv.org/abs/2301.01649 ,  27796kb)
------------------------------------------------------------------------------
\\
arXiv:2302.05910
replaced with revised version Sun, 4 Jun 2023 23:50:30 GMT   (4290kb,D)

Title: MANSA: Learning Fast and Slow in Multi-Agent Systems
Authors: David Mguni, Haojun Chen, Taher Jafferjee, Jianhong Wang, Long Fei,
 Xidong Feng, Stephen McAleer, Feifei Tong, Jun Wang, Yaodong Yang
Categories: cs.MA
\\ ( https://arxiv.org/abs/2302.05910 ,  4290kb)
------------------------------------------------------------------------------
\\
arXiv:2305.16818
replaced with revised version Sat, 3 Jun 2023 02:44:41 GMT   (765kb,D)

Title: Trust-Aware Resilient Control and Coordination of Connected and
 Automated Vehicles
Authors: H M Sabbir Ahmad, Ehsan Sabouni, Wei Xiao, Christos G. Cassandras,
 Wenchao Li
Categories: cs.MA cs.AI cs.SY eess.SY
Comments: Keywords: Resilient control and coordination, Cybersecurity, Safety
 guaranteed coordination, Connected And Autonomous Vehicles
\\ ( https://arxiv.org/abs/2305.16818 ,  765kb)
------------------------------------------------------------------------------
\\
arXiv:2006.01987
replaced with revised version Mon, 5 Jun 2023 14:32:56 GMT   (26760kb,D)

Title: Impact-Aware Task-Space Quadratic-Programming Control
Authors: Yuquan Wang, Niels Dehio, Arnaud Tanguy, and Abderrahmane Kheddar
Categories: cs.RO
\\ ( https://arxiv.org/abs/2006.01987 ,  26760kb)
------------------------------------------------------------------------------
\\
arXiv:2205.00955
replaced with revised version Fri, 2 Jun 2023 20:24:57 GMT   (4821kb,D)

Title: Coordination-free Multi-robot Path Planning for Congestion Reduction
 Using Topological Reasoning
Authors: Xiaolong Wang, Alp Sahin and Subhrajit Bhattacharya
Categories: cs.RO
Comments: 30 pages, 9 figures
\\ ( https://arxiv.org/abs/2205.00955 ,  4821kb)
------------------------------------------------------------------------------
\\
arXiv:2209.05135
replaced with revised version Mon, 5 Jun 2023 12:56:14 GMT   (14927kb,D)

Title: Signs of Language: Embodied Sign Language Fingerspelling Acquisition
 from Demonstrations for Human-Robot Interaction
Authors: Federico Tavella and Aphrodite Galata and Angelo Cangelosi
Categories: cs.RO cs.CL cs.CV cs.LG
\\ ( https://arxiv.org/abs/2209.05135 ,  14927kb)
------------------------------------------------------------------------------
\\
arXiv:2211.08201
replaced with revised version Sat, 3 Jun 2023 10:10:11 GMT   (46kb)

Title: Multiagent Rollout with Reshuffling for Warehouse Robots Path Planning
Authors: William Emanuelsson, Alejandro Penacho Riveiros, Yuchao Li, Karl H.
 Johansson, Jonas M{\aa}rtensson
Categories: cs.RO cs.SY eess.SY
\\ ( https://arxiv.org/abs/2211.08201 ,  46kb)
------------------------------------------------------------------------------
\\
arXiv:2212.07237
replaced with revised version Mon, 5 Jun 2023 12:36:26 GMT   (4028kb,D)

Title: Geometric Algebra for Optimal Control with Applications in Manipulation
 Tasks
Authors: Tobias L\"ow and Sylvain Calinon
Categories: cs.RO
Comments: 16 pages, 13 figuress
Journal-ref: Tobias L\"ow and Sylvain Calinon. (2023). Geometric Algebra for
 Optimal Control with Applications in Manipulation Tasks. IEEE Transactions on
 Robotics
DOI: 10.1109/TRO.2023.3277282
\\ ( https://arxiv.org/abs/2212.07237 ,  4028kb)
------------------------------------------------------------------------------
\\
arXiv:2301.08422
replaced with revised version Mon, 5 Jun 2023 06:30:12 GMT   (8767kb,D)

Title: A vision-based autonomous UAV inspection framework for unknown tunnel
 construction sites with dynamic obstacles
Authors: Zhefan Xu, Baihan Chen, Xiaoyang Zhan, Yumeng Xiu, Christopher Suzuki,
 Kenji Shimada
Categories: cs.RO cs.AI
Comments: 8 pages, 8 figures
\\ ( https://arxiv.org/abs/2301.08422 ,  8767kb)
------------------------------------------------------------------------------
\\
arXiv:2302.05103
replaced with revised version Sat, 3 Jun 2023 23:35:22 GMT   (9928kb,D)

Title: Controllability-Aware Unsupervised Skill Discovery
Authors: Seohong Park, Kimin Lee, Youngwoon Lee, Pieter Abbeel
Categories: cs.RO cs.AI cs.LG
Comments: ICML 2023
\\ ( https://arxiv.org/abs/2302.05103 ,  9928kb)
------------------------------------------------------------------------------
\\
arXiv:2302.10017
replaced with revised version Mon, 5 Jun 2023 10:18:57 GMT   (25915kb,D)

Title: Stable Motion Primitives via Imitation and Contrastive Learning
Authors: Rodrigo P\'erez-Dattari and Jens Kober
Categories: cs.RO
\\ ( https://arxiv.org/abs/2302.10017 ,  25915kb)
------------------------------------------------------------------------------
\\
arXiv:2303.02904
replaced with revised version Mon, 5 Jun 2023 04:25:41 GMT   (4843kb,D)

Title: Social Cue Analysis using Transfer Entropy
Authors: Haoyang Jiang, Elizabeth A. Croft, Michael Burke
Categories: cs.RO
Comments: 8 pages, 9 figures. Preprint
\\ ( https://arxiv.org/abs/2303.02904 ,  4843kb)
------------------------------------------------------------------------------
\\
arXiv:2303.03616
replaced with revised version Mon, 5 Jun 2023 00:55:58 GMT   (14942kb,D)

Title: Geometry-Aware Coverage Path Planning for Depowdering on Complex 3D
 Surfaces
Authors: Van-Thach Do and Quang-Cuong Pham
Categories: cs.RO cs.CG
Comments: 8 pages, 8 figures
\\ ( https://arxiv.org/abs/2303.03616 ,  14942kb)
------------------------------------------------------------------------------
\\
arXiv:2303.06034
replaced with revised version Mon, 5 Jun 2023 13:44:02 GMT   (4825kb,D)

Title: Tactile-Filter: Interactive Tactile Perception for Part Mating
Authors: Kei Ota, Devesh K. Jha, Hsiao-Yu Tung, Joshua B. Tenenbaum
Categories: cs.RO cs.AI cs.LG
Comments: Accepted at RSS2023
\\ ( https://arxiv.org/abs/2303.06034 ,  4825kb)
------------------------------------------------------------------------------
\\
arXiv:2304.00234
replaced with revised version Sat, 3 Jun 2023 02:39:16 GMT   (10083kb,D)

Title: Coordinated Defense Allocation in Reach-Avoid Scenarios with Efficient
 Online Optimization
Authors: Junwei Liu, Zikai Ouyang, Jiahui Yang, Hua Chen, Haibo Lu and Wei
 Zhang
Categories: cs.RO
\\ ( https://arxiv.org/abs/2304.00234 ,  10083kb)
------------------------------------------------------------------------------
\\
arXiv:2305.17527
replaced with revised version Fri, 2 Jun 2023 20:04:12 GMT   (1408kb,D)

Title: Towards computing low-makespan solutions for multi-arm multi-task
 planning problems
Authors: Valentin N. Hartmann, Marc Toussaint
Categories: cs.RO
Comments: Workshop for Planning and Robotics (PlanRob), International
 Conference on Automated Planning and Scheduling (ICAPS), 2023
\\ ( https://arxiv.org/abs/2305.17527 ,  1408kb)
------------------------------------------------------------------------------
\\
arXiv:2209.12457
replaced with revised version Sun, 4 Jun 2023 22:59:00 GMT   (3283kb,D)

Title: Fault Detection for Grid-Forming Inverters in Islanded Droop-Controlled
 AC Microgrids
Authors: Gabriel Intriago, Andres Intriago, Charalambos Konstantinou, Yu Zhang
Categories: eess.SY cs.SY
Comments: 10 pages, 6 figures
\\ ( https://arxiv.org/abs/2209.12457 ,  3283kb)
------------------------------------------------------------------------------
\\
arXiv:2210.04351
replaced with revised version Fri, 2 Jun 2023 19:51:35 GMT   (2959kb)

Title: California Test System (CATS): A Geographically Accurate Test System
 based on the California Grid
Authors: Sofia Taylor, Aditya Rangarajan, Noah Rhodes, Jonathan Snodgrass,
 Bernie Lesieutre, Line A. Roald
Categories: eess.SY cs.SY
Comments: 10 pages, 10 figures; conducted major revisions to improve clarity of
 writing and make cost data more realistic
\\ ( https://arxiv.org/abs/2210.04351 ,  2959kb)
------------------------------------------------------------------------------
\\
arXiv:2212.14250
replaced with revised version Mon, 5 Jun 2023 15:49:14 GMT   (617kb,D)

Title: Scheduling of Software-Defined Microgrids for Optimal Frequency
 Regulation
Authors: Zhongda Chu, Guoxuan Cui, Fei Teng
Categories: eess.SY cs.SY
\\ ( https://arxiv.org/abs/2212.14250 ,  617kb)
------------------------------------------------------------------------------
\\
arXiv:2212.14736
replaced with revised version Sat, 3 Jun 2023 01:10:14 GMT   (1950kb,D)

Title: PRISM: Privacy Preserving Healthcare Internet of Things Security
 Management
Authors: Savvas Hadjixenophontos and Anna Maria Mandalari and Yuchen Zhao and
 Hamed Haddadi
Categories: eess.SY cs.CR cs.SY
\\ ( https://arxiv.org/abs/2212.14736 ,  1950kb)
------------------------------------------------------------------------------
\\
arXiv:2302.07453
replaced with revised version Sat, 3 Jun 2023 21:24:32 GMT   (4726kb,D)

Title: Cooperative Driving for Speed Harmonization in Mixed-Traffic
 Environments
Authors: Zhe Fu, Abdul Rahman Kreidieh, Han Wang, Jonathan W. Lee, Maria Laura
 Delle Monache and Alexandre M. Bayen
Categories: eess.SY cs.SY
Comments: Accepted by IEEE IV 2023
\\ ( https://arxiv.org/abs/2302.07453 ,  4726kb)
------------------------------------------------------------------------------
\\
arXiv:2304.08897
replaced with revised version Mon, 5 Jun 2023 11:56:09 GMT   (4974kb,D)

Title: An adaptive safety layer with hard constraints for safe reinforcement
 learning in multi-energy management systems
Authors: Glenn Ceusters, Muhammad Andy Putratama, R\"udiger Franke, Ann Now\'e,
 Maarten Messagie
Categories: eess.SY cs.AI cs.LG cs.SY math.OC
Comments: 4703 words. arXiv admin note: text overlap with arXiv:2207.03830
\\ ( https://arxiv.org/abs/2304.08897 ,  4974kb)
------------------------------------------------------------------------------
\\
arXiv:2305.01771
replaced with revised version Sat, 3 Jun 2023 23:29:09 GMT   (429kb)

Title: Fault Tolerant Processing Unit Using Gamma Distribution Sliding Window
 For Autonomous Landing Guidance System
Authors: Hossam O. Ahmed
Categories: eess.SY cs.DC cs.SY
Comments: 21st IEEE Interregional NEWCAS Conference, Edinburgh, Scotland
\\ ( https://arxiv.org/abs/2305.01771 ,  429kb)
------------------------------------------------------------------------------
\\
arXiv:2305.18875
replaced with revised version Mon, 5 Jun 2023 11:11:42 GMT   (616kb,D)

Title: Centralised rehearsal of decentralised cooperation: Multi-agent
 reinforcement learning for the scalable coordination of residential energy
 flexibility
Authors: Flora Charbonnier, Bei Peng, Thomas Morstyn, Malcolm McCulloch
Categories: eess.SY cs.LG cs.MA cs.SY
\\ ( https://arxiv.org/abs/2305.18875 ,  616kb)
------------------------------------------------------------------------------
\\
arXiv:2201.06843
replaced with revised version Sat, 3 Jun 2023 21:45:47 GMT   (9929kb,D)

Title: Surrogate-assisted distributed swarm optimisation for computationally
 expensive geoscientific models
Authors: Rohitash Chandra, Yash Vardhan Sharma
Categories: cs.DC cs.AI
Journal-ref: Computational Geosciences, 2023
\\ ( https://arxiv.org/abs/2201.06843 ,  9929kb)
------------------------------------------------------------------------------
\\
arXiv:2202.02830
replaced with revised version Sat, 3 Jun 2023 00:05:28 GMT   (675kb,D)

Title: Discovering Personalized Semantics for Soft Attributes in Recommender
 Systems using Concept Activation Vectors
Authors: Christina G\"opfert and Alex Haig and Yinlam Chow and Chih-wei Hsu and
 Ivan Vendrov and Tyler Lu and Deepak Ramachandran and Hubert Pham and
 Mohammad Ghavamzadeh and Craig Boutilier
Categories: cs.IR cs.AI cs.LG
DOI: 10.1145/1122445.1122456
\\ ( https://arxiv.org/abs/2202.02830 ,  675kb)
------------------------------------------------------------------------------
\\
arXiv:2203.12026
replaced with revised version Sun, 4 Jun 2023 16:23:28 GMT   (3654kb,D)

Title: Machine Learning Testing in an ADAS Case Study Using
 Simulation-Integrated Bio-Inspired Search-Based Testing
Authors: Mahshid Helali Moghadam, Markus Borg, Mehrdad Saadatmand, Seyed
 Jalaleddin Mousavirad, Markus Bohlin, Bj\"orn Lisper
Categories: cs.SE cs.AI cs.LG cs.NE
Comments: 20 pages
\\ ( https://arxiv.org/abs/2203.12026 ,  3654kb)
------------------------------------------------------------------------------
\\
arXiv:2204.05428
replaced with revised version Mon, 5 Jun 2023 00:14:19 GMT   (6359kb,D)

Title: A Multilingual Perspective Towards the Evaluation of Attribution Methods
 in Natural Language Inference
Authors: Kerem Zaman, Yonatan Belinkov
Categories: cs.CL cs.AI
Comments: 21 pages, 7 figures. Code and data at
 https://keremzaman.com/explaiNLI/; Published in the Proceedings of EMNLP 2022
Journal-ref: https://aclanthology.org/2022.emnlp-main.101/
\\ ( https://arxiv.org/abs/2204.05428 ,  6359kb)
------------------------------------------------------------------------------
\\
arXiv:2204.06241
replaced with revised version Sun, 4 Jun 2023 11:00:50 GMT   (5554kb,D)

Title: Stealing and Evading Malware Classifiers and Antivirus at Low False
 Positive Conditions
Authors: Maria Rigaki and Sebastian Garcia
Categories: cs.CR cs.AI
Comments: 20 pages, 10 figures, 8 tables. Accepted, please use the DOI/ journal
 for citations
Journal-ref: Computers & Security, Volume 129, June 2023, 103192
DOI: 10.1016/j.cose.2023.103192
\\ ( https://arxiv.org/abs/2204.06241 ,  5554kb)
------------------------------------------------------------------------------
\\
arXiv:2210.00896 (*cross-listing*)
replaced with revised version Mon, 5 Jun 2023 01:21:00 GMT   (7267kb,D)

Title: CBLab: Supporting the Training of Large-scale Traffic Control Policies
 with Scalable Traffic Simulation
Authors: Chumeng Liang, Zherui Huang, Yicheng Liu, Zhanyu Liu, Guanjie Zheng,
 Hanyuan Shi, Kan Wu, Yuhao Du, Fuliang Li, Zhenhui Li
Categories: physics.soc-ph cs.AI cs.CY cs.DC cs.SE
Comments: Accepted by KDD2023 (Applied Data Science Track)
\\ ( https://arxiv.org/abs/2210.00896 ,  7267kb)
------------------------------------------------------------------------------
\\
arXiv:2210.06068
replaced with revised version Sun, 4 Jun 2023 20:42:19 GMT   (7750kb,D)

Title: Investigating Massive Multilingual Pre-Trained Machine Translation
 Models for Clinical Domain via Transfer Learning
Authors: Lifeng Han, Gleb Erofeev, Irina Sorokina, Serge Gladkoff, Goran
 Nenadic
Categories: cs.CL cs.AI
Comments: Accepted to ClinicalNLP-2023 WS@ACL-2023
\\ ( https://arxiv.org/abs/2210.06068 ,  7750kb)
------------------------------------------------------------------------------
\\
arXiv:2211.02626 (*cross-listing*)
replaced with revised version Sat, 3 Jun 2023 07:22:24 GMT   (2717kb,D)

Title: Leveraging Statistical Shape Priors in GAN-based ECG Synthesis
Authors: Nour Neifar and Achraf Ben-Hamadou and Afef Mdhaffar and Mohamed
 Jmaiel and Bernd Freisleben
Categories: eess.SP cs.AI cs.LG
Comments: 6 figures, 31 pages, under review
\\ ( https://arxiv.org/abs/2211.02626 ,  2717kb)
------------------------------------------------------------------------------
\\
arXiv:2212.08153
replaced with revised version Fri, 2 Jun 2023 23:28:17 GMT   (51kb,D)

Title: FiDO: Fusion-in-Decoder optimized for stronger performance and faster
 inference
Authors: Michiel de Jong, Yury Zemlyanskiy, Joshua Ainslie, Nicholas
 FitzGerald, Sumit Sanghai, Fei Sha, William Cohen
Categories: cs.CL cs.AI cs.LG
Comments: ACL Findings 2023
\\ ( https://arxiv.org/abs/2212.08153 ,  51kb)
------------------------------------------------------------------------------
\\
arXiv:2212.09282
replaced with revised version Mon, 5 Jun 2023 00:56:11 GMT   (1130kb,D)

Title: APOLLO: A Simple Approach for Adaptive Pretraining of Language Models
 for Logical Reasoning
Authors: Soumya Sanyal, Yichong Xu, Shuohang Wang, Ziyi Yang, Reid Pryzant,
 Wenhao Yu, Chenguang Zhu, Xiang Ren
Categories: cs.CL cs.AI cs.LG
Comments: Accepted at ACL 2023, code available at
 https://github.com/INK-USC/APOLLO
\\ ( https://arxiv.org/abs/2212.09282 ,  1130kb)
------------------------------------------------------------------------------
\\
arXiv:2212.09648
replaced with revised version Mon, 5 Jun 2023 17:17:53 GMT   (3218kb,D)

Title: NusaCrowd: Open Source Initiative for Indonesian NLP Resources
Authors: Samuel Cahyawijaya, Holy Lovenia, Alham Fikri Aji, Genta Indra Winata,
 Bryan Wilie, Rahmad Mahendra, Christian Wibisono, Ade Romadhony, Karissa
 Vincentio, Fajri Koto, Jennifer Santoso, David Moeljadi, Cahya Wirawan,
 Frederikus Hudi, Ivan Halim Parmonangan, Ika Alfina, Muhammad Satrio
 Wicaksono, Ilham Firdausi Putra, Samsul Rahmadani, Yulianti Oenang, Ali Akbar
 Septiandri, James Jaya, Kaustubh D. Dhole, Arie Ardiyanti Suryani, Rifki
 Afina Putri, Dan Su, Keith Stevens, Made Nindyatama Nityasya, Muhammad Farid
 Adilazuarda, Ryan Ignatius, Ryandito Diandaru, Tiezheng Yu, Vito Ghifari,
 Wenliang Dai, Yan Xu, Dyah Damapuspita, Cuk Tho, Ichwanul Muslim Karo Karo,
 Tirana Noor Fatyanosa, Ziwei Ji, Pascale Fung, Graham Neubig, Timothy
 Baldwin, Sebastian Ruder, Herry Sujaini, Sakriani Sakti, Ayu Purwarianti
Categories: cs.CL cs.AI
\\ ( https://arxiv.org/abs/2212.09648 ,  3218kb)
------------------------------------------------------------------------------
\\
arXiv:2212.09865
replaced with revised version Sat, 3 Jun 2023 22:51:39 GMT   (1028kb,D)

Title: Z-ICL: Zero-Shot In-Context Learning with Pseudo-Demonstrations
Authors: Xinxi Lyu, Sewon Min, Iz Beltagy, Luke Zettlemoyer, Hannaneh
 Hajishirzi
Categories: cs.CL cs.AI
Comments: 11 pages; 9 figures
\\ ( https://arxiv.org/abs/2212.09865 ,  1028kb)
------------------------------------------------------------------------------
\\
arXiv:2212.13937
replaced with revised version Sun, 4 Jun 2023 17:38:42 GMT   (1032kb,D)

Title: Towards Disentangling Relevance and Bias in Unbiased Learning to Rank
Authors: Yunan Zhang, Le Yan, Zhen Qin, Honglei Zhuang, Jiaming Shen, Xuanhui
 Wang, Michael Bendersky, Marc Najork
Categories: cs.IR cs.AI
Comments: Proceedings of the 29th ACM SIGKDD International Conference on
 Knowledge Discovery & Data Mining
\\ ( https://arxiv.org/abs/2212.13937 ,  1032kb)
------------------------------------------------------------------------------
\\
arXiv:2301.10448
replaced with revised version Fri, 2 Jun 2023 23:13:05 GMT   (563kb,D)

Title: Pre-computed memory or on-the-fly encoding? A hybrid approach to
 retrieval augmentation makes the most of your compute
Authors: Michiel de Jong, Yury Zemlyanskiy, Nicholas FitzGerald, Joshua
 Ainslie, Sumit Sanghai, Fei Sha, William Cohen
Categories: cs.CL cs.AI cs.LG
Comments: ICML 2023
\\ ( https://arxiv.org/abs/2301.10448 ,  563kb)
------------------------------------------------------------------------------
\\
arXiv:2301.10521
replaced with revised version Sat, 3 Jun 2023 17:11:28 GMT   (588kb,D)

Title: ExaRanker: Explanation-Augmented Neural Ranker
Authors: Fernando Ferraretto, Thiago Laitz, Roberto Lotufo and Rodrigo Nogueira
Categories: cs.CL cs.AI cs.IR
\\ ( https://arxiv.org/abs/2301.10521 ,  588kb)
------------------------------------------------------------------------------
\\
arXiv:2302.00277
replaced with revised version Sat, 3 Jun 2023 10:34:21 GMT   (44kb)

Title: Anti-unification and Generalization: A Survey
Authors: David M. Cerna and Temur Kutsia
Categories: cs.LO cs.AI
Comments: Accepted at IJCAI 2023 - Survey Track
 (https://ijcai-23.org/survey-track/)
\\ ( https://arxiv.org/abs/2302.00277 ,  44kb)
------------------------------------------------------------------------------
\\
arXiv:2302.01501
replaced with revised version Sun, 4 Jun 2023 16:23:00 GMT   (4979kb,D)

Title: ANTM: An Aligned Neural Topic Model for Exploring Evolving Topics
Authors: Hamed Rahimi, Hubert Naacke, Camelia Constantin, Bernd Amann
Categories: cs.IR cs.AI cs.LG cs.NE cs.SI
\\ ( https://arxiv.org/abs/2302.01501 ,  4979kb)
------------------------------------------------------------------------------
\\
arXiv:2302.12601
replaced with revised version Mon, 5 Jun 2023 07:47:34 GMT   (8638kb,AD)

Title: "An Adapt-or-Die Type of Situation": Perception, Adoption, and Use of
 Text-To-Image-Generation AI by Game Industry Professionals
Authors: Veera Vimpari, Annakaisa Kultima, Perttu H\"am\"al\"ainen, Christian
 Guckelsberger
Categories: cs.HC cs.AI
Comments: 32 pages (incl. appendix), 3 figures, 4 tables. Coding template (31
 pages, 10 tables), study invitations (email, social media) and pre-study
 survey provided as supplementary (ancillary) material. Accepted with minor
 revisions at ACM CHI Play 2023
\\ ( https://arxiv.org/abs/2302.12601 ,  8638kb)
------------------------------------------------------------------------------
\\
arXiv:2303.07205
replaced with revised version Fri, 2 Jun 2023 19:24:17 GMT   (1153kb,D)

Title: The Science of Detecting LLM-Generated Texts
Authors: Ruixiang Tang, Yu-Neng Chuang, Xia Hu
Categories: cs.CL cs.AI
\\ ( https://arxiv.org/abs/2303.07205 ,  1153kb)
------------------------------------------------------------------------------
\\
arXiv:2304.02721
replaced with revised version Sat, 3 Jun 2023 02:01:21 GMT   (6993kb,D)

Title: To Asymmetry and Beyond: Structured Pruning of Sequence to Sequence
 Models for Improved Inference Efficiency
Authors: Daniel Campos, ChengXiang Zhai
Categories: cs.CL cs.AI
Comments: SustaiNLP2023 @ ACL 2023,9 pages, 6 figures, 33 tables
\\ ( https://arxiv.org/abs/2304.02721 ,  6993kb)
------------------------------------------------------------------------------
\\
arXiv:2304.08216
replaced with revised version Sat, 3 Jun 2023 07:43:12 GMT   (6937kb,D)

Title: Context-Dependent Embedding Utterance Representations for Emotion
 Recognition in Conversations
Authors: Patr\'icia Pereira, Helena Moniz, Isabel Dias and Joao Paulo Carvalho
Categories: cs.CL cs.AI
Comments: WASSA'23
\\ ( https://arxiv.org/abs/2304.08216 ,  6937kb)
------------------------------------------------------------------------------
\\
arXiv:2304.13567
replaced with revised version Sun, 4 Jun 2023 09:11:03 GMT   (203kb,D)

Title: Technical Report on Token Position Bias in Transformers
Authors: Mehdi Ben Amor, Michael Granitzer, Jelena Mitrovi\'c
Categories: cs.CL cs.AI
Comments: Updated title of the preprint
\\ ( https://arxiv.org/abs/2304.13567 ,  203kb)
------------------------------------------------------------------------------
\\
arXiv:2305.02220
replaced with revised version Sat, 3 Jun 2023 17:56:29 GMT   (7584kb,D)

Title: WangLab at MEDIQA-Chat 2023: Clinical Note Generation from
 Doctor-Patient Conversations using Large Language Models
Authors: John Giorgi, Augustin Toma, Ronald Xie, Sondra S. Chen, Kevin R. An,
 Grace X. Zheng, Bo Wang
Categories: cs.CL cs.AI cs.LG
Comments: Camera-ready submission to ClinicalNLP @ ACL 2023
\\ ( https://arxiv.org/abs/2305.02220 ,  7584kb)
------------------------------------------------------------------------------
\\
arXiv:2305.03506
replaced with revised version Sun, 4 Jun 2023 03:04:05 GMT   (0kb,I)

Title: SI-LSTM: Speaker Hybrid Long-short Term Memory and Cross Modal Attention
 for Emotion Recognition in Conversation
Authors: Xingwei Liang, You Zou, Ruifeng Xu
Categories: cs.CL cs.AI cs.HC
Comments: Modification needed
\\ ( https://arxiv.org/abs/2305.03506 ,  0kb)
------------------------------------------------------------------------------
\\
arXiv:2305.03517
replaced with revised version Mon, 5 Jun 2023 00:58:41 GMT   (2690kb,D)

Title: Few-shot Domain-Adaptive Visually-fused Event Detection from Text
Authors: Farhad Moghimifar, Fatemeh Shiri, Van Nguyen, Reza Haffari, Yuan-Fang
 Li
Categories: cs.CL cs.AI
\\ ( https://arxiv.org/abs/2305.03517 ,  2690kb)
------------------------------------------------------------------------------
\\
arXiv:2305.05586
replaced with revised version Fri, 2 Jun 2023 18:43:17 GMT   (11313kb,D)

Title: RLocator: Reinforcement Learning for Bug Localization
Authors: Partha Chakraborty, Mahmoud Alfadel, and Meiyappan Nagappan
Categories: cs.SE cs.AI
\\ ( https://arxiv.org/abs/2305.05586 ,  11313kb)
------------------------------------------------------------------------------
\\
arXiv:2305.08062 (*cross-listing*)
replaced with revised version Fri, 2 Jun 2023 20:52:40 GMT   (3966kb,D)

Title: Off-Policy Evaluation for Large Action Spaces via Conjunct Effect
 Modeling
Authors: Yuta Saito, Qingyang Ren, Thorsten Joachims
Categories: stat.ML cs.AI cs.LG
Comments: accepted at ICML2023
\\ ( https://arxiv.org/abs/2305.08062 ,  3966kb)
------------------------------------------------------------------------------
\\
arXiv:2305.10614
replaced with revised version Fri, 2 Jun 2023 22:50:07 GMT   (879kb,D)

Title: Token-wise Decomposition of Autoregressive Language Model Hidden States
 for Analyzing Model Predictions
Authors: Byung-Doh Oh, William Schuler
Categories: cs.CL cs.AI
Comments: ACL 2023
\\ ( https://arxiv.org/abs/2305.10614 ,  879kb)
------------------------------------------------------------------------------
\\
arXiv:2305.10847
replaced with revised version Mon, 5 Jun 2023 03:54:52 GMT   (362kb,D)

Title: Large Language Models can be Guided to Evade AI-Generated Text Detection
Authors: Ning Lu, Shengcai Liu, Rui He, Qi Wang, Ke Tang
Categories: cs.CL cs.AI
\\ ( https://arxiv.org/abs/2305.10847 ,  362kb)
------------------------------------------------------------------------------
\\
arXiv:2305.16044
replaced with revised version Mon, 5 Jun 2023 13:22:08 GMT   (1998kb,D)

Title: Exploiting Noise as a Resource for Computation and Learning in Spiking
 Neural Networks
Authors: Gehua Ma, Rui Yan, Huajin Tang
Categories: cs.NE cs.AI cs.LG
Comments: Updated the code link; fixed the bug in the BBL file generated with
 bibliography management program
\\ ( https://arxiv.org/abs/2305.16044 ,  1998kb)
------------------------------------------------------------------------------
\\
arXiv:2305.16380
replaced with revised version Sun, 4 Jun 2023 04:24:01 GMT   (2336kb,D)

Title: Scan and Snap: Understanding Training Dynamics and Token Composition in
 1-layer Transformer
Authors: Yuandong Tian, Yiping Wang, Beidi Chen, Simon Du
Categories: cs.CL cs.AI cs.LG
Comments: Fix minor issues in the proofs and figures. Update figures to reflect
 the main conclusions more accurately
\\ ( https://arxiv.org/abs/2305.16380 ,  2336kb)
------------------------------------------------------------------------------
\\
arXiv:2305.16579
replaced with revised version Sat, 3 Jun 2023 14:01:24 GMT   (220kb,D)

Title: NLP Reproducibility For All: Understanding Experiences of Beginners
Authors: Shane Storks, Keunwoo Peter Yu, Ziqiao Ma, Joyce Chai
Categories: cs.CL cs.AI
Comments: ACL 2023 Theme Track
\\ ( https://arxiv.org/abs/2305.16579 ,  220kb)
------------------------------------------------------------------------------
\\
arXiv:2305.17182
replaced with revised version Sun, 4 Jun 2023 09:41:35 GMT   (625kb,D)

Title: On the Copying Problem of Unsupervised NMT: A Training Schedule with a
 Language Discriminator Loss
Authors: Yihong Liu, Alexandra Chronopoulou, Hinrich Sch\"utze, Alexander
 Fraser
Categories: cs.CL cs.AI
Comments: IWSLT 2023
\\ ( https://arxiv.org/abs/2305.17182 ,  625kb)
------------------------------------------------------------------------------
\\
arXiv:2305.17393
replaced with revised version Sat, 3 Jun 2023 05:40:25 GMT   (6977kb,D)

Title: Answering Unanswered Questions through Semantic Reformulations in Spoken
 QA
Authors: Pedro Faustini, Zhiyu Chen, Besnik Fetahu, Oleg Rokhlenko and Shervin
 Malmasi
Categories: cs.CL cs.AI
Comments: ACL 2023 Industry Track
\\ ( https://arxiv.org/abs/2305.17393 ,  6977kb)
------------------------------------------------------------------------------
\\
arXiv:2305.17553
replaced with revised version Sat, 3 Jun 2023 08:01:11 GMT   (8489kb,D)

Title: Detecting Edit Failures In Large Language Models: An Improved
 Specificity Benchmark
Authors: Jason Hoelscher-Obermaier, Julia Persson, Esben Kran, Ioannis Konstas
 and Fazl Barez
Categories: cs.CL cs.AI cs.LG
Comments: To be published in ACL Findings 2023; for code see
 https://github.com/apartresearch/specificityplus; for a homepage see
 https://specificityplus.apartresearch.com/; updated Figures to uniform style
ACM-class: I.2.7
\\ ( https://arxiv.org/abs/2305.17553 ,  8489kb)
------------------------------------------------------------------------------
\\
arXiv:2305.18486
replaced with revised version Mon, 5 Jun 2023 16:21:40 GMT   (9297kb,D)

Title: A Systematic Study and Comprehensive Evaluation of ChatGPT on Benchmark
 Datasets
Authors: Md Tahmid Rahman Laskar, M Saiful Bari, Mizanur Rahman, Md Amran
 Hossen Bhuiyan, Shafiq Joty, Jimmy Xiangji Huang
Categories: cs.CL cs.AI cs.LG
Comments: Accepted by ACL 2023 Findings. The first three authors contributed
 equally
\\ ( https://arxiv.org/abs/2305.18486 ,  9297kb)
------------------------------------------------------------------------------
\\
arXiv:2305.18885
replaced with revised version Sat, 3 Jun 2023 10:02:53 GMT   (1991kb,D)

Title: Criteria Tell You More than Ratings: Criteria Preference-Aware Light
 Graph Convolution for Effective Multi-Criteria Recommendation
Authors: Jin-Duk Park, Siqing Li, Xin Cao, Won-Yong Shin
Categories: cs.SI cs.AI cs.IR cs.IT cs.LG math.IT
Comments: 12 pages, 10 figures, 5 tables; 29th ACM SIGKDD Conference on
 Knowledge Discovery & Data (KDD 2023) (to appear) (Please cite our conference
 version.)
\\ ( https://arxiv.org/abs/2305.18885 ,  1991kb)
------------------------------------------------------------------------------
\\
arXiv:2306.00080
replaced with revised version Fri, 2 Jun 2023 19:32:32 GMT   (8334kb)

Title: AI Imagery and the Overton Window
Authors: Sarah K. Amer
Categories: cs.CY cs.AI cs.HC
Comments: 18 pages, 18 figures, awaiting peer review. Due to the
 rapidly-evolving nature of text-to-image generation models, this literature
 review includes some references to time-sensitive elements such as news
 articles, legal reports and other non-academic documents
\\ ( https://arxiv.org/abs/2306.00080 ,  8334kb)
------------------------------------------------------------------------------
\\
arXiv:2306.00418
replaced with revised version Sat, 3 Jun 2023 09:48:36 GMT   (15156kb,D)

Title: Uncertainty-Aware Unlikelihood Learning Improves Generative Aspect
 Sentiment Quad Prediction
Authors: Mengting Hu and Yinhao Bai and Yike Wu and Zhen Zhang and Liqi Zhang
 and Hang Gao and Shiwan Zhao and Minlie Huang
Categories: cs.CL cs.AI
Comments: Accepted by ACL Findings (2023)
\\ ( https://arxiv.org/abs/2306.00418 ,  15156kb)
------------------------------------------------------------------------------
\\
arXiv:2206.03382
replaced with revised version Mon, 5 Jun 2023 15:05:24 GMT   (4206kb,D)

Title: Tutel: Adaptive Mixture-of-Experts at Scale
Authors: Changho Hwang, Wei Cui, Yifan Xiong, Ziyue Yang, Ze Liu, Han Hu,
 Zilong Wang, Rafael Salas, Jithin Jose, Prabhat Ram, Joe Chau, Peng Cheng,
 Fan Yang, Mao Yang, Yongqiang Xiong
Categories: cs.DC cs.CL cs.CV
\\ ( https://arxiv.org/abs/2206.03382 ,  4206kb)
------------------------------------------------------------------------------
\\
arXiv:2211.07804 (*cross-listing*)
replaced with revised version Sat, 3 Jun 2023 22:06:56 GMT   (19742kb,D)

Title: Diffusion Models for Medical Image Analysis: A Comprehensive Survey
Authors: Amirhossein Kazerouni, Ehsan Khodapanah Aghdam, Moein Heidari, Reza
 Azad, Mohsen Fayyaz, Ilker Hacihaliloglu, Dorit Merhof
Categories: eess.IV cs.CV
Comments: Third revision: including more papers and further discussions
\\ ( https://arxiv.org/abs/2211.07804 ,  19742kb)
------------------------------------------------------------------------------
\\
arXiv:2306.01375 (*cross-listing*)
replaced with revised version Mon, 5 Jun 2023 14:25:53 GMT   (2169kb,D)

Title: Robust and Generalisable Segmentation of Subtle Epilepsy-causing
 Lesions: a Graph Convolutional Approach
Authors: Hannah Spitzer, Mathilde Ripart, Abdulah Fawaz, Logan Z. J. Williams,
 MELD project, Emma Robinson, Juan Eugenio Iglesias, Sophie Adler, Konrad
 Wagstyl
Categories: eess.IV cs.CV cs.LG
Comments: accepted at MICCAI 2023
\\ ( https://arxiv.org/abs/2306.01375 ,  2169kb)
------------------------------------------------------------------------------
\\
arXiv:1907.09282
replaced with revised version Fri, 2 Jun 2023 23:19:18 GMT   (946kb,D)

Title: Learning the Relation between Code Features and Code Transforms with
 Structured Prediction
Authors: Zhongxing Yu, Matias Martinez, Zimin Chen, Tegawend\'e F. Bissyand\'e,
 Martin Monperrus
Categories: cs.SE cs.LG cs.PL
Journal-ref: IEEE Transactions on Software Engineering, 2023
DOI: 10.1109/TSE.2023.3275380
\\ ( https://arxiv.org/abs/1907.09282 ,  946kb)
------------------------------------------------------------------------------
\\
arXiv:2105.09788 (*cross-listing*)
replaced with revised version Sat, 3 Jun 2023 16:18:32 GMT   (465kb)

Title: Distributed Adaptive Nearest Neighbor Classifier: Algorithm and Theory
Authors: Ruiqi Liu, Ganggang Xu, Zuofeng Shang
Categories: stat.ML cs.LG stat.ME
\\ ( https://arxiv.org/abs/2105.09788 ,  465kb)
------------------------------------------------------------------------------
\\
arXiv:2109.11926 (*cross-listing*)
replaced with revised version Sun, 4 Jun 2023 02:55:11 GMT   (1008kb,D)

Title: Sinkhorn Distributionally Robust Optimization
Authors: Jie Wang, Rui Gao, Yao Xie
Categories: math.OC cs.LG stat.ML
Comments: 57 pages, 9 figures
\\ ( https://arxiv.org/abs/2109.11926 ,  1008kb)
------------------------------------------------------------------------------
\\
arXiv:2201.13156
replaced with revised version Mon, 5 Jun 2023 08:00:24 GMT   (146kb,D)

Title: Low-Rank Updates of Matrix Square Roots
Authors: Shany Shumeli, Petros Drineas, Haim Avron
Categories: math.NA cs.LG cs.NA
\\ ( https://arxiv.org/abs/2201.13156 ,  146kb)
------------------------------------------------------------------------------
\\
arXiv:2202.02842
replaced with revised version Sun, 4 Jun 2023 21:59:47 GMT   (1094kb,D)

Title: Evaluating natural language processing models with generalization
 metrics that do not need access to any training or testing data
Authors: Yaoqing Yang, Ryan Theisen, Liam Hodgkinson, Joseph E. Gonzalez,
 Kannan Ramchandran, Charles H. Martin, Michael W. Mahoney
Categories: cs.CL cs.LG
Journal-ref: Proceedings of the 29th ACM SIGKDD international conference on
 knowledge discovery and data mining (2023)
\\ ( https://arxiv.org/abs/2202.02842 ,  1094kb)
------------------------------------------------------------------------------
\\
arXiv:2203.00922 (*cross-listing*)
replaced with revised version Mon, 5 Jun 2023 13:15:00 GMT   (733kb,D)

Title: Canonical foliations of neural networks: application to robustness
Authors: Eliot Tron, Nicolas Couellan, St\'ephane Puechmorel
Categories: stat.ML cs.IT cs.LG math.DG math.IT
\\ ( https://arxiv.org/abs/2203.00922 ,  733kb)
------------------------------------------------------------------------------
\\
arXiv:2203.15578
replaced with revised version Sun, 4 Jun 2023 18:08:38 GMT   (321kb,D)

Title: Disentangling speech from surroundings with neural embeddings
Authors: Ahmed Omran, Neil Zeghidour, Zal\'an Borsos, F\'elix de Chaumont
 Quitry, Malcolm Slaney, Marco Tagliasacchi
Categories: cs.SD cs.LG eess.AS
Comments: Accepted at ICASSP 2023
\\ ( https://arxiv.org/abs/2203.15578 ,  321kb)
------------------------------------------------------------------------------
\\
arXiv:2204.01057 (*cross-listing*)
replaced with revised version Sat, 3 Jun 2023 00:47:06 GMT   (129kb,D)

Title: A Survey on Machine Learning Solutions for Graph Pattern Extraction
Authors: Kai Siong Yow and Ningyi Liao and Siqiang Luo and Reynold Cheng and
 Chenhao Ma and Xiaolin Han
Categories: math.CO cs.DM cs.LG
Comments: v1: 41 pages; v2: 40 pages ; v3: This version focuses on just
 subgraph problems (discussions on other classic graph problems can be found
 in the earlier versions)
MSC-class: 05C90, 68M07, 68R10
\\ ( https://arxiv.org/abs/2204.01057 ,  129kb)
------------------------------------------------------------------------------
\\
arXiv:2204.01815
replaced with revised version Mon, 5 Jun 2023 13:56:32 GMT   (37kb)

Title: Tensor Completion with Provable Consistency and Fairness Guarantees for
 Recommender Systems
Authors: Tung Nguyen and Jeffrey Uhlmann
Categories: cs.IR cs.LG
Comments: Final revision after acceptance by journal
\\ ( https://arxiv.org/abs/2204.01815 ,  37kb)
------------------------------------------------------------------------------
\\
arXiv:2204.02272
replaced with revised version Mon, 5 Jun 2023 14:59:18 GMT   (3669kb,D)

Title: Deep surrogate accelerated delayed-acceptance HMC for Bayesian inference
 of spatio-temporal heat fluxes in rotating disc systems
Authors: Teo Deveney, Eike Mueller, Tony Shardlow
Categories: math.NA cs.LG cs.NA
\\ ( https://arxiv.org/abs/2204.02272 ,  3669kb)
------------------------------------------------------------------------------
\\
arXiv:2205.10282
replaced with revised version Sun, 4 Jun 2023 21:20:01 GMT   (1364kb)

Title: Heterformer: Transformer-based Deep Node Representation Learning on
 Heterogeneous Text-Rich Networks
Authors: Bowen Jin, Yu Zhang, Qi Zhu, Jiawei Han
Categories: cs.CL cs.LG
Comments: KDD 2023. (Code: https://github.com/PeterGriffinJin/Heterformer)
\\ ( https://arxiv.org/abs/2205.10282 ,  1364kb)
------------------------------------------------------------------------------
\\
arXiv:2205.14714 (*cross-listing*)
replaced with revised version Sat, 3 Jun 2023 13:29:50 GMT   (183kb,D)

Title: Comparison of meta-learners for estimating multi-valued treatment
 heterogeneous effects
Authors: Naoufal Acharki and Ramiro Lugo and Antoine Bertoncello and Josselin
 Garnier
Categories: stat.ML cs.LG stat.AP
Comments: 42 pages, 9 figures, to appear in ICML 2023 conference
\\ ( https://arxiv.org/abs/2205.14714 ,  183kb)
------------------------------------------------------------------------------
\\
arXiv:2206.07632 (*cross-listing*)
replaced with revised version Sat, 3 Jun 2023 08:43:39 GMT   (3728kb,D)

Title: Exploring Chemical Space with Score-based Out-of-distribution Generation
Authors: Seul Lee, Jaehyeong Jo, Sung Ju Hwang
Categories: q-bio.BM cs.LG physics.chem-ph
Comments: ICML 2023
\\ ( https://arxiv.org/abs/2206.07632 ,  3728kb)
------------------------------------------------------------------------------
\\
arXiv:2206.08648 (*cross-listing*)
replaced with revised version Fri, 2 Jun 2023 18:45:00 GMT   (549kb,D)

Title: Orthonormal Expansions for Translation-Invariant Kernels
Authors: Filip Tronarp and Toni Karvonen
Categories: math.CA cs.LG cs.NA math.NA stat.ML
Comments: 23 pages, 8 figures
\\ ( https://arxiv.org/abs/2206.08648 ,  549kb)
------------------------------------------------------------------------------
\\
arXiv:2206.14578
replaced with revised version Mon, 5 Jun 2023 09:02:01 GMT   (6837kb,D)

Title: Evaluating Generative Patent Language Models
Authors: Jieh-Sheng Lee
Categories: cs.CL cs.LG
Comments: 12 pages, 7 figures, and 5 tables
Journal-ref: World Patent Information, Volume 72, March 2023, 102173
DOI: 10.1016/j.wpi.2023.102173
\\ ( https://arxiv.org/abs/2206.14578 ,  6837kb)
------------------------------------------------------------------------------
\\
arXiv:2207.10415 (*cross-listing*)
replaced with revised version Fri, 2 Jun 2023 22:33:38 GMT   (11862kb,D)

Title: Log Barriers for Safe Black-box Optimization with Application to Safe
 Reinforcement Learning
Authors: Ilnura Usmanova, Yarden As, Maryam Kamgarpour, and Andreas Krause
Categories: math.OC cs.LG
Comments: 36 pages, 9 pages of appendix
\\ ( https://arxiv.org/abs/2207.10415 ,  11862kb)
------------------------------------------------------------------------------
\\
arXiv:2208.05844 (*cross-listing*)
replaced with revised version Mon, 5 Jun 2023 15:22:59 GMT   (627kb,D)

Title: Adaptive Identification of Populations with Treatment Benefit in
 Clinical Trials: Machine Learning Challenges and Solutions
Authors: Alicia Curth and Alihan H\"uy\"uk and Mihaela van der Schaar
Categories: stat.ML cs.LG
Comments: To appear in the Proceedings of the 40th International Conference on
 Machine Learning, Honolulu, Hawaii, USA. PMLR 202, 2023
\\ ( https://arxiv.org/abs/2208.05844 ,  627kb)
------------------------------------------------------------------------------
\\
arXiv:2208.10230 (*cross-listing*)
replaced with revised version Sat, 3 Jun 2023 09:58:11 GMT   (3270kb,D)

Title: From Static to Dynamic Structures: Improving Binding Affinity Prediction
 with a Graph-Based Deep Learning Model
Authors: Yaosen Min, Ye Wei, Peizhuo Wang, Xiaoting Wang, Han Li, Nian Wu,
 Stefan Bauer, Shuxin Zheng, Yu Shi, Yingheng Wang, Ji Wu, Dan Zhao and
 Jianyang Zeng
Categories: q-bio.BM cs.LG physics.chem-ph q-bio.QM
Comments: totally reorganize the texts and figures
\\ ( https://arxiv.org/abs/2208.10230 ,  3270kb)
------------------------------------------------------------------------------
\\
arXiv:2208.10917
replaced with revised version Sat, 3 Jun 2023 23:35:18 GMT   (59kb)

Title: Graph Embeddings via Tensor Products and Approximately Orthonormal Codes
Authors: Frank Qiu
Categories: cs.SI cs.LG stat.ML
Comments: 59 pages, 2 tables. arxiv admin note: substantial text overlap with
 arXiv:2208.08769
MSC-class: 68P02
\\ ( https://arxiv.org/abs/2208.10917 ,  59kb)
------------------------------------------------------------------------------
\\
arXiv:2209.15266
replaced with revised version Mon, 5 Jun 2023 13:52:24 GMT   (1503kb,D)

Title: Data Poisoning Attacks Against Multimodal Encoders
Authors: Ziqing Yang and Xinlei He and Zheng Li and Michael Backes and Mathias
 Humbert and Pascal Berrang and Yang Zhang
Categories: cs.CR cs.LG
Comments: To Appear in the 40th International Conference on Machine Learning,
 July 2023
\\ ( https://arxiv.org/abs/2209.15266 ,  1503kb)
------------------------------------------------------------------------------
\\
arXiv:2210.04318 (*cross-listing*)
replaced with revised version Mon, 5 Jun 2023 09:15:49 GMT   (119kb,D)

Title: Prediction intervals for neural network models using weighted asymmetric
 loss functions
Authors: Milo Grillo, Yunpeng Han and Agnieszka Werpachowska
Categories: stat.ML cs.LG
Comments: 14 pages, 3 figures, not submitted anywhere yet
\\ ( https://arxiv.org/abs/2210.04318 ,  119kb)
------------------------------------------------------------------------------
\\
arXiv:2210.14536 (*cross-listing*)
replaced with revised version Mon, 5 Jun 2023 11:14:23 GMT   (10818kb)

Title: Position tracking of a varying number of sound sources with sliding
 permutation invariant training
Authors: David Diaz-Guerra, Archontis Politis and Tuomas Virtanen
Categories: eess.AS cs.LG cs.SD eess.SP
Comments: Accepted for publication at the 31st European Signal Processing
 Conference (EUSIPCO 2023)
\\ ( https://arxiv.org/abs/2210.14536 ,  10818kb)
------------------------------------------------------------------------------
\\
arXiv:2210.15469
replaced with revised version Mon, 5 Jun 2023 11:56:17 GMT   (2476kb,D)

Title: Learning Failure-Inducing Models for Testing Software-Defined Networks
Authors: Rapha\"el Ollando, Seung Yeob Shin, Lionel C. Briand
Categories: cs.SE cs.CR cs.LG cs.NI
\\ ( https://arxiv.org/abs/2210.15469 ,  2476kb)
------------------------------------------------------------------------------
\\
arXiv:2211.06714
replaced with revised version Sun, 4 Jun 2023 17:49:45 GMT   (22085kb,D)

Title: Bayesian Learning of Coupled Biogeochemical-Physical Models
Authors: Abhinav Gupta and Pierre F. J. Lermusiaux
Categories: cs.CE cs.LG physics.geo-ph
Comments: 45 pages; 18 figures; 2 tables
MSC-class: 86-08
ACM-class: J.2; I.6.0; I.2.6; G.3
Journal-ref: Progress in Oceanography, p.103050 (2023)
DOI: 10.1016/j.pocean.2023.103050
\\ ( https://arxiv.org/abs/2211.06714 ,  22085kb)
------------------------------------------------------------------------------
\\
arXiv:2211.15079
replaced with revised version Mon, 5 Jun 2023 13:32:19 GMT   (363kb,D)

Title: Lightweight and Flexible Deep Equilibrium Learning for CSI Feedback in
 FDD Massive MIMO
Authors: Yifan Ma, Wentao Yu, Xianghao Yu, Jun Zhang, Shenghui Song, Khaled B.
 Letaief
Categories: cs.IT cs.LG eess.SP math.IT
Comments: submitted to IEEE for possible publication
\\ ( https://arxiv.org/abs/2211.15079 ,  363kb)
------------------------------------------------------------------------------
\\
arXiv:2212.09849
replaced with revised version Mon, 5 Jun 2023 04:02:10 GMT   (643kb,D)

Title: Dataless Knowledge Fusion by Merging Weights of Language Models
Authors: Xisen Jin, Xiang Ren, Daniel Preotiuc-Pietro, Pengxiang Cheng
Categories: cs.CL cs.LG
Comments: ICLR 2023; Updated captions of Table 1. The code is available at
 https://github.com/bloomberg/dataless-model-merging
\\ ( https://arxiv.org/abs/2212.09849 ,  643kb)
------------------------------------------------------------------------------
\\
arXiv:2212.10726
replaced with revised version Sun, 4 Jun 2023 22:42:10 GMT   (287kb,D)

Title: Beyond Contrastive Learning: A Variational Generative Model for
 Multilingual Retrieval
Authors: John Wieting, Jonathan H. Clark, William W. Cohen, Graham Neubig, and
 Taylor Berg-Kirkpatrick
Categories: cs.CL cs.LG
Comments: Published as a long paper at ACL 2023
\\ ( https://arxiv.org/abs/2212.10726 ,  287kb)
------------------------------------------------------------------------------
\\
arXiv:2212.10786
replaced with revised version Mon, 5 Jun 2023 00:43:13 GMT   (7436kb,D)

Title: Multi-hop Evidence Retrieval for Cross-document Relation Extraction
Authors: Keming Lu, I-Hung Hsu, Wenxuan Zhou, Mingyu Derek Ma and Muhao Chen
Categories: cs.CL cs.IR cs.LG
Comments: ACL 2023 (Findings)
\\ ( https://arxiv.org/abs/2212.10786 ,  7436kb)
------------------------------------------------------------------------------
\\
arXiv:2301.11716
replaced with revised version Mon, 5 Jun 2023 11:44:02 GMT   (154kb,D)

Title: Pre-training for Speech Translation: CTC Meets Optimal Transport
Authors: Phuong-Hang Le, Hongyu Gong, Changhan Wang, Juan Pino, Benjamin
 Lecouteux, Didier Schwab
Categories: cs.CL cs.LG cs.SD eess.AS
Comments: ICML 2023 (oral presentation). This version fixed URLs, updated
 affiliations & acknowledgements, and improved formatting
\\ ( https://arxiv.org/abs/2301.11716 ,  154kb)
------------------------------------------------------------------------------
\\
arXiv:2301.11955 (*cross-listing*)
replaced with revised version Sat, 3 Jun 2023 07:51:34 GMT   (12283kb,D)

Title: Adaptive whitening in neural populations with gain-modulating
 interneurons
Authors: Lyndon R. Duong, David Lipshutz, David J. Heeger, Dmitri B.
 Chklovskii, Eero P. Simoncelli
Categories: q-bio.NC cs.LG eess.SP
Comments: 20 pages, 10 figures (incl. appendix). To appear in the Proceedings
 of the 40th International Conference on Machine Learning
\\ ( https://arxiv.org/abs/2301.11955 ,  12283kb)
------------------------------------------------------------------------------
\\
arXiv:2302.03026 (*cross-listing*)
replaced with revised version Fri, 2 Jun 2023 20:28:38 GMT   (2491kb,D)

Title: Sampling-Based Accuracy Testing of Posterior Estimators for General
 Inference
Authors: Pablo Lemos, Adam Coogan, Yashar Hezaveh, Laurence Perreault-Levasseur
Categories: stat.ML astro-ph.IM cs.LG stat.ME
Comments: 15 pages, Accepted at ICML 2023
\\ ( https://arxiv.org/abs/2302.03026 ,  2491kb)
------------------------------------------------------------------------------
\\
arXiv:2302.11042
replaced with revised version Mon, 5 Jun 2023 17:49:58 GMT   (2609kb,D)

Title: In-context Example Selection with Influences
Authors: Tai Nguyen and Eric Wong
Categories: cs.CL cs.LG
\\ ( https://arxiv.org/abs/2302.11042 ,  2609kb)
------------------------------------------------------------------------------
\\
arXiv:2303.08272 (*cross-listing*)
replaced with revised version Fri, 2 Jun 2023 20:39:06 GMT   (1751kb,D)

Title: Automated patent extraction powers generative modeling in focused
 chemical spaces
Authors: Akshay Subramanian, Kevin Greenman, Alexis Gervaix, Tzuhsiung Yang,
 Rafael G\'omez-Bombarelli
Categories: physics.chem-ph cs.LG
\\ ( https://arxiv.org/abs/2303.08272 ,  1751kb)
------------------------------------------------------------------------------
\\
arXiv:2303.17671 (*cross-listing*)
replaced with revised version Sun, 4 Jun 2023 12:45:08 GMT   (955kb,D)

Title: Neural signature kernels as infinite-width-depth-limits of controlled
 ResNets
Authors: Nicola Muca Cirone, Maud Lemercier, Cristopher Salvi
Categories: math.DS cs.LG math.PR
Comments: Added commutativity of limits, ICML 2023 final version
MSC-class: 60L10, 60L90
\\ ( https://arxiv.org/abs/2303.17671 ,  955kb)
------------------------------------------------------------------------------
\\
arXiv:2304.13972 (*cross-listing*)
replaced with revised version Mon, 5 Jun 2023 01:41:27 GMT   (62kb)

Title: Convergence of Adam under Relaxed Assumptions
Authors: Haochuan Li, Alexander Rakhlin, Ali Jadbabaie
Categories: math.OC cs.LG stat.ML
Comments: 33 pages
\\ ( https://arxiv.org/abs/2304.13972 ,  62kb)
------------------------------------------------------------------------------
\\
arXiv:2304.14762 (*cross-listing*)
replaced with revised version Sun, 4 Jun 2023 18:37:26 GMT   (5680kb,D)

Title: Using Perturbation to Improve Goodness-of-Fit Tests based on Kernelized
 Stein Discrepancy
Authors: Xing Liu, Andrew B. Duncan, Axel Gandy
Categories: stat.ML cs.LG stat.ME
Comments: To appear at International Conference on Machine Learning (ICML)
 2023. 21 pages, 8 figures
MSC-class: 62-08 (Primary)
ACM-class: G.3
\\ ( https://arxiv.org/abs/2304.14762 ,  5680kb)
------------------------------------------------------------------------------
\\
arXiv:2305.02522
replaced with revised version Sat, 3 Jun 2023 22:53:19 GMT   (824kb,D)

Title: BitGNN: Unleashing the Performance Potential of Binary Graph Neural
 Networks on GPUs
Authors: Jou-An Chen, Hsin-Hsuan Sung, Xipeng Shen, Sutanay Choudhury, Ang Li
Categories: cs.DC cs.LG
Comments: To appear in the International Conference on Supercomputing (ICS'23)
\\ ( https://arxiv.org/abs/2305.02522 ,  824kb)
------------------------------------------------------------------------------
\\
arXiv:2305.04560 (*cross-listing*)
replaced with revised version Mon, 5 Jun 2023 08:14:56 GMT   (145kb,D)

Title: Building Neural Networks on Matrix Manifolds: A Gyrovector Space
 Approach
Authors: Xuan Son Nguyen, Shuo Yang
Categories: stat.ML cs.LG
\\ ( https://arxiv.org/abs/2305.04560 ,  145kb)
------------------------------------------------------------------------------
\\
arXiv:2305.12347 (*cross-listing*)
replaced with revised version Sun, 4 Jun 2023 10:09:36 GMT   (17894kb,D)

Title: Learning Joint 2D & 3D Diffusion Models for Complete Molecule Generation
Authors: Han Huang, Leilei Sun, Bowen Du, Weifeng Lv
Categories: q-bio.BM cs.LG
\\ ( https://arxiv.org/abs/2305.12347 ,  17894kb)
------------------------------------------------------------------------------
\\
arXiv:2305.16583 (*cross-listing*)
replaced with revised version Sat, 3 Jun 2023 00:07:54 GMT   (382kb,D)

Title: Detecting Errors in Numerical Data via any Regression Model
Authors: Hang Zhou, Jonas Mueller, Mayank Kumar, Jane-Ling Wang and Jing Lei
Categories: stat.ML cs.LG
\\ ( https://arxiv.org/abs/2305.16583 ,  382kb)
------------------------------------------------------------------------------
\\
arXiv:2305.18394 (*cross-listing*)
replaced with revised version Sun, 4 Jun 2023 04:35:03 GMT   (921kb,D)

Title: On Optimal Regularization Parameters via Bilevel Learning
Authors: Matthias J. Ehrhardt, Silvia Gazzola and Sebastian J. Scott
 (Department of Mathematical Sciences, University of Bath, Bath, UK)
Categories: math.OC cs.LG
Comments: 26 pages, 6 figures. Fixed typos in the header and Lemma 3
MSC-class: 65K10 (Primary) 65F22 (Secondary)
\\ ( https://arxiv.org/abs/2305.18394 ,  921kb)
------------------------------------------------------------------------------
\\
arXiv:2306.00575
replaced with revised version Mon, 5 Jun 2023 08:15:10 GMT   (874kb,D)

Title: Predicting Temporal Aspects of Movement for Predictive Replication in
 Fog Environments
Authors: Emil Balitzki and Tobias Pfandzelter and David Bermbach
Categories: cs.DC cs.LG
\\ ( https://arxiv.org/abs/2306.00575 ,  874kb)
------------------------------------------------------------------------------
\\
arXiv:2207.00823
replaced with revised version Mon, 5 Jun 2023 12:35:22 GMT   (32kb)

Title: Communication Pattern Logic: Epistemic and Topological Views
Authors: Armando Casta\~neda and Hans van Ditmarsch and David A. Rosenblueth
 and Diego A. Vel\'azquez
Categories: cs.DC cs.MA
\\ ( https://arxiv.org/abs/2207.00823 ,  32kb)
------------------------------------------------------------------------------
\\
arXiv:2211.06187 (*cross-listing*)
replaced with revised version Sat, 3 Jun 2023 10:14:11 GMT   (265kb,D)

Title: Performance Bounds of Model Predictive Control for Unconstrained and
 Constrained Linear Quadratic Problems and Beyond
Authors: Yuchao Li, Aren Karapetyan, John Lygeros, Karl H. Johansson, Jonas
 M{\aa}rtensson
Categories: math.OC cs.SY eess.SY
\\ ( https://arxiv.org/abs/2211.06187 ,  265kb)
------------------------------------------------------------------------------
\\
arXiv:2302.05416 (*cross-listing*)
replaced with revised version Mon, 5 Jun 2023 01:03:21 GMT   (1172kb,D)

Title: Approximate Dynamic Programming for a Mean-field Game of Traffic Flow:
 Existence and Uniqueness
Authors: Amoolya Tirumalai and John S. Baras
Categories: math.OC cs.SY eess.SY
Comments: 42 pages, 5 figures
\\ ( https://arxiv.org/abs/2302.05416 ,  1172kb)
%%%---%%%---%%%---%%%---%%%---%%%---%%%---%%%---%%%---%%%---%%%---%%%---%%%---