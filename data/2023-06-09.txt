------------------------------------------------------------------------------
------------------------------------------------------------------------------
Send any comments regarding submissions directly to submitter.
------------------------------------------------------------------------------
Archives at http://arxiv.org/
To unsubscribe, e-mail To: cs@arXiv.org, Subject: cancel
------------------------------------------------------------------------------
Submissions to:
Artificial Intelligence
Computer Vision and Pattern Recognition
Distributed, Parallel, and Cluster Computing
Computer Science and Game Theory
Machine Learning
Multiagent Systems
Robotics
Systems and Control
received from  Wed  7 Jun 23 18:00:00 GMT  to  Thu  8 Jun 23 18:00:00 GMT
------------------------------------------------------------------------------
------------------------------------------------------------------------------
\\
arXiv:2306.04750
Date: Wed, 7 Jun 2023 19:57:07 GMT   (598kb,D)

Title: AutoML Systems For Medical Imaging
Authors: Tasmia Tahmida Jidney, Angona Biswas, MD Abdullah Al Nasim, Ismail
 Hossain, Md Jahangir Alam, Sajedul Talukder, Mofazzal Hossain, Dr. Md Azim
 Ullah
Categories: cs.AI
Comments: 11 pages, 4 figures; Acceptance of the chapter for the Springer book
 "Data-driven approaches to medical imaging"
\\
 The integration of machine learning in medical image analysis can greatly
enhance the quality of healthcare provided by physicians. The combination of
human expertise and computerized systems can result in improved diagnostic
accuracy. An automated machine learning approach simplifies the creation of
custom image recognition models by utilizing neural architecture search and
transfer learning techniques. Medical imaging techniques are used to
non-invasively create images of internal organs and body parts for diagnostic
and procedural purposes. This article aims to highlight the potential
applications, strategies, and techniques of AutoML in medical imaging through
theoretical and empirical evidence.
\\ ( https://arxiv.org/abs/2306.04750 ,  598kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04765
Date: Wed, 7 Jun 2023 20:24:43 GMT   (1363kb,D)

Title: The HCI Aspects of Public Deployment of Research Chatbots: A User Study,
 Design Recommendations, and Open Challenges
Authors: Morteza Behrooz, William Ngan, Joshua Lane, Giuliano Morse, Benjamin
 Babcock, Kurt Shuster, Mojtaba Komeili, Moya Chen, Melanie Kambadur, Y-Lan
 Boureau, Jason Weston
Categories: cs.AI cs.CL
\\
 Publicly deploying research chatbots is a nuanced topic involving necessary
risk-benefit analyses. While there have recently been frequent discussions on
whether it is responsible to deploy such models, there has been far less focus
on the interaction paradigms and design approaches that the resulting
interfaces should adopt, in order to achieve their goals more effectively. We
aim to pose, ground, and attempt to answer HCI questions involved in this
scope, by reporting on a mixed-methods user study conducted on a recent
research chatbot. We find that abstract anthropomorphic representation for the
agent has a significant effect on user's perception, that offering AI
explainability may have an impact on feedback rates, and that two (diegetic and
extradiegetic) levels of the chat experience should be intentionally designed.
We offer design recommendations and areas of further focus for the research
community.
\\ ( https://arxiv.org/abs/2306.04765 ,  1363kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04792
Date: Wed, 7 Jun 2023 21:29:49 GMT   (13kb)

Title: On the Use of Generative Models in Observational Causal Analysis
Authors: Nimrod Megiddo
Categories: cs.AI
\\
 The use of a hypothetical generative model was been suggested for causal
analysis of observational data. The very assumption of a particular model is a
commitment to a certain set of variables and therefore to a certain set of
possible causes. Estimating the joint probability distribution of can be useful
for predicting values of variables in view of the observed values of others,
but it is not sufficient for inferring causal relationships. The model
describes a single observable distribution and cannot a chain of effects of
intervention that deviate from the observed distribution.
\\ ( https://arxiv.org/abs/2306.04792 ,  13kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04802
Date: Wed, 7 Jun 2023 21:51:56 GMT   (64kb)

Title: A Survey on Knowledge Graphs for Healthcare: Resources, Applications,
 and Promises
Authors: Hejie Cui, Jiaying Lu, Shiyu Wang, Ran Xu, Wenjing Ma, Shaojun Yu, Yue
 Yu, Xuan Kan, Chen Ling, Joyce Ho, Fei Wang, Carl Yang
Categories: cs.AI cs.CL cs.LG cs.SI
\\
 Healthcare knowledge graphs (HKGs) have emerged as a promising tool for
organizing medical knowledge in a structured and interpretable way, which
provides a comprehensive view of medical concepts and their relationships.
However, challenges such as data heterogeneity and limited coverage remain,
emphasizing the need for further research in the field of HKGs. This survey
paper serves as the first comprehensive overview of HKGs. We summarize the
pipeline and key techniques for HKG construction (i.e., from scratch and
through integration), as well as the common utilization approaches (i.e.,
model-free and model-based). To provide researchers with valuable resources, we
organize existing HKGs (The resource is available at
https://github.com/lujiaying/Awesome-HealthCare-KnowledgeBase) based on the
data types they capture and application domains, supplemented with pertinent
statistical information. In the application section, we delve into the
transformative impact of HKGs across various healthcare domains, spanning from
fine-grained basic science research to high-level clinical decision support.
Lastly, we shed light on the opportunities for creating comprehensive and
accurate HKGs in the era of large language models, presenting the potential to
revolutionize healthcare delivery and enhance the interpretability and
reliability of clinical prediction.
\\ ( https://arxiv.org/abs/2306.04802 ,  64kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04806
Date: Wed, 7 Jun 2023 22:05:48 GMT   (1717kb,D)

Title: Autonomous Capability Assessment of Black-Box Sequential Decision-Making
 Systems
Authors: Pulkit Verma, Rushang Karia, Siddharth Srivastava
Categories: cs.AI
Comments: ICAPS 2023 Workshop on Knowledge Engineering for Planning and
 Scheduling
\\
 It is essential for users to understand what their AI systems can and can't
do in order to use them safely. However, the problem of enabling users to
assess AI systems with evolving sequential decision making (SDM) capabilities
is relatively understudied. This paper presents a new approach for modeling the
capabilities of black-box AI systems that can plan and act, along with the
possible effects and requirements for executing those capabilities in
stochastic settings. We present an active-learning approach that can
effectively interact with a black-box SDM system and learn an interpretable
probabilistic model describing its capabilities. Theoretical analysis of the
approach identifies the conditions under which the learning process is
guaranteed to converge to the correct model of the agent; empirical evaluations
on different agents and simulated scenarios show that this approach is few-shot
generalizable and can effectively describe the capabilities of arbitrary
black-box SDM agents in a sample-efficient manner.
\\ ( https://arxiv.org/abs/2306.04806 ,  1717kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04813
Date: Wed, 7 Jun 2023 22:30:27 GMT   (4343kb,D)

Title: Human in the Loop Novelty Generation
Authors: Mark Bercasio, Allison Wong, Dustin Dannenhauer
Categories: cs.AI
\\
 Developing artificial intelligence approaches to overcome novel, unexpected
circumstances is a difficult, unsolved problem. One challenge to advancing the
state of the art in novelty accommodation is the availability of testing
frameworks for evaluating performance against novel situations. Recent novelty
generation approaches in domains such as Science Birds and Monopoly leverage
human domain expertise during the search to discover new novelties. Such
approaches introduce human guidance before novelty generation occurs and yield
novelties that can be directly loaded into a simulated environment. We
introduce a new approach to novelty generation that uses abstract models of
environments (including simulation domains) that do not require
domain-dependent human guidance to generate novelties. A key result is a
larger, often infinite space of novelties capable of being generated, with the
trade-off being a requirement to involve human guidance to select and filter
novelties post generation. We describe our Human-in-the-Loop novelty generation
process using our open-source novelty generation library to test baseline
agents in two domains: Monopoly and VizDoom. Our results shows the
Human-in-the-Loop method enables users to develop, implement, test, and revise
novelties within 4 hours for both Monopoly and VizDoom domains.
\\ ( https://arxiv.org/abs/2306.04813 ,  4343kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04814
Date: Wed, 7 Jun 2023 22:35:39 GMT   (41kb)

Title: Revisiting Inferential Benchmarks for Knowledge Graph Completion
Authors: Shuwen Liu, Bernardo Cuenca Grau, Ian Horrocks, Egor V. Kostylev
Categories: cs.AI
Comments: Accepted by the 20th International Conference on Principles of
 Knowledge Representation and Reasoning (KR 2023)
\\
 Knowledge Graph (KG) completion is the problem of extending an incomplete KG
with missing facts. A key feature of Machine Learning approaches for KG
completion is their ability to learn inference patterns, so that the predicted
facts are the results of applying these patterns to the KG. Standard completion
benchmarks, however, are not well-suited for evaluating models' abilities to
learn patterns, because the training and test sets of these benchmarks are a
random split of a given KG and hence do not capture the causality of inference
patterns. We propose a novel approach for designing KG completion benchmarks
based on the following principles: there is a set of logical rules so that the
missing facts are the results of the rules' application; the training set
includes both premises matching rule antecedents and the corresponding
conclusions; the test set consists of the results of applying the rules to the
training set; the negative examples are designed to discourage the models from
learning rules not entailed by the rule set. We use our methodology to generate
several benchmarks and evaluate a wide range of existing KG completion systems.
Our results provide novel insights on the ability of existing models to induce
inference patterns from incomplete KGs.
\\ ( https://arxiv.org/abs/2306.04814 ,  41kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04887
Date: Thu, 8 Jun 2023 02:30:55 GMT   (1003kb)

Title: Big-data-driven and AI-based framework to enable personalization in
 wireless networks
Authors: Rawan Alkurd, Ibrahim Abualhaol, and Halim Yanikomeroglu
Categories: cs.AI cs.NI
Journal-ref: IEEE Communications Magazine ( Volume: 58, Issue: 3, March 2020)
\\
 Current communication networks use design methodologies that prevent the
realization of maximum network efficiency. In the first place, while users'
perception of satisfactory service diverges widely, current networks are
designed to be a "universal fit," where they are generally over-engineered to
deliver services appealing to all types of users. Also, current networks lack
user-level data cognitive intelligence that would enable fast personalized
network decisions and actions through automation. Thus, in this article, we
propose the utilization of AI, big data analytics, and real-time non-intrusive
user feedback in order to enable the personalization of wireless networks.
Based on each user's actual QoS requirements and context, a multi-objective
formulation enables the network to micro-manage and optimize the provided QoS
and user satisfaction levels simultaneously. Moreover, in order to enable user
feedback tracking and measurement, we propose a user satisfaction model based
on the zone of tolerance concept. Furthermore, we propose a big-data-driven and
AI-based personalization framework to integrate personalization into wireless
networks. Finally, we implement a personalized network prototype to demonstrate
the proposed personalization concept and its potential benefits through a case
study. The case study shows how personalization can be realized to enable the
efficient optimization of network resources such that certain requirement
levels of user satisfaction and revenue in the form of saved resources are
achieved.
\\ ( https://arxiv.org/abs/2306.04887 ,  1003kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04962
Date: Thu, 8 Jun 2023 06:37:04 GMT   (197kb,D)

Title: arXiv4TGC: Large-Scale Datasets for Temporal Graph Clustering
Authors: Meng Liu, Ke Liang, Yue Liu, Siwei Wang, Sihang Zhou, Xinwang Liu
Categories: cs.AI cs.LG
\\
 Temporal graph clustering (TGC) is a crucial task in temporal graph learning.
Its focus is on node clustering on temporal graphs, and it offers greater
flexibility for large-scale graph structures due to the mechanism of temporal
graph methods. However, the development of TGC is currently constrained by a
significant problem: the lack of suitable and reliable large-scale temporal
graph datasets to evaluate clustering performance. In other words, most
existing temporal graph datasets are in small sizes, and even large-scale
datasets contain only a limited number of available node labels. It makes
evaluating models for large-scale temporal graph clustering challenging. To
address this challenge, we build arXiv4TGC, a set of novel academic datasets
(including arXivAI, arXivCS, arXivMath, arXivPhy, and arXivLarge) for
large-scale temporal graph clustering. In particular, the largest dataset,
arXivLarge, contains 1.3 million labeled available nodes and 10 million
temporal edges. We further compare the clustering performance with typical
temporal graph learning models on both previous classic temporal graph datasets
and the new datasets proposed in this paper. The clustering performance on
arXiv4TGC can be more apparent for evaluating different models, resulting in
higher clustering confidence and more suitable for large-scale temporal graph
clustering. The arXiv4TGC datasets are publicly available at:
https://github.com/MGitHubL/arXiv4TGC.
\\ ( https://arxiv.org/abs/2306.04962 ,  197kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05003
Date: Thu, 8 Jun 2023 07:47:18 GMT   (642kb,D)

Title: A Rapid Review of Responsible AI frameworks: How to guide the
 development of ethical AI
Authors: Vita Santa Barletta, Danilo Caivano, Domenico Gigante and Azzurra
 Ragone
Categories: cs.AI
Journal-ref: Proceedings of the International Conference on Evaluation and
 Assessment in Software Engineering (EASE '23), June 14--16, 2023, Oulu,
 Finland
DOI: 10.1145/3593434.3593478
\\
 In the last years, the raise of Artificial Intelligence (AI), and its
pervasiveness in our lives, has sparked a flourishing debate about the ethical
principles that should lead its implementation and use in society. Driven by
these concerns, we conduct a rapid review of several frameworks providing
principles, guidelines, and/or tools to help practitioners in the development
and deployment of Responsible AI (RAI) applications. We map each framework
w.r.t. the different Software Development Life Cycle (SDLC) phases discovering
that most of these frameworks fall just in the Requirements Elicitation phase,
leaving the other phases uncovered. Very few of these frameworks offer
supporting tools for practitioners, and they are mainly provided by private
companies. Our results reveal that there is not a "catching-all" framework
supporting both technical and non-technical stakeholders in the implementation
of real-world projects. Our findings highlight the lack of a comprehensive
framework encompassing all RAI principles and all (SDLC) phases that could be
navigated by users with different skill sets and with different goals.
\\ ( https://arxiv.org/abs/2306.05003 ,  642kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05016
Date: Thu, 8 Jun 2023 08:10:46 GMT   (7001kb,D)

Title: Progression Cognition Reinforcement Learning with Prioritized Experience
 for Multi-Vehicle Pursuit
Authors: Xinhang Li, Yiying Yang, Zheng Yuan, Zhe Wang, Qinwen Wang, Chen Xu,
 Lei Li, Jianhua He and Lin Zhang
Categories: cs.AI
\\
 Multi-vehicle pursuit (MVP) such as autonomous police vehicles pursuing
suspects is important but very challenging due to its mission and safety
critical nature. While multi-agent reinforcement learning (MARL) algorithms
have been proposed for MVP problem in structured grid-pattern roads, the
existing algorithms use randomly training samples in centralized learning,
which leads to homogeneous agents showing low collaboration performance. For
the more challenging problem of pursuing multiple evading vehicles, these
algorithms typically select a fixed target evading vehicle for pursuing
vehicles without considering dynamic traffic situation, which significantly
reduces pursuing success rate. To address the above problems, this paper
proposes a Progression Cognition Reinforcement Learning with Prioritized
Experience for MVP (PEPCRL-MVP) in urban multi-intersection dynamic traffic
scenes. PEPCRL-MVP uses a prioritization network to assess the transitions in
the global experience replay buffer according to the parameters of each MARL
agent. With the personalized and prioritized experience set selected via the
prioritization network, diversity is introduced to the learning process of
MARL, which can improve collaboration and task related performance.
Furthermore, PEPCRL-MVP employs an attention module to extract critical
features from complex urban traffic environments. These features are used to
develop progression cognition method to adaptively group pursuing vehicles.
Each group efficiently target one evading vehicle in dynamic driving
environments. Extensive experiments conducted with a simulator over
unstructured roads of an urban area show that PEPCRL-MVP is superior to other
state-of-the-art methods. Specifically, PEPCRL-MVP improves pursuing efficiency
by 3.95% over TD3-DMAP and its success rate is 34.78% higher than that of
MADDPG. Codes are open sourced.
\\ ( https://arxiv.org/abs/2306.05016 ,  7001kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05066
Date: Thu, 8 Jun 2023 09:31:18 GMT   (1563kb,D)

Title: Causal Fairness for Outcome Control
Authors: Drago Plecko, Elias Bareinboim
Categories: cs.AI cs.LG stat.ML
\\
 As society transitions towards an AI-based decision-making infrastructure, an
ever-increasing number of decisions once under control of humans are now
delegated to automated systems. Even though such developments make various
parts of society more efficient, a large body of evidence suggests that a great
deal of care needs to be taken to make such automated decision-making systems
fair and equitable, namely, taking into account sensitive attributes such as
gender, race, and religion. In this paper, we study a specific decision-making
task called outcome control in which an automated system aims to optimize an
outcome variable $Y$ while being fair and equitable. The interest in such a
setting ranges from interventions related to criminal justice and welfare, all
the way to clinical decision-making and public health. In this paper, we first
analyze through causal lenses the notion of benefit, which captures how much a
specific individual would benefit from a positive decision, counterfactually
speaking, when contrasted with an alternative, negative one. We introduce the
notion of benefit fairness, which can be seen as the minimal fairness
requirement in decision-making, and develop an algorithm for satisfying it. We
then note that the benefit itself may be influenced by the protected attribute,
and propose causal tools which can be used to analyze this. Finally, if some of
the variations of the protected attribute in the benefit are considered as
discriminatory, the notion of benefit fairness may need to be strengthened,
which leads us to articulating a notion of causal benefit fairness. Using this
notion, we develop a new optimization procedure capable of maximizing $Y$ while
ascertaining causal fairness in the decision process.
\\ ( https://arxiv.org/abs/2306.05066 ,  1563kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05069
Date: Thu, 8 Jun 2023 09:34:38 GMT   (74kb,D)

Title: Capturing (Optimal) Relaxed Plans with Stable and Supported Models of
 Logic Programs
Authors: Masood Feyzbakhsh Rankooh and Tomi Janhunen
Categories: cs.AI
Comments: Paper presented at the 39th International Conference on Logic
 Programming (ICLP 2023), 14 pages
\\
 We establish a novel relation between delete-free planning, an important task
for the AI Planning community also known as relaxed planning, and logic
programming. We show that given a planning problem, all subsets of actions that
could be ordered to produce relaxed plans for the problem can be bijectively
captured with stable models of a logic program describing the corresponding
relaxed planning problem. We also consider the supported model semantics of
logic programs, and introduce one causal and one diagnostic encoding of the
relaxed planning problem as logic programs, both capturing relaxed plans with
their supported models. Our experimental results show that these new encodings
can provide major performance gain when computing optimal relaxed plans, with
our diagnostic encoding outperforming state-of-the-art approaches to relaxed
planning regardless of the given time limit when measured on a wide collection
of STRIPS planning benchmarks.
\\ ( https://arxiv.org/abs/2306.05069 ,  74kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05082
Date: Thu, 8 Jun 2023 10:20:08 GMT   (947kb,D)

Title: The Importance of Time in Causal Algorithmic Recourse
Authors: Isacco Beretta and Martina Cinquini
Categories: cs.AI cs.LG
Comments: Accepted for xAI Conference 2023
\\
 The application of Algorithmic Recourse in decision-making is a promising
field that offers practical solutions to reverse unfavorable decisions.
However, the inability of these methods to consider potential dependencies
among variables poses a significant challenge due to the assumption of feature
independence. Recent advancements have incorporated knowledge of causal
dependencies, thereby enhancing the quality of the recommended recourse
actions. Despite these improvements, the inability to incorporate the temporal
dimension remains a significant limitation of these approaches. This is
particularly problematic as identifying and addressing the root causes of
undesired outcomes requires understanding time-dependent relationships between
variables. In this work, we motivate the need to integrate the temporal
dimension into causal algorithmic recourse methods to enhance recommendations'
plausibility and reliability. The experimental evaluation highlights the
significance of the role of time in this field.
\\ ( https://arxiv.org/abs/2306.05082 ,  947kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05112
Date: Thu, 8 Jun 2023 11:20:00 GMT   (2934kb,D)

Title: FheFL: Fully Homomorphic Encryption Friendly Privacy-Preserving
 Federated Learning with Byzantine Users
Authors: Yogachandran Rahulamathavan, Charuka Herath, Xiaolan Liu,
 Sangarapillai Lambotharan and Carsten Maple
Categories: cs.AI cs.CR
\\
 The federated learning (FL) technique was initially developed to mitigate
data privacy issues that can arise in the traditional machine learning
paradigm. While FL ensures that a user's data always remain with the user, the
gradients of the locally trained models must be communicated with the
centralized server to build the global model. This results in privacy leakage,
where the server can infer private information of the users' data from the
shared gradients. To mitigate this flaw, the next-generation FL architectures
proposed encryption and anonymization techniques to protect the model updates
from the server. However, this approach creates other challenges, such as a
malicious user might sabotage the global model by sharing false gradients.
Since the gradients are encrypted, the server is unable to identify and
eliminate rogue users which would protect the global model. Therefore, to
mitigate both attacks, this paper proposes a novel fully homomorphic encryption
(FHE) based scheme suitable for FL. We modify the one-to-one single-key
Cheon-Kim-Kim-Song (CKKS)-based FHE scheme into a distributed multi-key
additive homomorphic encryption scheme that supports model aggregation in FL.
We employ a novel aggregation scheme within the encrypted domain, utilizing
users' non-poisoning rates, to effectively address data poisoning attacks while
ensuring privacy is preserved by the proposed encryption scheme. Rigorous
security, privacy, convergence, and experimental analyses have been provided to
show that FheFL is novel, secure, and private, and achieves comparable accuracy
at reasonable computational cost.
\\ ( https://arxiv.org/abs/2306.05112 ,  2934kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05120
Date: Thu, 8 Jun 2023 11:42:47 GMT   (1385kb,D)

Title: Explainable Predictive Maintenance
Authors: Sepideh Pashami, Slawomir Nowaczyk, Yuantao Fan, Jakub Jakubowski,
 Nuno Paiva, Narjes Davari, Szymon Bobek, Samaneh Jamshidi, Hamid Sarmadi,
 Abdallah Alabdallah, Rita P. Ribeiro, Bruno Veloso, Moamar Sayed-Mouchaweh,
 Lala Rajaoarisoa, Grzegorz J. Nalepa, Jo\~ao Gama
Categories: cs.AI
Comments: 51 pages, 9 figures
ACM-class: I.2.1
\\
 Explainable Artificial Intelligence (XAI) fills the role of a critical
interface fostering interactions between sophisticated intelligent systems and
diverse individuals, including data scientists, domain experts, end-users, and
more. It aids in deciphering the intricate internal mechanisms of ``black box''
Machine Learning (ML), rendering the reasons behind their decisions more
understandable. However, current research in XAI primarily focuses on two
aspects; ways to facilitate user trust, or to debug and refine the ML model.
The majority of it falls short of recognising the diverse types of explanations
needed in broader contexts, as different users and varied application areas
necessitate solutions tailored to their specific needs.
 One such domain is Predictive Maintenance (PdM), an exploding area of
research under the Industry 4.0 \& 5.0 umbrella. This position paper highlights
the gap between existing XAI methodologies and the specific requirements for
explanations within industrial applications, particularly the Predictive
Maintenance field. Despite explainability's crucial role, this subject remains
a relatively under-explored area, making this paper a pioneering attempt to
bring relevant challenges to the research community's attention. We provide an
overview of predictive maintenance tasks and accentuate the need and varying
purposes for corresponding explanations. We then list and describe XAI
techniques commonly employed in the literature, discussing their suitability
for PdM tasks. Finally, to make the ideas and claims more concrete, we
demonstrate XAI applied in four specific industrial use cases: commercial
vehicles, metro trains, steel plants, and wind farms, spotlighting areas
requiring further research.
\\ ( https://arxiv.org/abs/2306.05120 ,  1385kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05138
Date: Thu, 8 Jun 2023 12:04:52 GMT   (6771kb,D)

Title: Gradient-Informed Quality Diversity for the Illumination of Discrete
 Spaces
Authors: Raphael Boige, Guillaume Richard, J\'er\'emie Dona, Thomas Pierrot,
 Antoine Cully
Categories: cs.AI
\\
 Quality Diversity (QD) algorithms have been proposed to search for a large
collection of both diverse and high-performing solutions instead of a single
set of local optima. While early QD algorithms view the objective and
descriptor functions as black-box functions, novel tools have been introduced
to use gradient information to accelerate the search and improve overall
performance of those algorithms over continuous input spaces. However a broad
range of applications involve discrete spaces, such as drug discovery or image
generation. Exploring those spaces is challenging as they are combinatorially
large and gradients cannot be used in the same manner as in continuous spaces.
We introduce map-elites with a Gradient-Informed Discrete Emitter (ME-GIDE),
which extends QD optimisation with differentiable functions over discrete
search spaces. ME-GIDE leverages the gradient information of the objective and
descriptor functions with respect to its discrete inputs to propose
gradient-informed updates that guide the search towards a diverse set of high
quality solutions. We evaluate our method on challenging benchmarks including
protein design and discrete latent space illumination and find that our method
outperforms state-of-the-art QD algorithms in all benchmarks.
\\ ( https://arxiv.org/abs/2306.05138 ,  6771kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05298
Date: Thu, 8 Jun 2023 15:42:56 GMT   (565kb,D)

Title: Habits of Mind: Reusing Action Sequences for Efficient Planning
Authors: No\'emi \'Eltet\H{o} and Peter Dayan
Categories: cs.AI
\\
 When we exercise sequences of actions, their execution becomes more fluent
and precise. Here, we consider the possibility that exercised action sequences
can also be used to make planning faster and more accurate by focusing
expansion of the search tree on paths that have been frequently used in the
past, and by reducing deep planning problems to shallow ones via multi-step
jumps in the tree. To capture such sequences, we use a flexible Bayesian action
chunking mechanism which finds and exploits statistically reliable structure at
different scales. This gives rise to shorter or longer routines that can be
embedded into a Monte-Carlo tree search planner. We show the benefits of this
scheme using a physical construction task patterned after tangrams.
\\ ( https://arxiv.org/abs/2306.05298 ,  565kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05331
Date: Thu, 8 Jun 2023 16:31:47 GMT   (3232kb,D)

Title: Actively learning a Bayesian matrix fusion model with deep side
 information
Authors: Yangyang Yu, Jordan W. Suchow
Categories: cs.AI cs.CE
\\
 High-dimensional deep neural network representations of images and concepts
can be aligned to predict human annotations of diverse stimuli. However, such
alignment requires the costly collection of behavioral responses, such that, in
practice, the deep-feature spaces are only ever sparsely sampled. Here, we
propose an active learning approach to adaptively sampling experimental stimuli
to efficiently learn a Bayesian matrix factorization model with deep side
information. We observe a significant efficiency gain over a passive baseline.
Furthermore, with a sequential batched sampling strategy, the algorithm is
applicable not only to small datasets collected from traditional laboratory
experiments but also to settings where large-scale crowdsourced data collection
is needed to accurately align the high-dimensional deep feature representations
derived from pre-trained networks.
\\ ( https://arxiv.org/abs/2306.05331 ,  3232kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05353
Date: Thu, 8 Jun 2023 16:57:12 GMT   (5474kb,D)

Title: Negotiated Reasoning: On Provably Addressing Relative
 Over-Generalization
Authors: Junjie Sheng, Wenhao Li, Bo Jin, Hongyuan Zha, Jun Wang, Xiangfeng
 Wang
Categories: cs.AI cs.MA
Comments: 21 pages
\\
 Over-generalization is a thorny issue in cognitive science, where people may
become overly cautious due to past experiences. Agents in multi-agent
reinforcement learning (MARL) also have been found to suffer relative
over-generalization (RO) as people do and stuck to sub-optimal cooperation.
Recent methods have shown that assigning reasoning ability to agents can
mitigate RO algorithmically and empirically, but there has been a lack of
theoretical understanding of RO, let alone designing provably RO-free methods.
This paper first proves that RO can be avoided when the MARL method satisfies a
consistent reasoning requirement under certain conditions. Then we introduce a
novel reasoning framework, called negotiated reasoning, that first builds the
connection between reasoning and RO with theoretical justifications. After
that, we propose an instantiated algorithm, Stein variational negotiated
reasoning (SVNR), which uses Stein variational gradient descent to derive a
negotiation policy that provably avoids RO in MARL under maximum entropy policy
iteration. The method is further parameterized with neural networks for
amortized learning, making computation efficient. Numerical experiments on many
RO-challenged environments demonstrate the superiority and efficiency of SVNR
compared to state-of-the-art methods in addressing RO.
\\ ( https://arxiv.org/abs/2306.05353 ,  5474kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04641
Date: Thu, 25 May 2023 08:24:22 GMT   (6669kb,D)

Title: Generalizable Low-Resource Activity Recognition with Diverse and
 Discriminative Representation Learning
Authors: Xin Qin, Jindong Wang, Shuo Ma, Wang Lu, Yongchun Zhu, Xing Xie,
 Yiqiang Chen
Categories: cs.CV cs.AI cs.LG
Comments: Accepted by SIGKDD 2023 Research track; 12 pages
\\
 Human activity recognition (HAR) is a time series classification task that
focuses on identifying the motion patterns from human sensor readings. Adequate
data is essential but a major bottleneck for training a generalizable HAR
model, which assists customization and optimization of online web applications.
However, it is costly in time and economy to collect large-scale labeled data
in reality, i.e., the low-resource challenge. Meanwhile, data collected from
different persons have distribution shifts due to different living habits, body
shapes, age groups, etc. The low-resource and distribution shift challenges are
detrimental to HAR when applying the trained model to new unseen subjects. In
this paper, we propose a novel approach called Diverse and Discriminative
representation Learning (DDLearn) for generalizable low-resource HAR. DDLearn
simultaneously considers diversity and discrimination learning. With the
constructed self-supervised learning task, DDLearn enlarges the data diversity
and explores the latent activity properties. Then, we propose a diversity
preservation module to preserve the diversity of learned features by enlarging
the distribution divergence between the original and augmented domains.
Meanwhile, DDLearn also enhances semantic discrimination by learning
discriminative representations with supervised contrastive learning. Extensive
experiments on three public HAR datasets demonstrate that our method
significantly outperforms state-of-art methods by an average accuracy
improvement of 9.5% under the low-resource distribution shift scenarios, while
being a generic, explainable, and flexible framework.
\\ ( https://arxiv.org/abs/2306.04641 ,  6669kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04644
Date: Sat, 27 May 2023 14:33:01 GMT   (2679kb,D)

Title: Decom--CAM: Tell Me What You See, In Details! Feature-Level
 Interpretation via Decomposition Class Activation Map
Authors: Yuguang Yang, Runtang Guo, Sheng Wu, Yimi Wang, Juan Zhang, Xuan Gong,
 Baochang Zhang
Categories: cs.CV cs.AI
\\
 Interpretation of deep learning remains a very challenging problem. Although
the Class Activation Map (CAM) is widely used to interpret deep model
predictions by highlighting object location, it fails to provide insight into
the salient features used by the model to make decisions. Furthermore, existing
evaluation protocols often overlook the correlation between interpretability
performance and the model's decision quality, which presents a more fundamental
issue. This paper proposes a new two-stage interpretability method called the
Decomposition Class Activation Map (Decom-CAM), which offers a feature-level
interpretation of the model's prediction. Decom-CAM decomposes intermediate
activation maps into orthogonal features using singular value decomposition and
generates saliency maps by integrating them. The orthogonality of features
enables CAM to capture local features and can be used to pinpoint semantic
components such as eyes, noses, and faces in the input image, making it more
beneficial for deep model interpretation. To ensure a comprehensive comparison,
we introduce a new evaluation protocol by dividing the dataset into subsets
based on classification accuracy results and evaluating the interpretability
performance on each subset separately. Our experiments demonstrate that the
proposed Decom-CAM outperforms current state-of-the-art methods significantly
by generating more precise saliency maps across all levels of classification
accuracy. Combined with our feature-level interpretability approach, this paper
could pave the way for a new direction for understanding the decision-making
process of deep neural networks.
\\ ( https://arxiv.org/abs/2306.04644 ,  2679kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04650
Date: Tue, 6 Jun 2023 07:24:53 GMT   (2686kb,D)

Title: GaitMPL: Gait Recognition with Memory-Augmented Progressive Learning
Authors: Huanzhang Dou, Pengyi Zhang, Yuhan Zhao, Lin Dong, Zequn Qin, Xi Li
Categories: cs.CV
Comments: Accepted by TIP2022
\\
 Gait recognition aims at identifying the pedestrians at a long distance by
their biometric gait patterns. It is inherently challenging due to the various
covariates and the properties of silhouettes (textureless and colorless), which
result in two kinds of pair-wise hard samples: the same pedestrian could have
distinct silhouettes (intra-class diversity) and different pedestrians could
have similar silhouettes (inter-class similarity). In this work, we propose to
solve the hard sample issue with a Memory-augmented Progressive Learning
network (GaitMPL), including Dynamic Reweighting Progressive Learning module
(DRPL) and Global Structure-Aligned Memory bank (GSAM). Specifically, DRPL
reduces the learning difficulty of hard samples by easy-to-hard progressive
learning. GSAM further augments DRPL with a structure-aligned memory mechanism,
which maintains and models the feature distribution of each ID. Experiments on
two commonly used datasets, CASIA-B and OU-MVLP, demonstrate the effectiveness
of GaitMPL. On CASIA-B, we achieve the state-of-the-art performance, i.e.,
88.0% on the most challenging condition (Clothing) and 93.3% on the average
condition, which outperforms the other methods by at least 3.8% and 1.4%,
respectively.
\\ ( https://arxiv.org/abs/2306.04650 ,  2686kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04652
Date: Tue, 6 Jun 2023 08:26:22 GMT   (985kb,D)

Title: Language Adaptive Weight Generation for Multi-task Visual Grounding
Authors: Wei Su, Peihan Miao, Huanzhang Dou, Gaoang Wang, Liang Qiao, Zheyang
 Li, and Xi Li
Categories: cs.CV
Comments: Accepted by CVPR2023
\\
 Although the impressive performance in visual grounding, the prevailing
approaches usually exploit the visual backbone in a passive way, i.e., the
visual backbone extracts features with fixed weights without expression-related
hints. The passive perception may lead to mismatches (e.g., redundant and
missing), limiting further performance improvement. Ideally, the visual
backbone should actively extract visual features since the expressions already
provide the blueprint of desired visual features. The active perception can
take expressions as priors to extract relevant visual features, which can
effectively alleviate the mismatches. Inspired by this, we propose an active
perception Visual Grounding framework based on Language Adaptive Weights,
called VG-LAW. The visual backbone serves as an expression-specific feature
extractor through dynamic weights generated for various expressions. Benefiting
from the specific and relevant visual features extracted from the
language-aware visual backbone, VG-LAW does not require additional modules for
cross-modal interaction. Along with a neat multi-task head, VG-LAW can be
competent in referring expression comprehension and segmentation jointly.
Extensive experiments on four representative datasets, i.e., RefCOCO, RefCOCO+,
RefCOCOg, and ReferItGame, validate the effectiveness of the proposed framework
and demonstrate state-of-the-art performance.
\\ ( https://arxiv.org/abs/2306.04652 ,  985kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04654
Date: Tue, 6 Jun 2023 15:04:45 GMT   (5938kb,D)

Title: DenseDINO: Boosting Dense Self-Supervised Learning with Token-Based
 Point-Level Consistency
Authors: Yike Yuan, Xinghe Fu, Yunlong Yu, Xi Li
Categories: cs.CV
Comments: IJCAI 2023 accepted
\\
 In this paper, we propose a simple yet effective transformer framework for
self-supervised learning called DenseDINO to learn dense visual
representations. To exploit the spatial information that the dense prediction
tasks require but neglected by the existing self-supervised transformers, we
introduce point-level supervision across views in a novel token-based way.
Specifically, DenseDINO introduces some extra input tokens called reference
tokens to match the point-level features with the position prior. With the
reference token, the model could maintain spatial consistency and deal with
multi-object complex scene images, thus generalizing better on dense prediction
tasks. Compared with the vanilla DINO, our approach obtains competitive
performance when evaluated on classification in ImageNet and achieves a large
margin (+7.2% mIoU) improvement in semantic segmentation on PascalVOC under the
linear probing protocol for segmentation.
\\ ( https://arxiv.org/abs/2306.04654 ,  5938kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04670
Date: Wed, 7 Jun 2023 16:13:38 GMT   (31474kb,D)

Title: 2D Object Detection with Transformers: A Review
Authors: Tahira Shehzadi, Khurram Azeem Hashmi, Didier Stricker and Muhammad
 Zeshan Afzal
Categories: cs.CV
\\
 Astounding performance of Transformers in natural language processing (NLP)
has delighted researchers to explore their utilization in computer vision
tasks. Like other computer vision tasks, DEtection TRansformer (DETR)
introduces transformers for object detection tasks by considering the detection
as a set prediction problem without needing proposal generation and
post-processing steps. It is a state-of-the-art (SOTA) method for object
detection, particularly in scenarios where the number of objects in an image is
relatively small. Despite the success of DETR, it suffers from slow training
convergence and performance drops for small objects. Therefore, many
improvements are proposed to address these issues, leading to immense
refinement in DETR. Since 2020, transformer-based object detection has
attracted increasing interest and demonstrated impressive performance. Although
numerous surveys have been conducted on transformers in vision in general, a
review regarding advancements made in 2D object detection using transformers is
still missing. This paper gives a detailed review of twenty-one papers about
recent developments in DETR. We begin with the basic modules of Transformers,
such as self-attention, object queries and input features encoding. Then, we
cover the latest advancements in DETR, including backbone modification, query
design and attention refinement. We also compare all detection transformers in
terms of performance and network design. We hope this study will increase the
researcher's interest in solving existing challenges towards applying
transformers in the object detection domain. Researchers can follow newer
improvements in detection transformers on this webpage available at:
https://github.com/mindgarage-shan/trans_object_detection_survey
\\ ( https://arxiv.org/abs/2306.04670 ,  31474kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04695
Date: Wed, 7 Jun 2023 18:00:38 GMT   (10106kb,D)

Title: ConceptBed: Evaluating Concept Learning Abilities of Text-to-Image
 Diffusion Models
Authors: Maitreya Patel and Tejas Gokhale and Chitta Baral and Yezhou Yang
Categories: cs.CV cs.CL cs.LG
Comments: Project page: https://conceptbed.github.io
\\
 The ability to understand visual concepts and replicate and compose these
concepts from images is a central goal for computer vision. Recent advances in
text-to-image (T2I) models have lead to high definition and realistic image
quality generation by learning from large databases of images and their
descriptions. However, the evaluation of T2I models has focused on photorealism
and limited qualitative measures of visual understanding. To quantify the
ability of T2I models in learning and synthesizing novel visual concepts, we
introduce ConceptBed, a large-scale dataset that consists of 284 unique visual
concepts, 5K unique concept compositions, and 33K composite text prompts. Along
with the dataset, we propose an evaluation metric, Concept Confidence Deviation
(CCD), that uses the confidence of oracle concept classifiers to measure the
alignment between concepts generated by T2I generators and concepts contained
in ground truth images. We evaluate visual concepts that are either objects,
attributes, or styles, and also evaluate four dimensions of compositionality:
counting, attributes, relations, and actions. Our human study shows that CCD is
highly correlated with human understanding of concepts. Our results point to a
trade-off between learning the concepts and preserving the compositionality
which existing approaches struggle to overcome.
\\ ( https://arxiv.org/abs/2306.04695 ,  10106kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04699
Date: Wed, 7 Jun 2023 18:05:14 GMT   (16612kb,D)

Title: DiViNeT: 3D Reconstruction from Disparate Views via Neural Template
 Regularization
Authors: Aditya Vora, Akshay Gadi Patil, Hao Zhang
Categories: cs.CV
\\
 We present a volume rendering-based neural surface reconstruction method that
takes as few as three disparate RGB images as input. Our key idea is to
regularize the reconstruction, which is severely ill-posed and leaving Our
method, coined DiViNet, operates in two stages. The first stage learns the
templates, in the form of 3D Gaussian functions, across different scenes,
without 3D supervision. In the reconstruction stage, our predicted templates
serve as anchors to help ``stitch'' the surfaces over sparse regions. We
demonstrate that our approach is not only able to complete the surface geometry
but also reconstructs surface details to a reasonable extent from few disparate
input views. On the DTU and BlendedMVS datasets, our approach achieves the best
reconstruction quality among existing methods in the presence of such sparse
views, and performs on par, if not better, with competing methods when dense
views are employed as inputs.
\\ ( https://arxiv.org/abs/2306.04699 ,  16612kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04701
Date: Wed, 7 Jun 2023 18:08:11 GMT   (1560kb,D)

Title: Robust-DefReg: A Robust Deformable Point Cloud Registration Method based
 on Graph Convolutional Neural Networks
Authors: Sara Monji-Azad, Marvin Kinz, J\"urgen Hesser
Categories: cs.CV cs.LG
\\
 Point cloud registration is a fundamental problem in computer vision that
aims to estimate the transformation between corresponding sets of points.
Non-rigid registration, in particular, involves addressing challenges including
various levels of deformation, noise, outliers, and data incompleteness. This
paper introduces Robust-DefReg, a robust non-rigid point cloud registration
method based on graph convolutional networks (GCNNs). Robust-DefReg is a
coarse-to-fine registration approach within an end-to-end pipeline, leveraging
the advantages of both coarse and fine methods. The method learns global
features to find correspondences between source and target point clouds, to
enable appropriate initial alignment, and subsequently fine registration. The
simultaneous achievement of high accuracy and robustness across all challenges
is reported less frequently in existing studies, making it a key objective of
the Robust-DefReg method. The proposed method achieves high accuracy in large
deformations while maintaining computational efficiency. This method possesses
three primary attributes: high accuracy, robustness to different challenges,
and computational efficiency. The experimental results show that the proposed
Robust-DefReg holds significant potential as a foundational architecture for
future investigations in non-rigid point cloud registration. The source code of
Robust-DefReg is available.
\\ ( https://arxiv.org/abs/2306.04701 ,  1560kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04709
Date: Wed, 7 Jun 2023 18:21:22 GMT   (6654kb)

Title: Improved statistical benchmarking of digital pathology models using
 pairwise frames evaluation
Authors: Ylaine Gerardin, John Shamshoian, Judy Shen, Nhat Le, Jamie Prezioso,
 John Abel, Isaac Finberg, Daniel Borders, Raymond Biju, Michael Nercessian,
 Vaed Prasad, Joseph Lee, Spencer Wyman, Sid Gupta, Abigail Emerson, Bahar
 Rahsepar, Darpan Sanghavi, Ryan Leung, Limin Yu, Archit Khosla, Amaro
 Taylor-Weiner
Categories: cs.CV cs.LG
Comments: 10 pages, 7 figures
\\
 Nested pairwise frames is a method for relative benchmarking of cell or
tissue digital pathology models against manual pathologist annotations on a set
of sampled patches. At a high level, the method compares agreement between a
candidate model and pathologist annotations with agreement among pathologists'
annotations. This evaluation framework addresses fundamental issues of data
size and annotator variability in using manual pathologist annotations as a
source of ground truth for model validation. We implemented nested pairwise
frames evaluation for tissue classification, cell classification, and cell
count prediction tasks and show results for cell and tissue models deployed on
an H&E-stained melanoma dataset.
\\ ( https://arxiv.org/abs/2306.04709 ,  6654kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04715
Date: Wed, 7 Jun 2023 18:26:22 GMT   (3040kb,D)

Title: UniBoost: Unsupervised Unimodal Pre-training for Boosting Zero-shot
 Vision-Language Tasks
Authors: Yanan Sun and Zihan Zhong and Qi Fan and Chi-Keung Tang and Yu-Wing
 Tai
Categories: cs.CV
\\
 Large-scale joint training of multimodal models, e.g., CLIP, have
demonstrated great performance in many vision-language tasks. However,
image-text pairs for pre-training are restricted to the intersection of images
and texts, limiting their ability to cover a large distribution of real-world
data, where noise can also be introduced as misaligned pairs during
pre-processing. Conversely, unimodal models trained on text or image data alone
through unsupervised techniques can achieve broader coverage of diverse
real-world data and are not constrained by the requirement of simultaneous
presence of image and text. In this paper, we demonstrate that using
large-scale unsupervised unimodal models as pre-training can enhance the
zero-shot performance of image-text pair models. Our thorough studies validate
that models pre-trained as such can learn rich representations of both
modalities, improving their ability to understand how images and text relate to
each other. Our experiments show that unimodal pre-training outperforms
state-of-the-art CLIP-based models by 6.5% (52.3% $\rightarrow$ 58.8%) on
PASCAL-5$^i$ and 6.2% (27.2% $\rightarrow$ 33.4%) on COCO-20$^i$ semantic
segmentation under zero-shot setting respectively. By learning representations
of both modalities, unimodal pre-training offers broader coverage, reduced
misalignment errors, and the ability to capture more complex features and
patterns in the real-world data resulting in better performance especially for
zero-shot vision-language tasks.
\\ ( https://arxiv.org/abs/2306.04715 ,  3040kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04717
Date: Wed, 7 Jun 2023 18:28:21 GMT   (13860kb,D)

Title: AGIQA-3K: An Open Database for AI-Generated Image Quality Assessment
Authors: Chunyi Li, Zicheng Zhang, Haoning Wu, Wei Sun, Xiongkuo Min, Xiaohong
 Liu, Guangtao Zhai, Weisi Lin
Categories: cs.CV cs.AI eess.IV
Comments: 12 pages, 11 figures
\\
 With the rapid advancements of the text-to-image generative model,
AI-generated images (AGIs) have been widely applied to entertainment,
education, social media, etc. However, considering the large quality variance
among different AGIs, there is an urgent need for quality models that are
consistent with human subjective ratings. To address this issue, we extensively
consider various popular AGI models, generated AGI through different prompts
and model parameters, and collected subjective scores at the perceptual quality
and text-to-image alignment, thus building the most comprehensive AGI
subjective quality database AGIQA-3K so far. Furthermore, we conduct a
benchmark experiment on this database to evaluate the consistency between the
current Image Quality Assessment (IQA) model and human perception, while
proposing StairReward that significantly improves the assessment performance of
subjective text-to-image alignment. We believe that the fine-grained subjective
scores in AGIQA-3K will inspire subsequent AGI quality models to fit human
subjective perception mechanisms at both perception and alignment levels and to
optimize the generation result of future AGI models. The database is released
on \url{https://github.com/lcysyzxdxc/AGIQA-3k-Database}.
\\ ( https://arxiv.org/abs/2306.04717 ,  13860kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04719
Date: Wed, 7 Jun 2023 18:31:39 GMT   (8394kb,D)

Title: Don't trust your eyes: on the (un)reliability of feature visualizations
Authors: Robert Geirhos, Roland S. Zimmermann, Blair Bilodeau, Wieland Brendel,
 Been Kim
Categories: cs.CV cs.AI cs.HC cs.LG q-bio.NC
\\
 How do neural networks extract patterns from pixels? Feature visualizations
attempt to answer this important question by visualizing highly activating
patterns through optimization. Today, visualization methods form the foundation
of our knowledge about the internal workings of neural networks, as a type of
mechanistic interpretability. Here we ask: How reliable are feature
visualizations? We start our investigation by developing network circuits that
trick feature visualizations into showing arbitrary patterns that are
completely disconnected from normal network behavior on natural input. We then
provide evidence for a similar phenomenon occurring in standard, unmanipulated
networks: feature visualizations are processed very differently from standard
input, casting doubt on their ability to "explain" how neural networks process
natural images. We underpin this empirical finding by theory proving that the
set of functions that can be reliably understood by feature visualization is
extremely small and does not include general black-box neural networks.
Therefore, a promising way forward could be the development of networks that
enforce certain structures in order to ensure more reliable feature
visualizations.
\\ ( https://arxiv.org/abs/2306.04719 ,  8394kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04736
Date: Wed, 7 Jun 2023 19:12:03 GMT   (1872kb,D)

Title: BU-CVKit: Extendable Computer Vision Framework for Species Independent
 Tracking and Analysis
Authors: Mahir Patel, Lucas Carstensen, Yiwen Gu, Michael E. Hasselmo, Margrit
 Betke
Categories: cs.CV
\\
 A major bottleneck of interdisciplinary computer vision (CV) research is the
lack of a framework that eases the reuse and abstraction of state-of-the-art CV
models by CV and non-CV researchers alike. We present here BU-CVKit, a computer
vision framework that allows the creation of research pipelines with chainable
Processors. The community can create plugins of their work for the framework,
hence improving the re-usability, accessibility, and exposure of their work
with minimal overhead. Furthermore, we provide MuSeqPose Kit, a user interface
for the pose estimation package of BU-CVKit, which automatically scans for
installed plugins and programmatically generates an interface for them based on
the metadata provided by the user. It also provides software support for
standard pose estimation features such as annotations, 3D reconstruction,
reprojection, and camera calibration. Finally, we show examples of behavioral
neuroscience pipelines created through the sample plugins created for our
framework.
\\ ( https://arxiv.org/abs/2306.04736 ,  1872kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04738
Date: Wed, 7 Jun 2023 19:20:01 GMT   (1566kb,D)

Title: MultiEarth 2023 -- Multimodal Learning for Earth and Environment
 Workshop and Challenge
Authors: Miriam Cha, Gregory Angelides, Mark Hamilton, Andy Soszynski, Brandon
 Swenson, Nathaniel Maidel, Phillip Isola, Taylor Perron, Bill Freeman
Categories: cs.CV cs.AI
\\
 The Multimodal Learning for Earth and Environment Workshop (MultiEarth 2023)
is the second annual CVPR workshop aimed at the monitoring and analysis of the
health of Earth ecosystems by leveraging the vast amount of remote sensing data
that is continuously being collected. The primary objective of this workshop is
to bring together the Earth and environmental science communities as well as
the multimodal representation learning communities to explore new ways of
harnessing technological advancements in support of environmental monitoring.
The MultiEarth Workshop also seeks to provide a common benchmark for processing
multimodal remote sensing information by organizing public challenges focused
on monitoring the Amazon rainforest. These challenges include estimating
deforestation, detecting forest fires, translating synthetic aperture radar
(SAR) images to the visible domain, and projecting environmental trends. This
paper presents the challenge guidelines, datasets, and evaluation metrics. Our
challenge website is available at
https://sites.google.com/view/rainforest-challenge/multiearth-2023.
\\ ( https://arxiv.org/abs/2306.04738 ,  1566kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04744
Date: Wed, 7 Jun 2023 19:44:14 GMT   (11607kb,D)

Title: WOUAF: Weight Modulation for User Attribution and Fingerprinting in
 Text-to-Image Diffusion Models
Authors: Changhoon Kim, Kyle Min, Maitreya Patel, Sheng Cheng, Yezhou Yang
Categories: cs.CV
\\
 The rapid advancement of generative models, facilitating the creation of
hyper-realistic images from textual descriptions, has concurrently escalated
critical societal concerns such as misinformation. Traditional fake detection
mechanisms, although providing some mitigation, fall short in attributing
responsibility for the malicious use of synthetic images. This paper introduces
a novel approach to model fingerprinting that assigns responsibility for the
generated images, thereby serving as a potential countermeasure to model
misuse. Our method modifies generative models based on each user's unique
digital fingerprint, imprinting a unique identifier onto the resultant content
that can be traced back to the user. This approach, incorporating fine-tuning
into Text-to-Image (T2I) tasks using the Stable Diffusion Model, demonstrates
near-perfect attribution accuracy with a minimal impact on output quality. We
rigorously scrutinize our method's secrecy under two distinct scenarios: one
where a malicious user attempts to detect the fingerprint, and another where a
user possesses a comprehensive understanding of our method. We also evaluate
the robustness of our approach against various image post-processing
manipulations typically executed by end-users. Through extensive evaluation of
the Stable Diffusion models, our method presents a promising and novel avenue
for accountable model distribution and responsible use.
\\ ( https://arxiv.org/abs/2306.04744 ,  11607kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04745
Date: Wed, 7 Jun 2023 19:46:30 GMT   (23256kb,D)

Title: 3D Human Keypoints Estimation From Point Clouds in the Wild Without
 Human Labels
Authors: Zhenzhen Weng, Alexander S. Gorban, Jingwei Ji, Mahyar Najibi, Yin
 Zhou, Dragomir Anguelov
Categories: cs.CV cs.AI
Comments: CVPR 2023
\\
 Training a 3D human keypoint detector from point clouds in a supervised
manner requires large volumes of high quality labels. While it is relatively
easy to capture large amounts of human point clouds, annotating 3D keypoints is
expensive, subjective, error prone and especially difficult for long-tail cases
(pedestrians with rare poses, scooterists, etc.). In this work, we propose
GC-KPL - Geometry Consistency inspired Key Point Leaning, an approach for
learning 3D human joint locations from point clouds without human labels. We
achieve this by our novel unsupervised loss formulations that account for the
structure and movement of the human body. We show that by training on a large
training set from Waymo Open Dataset without any human annotated keypoints, we
are able to achieve reasonable performance as compared to the fully supervised
approach. Further, the backbone benefits from the unsupervised training and is
useful in downstream fewshot learning of keypoints, where fine-tuning on only
10 percent of the labeled training data gives comparable performance to
fine-tuning on the entire set. We demonstrated that GC-KPL outperforms by a
large margin over SoTA when trained on entire dataset and efficiently leverages
large volumes of unlabeled data.
\\ ( https://arxiv.org/abs/2306.04745 ,  23256kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04774
Date: Wed, 7 Jun 2023 20:45:15 GMT   (33346kb,D)

Title: RefineVIS: Video Instance Segmentation with Temporal Attention
 Refinement
Authors: Andre Abrantes, Jiang Wang, Peng Chu, Quanzeng You, Zicheng Liu
Categories: cs.CV
\\
 We introduce a novel framework called RefineVIS for Video Instance
Segmentation (VIS) that achieves good object association between frames and
accurate segmentation masks by iteratively refining the representations using
sequence context. RefineVIS learns two separate representations on top of an
off-the-shelf frame-level image instance segmentation model: an association
representation responsible for associating objects across frames and a
segmentation representation that produces accurate segmentation masks.
Contrastive learning is utilized to learn temporally stable association
representations. A Temporal Attention Refinement (TAR) module learns
discriminative segmentation representations by exploiting temporal
relationships and a novel temporal contrastive denoising technique. Our method
supports both online and offline inference. It achieves state-of-the-art video
instance segmentation accuracy on YouTube-VIS 2019 (64.4 AP), Youtube-VIS 2021
(61.4 AP), and OVIS (46.1 AP) datasets. The visualization shows that the TAR
module can generate more accurate instance segmentation masks, particularly for
challenging cases such as highly occluded objects.
\\ ( https://arxiv.org/abs/2306.04774 ,  33346kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04811
Date: Wed, 7 Jun 2023 22:20:51 GMT   (20706kb,D)

Title: Generative Text-Guided 3D Vision-Language Pretraining for Unified
 Medical Image Segmentation
Authors: Yinda Chen, Che Liu, Wei Huang, Sibo Cheng, Rossella Arcucci, Zhiwei
 Xiong
Categories: cs.CV cs.AI
\\
 Vision-Language Pretraining (VLP) has demonstrated remarkable capabilities in
learning visual representations from textual descriptions of images without
annotations. Yet, effective VLP demands large-scale image-text pairs, a
resource that suffers scarcity in the medical domain. Moreover, conventional
VLP is limited to 2D images while medical images encompass diverse modalities,
often in 3D, making the learning process more challenging. To address these
challenges, we present Generative Text-Guided 3D Vision-Language Pretraining
for Unified Medical Image Segmentation (GTGM), a framework that extends of VLP
to 3D medical images without relying on paired textual descriptions.
Specifically, GTGM utilizes large language models (LLM) to generate
medical-style text from 3D medical images. This synthetic text is then used to
supervise 3D visual representation learning. Furthermore, a negative-free
contrastive learning objective strategy is introduced to cultivate consistent
visual representations between augmented 3D medical image patches, which
effectively mitigates the biases associated with strict positive-negative
sample pairings. We evaluate GTGM on three imaging modalities - Computed
Tomography (CT), Magnetic Resonance Imaging (MRI), and electron microscopy (EM)
over 13 datasets. GTGM's superior performance across various medical image
segmentation tasks underscores its effectiveness and versatility, by enabling
VLP extension into 3D medical imagery while bypassing the need for paired text.
\\ ( https://arxiv.org/abs/2306.04811 ,  20706kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04822
Date: Wed, 7 Jun 2023 23:06:53 GMT   (1231kb,D)

Title: Optimizing ViViT Training: Time and Memory Reduction for Action
 Recognition
Authors: Shreyank N Gowda, Anurag Arnab, Jonathan Huang
Categories: cs.CV
\\
 In this paper, we address the challenges posed by the substantial training
time and memory consumption associated with video transformers, focusing on the
ViViT (Video Vision Transformer) model, in particular the Factorised Encoder
version, as our baseline for action recognition tasks. The factorised encoder
variant follows the late-fusion approach that is adopted by many state of the
art approaches. Despite standing out for its favorable speed/accuracy tradeoffs
among the different variants of ViViT, its considerable training time and
memory requirements still pose a significant barrier to entry. Our method is
designed to lower this barrier and is based on the idea of freezing the spatial
transformer during training. This leads to a low accuracy model if naively
done. But we show that by (1) appropriately initializing the temporal
transformer (a module responsible for processing temporal information) (2)
introducing a compact adapter model connecting frozen spatial representations
((a module that selectively focuses on regions of the input image) to the
temporal transformer, we can enjoy the benefits of freezing the spatial
transformer without sacrificing accuracy. Through extensive experimentation
over 6 benchmarks, we demonstrate that our proposed training strategy
significantly reduces training costs (by $\sim 50\%$) and memory consumption
while maintaining or slightly improving performance by up to 1.79\% compared to
the baseline model. Our approach additionally unlocks the capability to utilize
larger image transformer models as our spatial transformer and access more
frames with the same memory consumption.
\\ ( https://arxiv.org/abs/2306.04822 ,  1231kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04829
Date: Wed, 7 Jun 2023 23:18:14 GMT   (18026kb,D)

Title: Object-Centric Learning for Real-World Videos by Predicting Temporal
 Feature Similarities
Authors: Andrii Zadaianchuk and Maximilian Seitzer and Georg Martius
Categories: cs.CV cs.LG
\\
 Unsupervised video-based object-centric learning is a promising avenue to
learn structured representations from large, unlabeled video collections, but
previous approaches have only managed to scale to real-world datasets in
restricted domains. Recently, it was shown that the reconstruction of
pre-trained self-supervised features leads to object-centric representations on
unconstrained real-world image datasets. Building on this approach, we propose
a novel way to use such pre-trained features in the form of a temporal feature
similarity loss. This loss encodes temporal correlations between image patches
and is a natural way to introduce a motion bias for object discovery. We
demonstrate that this loss leads to state-of-the-art performance on the
challenging synthetic MOVi datasets. When used in combination with the feature
reconstruction loss, our model is the first object-centric video model that
scales to unconstrained video datasets such as YouTube-VIS.
\\ ( https://arxiv.org/abs/2306.04829 ,  18026kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04834
Date: Wed, 7 Jun 2023 23:40:04 GMT   (7713kb,D)

Title: A Semi-supervised Object Detection Algorithm for Underwater Imagery
Authors: Suraj Bijjahalli, Oscar Pizarro, and Stefan B. Williams
Categories: cs.CV cs.LG
Comments: 8 pages, 9 figures, submitted to IEEE/RSJ International Conference on
 Intelligent Robots and Systems (IROS) 2023
\\
 Detection of artificial objects from underwater imagery gathered by
Autonomous Underwater Vehicles (AUVs) is a key requirement for many subsea
applications. Real-world AUV image datasets tend to be very large and
unlabelled. Furthermore, such datasets are typically imbalanced, containing few
instances of objects of interest, particularly when searching for unusual
objects in a scene. It is therefore, difficult to fit models capable of
reliably detecting these objects. Given these factors, we propose to treat
artificial objects as anomalies and detect them through a semi-supervised
framework based on Variational Autoencoders (VAEs). We develop a method which
clusters image data in a learned low-dimensional latent space and extracts
images that are likely to contain anomalous features. We also devise an anomaly
score based on extracting poorly reconstructed regions of an image. We
demonstrate that by applying both methods on large image datasets, human
operators can be shown candidate anomalous samples with a low false positive
rate to identify objects of interest. We apply our approach to real seafloor
imagery gathered by an AUV and evaluate its sensitivity to the dimensionality
of the latent representation used by the VAE. We evaluate the precision-recall
tradeoff and demonstrate that by choosing an appropriate latent dimensionality
and threshold, we are able to achieve an average precision of 0.64 on
unlabelled datasets.
\\ ( https://arxiv.org/abs/2306.04834 ,  7713kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04842
Date: Thu, 8 Jun 2023 00:28:22 GMT   (13879kb,D)

Title: InvPT++: Inverted Pyramid Multi-Task Transformer for Visual Scene
 Understanding
Authors: Hanrong Ye and Dan Xu
Categories: cs.CV
Comments: Journal extension for InvPT
\\
 Multi-task scene understanding aims to design models that can simultaneously
predict several scene understanding tasks with one versatile model. Previous
studies typically process multi-task features in a more local way, and thus
cannot effectively learn spatially global and cross-task interactions, which
hampers the models' ability to fully leverage the consistency of various tasks
in multi-task learning. To tackle this problem, we propose an Inverted Pyramid
multi-task Transformer, capable of modeling cross-task interaction among
spatial features of different tasks in a global context. Specifically, we first
utilize a transformer encoder to capture task-generic features for all tasks.
And then, we design a transformer decoder to establish spatial and cross-task
interaction globally, and a novel UP-Transformer block is devised to increase
the resolutions of multi-task features gradually and establish cross-task
interaction at different scales. Furthermore, two types of Cross-Scale
Self-Attention modules, i.e., Fusion Attention and Selective Attention, are
proposed to efficiently facilitate cross-task interaction across different
feature scales. An Encoder Feature Aggregation strategy is further introduced
to better model multi-scale information in the decoder. Comprehensive
experiments on several 2D/3D multi-task benchmarks clearly demonstrate our
proposal's effectiveness, establishing significant state-of-the-art
performances.
\\ ( https://arxiv.org/abs/2306.04842 ,  13879kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04849
Date: Thu, 8 Jun 2023 00:57:09 GMT   (2578kb,D)

Title: ScaleDet: A Scalable Multi-Dataset Object Detector
Authors: Yanbei Chen, Manchen Wang, Abhay Mittal, Zhenlin Xu, Paolo Favaro,
 Joseph Tighe, Davide Modolo
Categories: cs.CV
Comments: CVPR 2023
\\
 Multi-dataset training provides a viable solution for exploiting
heterogeneous large-scale datasets without extra annotation cost. In this work,
we propose a scalable multi-dataset detector (ScaleDet) that can scale up its
generalization across datasets when increasing the number of training datasets.
Unlike existing multi-dataset learners that mostly rely on manual relabelling
efforts or sophisticated optimizations to unify labels across datasets, we
introduce a simple yet scalable formulation to derive a unified semantic label
space for multi-dataset training. ScaleDet is trained by visual-textual
alignment to learn the label assignment with label semantic similarities across
datasets. Once trained, ScaleDet can generalize well on any given upstream and
downstream datasets with seen and unseen classes. We conduct extensive
experiments using LVIS, COCO, Objects365, OpenImages as upstream datasets, and
13 datasets from Object Detection in the Wild (ODinW) as downstream datasets.
Our results show that ScaleDet achieves compelling strong model performance
with an mAP of 50.7 on LVIS, 58.8 on COCO, 46.8 on Objects365, 76.2 on
OpenImages, and 71.8 on ODinW, surpassing state-of-the-art detectors with the
same backbone.
\\ ( https://arxiv.org/abs/2306.04849 ,  2578kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04865
Date: Thu, 8 Jun 2023 01:35:43 GMT   (18546kb,D)

Title: MyStyle++: A Controllable Personalized Generative Prior
Authors: Libing Zeng, Lele Chen, Yi Xu, Nima Kalantari
Categories: cs.CV
\\
 In this paper, we propose an approach to obtain a personalized generative
prior with explicit control over a set of attributes. We build upon MyStyle, a
recently introduced method, that tunes the weights of a pre-trained StyleGAN
face generator on a few images of an individual. This system allows
synthesizing, editing, and enhancing images of the target individual with high
fidelity to their facial features. However, MyStyle does not demonstrate
precise control over the attributes of the generated images. We propose to
address this problem through a novel optimization system that organizes the
latent space in addition to tuning the generator. Our key contribution is to
formulate a loss that arranges the latent codes, corresponding to the input
images, along a set of specific directions according to their attributes. We
demonstrate that our approach, dubbed MyStyle++, is able to synthesize, edit,
and enhance images of an individual with great control over the attributes,
while preserving the unique facial characteristics of that individual.
\\ ( https://arxiv.org/abs/2306.04865 ,  18546kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04877
Date: Thu, 8 Jun 2023 02:17:29 GMT   (1849kb,D)

Title: Trojan Model Detection Using Activation Optimization
Authors: Mohamed E. Hussein, Sudharshan Subramaniam Janakiraman, Wael
 AbdAlmageed
Categories: cs.CV cs.CR cs.LG
\\
 Due to data's unavailability or large size, and the high computational and
human labor costs of training machine learning models, it is a common practice
to rely on open source pre-trained models whenever possible. However, this
practice is worry some from the security perspective. Pre-trained models can be
infected with Trojan attacks, in which the attacker embeds a trigger in the
model such that the model's behavior can be controlled by the attacker when the
trigger is present in the input. In this paper, we present our preliminary work
on a novel method for Trojan model detection. Our method creates a signature
for a model based on activation optimization. A classifier is then trained to
detect a Trojan model given its signature. Our method achieves state of the art
performance on two public datasets.
\\ ( https://arxiv.org/abs/2306.04877 ,  1849kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04889
Date: Thu, 8 Jun 2023 02:35:30 GMT   (12236kb,D)

Title: ShaDDR: Real-Time Example-Based Geometry and Texture Generation via 3D
 Shape Detailization and Differentiable Rendering
Authors: Qimin Chen, Zhiqin Chen, Hang Zhou, Hao Zhang
Categories: cs.CV cs.GR cs.LG
\\
 We present ShaDDR, an example-based deep generative neural network which
produces a high-resolution textured 3D shape through geometry detailization and
conditional texture generation applied to an input coarse voxel shape. Trained
on a small set of detailed and textured exemplar shapes, our method learns to
detailize the geometry via multi-resolution voxel upsampling and generate
textures on voxel surfaces via differentiable rendering against exemplar
texture images from a few views. The generation is real-time, taking less than
1 second to produce a 3D model with voxel resolutions up to 512^3. The
generated shape preserves the overall structure of the input coarse voxel
model, while the style of the generated geometric details and textures can be
manipulated through learned latent codes. In the experiments, we show that our
method can generate higher-resolution shapes with plausible and improved
geometric details and clean textures compared to prior works. Furthermore, we
showcase the ability of our method to learn geometric details and textures from
shapes reconstructed from real-world photos. In addition, we have developed an
interactive modeling application to demonstrate the generalizability of our
method to various user inputs and the controllability it offers, allowing users
to interactively sculpt a coarse voxel shape to define the overall structure of
the detailized 3D shape.
\\ ( https://arxiv.org/abs/2306.04889 ,  12236kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04893
Date: Thu, 8 Jun 2023 02:45:15 GMT   (2505kb,D)

Title: Coping with Change: Learning Invariant and Minimum Sufficient
 Representations for Fine-Grained Visual Categorization
Authors: Shuo Ye and Shujian Yu and Wenjin Hou and Yu Wang and Xinge You
Categories: cs.CV
\\
 Fine-grained visual categorization (FGVC) is a challenging task due to
similar visual appearances between various species. Previous studies always
implicitly assume that the training and test data have the same underlying
distributions, and that features extracted by modern backbone architectures
remain discriminative and generalize well to unseen test data. However, we
empirically justify that these conditions are not always true on benchmark
datasets. To this end, we combine the merits of invariant risk minimization
(IRM) and information bottleneck (IB) principle to learn invariant and minimum
sufficient (IMS) representations for FGVC, such that the overall model can
always discover the most succinct and consistent fine-grained features. We
apply the matrix-based R{\'e}nyi's $\alpha$-order entropy to simplify and
stabilize the training of IB; we also design a ``soft" environment partition
scheme to make IRM applicable to FGVC task. To the best of our knowledge, we
are the first to address the problem of FGVC from a generalization perspective
and develop a new information-theoretic solution accordingly. Extensive
experiments demonstrate the consistent performance gain offered by our IMS.
\\ ( https://arxiv.org/abs/2306.04893 ,  2505kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04897
Date: Thu, 8 Jun 2023 02:58:15 GMT   (2167kb,D)

Title: Muti-Scale And Token Mergence: Make Your ViT More Efficient
Authors: Zhe Bian, Zhe Wang, Wenqiang Han, Kangping Wang
Categories: cs.CV
\\
 Since its inception, Vision Transformer (ViT) has emerged as a prevalent
model in the computer vision domain. Nonetheless, the multi-head self-attention
(MHSA) mechanism in ViT is computationally expensive due to its calculation of
relationships among all tokens. Although some techniques mitigate computational
overhead by discarding tokens, this also results in the loss of potential
information from those tokens. To tackle these issues, we propose a novel token
pruning method that retains information from non-crucial tokens by merging them
with more crucial tokens, thereby mitigating the impact of pruning on model
performance. Crucial and non-crucial tokens are identified by their importance
scores and merged based on similarity scores. Furthermore, multi-scale features
are exploited to represent images, which are fused prior to token pruning to
produce richer feature representations. Importantly, our method can be
seamlessly integrated with various ViTs, enhancing their adaptability.
Experimental evidence substantiates the efficacy of our approach in reducing
the influence of token pruning on model performance. For instance, on the
ImageNet dataset, it achieves a remarkable 33% reduction in computational costs
while only incurring a 0.1% decrease in accuracy on DeiT-S.
\\ ( https://arxiv.org/abs/2306.04897 ,  2167kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04911
Date: Thu, 8 Jun 2023 03:26:16 GMT   (983kb,D)

Title: Test-Time Style Shifting: Handling Arbitrary Styles in Domain
 Generalization
Authors: Jungwuk Park, Dong-Jun Han, Soyeong Kim, Jaekyun Moon
Categories: cs.CV cs.AI
Comments: ICML 2023 camera-ready version
\\
 In domain generalization (DG), the target domain is unknown when the model is
being trained, and the trained model should successfully work on an arbitrary
(and possibly unseen) target domain during inference. This is a difficult
problem, and despite active studies in recent years, it remains a great
challenge. In this paper, we take a simple yet effective approach to tackle
this issue. We propose test-time style shifting, which shifts the style of the
test sample (that has a large style gap with the source domains) to the nearest
source domain that the model is already familiar with, before making the
prediction. This strategy enables the model to handle any target domains with
arbitrary style statistics, without additional model update at test-time.
Additionally, we propose style balancing, which provides a great platform for
maximizing the advantage of test-time style shifting by handling the
DG-specific imbalance issues. The proposed ideas are easy to implement and
successfully work in conjunction with various other DG schemes. Experimental
results on different datasets show the effectiveness of our methods.
\\ ( https://arxiv.org/abs/2306.04911 ,  983kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04927
Date: Thu, 8 Jun 2023 04:18:31 GMT   (15012kb,D)

Title: An Efficient Transformer for Simultaneous Learning of BEV and Lane
 Representations in 3D Lane Detection
Authors: Ziye Chen, Kate Smith-Miles, Bo Du, Guoqi Qian, Mingming Gong
Categories: cs.CV
\\
 Accurately detecting lane lines in 3D space is crucial for autonomous
driving. Existing methods usually first transform image-view features into
bird-eye-view (BEV) by aid of inverse perspective mapping (IPM), and then
detect lane lines based on the BEV features. However, IPM ignores the changes
in road height, leading to inaccurate view transformations. Additionally, the
two separate stages of the process can cause cumulative errors and increased
complexity. To address these limitations, we propose an efficient transformer
for 3D lane detection. Different from the vanilla transformer, our model
contains a decomposed cross-attention mechanism to simultaneously learn lane
and BEV representations. The mechanism decomposes the cross-attention between
image-view and BEV features into the one between image-view and lane features,
and the one between lane and BEV features, both of which are supervised with
ground-truth lane lines. Our method obtains 2D and 3D lane predictions by
applying the lane features to the image-view and BEV features, respectively.
This allows for a more accurate view transformation than IPM-based methods, as
the view transformation is learned from data with a supervised cross-attention.
Additionally, the cross-attention between lane and BEV features enables them to
adjust to each other, resulting in more accurate lane detection than the two
separate stages. Finally, the decomposed cross-attention is more efficient than
the original one. Experimental results on OpenLane and ONCE-3DLanes demonstrate
the state-of-the-art performance of our method.
\\ ( https://arxiv.org/abs/2306.04927 ,  15012kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04934
Date: Thu, 8 Jun 2023 04:32:10 GMT   (635kb,D)

Title: On the Effectiveness of Out-of-Distribution Data in Self-Supervised
 Long-Tail Learning
Authors: Jianhong Bai, Zuozhu Liu, Hualiang Wang, Jin Hao, Yang Feng, Huanpeng
 Chu, Haoji Hu
Categories: cs.CV
\\
 Though Self-supervised learning (SSL) has been widely studied as a promising
technique for representation learning, it doesn't generalize well on
long-tailed datasets due to the majority classes dominating the feature space.
Recent work shows that the long-tailed learning performance could be boosted by
sampling extra in-domain (ID) data for self-supervised training, however,
large-scale ID data which can rebalance the minority classes are expensive to
collect. In this paper, we propose an alternative but easy-to-use and effective
solution, Contrastive with Out-of-distribution (OOD) data for Long-Tail
learning (COLT), which can effectively exploit OOD data to dynamically
re-balance the feature space. We empirically identify the counter-intuitive
usefulness of OOD samples in SSL long-tailed learning and principally design a
novel SSL method. Concretely, we first localize the `head' and `tail' samples
by assigning a tailness score to each OOD sample based on its neighborhoods in
the feature space. Then, we propose an online OOD sampling strategy to
dynamically re-balance the feature space. Finally, we enforce the model to be
capable of distinguishing ID and OOD samples by a distribution-level supervised
contrastive loss. Extensive experiments are conducted on various datasets and
several state-of-the-art SSL frameworks to verify the effectiveness of the
proposed method. The results show that our method significantly improves the
performance of SSL on long-tailed datasets by a large margin, and even
outperforms previous work which uses external ID data. Our code is available at
https://github.com/JianhongBai/COLT.
\\ ( https://arxiv.org/abs/2306.04934 ,  635kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04938
Date: Thu, 8 Jun 2023 05:08:32 GMT   (275kb)

Title: Knowledge Detection by Relevant Question and Image Attributes in Visual
 Question Answering
Authors: Param Ahir, Dr. Hiteishi Diwanji
Categories: cs.CV cs.AI
\\
 Visual question answering (VQA) is a Multidisciplinary research problem that
pursued through practices of natural language processing and computer vision.
Visual question answering automatically answers natural language questions
according to the content of an image. Some testing questions require external
knowledge to derive a solution. Such knowledge-based VQA uses various methods
to retrieve features of image and text, and combine them to generate the
answer. To generate knowledgebased answers either question dependent or image
dependent knowledge retrieval methods are used. If knowledge about all the
objects in the image is derived, then not all knowledge is relevant to the
question. On other side only question related knowledge may lead to incorrect
answers and over trained model that answers question that is irrelevant to
image. Our proposed method takes image attributes and question features as
input for knowledge derivation module and retrieves only question relevant
knowledge about image objects which can provide accurate answers.
\\ ( https://arxiv.org/abs/2306.04938 ,  275kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04947
Date: Thu, 8 Jun 2023 05:40:07 GMT   (2593kb,D)

Title: Neighborhood Attention Makes the Encoder of ResUNet Stronger for
 Accurate Road Extraction
Authors: Ali Jamali, Swalpa Kumar Roy, Jonathan Li, Pedram Ghamisi
Categories: cs.CV eess.IV
Comments: Submitted in IEEE
\\
 In the domain of remote sensing image interpretation, road extraction from
high-resolution aerial imagery has already been a hot research topic. Although
deep CNNs have presented excellent results for semantic segmentation, the
efficiency and capabilities of vision transformers are yet to be fully
researched. As such, for accurate road extraction, a deep semantic segmentation
neural network that utilizes the abilities of residual learning, HetConvs,
UNet, and vision transformers, which is called \texttt{ResUNetFormer}, is
proposed in this letter. The developed \texttt{ResUNetFormer} is evaluated on
various cutting-edge deep learning-based road extraction techniques on the
public Massachusetts road dataset. Statistical and visual results demonstrate
the superiority of the \texttt{ResUNetFormer} over the state-of-the-art CNNs
and vision transformers for segmentation. The code will be made available
publicly at \url{https://github.com/aj1365/ResUNetFormer}.
\\ ( https://arxiv.org/abs/2306.04947 ,  2593kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04955
Date: Thu, 8 Jun 2023 06:02:39 GMT   (1534kb,D)

Title: Degraded Polygons Raise Fundamental Questions of Neural Network
 Perception
Authors: Leonard Tang, Dan Ley
Categories: cs.CV cs.AI cs.LG
\\
 It is well-known that modern computer vision systems often exhibit behaviors
misaligned with those of humans: from adversarial attacks to image corruptions,
deep learning vision models suffer in a variety of settings that humans capably
handle. In light of these phenomena, here we introduce another, orthogonal
perspective studying the human-machine vision gap. We revisit the task of
recovering images under degradation, first introduced over 30 years ago in the
Recognition-by-Components theory of human vision. Specifically, we study the
performance and behavior of neural networks on the seemingly simple task of
classifying regular polygons at varying orders of degradation along their
perimeters. To this end, we implement the Automated Shape Recoverability Test
for rapidly generating large-scale datasets of perimeter-degraded regular
polygons, modernizing the historically manual creation of image recoverability
experiments. We then investigate the capacity of neural networks to recognize
and recover such degraded shapes when initialized with different priors.
Ultimately, we find that neural networks' behavior on this simple task
conflicts with human behavior, raising a fundamental question of the robustness
and learning capabilities of modern computer vision models.
\\ ( https://arxiv.org/abs/2306.04955 ,  1534kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04957
Date: Thu, 8 Jun 2023 06:15:13 GMT   (4788kb,D)

Title: IFaceUV: Intuitive Motion Facial Image Generation by Identity
 Preservation via UV map
Authors: Hansol Lee, Yunhoe Ku, Eunseo Kim, Seungryul Baek
Categories: cs.CV
\\
 Reenacting facial images is an important task that can find numerous
applications. We proposed IFaceUV, a fully differentiable pipeline that
properly combines 2D and 3D information to conduct the facial reenactment task.
The three-dimensional morphable face models (3DMMs) and corresponding UV maps
are utilized to intuitively control facial motions and textures, respectively.
Two-dimensional techniques based on 2D image warping is further required to
compensate for missing components of the 3DMMs such as backgrounds, ear, hair
and etc. In our pipeline, we first extract 3DMM parameters and corresponding UV
maps from source and target images. Then, initial UV maps are refined by the UV
map refinement network and it is rendered to the image with the motion
manipulated 3DMM parameters. In parallel, we warp the source image according to
the 2D flow field obtained from the 2D warping network. Rendered and warped
images are combined in the final editing network to generate the final
reenactment image. Additionally, we tested our model for the audio-driven
facial reenactment task. Extensive qualitative and quantitative experiments
illustrate the remarkable performance of our method compared to other
state-of-the-art methods.
\\ ( https://arxiv.org/abs/2306.04957 ,  4788kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04988
Date: Thu, 8 Jun 2023 07:19:27 GMT   (34370kb,D)

Title: StreetSurf: Extending Multi-view Implicit Surface Reconstruction to
 Street Views
Authors: Jianfei Guo, Nianchen Deng, Xinyang Li, Yeqi Bai, Botian Shi, Chiyu
 Wang, Chenjing Ding, Dongliang Wang, Yikang Li
Categories: cs.CV cs.GR
Comments: https://ventusff.github.io/streetsurf_web/
\\
 We present a novel multi-view implicit surface reconstruction technique,
termed StreetSurf, that is readily applicable to street view images in
widely-used autonomous driving datasets, such as Waymo-perception sequences,
without necessarily requiring LiDAR data. As neural rendering research expands
rapidly, its integration into street views has started to draw interests.
Existing approaches on street views either mainly focus on novel view synthesis
with little exploration of the scene geometry, or rely heavily on dense LiDAR
data when investigating reconstruction. Neither of them investigates multi-view
implicit surface reconstruction, especially under settings without LiDAR data.
Our method extends prior object-centric neural surface reconstruction
techniques to address the unique challenges posed by the unbounded street views
that are captured with non-object-centric, long and narrow camera trajectories.
We delimit the unbounded space into three parts, close-range, distant-view and
sky, with aligned cuboid boundaries, and adapt cuboid/hyper-cuboid hash-grids
along with road-surface initialization scheme for finer and disentangled
representation. To further address the geometric errors arising from
textureless regions and insufficient viewing angles, we adopt geometric priors
that are estimated using general purpose monocular models. Coupled with our
implementation of efficient and fine-grained multi-stage ray marching strategy,
we achieve state of the art reconstruction quality in both geometry and
appearance within only one to two hours of training time with a single RTX3090
GPU for each street view sequence. Furthermore, we demonstrate that the
reconstructed implicit surfaces have rich potential for various downstream
tasks, including ray tracing and LiDAR simulation.
\\ ( https://arxiv.org/abs/2306.04988 ,  34370kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04990
Date: Thu, 8 Jun 2023 07:24:08 GMT   (20146kb,D)

Title: Multi-Architecture Multi-Expert Diffusion Models
Authors: Yunsung Lee, Jin-Young Kim, Hyojun Go, Myeongho Jeong, Shinhyeok Oh,
 Seungtaek Choi
Categories: cs.CV
\\
 Diffusion models have achieved impressive results in generating diverse and
realistic data by employing multi-step denoising processes. However, the need
for accommodating significant variations in input noise at each time-step has
led to diffusion models requiring a large number of parameters for their
denoisers. We have observed that diffusion models effectively act as filters
for different frequency ranges at each time-step noise. While some previous
works have introduced multi-expert strategies, assigning denoisers to different
noise intervals, they overlook the importance of specialized operations for
high and low frequencies. For instance, self-attention operations are effective
at handling low-frequency components (low-pass filters), while convolutions
excel at capturing high-frequency features (high-pass filters). In other words,
existing diffusion models employ denoisers with the same architecture, without
considering the optimal operations for each time-step noise. To address this
limitation, we propose a novel approach called Multi-architecturE Multi-Expert
(MEME), which consists of multiple experts with specialized architectures
tailored to the operations required at each time-step interval. Through
extensive experiments, we demonstrate that MEME outperforms large competitors
in terms of both generation performance and computational efficiency.
\\ ( https://arxiv.org/abs/2306.04990 ,  20146kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05001
Date: Thu, 8 Jun 2023 07:45:24 GMT   (14601kb,D)

Title: COURIER: Contrastive User Intention Reconstruction for Large-Scale
 Pre-Train of Image Features
Authors: Jia-Qi Yang, Chenglei Dai, OU Dan, Ju Huang, De-Chuan Zhan, Qingwen
 Liu, Xiaoyi Zeng, Yang Yang
Categories: cs.CV cs.LG
\\
 With the development of the multi-media internet, visual characteristics have
become an important factor affecting user interests. Thus, incorporating visual
features is a promising direction for further performance improvements in
click-through rate (CTR) prediction. However, we found that simply injecting
the image embeddings trained with established pre-training methods only has
marginal improvements. We attribute the failure to two reasons: First, The
pre-training methods are designed for well-defined computer vision tasks
concentrating on semantic features, and they cannot learn personalized interest
in recommendations. Secondly, pre-trained image embeddings only containing
semantic information have little information gain, considering we already have
semantic features such as categories and item titles as inputs in the CTR
prediction task. We argue that a pre-training method tailored for
recommendation is necessary for further improvements. To this end, we propose a
recommendation-aware image pre-training method that can learn visual features
from user click histories. Specifically, we propose a user interest
reconstruction module to mine visual features related to user interests from
behavior histories. We further propose a contrastive training method to avoid
collapsing of embedding vectors. We conduct extensive experiments to verify
that our method can learn users' visual interests, and our method achieves
$0.46\%$ improvement in offline AUC and $0.88\%$ improvement in Taobao online
GMV with p-value$<0.01$.
\\ ( https://arxiv.org/abs/2306.05001 ,  14601kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05029
Date: Thu, 8 Jun 2023 08:29:10 GMT   (1446kb,D)

Title: Multi-level Multiple Instance Learning with Transformer for Whole Slide
 Image Classification
Authors: Ruijie Zhang, Qiaozhe Zhang, Yingzhuang Liu, Hao Xin, Yan Liu,
 Xinggang Wang
Categories: cs.CV cs.LG
\\
 Whole slide image (WSI) refers to a type of high-resolution scanned tissue
image, which is extensively employed in computer-assisted diagnosis (CAD). The
extremely high resolution and limited availability of region-level annotations
make it challenging to employ deep learning methods for WSI-based digital
diagnosis. Multiple instance learning (MIL) is a powerful tool to address the
weak annotation problem, while Transformer has shown great success in the field
of visual tasks. The combination of both should provide new insights for deep
learning based image diagnosis. However, due to the limitations of single-level
MIL and the attention mechanism's constraints on sequence length, directly
applying Transformer to WSI-based MIL tasks is not practical. To tackle this
issue, we propose a Multi-level MIL with Transformer (MMIL-Transformer)
approach. By introducing a hierarchical structure to MIL, this approach enables
efficient handling of MIL tasks that involve a large number of instances. To
validate its effectiveness, we conducted a set of experiments on WSIs
classification task, where MMIL-Transformer demonstrate superior performance
compared to existing state-of-the-art methods. Our proposed approach achieves
test AUC 94.74% and test accuracy 93.41% on CAMELYON16 dataset, test AUC 99.04%
and test accuracy 94.37% on TCGA-NSCLC dataset, respectively. All code and
pre-trained models are available at: https://github.com/hustvl/MMIL-Transformer
\\ ( https://arxiv.org/abs/2306.05029 ,  1446kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05037
Date: Thu, 8 Jun 2023 08:42:08 GMT   (3498kb,D)

Title: Normalization-Equivariant Neural Networks with Application to Image
 Denoising
Authors: S\'ebastien Herbreteau, Emmanuel Moebel and Charles Kervrann
Categories: cs.CV
\\
 In many information processing systems, it may be desirable to ensure that
any change of the input, whether by shifting or scaling, results in a
corresponding change in the system response. While deep neural networks are
gradually replacing all traditional automatic processing methods, they
surprisingly do not guarantee such normalization-equivariance (scale + shift)
property, which can be detrimental in many applications. To address this issue,
we propose a methodology for adapting existing neural networks so that
normalization-equivariance holds by design. Our main claim is that not only
ordinary convolutional layers, but also all activation functions, including the
ReLU (rectified linear unit), which are applied element-wise to the
pre-activated neurons, should be completely removed from neural networks and
replaced by better conditioned alternatives. To this end, we introduce
affine-constrained convolutions and channel-wise sort pooling layers as
surrogates and show that these two architectural modifications do preserve
normalization-equivariance without loss of performance. Experimental results in
image denoising show that normalization-equivariant neural networks, in
addition to their better conditioning, also provide much better generalization
across noise levels.
\\ ( https://arxiv.org/abs/2306.05037 ,  3498kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05045
Date: Thu, 8 Jun 2023 08:55:16 GMT   (3335kb,D)

Title: Spain on Fire: A novel wildfire risk assessment model based on image
 satellite processing and atmospheric information
Authors: Helena Liz-L\'opez, Javier Huertas-Tato, Jorge P\'erez-Aracil, Carlos
 Casanova-Mateo, Julia Sanz-Justo, David Camacho
Categories: cs.CV cs.AI eess.IV
\\
 Each year, wildfires destroy larger areas of Spain, threatening numerous
ecosystems. Humans cause 90% of them (negligence or provoked) and the behaviour
of individuals is unpredictable. However, atmospheric and environmental
variables affect the spread of wildfires, and they can be analysed by using
deep learning. In order to mitigate the damage of these events we proposed the
novel Wildfire Assessment Model (WAM). Our aim is to anticipate the economic
and ecological impact of a wildfire, assisting managers resource allocation and
decision making for dangerous regions in Spain, Castilla y Le\'on and
Andaluc\'ia. The WAM uses a residual-style convolutional network architecture
to perform regression over atmospheric variables and the greenness index,
computing necessary resources, the control and extinction time, and the
expected burnt surface area. It is first pre-trained with self-supervision over
100,000 examples of unlabelled data with a masked patch prediction objective
and fine-tuned using 311 samples of wildfires. The pretraining allows the model
to understand situations, outclassing baselines with a 1,4%, 3,7% and 9%
improvement estimating human, heavy and aerial resources; 21% and 10,2% in
expected extinction and control time; and 18,8% in expected burnt area. Using
the WAM we provide an example assessment map of Castilla y Le\'on, visualizing
the expected resources over an entire region.
\\ ( https://arxiv.org/abs/2306.05045 ,  3335kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05056
Date: Thu, 8 Jun 2023 09:20:51 GMT   (2356kb,D)

Title: Magnitude Attention-based Dynamic Pruning
Authors: Jihye Back, Namhyuk Ahn, Jangho Kim
Categories: cs.CV cs.LG
\\
 Existing pruning methods utilize the importance of each weight based on
specified criteria only when searching for a sparse structure but do not
utilize it during training. In this work, we propose a novel approach -
\textbf{M}agnitude \textbf{A}ttention-based Dynamic \textbf{P}runing (MAP)
method, which applies the importance of weights throughout both the forward and
backward paths to explore sparse model structures dynamically. Magnitude
attention is defined based on the magnitude of weights as continuous
real-valued numbers enabling a seamless transition from a redundant to an
effective sparse network by promoting efficient exploration. Additionally, the
attention mechanism ensures more effective updates for important layers within
the sparse network. In later stages of training, our approach shifts from
exploration to exploitation, exclusively updating the sparse model composed of
crucial weights based on the explored structure, resulting in pruned models
that not only achieve performance comparable to dense models but also
outperform previous pruning methods on CIFAR-10/100 and ImageNet.
\\ ( https://arxiv.org/abs/2306.05056 ,  2356kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05061
Date: Thu, 8 Jun 2023 09:24:46 GMT   (1137kb,D)

Title: A Dynamic Feature Interaction Framework for Multi-task Visual Perception
Authors: Yuling Xi, Hao Chen, Ning Wang, Peng Wang, Yanning Zhang, Chunhua
 Shen, Yifan Liu
Categories: cs.CV
Comments: Accepted by International Journal of Computer Vision. arXiv admin
 note: text overlap with arXiv:2011.09796
\\
 Multi-task visual perception has a wide range of applications in scene
understanding such as autonomous driving. In this work, we devise an efficient
unified framework to solve multiple common perception tasks, including instance
segmentation, semantic segmentation, monocular 3D detection, and depth
estimation. Simply sharing the same visual feature representations for these
tasks impairs the performance of tasks, while independent task-specific feature
extractors lead to parameter redundancy and latency. Thus, we design two
feature-merge branches to learn feature basis, which can be useful to, and thus
shared by, multiple perception tasks. Then, each task takes the corresponding
feature basis as the input of the prediction task head to fulfill a specific
task. In particular, one feature merge branch is designed for instance-level
recognition the other for dense predictions. To enhance inter-branch
communication, the instance branch passes pixel-wise spatial information of
each instance to the dense branch using efficient dynamic convolution
weighting. Moreover, a simple but effective dynamic routing mechanism is
proposed to isolate task-specific features and leverage common properties among
tasks. Our proposed framework, termed D2BNet, demonstrates a unique approach to
parameter-efficient predictions for multi-task perception. In addition, as
tasks benefit from co-training with each other, our solution achieves on par
results on partially labeled settings on nuScenes and outperforms previous
works for 3D detection and depth estimation on the Cityscapes dataset with full
supervision.
\\ ( https://arxiv.org/abs/2306.05061 ,  1137kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05089
Date: Thu, 8 Jun 2023 10:48:11 GMT   (557kb)

Title: A review of UAV Visual Detection and Tracking Methods
Authors: Raed Abu Zitar, Mohammad Al-Betar, Mohamad Ryalat and Sofian
 Kassaymehd
Categories: cs.CV eess.SP
Comments: 10 pages
\\
 This paper presents a review of techniques used for the detection and
tracking of UAVs or drones. There are different techniques that depend on
collecting measurements of the position, velocity, and image of the UAV and
then using them in detection and tracking. Hybrid detection techniques are also
presented. The paper is a quick reference for a wide spectrum of methods that
are used in the drone detection process.
\\ ( https://arxiv.org/abs/2306.05089 ,  557kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05107
Date: Thu, 8 Jun 2023 11:15:04 GMT   (4694kb,D)

Title: Unsupervised augmentation optimization for few-shot medical image
 segmentation
Authors: Quan Quan, Shang Zhao, Qingsong Yao, Heqin Zhu, S. Kevin Zhou
Categories: cs.CV
\\
 The augmentation parameters matter to few-shot semantic segmentation since
they directly affect the training outcome by feeding the networks with varying
perturbated samples. However, searching optimal augmentation parameters for
few-shot segmentation models without annotations is a challenge that current
methods fail to address. In this paper, we first propose a framework to
determine the ``optimal'' parameters without human annotations by solving a
distribution-matching problem between the intra-instance and intra-class
similarity distribution, with the intra-instance similarity describing the
similarity between the original sample of a particular anatomy and its
augmented ones and the intra-class similarity representing the similarity
between the selected sample and the others in the same class. Extensive
experiments demonstrate the superiority of our optimized augmentation in
boosting few-shot segmentation models. We greatly improve the top competing
method by 1.27\% and 1.11\% on Abd-MRI and Abd-CT datasets, respectively, and
even achieve a significant improvement for SSL-ALP on the left kidney by 3.39\%
on the Abd-CT dataset.
\\ ( https://arxiv.org/abs/2306.05107 ,  4694kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05129
Date: Thu, 8 Jun 2023 11:54:37 GMT   (2606kb,D)

Title: Focus for Free in Density-Based Counting
Authors: Zenglin Shi, Pascal Mettes, Cees G.M. Snoek
Categories: cs.CV
Comments: 18 pages
\\
 This work considers supervised learning to count from images and their
corresponding point annotations. Where density-based counting methods typically
use the point annotations only to create Gaussian-density maps, which act as
the supervision signal, the starting point of this work is that point
annotations have counting potential beyond density map generation. We introduce
two methods that repurpose the available point annotations to enhance counting
performance. The first is a counting-specific augmentation that leverages point
annotations to simulate occluded objects in both input and density images to
enhance the network's robustness to occlusions. The second method, foreground
distillation, generates foreground masks from the point annotations, from which
we train an auxiliary network on images with blacked-out backgrounds. By doing
so, it learns to extract foreground counting knowledge without interference
from the background. These methods can be seamlessly integrated with existing
counting advances and are adaptable to different loss functions. We demonstrate
complementary effects of the approaches, allowing us to achieve robust counting
results even in challenging scenarios such as background clutter, occlusion,
and varying crowd densities. Our proposed approach achieves strong counting
results on multiple datasets, including ShanghaiTech Part\_A and Part\_B,
UCF\_QNRF, JHU-Crowd++, and NWPU-Crowd.
\\ ( https://arxiv.org/abs/2306.05129 ,  2606kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05135
Date: Thu, 8 Jun 2023 12:02:03 GMT   (10020kb,D)

Title: Does Image Anonymization Impact Computer Vision Training?
Authors: H{\aa}kon Hukkel{\aa}s, Frank Lindseth
Categories: cs.CV cs.AI
Comments: Accepted at CVPR Workshop on Autonomous Driving 2023
\\
 Image anonymization is widely adapted in practice to comply with privacy
regulations in many regions. However, anonymization often degrades the quality
of the data, reducing its utility for computer vision development. In this
paper, we investigate the impact of image anonymization for training computer
vision models on key computer vision tasks (detection, instance segmentation,
and pose estimation). Specifically, we benchmark the recognition drop on common
detection datasets, where we evaluate both traditional and realistic
anonymization for faces and full bodies. Our comprehensive experiments reflect
that traditional image anonymization substantially impacts final model
performance, particularly when anonymizing the full body. Furthermore, we find
that realistic anonymization can mitigate this decrease in performance, where
our experiments reflect a minimal performance drop for face anonymization. Our
study demonstrates that realistic anonymization can enable privacy-preserving
computer vision development with minimal performance degradation across a range
of important computer vision benchmarks.
\\ ( https://arxiv.org/abs/2306.05135 ,  10020kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05144
Date: Thu, 8 Jun 2023 12:11:16 GMT   (2708kb,D)

Title: Mesogeos: A multi-purpose dataset for data-driven wildfire modeling in
 the Mediterranean
Authors: Spyros Kondylatos, Ioannis Prapas, Gustau Camps-Valls, Ioannis
 Papoutsis
Categories: cs.CV cs.LG
\\
 We introduce Mesogeos, a large-scale multi-purpose dataset for wildfire
modeling in the Mediterranean. Mesogeos integrates variables representing
wildfire drivers (meteorology, vegetation, human activity) and historical
records of wildfire ignitions and burned areas for 17 years (2006-2022). It is
designed as a cloud-friendly spatio-temporal dataset, namely a datacube,
harmonizing all variables in a grid of 1km x 1km x 1-day resolution. The
datacube structure offers opportunities to assess machine learning (ML) usage
in various wildfire modeling tasks. We extract two ML-ready datasets that
establish distinct tracks to demonstrate this potential: (1) short-term
wildfire danger forecasting and (2) final burned area estimation given the
point of ignition. We define appropriate metrics and baselines to evaluate the
performance of models in each track. By publishing the datacube, along with the
code to create the ML datasets and models, we encourage the community to foster
the implementation of additional tracks for mitigating the increasing threat of
wildfires in the Mediterranean.
\\ ( https://arxiv.org/abs/2306.05144 ,  2708kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05145
Date: Thu, 8 Jun 2023 12:12:02 GMT   (2740kb,D)

Title: Variable Radiance Field for Real-Life Category-Specifc Reconstruction
 from Single Image
Authors: Kun Wang, Zhiqiang Yan, Zhenyu Zhang, Xiang Li, Jun Li, and Jian Yang
Categories: cs.CV
\\
 Reconstructing category-specific objects from a single image is a challenging
task that requires inferring the geometry and appearance of an object from a
limited viewpoint. Existing methods typically rely on local feature retrieval
based on re-projection with known camera intrinsic, which are slow and prone to
distortion at viewpoints distant from the input image. In this paper, we
present Variable Radiance Field (VRF), a novel framework that can efficiently
reconstruct category-specific objects from a single image without known camera
parameters. Our key contributions are: (1) We parameterize the geometry and
appearance of the object using a multi-scale global feature extractor, which
avoids frequent point-wise feature retrieval and camera dependency. We also
propose a contrastive learning-based pretraining strategy to improve the
feature extractor. (2) We reduce the geometric complexity of the object by
learning a category template, and use hypernetworks to generate a small neural
radiance field for fast and instance-specific rendering. (3) We align each
training instance to the template space using a learned similarity
transformation, which enables semantic-consistent learning across different
objects. We evaluate our method on the CO3D dataset and show that it
outperforms existing methods in terms of quality and speed. We also demonstrate
its applicability to shape interpolation and object placement tasks.
\\ ( https://arxiv.org/abs/2306.05145 ,  2740kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05147
Date: Thu, 8 Jun 2023 12:15:16 GMT   (1809kb,D)

Title: Human Action Recognition in Egocentric Perspective Using 2D Object and
 Hands Pose
Authors: Wiktor Mucha and Martin Kampel
Categories: cs.CV
\\
 Egocentric action recognition is essential for healthcare and assistive
technology that relies on egocentric cameras because it allows for the
automatic and continuous monitoring of activities of daily living (ADLs)
without requiring any conscious effort from the user. This study explores the
feasibility of using 2D hand and object pose information for egocentric action
recognition. While current literature focuses on 3D hand pose information, our
work shows that using 2D skeleton data is a promising approach for hand-based
action classification, might offer privacy enhancement, and could be less
computationally demanding. The study uses a state-of-the-art transformer-based
method to classify sequences and achieves validation results of 94%,
outperforming other existing solutions. The accuracy of the test subset drops
to 76%, indicating the need for further generalization improvement. This
research highlights the potential of 2D hand and object pose information for
action recognition tasks and offers a promising alternative to 3D-based
methods.
\\ ( https://arxiv.org/abs/2306.05147 ,  1809kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05178
Date: Thu, 8 Jun 2023 13:18:23 GMT   (42873kb,D)

Title: SyncDiffusion: Coherent Montage via Synchronized Joint Diffusions
Authors: Yuseung Lee, Kunho Kim, Hyunjin Kim, Minhyuk Sung
Categories: cs.CV
Comments: Project page: https://syncdiffusion.github.io
\\
 The remarkable capabilities of pretrained image diffusion models have been
utilized not only for generating fixed-size images but also for creating
panoramas. However, naive stitching of multiple images often results in visible
seams. Recent techniques have attempted to address this issue by performing
joint diffusions in multiple windows and averaging latent features in
overlapping regions. However, these approaches, which focus on seamless montage
generation, often yield incoherent outputs by blending different scenes within
a single image. To overcome this limitation, we propose SyncDiffusion, a
plug-and-play module that synchronizes multiple diffusions through gradient
descent from a perceptual similarity loss. Specifically, we compute the
gradient of the perceptual loss using the predicted denoised images at each
denoising step, providing meaningful guidance for achieving coherent montages.
Our experimental results demonstrate that our method produces significantly
more coherent outputs compared to previous methods (66.35% vs. 33.65% in our
user study) while still maintaining fidelity (as assessed by GIQA) and
compatibility with the input prompt (as measured by CLIP score).
\\ ( https://arxiv.org/abs/2306.05178 ,  42873kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05182
Date: Mon, 15 May 2023 18:38:25 GMT   (7175kb,D)

Title: Interactive Fashion Content Generation Using LLMs and Latent Diffusion
 Models
Authors: Krishna Sri Ipsit Mantri and Nevasini Sasikumar
Categories: cs.CV cs.LG
Comments: Third Workshop on Ethical Considerations in Creative applications of
 Computer Vision (EC3V) at CVPR 2023. arXiv admin note: substantial text
 overlap with arXiv:2301.02110 by other authors
\\
 Fashionable image generation aims to synthesize images of diverse fashion
prevalent around the globe, helping fashion designers in real-time
visualization by giving them a basic customized structure of how a specific
design preference would look in real life and what further improvements can be
made for enhanced customer satisfaction. Moreover, users can alone interact and
generate fashionable images by just giving a few simple prompts. Recently,
diffusion models have gained popularity as generative models owing to their
flexibility and generation of realistic images from Gaussian noise. Latent
diffusion models are a type of generative model that use diffusion processes to
model the generation of complex data, such as images, audio, or text. They are
called "latent" because they learn a hidden representation, or latent variable,
of the data that captures its underlying structure. We propose a method
exploiting the equivalence between diffusion models and energy-based models
(EBMs) and suggesting ways to compose multiple probability distributions. We
describe a pipeline on how our method can be used specifically for new
fashionable outfit generation and virtual try-on using LLM-guided text-to-image
generation. Our results indicate that using an LLM to refine the prompts to the
latent diffusion model assists in generating globally creative and culturally
diversified fashion styles and reducing bias.
\\ ( https://arxiv.org/abs/2306.05182 ,  7175kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05225
Date: Thu, 8 Jun 2023 14:21:02 GMT   (22224kb,D)

Title: Boosting Adversarial Transferability by Achieving Flat Local Maxima
Authors: Zhijin Ge, Fanhua Shang, Hongying Liu, Yuanyuan Liu, Xiaosen Wang
Categories: cs.CV cs.CR cs.LG
Comments: 17 pages, 5 figures, 6 tables
ACM-class: I.4.0; I.2.10
\\
 Transfer-based attack adopts the adversarial examples generated on the
surrogate model to attack various models, making it applicable in the physical
world and attracting increasing interest. Recently, various adversarial attacks
have emerged to boost adversarial transferability from different perspectives.
In this work, inspired by the fact that flat local minima are correlated with
good generalization, we assume and empirically validate that adversarial
examples at a flat local region tend to have good transferability by
introducing a penalized gradient norm to the original loss function. Since
directly optimizing the gradient regularization norm is computationally
expensive and intractable for generating adversarial examples, we propose an
approximation optimization method to simplify the gradient update of the
objective function. Specifically, we randomly sample an example and adopt the
first-order gradient to approximate the second-order Hessian matrix, which
makes computing more efficient by interpolating two Jacobian matrices.
Meanwhile, in order to obtain a more stable gradient direction, we randomly
sample multiple examples and average the gradients of these examples to reduce
the variance due to random sampling during the iterative process. Extensive
experimental results on the ImageNet-compatible dataset show that the proposed
method can generate adversarial examples at flat local regions, and
significantly improve the adversarial transferability on either normally
trained models or adversarially trained models than the state-of-the-art
attacks.
\\ ( https://arxiv.org/abs/2306.05225 ,  22224kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05236
Date: Thu, 8 Jun 2023 14:33:41 GMT   (19246kb,D)

Title: Population-Based Evolutionary Gaming for Unsupervised Person
 Re-identification
Authors: Yunpeng Zhai, Peixi Peng, Mengxi Jia, Shiyong Li, Weiqiang Chen,
 Xuesong Gao, Yonghong Tian
Categories: cs.CV
Comments: Accepted in IJCV
\\
 Unsupervised person re-identification has achieved great success through the
self-improvement of individual neural networks. However, limited by the lack of
diversity of discriminant information, a single network has difficulty learning
sufficient discrimination ability by itself under unsupervised conditions. To
address this limit, we develop a population-based evolutionary gaming (PEG)
framework in which a population of diverse neural networks is trained
concurrently through selection, reproduction, mutation, and population mutual
learning iteratively. Specifically, the selection of networks to preserve is
modeled as a cooperative game and solved by the best-response dynamics, then
the reproduction and mutation are implemented by cloning and fluctuating
hyper-parameters of networks to learn more diversity, and population mutual
learning improves the discrimination of networks by knowledge distillation from
each other within the population. In addition, we propose a cross-reference
scatter (CRS) to approximately evaluate re-ID models without labeled samples
and adopt it as the criterion of network selection in PEG. CRS measures a
model's performance by indirectly estimating the accuracy of its predicted
pseudo-labels according to the cohesion and separation of the feature space.
Extensive experiments demonstrate that (1) CRS approximately measures the
performance of models without labeled samples; (2) and PEG produces new
state-of-the-art accuracy for person re-identification, indicating the great
potential of population-based network cooperative training for unsupervised
learning.
\\ ( https://arxiv.org/abs/2306.05236 ,  19246kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05238
Date: Thu, 8 Jun 2023 14:36:10 GMT   (1333kb,D)

Title: SparseTrack: Multi-Object Tracking by Performing Scene Decomposition
 based on Pseudo-Depth
Authors: Zelin Liu, Xinggang Wang, Cheng Wang, Wenyu Liu, Xiang Bai
Categories: cs.CV
Comments: 12 pages, 8 figures
\\
 Exploring robust and efficient association methods has always been an
important issue in multiple-object tracking (MOT). Although existing tracking
methods have achieved impressive performance, congestion and frequent
occlusions still pose challenging problems in multi-object tracking. We reveal
that performing sparse decomposition on dense scenes is a crucial step to
enhance the performance of associating occluded targets. To this end, we
propose a pseudo-depth estimation method for obtaining the relative depth of
targets from 2D images. Secondly, we design a depth cascading matching (DCM)
algorithm, which can use the obtained depth information to convert a dense
target set into multiple sparse target subsets and perform data association on
these sparse target subsets in order from near to far. By integrating the
pseudo-depth method and the DCM strategy into the data association process, we
propose a new tracker, called SparseTrack. SparseTrack provides a new
perspective for solving the challenging crowded scene MOT problem. Only using
IoU matching, SparseTrack achieves comparable performance with the
state-of-the-art (SOTA) methods on the MOT17 and MOT20 benchmarks. Code and
models are publicly available at \url{https://github.com/hustvl/SparseTrack}.
\\ ( https://arxiv.org/abs/2306.05238 ,  1333kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05239
Date: Thu, 8 Jun 2023 14:38:43 GMT   (12971kb,D)

Title: Point-Voxel Absorbing Graph Representation Learning for Event Stream
 based Recognition
Authors: Bo Jiang, Chengguo Yuan, Xiao Wang, Zhimin Bao, Lin Zhu, Bin Luo
Categories: cs.CV cs.NE
\\
 Considering the balance of performance and efficiency, sampled point and
voxel methods are usually employed to down-sample dense events into sparse
ones. After that, one popular way is to leverage a graph model which treats the
sparse points/voxels as nodes and adopts graph neural networks (GNNs) to learn
the representation for event data. Although good performance can be obtained,
however, their results are still limited mainly due to two issues. (1) Existing
event GNNs generally adopt the additional max (or mean) pooling layer to
summarize all node embeddings into a single graph-level representation for the
whole event data representation. However, this approach fails to capture the
importance of graph nodes and also fails to be fully aware of the node
representations. (2) Existing methods generally employ either a sparse point or
voxel graph representation model which thus lacks consideration of the
complementary between these two types of representation models. To address
these issues, in this paper, we propose a novel dual point-voxel absorbing
graph representation learning for event stream data representation. To be
specific, given the input event stream, we first transform it into the sparse
event cloud and voxel grids and build dual absorbing graph models for them
respectively. Then, we design a novel absorbing graph convolutional network
(AGCN) for our dual absorbing graph representation and learning. The key aspect
of the proposed AGCN is its ability to effectively capture the importance of
nodes and thus be fully aware of node representations in summarizing all node
representations through the introduced absorbing nodes. Finally, the event
representations of dual learning branches are concatenated together to extract
the complementary information of two cues. The output is then fed into a linear
layer for event data classification.
\\ ( https://arxiv.org/abs/2306.05239 ,  12971kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05242
Date: Thu, 8 Jun 2023 14:41:56 GMT   (9253kb,D)

Title: Efficient Multi-Task Scene Analysis with RGB-D Transformers
Authors: S\"ohnke Benedikt Fischedick, Daniel Seichter, Robin Schmidt, Leonard
 Rabes, and Horst-Michael Gross
Categories: cs.CV cs.RO
Comments: To be published in IEEE International Joint Conference on Neural
 Networks (IJCNN) 2023
\\
 Scene analysis is essential for enabling autonomous systems, such as mobile
robots, to operate in real-world environments. However, obtaining a
comprehensive understanding of the scene requires solving multiple tasks, such
as panoptic segmentation, instance orientation estimation, and scene
classification. Solving these tasks given limited computing and battery
capabilities on mobile platforms is challenging. To address this challenge, we
introduce an efficient multi-task scene analysis approach, called EMSAFormer,
that uses an RGB-D Transformer-based encoder to simultaneously perform the
aforementioned tasks. Our approach builds upon the previously published
EMSANet. However, we show that the dual CNN-based encoder of EMSANet can be
replaced with a single Transformer-based encoder. To achieve this, we
investigate how information from both RGB and depth data can be effectively
incorporated in a single encoder. To accelerate inference on robotic hardware,
we provide a custom NVIDIA TensorRT extension enabling highly optimization for
our EMSAFormer approach. Through extensive experiments on the commonly used
indoor datasets NYUv2, SUNRGB-D, and ScanNet, we show that our approach
achieves state-of-the-art performance while still enabling inference with up to
39.1 FPS on an NVIDIA Jetson AGX Orin 32 GB.
\\ ( https://arxiv.org/abs/2306.05242 ,  9253kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05246
Date: Thu, 8 Jun 2023 14:44:57 GMT   (12512kb,D)

Title: Mesh-MLP: An all-MLP Architecture for Mesh Classification and Semantic
 Segmentation
Authors: Qiujie Dong, Rui Xu, Xiaoran Gong, Zixiong Wang, Shuangmin Chen,
 Shiqing Xin, Changhe Tu
Categories: cs.CV cs.GR
Comments: 8 pages, 6 figures
\\
 With the rapid development of geometric deep learning techniques, many
mesh-based convolutional operators have been proposed to bridge irregular mesh
structures and popular backbone networks. In this paper, we show that while
convolutions are helpful, a simple architecture based exclusively on
multi-layer perceptrons (MLPs) is competent enough to deal with mesh
classification and semantic segmentation. Our new network architecture, named
Mesh-MLP, takes mesh vertices equipped with the heat kernel signature (HKS) and
dihedral angles as the input, replaces the convolution module of a ResNet with
Multi-layer Perceptron (MLP), and utilizes layer normalization (LN) to perform
the normalization of the layers. The all-MLP architecture operates in an
end-to-end fashion and does not include a pooling module. Extensive
experimental results on the mesh classification/segmentation tasks validate the
effectiveness of the all-MLP architecture.
\\ ( https://arxiv.org/abs/2306.05246 ,  12512kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05254
Date: Thu, 8 Jun 2023 14:49:32 GMT   (8028kb,D)

Title: Devil is in Channels: Contrastive Single Domain Generalization for
 Medical Image Segmentation
Authors: Shishuai Hu, Zehui Liao, Yong Xia
Categories: cs.CV
Comments: 12 pages, 5 figures
\\
 Deep learning-based medical image segmentation models suffer from performance
degradation when deployed to a new healthcare center. To address this issue,
unsupervised domain adaptation and multi-source domain generalization methods
have been proposed, which, however, are less favorable for clinical practice
due to the cost of acquiring target-domain data and the privacy concerns
associated with redistributing the data from multiple source domains. In this
paper, we propose a \textbf{C}hannel-level \textbf{C}ontrastive \textbf{S}ingle
\textbf{D}omain \textbf{G}eneralization (\textbf{C$^2$SDG}) model for medical
image segmentation. In C$^2$SDG, the shallower features of each image and its
style-augmented counterpart are extracted and used for contrastive training,
resulting in the disentangled style representations and structure
representations. The segmentation is performed based solely on the structure
representations. Our method is novel in the contrastive perspective that
enables channel-wise feature disentanglement using a single source domain. We
evaluated C$^2$SDG against six SDG methods on a multi-domain joint optic cup
and optic disc segmentation benchmark. Our results suggest the effectiveness of
each module in C$^2$SDG and also indicate that C$^2$SDG outperforms the
baseline and all competing methods with a large margin. The code will be
available at \url{https://github.com/ShishuaiHu/CCSDG}.
\\ ( https://arxiv.org/abs/2306.05254 ,  8028kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05262
Date: Thu, 8 Jun 2023 15:03:47 GMT   (12331kb,D)

Title: EXOT: Exit-aware Object Tracker for Safe Robotic Manipulation of Moving
 Object
Authors: Hyunseo Kim, Hye Jung Yoon, Minji Kim, Dong-Sig Han, and Byoung-Tak
 Zhang
Categories: cs.CV
Comments: 2023 IEEE International Conference on Robotics and Automation (ICRA)
\\
 Current robotic hand manipulation narrowly operates with objects in
predictable positions in limited environments. Thus, when the location of the
target object deviates severely from the expected location, a robot sometimes
responds in an unexpected way, especially when it operates with a human. For
safe robot operation, we propose the EXit-aware Object Tracker (EXOT) on a
robot hand camera that recognizes an object's absence during manipulation. The
robot decides whether to proceed by examining the tracker's bounding box output
containing the target object. We adopt an out-of-distribution classifier for
more accurate object recognition since trackers can mistrack a background as a
target object. To the best of our knowledge, our method is the first approach
of applying an out-of-distribution classification technique to a tracker
output. We evaluate our method on the first-person video benchmark dataset,
TREK-150, and on the custom dataset, RMOT-223, that we collect from the UR5e
robot. Then we test our tracker on the UR5e robot in real-time with a
conveyor-belt sushi task, to examine the tracker's ability to track target
dishes and to determine the exit status. Our tracker shows 38% higher
exit-aware performance than a baseline method. The dataset and the code will be
released at https://github.com/hskAlena/EXOT.
\\ ( https://arxiv.org/abs/2306.05262 ,  12331kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05272
Date: Thu, 8 Jun 2023 15:20:27 GMT   (38378kb,D)

Title: Image Clustering via the Principle of Rate Reduction in the Age of
 Pretrained Models
Authors: Tianzhe Chu, Shengbang Tong, Tianjiao Ding, Xili Dai, Benjamin David
 Haeffele, Rene Vidal, Yi Ma
Categories: cs.CV cs.LG
Comments: 21 pages, 13 figures
\\
 The advent of large pre-trained models has brought about a paradigm shift in
both visual representation learning and natural language processing. However,
clustering unlabeled images, as a fundamental and classic machine learning
problem, still lacks effective solution, particularly for large-scale datasets.
In this paper, we propose a novel image clustering pipeline that leverages the
powerful feature representation of large pre-trained models such as CLIP and
cluster images effectively and efficiently at scale. We show that the
pre-trained features are significantly more structured by further optimizing
the rate reduction objective. The resulting features may significantly improve
the clustering accuracy, e.g., from 57\% to 66\% on ImageNet-1k. Furthermore,
by leveraging CLIP's image-text binding, we show how the new clustering method
leads to a simple yet effective self-labeling algorithm that successfully works
on unlabeled large datasets such as MS-COCO and LAION-Aesthetics. We will
release the code in https://github.com/LeslieTrue/CPP.
\\ ( https://arxiv.org/abs/2306.05272 ,  38378kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05303
Date: Thu, 8 Jun 2023 15:49:30 GMT   (13779kb,D)

Title: Enhance-NeRF: Multiple Performance Evaluation for Neural Radiance Fields
Authors: Qianqiu Tan, Tao Liu, Yinling Xie, Shuwan Yu, Baohua Zhang
Categories: cs.CV
\\
 The quality of three-dimensional reconstruction is a key factor affecting the
effectiveness of its application in areas such as virtual reality (VR) and
augmented reality (AR) technologies. Neural Radiance Fields (NeRF) can generate
realistic images from any viewpoint. It simultaneously reconstructs the shape,
lighting, and materials of objects, and without surface defects, which breaks
down the barrier between virtuality and reality. The potential spatial
correspondences displayed by NeRF between reconstructed scenes and real-world
scenes offer a wide range of practical applications possibilities. Despite
significant progress in 3D reconstruction since NeRF were introduced, there
remains considerable room for exploration and experimentation. NeRF-based
models are susceptible to interference issues caused by colored "fog" noise.
Additionally, they frequently encounter instabilities and failures while
attempting to reconstruct unbounded scenes. Moreover, the model takes a
significant amount of time to converge, making it even more challenging to use
in such scenarios. Our approach, coined Enhance-NeRF, which adopts joint color
to balance low and high reflectivity objects display, utilizes a decoding
architecture with prior knowledge to improve recognition, and employs
multi-layer performance evaluation mechanisms to enhance learning capacity. It
achieves reconstruction of outdoor scenes within one hour under single-card
condition. Based on experimental results, Enhance-NeRF partially enhances
fitness capability and provides some support to outdoor scene reconstruction.
The Enhance-NeRF method can be used as a plug-and-play component, making it
easy to integrate with other NeRF-based models. The code is available at:
https://github.com/TANQIanQ/Enhance-NeRF
\\ ( https://arxiv.org/abs/2306.05303 ,  13779kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05311
Date: Thu, 8 Jun 2023 16:00:04 GMT   (17511kb,D)

Title: Predictive Modeling of Equine Activity Budgets Using a 3D Skeleton
 Reconstructed from Surveillance Recordings
Authors: Ernest Pokropek, Sofia Broom\'e, Pia Haubro Andersen, Hedvig
 Kjellstr\"om
Categories: cs.CV
Comments: 3rd Workshop on CV4Animals: Computer Vision for Animal Behavior
 Tracking and Modeling (in conjunction with CVPR 2023) [POSTER]
\\
 In this work, we present a pipeline to reconstruct the 3D pose of a horse
from 4 simultaneous surveillance camera recordings. Our environment poses
interesting challenges to tackle, such as limited field view of the cameras and
a relatively closed and small environment. The pipeline consists of training a
2D markerless pose estimation model to work on every viewpoint, then applying
it to the videos and performing triangulation. We present numerical evaluation
of the results (error analysis), as well as show the utility of the achieved
poses in downstream tasks of selected behavioral predictions. Our analysis of
the predictive model for equine behavior showed a bias towards pain-induced
horses, which aligns with our understanding of how behavior varies across
painful and healthy subjects.
\\ ( https://arxiv.org/abs/2306.05311 ,  17511kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05341
Date: Thu, 8 Jun 2023 16:45:16 GMT   (7884kb,D)

Title: Real-time GeoAI for High-resolution Mapping and Segmentation of Arctic
 Permafrost Features
Authors: Wenwen Li, Chia-Yu Hsu, Sizhe Wang, Chandi Witharana, Anna Liljedahl
Categories: cs.CV
\\
 This paper introduces a real-time GeoAI workflow for large-scale image
analysis and the segmentation of Arctic permafrost features at a
fine-granularity. Very high-resolution (0.5m) commercial imagery is used in
this analysis. To achieve real-time prediction, our workflow employs a
lightweight, deep learning-based instance segmentation model, SparseInst, which
introduces and uses Instance Activation Maps to accurately locate the position
of objects within the image scene. Experimental results show that the model can
achieve better accuracy of prediction at a much faster inference speed than the
popular Mask-RCNN model.
\\ ( https://arxiv.org/abs/2306.05341 ,  7884kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05356
Date: Thu, 8 Jun 2023 17:01:14 GMT   (31629kb,D)

Title: ReliableSwap: Boosting General Face Swapping Via Reliable Supervision
Authors: Ge Yuan, Maomao Li, Yong Zhang, Huicheng Zheng
Categories: cs.CV
Comments: Project page: https://reliable-swap.github.io/ ; Github repository:
 https://github.com/ygtxr1997/ReliableSwap ; Demo (HuggingFace):
 https://huggingface.co/spaces/ygtxr1997/ReliableSwap_Demo ;
\\
 Almost all advanced face swapping approaches use reconstruction as the proxy
task, i.e., supervision only exists when the target and source belong to the
same person. Otherwise, lacking pixel-level supervision, these methods struggle
for source identity preservation. This paper proposes to construct reliable
supervision, dubbed cycle triplets, which serves as the image-level guidance
when the source identity differs from the target one during training.
Specifically, we use face reenactment and blending techniques to synthesize the
swapped face from real images in advance, where the synthetic face preserves
source identity and target attributes. However, there may be some artifacts in
such a synthetic face. To avoid the potential artifacts and drive the
distribution of the network output close to the natural one, we reversely take
synthetic images as input while the real face as reliable supervision during
the training stage of face swapping. Besides, we empirically find that the
existing methods tend to lose lower-face details like face shape and mouth from
the source. This paper additionally designs a FixerNet, providing
discriminative embeddings of lower faces as an enhancement. Our face swapping
framework, named ReliableSwap, can boost the performance of any existing face
swapping network with negligible overhead. Extensive experiments demonstrate
the efficacy of our ReliableSwap, especially in identity preservation. The
project page is https://reliable-swap.github.io/.
\\ ( https://arxiv.org/abs/2306.05356 ,  31629kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05357
Date: Thu, 8 Jun 2023 17:02:15 GMT   (8066kb,D)

Title: Unsupervised Compositional Concepts Discovery with Text-to-Image
 Generative Models
Authors: Nan Liu, Yilun Du, Shuang Li, Joshua B. Tenenbaum, Antonio Torralba
Categories: cs.CV cs.AI cs.LG
Comments: Project Webpage:
 https://energy-based-model.github.io/unsupervised-concept-discovery/
\\
 Text-to-image generative models have enabled high-resolution image synthesis
across different domains, but require users to specify the content they wish to
generate. In this paper, we consider the inverse problem -- given a collection
of different images, can we discover the generative concepts that represent
each image? We present an unsupervised approach to discover generative concepts
from a collection of images, disentangling different art styles in paintings,
objects, and lighting from kitchen scenes, and discovering image classes given
ImageNet images. We show how such generative concepts can accurately represent
the content of images, be recombined and composed to generate new artistic and
hybrid images, and be further used as a representation for downstream
classification tasks.
\\ ( https://arxiv.org/abs/2306.05357 ,  8066kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05376
Date: Thu, 25 May 2023 19:17:39 GMT   (5084kb,D)

Title: Anomaly Detection in Satellite Videos using Diffusion Models
Authors: Akash Awasthi, Son Ly, Jaer Nizam, Samira Zare, Videet Mehta, Safwan
 Ahmed, Keshav Shah, Ramakrishna Nemani, Saurabh Prasad, Hien Van Nguyen
Categories: cs.CV cs.LG
\\
 The definition of anomaly detection is the identification of an unexpected
event. Real-time detection of extreme events such as wildfires, cyclones, or
floods using satellite data has become crucial for disaster management.
Although several earth-observing satellites provide information about
disasters, satellites in the geostationary orbit provide data at intervals as
frequent as every minute, effectively creating a video from space. There are
many techniques that have been proposed to identify anomalies in surveillance
videos; however, the available datasets do not have dynamic behavior, so we
discuss an anomaly framework that can work on very high-frequency datasets to
find very fast-moving anomalies. In this work, we present a diffusion model
which does not need any motion component to capture the fast-moving anomalies
and outperforms the other baseline methods.
\\ ( https://arxiv.org/abs/2306.05376 ,  5084kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05381
Date: Thu, 25 May 2023 08:59:26 GMT   (2430kb,D)

Title: FollowNet: A Comprehensive Benchmark for Car-Following Behavior Modeling
Authors: Xianda Chen, Meixin Zhu, Kehua Chen, Pengqin Wang, Hongliang Lu, Hui
 Zhong, Xu Han, Yinhai Wang
Categories: cs.CV cs.AI
\\
 Car-following is a control process in which a following vehicle (FV) adjusts
its acceleration to keep a safe distance from the lead vehicle (LV). Recently,
there has been a booming of data-driven models that enable more accurate
modeling of car-following through real-world driving datasets. Although there
are several public datasets available, their formats are not always consistent,
making it challenging to determine the state-of-the-art models and how well a
new model performs compared to existing ones. In contrast, research fields such
as image recognition and object detection have benchmark datasets like
ImageNet, Microsoft COCO, and KITTI. To address this gap and promote the
development of microscopic traffic flow modeling, we establish a public
benchmark dataset for car-following behavior modeling. The benchmark consists
of more than 80K car-following events extracted from five public driving
datasets using the same criteria. These events cover diverse situations
including different road types, various weather conditions, and mixed traffic
flows with autonomous vehicles. Moreover, to give an overview of current
progress in car-following modeling, we implemented and tested representative
baseline models with the benchmark. Results show that the deep deterministic
policy gradient (DDPG) based model performs competitively with a lower MSE for
spacing compared to traditional intelligent driver model (IDM) and
Gazis-Herman-Rothery (GHR) models, and a smaller collision rate compared to
fully connected neural network (NN) and long short-term memory (LSTM) models in
most datasets. The established benchmark will provide researchers with
consistent data formats and metrics for cross-comparing different car-following
models, promoting the development of more accurate models. We open-source our
dataset and implementation code in
https://github.com/HKUST-DRIVE-AI-LAB/FollowNet.
\\ ( https://arxiv.org/abs/2306.05381 ,  2430kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05382
Date: Thu, 8 Jun 2023 17:31:24 GMT   (3904kb,D)

Title: Automatic Image Blending Algorithm Based on SAM and DINO
Authors: Haochen Xue, Mingyu Jin, Chong Zhang, Yuxuan Huang, Qian Weng, Xiaobo
 Jin
Categories: cs.CV
Comments: 14 pages, 9 figure
\\
 The field of image blending has gained significant popularity in recent years
due to its ability to create visually stunning content. The main objective of
image blending is to merge an object from one image onto another seamlessly,
with minor masking adjustments. With the recent development of SAM, which can
detect and segment targets in images automatically. Our approach (1) combines
semantic object detection and segmentation with corresponding mask generation
to automatically fuse images and (2) introduces the use of PAN for further
quality enhancement during the fusion process. Our approach surpasses many
classical visual fusion models in various performance indicators such as PSNR,
SSIM, and Realism. Notably, our process is highly efficient and speedy, making
it widely applicable in industrial settings. This new process has the potential
to revolutionize visual content creation and improve productivity across
various industries.
\\ ( https://arxiv.org/abs/2306.05382 ,  3904kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05390
Date: Thu, 8 Jun 2023 17:44:21 GMT   (23030kb,D)

Title: HQ-50K: A Large-scale, High-quality Dataset for Image Restoration
Authors: Qinhong Yang and Dongdong Chen and Zhentao Tan and Qiankun Liu and Qi
 Chu and Jianmin Bao and Lu Yuan and Gang Hua and Nenghai Yu
Categories: cs.CV
Comments: Dataset and code will be available at
 https://github.com/littleYaang/HQ-50K
\\
 This paper introduces a new large-scale image restoration dataset, called
HQ-50K, which contains 50,000 high-quality images with rich texture details and
semantic diversity. We analyze existing image restoration datasets from five
different perspectives, including data scale, resolution, compression rates,
texture details, and semantic coverage. However, we find that all of these
datasets are deficient in some aspects. In contrast, HQ-50K considers all of
these five aspects during the data curation process and meets all requirements.
We also present a new Degradation-Aware Mixture of Expert (DAMoE) model, which
enables a single model to handle multiple corruption types and unknown levels.
Our extensive experiments demonstrate that HQ-50K consistently improves the
performance on various image restoration tasks, such as super-resolution,
denoising, dejpeg, and deraining. Furthermore, our proposed DAMoE, trained on
our \dataset, outperforms existing state-of-the-art unified models designed for
multiple restoration tasks and levels. The dataset and code are available at
\url{https://github.com/littleYaang/HQ-50K}.
\\ ( https://arxiv.org/abs/2306.05390 ,  23030kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05399
Date: Thu, 8 Jun 2023 17:51:58 GMT   (13575kb,D)

Title: Matting Anything
Authors: Jiachen Li, Jitesh Jain, Humphrey Shi
Categories: cs.CV
Comments: Project web-page:
 https://chrisjuniorli.github.io/project/Matting-Anything/
\\
 In this paper, we propose the Matting Anything Model (MAM), an efficient and
versatile framework for estimating the alpha matte of any instance in an image
with flexible and interactive visual or linguistic user prompt guidance. MAM
offers several significant advantages over previous specialized image matting
networks: (i) MAM is capable of dealing with various types of image matting,
including semantic, instance, and referring image matting with only a single
model; (ii) MAM leverages the feature maps from the Segment Anything Model
(SAM) and adopts a lightweight Mask-to-Matte (M2M) module to predict the alpha
matte through iterative refinement, which has only 2.7 million trainable
parameters. (iii) By incorporating SAM, MAM simplifies the user intervention
required for the interactive use of image matting from the trimap to the box,
point, or text prompt. We evaluate the performance of MAM on various image
matting benchmarks, and the experimental results demonstrate that MAM achieves
comparable performance to the state-of-the-art specialized image matting models
under different metrics on each benchmark. Overall, MAM shows superior
generalization ability and can effectively handle various image matting tasks
with fewer parameters, making it a practical solution for unified image
matting. Our code and models are open-sourced at
https://github.com/SHI-Labs/Matting-Anything.
\\ ( https://arxiv.org/abs/2306.05399 ,  13575kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05407
Date: Thu, 8 Jun 2023 17:54:47 GMT   (13023kb,D)

Title: SNAP: Self-Supervised Neural Maps for Visual Positioning and Semantic
 Understanding
Authors: Paul-Edouard Sarlin, Eduard Trulls, Marc Pollefeys, Jan Hosang, Simon
 Lynen
Categories: cs.CV
\\
 Semantic 2D maps are commonly used by humans and machines for navigation
purposes, whether it's walking or driving. However, these maps have
limitations: they lack detail, often contain inaccuracies, and are difficult to
create and maintain, especially in an automated fashion. Can we use raw imagery
to automatically create better maps that can be easily interpreted by both
humans and machines? We introduce SNAP, a deep network that learns rich neural
2D maps from ground-level and overhead images. We train our model to align
neural maps estimated from different inputs, supervised only with camera poses
over tens of millions of StreetView images. SNAP can resolve the location of
challenging image queries beyond the reach of traditional methods,
outperforming the state of the art in localization by a large margin. Moreover,
our neural maps encode not only geometry and appearance but also high-level
semantics, discovered without explicit supervision. This enables effective
pre-training for data-efficient semantic scene understanding, with the
potential to unlock cost-efficient creation of more detailed maps.
\\ ( https://arxiv.org/abs/2306.05407 ,  13023kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05410
Date: Thu, 8 Jun 2023 17:56:22 GMT   (13327kb,D)

Title: LU-NeRF: Scene and Pose Estimation by Synchronizing Local Unposed NeRFs
Authors: Zezhou Cheng, Carlos Esteves, Varun Jampani, Abhishek Kar, Subhransu
 Maji, Ameesh Makadia
Categories: cs.CV
Comments: Project website: https://people.cs.umass.edu/~zezhoucheng/lu-nerf/
\\
 A critical obstacle preventing NeRF models from being deployed broadly in the
wild is their reliance on accurate camera poses. Consequently, there is growing
interest in extending NeRF models to jointly optimize camera poses and scene
representation, which offers an alternative to off-the-shelf SfM pipelines
which have well-understood failure modes. Existing approaches for unposed NeRF
operate under limited assumptions, such as a prior pose distribution or coarse
pose initialization, making them less effective in a general setting. In this
work, we propose a novel approach, LU-NeRF, that jointly estimates camera poses
and neural radiance fields with relaxed assumptions on pose configuration. Our
approach operates in a local-to-global manner, where we first optimize over
local subsets of the data, dubbed mini-scenes. LU-NeRF estimates local pose and
geometry for this challenging few-shot task. The mini-scene poses are brought
into a global reference frame through a robust pose synchronization step, where
a final global optimization of pose and scene can be performed. We show our
LU-NeRF pipeline outperforms prior attempts at unposed NeRF without making
restrictive assumptions on the pose prior. This allows us to operate in the
general SE(3) pose setting, unlike the baselines. Our results also indicate our
model can be complementary to feature-based SfM pipelines as it compares
favorably to COLMAP on low-texture and low-resolution images.
\\ ( https://arxiv.org/abs/2306.05410 ,  13327kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05411
Date: Thu, 8 Jun 2023 17:56:46 GMT   (13290kb,D)

Title: R-MAE: Regions Meet Masked Autoencoders
Authors: Duy-Kien Nguyen, Vaibhav Aggarwal, Yanghao Li, Martin R. Oswald,
 Alexander Kirillov, Cees G. M. Snoek, Xinlei Chen
Categories: cs.CV
\\
 Vision-specific concepts such as "region" have played a key role in extending
general machine learning frameworks to tasks like object detection. Given the
success of region-based detectors for supervised learning and the progress of
intra-image methods for contrastive learning, we explore the use of regions for
reconstructive pre-training. Starting from Masked Autoencoding (MAE) both as a
baseline and an inspiration, we propose a parallel pre-text task tailored to
address the one-to-many mapping between images and regions. Since such regions
can be generated in an unsupervised way, our approach (R-MAE) inherits the wide
applicability from MAE, while being more "region-aware". We conduct thorough
analyses during the development of R-MAE, and converge on a variant that is
both effective and efficient (1.3% overhead over MAE). Moreover, it shows
consistent quantitative improvements when generalized to various pre-training
data and downstream detection and segmentation benchmarks. Finally, we provide
extensive qualitative visualizations to enhance the understanding of R-MAE's
behaviour and potential. Code will be made available at
https://github.com/facebookresearch/r-mae.
\\ ( https://arxiv.org/abs/2306.05411 ,  13290kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05414
Date: Thu, 8 Jun 2023 17:57:18 GMT   (22503kb,D)

Title: Improving Negative-Prompt Inversion via Proximal Guidance
Authors: Ligong Han, Song Wen, Qi Chen, Zhixing Zhang, Kunpeng Song, Mengwei
 Ren, Ruijiang Gao, Yuxiao Chen, Di Liu, Qilong Zhangli, Anastasis
 Stathopoulos, Jindong Jiang, Zhaoyang Xia, Akash Srivastava, Dimitris Metaxas
Categories: cs.CV
Comments: Code at https://github.com/phymhan/prompt-to-prompt
\\
 DDIM inversion has revealed the remarkable potential of real image editing
within diffusion-based methods. However, the accuracy of DDIM reconstruction
degrades as larger classifier-free guidance (CFG) scales being used for
enhanced editing. Null-text inversion (NTI) optimizes null embeddings to align
the reconstruction and inversion trajectories with larger CFG scales, enabling
real image editing with cross-attention control. Negative-prompt inversion
(NPI) further offers a training-free closed-form solution of NTI. However, it
may introduce artifacts and is still constrained by DDIM reconstruction
quality. To overcome these limitations, we propose Proximal Negative-Prompt
Inversion (ProxNPI), extending the concepts of NTI and NPI. We enhance NPI with
a regularization term and reconstruction guidance, which reduces artifacts
while capitalizing on its training-free nature. Our method provides an
efficient and straightforward approach, effectively addressing real image
editing tasks with minimal computational overhead.
\\ ( https://arxiv.org/abs/2306.05414 ,  22503kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05416
Date: Thu, 8 Jun 2023 17:58:45 GMT   (1558kb,D)

Title: Tracking Objects with 3D Representation from Videos
Authors: Jiawei He, Lue Fan, Yuqi Wang, Yuntao Chen, Zehao Huang, Naiyan Wang,
 Zhaoxiang Zhang
Categories: cs.CV
Comments: Technical report
\\
 Data association is a knotty problem for 2D Multiple Object Tracking due to
the object occlusion. However, in 3D space, data association is not so hard.
Only with a 3D Kalman Filter, the online object tracker can associate the
detections from LiDAR. In this paper, we rethink the data association in 2D MOT
and utilize the 3D object representation to separate each object in the feature
space. Unlike the existing depth-based MOT methods, the 3D object
representation can be jointly learned with the object association module.
Besides, the object's 3D representation is learned from the video and
supervised by the 2D tracking labels without additional manual annotations from
LiDAR or pretrained depth estimator. With 3D object representation learning
from Pseudo 3D object labels in monocular videos, we propose a new 2D MOT
paradigm, called P3DTrack. Extensive experiments show the effectiveness of our
method. We achieve new state-of-the-art performance on the large-scale Waymo
Open Dataset.
\\ ( https://arxiv.org/abs/2306.05416 ,  1558kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05418
Date: Thu, 8 Jun 2023 17:58:57 GMT   (1581kb,D)

Title: 2D Supervised Monocular 3D Object Detection by Global-to-Local 3D
 Reconstruction
Authors: Jiawei He, Yuqi Wang, Yuntao Chen, Zhaoxiang Zhang
Categories: cs.CV
Comments: Project page: https://ba2det.site
\\
 With the advent of the big model era, the demand for data has become more
important. Especially in monocular 3D object detection, expensive manual
annotations potentially limit further developments. Existing works have
investigated weakly supervised algorithms with the help of LiDAR modality to
generate 3D pseudo labels, which cannot be applied to ordinary videos. In this
paper, we propose a novel paradigm, termed as BA$^2$-Det, leveraging the idea
of global-to-local 3D reconstruction for 2D supervised monocular 3D object
detection. Specifically, we recover 3D structures from monocular videos by
scene-level global reconstruction with global bundle adjustment (BA) and obtain
object clusters by the DoubleClustering algorithm. Learning from completely
reconstructed objects in global BA, GBA-Learner predicts pseudo labels for
occluded objects. Finally, we train an LBA-Learner with object-centric local BA
to generalize the generated 3D pseudo labels to moving objects. Experiments on
the large-scale Waymo Open Dataset show that the performance of BA$^2$-Det is
on par with the fully-supervised BA-Det trained with 10% videos and even
outperforms some pioneer fully-supervised methods. We also show the great
potential of BA$^2$-Det for detecting open-set 3D objects in complex scenes.
The code will be made available. Project page: https://ba2det.site .
\\ ( https://arxiv.org/abs/2306.05418 ,  1581kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05419
Date: Thu, 8 Jun 2023 17:58:57 GMT   (130kb,D)

Title: TopoMask: Instance-Mask-Based Formulation for the Road Topology Problem
 via Transformer-Based Architecture
Authors: M. Esat Kalfaoglu, Halil Ibrahim Ozturk, Ozsel Kilinc, Alptekin
 Temizel
Categories: cs.CV cs.AI cs.LG
Comments: 4th in OLS and 2nd in the F1-score in OpenLane Topology Challenge
 2023
\\
 Driving scene understanding task involves detecting static elements such as
lanes, traffic signs, and traffic lights, and their relationships with each
other. To facilitate the development of comprehensive scene understanding
solutions using multiple camera views, a new dataset called Road Genome
(OpenLane-V2) has been released. This dataset allows for the exploration of
complex road connections and situations where lane markings may be absent.
Instead of using traditional lane markings, the lanes in this dataset are
represented by centerlines, which offer a more suitable representation of lanes
and their connections. In this study, we have introduced a new approach called
TopoMask for predicting centerlines in road topology. Unlike existing
approaches in the literature that rely on keypoints or parametric methods,
TopoMask utilizes an instance-mask based formulation with a transformer-based
architecture and, in order to enrich the mask instances with flow information,
a direction label representation is proposed. TopoMask have ranked 4th in the
OpenLane-V2 Score (OLS) and ranked 2nd in the F1 score of centerline prediction
in OpenLane Topology Challenge 2023. In comparison to the current
state-of-the-art method, TopoNet, the proposed method has achieved similar
performance in Frechet-based lane detection and outperformed TopoNet in
Chamfer-based lane detection without utilizing its scene graph neural network.
\\ ( https://arxiv.org/abs/2306.05419 ,  130kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05421
Date: Thu, 8 Jun 2023 17:59:09 GMT   (32594kb,D)

Title: Stochastic Multi-Person 3D Motion Forecasting
Authors: Sirui Xu, Yu-Xiong Wang, Liang-Yan Gui
Categories: cs.CV
Comments: ICLR 2023 (Top 25% Paper); Project Page:
 https://sirui-xu.github.io/DuMMF
\\
 This paper aims to deal with the ignored real-world complexities in prior
work on human motion forecasting, emphasizing the social properties of
multi-person motion, the diversity of motion and social interactions, and the
complexity of articulated motion. To this end, we introduce a novel task of
stochastic multi-person 3D motion forecasting. We propose a dual-level
generative modeling framework that separately models independent individual
motion at the local level and social interactions at the global level. Notably,
this dual-level modeling mechanism can be achieved within a shared generative
model, through introducing learnable latent codes that represent intents of
future motion and switching the codes' modes of operation at different levels.
Our framework is general; we instantiate it with different generative models,
including generative adversarial networks and diffusion models, and various
multi-person forecasting models. Extensive experiments on CMU-Mocap, MuPoTS-3D,
and SoMoF benchmarks show that our approach produces diverse and accurate
multi-person predictions, significantly outperforming the state of the art.
\\ ( https://arxiv.org/abs/2306.05421 ,  32594kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05422
Date: Thu, 8 Jun 2023 17:59:29 GMT   (10975kb,D)

Title: Tracking Everything Everywhere All at Once
Authors: Qianqian Wang, Yen-Yu Chang, Ruojin Cai, Zhengqi Li, Bharath
 Hariharan, Aleksander Holynski, Noah Snavely
Categories: cs.CV
\\
 We present a new test-time optimization method for estimating dense and
long-range motion from a video sequence. Prior optical flow or particle video
tracking algorithms typically operate within limited temporal windows,
struggling to track through occlusions and maintain global consistency of
estimated motion trajectories. We propose a complete and globally consistent
motion representation, dubbed OmniMotion, that allows for accurate, full-length
motion estimation of every pixel in a video. OmniMotion represents a video
using a quasi-3D canonical volume and performs pixel-wise tracking via
bijections between local and canonical space. This representation allows us to
ensure global consistency, track through occlusions, and model any combination
of camera and object motion. Extensive evaluations on the TAP-Vid benchmark and
real-world footage show that our approach outperforms prior state-of-the-art
methods by a large margin both quantitatively and qualitatively. See our
project page for more results: http://omnimotion.github.io/
\\ ( https://arxiv.org/abs/2306.05422 ,  10975kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05423
Date: Thu, 8 Jun 2023 17:59:32 GMT   (15514kb,D)

Title: ADDP: Learning General Representations for Image Recognition and
 Generation with Alternating Denoising Diffusion Process
Authors: Changyao Tian, Chenxin Tao, Jifeng Dai, Hao Li, Ziheng Li, Lewei Lu,
 Xiaogang Wang, Hongsheng Li, Gao Huang, Xizhou Zhu
Categories: cs.CV
\\
 Image recognition and generation have long been developed independently of
each other. With the recent trend towards general-purpose representation
learning, the development of general representations for both recognition and
generation tasks is also promoted. However, preliminary attempts mainly focus
on generation performance, but are still inferior on recognition tasks. These
methods are modeled in the vector-quantized (VQ) space, whereas leading
recognition methods use pixels as inputs. Our key insights are twofold: (1)
pixels as inputs are crucial for recognition tasks; (2) VQ tokens as
reconstruction targets are beneficial for generation tasks. These observations
motivate us to propose an Alternating Denoising Diffusion Process (ADDP) that
integrates these two spaces within a single representation learning framework.
In each denoising step, our method first decodes pixels from previous VQ
tokens, then generates new VQ tokens from the decoded pixels. The diffusion
process gradually masks out a portion of VQ tokens to construct the training
samples. The learned representations can be used to generate diverse
high-fidelity images and also demonstrate excellent transfer performance on
recognition tasks. Extensive experiments show that our method achieves
competitive performance on unconditional generation, ImageNet classification,
COCO detection, and ADE20k segmentation. Importantly, our method represents the
first successful development of general representations applicable to both
generation and dense recognition tasks. Code shall be released.
\\ ( https://arxiv.org/abs/2306.05423 ,  15514kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05424
Date: Thu, 8 Jun 2023 17:59:56 GMT   (8711kb,D)

Title: Video-ChatGPT: Towards Detailed Video Understanding via Large Vision and
 Language Models
Authors: Muhammad Maaz, Hanoona Rasheed, Salman Khan, Fahad Shahbaz Khan
Categories: cs.CV
\\
 Conversation agents fueled by Large Language Models (LLMs) are providing a
new way to interact with visual data. While there have been initial attempts
for image-based conversation models, this work addresses the underexplored
field of video-based conversation by introducing Video-ChatGPT. It is a
multimodal model that merges a video-adapted visual encoder with a LLM. The
model is capable of understanding and generating human-like conversations about
videos. We introduce a new dataset of 100,000 video-instruction pairs used to
train Video-ChatGPT acquired via manual and semi-automated pipeline that is
easily scalable and robust to label noise. We also develop a quantiative
evaluation framework for video-based dialogue models to objectively analyse the
strengths and weaknesses of proposed models. Our code, models, instruction-sets
and demo are released at https://github.com/mbzuai-oryx/Video-ChatGPT.
\\ ( https://arxiv.org/abs/2306.05424 ,  8711kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05425
Date: Thu, 8 Jun 2023 17:59:56 GMT   (13621kb,D)

Title: MIMIC-IT: Multi-Modal In-Context Instruction Tuning
Authors: Bo Li, Yuanhan Zhang, Liangyu Chen, Jinghao Wang, Fanyi Pu, Jingkang
 Yang, Chunyuan Li, Ziwei Liu
Categories: cs.CV cs.AI cs.CL cs.HC
Comments: Project page: https://otter-ntu.github.io/ Dataset & code:
 https://github.com/Luodian/otter Initial release, work in progress
\\
 High-quality instructions and responses are essential for the zero-shot
performance of large language models on interactive natural language tasks. For
interactive vision-language tasks involving intricate visual scenes, a large
quantity of diverse and creative instruction-response pairs should be
imperative to tune vision-language models (VLMs). Nevertheless, the current
availability of vision-language instruction-response pairs in terms of
quantity, diversity, and creativity remains limited, posing challenges to the
generalization of interactive VLMs. Here we present MultI-Modal In-Context
Instruction Tuning (MIMIC-IT), a dataset comprising 2.8 million multimodal
instruction-response pairs, with 2.2 million unique instructions derived from
images and videos. Each pair is accompanied by multi-modal in-context
information, forming conversational contexts aimed at empowering VLMs in
perception, reasoning, and planning. The instruction-response collection
process, dubbed as Syphus, is scaled using an automatic annotation pipeline
that combines human expertise with GPT's capabilities. Using the MIMIC-IT
dataset, we train a large VLM named Otter. Based on extensive evaluations
conducted on vision-language benchmarks, it has been observed that Otter
demonstrates remarkable proficiency in multi-modal perception, reasoning, and
in-context learning. Human evaluation reveals it effectively aligns with the
user's intentions. We release the MIMIC-IT dataset, instruction-response
collection pipeline, benchmarks, and the Otter model.
\\ ( https://arxiv.org/abs/2306.05425 ,  13621kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05427
Date: Thu, 8 Jun 2023 17:59:59 GMT   (39038kb,D)

Title: Grounded Text-to-Image Synthesis with Attention Refocusing
Authors: Quynh Phung, Songwei Ge, Jia-Bin Huang
Categories: cs.CV
Comments: Project page: https://attention-refocusing.github.io/
\\
 Driven by scalable diffusion models trained on large-scale paired text-image
datasets, text-to-image synthesis methods have shown compelling results.
However, these models still fail to precisely follow the text prompt when
multiple objects, attributes, and spatial compositions are involved in the
prompt. In this paper, we identify the potential reasons in both the
cross-attention and self-attention layers of the diffusion model. We propose
two novel losses to refocus the attention maps according to a given layout
during the sampling process. We perform comprehensive experiments on the
DrawBench and HRS benchmarks using layouts synthesized by Large Language
Models, showing that our proposed losses can be integrated easily and
effectively into existing text-to-image methods and consistently improve their
alignment between the generated images and the text prompts.
\\ ( https://arxiv.org/abs/2306.05427 ,  39038kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05428
Date: Thu, 8 Jun 2023 17:59:59 GMT   (39091kb,D)

Title: Background Prompting for Improved Object Depth
Authors: Manel Baradad, Yuanzhen Li, Forrester Cole, Michael Rubinstein,
 Antonio Torralba, William T. Freeman, Varun Jampani
Categories: cs.CV
\\
 Estimating the depth of objects from a single image is a valuable task for
many vision, robotics, and graphics applications. However, current methods
often fail to produce accurate depth for objects in diverse scenes. In this
work, we propose a simple yet effective Background Prompting strategy that
adapts the input object image with a learned background. We learn the
background prompts only using small-scale synthetic object datasets. To infer
object depth on a real image, we place the segmented object into the learned
background prompt and run off-the-shelf depth networks. Background Prompting
helps the depth networks focus on the foreground object, as they are made
invariant to background variations. Moreover, Background Prompting minimizes
the domain gap between synthetic and real object images, leading to better
sim2real generalization than simple finetuning. Results on multiple synthetic
and real datasets demonstrate consistent improvements in real object depths for
a variety of existing depth networks. Code and optimized background prompts can
be found at: https://mbaradad.github.io/depth_prompt.
\\ ( https://arxiv.org/abs/2306.05428 ,  39091kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04890
Date: Thu, 8 Jun 2023 02:38:15 GMT   (211kb)

Title: T\^atonnement in Homothetic Fisher Markets
Authors: Denizalp Goktas and Jiayi Zhao and Amy Greenwald
Categories: cs.GT econ.TH
Comments: 33 pages, 2 figues, appeared at EC'23
\\
 A prevalent theme in the economics and computation literature is to identify
natural price-adjustment processes by which sellers and buyers in a market can
discover equilibrium prices. An example of such a process is t\^atonnement, an
auction-like algorithm first proposed in 1874 by French economist Walras in
which sellers adjust prices based on the Marshallian demands of buyers. A dual
concept in consumer theory is a buyer's Hicksian demand. In this paper, we
identify the maximum of the absolute value of the elasticity of the Hicksian
demand, as an economic parameter sufficient to capture and explain a range of
convergent and non-convergent t\^atonnement behaviors in a broad class of
markets. In particular, we prove the convergence of t\^atonnement at a rate of
$O((1+\varepsilon^2)/T)$, in homothetic Fisher markets with bounded price
elasticity of Hicksian demand, i.e., Fisher markets in which consumers have
preferences represented by homogeneous utility functions and the price
elasticity of their Hicksian demand is bounded, where $\varepsilon \geq 0$ is
the maximum absolute value of the price elasticity of Hicksian demand across
all buyers. Our result not only generalizes known convergence results for CES
Fisher markets, but extends them to mixed nested CES markets and Fisher markets
with continuous, possibly non-concave, homogeneous utility functions. Our
convergence rate covers the full spectrum of nested CES utilities, including
Leontief and linear utilities, unifying previously existing disparate
convergence and non-convergence results. In particular, for $\varepsilon = 0$,
i.e., Leontief markets, we recover the best-known convergence rate of $O(1/T)$,
and as $\varepsilon \to \infty$, e.g., linear Fisher markets, we obtain
non-convergent behavior, as expected.
\\ ( https://arxiv.org/abs/2306.04890 ,  211kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05028
Date: Thu, 8 Jun 2023 08:29:00 GMT   (248kb,D)

Title: Condorcet Markets
Authors: St\'ephane Airiau, Nicholas Kees Dupuis, Davide Grossi
Categories: cs.GT cs.MA
\\
 The paper studies information markets about single events from an epistemic
social choice perspective. Within the classical Condorcet error model for
collective binary decisions, we establish equivalence results between elections
and markets, showing that the alternative that would be selected by weighed
majority voting (under specific weighting schemes) corresponds to the
alternative with highest price in the equilibrium of the market (under specific
assumptions on the market type). This makes it possible to implement specific
weighted majority elections, which are known to have superior truth-tracking
performance, through information markets and, crucially, without needing to
elicit voters' competences.
\\ ( https://arxiv.org/abs/2306.05028 ,  248kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05216
Date: Thu, 8 Jun 2023 14:13:18 GMT   (88kb)

Title: Computing Optimal Equilibria and Mechanisms via Learning in Zero-Sum
 Extensive-Form Games
Authors: Brian Hu Zhang, Gabriele Farina, Ioannis Anagnostides, Federico
 Cacciamani, Stephen Marcus McAleer, Andreas Alexander Haupt, Andrea Celli,
 Nicola Gatti, Vincent Conitzer, Tuomas Sandholm
Categories: cs.GT
\\
 We introduce a new approach for computing optimal equilibria via learning in
games. It applies to extensive-form settings with any number of players,
including mechanism design, information design, and solution concepts such as
correlated, communication, and certification equilibria. We observe that
optimal equilibria are minimax equilibrium strategies of a player in an
extensive-form zero-sum game. This reformulation allows to apply techniques for
learning in zero-sum games, yielding the first learning dynamics that converge
to optimal equilibria, not only in empirical averages, but also in iterates. We
demonstrate the practical scalability and flexibility of our approach by
attaining state-of-the-art performance in benchmark tabular games, and by
computing an optimal mechanism for a sequential auction design problem using
deep reinforcement learning.
\\ ( https://arxiv.org/abs/2306.05216 ,  88kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05221
Date: Thu, 8 Jun 2023 14:18:46 GMT   (18099kb,D)

Title: Steering No-Regret Learners to Optimal Equilibria
Authors: Brian Hu Zhang, Gabriele Farina, Ioannis Anagnostides, Federico
 Cacciamani, Stephen Marcus McAleer, Andreas Alexander Haupt, Andrea Celli,
 Nicola Gatti, Vincent Conitzer, Tuomas Sandholm
Categories: cs.GT
\\
 We consider the problem of steering no-regret-learning agents to play
desirable equilibria in extensive-form games via nonnegative payments. We show
that steering is impossible if the total budget (across iterations) is finite.
However, with average, realized payments converging to zero, we show that
steering is possible. In the full-feedback setting, that is, when players' full
strategies are observed at each timestep, it is possible with constant
per-iteration payments. In the bandit-feedback setting, that is, when only
trajectories through the game tree are observable, steering is impossible with
constant per-iteration payments but possible if we allow the maximum
per-iteration payment to grow with time, while maintaining the property that
average, realized payments vanish. We supplement our theoretical positive
results with experiments highlighting the efficacy of steering in large,
extensive-form games, and show how our framework relates to optimal mechanism
design and information design.
\\ ( https://arxiv.org/abs/2306.05221 ,  18099kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05366
Date: Thu, 8 Jun 2023 17:08:52 GMT   (760kb,D)

Title: Ordinal Potential-based Player Rating
Authors: Nelson Vadori and Rahul Savani
Categories: cs.GT cs.LG
\\
 A two-player symmetric zero-sum game is transitive if for any pure strategies
$x$, $y$, $z$, if $x$ is better than $y$, and $y$ is better than $z$, then $x$
is better than $z$. It was recently observed that the Elo rating fails at
preserving transitive relations among strategies and therefore cannot correctly
extract the transitive component of a game. Our first contribution is to show
that the Elo rating actually does preserve transitivity when computed in the
right space. Precisely, using a suitable invertible mapping $\varphi$, we first
apply $\varphi$ to the game, then compute Elo ratings, then go back to the
original space by applying $\varphi^{-1}$. We provide a characterization of
transitive games as a weak variant of ordinal potential games with additively
separable potential functions. Leveraging this insight, we introduce the
concept of transitivity order, the minimum number of invertible mappings
required to transform the payoff of a transitive game into (differences of) its
potential function. The transitivity order is a tool to classify transitive
games, with Elo games being an example of transitive games of order one. Most
real-world games have both transitive and non-transitive (cyclic) components,
and we use our analysis of transitivity to extract the transitive (potential)
component of an arbitrary game. We link transitivity to the known concept of
sign-rank: transitive games have sign-rank two; arbitrary games may have higher
sign-rank. Using a neural network-based architecture, we learn a decomposition
of an arbitrary game into transitive and cyclic components that prioritises
capturing the sign pattern of the game. In particular, a transitive game always
has just one component in its decomposition, the potential component. We
provide a comprehensive evaluation of our methodology using both toy examples
and empirical data from real-world games.
\\ ( https://arxiv.org/abs/2306.05366 ,  760kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04645
Date: Wed, 31 May 2023 19:27:45 GMT   (1711kb,D)

Title: Special Session: Approximation and Fault Resiliency of DNN Accelerators
Authors: Mohammad Hasan Ahmadilivani, Mario Barbareschi, Salvatore Barone,
 Alberto Bosio, Masoud Daneshtalab, Salvatore Della Torca, Gabriele Gavarini,
 Maksim Jenihhin, Jaan Raik, Annachiara Ruospo, Ernesto Sanchez, and Mahdi
 Taheri
Categories: cs.LG cs.AR cs.DC
Comments: 10 pages, 6 tables, 9 figures
\\
 Deep Learning, and in particular, Deep Neural Network (DNN) is nowadays
widely used in many scenarios, including safety-critical applications such as
autonomous driving. In this context, besides energy efficiency and performance,
reliability plays a crucial role since a system failure can jeopardize human
life. As with any other device, the reliability of hardware architectures
running DNNs has to be evaluated, usually through costly fault injection
campaigns. This paper explores the approximation and fault resiliency of DNN
accelerators. We propose to use approximate (AxC) arithmetic circuits to
agilely emulate errors in hardware without performing fault injection on the
DNN. To allow fast evaluation of AxC DNN, we developed an efficient GPU-based
simulation framework. Further, we propose a fine-grain analysis of fault
resiliency by examining fault propagation and masking in networks
\\ ( https://arxiv.org/abs/2306.04645 ,  1711kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04646
Date: Thu, 1 Jun 2023 19:35:13 GMT   (201kb,D)

Title: Improve State-Level Wheat Yield Forecasts in Kazakhstan on GEOGLAM's EO
 Data by Leveraging A Simple Spatial-Aware Technique
Authors: Anh Nhat Nhu, Ritvik Sahajpal, Christina Justice, Inbal Becker-Reshef
Categories: cs.LG cs.CY
Comments: Accepted to (ICLR) 2023 Workshop on Machine Learning for Remote
 Sensing
Journal-ref: International Conference on Learning Representation (ICLR), First
 Workshop on Machine Learning for Remote Sensing, 2023
\\
 Accurate yield forecasting is essential for making informed policies and
long-term decisions for food security. Earth Observation (EO) data and machine
learning algorithms play a key role in providing a comprehensive and timely
view of crop conditions from field to national scales. However, machine
learning algorithms' prediction accuracy is often harmed by spatial
heterogeneity caused by exogenous factors not reflected in remote sensing data,
such as differences in crop management strategies. In this paper, we propose
and investigate a simple technique called state-wise additive bias to
explicitly address the cross-region yield heterogeneity in Kazakhstan. Compared
to baseline machine learning models (Random Forest, CatBoost, XGBoost), our
method reduces the overall RMSE by 8.9\% and the highest state-wise RMSE by
28.37\%. The effectiveness of state-wise additive bias indicates machine
learning's performance can be significantly improved by explicitly addressing
the spatial heterogeneity, motivating future work on spatial-aware machine
learning algorithms for yield forecasts as well as for general geospatial
forecasting problems.
\\ ( https://arxiv.org/abs/2306.04646 ,  201kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04648
Date: Mon, 5 Jun 2023 13:57:23 GMT   (360kb,D)

Title: On training locally adaptive CP
Authors: Nicolo Colombo
Categories: cs.LG cs.AI stat.ML
Comments: 15 pages, 1 table, 1 figure
\\
 We address the problem of making Conformal Prediction (CP) intervals locally
adaptive. Most existing methods focus on approximating the object-conditional
validity of the intervals by partitioning or re-weighting the calibration set.
Our strategy is new and conceptually different. Instead of re-weighting the
calibration data, we redefine the conformity measure through a trainable change
of variables, $A \to \phi_X(A)$, that depends explicitly on the object
attributes, $X$. Under certain conditions and if $\phi_X$ is monotonic in $A$
for any $X$, the transformations produce prediction intervals that are
guaranteed to be marginally valid and have $X$-dependent sizes. We describe how
to parameterize and train $\phi_X$ to maximize the interval efficiency.
Contrary to other CP-aware training methods, the objective function is smooth
and can be minimized through standard gradient methods without approximations.
\\ ( https://arxiv.org/abs/2306.04648 ,  360kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04653
Date: Tue, 6 Jun 2023 10:22:43 GMT   (403kb)

Title: From Data to Action: Exploring AI and IoT-driven Solutions for Smarter
 Cities
Authors: Tiago Dias, Tiago Fonseca, Jo\~ao Vitorino, Andreia Martins, Sofia
 Malpique and Isabel Pra\c{c}a
Categories: cs.LG cs.CV cs.SY eess.SY
Comments: 10 pages, 8 Figures, accepted for DCAI2023
\\
 The emergence of smart cities demands harnessing advanced technologies like
the Internet of Things (IoT) and Artificial Intelligence (AI) and promises to
unlock cities' potential to become more sustainable, efficient, and ultimately
livable for their inhabitants. This work introduces an intelligent city
management system that provides a data-driven approach to three use cases: (i)
analyze traffic information to reduce the risk of traffic collisions and
improve driver and pedestrian safety, (ii) identify when and where energy
consumption can be reduced to improve cost savings, and (iii) detect
maintenance issues like potholes in the city's roads and sidewalks, as well as
the beginning of hazards like floods and fires. A case study in Aveiro City
demonstrates the system's effectiveness in generating actionable insights that
enhance security, energy efficiency, and sustainability, while highlighting the
potential of AI and IoT-driven solutions for smart city development.
\\ ( https://arxiv.org/abs/2306.04653 ,  403kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04660
Date: Wed, 7 Jun 2023 01:16:45 GMT   (866kb)

Title: Adaptive Frequency Green Light Optimal Speed Advisory based on Hybrid
 Actor-Critic Reinforcement Learning
Authors: Ming Xu, Dongyu Zuo
Categories: cs.LG cs.AI
\\
 Green Light Optimal Speed Advisory (GLOSA) system suggests speeds to vehicles
to assist them in passing through intersections during green intervals, thus
reducing traffic congestion and fuel consumption by minimizing the number of
stops and idle times at intersections. However, previous research has focused
on optimizing the GLOSA algorithm, neglecting the frequency of speed advisory
by the GLOSA system. Specifically, some studies provide speed advisory profile
at each decision step, resulting in redundant advisory, while others calculate
the optimal speed for the vehicle only once, which cannot adapt to dynamic
traffic. In this paper, we propose an Adaptive Frequency GLOSA (AF-GLOSA) model
based on Hybrid Proximal Policy Optimization (H-PPO), which employs an
actor-critic architecture with a hybrid actor network. The hybrid actor network
consists of a discrete actor that outputs advisory frequency and a continuous
actor that outputs acceleration profiles. Additionally, we design a novel
reward function that considers both travel efficiency and fuel consumption. The
AF-GLOSA model is evaluated in comparison to traditional GLOSA and
learning-based GLOSA methods in a three-lane intersection with a traffic signal
in SUMO, under three different levels of traffic density. The results
demonstrate that the AF-GLOSA model performs best in reducing average stop
times, fuel consumption and CO2 emissions.
\\ ( https://arxiv.org/abs/2306.04660 ,  866kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04662
Date: Wed, 7 Jun 2023 02:32:45 GMT   (3136kb,D)

Title: Understanding Place Identity with Generative AI
Authors: Kee Moon Jang and Junda Chen and Yuhao Kang and Junghwan Kim and
 Jinhyung Lee and F\'abio Duarte
Categories: cs.LG cs.CY cs.HC cs.SI
Comments: 6 pages, 3 figures, GIScience 2023
\\
 Researchers are constantly leveraging new forms of data with the goal of
understanding how people perceive the built environment and build the
collective place identity of cities. Latest advancements in generative
artificial intelligence (AI) models have enabled the production of realistic
representations learned from vast amounts of data. In this study, we aim to
test the potential of generative AI as the source of textual and visual
information in capturing the place identity of cities assessed by filtered
descriptions and images. We asked questions on the place identity of a set of
31 global cities to two generative AI models, ChatGPT and DALL-E2. Since
generative AI has raised ethical concerns regarding its trustworthiness, we
performed cross-validation to examine whether the results show similar patterns
to real urban settings. In particular, we compared the outputs with Wikipedia
data for text and images searched from Google for image. Our results indicate
that generative AI models have the potential to capture the collective image of
cities that can make them distinguishable. This study is among the first
attempts to explore the capabilities of generative AI in understanding human
perceptions of the built environment. It contributes to urban design literature
by discussing future research opportunities and potential limitations.
\\ ( https://arxiv.org/abs/2306.04662 ,  3136kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04675
Date: Wed, 7 Jun 2023 18:00:00 GMT   (43847kb,D)

Title: Exposing flaws of generative model evaluation metrics and their unfair
 treatment of diffusion models
Authors: George Stein, Jesse C. Cresswell, Rasa Hosseinzadeh, Yi Sui, Brendan
 Leigh Ross, Valentin Villecroze, Zhaoyan Liu, Anthony L. Caterini, J. Eric T.
 Taylor, Gabriel Loaiza-Ganem
Categories: cs.LG cs.CV stat.ML
Comments: 50 pages, 29 figures, 12 tables, code at
 https://github.com/layer6ai-labs/dgm-eval
\\
 We systematically study a wide variety of image-based generative models
spanning semantically-diverse datasets to understand and improve the feature
extractors and metrics used to evaluate them. Using best practices in
psychophysics, we measure human perception of image realism for generated
samples by conducting the largest experiment evaluating generative models to
date, and find that no existing metric strongly correlates with human
evaluations. Comparing to 16 modern metrics for evaluating the overall
performance, fidelity, diversity, and memorization of generative models, we
find that the state-of-the-art perceptual realism of diffusion models as judged
by humans is not reflected in commonly reported metrics such as FID. This
discrepancy is not explained by diversity in generated samples, though one
cause is over-reliance on Inception-V3. We address these flaws through a study
of alternative self-supervised feature extractors, find that the semantic
information encoded by individual networks strongly depends on their training
procedure, and show that DINOv2-ViT-L/14 allows for much richer evaluation of
generative models. Next, we investigate data memorization, and find that
generative models do memorize training examples on simple, smaller datasets
like CIFAR10, but not necessarily on more complex datasets like ImageNet.
However, our experiments show that current metrics do not properly detect
memorization; none in the literature is able to separate memorization from
other phenomena such as underfitting or mode shrinkage. To facilitate further
development of generative models and their evaluation we release all generated
image datasets, human evaluation data, and a modular library to compute 16
common metrics for 8 different encoders at
https://github.com/layer6ai-labs/dgm-eval.
\\ ( https://arxiv.org/abs/2306.04675 ,  43847kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04718
Date: Wed, 7 Jun 2023 18:30:25 GMT   (495kb,D)

Title: Neural Symbolic Regression using Control Variables
Authors: Xieting Chu, Hongjue Zhao, Enze Xu, Hairong Qi, Minghan Chen, Huajie
 Shao
Categories: cs.LG
\\
 Symbolic regression (SR) is a powerful technique for discovering the
analytical mathematical expression from data, finding various applications in
natural sciences due to its good interpretability of results. However, existing
methods face scalability issues when dealing with complex equations involving
multiple variables. To address this challenge, we propose SRCV, a novel neural
symbolic regression method that leverages control variables to enhance both
accuracy and scalability. The core idea is to decompose multi-variable symbolic
regression into a set of single-variable SR problems, which are then combined
in a bottom-up manner. The proposed method involves a four-step process. First,
we learn a data generator from observed data using deep neural networks (DNNs).
Second, the data generator is used to generate samples for a certain variable
by controlling the input variables. Thirdly, single-variable symbolic
regression is applied to estimate the corresponding mathematical expression.
Lastly, we repeat steps 2 and 3 by gradually adding variables one by one until
completion. We evaluate the performance of our method on multiple benchmark
datasets. Experimental results demonstrate that the proposed SRCV significantly
outperforms state-of-the-art baselines in discovering mathematical expressions
with multiple variables. Moreover, it can substantially reduce the search space
for symbolic regression. The source code will be made publicly available upon
publication.
\\ ( https://arxiv.org/abs/2306.04718 ,  495kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04739
Date: Wed, 7 Jun 2023 19:28:32 GMT   (3722kb,D)

Title: Automatic retrieval of corresponding US views in longitudinal
 examinations
Authors: Hamideh Kerdegari, Tran Huy Nhat Phung1, Van Hao Nguyen, Thi Phuong
 Thao Truong, Ngoc Minh Thu Le, Thanh Phuong Le, Thi Mai Thao Le, Luigi
 Pisani, Linda Denehy, Vital Consortium, Reza Razavi, Louise Thwaites, Sophie
 Yacoub, Andrew P. King, and Alberto Gomez
Categories: cs.LG
Comments: 10 pages, 6 figures
\\
 Skeletal muscle atrophy is a common occurrence in critically ill patients in
the intensive care unit (ICU) who spend long periods in bed. Muscle mass must
be recovered through physiotherapy before patient discharge and ultrasound
imaging is frequently used to assess the recovery process by measuring the
muscle size over time. However, these manual measurements are subject to large
variability, particularly since the scans are typically acquired on different
days and potentially by different operators. In this paper, we propose a
self-supervised contrastive learning approach to automatically retrieve similar
ultrasound muscle views at different scan times. Three different models were
compared using data from 67 patients acquired in the ICU. Results indicate that
our contrastive model outperformed a supervised baseline model in the task of
view retrieval with an AUC of 73.52% and when combined with an automatic
segmentation model achieved 5.7%+/-0.24% error in cross-sectional area.
Furthermore, a user study survey confirmed the efficacy of our model for muscle
view retrieval.
\\ ( https://arxiv.org/abs/2306.04739 ,  3722kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04748
Date: Wed, 7 Jun 2023 19:54:56 GMT   (1117kb)

Title: Analysis, Identification and Prediction of Parkinson's disease sub-types
 and progression through Machine Learning
Authors: Ashwin Ram
Categories: cs.LG
Comments: 9 Pages. Machine Learning; Parkinson's Disease
\\
 Parkinson's disease (PD) is a prevalent neurodegenerative disorder with
varying patient trajectories, yet little is understood about the underlying
causes and symptom progression. The Parkinson's Progression Markers Initiative
(PPMI) has collected comprehensive longitudinal data from diverse patient
cohorts to identify biomarkers and aid in the development of interventions.
Despite over 110 machine learning studies using the PPMI database, the majority
have focused on supervised models for diagnosis prediction, which has limited
impact on understanding patient variability and progression. This paper
addresses this gap by combining supervised and unsupervised machine learning
methods to identify subtypes that accurately predict disease progression in
Parkinson's patients. Building upon previous work, we replicate and extend the
study by integrating unsupervised patient clustering and prediction of present
and future symptoms using 5 additional years of longitudinal data from the
Progressive Parkinson's Markers Initiative (PPMI) database. Our findings
demonstrate accurate prediction of disease trajectories and symptoms at
baseline, offering valuable insights into patient heterogeneity and the
potential for personalized interventions. The integration of supervised and
unsupervised models presents a promising avenue for uncovering latent subgroups
and understanding the complexity of Parkinson's disease progression.
\\ ( https://arxiv.org/abs/2306.04748 ,  1117kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04756
Date: Wed, 7 Jun 2023 20:08:27 GMT   (1541kb,D)

Title: A Linearly Convergent GAN Inversion-based Algorithm for Reverse
 Engineering of Deceptions
Authors: Darshan Thaker, Paris Giampouras, Ren\'e Vidal
Categories: cs.LG cs.CR
\\
 An important aspect of developing reliable deep learning systems is devising
strategies that make these systems robust to adversarial attacks. There is a
long line of work that focuses on developing defenses against these attacks,
but recently, researchers have began to study ways to reverse engineer the
attack process. This allows us to not only defend against several attack
models, but also classify the threat model. However, there is still a lack of
theoretical guarantees for the reverse engineering process. Current approaches
that give any guarantees are based on the assumption that the data lies in a
union of linear subspaces, which is not a valid assumption for more complex
datasets. In this paper, we build on prior work and propose a novel framework
for reverse engineering of deceptions which supposes that the clean data lies
in the range of a GAN. To classify the signal and attack, we jointly solve a
GAN inversion problem and a block-sparse recovery problem. For the first time
in the literature, we provide deterministic linear convergence guarantees for
this problem. We also empirically demonstrate the merits of the proposed
approach on several nonlinear datasets as compared to state-of-the-art methods.
\\ ( https://arxiv.org/abs/2306.04756 ,  1541kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04766
Date: Wed, 7 Jun 2023 20:27:17 GMT   (386kb,D)

Title: Enabling tabular deep learning when $d \gg n$ with an auxiliary
 knowledge graph
Authors: Camilo Ruiz, Hongyu Ren, Kexin Huang, Jure Leskovec
Categories: cs.LG cs.AI
\\
 Machine learning models exhibit strong performance on datasets with abundant
labeled samples. However, for tabular datasets with extremely high
$d$-dimensional features but limited $n$ samples (i.e. $d \gg n$), machine
learning models struggle to achieve strong performance due to the risk of
overfitting. Here, our key insight is that there is often abundant, auxiliary
domain information describing input features which can be structured as a
heterogeneous knowledge graph (KG). We propose PLATO, a method that achieves
strong performance on tabular data with $d \gg n$ by using an auxiliary KG
describing input features to regularize a multilayer perceptron (MLP). In
PLATO, each input feature corresponds to a node in the auxiliary KG. In the
MLP's first layer, each input feature also corresponds to a weight vector.
PLATO is based on the inductive bias that two input features corresponding to
similar nodes in the auxiliary KG should have similar weight vectors in the
MLP's first layer. PLATO captures this inductive bias by inferring the weight
vector for each input feature from its corresponding node in the KG via a
trainable message-passing function. Across 6 $d \gg n$ datasets, PLATO
outperforms 13 state-of-the-art baselines by up to 10.19%.
\\ ( https://arxiv.org/abs/2306.04766 ,  386kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04775
Date: Wed, 7 Jun 2023 20:48:35 GMT   (354kb)

Title: Exploiting Observation Bias to Improve Matrix Completion
Authors: Sean Mann, Charlotte Park, Devavrat Shah
Categories: cs.LG stat.ML
\\
 We consider a variant of matrix completion where entries are revealed in a
biased manner, adopting a model akin to that introduced by Ma and Chen. Instead
of treating this observation bias as a disadvantage, as is typically the case,
our goal is to exploit the shared information between the bias and the outcome
of interest to improve predictions. Towards this, we propose a simple two-stage
algorithm: (i) interpreting the observation pattern as a fully observed noisy
matrix, we apply traditional matrix completion methods to the observation
pattern to estimate the distances between the latent factors; (ii) we apply
supervised learning on the recovered features to impute missing observations.
We establish finite-sample error rates that are competitive with the
corresponding supervised learning parametric rates, suggesting that our
learning performance is comparable to having access to the unobserved
covariates. Empirical evaluation using a real-world dataset reflects similar
performance gains, with our algorithm's estimates having 30x smaller mean
squared error compared to traditional matrix completion methods.
\\ ( https://arxiv.org/abs/2306.04775 ,  354kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04777
Date: Wed, 7 Jun 2023 20:52:01 GMT   (89kb,D)

Title: Invariant Causal Set Covering Machines
Authors: Thibaud Godon, Baptiste Bauvin, Pascal Germain, Jacques Corbeil,
 Alexandre Drouin
Categories: cs.LG stat.ME stat.ML
\\
 Rule-based models, such as decision trees, appeal to practitioners due to
their interpretable nature. However, the learning algorithms that produce such
models are often vulnerable to spurious associations and thus, they are not
guaranteed to extract causally-relevant insights. In this work, we build on
ideas from the invariant causal prediction literature to propose Invariant
Causal Set Covering Machines, an extension of the classical Set Covering
Machine algorithm for conjunctions/disjunctions of binary-valued rules that
provably avoids spurious associations. We demonstrate both theoretically and
empirically that our method can identify the causal parents of a variable of
interest in polynomial time.
\\ ( https://arxiv.org/abs/2306.04777 ,  89kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04778
Date: Wed, 7 Jun 2023 20:53:50 GMT   (33kb)

Title: Loss Functions for Behavioral Game Theory
Authors: Greg d'Eon, Sophie Greenwood, Kevin Leyton-Brown, and James Wright
Categories: cs.LG cs.GT
Comments: 17 pages (10 pages body + references and appendix). Under review at
 NeurIPS 2023
\\
 Behavioral game theorists all use experimental data to evaluate predictive
models of human behavior. However, they differ greatly in their choice of loss
function for these evaluations, with error rate, negative log-likelihood,
cross-entropy, Brier score, and L2 error all being common choices. We attempt
to offer a principled answer to the question of which loss functions make sense
for this task, formalizing desiderata that we argue loss functions should
satisfy. We construct a family of loss functions, which we dub "diagonal
bounded Bregman divergences", that satisfy all of these axioms and includes the
squared L2 error. In fact, the squared L2 error is the only acceptable loss
that is relatively commonly used in practice; we thus recommend its continued
use to behavioral game theorists.
\\ ( https://arxiv.org/abs/2306.04778 ,  33kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04785
Date: Wed, 7 Jun 2023 21:08:09 GMT   (1202kb,D)

Title: Interpretable Deep Clustering
Authors: Jonathan Svirsky, Ofir Lindenbaum
Categories: cs.LG stat.ML
\\
 Clustering is a fundamental learning task widely used as a first step in data
analysis. For example, biologists often use cluster assignments to analyze
genome sequences, medical records, or images. Since downstream analysis is
typically performed at the cluster level, practitioners seek reliable and
interpretable clustering models. We propose a new deep-learning framework that
predicts interpretable cluster assignments at the instance and cluster levels.
First, we present a self-supervised procedure to identify a subset of
informative features from each data point. Then, we design a model that
predicts cluster assignments and a gate matrix that leads to cluster-level
feature selection. We show that the proposed method can reliably predict
cluster assignments using synthetic and real data. Furthermore, we verify that
our model leads to interpretable results at a sample and cluster level.
\\ ( https://arxiv.org/abs/2306.04785 ,  1202kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04791
Date: Wed, 7 Jun 2023 21:25:32 GMT   (24257kb,D)

Title: XInsight: Revealing Model Insights for GNNs with Flow-based Explanations
Authors: Eli Laird, Ayesh Madushanka, Elfi Kraka, Corey Clark
Categories: cs.LG cs.AI
Comments: eXplainable Artificial Intelligence. 1st World Conference on
 eXplainable Artificial Intelligence, xAI-2023, Lisbon, Portugal
\\
 Progress in graph neural networks has grown rapidly in recent years, with
many new developments in drug discovery, medical diagnosis, and recommender
systems. While this progress is significant, many networks are `black boxes'
with little understanding of the `what' exactly the network is learning. Many
high-stakes applications, such as drug discovery, require human-intelligible
explanations from the models so that users can recognize errors and discover
new knowledge. Therefore, the development of explainable AI algorithms is
essential for us to reap the benefits of AI.
 We propose an explainability algorithm for GNNs called eXplainable Insight
(XInsight) that generates a distribution of model explanations using GFlowNets.
Since GFlowNets generate objects with probabilities proportional to a reward,
XInsight can generate a diverse set of explanations, compared to previous
methods that only learn the maximum reward sample. We demonstrate XInsight by
generating explanations for GNNs trained on two graph classification tasks:
classifying mutagenic compounds with the MUTAG dataset and classifying acyclic
graphs with a synthetic dataset that we have open-sourced. We show the utility
of XInsight's explanations by analyzing the generated compounds using QSAR
modeling, and we find that XInsight generates compounds that cluster by
lipophilicity, a known correlate of mutagenicity. Our results show that
XInsight generates a distribution of explanations that uncovers the underlying
relationships demonstrated by the model. They also highlight the importance of
generating a diverse set of explanations, as it enables us to discover hidden
relationships in the model and provides valuable guidance for further analysis.
\\ ( https://arxiv.org/abs/2306.04791 ,  24257kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04793
Date: Wed, 7 Jun 2023 21:35:26 GMT   (8844kb,D)

Title: On the Joint Interaction of Models, Data, and Features
Authors: Yiding Jiang, Christina Baek, J. Zico Kolter
Categories: cs.LG stat.ML
\\
 Learning features from data is one of the defining characteristics of deep
learning, but our theoretical understanding of the role features play in deep
learning is still rudimentary. To address this gap, we introduce a new tool,
the interaction tensor, for empirically analyzing the interaction between data
and model through features. With the interaction tensor, we make several key
observations about how features are distributed in data and how models with
different random seeds learn different features. Based on these observations,
we propose a conceptual framework for feature learning. Under this framework,
the expected accuracy for a single hypothesis and agreement for a pair of
hypotheses can both be derived in closed-form. We demonstrate that the proposed
framework can explain empirically observed phenomena, including the recently
discovered Generalization Disagreement Equality (GDE) that allows for
estimating the generalization error with only unlabeled data. Further, our
theory also provides explicit construction of natural data distributions that
break the GDE. Thus, we believe this work provides valuable new insight into
our understanding of feature learning.
\\ ( https://arxiv.org/abs/2306.04793 ,  8844kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04795
Date: Wed, 7 Jun 2023 21:37:21 GMT   (1776kb,D)

Title: Feature Selection using Sparse Adaptive Bottleneck Centroid-Encoder
Authors: Tomojit Ghosh, Michael Kirby
Categories: cs.LG
Comments: A novel nonlinear feature selection technique with new state of the
 art result. 22 pages (including references), 13 figures. The article is in
 review
\\
 We introduce a novel nonlinear model, Sparse Adaptive Bottleneck
Centroid-Encoder (SABCE), for determining the features that discriminate
between two or more classes. The algorithm aims to extract discriminatory
features in groups while reconstructing the class centroids in the ambient
space and simultaneously use additional penalty terms in the bottleneck layer
to decrease within-class scatter and increase the separation of different class
centroids. The model has a sparsity-promoting layer (SPL) with a one-to-one
connection to the input layer. Along with the primary objective, we minimize
the $l_{2,1}$-norm of the sparse layer, which filters out unnecessary features
from input data. During training, we update class centroids by taking the
Hadamard product of the centroids and weights of the sparse layer, thus
ignoring the irrelevant features from the target. Therefore the proposed method
learns to reconstruct the critical components of class centroids rather than
the whole centroids. The algorithm is applied to various real-world data sets,
including high-dimensional biological, image, speech, and accelerometer sensor
data. We compared our method to different state-of-the-art feature selection
techniques, including supervised Concrete Autoencoders (SCAE), Feature
Selection Networks (FsNet), Stochastic Gates (STG), and LassoNet. We
empirically showed that SABCE features often produced better classification
accuracy than other methods on the sequester test sets, setting new
state-of-the-art results.
\\ ( https://arxiv.org/abs/2306.04795 ,  1776kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04803
Date: Wed, 7 Jun 2023 21:53:14 GMT   (163kb,D)

Title: Privately generating tabular data using language models
Authors: Alexandre Sablayrolles, Yue Wang, Brian Karrer
Categories: cs.LG cs.CL cs.CR
Comments: 9 pages, 3 figures
\\
 Privately generating synthetic data from a table is an important brick of a
privacy-first world. We propose and investigate a simple approach of treating
each row in a table as a sentence and training a language model with
differential privacy. We show this approach obtains competitive results in
modelling tabular data across multiple datasets, even at small scales that
favor alternative methods based on marginal distributions.
\\ ( https://arxiv.org/abs/2306.04803 ,  163kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04815
Date: Wed, 7 Jun 2023 22:37:11 GMT   (10686kb,D)

Title: Catapults in SGD: spikes in the training loss and their impact on
 generalization through feature learning
Authors: Libin Zhu, Chaoyue Liu, Adityanarayanan Radhakrishnan, Mikhail Belkin
Categories: cs.LG
\\
 In this paper, we first present an explanation regarding the common
occurrence of spikes in the training loss when neural networks are trained with
stochastic gradient descent (SGD). We provide evidence that the spikes in the
training loss of SGD are "catapults", an optimization phenomenon originally
observed in GD with large learning rates in [Lewkowycz et al. 2020]. We
empirically show that these catapults occur in a low-dimensional subspace
spanned by the top eigenvectors of the tangent kernel, for both GD and SGD.
Second, we posit an explanation for how catapults lead to better generalization
by demonstrating that catapults promote feature learning by increasing
alignment with the Average Gradient Outer Product (AGOP) of the true predictor.
Furthermore, we demonstrate that a smaller batch size in SGD induces a larger
number of catapults, thereby improving AGOP alignment and test performance.
\\ ( https://arxiv.org/abs/2306.04815 ,  10686kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04824
Date: Wed, 7 Jun 2023 23:07:55 GMT   (1614kb,D)

Title: Sparse Linear Centroid-Encoder: A Convex Method for Feature Selection
Authors: Tomojit Ghosh, Michael Kirby
Categories: cs.LG
Comments: A novel linear feature selection technique using convex optimization.
 Total 13 pages including references, 7 figures. The article is under review
\\
 We present a novel feature selection technique, Sparse Linear
Centroid-Encoder (SLCE). The algorithm uses a linear transformation to
reconstruct a point as its class centroid and, at the same time, uses the
$\ell_1$-norm penalty to filter out unnecessary features from the input data.
The original formulation of the optimization problem is nonconvex, but we
propose a two-step approach, where each step is convex. In the first step, we
solve the linear Centroid-Encoder, a convex optimization problem over a matrix
$A$. In the second step, we only search for a sparse solution over a diagonal
matrix $B$ while keeping $A$ fixed. Unlike other linear methods, e.g., Sparse
Support Vector Machines and Lasso, Sparse Linear Centroid-Encoder uses a single
model for multi-class data. We present an in-depth empirical analysis of the
proposed model and show that it promotes sparsity on various data sets,
including high-dimensional biological data. Our experimental results show that
SLCE has a performance advantage over some state-of-the-art neural
network-based feature selection techniques.
\\ ( https://arxiv.org/abs/2306.04824 ,  1614kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04828
Date: Wed, 7 Jun 2023 23:12:42 GMT   (694kb,D)

Title: Fast and Effective GNN Training with Linearized Random Spanning Trees
Authors: Francesco Bonchi, Claudio Gentile, Andr\'e Panisson, Fabio Vitale
Categories: cs.LG
\\
 We present a new effective and scalable framework for training GNNs in
supervised node classification tasks, given graph-structured data. Our approach
increasingly refines the weight update operations on a sequence of path graphs
obtained by linearizing random spanning trees extracted from the input network.
The path graphs are designed to retain essential topological and node
information of the original graph. At the same time, the sparsity of path
graphs enables a much lighter GNN training which, besides scalability, helps in
mitigating classical training issues, like over-squashing and over-smoothing.
We carry out an extensive experimental investigation on a number of real-world
graph benchmarks, where we apply our framework to graph convolutional networks,
showing simultaneous improvement of both training speed and test accuracy, as
compared to well-known baselines.
\\ ( https://arxiv.org/abs/2306.04828 ,  694kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04835
Date: Wed, 7 Jun 2023 23:40:18 GMT   (2181kb,D)

Title: Empowering Counterfactual Reasoning over Graph Neural Networks through
 Inductivity
Authors: Samidha Verma, Burouj Armgaan, Sourav Medya, Sayan Ranu
Categories: cs.LG cs.AI cs.SI
\\
 Graph neural networks (GNNs) have various practical applications, such as
drug discovery, recommendation engines, and chip design. However, GNNs lack
transparency as they cannot provide understandable explanations for their
predictions. To address this issue, counterfactual reasoning is used. The main
goal is to make minimal changes to the input graph of a GNN in order to alter
its prediction. While several algorithms have been proposed for counterfactual
explanations of GNNs, most of them have two main drawbacks. Firstly, they only
consider edge deletions as perturbations. Secondly, the counterfactual
explanation models are transductive, meaning they do not generalize to unseen
data. In this study, we introduce an inductive algorithm called INDUCE, which
overcomes these limitations. By conducting extensive experiments on several
datasets, we demonstrate that incorporating edge additions leads to better
counterfactual results compared to the existing methods. Moreover, the
inductive modeling approach allows INDUCE to directly predict counterfactual
perturbations without requiring instance-specific training. This results in
significant computational speed improvements compared to baseline methods and
enables scalable counterfactual analysis for GNNs.
\\ ( https://arxiv.org/abs/2306.04835 ,  2181kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04847
Date: Thu, 8 Jun 2023 00:50:16 GMT   (557kb)

Title: Embedding stochastic differential equations into neural networks via
 dual processes
Authors: Naoki Sughishita and Jun Ohkubo
Categories: cs.LG physics.data-an
Comments: 13 pages, 4 figures
\\
 We propose a new approach to constructing a neural network for predicting
expectations of stochastic differential equations. The proposed method does not
need data sets of inputs and outputs; instead, the information obtained from
the time-evolution equations, i.e., the corresponding dual process, is directly
compared with the weights in the neural network. As a demonstration, we
construct neural networks for the Ornstein-Uhlenbeck process and the noisy van
der Pol system. The remarkable feature of learned networks with the proposed
method is the accuracy of inputs near the origin. Hence, it would be possible
to avoid the overfitting problem because the learned network does not depend on
training data sets.
\\ ( https://arxiv.org/abs/2306.04847 ,  557kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04848
Date: Thu, 8 Jun 2023 00:56:33 GMT   (2352kb,D)

Title: Interpreting and Improving Diffusion Models Using the Euclidean Distance
 Function
Authors: Frank Permenter and Chenyang Yuan
Categories: cs.LG cs.CV math.OC stat.ML
Comments: 18 pages, 6 figures, 2 tables
\\
 Denoising is intuitively related to projection. Indeed, under the manifold
hypothesis, adding random noise is approximately equivalent to orthogonal
perturbation. Hence, learning to denoise is approximately learning to project.
In this paper, we use this observation to reinterpret denoising diffusion
models as approximate gradient descent applied to the Euclidean distance
function. We then provide straight-forward convergence analysis of the DDIM
sampler under simple assumptions on the projection-error of the denoiser.
Finally, we propose a new sampler based on two simple modifications to DDIM
using insights from our theoretical results. In as few as 5-10 function
evaluations, our sampler achieves state-of-the-art FID scores on pretrained
CIFAR-10 and CelebA models and can generate high quality samples on latent
diffusion models.
\\ ( https://arxiv.org/abs/2306.04848 ,  2352kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04862
Date: Thu, 8 Jun 2023 01:26:22 GMT   (4632kb,D)

Title: A Systematic Literature Review on Client Selection in Federated Learning
Authors: Carl Smestad (1) and Jingyue Li (2) ((1) Norwegian University of
 Science and Technology, (2) Norwegian University of Science and Technology)
Categories: cs.LG cs.AI
DOI: 10.1145/3593434.3593438
\\
 With the arising concerns of privacy within machine learning, federated
learning (FL) was invented in 2017, in which the clients, such as mobile
devices, train a model and send the update to the centralized server. Choosing
clients randomly for FL can harm learning performance due to different reasons.
Many studies have proposed approaches to address the challenges of client
selection of FL. However, no systematic literature review (SLR) on this topic
existed. This SLR investigates the state of the art of client selection in FL
and answers the challenges, solutions, and metrics to evaluate the solutions.
We systematically reviewed 47 primary studies. The main challenges found in
client selection are heterogeneity, resource allocation, communication costs,
and fairness. The client selection schemes aim to improve the original random
selection algorithm by focusing on one or several of the aforementioned
challenges. The most common metric used is testing accuracy versus
communication rounds, as testing accuracy measures the successfulness of the
learning and preferably in as few communication rounds as possible, as they are
very expensive. Although several possible improvements can be made with the
current state of client selection, the most beneficial ones are evaluating the
impact of unsuccessful clients and gaining a more theoretical understanding of
the impact of fairness in FL.
\\ ( https://arxiv.org/abs/2306.04862 ,  4632kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04873
Date: Thu, 8 Jun 2023 02:02:55 GMT   (10340kb,D)

Title: City-wide Origin-Destination Matrix Generation via Graph Denoising
 Diffusion
Authors: Can Rong, Jingtao Ding, Zhicheng Liu, Yong Li
Categories: cs.LG
Comments: 11 pagers, 5 figures
\\
 The Origin-Destination~(OD) matrix provides an estimation of number of
individuals traveling between regions, i.e., mobility flow in the city, which
is widely-used in urban planning, transportation, etc. Given various city
characteristics of urban regions, generating the city-wide OD matrix without
using historical flow information has become increasingly appealing to both
researchers and practitioners. However, existing works are limited in
independent generation of each element, i.e., flow, in OD matrix, overlooking
the element relations within the matrix that can be well formulated as a
network. In this paper, we instead propose to generate the city-wide OD matrix
from the network perspective, and design a graph denoising diffusion method to
learn the conditional joint probability distribution of all elements in the OD
matrix given city characteristics at region level. To overcome the learning
difficulty of the city-wide OD matrix covering over thousands of regions, we
decompose the original one-shot generative modeling of the diffusion model into
two cascaded stages, corresponding to the generation of network topology and
mobility flow, respectively. To further reproduce important network properties
contained in city-wide OD matrices, we design an elaborated graph denoising
network structure including a node property augmentation module and a graph
transformer backbone. Empirical experiments on data collected in two large US
cities have verified that our method can generate OD matrices for new cities
with network statistics remarkably similar with the ground truth, further
achieving superior outperformance over competitive baselines in terms of the
generation realism.
\\ ( https://arxiv.org/abs/2306.04873 ,  10340kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04875
Date: Thu, 8 Jun 2023 02:12:26 GMT   (18004kb,D)

Title: Instructed Diffuser with Temporal Condition Guidance for Offline
 Reinforcement Learning
Authors: Jifeng Hu, Yanchao Sun, Sili Huang, SiYuan Guo, Hechang Chen, Li Shen,
 Lichao Sun, Yi Chang, Dacheng Tao
Categories: cs.LG
\\
 Recent works have shown the potential of diffusion models in computer vision
and natural language processing. Apart from the classical supervised learning
fields, diffusion models have also shown strong competitiveness in
reinforcement learning (RL) by formulating decision-making as sequential
generation. However, incorporating temporal information of sequential data and
utilizing it to guide diffusion models to perform better generation is still an
open challenge. In this paper, we take one step forward to investigate
controllable generation with temporal conditions that are refined from temporal
information. We observe the importance of temporal conditions in sequential
generation in sufficient explorative scenarios and provide a comprehensive
discussion and comparison of different temporal conditions. Based on the
observations, we propose an effective temporally-conditional diffusion model
coined Temporally-Composable Diffuser (TCD), which extracts temporal
information from interaction sequences and explicitly guides generation with
temporal conditions. Specifically, we separate the sequences into three parts
according to time expansion and identify historical, immediate, and prospective
conditions accordingly. Each condition preserves non-overlapping temporal
information of sequences, enabling more controllable generation when we jointly
use them to guide the diffuser. Finally, we conduct extensive experiments and
analysis to reveal the favorable applicability of TCD in offline RL tasks,
where our method reaches or matches the best performance compared with prior
SOTA baselines.
\\ ( https://arxiv.org/abs/2306.04875 ,  18004kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04879
Date: Thu, 8 Jun 2023 02:18:58 GMT   (1257kb,D)

Title: Augmenting Hessians with Inter-Layer Dependencies for Mixed-Precision
 Post-Training Quantization
Authors: Clemens JS Schaefer, Navid Lambert-Shirzad, Xiaofan Zhang, Chiachen
 Chou, Tom Jablin, Jian Li, Elfie Guo, Caitlin Stanton, Siddharth Joshi, Yu
 Emma Wang
Categories: cs.LG
\\
 Efficiently serving neural network models with low latency is becoming more
challenging due to increasing model complexity and parameter count. Model
quantization offers a solution which simultaneously reduces memory footprint
and compute requirements. However, aggressive quantization may lead to an
unacceptable loss in model accuracy owing to differences in sensitivity to
numerical imperfection across different layers in the model. To address this
challenge, we propose a mixed-precision post training quantization (PTQ)
approach that assigns different numerical precisions to tensors in a network
based on their specific needs, for a reduced memory footprint and improved
latency while preserving model accuracy. Previous works rely on layer-wise
Hessian information to determine numerical precision, but as we demonstrate,
Hessian estimation is typically insufficient in determining an effective
ordering of layer sensitivities. We address this by augmenting the estimated
Hessian with additional information to capture inter-layer dependencies. We
demonstrate that this consistently improves PTQ performance along the
accuracy-latency Pareto frontier across multiple models. Our method combines
second-order information and inter-layer dependencies to guide a bisection
search, finding quantization configurations within a user-configurable model
accuracy degradation range. We evaluate the effectiveness of our method on the
ResNet50, MobileNetV2, and BERT models. Our experiments demonstrate latency
reductions compared to a 16-bit baseline of $25.48\%$, $21.69\%$, and $33.28\%$
respectively, while maintaining model accuracy to within $99.99\%$ of the
baseline model.
\\ ( https://arxiv.org/abs/2306.04879 ,  1257kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04891
Date: Thu, 8 Jun 2023 02:38:23 GMT   (27239kb,D)

Title: In-Context Learning through the Bayesian Prism
Authors: Kabir Ahuja, Madhur Panwar, Navin Goyal
Categories: cs.LG cs.CL
\\
 In-context learning is one of the surprising and useful features of large
language models. How it works is an active area of research. Recently, stylized
meta-learning-like setups have been devised that train these models on a
sequence of input-output pairs $(x, f(x))$ from a function class using the
language modeling loss and observe generalization to unseen functions from the
same class. One of the main discoveries in this line of research has been that
for several problems such as linear regression, trained transformers learn
algorithms for learning functions in context. However, the inductive biases of
these models resulting in this behavior are not clearly understood. A model
with unlimited training data and compute is a Bayesian predictor: it learns the
pretraining distribution. It has been shown that high-capacity transformers
mimic the Bayesian predictor for linear regression. In this paper, we show
empirical evidence of transformers exhibiting the behavior of this ideal
learner across different linear and non-linear function classes. We also extend
the previous setups to work in the multitask setting and verify that
transformers can do in-context learning in this setup as well and the Bayesian
perspective sheds light on this setting also. Finally, via the example of
learning Fourier series, we study the inductive bias for in-context learning.
We find that in-context learning may or may not have simplicity bias depending
on the pretraining data distribution.
\\ ( https://arxiv.org/abs/2306.04891 ,  27239kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04898
Date: Thu, 8 Jun 2023 03:00:10 GMT   (27833kb,D)

Title: Understanding Masked Autoencoders via Hierarchical Latent Variable
 Models
Authors: Lingjing Kong, Martin Q. Ma, Guangyi Chen, Eric P. Xing, Yuejie Chi,
 Louis-Philippe Morency, Kun Zhang
Categories: cs.LG cs.CV
Comments: CVPR 2023 Highlight
\\
 Masked autoencoder (MAE), a simple and effective self-supervised learning
framework based on the reconstruction of masked image regions, has recently
achieved prominent success in a variety of vision tasks. Despite the emergence
of intriguing empirical observations on MAE, a theoretically principled
understanding is still lacking. In this work, we formally characterize and
justify existing empirical insights and provide theoretical guarantees of MAE.
We formulate the underlying data-generating process as a hierarchical latent
variable model and show that under reasonable assumptions, MAE provably
identifies a set of latent variables in the hierarchical model, explaining why
MAE can extract high-level information from pixels. Further, we show how key
hyperparameters in MAE (the masking ratio and the patch size) determine which
true latent variables to be recovered, therefore influencing the level of
semantic information in the representation. Specifically, extremely large or
small masking ratios inevitably lead to low-level representations. Our theory
offers coherent explanations of existing empirical observations and provides
insights for potential empirical improvements and fundamental limitations of
the masking-reconstruction paradigm. We conduct extensive experiments to
validate our theoretical insights.
\\ ( https://arxiv.org/abs/2306.04898 ,  27833kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04901
Date: Thu, 8 Jun 2023 03:08:40 GMT   (341kb)

Title: Generalization Performance of Transfer Learning: Overparameterized and
 Underparameterized Regimes
Authors: Peizhong Ju, Sen Lin, Mark S. Squillante, Yingbin Liang, Ness B.
 Shroff
Categories: cs.LG
\\
 Transfer learning is a useful technique for achieving improved performance
and reducing training costs by leveraging the knowledge gained from source
tasks and applying it to target tasks. Assessing the effectiveness of transfer
learning relies on understanding the similarity between the ground truth of the
source and target tasks. In real-world applications, tasks often exhibit
partial similarity, where certain aspects are similar while others are
different or irrelevant. To investigate the impact of partial similarity on
transfer learning performance, we focus on a linear regression model with two
distinct sets of features: a common part shared across tasks and a
task-specific part. Our study explores various types of transfer learning,
encompassing two options for parameter transfer. By establishing a theoretical
characterization on the error of the learned model, we compare these transfer
learning options, particularly examining how generalization performance changes
with the number of features/parameters in both underparameterized and
overparameterized regimes. Furthermore, we provide practical guidelines for
determining the number of features in the common and task-specific parts for
improved generalization performance. For example, when the total number of
features in the source task's learning model is fixed, we show that it is more
advantageous to allocate a greater number of redundant features to the
task-specific part rather than the common part. Moreover, in specific
scenarios, particularly those characterized by high noise levels and small true
parameters, sacrificing certain true features in the common part in favor of
employing more redundant features in the task-specific part can yield notable
benefits.
\\ ( https://arxiv.org/abs/2306.04901 ,  341kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04904
Date: Thu, 8 Jun 2023 03:16:21 GMT   (5793kb,D)

Title: An adaptive augmented Lagrangian method for training physics and
 equality constrained artificial neural networks
Authors: Shamsulhaq Basir, Inanc Senocak
Categories: cs.LG physics.comp-ph physics.flu-dyn
MSC-class: 35Qxx, 35Exx, 76Dxx, 68Wxx, 65Mxx, 65Kxx, 49Mxx, 49Kxx,
ACM-class: G.1.6; G.1.8; G.1.10; J.2; I.2; I.6
\\
 Physics and equality constrained artificial neural networks (PECANN) are
grounded in methods of constrained optimization to properly constrain the
solution of partial differential equations (PDEs) with their boundary and
initial conditions and any high-fidelity data that may be available. To this
end, adoption of the augmented Lagrangian method within the PECANN framework is
paramount for learning the solution of PDEs without manually balancing the
individual loss terms in the objective function used for determining the
parameters of the neural network. Generally speaking, ALM combines the merits
of the penalty and Lagrange multiplier methods while avoiding the ill
conditioning and convergence issues associated singly with these methods . In
the present work, we apply our PECANN framework to solve forward and inverse
problems that have an expanded and diverse set of constraints. We show that ALM
with its conventional formulation to update its penalty parameter and Lagrange
multipliers stalls for such challenging problems. To address this issue, we
propose an adaptive ALM in which each constraint is assigned a unique penalty
parameter that evolve adaptively according to a rule inspired by the adaptive
subgradient method. Additionally, we revise our PECANN formulation for improved
computational efficiency and savings which allows for mini-batch training. We
demonstrate the efficacy of our proposed approach by solving several forward
and PDE-constrained inverse problems with noisy data, including simulation of
incompressible fluid flows with a primitive-variables formulation of the
Navier-Stokes equations up to a Reynolds number of 1000.
\\ ( https://arxiv.org/abs/2306.04904 ,  5793kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04919
Date: Thu, 8 Jun 2023 03:43:32 GMT   (9747kb,D)

Title: Unsupervised Cross-Domain Soft Sensor Modelling via A Deep Bayesian
 Particle Flow Framework
Authors: Junn Yong Loo, Ze Yang Ding, Surya G. Nurzaman, Chee-Ming Ting, Vishnu
 Monn Baskaran and Chee Pin Tan
Categories: cs.LG
\\
 Data-driven soft sensors are essential for achieving accurate perception
through reliable state inference. However, developing representative soft
sensor models is challenged by issues such as missing labels, domain
adaptability, and temporal coherence in data. To address these challenges, we
propose a deep Particle Flow Bayes (DPFB) framework for cross-domain soft
sensor modeling in the absence of target state labels. In particular, a
sequential Bayes objective is first formulated to perform the maximum
likelihood estimation underlying the cross-domain soft sensing problem. At the
core of the framework, we incorporate a physics-inspired particle flow that
optimizes the sequential Bayes objective to perform an exact Bayes update of
the model extracted latent and hidden features. As a result, these
contributions enable the proposed framework to learn a cohesive approximate
posterior feature representation capable of characterizing complex cross-domain
system dynamics and performing effective time series unsupervised domain
adaptation (UDA). Finally, we validate the framework on a complex industrial
multiphase flow process system with complex dynamics and multiple operating
conditions. The results demonstrate that the DPFB framework achieves superior
unsupervised cross-domain soft sensing performance, outperforming
state-of-the-art deep UDA and normalizing flow approaches.
\\ ( https://arxiv.org/abs/2306.04919 ,  9747kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04922
Date: Thu, 8 Jun 2023 03:47:33 GMT   (4548kb,D)

Title: Efficient and Equivariant Graph Networks for Predicting Quantum
 Hamiltonian
Authors: Haiyang Yu, Zhao Xu, Xiaofeng Qian, Xiaoning Qian, Shuiwang Ji
Categories: cs.LG physics.comp-ph
\\
 We consider the prediction of the Hamiltonian matrix, which finds use in
quantum chemistry and condensed matter physics. Efficiency and equivariance are
two important, but conflicting factors. In this work, we propose a
SE(3)-equivariant network, named QHNet, that achieves efficiency and
equivariance. Our key advance lies at the innovative design of QHNet
architecture, which not only obeys the underlying symmetries, but also enables
the reduction of number of tensor products by 92\%. In addition, QHNet prevents
the exponential growth of channel dimension when more atom types are involved.
We perform experiments on MD17 datasets, including four molecular systems.
Experimental results show that our QHNet can achieve comparable performance to
the state of the art methods at a significantly faster speed. Besides, our
QHNet consumes 50\% less memory due to its streamlined architecture. Our code
is publicly available as part of the AIRS library
(\url{https://github.com/divelab/AIRS}).
\\ ( https://arxiv.org/abs/2306.04922 ,  4548kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04923
Date: Thu, 8 Jun 2023 03:55:33 GMT   (124kb,D)

Title: Unconstrained Online Learning with Unbounded Losses
Authors: Andrew Jacobsen, Ashok Cutkosky
Categories: cs.LG stat.ML
Comments: 41 pages; ICML 2023
\\
 Algorithms for online learning typically require one or more boundedness
assumptions: that the domain is bounded, that the losses are Lipschitz, or
both. In this paper, we develop a new setting for online learning with
unbounded domains and non-Lipschitz losses. For this setting we provide an
algorithm which guarantees $R_{T}(u)\le \tilde
O(G\|u\|\sqrt{T}+L\|u\|^{2}\sqrt{T})$ regret on any problem where the
subgradients satisfy $\|g_{t}\|\le G+L\|w_{t}\|$, and show that this bound is
unimprovable without further assumptions. We leverage this algorithm to develop
new saddle-point optimization algorithms that converge in duality gap in
unbounded domains, even in the absence of meaningful curvature. Finally, we
provide the first algorithm achieving non-trivial dynamic regret in an
unbounded domain for non-Lipschitz losses, as well as a matching lower bound.
The regret of our dynamic regret algorithm automatically improves to a novel
$L^{*}$ bound when the losses are smooth.
\\ ( https://arxiv.org/abs/2306.04923 ,  124kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04924
Date: Thu, 8 Jun 2023 04:00:00 GMT   (174kb,D)

Title: Exact Optimality of Communication-Privacy-Utility Tradeoffs in
 Distributed Mean Estimation
Authors: Berivan Isik, Wei-Ning Chen, Ayfer Ozgur, Tsachy Weissman, Albert No
Categories: cs.LG cs.CR cs.DC cs.IT math.IT stat.ML
\\
 We study the mean estimation problem under communication and local
differential privacy constraints. While previous work has proposed
\emph{order}-optimal algorithms for the same problem (i.e., asymptotically
optimal as we spend more bits), \emph{exact} optimality (in the non-asymptotic
setting) still has not been achieved. In this work, we take a step towards
characterizing the \emph{exact}-optimal approach in the presence of shared
randomness (a random variable shared between the server and the user) and
identify several necessary conditions for \emph{exact} optimality. We prove
that one of the necessary conditions is to utilize a rotationally symmetric
shared random codebook. Based on this, we propose a randomization mechanism
where the codebook is a randomly rotated simplex -- satisfying the necessary
properties of the \emph{exact}-optimal codebook. The proposed mechanism is
based on a $k$-closest encoding which we prove to be \emph{exact}-optimal for
the randomly rotated simplex codebook.
\\ ( https://arxiv.org/abs/2306.04924 ,  174kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04940
Date: Thu, 8 Jun 2023 05:13:34 GMT   (3670kb,D)

Title: Layer-level activation mechanism
Authors: Yoon Kihyuk and Lim Chiehyeon
Categories: cs.LG cs.CV cs.NE
Comments: 9 pages, 4 figures, 4 tables except appendix
\\
 In this work, we propose a novel activation mechanism aimed at establishing
layer-level activation (LayerAct) functions. These functions are designed to be
more noise-robust compared to traditional element-level activation functions by
reducing the layer-level fluctuation of the activation outputs due to shift in
inputs. Moreover, the LayerAct functions achieve a zero-like mean activation
output without restricting the activation output space. We present an analysis
and experiments demonstrating that LayerAct functions exhibit superior
noise-robustness compared to element-level activation functions, and
empirically show that these functions have a zero-like mean activation.
Experimental results on three benchmark image classification tasks show that
LayerAct functions excel in handling noisy image datasets, outperforming
element-level activation functions, while the performance on clean datasets is
also superior in most cases.
\\ ( https://arxiv.org/abs/2306.04940 ,  3670kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04948
Date: Thu, 8 Jun 2023 05:41:42 GMT   (7919kb,D)

Title: ShuttleSet: A Human-Annotated Stroke-Level Singles Dataset for Badminton
 Tactical Analysis
Authors: Wei-Yao Wang, Yung-Chang Huang, Tsi-Ui Ik, Wen-Chih Peng
Categories: cs.LG cs.AI
Comments: KDD 2023. Project page: https://github.com/wywyWang/CoachAI-Projects
\\
 With the recent progress in sports analytics, deep learning approaches have
demonstrated the effectiveness of mining insights into players' tactics for
improving performance quality and fan engagement. This is attributed to the
availability of public ground-truth datasets. While there are a few available
datasets for turn-based sports for action detection, these datasets severely
lack structured source data and stroke-level records since these require
high-cost labeling efforts from domain experts and are hard to detect using
automatic techniques. Consequently, the development of artificial intelligence
approaches is significantly hindered when existing models are applied to more
challenging structured turn-based sequences. In this paper, we present
ShuttleSet, the largest publicly-available badminton singles dataset with
annotated stroke-level records. It contains 104 sets, 3,685 rallies, and 36,492
strokes in 44 matches between 2018 and 2021 with 27 top-ranking men's singles
and women's singles players. ShuttleSet is manually annotated with a
computer-aided labeling tool to increase the labeling efficiency and
effectiveness of selecting the shot type with a choice of 18 distinct classes,
the corresponding hitting locations, and the locations of both players at each
stroke. In the experiments, we provide multiple benchmarks (i.e., stroke
influence, stroke forecasting, and movement forecasting) with baselines to
illustrate the practicability of using ShuttleSet for turn-based analytics,
which is expected to stimulate both academic and sports communities. Over the
past two years, a visualization platform has been deployed to illustrate the
variability of analysis cases from ShuttleSet for coaches to delve into
players' tactical preferences with human-interactive interfaces, which was also
used by national badminton teams during multiple international high-ranking
matches.
\\ ( https://arxiv.org/abs/2306.04948 ,  7919kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04949
Date: Thu, 8 Jun 2023 05:44:06 GMT   (4602kb,D)

Title: Robust Learning with Progressive Data Expansion Against Spurious
 Correlation
Authors: Yihe Deng, Yu Yang, Baharan Mirzasoleiman, Quanquan Gu
Categories: cs.LG
\\
 While deep learning models have shown remarkable performance in various
tasks, they are susceptible to learning non-generalizable spurious features
rather than the core features that are genuinely correlated to the true label.
In this paper, beyond existing analyses of linear models, we theoretically
examine the learning process of a two-layer nonlinear convolutional neural
network in the presence of spurious features. Our analysis suggests that
imbalanced data groups and easily learnable spurious features can lead to the
dominance of spurious features during the learning process. In light of this,
we propose a new training algorithm called PDE that efficiently enhances the
model's robustness for a better worst-group performance. PDE begins with a
group-balanced subset of training data and progressively expands it to
facilitate the learning of the core features. Experiments on synthetic and
real-world benchmark datasets confirm the superior performance of our method on
models such as ResNets and Transformers. On average, our method achieves a 2.8%
improvement in worst-group accuracy compared with the state-of-the-art method,
while enjoying up to 10x faster training efficiency.
\\ ( https://arxiv.org/abs/2306.04949 ,  4602kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04961
Date: Thu, 8 Jun 2023 06:35:47 GMT   (177kb,D)

Title: Recovering Simultaneously Structured Data via Non-Convex Iteratively
 Reweighted Least Squares
Authors: Christian K\"ummerle and Johannes Maly
Categories: cs.LG cs.IT math.IT math.OC
Comments: 35 pages, 6 figures
\\
 We propose a new algorithm for the problem of recovering data that adheres to
multiple, heterogeneous low-dimensional structures from linear observations.
Focusing on data matrices that are simultaneously row-sparse and low-rank, we
propose and analyze an iteratively reweighted least squares (IRLS) algorithm
that is able to leverage both structures. In particular, it optimizes a
combination of non-convex surrogates for row-sparsity and rank, a balancing of
which is built into the algorithm. We prove locally quadratic convergence of
the iterates to a simultaneously structured data matrix in a regime of minimal
sample complexity (up to constants and a logarithmic factor), which is known to
be impossible for a combination of convex surrogates. In experiments, we show
that the IRLS method exhibits favorable empirical convergence, identifying
simultaneously row-sparse and low-rank matrices from fewer measurements than
state-of-the-art methods.
\\ ( https://arxiv.org/abs/2306.04961 ,  177kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04974
Date: Thu, 8 Jun 2023 07:05:36 GMT   (3105kb,D)

Title: Conservative Prediction via Data-Driven Confidence Minimization
Authors: Caroline Choi and Fahim Tajwar and Yoonho Lee and Huaxiu Yao and
 Ananya Kumar and Chelsea Finn
Categories: cs.LG cs.AI
Comments: Preprint. Under review
\\
 Errors of machine learning models are costly, especially in safety-critical
domains such as healthcare, where such mistakes can prevent the deployment of
machine learning altogether. In these settings, conservative models -- models
which can defer to human judgment when they are likely to make an error -- may
offer a solution. However, detecting unusual or difficult examples is notably
challenging, as it is impossible to anticipate all potential inputs at test
time. To address this issue, prior work has proposed to minimize the model's
confidence on an auxiliary pseudo-OOD dataset. We theoretically analyze the
effect of confidence minimization and show that the choice of auxiliary dataset
is critical. Specifically, if the auxiliary dataset includes samples from the
OOD region of interest, confidence minimization provably separates ID and OOD
inputs by predictive confidence. Taking inspiration from this result, we
present data-driven confidence minimization (DCM), which minimizes confidence
on an uncertainty dataset containing examples that the model is likely to
misclassify at test time. Our experiments show that DCM consistently
outperforms state-of-the-art OOD detection methods on 8 ID-OOD dataset pairs,
reducing FPR (at TPR 95%) by 6.3% and 58.1% on CIFAR-10 and CIFAR-100, and
outperforms existing selective classification approaches on 4 datasets in
conditions of distribution shift.
\\ ( https://arxiv.org/abs/2306.04974 ,  3105kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04979
Date: Thu, 8 Jun 2023 07:10:35 GMT   (1316kb,D)

Title: CoCo: A Coupled Contrastive Framework for Unsupervised Domain Adaptive
 Graph Classification
Authors: Nan Yin, Li Shen, Mengzhu Wang, Long Lan, Zeyu Ma, Chong Chen,
 Xian-Sheng Hua, Xiao Luo
Categories: cs.LG cs.AI
\\
 Although graph neural networks (GNNs) have achieved impressive achievements
in graph classification, they often need abundant task-specific labels, which
could be extensively costly to acquire. A credible solution is to explore
additional labeled graphs to enhance unsupervised learning on the target
domain. However, how to apply GNNs to domain adaptation remains unsolved owing
to the insufficient exploration of graph topology and the significant domain
discrepancy. In this paper, we propose \underline{Co}upled
\underline{Co}ntrastive Graph Representation Learning (\method{}), which
extracts the topological information from coupled learning branches and reduces
the domain discrepancy with coupled contrastive learning. \method{} contains a
graph convolutional network branch and a hierarchical graph kernel network
branch, which explore graph topology in implicit and explicit manners. Besides,
we incorporate coupled branches into a holistic multi-view contrastive learning
framework, which not only incorporates graph representations learned from
complementary views for enhanced understanding, but also encourages the
similarity between cross-domain example pairs with the same semantics for
domain alignment. Extensive experiments on various popular datasets show that
\method{} outperforms these competing baselines by 5.7\% to 21.0\% generally.
\\ ( https://arxiv.org/abs/2306.04979 ,  1316kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04985
Date: Thu, 8 Jun 2023 07:16:03 GMT   (479kb,D)

Title: Beyond Probability Partitions: Calibrating Neural Networks with Semantic
 Aware Grouping
Authors: Jia-Qi Yang, De-Chuan Zhan, Le Gan
Categories: cs.LG
\\
 Research has shown that deep networks tend to be overly optimistic about
their predictions, leading to an underestimation of prediction errors. Due to
the limited nature of data, existing studies have proposed various methods
based on model prediction probabilities to bin the data and evaluate
calibration error. We propose a more generalized definition of calibration
error called Partitioned Calibration Error (PCE), revealing that the key
difference among these calibration error metrics lies in how the data space is
partitioned. We put forth an intuitive proposition that an accurate model
should be calibrated across any partition, suggesting that the input space
partitioning can extend beyond just the partitioning of prediction
probabilities, and include partitions directly related to the input. Through
semantic-related partitioning functions, we demonstrate that the relationship
between model accuracy and calibration lies in the granularity of the
partitioning function. This highlights the importance of partitioning criteria
for training a calibrated and accurate model. To validate the aforementioned
analysis, we propose a method that involves jointly learning a semantic aware
grouping function based on deep model features and logits to partition the data
space into subsets. Subsequently, a separate calibration function is learned
for each subset. Experimental results demonstrate that our approach achieves
significant performance improvements across multiple datasets and network
architectures, thus highlighting the importance of the partitioning function
for calibration.
\\ ( https://arxiv.org/abs/2306.04985 ,  479kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04994
Date: Thu, 8 Jun 2023 07:29:42 GMT   (914kb,D)

Title: Ambulance Demand Prediction via Convolutional Neural Networks
Authors: Maximiliane Rautenstrau{\ss} and Maximilian Schiffer
Categories: cs.LG
Comments: 29 pages, 8 figures
\\
 Minimizing response times is crucial for emergency medical services to reduce
patients' waiting times and to increase their survival rates. Many models exist
to optimize operational tasks such as ambulance allocation and dispatching.
Including accurate demand forecasts in such models can improve operational
decision-making. Against this background, we present a novel convolutional
neural network (CNN) architecture that transforms time series data into
heatmaps to predict ambulance demand. Applying such predictions requires
incorporating external features that influence ambulance demands. We contribute
to the existing literature by providing a flexible, generic CNN architecture,
allowing for the inclusion of external features with varying dimensions.
Additionally, we provide a feature selection and hyperparameter optimization
framework utilizing Bayesian optimization. We integrate historical ambulance
demand and external information such as weather, events, holidays, and time. To
show the superiority of the developed CNN architecture over existing
approaches, we conduct a case study for Seattle's 911 call data and include
external information. We show that the developed CNN architecture outperforms
existing state-of-the-art methods and industry practice by more than 9%.
\\ ( https://arxiv.org/abs/2306.04994 ,  914kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05021
Date: Thu, 8 Jun 2023 08:16:38 GMT   (800kb,D)

Title: Mixed-TD: Efficient Neural Network Accelerator with Layer-Specific
 Tensor Decomposition
Authors: Zhewen Yu, Christos-Savvas Bouganis
Categories: cs.LG cs.AR
\\
 Neural Network designs are quite diverse, from VGG-style to ResNet-style, and
from Convolutional Neural Networks to Transformers. Towards the design of
efficient accelerators, many works have adopted a dataflow-based, inter-layer
pipelined architecture, with a customised hardware towards each layer,
achieving ultra high throughput and low latency. The deployment of neural
networks to such dataflow architecture accelerators is usually hindered by the
available on-chip memory as it is desirable to preload the weights of neural
networks on-chip to maximise the system performance. To address this, networks
are usually compressed before the deployment through methods such as pruning,
quantization and tensor decomposition. In this paper, a framework for mapping
CNNs onto FPGAs based on a novel tensor decomposition method called Mixed-TD is
proposed. The proposed method applies layer-specific Singular Value
Decomposition (SVD) and Canonical Polyadic Decomposition (CPD) in a mixed
manner, achieving 1.73x to 10.29x throughput per DSP to state-of-the-art CNNs.
Our work is open-sourced: https://github.com/Yu-Zhewen/Mixed-TD
\\ ( https://arxiv.org/abs/2306.05021 ,  800kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05031
Date: Thu, 8 Jun 2023 08:34:26 GMT   (4745kb,D)

Title: Generalizable Lightweight Proxy for Robust NAS against Diverse
 Perturbations
Authors: Hyeonjeong Ha, Minseon Kim, Sung Ju Hwang
Categories: cs.LG
\\
 Recent neural architecture search (NAS) frameworks have been successful in
finding optimal architectures for given conditions (e.g., performance or
latency). However, they search for optimal architectures in terms of their
performance on clean images only, while robustness against various types of
perturbations or corruptions is crucial in practice. Although there exist
several robust NAS frameworks that tackle this issue by integrating adversarial
training into one-shot NAS, however, they are limited in that they only
consider robustness against adversarial attacks and require significant
computational resources to discover optimal architectures for a single task,
which makes them impractical in real-world scenarios. To address these
challenges, we propose a novel lightweight robust zero-cost proxy that
considers the consistency across features, parameters, and gradients of both
clean and perturbed images at the initialization state. Our approach
facilitates an efficient and rapid search for neural architectures capable of
learning generalizable features that exhibit robustness across diverse
perturbations. The experimental results demonstrate that our proxy can rapidly
and efficiently search for neural architectures that are consistently robust
against various perturbations on multiple benchmark datasets and diverse search
spaces, largely outperforming existing clean zero-shot NAS and robust NAS with
reduced search cost.
\\ ( https://arxiv.org/abs/2306.05031 ,  4745kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05035
Date: Thu, 8 Jun 2023 08:37:49 GMT   (1351kb,D)

Title: Does Long-Term Series Forecasting Need Complex Attention and Extra Long
 Inputs?
Authors: Daojun Liang, Haixia Zhang, Dongfeng Yuan, Xiaoyan Ma, Dongyang Li and
 Minggao Zhang
Categories: cs.LG
Comments: Under Review
\\
 As Transformer-based models have achieved impressive performance on various
time series tasks, Long-Term Series Forecasting (LTSF) tasks have also received
extensive attention in recent years. However, due to the inherent computational
complexity and long sequences demanding of Transformer-based methods, its
application on LTSF tasks still has two major issues that need to be further
investigated: 1) Whether the sparse attention mechanism designed by these
methods actually reduce the running time on real devices; 2) Whether these
models need extra long input sequences to guarantee their performance? The
answers given in this paper are negative. Therefore, to better copy with these
two issues, we design a lightweight Period-Attention mechanism (Periodformer),
which renovates the aggregation of long-term subseries via explicit periodicity
and short-term subseries via built-in proximity. Meanwhile, a gating mechanism
is embedded into Periodformer to regulate the influence of the attention module
on the prediction results. Furthermore, to take full advantage of GPUs for fast
hyperparameter optimization (e.g., finding the suitable input length), a
Multi-GPU Asynchronous parallel algorithm based on Bayesian Optimization (MABO)
is presented. MABO allocates a process to each GPU via a queue mechanism, and
then creates multiple trials at a time for asynchronous parallel search, which
greatly reduces the search time. Compared with the state-of-the-art methods,
the prediction error of Periodformer reduced by 13% and 26% for multivariate
and univariate forecasting, respectively. In addition, MABO reduces the average
search time by 46% while finding better hyperparameters. As a conclusion, this
paper indicates that LTSF may not need complex attention and extra long input
sequences. The source code will be open source on Github.
\\ ( https://arxiv.org/abs/2306.05035 ,  1351kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05041
Date: Thu, 8 Jun 2023 08:49:42 GMT   (7139kb,D)

Title: Energy-Efficient Downlink Semantic Generative Communication with
 Text-to-Image Generators
Authors: Hyein Lee, Jihong Park, Sooyoung Kim, Jinho Choi
Categories: cs.LG cs.AI cs.DC
Comments: 6 pages, 7 figures. arXiv admin note: text overlap with
 arXiv:2302.02498
\\
 In this paper, we introduce a novel semantic generative communication (SGC)
framework, where generative users leverage text-to-image (T2I) generators to
create images locally from downloaded text prompts, while non-generative users
directly download images from a base station (BS). Although generative users
help reduce downlink transmission energy at the BS, they consume additional
energy for image generation and for uploading their generator state information
(GSI). We formulate the problem of minimizing the total energy consumption of
the BS and the users, and devise a generative user selection algorithm.
Simulation results corroborate that our proposed algorithm reduces total energy
by up to 54% compared to a baseline with all non-generative users.
\\ ( https://arxiv.org/abs/2306.05041 ,  7139kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05043
Date: Thu, 8 Jun 2023 08:53:59 GMT   (2046kb,D)

Title: Non-autoregressive Conditional Diffusion Models for Time Series
 Prediction
Authors: Lifeng Shen, James Kwok
Categories: cs.LG
Comments: Accepted by ICML 2023 (Poster)
\\
 Recently, denoising diffusion models have led to significant breakthroughs in
the generation of images, audio and text. However, it is still an open question
on how to adapt their strong modeling ability to model time series. In this
paper, we propose TimeDiff, a non-autoregressive diffusion model that achieves
high-quality time series prediction with the introduction of two novel
conditioning mechanisms: future mixup and autoregressive initialization.
Similar to teacher forcing, future mixup allows parts of the ground-truth
future predictions for conditioning, while autoregressive initialization helps
better initialize the model with basic time series patterns such as short-term
trends. Extensive experiments are performed on nine real-world datasets.
Results show that TimeDiff consistently outperforms existing time series
diffusion models, and also achieves the best overall performance across a
variety of the existing strong baselines (including transformers and FiLM).
\\ ( https://arxiv.org/abs/2306.05043 ,  2046kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05046
Date: Thu, 8 Jun 2023 08:57:06 GMT   (1930kb,D)

Title: A Gradient-based Approach for Online Robust Deep Neural Network Training
 with Noisy Labels
Authors: Yifan Yang, Alec Koppel, Zheng Zhang
Categories: cs.LG
\\
 Learning with noisy labels is an important topic for scalable training in
many real-world scenarios. However, few previous research considers this
problem in the online setting, where the arrival of data is streaming. In this
paper, we propose a novel gradient-based approach to enable the detection of
noisy labels for the online learning of model parameters, named Online
Gradient-based Robust Selection (OGRS). In contrast to the previous sample
selection approach for the offline training that requires the estimation of a
clean ratio of the dataset before each epoch of training, OGRS can
automatically select clean samples by steps of gradient update from datasets
with varying clean ratios without changing the parameter setting. During the
training process, the OGRS method selects clean samples at each iteration and
feeds the selected sample to incrementally update the model parameters. We
provide a detailed theoretical analysis to demonstrate data selection process
is converging to the low-loss region of the sample space, by introducing and
proving the sub-linear local Lagrangian regret of the non-convex constrained
optimization problem. Experimental results show that it outperforms
state-of-the-art methods in different settings.
\\ ( https://arxiv.org/abs/2306.05046 ,  1930kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05052
Date: Thu, 8 Jun 2023 09:12:28 GMT   (3224kb,D)

Title: Interpretable Medical Diagnostics with Structured Data Extraction by
 Large Language Models
Authors: Aleksa Bisercic, Mladen Nikolic, Mihaela van der Schaar, Boris
 Delibasic, Pietro Lio, Andrija Petrovic
Categories: cs.LG cs.AI cs.CL
\\
 Tabular data is often hidden in text, particularly in medical diagnostic
reports. Traditional machine learning (ML) models designed to work with tabular
data, cannot effectively process information in such form. On the other hand,
large language models (LLMs) which excel at textual tasks, are probably not the
best tool for modeling tabular data. Therefore, we propose a novel, simple, and
effective methodology for extracting structured tabular data from textual
medical reports, called TEMED-LLM. Drawing upon the reasoning capabilities of
LLMs, TEMED-LLM goes beyond traditional extraction techniques, accurately
inferring tabular features, even when their names are not explicitly mentioned
in the text. This is achieved by combining domain-specific reasoning guidelines
with a proposed data validation and reasoning correction feedback loop. By
applying interpretable ML models such as decision trees and logistic regression
over the extracted and validated data, we obtain end-to-end interpretable
predictions. We demonstrate that our approach significantly outperforms
state-of-the-art text classification models in medical diagnostics. Given its
predictive performance, simplicity, and interpretability, TEMED-LLM underscores
the potential of leveraging LLMs to improve the performance and trustworthiness
of ML models in medical applications.
\\ ( https://arxiv.org/abs/2306.05052 ,  3224kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05058
Date: Thu, 8 Jun 2023 09:23:09 GMT   (1738kb,D)

Title: Neuro-Symbolic Approaches for Context-Aware Human Activity Recognition
Authors: Luca Arrotta, Gabriele Civitarese, Claudio Bettini
Categories: cs.LG cs.AI eess.SP
\\
 Deep Learning models are a standard solution for sensor-based Human Activity
Recognition (HAR), but their deployment is often limited by labeled data
scarcity and models' opacity. Neuro-Symbolic AI (NeSy) provides an interesting
research direction to mitigate these issues by infusing knowledge about context
information into HAR deep learning classifiers. However, existing NeSy methods
for context-aware HAR require computationally expensive symbolic reasoners
during classification, making them less suitable for deployment on
resource-constrained devices (e.g., mobile devices). Additionally, NeSy
approaches for context-aware HAR have never been evaluated on in-the-wild
datasets, and their generalization capabilities in real-world scenarios are
questionable. In this work, we propose a novel approach based on a semantic
loss function that infuses knowledge constraints in the HAR model during the
training phase, avoiding symbolic reasoning during classification. Our results
on scripted and in-the-wild datasets show the impact of different semantic loss
functions in outperforming a purely data-driven model. We also compare our
solution with existing NeSy methods and analyze each approach's strengths and
weaknesses. Our semantic loss remains the only NeSy solution that can be
deployed as a single DNN without the need for symbolic reasoning modules,
reaching recognition rates close (and better in some cases) to existing
approaches.
\\ ( https://arxiv.org/abs/2306.05058 ,  1738kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05060
Date: Thu, 8 Jun 2023 09:23:46 GMT   (9960kb,D)

Title: Precision-aware Latency and Energy Balancing on Multi-Accelerator
 Platforms for DNN Inference
Authors: Matteo Risso, Alessio Burrello, Giuseppe Maria Sarda, Luca Benini,
 Enrico Macii, Massimo Poncino, Marian Verhelst, Daniele Jahier Pagliari
Categories: cs.LG
Comments: Accepted at 2023 ACM/IEEE International Symposium on Low Power
 Electronics and Design (ISLPED)
\\
 The need to execute Deep Neural Networks (DNNs) at low latency and low power
at the edge has spurred the development of new heterogeneous Systems-on-Chips
(SoCs) encapsulating a diverse set of hardware accelerators. How to optimally
map a DNN onto such multi-accelerator systems is an open problem. We propose
ODiMO, a hardware-aware tool that performs a fine-grain mapping across
different accelerators on-chip, splitting individual layers and executing them
in parallel, to reduce inference energy consumption or latency, while taking
into account each accelerator's quantization precision to maintain accuracy.
Pareto-optimal networks in the accuracy vs. energy or latency space are pursued
for three popular dataset/DNN pairs, and deployed on the DIANA heterogeneous
ultra-low power edge AI SoC. We show that ODiMO reduces energy/latency by up to
33%/31% with limited accuracy drop (-0.53%/-0.32%) compared to manual heuristic
mappings.
\\ ( https://arxiv.org/abs/2306.05060 ,  9960kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05067
Date: Thu, 8 Jun 2023 09:31:28 GMT   (6297kb,D)

Title: Improving Visual Prompt Tuning for Self-supervised Vision Transformers
Authors: Seungryong Yoo, Eunji Kim, Dahuin Jung, Jungbeom Lee, Sungroh Yoon
Categories: cs.LG cs.AI cs.CV
Comments: International Conference on Machine Learning (ICML) 2023
\\
 Visual Prompt Tuning (VPT) is an effective tuning method for adapting
pretrained Vision Transformers (ViTs) to downstream tasks. It leverages extra
learnable tokens, known as prompts, which steer the frozen pretrained ViTs.
Although VPT has demonstrated its applicability with supervised vision
transformers, it often underperforms with self-supervised ones. Through
empirical observations, we deduce that the effectiveness of VPT hinges largely
on the ViT blocks with which the prompt tokens interact. Specifically, VPT
shows improved performance on image classification tasks for MAE and MoCo v3
when the prompt tokens are inserted into later blocks rather than the first
block. These observations suggest that there exists an optimal location of
blocks for the insertion of prompt tokens. Unfortunately, identifying the
optimal blocks for prompts within each self-supervised ViT for diverse future
scenarios is a costly process. To mitigate this problem, we propose a simple
yet effective method that learns a gate for each ViT block to adjust its
intervention into the prompt tokens. With our method, prompt tokens are
selectively influenced by blocks that require steering for task adaptation. Our
method outperforms VPT variants in FGVC and VTAB image classification and
ADE20K semantic segmentation. The code is available at
https://github.com/ryongithub/GatedPromptTuning.
\\ ( https://arxiv.org/abs/2306.05067 ,  6297kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05068
Date: Thu, 8 Jun 2023 09:34:20 GMT   (693kb,D)

Title: Shedding light on underrepresentation and Sampling Bias in machine
 learning
Authors: Sami Zhioua, R\=uta Binkyt\.e
Categories: cs.LG cs.AI cs.CY
\\
 Accurately measuring discrimination is crucial to faithfully assessing
fairness of trained machine learning (ML) models. Any bias in measuring
discrimination leads to either amplification or underestimation of the existing
disparity. Several sources of bias exist and it is assumed that bias resulting
from machine learning is born equally by different groups (e.g. females vs
males, whites vs blacks, etc.). If, however, bias is born differently by
different groups, it may exacerbate discrimination against specific
sub-populations. Sampling bias, is inconsistently used in the literature to
describe bias due to the sampling procedure. In this paper, we attempt to
disambiguate this term by introducing clearly defined variants of sampling
bias, namely, sample size bias (SSB) and underrepresentation bias (URB). We
show also how discrimination can be decomposed into variance, bias, and noise.
Finally, we challenge the commonly accepted mitigation approach that
discrimination can be addressed by collecting more samples of the
underrepresented group.
\\ ( https://arxiv.org/abs/2306.05068 ,  693kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05079
Date: Thu, 8 Jun 2023 10:02:04 GMT   (1378kb,D)

Title: Enhancing Robustness of AI Offensive Code Generators via Data
 Augmentation
Authors: Cristina Improta, Pietro Liguori, Roberto Natella, Bojan Cukic and
 Domenico Cotroneo
Categories: cs.LG cs.CL cs.CR
\\
 In this work, we present a method to add perturbations to the code
descriptions, i.e., new inputs in natural language (NL) from well-intentioned
developers, in the context of security-oriented code, and analyze how and to
what extent perturbations affect the performance of AI offensive code
generators. Our experiments show that the performance of the code generators is
highly affected by perturbations in the NL descriptions. To enhance the
robustness of the code generators, we use the method to perform data
augmentation, i.e., to increase the variability and diversity of the training
data, proving its effectiveness against both perturbed and non-perturbed code
descriptions.
\\ ( https://arxiv.org/abs/2306.05079 ,  1378kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05101
Date: Thu, 8 Jun 2023 10:59:35 GMT   (816kb,D)

Title: Sy-CON: Symmetric Contrastive Loss for Continual Self-Supervised
 Representation Learning
Authors: Sungmin Cha and Taesup Moon
Categories: cs.LG
Comments: Preprint
\\
 We introduce a novel and general loss function, called Symmetric Contrastive
(Sy-CON) loss, for effective continual self-supervised learning (CSSL). We
first argue that the conventional loss form of continual learning which
consists of single task-specific loss (for plasticity) and a regularizer (for
stability) may not be ideal for contrastive loss based CSSL that focus on
representation learning. Our reasoning is that, in contrastive learning based
methods, the task-specific loss would suffer from decreasing diversity of
negative samples and the regularizer may hinder learning new distinctive
representations. To that end, we propose Sy-CON that consists of two losses
(one for plasticity and the other for stability) with symmetric dependence on
current and past models' negative sample embeddings. We argue our model can
naturally find good trade-off between the plasticity and stability without any
explicit hyperparameter tuning. We validate the effectiveness of our approach
through extensive experiments, demonstrating that MoCo-based implementation of
Sy-CON loss achieves superior performance compared to other state-of-the-art
CSSL methods.
\\ ( https://arxiv.org/abs/2306.05101 ,  816kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05108
Date: Thu, 8 Jun 2023 11:15:34 GMT   (1175kb,D)

Title: Hybrid Graph: A Unified Graph Representation with Datasets and
 Benchmarks for Complex Graphs
Authors: Zehui Li, Xiangyu Zhao, Mingzhu Shen, Guy-Bart Stan, Pietro Li\`o,
 Yiren Zhao
Categories: cs.LG cs.SI
Comments: Preprint. Under review. 16 pages, 5 figures, 11 tables
\\
 Graphs are widely used to encapsulate a variety of data formats, but
real-world networks often involve complex node relations beyond only being
pairwise. While hypergraphs and hierarchical graphs have been developed and
employed to account for the complex node relations, they cannot fully represent
these complexities in practice. Additionally, though many Graph Neural Networks
(GNNs) have been proposed for representation learning on higher-order graphs,
they are usually only evaluated on simple graph datasets. Therefore, there is a
need for a unified modelling of higher-order graphs, and a collection of
comprehensive datasets with an accessible evaluation framework to fully
understand the performance of these algorithms on complex graphs. In this
paper, we introduce the concept of hybrid graphs, a unified definition for
higher-order graphs, and present the Hybrid Graph Benchmark (HGB). HGB contains
23 real-world hybrid graph datasets across various domains such as biology,
social media, and e-commerce. Furthermore, we provide an extensible evaluation
framework and a supporting codebase to facilitate the training and evaluation
of GNNs on HGB. Our empirical study of existing GNNs on HGB reveals various
research opportunities and gaps, including (1) evaluating the actual
performance improvement of hypergraph GNNs over simple graph GNNs; (2)
comparing the impact of different sampling strategies on hybrid graph learning
methods; and (3) exploring ways to integrate simple graph and hypergraph
information. We make our source code and full datasets publicly available at
https://zehui127.github.io/hybrid-graph-benchmark/.
\\ ( https://arxiv.org/abs/2306.05108 ,  1175kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05109
Date: Thu, 8 Jun 2023 11:16:20 GMT   (817kb,D)

Title: Yet Another ICU Benchmark: A Flexible Multi-Center Framework for
 Clinical ML
Authors: Robin van de Water, Hendrik Schmidt, Paul Elbers, Patrick Thoral, Bert
 Arnrich, Patrick Rockenschaub
Categories: cs.LG
Comments: Main benchmark: https://github.com/rvandewater/YAIB, Cohort
 generation: https://github.com/rvandewater/YAIB-cohorts, Models:
 https://github.com/rvandewater/YAIB-models
\\
 Medical applications of machine learning (ML) have experienced a surge in
popularity in recent years. The intensive care unit (ICU) is a natural habitat
for ML given the abundance of available data from electronic health records.
Models have been proposed to address numerous ICU prediction tasks like the
early detection of complications. While authors frequently report
state-of-the-art performance, it is challenging to verify claims of
superiority. Datasets and code are not always published, and cohort
definitions, preprocessing pipelines, and training setups are difficult to
reproduce. This work introduces Yet Another ICU Benchmark (YAIB), a modular
framework that allows researchers to define reproducible and comparable
clinical ML experiments; we offer an end-to-end solution from cohort definition
to model evaluation. The framework natively supports most open-access ICU
datasets (MIMIC III/IV, eICU, HiRID, AUMCdb) and is easily adaptable to future
ICU datasets. Combined with a transparent preprocessing pipeline and extensible
training code for multiple ML and deep learning models, YAIB enables unified
model development. Our benchmark comes with five predefined established
prediction tasks (mortality, acute kidney injury, sepsis, kidney function, and
length of stay) developed in collaboration with clinicians. Adding further
tasks is straightforward by design. Using YAIB, we demonstrate that the choice
of dataset, cohort definition, and preprocessing have a major impact on the
prediction performance - often more so than model class - indicating an urgent
need for YAIB as a holistic benchmarking tool. We provide our work to the
clinical ML community to accelerate method development and enable real-world
clinical implementations. Software Repository:
https://github.com/rvandewater/YAIB.
\\ ( https://arxiv.org/abs/2306.05109 ,  817kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05123
Date: Thu, 8 Jun 2023 11:47:02 GMT   (1978kb,D)

Title: A Meta-Generation framework for Industrial System Generation
Authors: Fouad Oubari, Raphael Meunier, Rodrigue D\'ecatoire, Mathilde Mougeot
Categories: cs.LG
\\
 Generative design is an increasingly important tool in the industrial world.
It allows the designers and engineers to easily explore vast ranges of design
options, providing a cheaper and faster alternative to the trial and failure
approaches. Thanks to the flexibility they offer, Deep Generative Models are
gaining popularity amongst Generative Design technologies. However, developing
and evaluating these models can be challenging. The field lacks accessible
benchmarks, in order to evaluate and compare objectively different Deep
Generative Models architectures. Moreover, vanilla Deep Generative Models
appear to be unable to accurately generate multi-components industrial systems
that are controlled by latent design constraints. To address these challenges,
we propose an industry-inspired use case that incorporates actual industrial
system characteristics. This use case can be quickly generated and used as a
benchmark. We propose a Meta-VAE capable of producing multi-component
industrial systems and showcase its application on the proposed use case.
\\ ( https://arxiv.org/abs/2306.05123 ,  1978kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05143
Date: Thu, 8 Jun 2023 12:10:13 GMT   (5053kb,D)

Title: Genomic Interpreter: A Hierarchical Genomic Deep Neural Network with 1D
 Shifted Window Transformer
Authors: Zehui Li, Akashaditya Das, William A V Beardall, Yiren Zhao, Guy-Bart
 Stan
Categories: cs.LG q-bio.GN
\\
 Given the increasing volume and quality of genomics data, extracting new
insights requires interpretable machine-learning models. This work presents
Genomic Interpreter: a novel architecture for genomic assay prediction. This
model outperforms the state-of-the-art models for genomic assay prediction
tasks. Our model can identify hierarchical dependencies in genomic sites. This
is achieved through the integration of 1D-Swin, a novel Transformer-based block
designed by us for modelling long-range hierarchical data. Evaluated on a
dataset containing 38,171 DNA segments of 17K base pairs, Genomic Interpreter
demonstrates superior performance in chromatin accessibility and gene
expression prediction and unmasks the underlying `syntax' of gene regulation.
\\ ( https://arxiv.org/abs/2306.05143 ,  5053kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05150
Date: Thu, 8 Jun 2023 12:18:18 GMT   (56kb)

Title: Bayesian Optimization of Expensive Nested Grey-Box Functions
Authors: Wenjie Xu, Yuning Jiang, Bratislav Svetozarevic, Colin N. Jones
Categories: cs.LG cs.AI math.OC
\\
 We consider the problem of optimizing a grey-box objective function, i.e.,
nested function composed of both black-box and white-box functions. A general
formulation for such grey-box problems is given, which covers the existing
grey-box optimization formulations as special cases. We then design an
optimism-driven algorithm to solve it. Under certain regularity assumptions,
our algorithm achieves similar regret bound as that for the standard black-box
Bayesian optimization algorithm, up to a constant multiplicative term depending
on the Lipschitz constants of the functions considered. We further extend our
method to the constrained case and discuss several special cases. For the
commonly used kernel functions, the regret bounds allow us to derive a
convergence rate to the optimal solution. Experimental results show that our
grey-box optimization method empirically improves the speed of finding the
global optimal solution significantly, as compared to the standard black-box
optimization algorithm.
\\ ( https://arxiv.org/abs/2306.05150 ,  56kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05167
Date: Thu, 8 Jun 2023 13:03:53 GMT   (2913kb,D)

Title: Decision S4: Efficient Sequence-Based RL via State Spaces Layers
Authors: Shmuel Bar-David, Itamar Zimerman, Eliya Nachmani, Lior Wolf
Categories: cs.LG
Comments: 21 pages,13 figures
MSC-class: 14J60
ACM-class: F.2.2; I.2.7
\\
 Recently, sequence learning methods have been applied to the problem of
off-policy Reinforcement Learning, including the seminal work on Decision
Transformers, which employs transformers for this task. Since transformers are
parameter-heavy, cannot benefit from history longer than a fixed window size,
and are not computed using recurrence, we set out to investigate the
suitability of the S4 family of models, which are based on state-space layers
and have been shown to outperform transformers, especially in modeling
long-range dependencies. In this work we present two main algorithms: (i) an
off-policy training procedure that works with trajectories, while still
maintaining the training efficiency of the S4 model. (ii) An on-policy training
procedure that is trained in a recurrent manner, benefits from long-range
dependencies, and is based on a novel stable actor-critic mechanism. Our
results indicate that our method outperforms multiple variants of decision
transformers, as well as the other baseline methods on most tasks, while
reducing the latency, number of parameters, and training time by several orders
of magnitude, making our approach more suitable for real-world RL.
\\ ( https://arxiv.org/abs/2306.05167 ,  2913kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05172
Date: Thu, 8 Jun 2023 13:11:20 GMT   (325kb,D)

Title: FLEdge: Benchmarking Federated Machine Learning Applications in Edge
 Computing Systems
Authors: Herbert Woisetschl\"ager, Alexander Isenko, Ruben Mayer, Hans-Arno
 Jacobsen
Categories: cs.LG cs.DC
Comments: Preprint. Under Review
ACM-class: I.2.11; C.2.4; C.4; D.2.8
\\
 Federated Machine Learning (FL) has received considerable attention in recent
years. FL benchmarks are predominantly explored in either simulated systems or
data center environments, neglecting the setups of real-world systems, which
are often closely linked to edge computing. We close this research gap by
introducing FLEdge, a benchmark targeting FL workloads in edge computing
systems. We systematically study hardware heterogeneity, energy efficiency
during training, and the effect of various differential privacy levels on
training in FL systems. To make this benchmark applicable to real-world
scenarios, we evaluate the impact of client dropouts on state-of-the-art FL
strategies with failure rates as high as 50%. FLEdge provides new insights,
such as that training state-of-the-art FL workloads on older GPU-accelerated
embedded devices is up to 3x more energy efficient than on modern server-grade
GPUs.
\\ ( https://arxiv.org/abs/2306.05172 ,  325kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05175
Date: Thu, 8 Jun 2023 13:14:35 GMT   (19309kb,D)

Title: Large-scale Dataset Pruning with Dynamic Uncertainty
Authors: Muyang He, Shuo Yang, Tiejun Huang, Bo Zhao
Categories: cs.LG cs.CV
\\
 The state of the art of many learning tasks, e.g., image classification, is
advanced by collecting larger datasets and then training larger models on them.
As the outcome, the increasing computational cost is becoming unaffordable. In
this paper, we investigate how to prune the large-scale datasets, and thus
produce an informative subset for training sophisticated deep models with
negligible performance drop. We propose a simple yet effective dataset pruning
method by exploring both the prediction uncertainty and training dynamics. To
our knowledge, this is the first work to study dataset pruning on large-scale
datasets, i.e., ImageNet-1K and ImageNet-21K, and advanced models, i.e., Swin
Transformer and ConvNeXt. Extensive experimental results indicate that our
method outperforms the state of the art and achieves 75% lossless compression
ratio on both ImageNet-1K and ImageNet-21K. The code and pruned datasets are
available at https://github.com/BAAI-DCAI/Dataset-Pruning.
\\ ( https://arxiv.org/abs/2306.05175 ,  19309kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05189
Date: Thu, 8 Jun 2023 13:39:08 GMT   (2119kb,D)

Title: EMO: Episodic Memory Optimization for Few-Shot Meta-Learning
Authors: Yingjun Du, Jiayi Shen, Xiantong Zhen, Cee G.M. Snoek
Categories: cs.LG
Comments: Accepted by CoLLAs 2023
\\
 Few-shot meta-learning presents a challenge for gradient descent optimization
due to the limited number of training samples per task. To address this issue,
we propose an episodic memory optimization for meta-learning, we call
\emph{EMO}, which is inspired by the human ability to recall past learning
experiences from the brain's memory. EMO retains the gradient history of past
experienced tasks in external memory, enabling few-shot learning in a
memory-augmented way. By learning to retain and recall the learning process of
past training tasks, EMO nudges parameter updates in the right direction, even
when the gradients provided by a limited number of examples are uninformative.
We prove theoretically that our algorithm converges for smooth, strongly convex
objectives. EMO is generic, flexible, and model-agnostic, making it a simple
plug-and-play optimizer that can be seamlessly embedded into existing
optimization-based few-shot meta-learning approaches. Empirical results show
that EMO scales well with most few-shot classification benchmarks and improves
the performance of optimization-based meta-learning methods, resulting in
accelerated convergence.
\\ ( https://arxiv.org/abs/2306.05189 ,  2119kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05211
Date: Thu, 8 Jun 2023 14:09:38 GMT   (2520kb,D)

Title: Boosting-based Construction of BDDs for Linear Threshold Functions and
 Its Application to Verification of Neural Networks
Authors: Yiping Tang, Kohei Hatano, Eiji Takimoto
Categories: cs.LG
\\
 Understanding the characteristics of neural networks is important but
difficult due to their complex structures and behaviors. Some previous work
proposes to transform neural networks into equivalent Boolean expressions and
apply verification techniques for characteristics of interest. This approach is
promising since rich results of verification techniques for circuits and other
Boolean expressions can be readily applied. The bottleneck is the time
complexity of the transformation. More precisely, (i) each neuron of the
network, i.e., a linear threshold function, is converted to a Binary Decision
Diagram (BDD), and (ii) they are further combined into some final form, such as
Boolean circuits. For a linear threshold function with $n$ variables, an
existing method takes $O(n2^{\frac{n}{2}})$ time to construct an ordered BDD of
size $O(2^{\frac{n}{2}})$ consistent with some variable ordering. However, it
is non-trivial to choose a variable ordering producing a small BDD among $n!$
candidates.
 We propose a method to convert a linear threshold function to a specific form
of a BDD based on the boosting approach in the machine learning literature. Our
method takes $O(2^n \text{poly}(1/\rho))$ time and outputs BDD of size
$O(\frac{n^2}{\rho^4}\ln{\frac{1}{\rho}})$, where $\rho$ is the margin of some
consistent linear threshold function. Our method does not need to search for
good variable orderings and produces a smaller expression when the margin of
the linear threshold function is large. More precisely, our method is based on
our new boosting algorithm, which is of independent interest. We also propose a
method to combine them into the final Boolean expression representing the
neural network.
\\ ( https://arxiv.org/abs/2306.05211 ,  2520kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05255
Date: Thu, 8 Jun 2023 14:52:56 GMT   (2327kb,D)

Title: Toward more accurate and generalizable brain deformation estimators for
 traumatic brain injury detection with unsupervised domain adaptation
Authors: Xianghao Zhan, Jiawei Sun, Yuzhe Liu, Nicholas J. Cecchi, Enora Le
 Flao, Olivier Gevaert, Michael M. Zeineh, David B. Camarillo
Categories: cs.LG eess.SP physics.bio-ph q-bio.QM stat.AP
\\
 Machine learning head models (MLHMs) are developed to estimate brain
deformation for early detection of traumatic brain injury (TBI). However, the
overfitting to simulated impacts and the lack of generalizability caused by
distributional shift of different head impact datasets hinders the broad
clinical applications of current MLHMs. We propose brain deformation estimators
that integrates unsupervised domain adaptation with a deep neural network to
predict whole-brain maximum principal strain (MPS) and MPS rate (MPSR). With
12,780 simulated head impacts, we performed unsupervised domain adaptation on
on-field head impacts from 302 college football (CF) impacts and 457 mixed
martial arts (MMA) impacts using domain regularized component analysis (DRCA)
and cycle-GAN-based methods. The new model improved the MPS/MPSR estimation
accuracy, with the DRCA method significantly outperforming other domain
adaptation methods in prediction accuracy (p<0.001): MPS RMSE: 0.027 (CF) and
0.037 (MMA); MPSR RMSE: 7.159 (CF) and 13.022 (MMA). On another two hold-out
test sets with 195 college football impacts and 260 boxing impacts, the DRCA
model significantly outperformed the baseline model without domain adaptation
in MPS and MPSR estimation accuracy (p<0.001). The DRCA domain adaptation
reduces the MPS/MPSR estimation error to be well below TBI thresholds, enabling
accurate brain deformation estimation to detect TBI in future clinical
applications.
\\ ( https://arxiv.org/abs/2306.05255 ,  2327kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05256
Date: Thu, 8 Jun 2023 14:53:02 GMT   (1658kb,D)

Title: Unscented Autoencoder
Authors: Faris Janjo\v{s}, Lars Rosenbaum, Maxim Dolgov, J. Marius Z\"ollner
Categories: cs.LG cs.AI cs.CV
\\
 The Variational Autoencoder (VAE) is a seminal approach in deep generative
modeling with latent variables. Interpreting its reconstruction process as a
nonlinear transformation of samples from the latent posterior distribution, we
apply the Unscented Transform (UT) -- a well-known distribution approximation
used in the Unscented Kalman Filter (UKF) from the field of filtering. A finite
set of statistics called sigma points, sampled deterministically, provides a
more informative and lower-variance posterior representation than the
ubiquitous noise-scaling of the reparameterization trick, while ensuring
higher-quality reconstruction. We further boost the performance by replacing
the Kullback-Leibler (KL) divergence with the Wasserstein distribution metric
that allows for a sharper posterior. Inspired by the two components, we derive
a novel, deterministic-sampling flavor of the VAE, the Unscented Autoencoder
(UAE), trained purely with regularization-like terms on the per-sample
posterior. We empirically show competitive performance in Fr\'echet Inception
Distance (FID) scores over closely-related models, in addition to a lower
training variance than the VAE.
\\ ( https://arxiv.org/abs/2306.05256 ,  1658kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05257
Date: Thu, 8 Jun 2023 14:54:50 GMT   (1782kb,D)

Title: Comprehensive evaluation of deep and graph learning on drug-drug
 interactions prediction
Authors: Xuan Lin, Lichang Dai, Yafang Zhou, Zu-Guo Yu, Wen Zhang, Jian-Yu Shi,
 Dong-Sheng Cao, Li Zeng, Haowen Chen, Bosheng Song, Philip S. Yu and
 Xiangxiang Zeng
Categories: cs.LG q-bio.QM
Comments: Accepted by Briefings in Bioinformatics
DOI: 10.1093/bib/bbad235
\\
 Recent advances and achievements of artificial intelligence (AI) as well as
deep and graph learning models have established their usefulness in biomedical
applications, especially in drug-drug interactions (DDIs). DDIs refer to a
change in the effect of one drug to the presence of another drug in the human
body, which plays an essential role in drug discovery and clinical research.
DDIs prediction through traditional clinical trials and experiments is an
expensive and time-consuming process. To correctly apply the advanced AI and
deep learning, the developer and user meet various challenges such as the
availability and encoding of data resources, and the design of computational
methods. This review summarizes chemical structure based, network based, NLP
based and hybrid methods, providing an updated and accessible guide to the
broad researchers and development community with different domain knowledge. We
introduce widely-used molecular representation and describe the theoretical
frameworks of graph neural network models for representing molecular
structures. We present the advantages and disadvantages of deep and graph
learning methods by performing comparative experiments. We discuss the
potential technical challenges and highlight future directions of deep and
graph learning models for accelerating DDIs prediction.
\\ ( https://arxiv.org/abs/2306.05257 ,  1782kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05268
Date: Thu, 8 Jun 2023 15:17:04 GMT   (2937kb,D)

Title: Factorized Contrastive Learning: Going Beyond Multi-view Redundancy
Authors: Paul Pu Liang, Zihao Deng, Martin Ma, James Zou, Louis-Philippe
 Morency, Ruslan Salakhutdinov
Categories: cs.LG cs.AI cs.CL cs.CV cs.MM
Comments: Code available at: https://github.com/pliang279/FactorCL
\\
 In a wide range of multimodal tasks, contrastive learning has become a
particularly appealing approach since it can successfully learn representations
from abundant unlabeled data with only pairing information (e.g., image-caption
or video-audio pairs). Underpinning these approaches is the assumption of
multi-view redundancy - that shared information between modalities is necessary
and sufficient for downstream tasks. However, in many real-world settings,
task-relevant information is also contained in modality-unique regions:
information that is only present in one modality but still relevant to the
task. How can we learn self-supervised multimodal representations to capture
both shared and unique information relevant to downstream tasks? This paper
proposes FactorCL, a new multimodal representation learning method to go beyond
multi-view redundancy. FactorCL is built from three new contributions: (1)
factorizing task-relevant information into shared and unique representations,
(2) capturing task-relevant information via maximizing MI lower bounds and
removing task-irrelevant information via minimizing MI upper bounds, and (3)
multimodal data augmentations to approximate task relevance without labels. On
large-scale real-world datasets, FactorCL captures both shared and unique
information and achieves state-of-the-art results on six benchmarks.
\\ ( https://arxiv.org/abs/2306.05268 ,  2937kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05275
Date: Thu, 8 Jun 2023 15:21:47 GMT   (96kb)

Title: Federated Linear Contextual Bandits with User-level Differential Privacy
Authors: Ruiquan Huang, Huanyu Zhang, Luca Melis, Milan Shen, Meisam Hajzinia,
 Jing Yang
Categories: cs.LG cs.CR stat.ML
Comments: Accepted by ICML 2023
\\
 This paper studies federated linear contextual bandits under the notion of
user-level differential privacy (DP). We first introduce a unified federated
bandits framework that can accommodate various definitions of DP in the
sequential decision-making setting. We then formally introduce user-level
central DP (CDP) and local DP (LDP) in the federated bandits framework, and
investigate the fundamental trade-offs between the learning regrets and the
corresponding DP guarantees in a federated linear contextual bandits model. For
CDP, we propose a federated algorithm termed as \robin and show that it is
near-optimal in terms of the number of clients $M$ and the privacy budget
$\varepsilon$ by deriving nearly-matching upper and lower regret bounds when
user-level DP is satisfied. For LDP, we obtain several lower bounds, indicating
that learning under user-level $(\varepsilon,\delta)$-LDP must suffer a regret
blow-up factor at least {$\min\{1/\varepsilon,M\}$ or
$\min\{1/\sqrt{\varepsilon},\sqrt{M}\}$} under different conditions.
\\ ( https://arxiv.org/abs/2306.05275 ,  96kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05300
Date: Thu, 8 Jun 2023 15:45:57 GMT   (1429kb,D)

Title: Correlated Noise in Epoch-Based Stochastic Gradient Descent:
 Implications for Weight Variances
Authors: Marcel K\"uhn, Bernd Rosenow
Categories: cs.LG cond-mat.dis-nn
Comments: 25 pages, 7 figures
\\
 Stochastic gradient descent (SGD) has become a cornerstone of neural network
optimization, yet the noise introduced by SGD is often assumed to be
uncorrelated over time, despite the ubiquity of epoch-based training. In this
work, we challenge this assumption and investigate the effects of epoch-based
noise correlations on the stationary distribution of discrete-time SGD with
momentum, limited to a quadratic loss. Our main contributions are twofold:
first, we calculate the exact autocorrelation of the noise for training in
epochs under the assumption that the noise is independent of small fluctuations
in the weight vector; second, we explore the influence of correlations
introduced by the epoch-based learning scheme on SGD dynamics. We find that for
directions with a curvature greater than a hyperparameter-dependent crossover
value, the results for uncorrelated noise are recovered. However, for
relatively flat directions, the weight variance is significantly reduced. We
provide an intuitive explanation for these results based on a crossover between
correlation times, contributing to a deeper understanding of the dynamics of
SGD in the presence of epoch-based noise correlations.
\\ ( https://arxiv.org/abs/2306.05300 ,  1429kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05304
Date: Thu, 8 Jun 2023 15:50:35 GMT   (8963kb,D)

Title: Bayesian Optimisation of Functions on Graphs
Authors: Xingchen Wan, Pierre Osselin, Henry Kenlay, Binxin Ru, Michael A.
 Osborne, Xiaowen Dong
Categories: cs.LG cs.AI stat.ML
Comments: 10 pages, 9 figures, 1 table (23 pages, 24 figures, 1 table including
 references and appendices)
\\
 The increasing availability of graph-structured data motivates the task of
optimising over functions defined on the node set of graphs. Traditional graph
search algorithms can be applied in this case, but they may be
sample-inefficient and do not make use of information about the function
values; on the other hand, Bayesian optimisation is a class of promising
black-box solvers with superior sample efficiency, but it has been scarcely
been applied to such novel setups. To fill this gap, we propose a novel
Bayesian optimisation framework that optimises over functions defined on
generic, large-scale and potentially unknown graphs. Through the learning of
suitable kernels on graphs, our framework has the advantage of adapting to the
behaviour of the target function. The local modelling approach further
guarantees the efficiency of our method. Extensive experiments on both
synthetic and real-world graphs demonstrate the effectiveness of the proposed
optimisation framework.
\\ ( https://arxiv.org/abs/2306.05304 ,  8963kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05310
Date: Thu, 8 Jun 2023 15:59:31 GMT   (1042kb,D)

Title: A framework for dynamically training and adapting deep reinforcement
 learning models to different, low-compute, and continuously changing
 radiology deployment environments
Authors: Guangyao Zheng, Shuhao Lai, Vladimir Braverman, Michael A. Jacobs,
 Vishwa S. Parekh
Categories: cs.LG
\\
 While Deep Reinforcement Learning has been widely researched in medical
imaging, the training and deployment of these models usually require powerful
GPUs. Since imaging environments evolve rapidly and can be generated by edge
devices, the algorithm is required to continually learn and adapt to changing
environments, and adjust to low-compute devices. To this end, we developed
three image coreset algorithms to compress and denoise medical images for
selective experience replayed-based lifelong reinforcement learning. We
implemented neighborhood averaging coreset, neighborhood sensitivity-based
sampling coreset, and maximum entropy coreset on full-body DIXON water and
DIXON fat MRI images. All three coresets produced 27x compression with
excellent performance in localizing five anatomical landmarks: left knee, right
trochanter, left kidney, spleen, and lung across both imaging environments.
Maximum entropy coreset obtained the best performance of $11.97\pm 12.02$
average distance error, compared to the conventional lifelong learning
framework's $19.24\pm 50.77$.
\\ ( https://arxiv.org/abs/2306.05310 ,  1042kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05325
Date: Thu, 8 Jun 2023 16:18:08 GMT   (753kb,D)

Title: Federated Learning under Covariate Shifts with Generalization Guarantees
Authors: Ali Ramezani-Kebrya, Fanghui Liu, Thomas Pethick, Grigorios Chrysos,
 Volkan Cevher
Categories: cs.LG
Comments: Published in Transactions on Machine Learning Research (TMLR)
\\
 This paper addresses intra-client and inter-client covariate shifts in
federated learning (FL) with a focus on the overall generalization performance.
To handle covariate shifts, we formulate a new global model training paradigm
and propose Federated Importance-Weighted Empirical Risk Minimization (FTW-ERM)
along with improving density ratio matching methods without requiring perfect
knowledge of the supremum over true ratios. We also propose the
communication-efficient variant FITW-ERM with the same level of privacy
guarantees as those of classical ERM in FL. We theoretically show that FTW-ERM
achieves smaller generalization error than classical ERM under certain
settings. Experimental results demonstrate the superiority of FTW-ERM over
existing FL baselines in challenging imbalanced federated settings in terms of
data distribution shifts across clients.
\\ ( https://arxiv.org/abs/2306.05325 ,  753kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05344
Date: Thu, 8 Jun 2023 16:46:11 GMT   (2452kb,D)

Title: A Crystal-Specific Pre-Training Framework for Crystal Material Property
 Prediction
Authors: Haomin Yu, Yanru Song, Jilin Hu, Chenjuan Guo, Bin Yang
Categories: cs.LG cond-mat.mtrl-sci
\\
 Crystal property prediction is a crucial aspect of developing novel
materials. However, there are two technical challenges to be addressed for
speeding up the investigation of crystals. First, labeling crystal properties
is intrinsically difficult due to the high cost and time involved in physical
simulations or lab experiments. Second, crystals adhere to a specific quantum
chemical principle known as periodic invariance, which is often not captured by
existing machine learning methods. To overcome these challenges, we propose the
crystal-specific pre-training framework for learning crystal representations
with self-supervision. The framework designs a mutex mask strategy for
enhancing representation learning so as to alleviate the limited labels
available for crystal property prediction. Moreover, we take into account the
specific periodic invariance in crystal structures by developing a periodic
invariance multi-graph module and periodic attribute learning within our
framework. This framework has been tested on eight different tasks. The
experimental results on these tasks show that the framework achieves promising
prediction performance and is able to outperform recent strong baselines.
\\ ( https://arxiv.org/abs/2306.05344 ,  2452kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05401
Date: Thu, 8 Jun 2023 17:52:34 GMT   (34761kb,D)

Title: RDumb: A simple approach that questions our progress in continual
 test-time adaptation
Authors: Ori Press, Steffen Schneider, Matthias K\"ummerer, Matthias Bethge
Categories: cs.LG cs.CV
\\
 Test-Time Adaptation (TTA) allows to update pretrained models to changing
data distributions at deployment time. While early work tested these algorithms
for individual fixed distribution shifts, recent work proposed and applied
methods for continual adaptation over long timescales. To examine the reported
progress in the field, we propose the Continuously Changing Corruptions (CCC)
benchmark to measure asymptotic performance of TTA techniques. We find that
eventually all but one state-of-the-art methods collapse and perform worse than
a non-adapting model, including models specifically proposed to be robust to
performance collapse. In addition, we introduce a simple baseline, "RDumb",
that periodically resets the model to its pretrained state. RDumb performs
better or on par with the previously proposed state-of-the-art in all
considered benchmarks. Our results show that previous TTA approaches are
neither effective at regularizing adaptation to avoid collapse nor able to
outperform a simplistic resetting strategy.
\\ ( https://arxiv.org/abs/2306.05401 ,  34761kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05412
Date: Thu, 8 Jun 2023 17:56:46 GMT   (7333kb,D)

Title: Offline Prioritized Experience Replay
Authors: Yang Yue, Bingyi Kang, Xiao Ma, Gao Huang, Shiji Song, Shuicheng Yan
Categories: cs.LG cs.AI
Comments: preprint
\\
 Offline reinforcement learning (RL) is challenged by the distributional shift
problem. To address this problem, existing works mainly focus on designing
sophisticated policy constraints between the learned policy and the behavior
policy. However, these constraints are applied equally to well-performing and
inferior actions through uniform sampling, which might negatively affect the
learned policy. To alleviate this issue, we propose Offline Prioritized
Experience Replay (OPER), featuring a class of priority functions designed to
prioritize highly-rewarding transitions, making them more frequently visited
during training. Through theoretical analysis, we show that this class of
priority functions induce an improved behavior policy, and when constrained to
this improved policy, a policy-constrained offline RL algorithm is likely to
yield a better solution. We develop two practical strategies to obtain priority
weights by estimating advantages based on a fitted value network (OPER-A) or
utilizing trajectory returns (OPER-R) for quick computation. OPER is a
plug-and-play component for offline RL algorithms. As case studies, we evaluate
OPER on five different algorithms, including BC, TD3+BC, Onestep RL, CQL, and
IQL. Extensive experiments demonstrate that both OPER-A and OPER-R
significantly improve the performance for all baseline methods. Codes and
priority weights are availiable at https://github.com/sail-sg/OPER.
\\ ( https://arxiv.org/abs/2306.05412 ,  7333kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05415
Date: Thu, 8 Jun 2023 17:58:05 GMT   (7106kb,D)

Title: Causal normalizing flows: from theory to practice
Authors: Adri\'an Javaloy, Pablo S\'anchez-Mart\'in and Isabel Valera
Categories: cs.LG cs.AI stat.ME stat.ML
Comments: 31 pages, 15 figures. Under submission
\\
 In this work, we deepen on the use of normalizing flows for causal reasoning.
Specifically, we first leverage recent results on non-linear ICA to show that
causal models are identifiable from observational data given a causal ordering,
and thus can be recovered using autoregressive normalizing flows (NFs). Second,
we analyze different design and learning choices for causal normalizing flows
to capture the underlying causal data-generating process. Third, we describe
how to implement the do-operator in causal NFs, and thus, how to answer
interventional and counterfactual questions. Finally, in our experiments, we
validate our design and training choices through a comprehensive ablation
study; compare causal NFs to other approaches for approximating causal models;
and empirically demonstrate that causal NFs can be used to address real-world
problems, where the presence of mixed discrete-continuous data and partial
knowledge on the causal graph is the norm. The code for this work can be found
at https://github.com/psanch21/causal-flows.
\\ ( https://arxiv.org/abs/2306.05415 ,  7106kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05420
Date: Thu, 8 Jun 2023 17:59:08 GMT   (6179kb,D)

Title: Scaling Spherical CNNs
Authors: Carlos Esteves, Jean-Jacques Slotine, Ameesh Makadia
Categories: cs.LG cs.CV
Comments: Accepted to ICML'23
\\
 Spherical CNNs generalize CNNs to functions on the sphere, by using spherical
convolutions as the main linear operation. The most accurate and efficient way
to compute spherical convolutions is in the spectral domain (via the
convolution theorem), which is still costlier than the usual planar
convolutions. For this reason, applications of spherical CNNs have so far been
limited to small problems that can be approached with low model capacity. In
this work, we show how spherical CNNs can be scaled for much larger problems.
To achieve this, we make critical improvements including novel variants of
common model components, an implementation of core operations to exploit
hardware accelerator characteristics, and application-specific input
representations that exploit the properties of our model. Experiments show our
larger spherical CNNs reach state-of-the-art on several targets of the QM9
molecular benchmark, which was previously dominated by equivariant graph neural
networks, and achieve competitive performance on multiple weather forecasting
tasks. Our code is available at
https://github.com/google-research/spherical-cnn.
\\ ( https://arxiv.org/abs/2306.05420 ,  6179kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05426
Date: Thu, 8 Jun 2023 17:59:58 GMT   (841kb,D)

Title: SequenceMatch: Imitation Learning for Autoregressive Sequence Modelling
 with Backtracking
Authors: Chris Cundy, Stefano Ermon
Categories: cs.LG cs.AI
\\
 In many domains, autoregressive models can achieve low log-likelihood on the
task of predicting the next observation. However, this maximum-likelihood (MLE)
objective does not necessarily match a downstream use-case of autoregressively
generating high-quality sequences. The MLE objective weights sequences
proportionally to their frequency under the data distribution, with no guidance
for the model's behaviour out of distribution (OOD): leading to compounding
error during autoregressive generation. In order to address this compounding
error problem, we formulate sequence generation as an imitation learning (IL)
problem. This allows us to minimize a variety of divergences between the
distribution of sequences generated by an autoregressive model and sequences
from a dataset, including divergences with weight on OOD generated sequences.
The IL framework also allows us to incorporate backtracking by introducing a
backspace action into the generation process. This further mitigates the
compounding error problem by allowing the model to revert a sampled token if it
takes the sequence OOD. Our resulting method, SequenceMatch, can be implemented
without adversarial training or major architectural changes. We identify the
SequenceMatch-$\chi^2$ divergence as a more suitable training objective for
autoregressive models which are used for generation. We show that empirically,
SequenceMatch training leads to improvements over MLE on text generation with
language models.
\\ ( https://arxiv.org/abs/2306.05426 ,  841kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04732
Date: Wed, 7 Jun 2023 19:01:50 GMT   (28169kb,D)

Title: Online Multi-Contact Receding Horizon Planning via Value Function
 Approximation
Authors: Jiayi Wang, Sanghyun Kim, Teguh Santoso Lembono, Wenqian Du, Jaehyun
 Shim, Saeid Samadi, Ke Wang, Vladimir Ivan, Sylvain Calinon, Sethu
 Vijayakumar, Steve Tonneau
Categories: cs.RO
Comments: Under review for IEEE Transactions on Robotics
\\
 Planning multi-contact motions in a receding horizon fashion requires a value
function to guide the planning with respect to the future, e.g., building
momentum to traverse large obstacles. Traditionally, the value function is
approximated by computing trajectories in a prediction horizon (never executed)
that foresees the future beyond the execution horizon. However, given the
non-convex dynamics of multi-contact motions, this approach is computationally
expensive. To enable online Receding Horizon Planning (RHP) of multi-contact
motions, we find efficient approximations of the value function. Specifically,
we propose a trajectory-based and a learning-based approach. In the former,
namely RHP with Multiple Levels of Model Fidelity, we approximate the value
function by computing the prediction horizon with a convex relaxed model. In
the latter, namely Locally-Guided RHP, we learn an oracle to predict local
objectives for locomotion tasks, and we use these local objectives to construct
local value functions for guiding a short-horizon RHP. We evaluate both
approaches in simulation by planning centroidal trajectories of a humanoid
robot walking on moderate slopes, and on large slopes where the robot cannot
maintain static balance. Our results show that locally-guided RHP achieves the
best computation efficiency (95\%-98.6\% cycles converge online). This
computation advantage enables us to demonstrate online receding horizon
planning of our real-world humanoid robot Talos walking in dynamic environments
that change on-the-fly.
\\ ( https://arxiv.org/abs/2306.04732 ,  28169kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04781
Date: Wed, 7 Jun 2023 21:02:20 GMT   (4233kb,D)

Title: Learning to Navigate in Turbulent Flows with Aerial Robot Swarms: A
 Cooperative Deep Reinforcement Learning Approach
Authors: Diego Pati\~no and Siddharth Mayya and Juan Calderon and Kostas
 Daniilidis and David Salda\~na
Categories: cs.RO cs.LG cs.MA
DOI: 10.1109/LRA.2023.3280806
\\
 Aerial operation in turbulent environments is a challenging problem due to
the chaotic behavior of the flow. This problem is made even more complex when a
team of aerial robots is trying to achieve coordinated motion in turbulent wind
conditions. In this paper, we present a novel multi-robot controller to
navigate in turbulent flows, decoupling the trajectory-tracking control from
the turbulence compensation via a nested control architecture. Unlike previous
works, our method does not learn to compensate for the air-flow at a specific
time and space. Instead, our method learns to compensate for the flow based on
its effect on the team. This is made possible via a deep reinforcement learning
approach, implemented via a Graph Convolutional Neural Network (GCNN)-based
architecture, which enables robots to achieve better wind compensation by
processing the spatial-temporal correlation of wind flows across the team. Our
approach scales well to large robot teams -- as each robot only uses
information from its nearest neighbors -- , and generalizes well to robot teams
larger than seen in training. Simulated experiments demonstrate how information
sharing improves turbulence compensation in a team of aerial robots and
demonstrate the flexibility of our method over different team configurations.
\\ ( https://arxiv.org/abs/2306.04781 ,  4233kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04784
Date: Wed, 7 Jun 2023 21:07:56 GMT   (6190kb,D)

Title: A Framework for Designing Anthropomorphic Soft Hands through Interaction
Authors: Pragna Mannam, Kenneth Shaw, Dominik Bauer, Jean Oh, Deepak Pathak and
 Nancy Pollard
Categories: cs.RO
\\
 Modeling and simulating soft robot hands can aid in design iteration for
complex and high degree-of-freedom (DoF) morphologies. This can be further
supplemented by iterating on the design based on its performance in real world
manipulation tasks. However, this requires a framework that allows us to
iterate quickly at low costs. In this paper, we present a framework that
leverages rapid prototyping of the hand using 3D-printing, and utilizes
teleoperation to evaluate the hand in real world manipulation tasks. Using this
framework, we design a 3D-printed 16-DoF dexterous anthropomorphic soft hand
(DASH) and iteratively improve its design over three iterations. Rapid
prototyping techniques such as 3D-printing allow us to directly evaluate the
fabricated hand without modeling it in simulation. We show that the design is
improved at each iteration through the hand's performance in 30 real-world
teleoperated manipulation tasks. Testing over 600 demonstrations shows that our
final version of DASH can solve 16 of the 30 tasks compared to Allegro, a
popular rigid hand in the market, which can only solve 7 tasks. We open-source
our CAD models as well as the teleoperated dataset for further study and are
available on our website (https://dash-through-interaction.github.io.)
\\ ( https://arxiv.org/abs/2306.04784 ,  6190kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04853
Date: Thu, 8 Jun 2023 01:03:07 GMT   (4404kb,D)

Title: ExtPerFC: An Efficient 2D and 3D Perception Hardware-Software Framework
 for Mobile Cobot
Authors: Tuan Dang, Khang Nguyen, Manfred Huber
Categories: cs.RO
\\
 As the reliability of the robot's perception correlates with the number of
integrated sensing modalities to tackle uncertainty, a practical solution to
manage these sensors from different computers, operate them simultaneously, and
maintain their real-time performance on the existing robotic system with
minimal effort is needed. In this work, we present an end-to-end
software-hardware framework, namely ExtPerFC, that supports both conventional
hardware and software components and integrates machine learning object
detectors without requiring an additional dedicated graphic processor unit
(GPU). We first design our framework to achieve real-time performance on the
existing robotic system, guarantee configuration optimization, and concentrate
on code reusability. We then mathematically model and utilize our transfer
learning strategies for 2D object detection and fuse them into depth images for
3D depth estimation. Lastly, we systematically test the proposed framework on
the Baxter robot with two 7-DOF arms, a four-wheel mobility base, and an Intel
RealSense D435i RGB-D camera. The results show that the robot achieves
real-time performance while executing other tasks (e.g., map building,
localization, navigation, object detection, arm moving, and grasping)
simultaneously with available hardware like Intel onboard CPUS/GPUs on
distributed computers. Also, to comprehensively control, program, and monitor
the robot system, we design and introduce an end-user application. The source
code is available at https://github.com/tuantdang/perception_framework.
\\ ( https://arxiv.org/abs/2306.04853 ,  4404kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04857
Date: Thu, 8 Jun 2023 01:10:19 GMT   (639kb,D)

Title: The Hybrid Extended Bicycle: A Simple Model for High Dynamic Vehicle
 Trajectory Planning
Authors: Agapius Bou Ghosn, Philip Polack, Arnaud de La Fortelle
Categories: cs.RO
\\
 While highly automated driving relies most of the time on a smooth driving
assumption, the possibility of a vehicle performing harsh maneuvers with high
dynamic driving to face unexpected events is very likely. The modeling of the
behavior of the vehicle in these events is crucial to proper planning and
controlling; the used model should present accurate and computationally
efficient properties. In this article, we propose an LSTM-based hybrid extended
bicycle model able to present an accurate description of the state of the
vehicle for both normal and aggressive situations. The introduced model is used
in an MPPI framework for planning trajectories in high-dynamic scenarios where
other simple models fail.
\\ ( https://arxiv.org/abs/2306.04857 ,  639kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04910
Date: Thu, 8 Jun 2023 03:26:02 GMT   (6026kb,D)

Title: Local Map-Based DQN Navigation and a Transferability Metric Using Scene
 Similarity
Authors: Shiwei Lian and Feitian Zhang
Categories: cs.RO
\\
 Autonomous navigation in unknown environments without a global map is a
long-standing challenge for mobile robots. While deep reinforcement learning
(DRL) has attracted a rapidly growing interest in solving such an autonomous
navigation problem for its generalization capability, DRL typically leads to a
mediocre navigation performance in practice due to the gap between the training
scene and the actual test scene. Most existing work focuses on tuning the
algorithm to enhance its transferability, whereas few investigates how to
quantify or measure the gap therebetween. This letter presents a local
map-based deep Q-network (DQN) navigation algorithm, which uses local maps
converted from 2D LiDAR data as observations without a global map. More
importantly, this letter proposes a new transferability metric -- the scene
similarity calculated from an improved image template matching algorithm to
measure the similarity between the training and test scenes. With a wheeled
robot as the case study platform, both simulation and real-world experiments
are conducted in a total of 20 different scenes. The case study results
successfully validate the local map-based navigation algorithm as well as the
similarity metric in predicting the transferability or success rate of the
algorithm.
\\ ( https://arxiv.org/abs/2306.04910 ,  6026kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04928
Date: Thu, 8 Jun 2023 04:19:23 GMT   (4120kb,D)

Title: Underwater Intention Recognition using Head Motion and Throat Vibration
 for Supernumerary Robotic Assistance
Authors: Yuqin Guo, Rongzheng Zhang, Wanghongjie Qiu, Harry Asada, Fang Wan and
 Chaoyang Song
Categories: cs.RO cs.HC
Comments: 6 pages, 9 figures, 3 tables, accepted to IEEE CASE 2023
\\
 This study presents a multi-modal mechanism for recognizing human intentions
while diving underwater, aiming to achieve natural human-robot interactions
through an underwater superlimb for diving assistance. The underwater
environment severely limits the divers' capabilities in intention expression,
which becomes more challenging when they intend to operate tools while keeping
control of body postures in 3D with the various diving suits and gears. The
current literature is limited in underwater intention recognition, impeding the
development of intelligent wearable systems for human-robot interactions
underwater. Here, we present a novel solution to simultaneously detect head
motion and throat vibrations under the water in a compact, wearable design.
Experiment results show that using machine learning algorithms, we achieved
high performance in integrating these two modalities to translate human
intentions to robot control commands for an underwater superlimb system. This
study's results paved the way for future development in underwater intention
recognition and underwater human-robot interactions with supernumerary support.
\\ ( https://arxiv.org/abs/2306.04928 ,  4120kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04932
Date: Thu, 8 Jun 2023 04:29:27 GMT   (4495kb,D)

Title: Jigsaw-based Benchmarking for Learning Robotic Manipulation
Authors: Xiaobo Liu, Fang Wan, Sheng Ge, Haokun Wang, Haoran Sun, and Chaoyang
 Song
Categories: cs.RO
Comments: 7 pages, 7 figures, accepted to 2023 IEEE International Conference on
 Advanced Robotics and Mechatronics (ICARM)
\\
 Benchmarking provides experimental evidence of the scientific baseline to
enhance the progression of fundamental research, which is also applicable to
robotics. In this paper, we propose a method to benchmark metrics of robotic
manipulation, which addresses the spatial-temporal reasoning skills for robot
learning with the jigsaw game. In particular, our approach exploits a simple
set of jigsaw pieces by designing a structured protocol, which can be highly
customizable according to a wide range of task specifications. Researchers can
selectively adopt the proposed protocol to benchmark their research outputs, on
a comparable scale in the functional, task, and system-level of details. The
purpose is to provide a potential look-up table for learning-based robot
manipulation, commonly available in other engineering disciplines, to
facilitate the adoption of robotics through calculated, empirical, and
systematic experimental evidence.
\\ ( https://arxiv.org/abs/2306.04932 ,  4495kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04939
Date: Thu, 8 Jun 2023 05:12:26 GMT   (7416kb,D)

Title: UAP-BEV: Uncertainty Aware Planning using Bird's Eye View generated from
 Surround Monocular Images
Authors: Vikrant Dewangan, Basant Sharma, Tushar Choudhary, Sarthak Sharma,
 Aakash Aanegola, Arun K. Singh, K. Madhava Krishna
Categories: cs.RO
Comments: Accepted to CASE 2023. Project video available at
 https://vikr-182.github.io/UAP-BEV
\\
 Autonomous driving requires accurate reasoning of the location of objects
from raw sensor data. Recent end-to-end learning methods go from raw sensor
data to a trajectory output via Bird's Eye View(BEV) segmentation as an
interpretable intermediate representation. Motion planning over cost maps
generated via Birds Eye View (BEV) segmentation has emerged as a prominent
approach in autonomous driving. However, the current approaches have two
critical gaps. First, the optimization process is simplistic and involves just
evaluating a fixed set of trajectories over the cost map. The trajectory
samples are not adapted based on their associated cost values. Second, the
existing cost maps do not account for the uncertainty in the cost maps that can
arise due to noise in RGB images, and BEV annotations. As a result, these
approaches can struggle in challenging scenarios where there is abrupt cut-in,
stopping, overtaking, merging, etc from the neighboring vehicles.
 In this paper, we propose UAP-BEV: A novel approach that models the noise in
Spatio-Temporal BEV predictions to create an uncertainty-aware occupancy grid
map. Using queries of the distance to the closest occupied cell, we obtain a
sample estimate of the collision probability of the ego-vehicle. Subsequently,
our approach uses gradient-free sampling-based optimization to compute low-cost
trajectories over the cost map. Importantly, the sampling distribution is
adapted based on the optimal cost values of the sampled trajectories. By
explicitly modeling probabilistic collision avoidance in the BEV space, our
approach is able to outperform the cost-map-based baselines in collision
avoidance, route completion, time to completion, and smoothness. To further
validate our method, we also show results on the real-world dataset NuScenes,
where we report improvements in collision avoidance and smoothness.
\\ ( https://arxiv.org/abs/2306.04939 ,  7416kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04970
Date: Thu, 8 Jun 2023 06:59:02 GMT   (7288kb,D)

Title: Motion Planning for Aerial Pick-and-Place based on Geometric Feasibility
 Constraints
Authors: Huazi Cao, Jiahao Shen, Cunjia Liu, Bo Zhu, Shiyu Zhao
Categories: cs.RO cs.SY eess.SY
\\
 This paper studies the motion planning problem of the pick-and-place of an
aerial manipulator that consists of a quadcopter flying base and a Delta arm.
We propose a novel partially decoupled motion planning framework to solve this
problem. Compared to the state-of-the-art approaches, the proposed one has two
novel features. First, it does not suffer from increased computation in
high-dimensional configuration spaces. That is because it calculates the
trajectories of the quadcopter base and the end-effector separately in the
Cartesian space based on proposed geometric feasibility constraints. The
geometric feasibility constraints can ensure the resulting trajectories satisfy
the aerial manipulator's geometry. Second, collision avoidance for the Delta
arm is achieved through an iterative approach based on a pinhole mapping
method, so that the feasible trajectory can be found in an efficient manner.
The proposed approach is verified by three experiments on a real aerial
manipulation platform. The experimental results show the effectiveness of the
proposed method for the aerial pick-and-place task.
\\ ( https://arxiv.org/abs/2306.04970 ,  7288kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05111
Date: Thu, 8 Jun 2023 11:19:55 GMT   (41475kb,D)

Title: AutoCharge: Autonomous Charging for Perpetual Quadrotor Missions
Authors: Alessandro Saviolo, Jeffrey Mao, Roshan Balu T M B, Vivek
 Radhakrishnan, and Giuseppe Loianno
Categories: cs.RO
\\
 Battery endurance represents a key challenge for long-term autonomy and
long-range operations, especially in the case of aerial robots. In this paper,
we propose AutoCharge, an autonomous charging solution for quadrotors that
combines a portable ground station with a flexible, lightweight charging tether
and is capable of universal, highly efficient, and robust charging. We design
and manufacture a pair of circular magnetic connectors to ensure a precise
orientation-agnostic electrical connection between the ground station and the
charging tether. Moreover, we supply the ground station with an electromagnet
that largely increases the tolerance to localization and control errors during
the docking maneuver, while still guaranteeing smooth un-docking once the
charging process is completed. We demonstrate AutoCharge on a perpetual 10
hours quadrotor flight experiment and show that the docking and un-docking
performance is solidly repeatable, enabling perpetual quadrotor flight
missions.
\\ ( https://arxiv.org/abs/2306.05111 ,  41475kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05171
Date: Thu, 8 Jun 2023 13:10:00 GMT   (605kb)

Title: Robot Task Planning Based on Large Language Model Representing Knowledge
 with Directed Graph Structures
Authors: Yue Zhen, Sheng Bi, Lu Xing-tong, Pan Wei-qin, Shi Hai-peng, Chen
 Zi-rui, Fang Yi-shu
Categories: cs.RO cs.AI
\\
 Traditional robot task planning methods face challenges when dealing with
highly unstructured environments and complex tasks. We propose a task planning
method that combines human expertise with an LLM and have designed an LLM
prompt template, Think_Net_Prompt, with stronger expressive power to represent
structured professional knowledge. We further propose a method to progressively
decompose tasks and generate a task tree to reduce the planning volume for each
task, and we have designed a strategy to decouple robot task planning. By
dividing different planning entities and separating the task from the actual
machine binding process, the task planning process becomes more flexible.
Research results show that our method performs well in handling specified code
formats, understanding the relationship between tasks and subtasks, and
extracting parameters from text descriptions. However, there are also problems
such as limited complexity of task logic handling, ambiguity in the quantity of
parts and the precise location of assembly. Improving the precision of task
description and cognitive structure can bring certain improvements.
https://github.com/NOMIzy/Think_Net_Prompt
\\ ( https://arxiv.org/abs/2306.05171 ,  605kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05197
Date: Thu, 8 Jun 2023 13:52:49 GMT   (1337kb,D)

Title: Time-Optimal Path Tracking with ISO Safety Guarantees
Authors: Shohei Fujii, Quang-Cuong Pham
Categories: cs.RO
Comments: 8 pages, submitted to IROS 2023
\\
 One way of ensuring operator's safety during human-robot collaboration is
through Speed and Separation Monitoring (SSM), as defined in ISO standard
ISO/TS 15066. In general, it is impossible to avoid all human-robot collisions:
consider for instance the case when the robot does not move at all, a human
operator can still collide with it by hitting it of her own voluntary motion.
In the SSM framework, it is possible however to minimize harm by requiring
this: \emph{if} a collision ever occurs, then the robot must be in a
\emph{stationary state} (all links have zero velocity) at the time instant of
the collision. In this paper, we propose a time-optimal control policy based on
Time-Optimal Path Parameterization (TOPP) to guarantee such a behavior.
Specifically, we show that: for any robot motion that is strictly faster than
the motion recommended by our policy, there exists a human motion that results
in a collision with the robot in a non-stationary state. Correlatively, we
show, in simulation, that our policy is strictly less conservative than
state-of-the-art safe robot control methods. Additionally, we propose a
parallelization method to reduce the computation time of our pre-computation
phase (down to 0.5 sec, practically), which enables the whole pipeline
(including the pre-computation) to be executed at runtime, nearly in real-time.
Finally, we demonstrate the application of our method in a scenario:
time-optimal, safe control of a 6-dof industrial robot.
\\ ( https://arxiv.org/abs/2306.05197 ,  1337kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05309
Date: Thu, 8 Jun 2023 15:58:22 GMT   (35082kb,D)

Title: SMUG Planner: A Safe Multi-Goal Planner for Mobile Robots in Challenging
 Environments
Authors: Changan Chen, Jonas Frey, Philip Arm, and Marco Hutter
Categories: cs.RO
\\
 Robotic exploration or monitoring missions require mobile robots to
autonomously and safely navigate between multiple target locations in
potentially challenging environments. Currently, this type of multi-goal
mission often relies on humans designing a set of actions for the robot to
follow in the form of a path or waypoints. In this work, we consider the
multi-goal problem of visiting a set of pre-defined targets, each of which
could be visited from multiple potential locations. To increase autonomy in
these missions, we propose a safe multi-goal (SMUG) planner that generates an
optimal motion path to visit those targets. To increase safety and efficiency,
we propose a hierarchical state validity checking scheme, which leverages
robot-specific traversability learned in simulation. We use LazyPRM* with an
informed sampler to accelerate collision-free path generation. Our iterative
dynamic programming algorithm enables the planner to generate a path visiting
more than ten targets within seconds. Moreover, the proposed hierarchical state
validity checking scheme reduces the planning time by 30% compared to pure
volumetric collision checking and increases safety by avoiding high-risk
regions. We deploy the SMUG planner on the quadruped robot ANYmal and show its
capability to guide the robot in multi-goal missions fully autonomously on
rough terrain.
\\ ( https://arxiv.org/abs/2306.05309 ,  35082kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05324
Date: Thu, 8 Jun 2023 16:16:29 GMT   (9487kb,D)

Title: Perching by hugging: an initial feasibility study
Authors: William Stewart, Mohammad Askari, Ma\"ik Guihard, and Dario Floreano
Categories: cs.RO
Comments: Un-Peer Reviewed. Presented at the ICRA 2021 Aerial Robotics Workshop
\\
 Current UAVs capable of perching require added structure and mechanisms to
accomplish this. These take the form of hooks, claws, needles, etc which add
weight and usually drag. We propose in this paper the dual use of structures
already on the vehicle to enable perching, thus reducing the weight and drag
cost associated with perching UAVs. We propose a wing design capable of
passively wrapping around a vertical pole to perch. We experimentally
investigate the feasibility of the design, presenting results on minimum
required perching speeds as well as the effect of weight distribution on the
success rate of the wing wrapping. Finally, we comment on design requirements
for holding onto the pole based on our findings.
\\ ( https://arxiv.org/abs/2306.05324 ,  9487kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05329
Date: Thu, 8 Jun 2023 16:28:53 GMT   (433kb)

Title: Movement Optimization of Robotic Arms for Energy and Time Reduction
 using Evolutionary Algorithms
Authors: Abolfazl Akbari, Saeed Mozaffari, Rajmeet Singh, Majid Ahmadi,
 Shahpour Alirezaee
Categories: cs.RO cs.NA cs.SY eess.SY math.NA math.OC
\\
 Trajectory optimization of a robot manipulator consists of both optimization
of the robot movement as well as optimization of the robot end-effector path.
This paper aims to find optimum movement parameters including movement type,
speed, and acceleration to minimize robot energy. Trajectory optimization by
minimizing the energy would increase the longevity of robotic manipulators. We
utilized the particle swarm optimization method to find the movement parameters
leading to minimum energy consumption. The effectiveness of the proposed method
is demonstrated on different trajectories. Experimental results show that 49%
efficiency was obtained using a UR5 robotic arm.
\\ ( https://arxiv.org/abs/2306.05329 ,  433kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05340
Date: Thu, 8 Jun 2023 16:44:20 GMT   (553kb)

Title: Research Impact of Solar Panel Cleaning Robot on Photovoltaic Panel's
 Deflection
Authors: Trung Dat Phan, Minh Duc Nguyen, Maxence Auffray, Nhut Thang Le, Cong
 Toai Truong, Van Tu Duong, Huy Hung Nguyen, Tan Tien Nguyen
Categories: cs.RO
Comments: 8 pages, 8 figures, The 4th International Conference on Applied
 Convergence Engineering (ICACE 2023)
\\
 In the last few decades, solar panel cleaning robots (SPCR) have been widely
used for sanitizing photovoltaic (PV) panels as an effective solution for
ensuring PV efficiency. However, the dynamic load generated by the SPCR during
operation might have a negative impact on PV panels. To reduce these effects,
this paper presents the utilization of ANSYS software to simulate multiple
scenarios involving the impact of SPCR on PV panels. The simulation scenarios
provided in the paper are derived from the typical movements of SPCR observed
during practical operations. The simulation results show the deformation
process of PV panels, and a second-order polynomial is established to describe
the deformed amplitude along the centerline of PV panels. This second-order
polynomial contributes to the design process of a damper system for SPCR aiming
to reduce the influence of SPCR on PV panels. Moreover, the experiments are
conducted to examine the correlation between the results of the simulation and
the experiment.
\\ ( https://arxiv.org/abs/2306.05340 ,  553kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05343
Date: Thu, 8 Jun 2023 16:45:47 GMT   (2052kb)

Title: A Data-Driven Approach to Positioning Grab Bars in the Sagittal Plane
 for Elderly Persons
Authors: Roberto Bolli Jr. and H. Harry Asada
Categories: cs.RO
Comments: 4 pages, 8 figures
\\
 The placement of grab bars for elderly users is based largely on ADA building
codes and does not reflect the large differences in height, mobility, and
muscle power between individual persons. The goal of this study is to see if
there are any correlations between an elderly user's preferred handlebar pose
and various demographic indicators, self-rated mobility for tasks requiring
postural change, and biomechanical markers. For simplicity, we consider only
the case where the handlebar is positioned directly in front of the user, as
this confines the relevant body kinematics to a 2D sagittal plane. Previous
eldercare devices have been constructed to position a handlebar in various
poses in space. Our work augments these devices and adds to the body of
knowledge by assessing how the handlebar should be positioned based on data on
actual elderly people instead of simulations.
\\ ( https://arxiv.org/abs/2306.05343 ,  2052kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04782
Date: Wed, 7 Jun 2023 21:02:48 GMT   (1396kb,D)

Title: Traction and Stability Control using Fuzzy-based Controller Integration
Authors: Nimantha Dasanayake and Shehara Perera
Categories: eess.SY cs.SY
Comments: 11 pages, 11 figures, journal
\\
 Adverse road conditions can cause vehicle yaw instability and loss of
traction. To compensate for the instability under such conditions, corrective
actions must be taken. In comparison to a mechanical differential, an
electronic differential can independently control the two drive wheels and
provide means of generating more effective corrective actions. As a solution
for traction and stability issues in automobiles, this paper has developed a
controller for a vehicle electronic differential consisting of two
program-controlled rear motors. The control algorithm adjusts to changing road
conditions. Traction was controlled using a motor reaction torque
observer-based slip ratio estimation, and yaw stability was achieved by
tracking a reference yaw rate calculated using estimated tyre cornering
stiffnesses. A recursive least squares algorithm was used to estimate cornering
stiffness. The yaw rate of the vehicle, as well as its longitudinal and lateral
accelerations, were measured, and the body slip angle was estimated using an
observer. A fuzzy inference system was used to integrate the independently
developed traction control and yaw control schemes. The fuzzy inference system
modifies the commanded voltage generated by the driver's input to account for
the traction and yaw stability controller outputs. A vehicle simulator was used
to numerically simulate the integrated controller.
\\ ( https://arxiv.org/abs/2306.04782 ,  1396kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04821
Date: Wed, 7 Jun 2023 23:05:07 GMT   (1082kb,D)

Title: Augmented Digital Twin for Identification of Most Critical Cyberattacks
 in Industrial Systems
Authors: Bruno Paes Leao, Jagannadh Vempati, Siddharth Bhela, Tobias Ahlgrim,
 Daniel Arnold
Categories: eess.SY cs.SY
\\
 This work presents a novel methodology for identification of the most
critical cyberattacks that may disrupt the operation of an industrial system.
Application of the proposed framework can enable the design and development of
advanced cybersecurity functionality for a wide range of industrial
applications. The attacks are assessed taking into direct consideration how
they impact the system operation as measured by a defined Key Performance
Indicator (KPI). A simulation, or Digital Twin (DT), of the industrial process
is employed for calculation of the KPI based on operating conditions. Such DT
is augmented with a layer of information describing the computer network
topology, connected devices, and potential actions an adversary can take
associated to each device or network link. Each possible action is associated
with an abstract measure of effort, which is interpreted as a cost. It is
assumed that the adversary has a corresponding budget that constrains the
selection of the sequence of actions defining the progression of the attack. A
dynamical system comprising a set of states associated to the cyberattack
(cyber states) and transition logic for updating their values is also proposed.
The resulting Augmented Digital Twin (ADT) is then employed in a sequential
decision-making optimization formulated to yield the most critical attack
scenarios as measured by the defined KPI. The methodology is successfully
tested based on an electrical power distribution system simulation.
\\ ( https://arxiv.org/abs/2306.04821 ,  1082kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04830
Date: Wed, 7 Jun 2023 23:19:08 GMT   (440kb,D)

Title: Extended Neighboring Extremal Optimal Control with State and Preview
 Perturbations
Authors: Amin Vahidi-Moghaddam, Kaixiang Zhang, Zhaojian Li, Xunyuan Yin, Ziyou
 Song, Yan Wang
Categories: eess.SY cs.SY
\\
 Optimal control schemes have achieved remarkable performance in numerous
engineering applications. However, they typically require high computational
cost, which has limited their use in real-world engineering systems with fast
dynamics and/or limited computation power. To address this challenge,
Neighboring Extremal (NE) has been developed as an efficient optimal adaption
strategy to adapt a pre-computed nominal control solution to perturbations from
the nominal trajectory. The resulting control law is a time-varying feedback
gain that can be pre-computed along with the original optimal control problem,
and it takes negligible online computation. However, existing NE frameworks
only deal with state perturbations while in modern applications, optimal
controllers (e.g., predictive controllers) frequently incorporate preview
information. Therefore, a new NE framework is needed to adapt to such preview
perturbations. In this work, an extended NE (ENE) framework is developed to
systematically adapt the nominal control to both state and preview
perturbations. We show that the derived ENE law is two time-varying feedback
gains on the state perturbation and the preview perturbation. We also develop
schemes to handle nominal non-optimal solutions and large perturbations to
retain optimal performance and constraint satisfaction. Case study on nonlinear
model predictive control is presented due to its popularity but it can be
easily extended to other optimal control schemes. Promising simulation results
on the cart inverted pendulum problem demonstrate the efficacy of the ENE
algorithm.
\\ ( https://arxiv.org/abs/2306.04830 ,  440kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04931
Date: Thu, 8 Jun 2023 04:27:00 GMT   (594kb)

Title: A New Scoring Method for the Evaluation of Vehicle Road Departure
 Detection Systems
Authors: Dan Shen, Lingxi Li, Stanley Chien, Yaobin Chen, Rini Sherony
Categories: eess.SY cs.SY
\\
 Road departure detection systems (RDDSs) for eliminating unintentional road
departure collisions have been developed and equipped on some commercial
vehicles in recent years. In order to provide a standardized and objective
performance evaluation of RDDSs without the affections of systems complex
nature of RDDSs and the design requirements, this paper proposes the
development of the scoring method for evaluating vehicle RDDSs. Both flat road
edge and vertical road edge are considered in the proposed scoring method,
which combines two key variables: 1) the lateral distance of vehicle from road
edge when RDW triggers; 2) the lateral distance of vehicle from road edge when
RKA triggers. Two main criteria of road departure warning (RDW) and Road
Keeping Assistance (RKA) are used to describe the performance of RDDSs.
\\ ( https://arxiv.org/abs/2306.04931 ,  594kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04936
Date: Thu, 8 Jun 2023 04:59:31 GMT   (437kb,D)

Title: Combined Left and Right Temporal Robustness for Control under STL
 Specifications
Authors: Al\"ena Rodionova, Lars Lindemann, Manfred Morari and George J. Pappas
Categories: eess.SY cs.LO cs.SY
\\
 Many modern autonomous systems, particularly multi-agent systems, are
time-critical and need to be robust against timing uncertainties. Previous
works have studied left and right time robustness of signal temporal logic
specifications by considering time shifts in the predicates that are either
only to the left or only to the right. We propose a combined notion of temporal
robustness which simultaneously considers left and right time shifts. For
instance, in a scenario where a robot plans a trajectory around a pedestrian,
this combined notion can now capture uncertainty of the pedestrian arriving
earlier or later than anticipated. We first derive desirable properties of this
new notion with respect to left and right time shifts and then design control
laws for linear systems that maximize temporal robustness using mixed-integer
linear programming. Finally, we present two case studies to illustrate how the
proposed temporal robustness accounts for timing uncertainties.
\\ ( https://arxiv.org/abs/2306.04936 ,  437kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05136
Date: Thu, 8 Jun 2023 12:03:50 GMT   (25866kb,D)

Title: Safety Guaranteed Control for Spacecraft Inspection Mission
Authors: Kun Wang, Tao Meng, Jiakun Lei, Weijia Wang
Categories: eess.SY cs.SY
Comments: 22 pages, 9 figures, submitted to JGCD
\\
 This paper investigates the safety guaranteed problem in spacecraft
inspection missions, considering multiple position obstacles and logical
attitude forbidden zones. In order to address this issue, we propose a control
strategy based on control barrier functions, summarized as "safety check on
kinematics" and "velocity tracking on dynamics" approach. The proposed approach
employs control barrier functions to describe the obstacles and to generate
safe velocities via the solution of a quadratic programming problem.
Subsequently, we design a proportional-like controller based on the generated
velocity, which, despite its simplicity, can ensure safety even in the presence
of velocity tracking errors. The stability and safety of the system are
rigorously analyzed in this paper. Furthermore, to account for model
uncertainties and external disturbances, we incorporate an immersion and
invariance-based disturbance observer in our design. Finally, numerical
simulations are performed to demonstrate the effectiveness of the proposed
control strategy.
\\ ( https://arxiv.org/abs/2306.05136 ,  25866kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05140
Date: Thu, 8 Jun 2023 12:07:16 GMT   (683kb,D)

Title: A Two-dimensional Spatial Optimization Framework for Vehicle Powertrain
 Systems
Authors: Jorn van Kampen and Mauro Salazar and Theo Hofman
Categories: eess.SY cs.SY
Comments: Submitted to VPPC 2023
\\
 This paper presents a modeling framework to optimize the two-dimensional
placement of powertrain elements inside the vehicle, explicitly accounting for
the rotation, relative placement and alignment. Specifically, we first capture
the multi-level nature of the system mathematically, and construct a model that
captures different powertrain component orientations. Second, we include the
relative element placement as variables in the model and derive alignment
constraints for both child components and parent subsystems to automatically
connect mechanical ports. Finally, we showcase our framework on a four-wheel
driven electric vehicle. Our results demonstrate that our framework is capable
of efficiently generating system design solutions in a fully automated manner,
only using basic component properties.
\\ ( https://arxiv.org/abs/2306.05140 ,  683kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05161
Date: Thu, 8 Jun 2023 12:49:48 GMT   (599kb,D)

Title: Characterization of Multi-Channel Denial-of-Service and Full-Scale
 Denial-of-Service
Authors: Anindya Basu and Indrani Kar
Categories: cs.SY eess.SY
\\
 Over the past decades, interest in enhancing the safety of cyber-physical
systems (CPSs) has risen. The systems and control research society has
recognised that the embedded closed-loop in integrated systems may be damaged
if attackers can execute a successful malicious attack. This article examines
the resilient control problem for CPSs with numerous transmission channels
under Denial-of-Service (DoS). First, a partial observer technique is developed
in response to the Multi-Channel DoS (MCDoS) condition. The changing frequency
of MCDoS is characterized while maintaining the Global Asymptotic Stability
(GAS) of the closed loop system. The partial observer is modified then to
reduce the effect of the changing frequency of MCDoS in the system. Then a
resilient event-based feedback control scheme is developed to address the
Full-Scale DoS (FSDoS). We depict the changing frequency of MCDoS and the
frequency and duration of FSDoS, allowing the feedback system's Global
Asymptotic Stability (GAS) to be maintained. We regard event-based controllers
for which a minimal inter-sample time is precisely formulated in response to
the existence of digital channels.
\\ ( https://arxiv.org/abs/2306.05161 ,  599kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05227
Date: Thu, 8 Jun 2023 14:24:15 GMT   (2196kb,D)

Title: Distributionally Robust LQG control under Distributed Uncertainty
Authors: Lucia Falconi, Augusto Ferrante, Mattia Zorzi
Categories: eess.SY cs.SY
\\
 A new paradigm is proposed for the robustification of the LQG controller
against distributional uncertainties on the noise process. Our controller
optimizes the closed-loop performances in the worst possible scenario under the
constraint that the noise distributional aberrance does not exceed a certain
threshold limiting the relative entropy pseudo-distance between the actual
noise distribution the nominal one. The main novelty is that the bounds on the
distributional aberrance can be arbitrarily distributed along the whole
disturbance trajectory. We discuss why this can, in principle, be a substantial
advantage and we provide simulation results that substantiate such a principle.
\\ ( https://arxiv.org/abs/2306.05227 ,  2196kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05234
Date: Thu, 8 Jun 2023 14:31:59 GMT   (542kb)

Title: Global Stabilization of Antipodal Points on n-Sphere with Application to
 Attitude Tracking
Authors: Xin Tong and Shing Shin Cheng
Categories: eess.SY cs.SY
Comments: 8 pages
DOI: 10.1109/TAC.2023.3281341
\\
 Existing approaches to robust global asymptotic stabilization of a pair of
antipodal points on unit $n$-sphere $\mathbb{S}^n$ typically involve the
non-centrally synergistic hybrid controllers for attitude tracking on unit
quaternion space. However, when switching faults occur due to parameter errors,
the non-centrally synergistic property can lead to the unwinding problem or in
some cases, destabilize the desired set. In this work, a hybrid controller is
first proposed based on a novel centrally synergistic family of potential
functions on $\mathbb{S}^n$, which is generated from a basic potential function
through angular warping. The synergistic parameter can be explicitly expressed
if the warping angle has a positive lower bound at the undesired critical
points of the family. Next, the proposed approach induces a new
quaternion-based controller for global attitude tracking. It has three
advantageous features over existing synergistic designs: 1) it is consistent,
i.e., free from the ambiguity of unit quaternion representation; 2) it is
switching-fault-tolerant, i.e., the desired closed-loop equilibria remain
asymptotically stable even when the switching mechanism does not work; 3) it
relaxes the assumption on the parameter of the basic potential function in
literature. Comprehensive simulation confirms the high robustness of the
proposed centrally synergistic approach compared with existing non-centrally
synergistic approaches.
\\ ( https://arxiv.org/abs/2306.05234 ,  542kb)
%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-
------------------------------------------------------------------------------
\\
arXiv:2306.04643 (*cross-listing*)
Date: Thu, 25 May 2023 15:12:14 GMT   (6154kb,D)

Title: Abnormal Trading Detection in the NFT Market
Authors: Mingxiao Song and Yunsong Liu and Agam Shah and Sudheer Chava
Categories: q-fin.TR cs.AI q-fin.CP
\\
 The Non-Fungible-Token (NFT) market has experienced explosive growth in
recent years. According to DappRadar, the total transaction volume on OpenSea,
the largest NFT marketplace, reached 34.7 billion dollars in February 2023.
However, the NFT market is mostly unregulated and there are significant
concerns about money laundering, fraud and wash trading. Amateur traders and
retail investors comprise a significant fraction of the NFT market. Hence it is
important that researchers highlight the relevant risks involved in NFT
trading. In this paper, we attempt to uncover common fraudulent behaviors such
as wash trading that could mislead other traders. Using market data, we design
quantitative features from the network, monetary, and temporal perspectives
that are fed into K-means clustering unsupervised learning algorithm to sort
traders into groups. Lastly, we discuss the clustering results' significance
and how regulations can reduce undesired behaviors. Our work can potentially
help regulators narrow down their search space for bad actors in the market as
well as provide insights for amateur traders to protect themselves from
unforeseen frauds.
\\ ( https://arxiv.org/abs/2306.04643 ,  6154kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04657 (*cross-listing*)
Date: Wed, 24 May 2023 10:25:12 GMT   (2676kb,D)

Title: Improving Empathetic Dialogue Generation by Dynamically Infusing
 Commonsense Knowledge
Authors: Hua Cai, Xuli Shen, Qing Xu, Weilin Shen, Xiaomei Wang, Weifeng Ge,
 Xiaoqing Zheng and Xiangyang Xue
Categories: cs.CL cs.AI
Comments: Accepted by ACL 2023. arXiv admin note: substantial text overlap with
 arXiv:2109.05739 by other authors
\\
 In empathetic conversations, individuals express their empathy towards
others. Previous work has mainly focused on generating empathetic responses by
utilizing the speaker's emotion. Besides, external commonsense knowledge has
been applied to enhance the system's understandings of the speaker's situation.
However, given an event, commonsense knowledge base contains various relations,
potentially leading to confusion for the dialogue system. Consequently,
inconsistencies arise among the emotion, generated response and speaker's
contextual information. To this end, we propose a novel approach for empathetic
response generation, which incorporates an adaptive module for commonsense
knowledge selection to ensure consistency between the generated empathetic
responses and the speaker's situation. This selected knowledge is used to
refine the commonsense cognition and empathy expression for generated
responses. Experimental results show that our approach significantly
outperforms baseline models in both automatic and human evaluations, exhibiting
the generation of more coherent and empathetic responses. Moreover, case
studies highlight the interpretability of knowledge selection in the responses
and the effectiveness of adaptive module in our model. Code:
https://github.com/Hanscal/DCKS.
\\ ( https://arxiv.org/abs/2306.04657 ,  2676kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04707 (*cross-listing*)
Date: Wed, 7 Jun 2023 18:19:46 GMT   (8389kb,D)

Title: Improving Open Language Models by Learning from Organic Interactions
Authors: Jing Xu, Da Ju, Joshua Lane, Mojtaba Komeili, Eric Michael Smith,
 Megan Ung, Morteza Behrooz, William Ngan, Rashel Moritz, Sainbayar
 Sukhbaatar, Y-Lan Boureau, Jason Weston, Kurt Shuster
Categories: cs.CL cs.AI
\\
 We present BlenderBot 3x, an update on the conversational model BlenderBot 3,
which is now trained using organic conversation and feedback data from
participating users of the system in order to improve both its skills and
safety. We are publicly releasing the participating de-identified interaction
data for use by the research community, in order to spur further progress.
Training models with organic data is challenging because interactions with
people "in the wild" include both high quality conversations and feedback, as
well as adversarial and toxic behavior. We study techniques that enable
learning from helpful teachers while avoiding learning from people who are
trying to trick the model into unhelpful or toxic responses. BlenderBot 3x is
both preferred in conversation to BlenderBot 3, and is shown to produce safer
responses in challenging situations. While our current models are still far
from perfect, we believe further improvement can be achieved by continued use
of the techniques explored in this work.
\\ ( https://arxiv.org/abs/2306.04707 ,  8389kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04723 (*cross-listing*)
Date: Wed, 7 Jun 2023 18:38:04 GMT   (1053kb,D)

Title: Intrinsic Dimension Estimation for Robust Detection of AI-Generated
 Texts
Authors: Eduard Tulchinskii, Kristian Kuznetsov, Laida Kushnareva, Daniil
 Cherniavskii, Serguei Barannikov, Irina Piontkovskaya, Sergey Nikolenko and
 Evgeny Burnaev
Categories: cs.CL cs.AI
MSC-class: 68T50
\\
 Rapidly increasing quality of AI-generated content makes it difficult to
distinguish between human and AI-generated texts, which may lead to undesirable
consequences for society. Therefore, it becomes increasingly important to study
the properties of human texts that are invariant over text domains and various
proficiency of human writers, can be easily calculated for any language, and
can robustly separate natural and AI-generated texts regardless of the
generation model and sampling method. In this work, we propose such an
invariant of human texts, namely the intrinsic dimensionality of the manifold
underlying the set of embeddings of a given text sample. We show that the
average intrinsic dimensionality of fluent texts in natural language is
hovering around the value $9$ for several alphabet-based languages and around
$7$ for Chinese, while the average intrinsic dimensionality of AI-generated
texts for each language is $\approx 1.5$ lower, with a clear statistical
separation between human-generated and AI-generated distributions. This
property allows us to build a score-based artificial text detector. The
proposed detector's accuracy is stable over text domains, generator models, and
human writer proficiency levels, outperforming SOTA detectors in model-agnostic
and cross-domain scenarios by a significant margin.
\\ ( https://arxiv.org/abs/2306.04723 ,  1053kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04735 (*cross-listing*)
Date: Wed, 7 Jun 2023 19:11:25 GMT   (15373kb,D)

Title: Soft-prompt Tuning for Large Language Models to Evaluate Bias
Authors: Jacob-Junqi Tian, David Emerson, Sevil Zanjani Miyandoab, Deval
 Pandya, Laleh Seyyed-Kalantari, Faiza Khan Khattak
Categories: cs.CL cs.AI cs.LG
\\
 Prompting large language models has gained immense popularity in recent years
due to the advantage of producing good results even without the need for
labelled data. However, this requires prompt tuning to get optimal prompts that
lead to better model performances. In this paper, we explore the use of
soft-prompt tuning on sentiment classification task to quantify the biases of
large language models (LLMs) such as Open Pre-trained Transformers (OPT) and
Galactica language model. Since these models are trained on real-world data
that could be prone to bias toward certain groups of populations, it is
important to identify these underlying issues. Using soft-prompts to evaluate
bias gives us the extra advantage of avoiding the human-bias injection that can
be caused by manually designed prompts. We check the model biases on different
sensitive attributes using the group fairness (bias) and find interesting bias
patterns. Since LLMs have been used in the industry in various applications, it
is crucial to identify the biases before deploying these models in practice. We
open-source our pipeline and encourage industry researchers to adapt our work
to their use cases.
\\ ( https://arxiv.org/abs/2306.04735 ,  15373kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04743 (*cross-listing*)
Date: Wed, 7 Jun 2023 19:37:55 GMT   (428kb,D)

Title: ScienceBenchmark: A Complex Real-World Benchmark for Evaluating Natural
 Language to SQL Systems
Authors: Yi Zhang, Jan Deriu, George Katsogiannis-Meimarakis, Catherine Kosten,
 Georgia Koutrika, Kurt Stockinger
Categories: cs.DB cs.AI cs.CL
Comments: 12 pages, 2 figures, 5 tables
ACM-class: H.2.4; I.2.7
\\
 Natural Language to SQL systems (NL-to-SQL) have recently shown a significant
increase in accuracy for natural language to SQL query translation. This
improvement is due to the emergence of transformer-based language models, and
the popularity of the Spider benchmark - the de-facto standard for evaluating
NL-to-SQL systems. The top NL-to-SQL systems reach accuracies of up to 85\%.
However, Spider mainly contains simple databases with few tables, columns, and
entries, which does not reflect a realistic setting. Moreover, complex
real-world databases with domain-specific content have little to no training
data available in the form of NL/SQL-pairs leading to poor performance of
existing NL-to-SQL systems.
 In this paper, we introduce ScienceBenchmark, a new complex NL-to-SQL
benchmark for three real-world, highly domain-specific databases. For this new
benchmark, SQL experts and domain experts created high-quality NL/SQL-pairs for
each domain. To garner more data, we extended the small amount of
human-generated data with synthetic data generated using GPT-3. We show that
our benchmark is highly challenging, as the top performing systems on Spider
achieve a very low performance on our benchmark. Thus, the challenge is
many-fold: creating NL-to-SQL systems for highly complex domains with a small
amount of hand-made training data augmented with synthetic data. To our
knowledge, ScienceBenchmark is the first NL-to-SQL benchmark designed with
complex real-world scientific databases, containing challenging training and
test data carefully validated by domain experts.
\\ ( https://arxiv.org/abs/2306.04743 ,  428kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04757 (*cross-listing*)
Date: Wed, 7 Jun 2023 20:12:29 GMT   (321kb,D)

Title: INSTRUCTEVAL: Towards Holistic Evaluation of Instruction-Tuned Large
 Language Models
Authors: Yew Ken Chia, Pengfei Hong, Lidong Bing, Soujanya Poria
Categories: cs.CL cs.AI
Comments: https://github.com/declare-lab/instruct-eval
\\
 Instruction-tuned large language models have revolutionized natural language
processing and have shown great potential in applications such as
conversational agents. These models, such as GPT-4, can not only master
language but also solve complex tasks in areas like mathematics, coding,
medicine, and law. Despite their impressive capabilities, there is still a lack
of comprehensive understanding regarding their full potential, primarily due to
the black-box nature of many models and the absence of holistic evaluation
studies. To address these challenges, we present INSTRUCTEVAL, a more
comprehensive evaluation suite designed specifically for instruction-tuned
large language models. Unlike previous works, our evaluation involves a
rigorous assessment of models based on problem-solving, writing ability, and
alignment to human values. We take a holistic approach to analyze various
factors affecting model performance, including the pretraining foundation,
instruction-tuning data, and training methods. Our findings reveal that the
quality of instruction data is the most crucial factor in scaling model
performance. While open-source models demonstrate impressive writing abilities,
there is substantial room for improvement in problem-solving and alignment. We
are encouraged by the rapid development of models by the open-source community,
but we also highlight the need for rigorous evaluation to support claims made
about these models. Through INSTRUCTEVAL, we aim to foster a deeper
understanding of instruction-tuned models and advancements in their
capabilities. INSTRUCTEVAL is publicly available at
https://github.com/declare-lab/instruct-eval.
\\ ( https://arxiv.org/abs/2306.04757 ,  321kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04758 (*cross-listing*)
Date: Wed, 7 Jun 2023 20:16:08 GMT   (23308kb,D)

Title: SKG: A Versatile Information Retrieval and Analysis Framework for
 Academic Papers with Semantic Knowledge Graphs
Authors: Yamei Tu, Rui Qiu, Han-Wei Shen
Categories: cs.IR cs.AI cs.GR cs.HC
\\
 The number of published research papers has experienced exponential growth in
recent years, which makes it crucial to develop new methods for efficient and
versatile information extraction and knowledge discovery. To address this need,
we propose a Semantic Knowledge Graph (SKG) that integrates semantic concepts
from abstracts and other meta-information to represent the corpus. The SKG can
support various semantic queries in academic literature thanks to the high
diversity and rich information content stored within. To extract knowledge from
unstructured text, we develop a Knowledge Extraction Module that includes a
semi-supervised pipeline for entity extraction and entity normalization. We
also create an ontology to integrate the concepts with other meta information,
enabling us to build the SKG. Furthermore, we design and develop a dataflow
system that demonstrates how to conduct various semantic queries flexibly and
interactively over the SKG. To demonstrate the effectiveness of our approach,
we conduct the research based on the visualization literature and provide
real-world use cases to show the usefulness of the SKG.
 The dataset and codes for this work are available at
https://osf.io/aqv8p/?view_only=2c26b36e3e3941ce999df47e4616207f.
\\ ( https://arxiv.org/abs/2306.04758 ,  23308kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04833 (*cross-listing*)
Date: Wed, 7 Jun 2023 23:24:50 GMT   (2796kb,D)

Title: Unified Embedding Based Personalized Retrieval in Etsy Search
Authors: Rishikesh Jha, Siddharth Subramaniyam, Ethan Benjamin, Thrivikrama
 Taula
Categories: cs.IR cs.AI
\\
 Embedding-based neural retrieval is a prevalent approach to address the
semantic gap problem which often arises in product search on tail queries. In
contrast, popular queries typically lack context and have a broad intent where
additional context from users historical interaction can be helpful. In this
paper, we share our novel approach to address both: the semantic gap problem
followed by an end to end trained model for personalized semantic retrieval. We
propose learning a unified embedding model incorporating graph, transformer and
term-based embeddings end to end and share our design choices for optimal
tradeoff between performance and efficiency. We share our learnings in feature
engineering, hard negative sampling strategy, and application of transformer
model, including a novel pre-training strategy and other tricks for improving
search relevance and deploying such a model at industry scale. Our personalized
retrieval model significantly improves the overall search experience, as
measured by a 5.58% increase in search purchase rate and a 2.63% increase in
site-wide conversion rate, aggregated across multiple A/B tests - on live
traffic.
\\ ( https://arxiv.org/abs/2306.04833 ,  2796kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04846 (*cross-listing*)
Date: Thu, 8 Jun 2023 00:42:10 GMT   (10353kb)

Title: Learned spatial data partitioning
Authors: Keizo Hori, Yuya Sasaki, Daichi Amagata, Yuki Murosaki, Makoto Onizuka
Categories: cs.DB cs.AI
\\
 Due to the significant increase in the size of spatial data, it is essential
to use distributed parallel processing systems to efficiently analyze spatial
data. In this paper, we first study learned spatial data partitioning, which
effectively assigns groups of big spatial data to computers based on locations
of data by using machine learning techniques. We formalize spatial data
partitioning in the context of reinforcement learning and develop a novel deep
reinforcement learning algorithm. Our learning algorithm leverages features of
spatial data partitioning and prunes ineffective learning processes to find
optimal partitions efficiently. Our experimental study, which uses Apache
Sedona and real-world spatial data, demonstrates that our method efficiently
finds partitions for accelerating distance join queries and reduces the
workload run time by up to 59.4%.
\\ ( https://arxiv.org/abs/2306.04846 ,  10353kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04874 (*cross-listing*)
Date: Thu, 8 Jun 2023 02:07:49 GMT   (573kb,D)

Title: Expanding Scope: Adapting English Adversarial Attacks to Chinese
Authors: Hanyu Liu, Chengyuan Cai, Yanjun Qi
Categories: cs.CL cs.AI cs.CR cs.LG
Comments: 11 pages; in ACL23 TrustNLP 2023: TrustNLP: Third Workshop on
 Trustworthy Natural Language Processing Colocated with the Annual Conference
 of the Association for Computational Linguistics (ACL 2023)
\\
 Recent studies have revealed that NLP predictive models are vulnerable to
adversarial attacks. Most existing studies focused on designing attacks to
evaluate the robustness of NLP models in the English language alone. Literature
has seen an increasing need for NLP solutions for other languages. We,
therefore, ask one natural question: whether state-of-the-art (SOTA) attack
methods generalize to other languages. This paper investigates how to adapt
SOTA adversarial attack algorithms in English to the Chinese language. Our
experiments show that attack methods previously applied to English NLP can
generate high-quality adversarial examples in Chinese when combined with proper
text segmentation and linguistic constraints. In addition, we demonstrate that
the generated adversarial examples can achieve high fluency and semantic
consistency by focusing on the Chinese language's morphology and phonology,
which in turn can be used to improve the adversarial robustness of Chinese NLP
models.
\\ ( https://arxiv.org/abs/2306.04874 ,  573kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04899 (*cross-listing*)
Date: Thu, 8 Jun 2023 03:00:50 GMT   (9557kb,D)

Title: Multi-level Protein Representation Learning for Blind Mutational Effect
 Prediction
Authors: Yang Tan, Bingxin Zhou, Yuanhong Jiang, Yu Guang Wang, Liang Hong
Categories: q-bio.QM cs.AI
\\
 Directed evolution plays an indispensable role in protein engineering that
revises existing protein sequences to attain new or enhanced functions.
Accurately predicting the effects of protein variants necessitates an in-depth
understanding of protein structure and function. Although large self-supervised
language models have demonstrated remarkable performance in zero-shot inference
using only protein sequences, these models inherently do not interpret the
spatial characteristics of protein structures, which are crucial for
comprehending protein folding stability and internal molecular interactions.
This paper introduces a novel pre-training framework that cascades sequential
and geometric analyzers for protein primary and tertiary structures. It guides
mutational directions toward desired traits by simulating natural selection on
wild-type proteins and evaluates the effects of variants based on their fitness
to perform the function. We assess the proposed approach using a public
database and two new databases for a variety of variant effect prediction
tasks, which encompass a diverse set of proteins and assays from different
taxa. The prediction results achieve state-of-the-art performance over other
zero-shot learning methods for both single-site mutations and deep mutations.
\\ ( https://arxiv.org/abs/2306.04899 ,  9557kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04926 (*cross-listing*)
Date: Thu, 8 Jun 2023 04:08:32 GMT   (707kb)

Title: covLLM: Large Language Models for COVID-19 Biomedical Literature
Authors: Yousuf A. Khan, Clarisse Hokia, Jennifer Xu, Ben Ehlert
Categories: cs.CL cs.AI cs.LG
\\
 The COVID-19 pandemic led to 1.1 million deaths in the United States, despite
the explosion of coronavirus research. These new findings are slow to translate
to clinical interventions, leading to poorer patient outcomes and unnecessary
deaths. One reason is that clinicians, overwhelmed by patients, struggle to
keep pace with the rate of new coronavirus literature. A potential solution is
developing a tool for evaluating coronavirus literature using large language
models (LLMs) -- neural networks that are deployed for natural language
processing. LLMs can be used to summarize and extract user-specified
information. The greater availability and advancement of LLMs and pre-processed
coronavirus literature databases provide the opportunity to assist clinicians
in evaluating coronavirus literature through a coronavirus literature specific
LLM (covLLM), a tool that directly takes an inputted research article and a
user query to return an answer. Using the COVID-19 Open Research Dataset
(CORD-19), we produced two datasets: (1) synCovid, which uses a combination of
handwritten prompts and synthetic prompts generated using OpenAI, and (2) real
abstracts, which contains abstract and title pairs. covLLM was trained with
LLaMA 7B as a baseline model to produce three models trained on (1) the Alpaca
and synCovid datasets, (2) the synCovid dataset, and (3) the synCovid and real
abstract datasets. These models were evaluated by two human evaluators and
ChatGPT. Results demonstrate that training covLLM on the synCovid and abstract
pairs datasets performs competitively with ChatGPT and outperforms covLLM
trained primarily using the Alpaca dataset.
\\ ( https://arxiv.org/abs/2306.04926 ,  707kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04959 (*cross-listing*)
Date: Thu, 8 Jun 2023 06:21:35 GMT   (3262kb,D)

Title: FedMLSecurity: A Benchmark for Attacks and Defenses in Federated
 Learning and LLMs
Authors: Shanshan Han, Baturalp Buyukates, Zijian Hu, Han Jin, Weizhao Jin,
 Lichao Sun, Xiaoyang Wang, Chulin Xie, Kai Zhang, Qifan Zhang, Yuhui Zhang,
 Chaoyang He and Salman Avestimehr
Categories: cs.CR cs.AI
\\
 This paper introduces FedMLSecurity, a benchmark that simulates adversarial
attacks and corresponding defense mechanisms in Federated Learning (FL). As an
integral module of the open-sourced library FedML that facilitates FL algorithm
development and performance comparison, FedMLSecurity enhances the security
assessment capacity of FedML. FedMLSecurity comprises two principal components:
FedMLAttacker, which simulates attacks injected into FL training, and
FedMLDefender, which emulates defensive strategies designed to mitigate the
impacts of the attacks. FedMLSecurity is open-sourced 1 and is customizable to
a wide range of machine learning models (e.g., Logistic Regression, ResNet,
GAN, etc.) and federated optimizers (e.g., FedAVG, FedOPT, FedNOVA, etc.).
Experimental evaluations in this paper also demonstrate the ease of application
of FedMLSecurity to Large Language Models (LLMs), further reinforcing its
versatility and practical utility in various scenarios.
\\ ( https://arxiv.org/abs/2306.04959 ,  3262kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04997 (*cross-listing*)
Date: Thu, 8 Jun 2023 07:35:39 GMT   (280kb,D)

Title: Blockage Prediction in Directional mmWave Links Using Liquid Time
 Constant Network
Authors: Martin H. Nielsen, Chia-Yi Yeh, Ming Shen, and Muriel M\'edard
Categories: eess.SP cs.AI
Comments: 2 pages, pre-print for IRMMW 2023 conference
\\
 We propose to use a liquid time constant (LTC) network to predict the future
blockage status of a millimeter wave (mmWave) link using only the received
signal power as the input to the system. The LTC network is based on an
ordinary differential equation (ODE) system inspired by biology and specialized
for near-future prediction for time sequence observation as the input. Using an
experimental dataset at 60 GHz, we show that our proposed use of LTC can
reliably predict the occurrence of blockage and the length of the blockage
without the need for scenario-specific data. The results show that the proposed
LTC can predict with upwards of 97.85\% accuracy without prior knowledge of the
outdoor scenario or retraining/tuning. These results highlight the promising
gains of using LTC networks to predict time series-dependent signals, which can
lead to more reliable and low-latency communication.
\\ ( https://arxiv.org/abs/2306.04997 ,  280kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05004 (*cross-listing*)
Date: Thu, 8 Jun 2023 07:48:01 GMT   (139kb,D)

Title: VIFS: An End-to-End Variational Inference for Foley Sound Synthesis
Authors: Junhyeok Lee, Hyeonuk Nam, Yong-Hwa Park
Categories: eess.AS cs.AI cs.SD
Comments: DCASE 2023 Challenge Task 7
\\
 The goal of DCASE 2023 Challenge Task 7 is to generate various sound clips
for Foley sound synthesis (FSS) by "category-to-sound" approach. "Category" is
expressed by a single index while corresponding "sound" covers diverse and
different sound examples. To generate diverse sounds for a given category, we
adopt VITS, a text-to-speech (TTS) model with variational inference. In
addition, we apply various techniques from speech synthesis including PhaseAug
and Avocodo. Different from TTS models which generate short pronunciation from
phonemes and speaker identity, the category-to-sound problem requires
generating diverse sounds just from a category index. To compensate for the
difference while maintaining consistency within each audio clip, we heavily
modified the prior encoder to enhance consistency with posterior latent
variables. This introduced additional Gaussian on the prior encoder which
promotes variance within the category. With these modifications, we propose
VIFS, variational inference for end-to-end Foley sound synthesis, which
generates diverse high-quality sounds.
\\ ( https://arxiv.org/abs/2306.05004 ,  139kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05036 (*cross-listing*)
Date: Thu, 8 Jun 2023 08:41:30 GMT   (3614kb,D)

Title: Mapping the Challenges of HCI: An Application and Evaluation of ChatGPT
 and GPT-4 for Cost-Efficient Question Answering
Authors: Jonas Oppenlaender, Joonas H\"am\"al\"ainen
Categories: cs.HC cs.AI
Comments: 12 pages, 3 figures, 4 tables
ACM-class: H.5.m; I.2.7; J.m
\\
 Large language models (LLMs), such as ChatGPT and GPT-4, are gaining
wide-spread real world use. Yet, the two LLMs are closed source, and little is
known about the LLMs' performance in real-world use cases. In academia, LLM
performance is often measured on benchmarks which may have leaked into
ChatGPT's and GPT-4's training data. In this paper, we apply and evaluate
ChatGPT and GPT-4 for the real-world task of cost-efficient extractive question
answering over a text corpus that was published after the two LLMs completed
training. More specifically, we extract research challenges for researchers in
the field of HCI from the proceedings of the 2023 Conference on Human Factors
in Computing Systems (CHI). We critically evaluate the LLMs on this practical
task and conclude that the combination of ChatGPT and GPT-4 makes an excellent
cost-efficient means for analyzing a text corpus at scale. Cost-efficiency is
key for prototyping research ideas and analyzing text corpora from different
perspectives, with implications for applying LLMs in academia and practice. For
researchers in HCI, we contribute an interactive visualization of 4392 research
challenges in over 90 research topics. We share this visualization and the
dataset in the spirit of open science.
\\ ( https://arxiv.org/abs/2306.05036 ,  3614kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05053 (*cross-listing*)
Date: Thu, 8 Jun 2023 09:15:01 GMT   (1654kb,D)

Title: Active Inference in Hebbian Learning Networks
Authors: Ali Safa, Tim Verbelen, Lars Keuninckx, Ilja Ocket, Andr\'e Bourdoux,
 Francky Catthoor, Georges Gielen, Gert Cauwenberghs
Categories: cs.NE cs.AI
\\
 This work studies how brain-inspired neural ensembles equipped with local
Hebbian plasticity can perform active inference (AIF) in order to control
dynamical agents. A generative model capturing the environment dynamics is
learned by a network composed of two distinct Hebbian ensembles: a posterior
network, which infers latent states given the observations, and a state
transition network, which predicts the next expected latent state given current
state-action pairs. Experimental studies are conducted using the Mountain Car
environment from the OpenAI gym suite, to study the effect of the various
Hebbian network parameters on the task performance. It is shown that the
proposed Hebbian AIF approach outperforms the use of Q-learning, while not
requiring any replay buffer, as in typical reinforcement learning systems.
These results motivate further investigations of Hebbian learning for the
design of AIF networks that can learn environment dynamics without the need for
revisiting past buffered experiences.
\\ ( https://arxiv.org/abs/2306.05053 ,  1654kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05059 (*cross-listing*)
Date: Thu, 8 Jun 2023 09:23:22 GMT   (1142kb,D)

Title: Reconciling Predictive and Statistical Parity: A Causal Approach
Authors: Drago Plecko, Elias Bareinboim
Categories: cs.CY cs.AI cs.LG stat.ML
\\
 Since the rise of fair machine learning as a critical field of inquiry, many
different notions on how to quantify and measure discrimination have been
proposed in the literature. Some of these notions, however, were shown to be
mutually incompatible. Such findings make it appear that numerous different
kinds of fairness exist, thereby making a consensus on the appropriate measure
of fairness harder to reach, hindering the applications of these tools in
practice. In this paper, we investigate one of these key impossibility results
that relates the notions of statistical and predictive parity. Specifically, we
derive a new causal decomposition formula for the fairness measures associated
with predictive parity, and obtain a novel insight into how this criterion is
related to statistical parity through the legal doctrines of disparate
treatment, disparate impact, and the notion of business necessity. Our results
show that through a more careful causal analysis, the notions of statistical
and predictive parity are not really mutually exclusive, but complementary and
spanning a spectrum of fairness notions through the concept of business
necessity. Finally, we demonstrate the importance of our findings on a
real-world example.
\\ ( https://arxiv.org/abs/2306.05059 ,  1142kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05064 (*cross-listing*)
Date: Thu, 8 Jun 2023 09:29:05 GMT   (1075kb,D)

Title: Learning A Foundation Language Model for Geoscience Knowledge
 Understanding and Utilization
Authors: Cheng Deng, Tianhang Zhang, Zhongmou He, Qiyuan Chen, Yuanyuan Shi, Le
 Zhou, Luoyi Fu, Weinan Zhang, Xinbing Wang, Chenghu Zhou, Zhouhan Lin,
 Junxian He
Categories: cs.CL cs.AI
ACM-class: I.2.7; F.4.1
\\
 Large language models (LLMs)have achieved great success in general domains of
natural language processing. In this paper, we bring LLMs to the realm of
geoscience, with the objective of advancing research and applications in this
field. To this end, we present the first-ever LLM in geoscience, K2, alongside
a suite of resources developed to further promote LLM research within
geoscience. For instance, we have curated the first geoscience instruction
tuning dataset, GeoSignal, which aims to align LLM responses to
geoscience-related user queries. Additionally, we have established the first
geoscience benchmark, GeoBenchmark, to evaluate LLMs in the context of
geoscience. In this work, we experiment with a complete recipe to adapt a
pretrained general-domain LLM to the geoscience domain. Specifically, we
further train the LLaMA-7B model on over 1 million pieces of geoscience
literature and utilize GeoSignal's supervised data to fine-tune the model.
Moreover, we share a protocol that can efficiently gather domain-specific data
and construct domain-supervised data, even in situations where manpower is
scarce. Experiments conducted on the GeoBenchmark demonstrate the the
effectiveness of our approach and datasets.
\\ ( https://arxiv.org/abs/2306.05064 ,  1075kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05071 (*cross-listing*)
Date: Thu, 8 Jun 2023 09:40:28 GMT   (64kb,D)

Title: A Causal Framework for Decomposing Spurious Variations
Authors: Drago Plecko, Elias Bareinboim
Categories: stat.ME cs.AI cs.LG stat.ML
\\
 One of the fundamental challenges found throughout the data sciences is to
explain why things happen in specific ways, or through which mechanisms a
certain variable $X$ exerts influences over another variable $Y$. In statistics
and machine learning, significant efforts have been put into developing
machinery to estimate correlations across variables efficiently. In causal
inference, a large body of literature is concerned with the decomposition of
causal effects under the rubric of mediation analysis. However, many variations
are spurious in nature, including different phenomena throughout the applied
sciences. Despite the statistical power to estimate correlations and the
identification power to decompose causal effects, there is still little
understanding of the properties of spurious associations and how they can be
decomposed in terms of the underlying causal mechanisms. In this manuscript, we
develop formal tools for decomposing spurious variations in both Markovian and
Semi-Markovian models. We prove the first results that allow a non-parametric
decomposition of spurious effects and provide sufficient conditions for the
identification of such decompositions. The described approach has several
applications, ranging from explainable and fair AI to questions in epidemiology
and medicine, and we empirically demonstrate its use on a real-world dataset.
\\ ( https://arxiv.org/abs/2306.05071 ,  64kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05077 (*cross-listing*)
Date: Thu, 8 Jun 2023 10:00:19 GMT   (6896kb,D)

Title: Improving Language Model Integration for Neural Machine Translation
Authors: Christian Herold and Yingbo Gao and Mohammad Zeineldeen and Hermann
 Ney
Categories: cs.CL cs.AI cs.LG
Comments: accepted at ACL2023 (Findings)
\\
 The integration of language models for neural machine translation has been
extensively studied in the past. It has been shown that an external language
model, trained on additional target-side monolingual data, can help improve
translation quality. However, there has always been the assumption that the
translation model also learns an implicit target-side language model during
training, which interferes with the external language model at decoding time.
Recently, some works on automatic speech recognition have demonstrated that, if
the implicit language model is neutralized in decoding, further improvements
can be gained when integrating an external language model. In this work, we
transfer this concept to the task of machine translation and compare with the
most prominent way of including additional monolingual data - namely
back-translation. We find that accounting for the implicit language model
significantly boosts the performance of language model fusion, although this
approach is still outperformed by back-translation.
\\ ( https://arxiv.org/abs/2306.05077 ,  6896kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05087 (*cross-listing*)
Date: Thu, 8 Jun 2023 10:41:56 GMT   (2881kb,D)

Title: PandaLM: An Automatic Evaluation Benchmark for LLM Instruction Tuning
 Optimization
Authors: Yidong Wang, Zhuohao Yu, Zhengran Zeng, Linyi Yang, Cunxiang Wang, Hao
 Chen, Chaoya Jiang, Rui Xie, Jindong Wang, Xing Xie, Wei Ye, Shikun Zhang,
 Yue Zhang
Categories: cs.CL cs.AI
\\
 Instruction tuning large language models (LLMs) remains a challenging task,
owing to the complexity of hyperparameter selection and the difficulty involved
in evaluating the tuned models. To determine the optimal hyperparameters, an
automatic, robust, and reliable evaluation benchmark is essential. However,
establishing such a benchmark is not a trivial task due to the challenges
associated with evaluation accuracy and privacy protection. In response to
these challenges, we introduce a judge large language model, named PandaLM,
which is trained to distinguish the superior model given several LLMs.
PandaLM's focus extends beyond just the objective correctness of responses,
which is the main focus of traditional evaluation datasets. It addresses vital
subjective factors such as relative conciseness, clarity, adherence to
instructions, comprehensiveness, and formality. To ensure the reliability of
PandaLM, we collect a diverse human-annotated test dataset, where all contexts
are generated by humans and labels are aligned with human preferences. Our
results indicate that PandaLM-7B achieves 93.75% of GPT-3.5's evaluation
ability and 88.28% of GPT-4's in terms of F1-score on our test dataset. PandaLM
enables the evaluation of LLM to be fairer but with less cost, evidenced by
significant improvements achieved by models tuned through PandaLM compared to
their counterparts trained with default Alpaca's hyperparameters. In addition,
PandaLM does not depend on API-based evaluations, thus avoiding potential data
leakage. All resources of PandaLM are released at
https://github.com/WeOpenML/PandaLM.
\\ ( https://arxiv.org/abs/2306.05087 ,  2881kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05116 (*cross-listing*)
Date: Thu, 8 Jun 2023 11:30:43 GMT   (6900kb,D)

Title: On Search Strategies for Document-Level Neural Machine Translation
Authors: Christian Herold and Hermann Ney
Categories: cs.CL cs.AI cs.LG
Comments: Accepted to ACL 2023 (Findings)
\\
 Compared to sentence-level systems, document-level neural machine translation
(NMT) models produce a more consistent output across a document and are able to
better resolve ambiguities within the input. There are many works on
document-level NMT, mostly focusing on modifying the model architecture or
training strategy to better accommodate the additional context-input. On the
other hand, in most works, the question on how to perform search with the
trained model is scarcely discussed, sometimes not mentioned at all. In this
work, we aim to answer the question how to best utilize a context-aware
translation model in decoding. We start with the most popular document-level
NMT approach and compare different decoding schemes, some from the literature
and others proposed by us. In the comparison, we are using both, standard
automatic metrics, as well as specific linguistic phenomena on three standard
document-level translation benchmarks. We find that most commonly used decoding
strategies perform similar to each other and that higher quality context
information has the potential to further improve the translation.
\\ ( https://arxiv.org/abs/2306.05116 ,  6900kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05153 (*cross-listing*)
Date: Thu, 8 Jun 2023 12:22:56 GMT   (124kb,D)

Title: Is AI the better programming partner? Human-Human Pair Programming vs.
 Human-AI pAIr Programming
Authors: Qianou (Christina) Ma, Tongshuang Wu, Kenneth Koedinger
Categories: cs.HC cs.AI
Comments: 8 pages (without references), 2 tables
\\
 The emergence of large-language models (LLMs) that excel at code generation
and commercial products such as GitHub's Copilot has sparked interest in
human-AI pair programming (referred to as "pAIr programming") where an AI
system collaborates with a human programmer. While traditional pair programming
between humans has been extensively studied, it remains uncertain whether its
findings can be applied to human-AI pair programming. We compare human-human
and human-AI pair programming, exploring their similarities and differences in
interaction, measures, benefits, and challenges. We find that the effectiveness
of both approaches is mixed in the literature (though the measures used for
pAIr programming are not as comprehensive). We summarize moderating factors on
the success of human-human pair programming, which provides opportunities for
pAIr programming research. For example, mismatched expertise makes pair
programming less productive, therefore well-designed AI programming assistants
may adapt to differences in expertise levels.
\\ ( https://arxiv.org/abs/2306.05153 ,  124kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05176 (*cross-listing*)
Date: Thu, 8 Jun 2023 13:17:06 GMT   (41kb,D)

Title: RRWKV: Capturing Long-range Dependencies in RWKV
Authors: Leilei Wang
Categories: cs.CL cs.AI
\\
 Owing to the impressive dot-product attention, the Transformers have been the
dominant architectures in various natural language processing (NLP) tasks.
Recently, the Receptance Weighted Key Value (RWKV) architecture follows a
non-transformer architecture to eliminate the drawbacks of dot-product
attention, where memory and computational complexity exhibits quadratic scaling
with sequence length. Although RWKV has exploited a linearly tensor-product
attention mechanism and achieved parallelized computations by deploying the
time-sequential mode, it fails to capture long-range dependencies because of
its limitation on looking back at previous information, compared with full
information obtained by direct interactions in the standard transformer.
Therefore, the paper devises the Retrospected Receptance Weighted Key Value
(RRWKV) architecture via incorporating the retrospecting ability into the RWKV
to effectively absorb information, which maintains memory and computational
efficiency as well.
\\ ( https://arxiv.org/abs/2306.05176 ,  41kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05183 (*cross-listing*)
Date: Thu, 8 Jun 2023 13:28:48 GMT   (6900kb,D)

Title: Improving Long Context Document-Level Machine Translation
Authors: Christian Herold and Hermann Ney
Categories: cs.CL cs.AI cs.LG
Comments: accepted at CODI 2023 (ACL workshop)
\\
 Document-level context for neural machine translation (NMT) is crucial to
improve the translation consistency and cohesion, the translation of ambiguous
inputs, as well as several other linguistic phenomena. Many works have been
published on the topic of document-level NMT, but most restrict the system to
only local context, typically including just the one or two preceding sentences
as additional information. This might be enough to resolve some ambiguous
inputs, but it is probably not sufficient to capture some document-level
information like the topic or style of a conversation. When increasing the
context size beyond just the local context, there are two challenges: (i)
the~memory usage increases exponentially (ii) the translation performance
starts to degrade. We argue that the widely-used attention mechanism is
responsible for both issues. Therefore, we propose a constrained attention
variant that focuses the attention on the most relevant parts of the sequence,
while simultaneously reducing the memory consumption. For evaluation, we
utilize targeted test sets in combination with novel evaluation techniques to
analyze the translations in regards to specific discourse-related phenomena. We
find that our approach is a good compromise between sentence-level NMT vs
attending to the full context, especially in low resource scenarios.
\\ ( https://arxiv.org/abs/2306.05183 ,  6900kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05240 (*cross-listing*)
Date: Thu, 8 Jun 2023 14:39:24 GMT   (419kb,D)

Title: Dealing with Semantic Underspecification in Multimodal NLP
Authors: Sandro Pezzelle
Categories: cs.CL cs.AI cs.CV
Comments: To appear in the Proceedings of ACL 2023 (main conference). 13 pages,
 3 figures
\\
 Intelligent systems that aim at mastering language as humans do must deal
with its semantic underspecification, namely, the possibility for a linguistic
signal to convey only part of the information needed for communication to
succeed. Consider the usages of the pronoun they, which can leave the gender
and number of its referent(s) underspecified. Semantic underspecification is
not a bug but a crucial language feature that boosts its storage and processing
efficiency. Indeed, human speakers can quickly and effortlessly integrate
semantically-underspecified linguistic signals with a wide range of
non-linguistic information, e.g., the multimodal context, social or cultural
conventions, and shared knowledge. Standard NLP models have, in principle, no
or limited access to such extra information, while multimodal systems grounding
language into other modalities, such as vision, are naturally equipped to
account for this phenomenon. However, we show that they struggle with it, which
could negatively affect their performance and lead to harmful consequences when
used for applications. In this position paper, we argue that our community
should be aware of semantic underspecification if it aims to develop language
technology that can successfully interact with human users. We discuss some
applications where mastering it is crucial and outline a few directions toward
achieving this goal.
\\ ( https://arxiv.org/abs/2306.05240 ,  419kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05276 (*cross-listing*)
Date: Thu, 8 Jun 2023 15:25:24 GMT   (1269kb,D)

Title: Extensive Evaluation of Transformer-based Architectures for Adverse Drug
 Events Extraction
Authors: Simone Scaboro, Beatrice Portellia, Emmanuele Chersoni, Enrico Santus,
 Giuseppe Serra
Categories: cs.CL cs.AI
\\
 Adverse Event (ADE) extraction is one of the core tasks in digital
pharmacovigilance, especially when applied to informal texts. This task has
been addressed by the Natural Language Processing community using large
pre-trained language models, such as BERT. Despite the great number of
Transformer-based architectures used in the literature, it is unclear which of
them has better performances and why. Therefore, in this paper we perform an
extensive evaluation and analysis of 19 Transformer-based models for ADE
extraction on informal texts. We compare the performance of all the considered
models on two datasets with increasing levels of informality (forums posts and
tweets). We also combine the purely Transformer-based models with two
commonly-used additional processing layers (CRF and LSTM), and analyze their
effect on the models performance. Furthermore, we use a well-established
feature importance technique (SHAP) to correlate the performance of the models
with a set of features that describe them: model category (AutoEncoding,
AutoRegressive, Text-to-Text), pretraining domain, training from scratch, and
model size in number of parameters. At the end of our analyses, we identify a
list of take-home messages that can be derived from the experimental data.
\\ ( https://arxiv.org/abs/2306.05276 ,  1269kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05281 (*cross-listing*)
Date: Tue, 30 May 2023 12:24:41 GMT   (6451kb,D)

Title: Fault Identification of Rotating Machinery Based on Dynamic Feature
 Reconstruction Signal Graph
Authors: Wenbin He, Jianxu Mao, Zhe Li, Yaonan Wang, Qiu Fang, Haotian Wu
Categories: eess.SP cs.AI cs.RO
\\
 To improve the performance in identifying the faults under strong noise for
rotating machinery, this paper presents a dynamic feature reconstruction signal
graph method, which plays the key role of the proposed end-to-end fault
diagnosis model. Specifically, the original mechanical signal is first
decomposed by wavelet packet decomposition (WPD) to obtain multiple subbands
including coefficient matrix. Then, with originally defined two feature
extraction factors MDD and DDD, a dynamic feature selection method based on L2
energy norm (DFSL) is proposed, which can dynamically select the feature
coefficient matrix of WPD based on the difference in the distribution of norm
energy, enabling each sub-signal to take adaptive signal reconstruction. Next
the coefficient matrices of the optimal feature sub-bands are reconstructed and
reorganized to obtain the feature signal graphs. Finally, deep features are
extracted from the feature signal graphs by 2D-Convolutional neural network
(2D-CNN). Experimental results on a public data platform of a bearing and our
laboratory platform of robot grinding show that this method is better than the
existing methods under different noise intensities.
\\ ( https://arxiv.org/abs/2306.05281 ,  6451kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05284 (*cross-listing*)
Date: Thu, 8 Jun 2023 15:31:05 GMT   (269kb,D)

Title: Simple and Controllable Music Generation
Authors: Jade Copet, Felix Kreuk, Itai Gat, Tal Remez, David Kant, Gabriel
 Synnaeve, Yossi Adi, Alexandre D\'efossez
Categories: cs.SD cs.AI cs.LG eess.AS
\\
 We tackle the task of conditional music generation. We introduce MusicGen, a
single Language Model (LM) that operates over several streams of compressed
discrete music representation, i.e., tokens. Unlike prior work, MusicGen is
comprised of a single-stage transformer LM together with efficient token
interleaving patterns, which eliminates the need for cascading several models,
e.g., hierarchically or upsampling. Following this approach, we demonstrate how
MusicGen can generate high-quality samples, while being conditioned on textual
description or melodic features, allowing better controls over the generated
output. We conduct extensive empirical evaluation, considering both automatic
and human studies, showing the proposed approach is superior to the evaluated
baselines on a standard text-to-music benchmark. Through ablation studies, we
shed light over the importance of each of the components comprising MusicGen.
Music samples, code, and models are available at
https://github.com/facebookresearch/audiocraft.
\\ ( https://arxiv.org/abs/2306.05284 ,  269kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05291 (*cross-listing*)
Date: Wed, 31 May 2023 14:52:42 GMT   (2281kb)

Title: One shot learning based drivers head movement identification using a
 millimetre wave radar sensor
Authors: Hong Nhung Nguyen, Seongwook Lee, Tien Tung Nguyen, Yong Hwa Kim
Categories: eess.SP cs.AI cs.LG
\\
 Concentration of drivers on traffic is a vital safety issue; thus, monitoring
a driver being on road becomes an essential requirement. The key purpose of
supervision is to detect abnormal behaviours of the driver and promptly send
warnings to him her for avoiding incidents related to traffic accidents. In
this paper, to meet the requirement, based on radar sensors applications, the
authors first use a small sized millimetre wave radar installed at the steering
wheel of the vehicle to collect signals from different head movements of the
driver. The received signals consist of the reflection patterns that change in
response to the head movements of the driver. Then, in order to distinguish
these different movements, a classifier based on the measured signal of the
radar sensor is designed. However, since the collected data set is not large,
in this paper, the authors propose One shot learning to classify four cases of
driver's head movements. The experimental results indicate that the proposed
method can classify the four types of cases according to the various head
movements of the driver with a high accuracy reaching up to 100. In addition,
the classification performance of the proposed method is significantly better
than that of the convolutional neural network model.
\\ ( https://arxiv.org/abs/2306.05291 ,  2281kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05323 (*cross-listing*)
Date: Thu, 8 Jun 2023 16:15:46 GMT   (587kb)

Title: Advancing Italian Biomedical Information Extraction with Large Language
 Models: Methodological Insights and Multicenter Practical Application
Authors: Claudio Crema, Tommaso Mario Buonocore, Silvia Fostinelli, Enea
 Parimbelli, Federico Verde, Cira Fundar\`o, Marina Manera, Matteo Cotta
 Ramusino, Marco Capelli, Alfredo Costa, Giuliano Binetti, Riccardo Bellazzi
 and Alberto Redolfi
Categories: cs.CL cs.AI cs.LG
ACM-class: I.2.7; J.3
\\
 The introduction of computerized medical records in hospitals has reduced
burdensome operations like manual writing and information fetching. However,
the data contained in medical records are still far underutilized, primarily
because extracting them from unstructured textual medical records takes time
and effort. Information Extraction, a subfield of Natural Language Processing,
can help clinical practitioners overcome this limitation, using automated
text-mining pipelines. In this work, we created the first Italian
neuropsychiatric Named Entity Recognition dataset, PsyNIT, and used it to
develop a Large Language Model for this task. Moreover, we conducted several
experiments with three external independent datasets to implement an effective
multicenter model, with overall F1-score 84.77%, Precision 83.16%, Recall
86.44%. The lessons learned are: (i) the crucial role of a consistent
annotation process and (ii) a fine-tuning strategy that combines classical
methods with a "few-shot" approach. This allowed us to establish methodological
guidelines that pave the way for future implementations in this field and allow
Italian hospitals to tap into important research opportunities.
\\ ( https://arxiv.org/abs/2306.05323 ,  587kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05358 (*cross-listing*)
Date: Tue, 30 May 2023 00:57:51 GMT   (1968kb,D)

Title: Trustworthy Sensor Fusion against Inaudible Command Attacks in Advanced
 Driver-Assistance System
Authors: Jiwei Guan, Lei Pan, Chen Wang, Shui Yu, Longxiang Gao, Xi Zheng
Categories: cs.CR cs.AI cs.LG cs.SD eess.AS
\\
 There are increasing concerns about malicious attacks on autonomous vehicles.
In particular, inaudible voice command attacks pose a significant threat as
voice commands become available in autonomous driving systems. How to
empirically defend against these inaudible attacks remains an open question.
Previous research investigates utilizing deep learning-based multimodal fusion
for defense, without considering the model uncertainty in trustworthiness. As
deep learning has been applied to increasingly sensitive tasks, uncertainty
measurement is crucial in helping improve model robustness, especially in
mission-critical scenarios. In this paper, we propose the Multimodal Fusion
Framework (MFF) as an intelligent security system to defend against inaudible
voice command attacks. MFF fuses heterogeneous audio-vision modalities using
VGG family neural networks and achieves the detection accuracy of 92.25% in the
comparative fusion method empirical study. Additionally, extensive experiments
on audio-vision tasks reveal the model's uncertainty. Using Expected
Calibration Errors, we measure calibration errors and Monte-Carlo Dropout to
estimate the predictive distribution for the proposed models. Our findings show
empirically to train robust multimodal models, improve standard accuracy and
provide a further step toward interpretability. Finally, we discuss the pros
and cons of our approach and its applicability for Advanced Driver Assistance
Systems.
\\ ( https://arxiv.org/abs/2306.05358 ,  1968kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05360 (*cross-listing*)
Date: Thu, 8 Jun 2023 17:05:38 GMT   (7163kb,D)

Title: The ADAIO System at the BEA-2023 Shared Task on Generating AI Teacher
 Responses in Educational Dialogues
Authors: Adaeze Adigwe (1), Zheng Yuan (2 and 3)((1) University of Edinburgh,
 United Kingdom, (2) Istituto Italiano di Tecnologia, Italy, (3) Universit\`a
 di Ferrara, Italy)
Categories: cs.CL cs.AI cs.CY
Comments: Accepted in the BEA workshop at ACL 2023
\\
 This paper presents the ADAIO team's system entry in the Building Educational
Applications (BEA) 2023 Shared Task on Generating AI Teacher Responses in
Educational Dialogues. The task aims to assess the performance of
state-of-the-art generative models as AI teachers in producing suitable
responses within a student-teacher dialogue. Our system comprises evaluating
various baseline models using OpenAI GPT-3 and designing diverse prompts to
prompt the OpenAI models for teacher response generation. After the challenge,
our system achieved second place by employing a few-shot prompt-based approach
with the OpenAI text-davinci-003 model. The results highlight the few-shot
learning capabilities of large-language models, particularly OpenAI's GPT-3, in
the role of AI teachers.
\\ ( https://arxiv.org/abs/2306.05360 ,  7163kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04642 (*cross-listing*)
Date: Thu, 25 May 2023 11:59:28 GMT   (20938kb,D)

Title: DiffusionShield: A Watermark for Copyright Protection against Generative
 Diffusion Models
Authors: Yingqian Cui, Jie Ren, Han Xu, Pengfei He, Hui Liu, Lichao Sun,
 Jiliang Tang
Categories: cs.CR cs.CV cs.LG
\\
 Recently, Generative Diffusion Models (GDMs) have showcased their remarkable
capabilities in learning and generating images. A large community of GDMs has
naturally emerged, further promoting the diversified applications of GDMs in
various fields. However, this unrestricted proliferation has raised serious
concerns about copyright protection. For example, artists including painters
and photographers are becoming increasingly concerned that GDMs could
effortlessly replicate their unique creative works without authorization. In
response to these challenges, we introduce a novel watermarking scheme,
DiffusionShield, tailored for GDMs. DiffusionShield protects images from
copyright infringement by GDMs through encoding the ownership information into
an imperceptible watermark and injecting it into the images. Its watermark can
be easily learned by GDMs and will be reproduced in their generated images. By
detecting the watermark from generated images, copyright infringement can be
exposed with evidence. Benefiting from the uniformity of the watermarks and the
joint optimization method, DiffusionShield ensures low distortion of the
original image, high watermark detection performance, and the ability to embed
lengthy messages. We conduct rigorous and comprehensive experiments to show the
effectiveness of DiffusionShield in defending against infringement by GDMs and
its superiority over traditional watermarking methods.
\\ ( https://arxiv.org/abs/2306.04642 ,  20938kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04664 (*cross-listing*)
Date: Wed, 7 Jun 2023 10:04:16 GMT   (11881kb,D)

Title: Estimating Uncertainty in PET Image Reconstruction via Deep Posterior
 Sampling
Authors: Tin Vla\v{s}i\'c, Tomislav Matuli\'c and Damir Ser\v{s}i\'c
Categories: eess.IV cs.CV cs.LG
Comments: 20 pages, 9 figures, accepted for publication at MIDL 2023
\\
 Positron emission tomography (PET) is an important functional medical imaging
technique often used in the evaluation of certain brain disorders, whose
reconstruction problem is ill-posed. The vast majority of reconstruction
methods in PET imaging, both iterative and deep learning, return a single
estimate without quantifying the associated uncertainty. Due to ill-posedness
and noise, a single solution can be misleading or inaccurate. Thus, providing a
measure of uncertainty in PET image reconstruction can help medical
practitioners in making critical decisions. This paper proposes a deep
learning-based method for uncertainty quantification in PET image
reconstruction via posterior sampling. The method is based on training a
conditional generative adversarial network whose generator approximates
sampling from the posterior in Bayesian inversion. The generator is conditioned
on reconstruction from a low-dose PET scan obtained by a conventional
reconstruction method and a high-quality magnetic resonance image and learned
to estimate a corresponding standard-dose PET scan reconstruction. We show that
the proposed model generates high-quality posterior samples and yields
physically-meaningful uncertainty estimates.
\\ ( https://arxiv.org/abs/2306.04664 ,  11881kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04668 (*cross-listing*)
Date: Wed, 7 Jun 2023 14:53:02 GMT   (5475kb,D)

Title: SMRVIS: Point cloud extraction from 3-D ultrasound for non-destructive
 testing
Authors: Lisa Y.W. Tang
Categories: eess.IV cs.CV cs.LG
\\
 We propose to formulate point cloud extraction from ultrasound volumes as an
image segmentation problem. Through this convenient formulation, a quick
prototype exploring various variants of the U-Net architecture was developed
and evaluated. This report documents the experimental results compiled using a
training dataset of 5 labelled ultrasound volumes and 84 unlabelled volumes
that got completed in a two-week period as part of a challenge submission to an
open challenge entitled ``Deep Learning in Ultrasound Image Analysis''. Source
code is shared with the research community at this GitHub URL
\url{https://github.com/lisatwyw/smrvis}.
\\ ( https://arxiv.org/abs/2306.04668 ,  5475kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04754 (*cross-listing*)
Date: Wed, 7 Jun 2023 20:04:23 GMT   (914kb)

Title: Computational Modeling of Deep Multiresolution-Fractal Texture and Its
 Application to Abnormal Brain Tissue Segmentation
Authors: A. Temtam, L. Pei, and K. Iftekharuddin
Categories: eess.IV cs.CV cs.LG
\\
 Computational modeling of Multiresolution- Fractional Brownian motion (fBm)
has been effective in stochastic multiscale fractal texture feature extraction
and machine learning of abnormal brain tissue segmentation. Further, deep
multiresolution methods have been used for pixel-wise brain tissue
segmentation. Robust tissue segmentation and volumetric measurement may provide
more objective quantification of disease burden and offer improved tracking of
treatment response for the disease. However, we posit that computational
modeling of deep multiresolution fractal texture features may offer elegant
feature learning. Consequently, this work proposes novel modeling of
Multiresolution Fractal Deep Neural Network (MFDNN) and its computational
implementation that mathematically combines a multiresolution fBm model and
deep multiresolution analysis. The proposed full 3D MFDNN model offers the
desirable properties of estimating multiresolution stochastic texture features
by analyzing large amount of raw MRI image data for brain tumor segmentation.
We apply the proposed MFDNN to estimate stochastic deep multiresolution fractal
texture features for tumor tissues in brain MRI images. The MFDNN model is
evaluated using 1251 patient cases for brain tumor segmentation using the most
recent BRATS 2021 Challenges dataset. The evaluation of the proposed model
using Dice overlap score, Husdorff distance and associated uncertainty
estimation offers either better or comparable performances in abnormal brain
tissue segmentation when compared to the state-of-the-art methods in the
literature. Index Terms: Computational Modeling, Multiresolution Fractional
Brownian Motion (fBm), Deep Multiresolution Analysis, Fractal Dimension (FD),
Texture Features, Brain tumor segmentation, Deep Learning.
\\ ( https://arxiv.org/abs/2306.04754 ,  914kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04763 (*cross-listing*)
Date: Wed, 7 Jun 2023 20:23:05 GMT   (13249kb,D)

Title: Context-Aware Self-Supervised Learning of Whole Slide Images
Authors: Milan Aryal, Nasim Yahyasoltani
Categories: eess.IV cs.CV cs.LG
\\
 Presenting whole slide images (WSIs) as graph will enable a more efficient
and accurate learning framework for cancer diagnosis. Due to the fact that a
single WSI consists of billions of pixels and there is a lack of vast annotated
datasets required for computational pathology, the problem of learning from
WSIs using typical deep learning approaches such as convolutional neural
network (CNN) is challenging. Additionally, WSIs down-sampling may lead to the
loss of data that is essential for cancer detection. A novel two-stage learning
technique is presented in this work. Since context, such as topological
features in the tumor surroundings, may hold important information for cancer
grading and diagnosis, a graph representation capturing all dependencies among
regions in the WSI is very intuitive. Graph convolutional network (GCN) is
deployed to include context from the tumor and adjacent tissues, and
self-supervised learning is used to enhance training through unlabeled data.
More specifically, the entire slide is presented as a graph, where the nodes
correspond to the patches from the WSI. The proposed framework is then tested
using WSIs from prostate and kidney cancers. To assess the performance
improvement through self-supervised mechanism, the proposed context-aware model
is tested with and without use of pre-trained self-supervised layer. The
overall model is also compared with multi-instance learning (MIL) based and
other existing approaches.
\\ ( https://arxiv.org/abs/2306.04763 ,  13249kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04905 (*cross-listing*)
Date: Thu, 8 Jun 2023 03:17:00 GMT   (3330kb,D)

Title: ViG-UNet: Vision Graph Neural Networks for Medical Image Segmentation
Authors: Juntao Jiang, Xiyu Chen, Guanzhong Tian and Yong Liu
Categories: eess.IV cs.CV
Comments: Accepted at ISBI 2023. This version fixes some errors in the
 camera-ready version. We misused mIoU and mDice in the camera-ready version;
 however, it should be the IoU and Dice of the lesions, excluding the
 background. And some mistakes in citations and formulas are also fixed
\\
 Deep neural networks have been widely used in medical image analysis and
medical image segmentation is one of the most important tasks. U-shaped neural
networks with encoder-decoder are prevailing and have succeeded greatly in
various segmentation tasks. While CNNs treat an image as a grid of pixels in
Euclidean space and Transformers recognize an image as a sequence of patches,
graph-based representation is more generalized and can construct connections
for each part of an image. In this paper, we propose a novel ViG-UNet, a graph
neural network-based U-shaped architecture with the encoder, the decoder, the
bottleneck, and skip connections. The downsampling and upsampling modules are
also carefully designed. The experimental results on ISIC 2016, ISIC 2017 and
Kvasir-SEG datasets demonstrate that our proposed architecture outperforms most
existing classic and state-of-the-art U-shaped networks.
\\ ( https://arxiv.org/abs/2306.04905 ,  3330kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05012 (*cross-listing*)
Date: Thu, 8 Jun 2023 08:04:56 GMT   (396kb,D)

Title: Sequence-to-Sequence Model with Transformer-based Attention Mechanism
 and Temporal Pooling for Non-Intrusive Load Monitoring
Authors: Mohammad Irani Azad, Roozbeh Rajabi, Abouzar Estebsari
Categories: eess.SP cs.CV cs.LG
Comments: 5 pages, EEEIC 2023 conference
\\
 This paper presents a novel Sequence-to-Sequence (Seq2Seq) model based on a
transformer-based attention mechanism and temporal pooling for Non-Intrusive
Load Monitoring (NILM) of smart buildings. The paper aims to improve the
accuracy of NILM by using a deep learning-based method. The proposed method
uses a Seq2Seq model with a transformer-based attention mechanism to capture
the long-term dependencies of NILM data. Additionally, temporal pooling is used
to improve the model's accuracy by capturing both the steady-state and
transient behavior of appliances. The paper evaluates the proposed method on a
publicly available dataset and compares the results with other state-of-the-art
NILM techniques. The results demonstrate that the proposed method outperforms
the existing methods in terms of both accuracy and computational efficiency.
\\ ( https://arxiv.org/abs/2306.05012 ,  396kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05179 (*cross-listing*)
Date: Thu, 8 Jun 2023 13:21:29 GMT   (1442kb,D)

Title: M3Exam: A Multilingual, Multimodal, Multilevel Benchmark for Examining
 Large Language Models
Authors: Wenxuan Zhang, Sharifah Mahani Aljunied, Chang Gao, Yew Ken Chia,
 Lidong Bing
Categories: cs.CL cs.CV
\\
 Despite the existence of various benchmarks for evaluating natural language
processing models, we argue that human exams are a more suitable means of
evaluating general intelligence for large language models (LLMs), as they
inherently demand a much wider range of abilities such as language
understanding, domain knowledge, and problem-solving skills. To this end, we
introduce M3Exam, a novel benchmark sourced from real and official human exam
questions for evaluating LLMs in a multilingual, multimodal, and multilevel
context. M3Exam exhibits three unique characteristics: (1) multilingualism,
encompassing questions from multiple countries that require strong multilingual
proficiency and cultural knowledge; (2) multimodality, accounting for the
multimodal nature of many exam questions to test the model's multimodal
understanding capability; and (3) multilevel structure, featuring exams from
three critical educational periods to comprehensively assess a model's
proficiency at different levels. In total, M3Exam contains 12,317 questions in
9 diverse languages with three educational levels, where about 23\% of the
questions require processing images for successful solving. We assess the
performance of top-performing LLMs on M3Exam and find that current models,
including GPT-4, still struggle with multilingual text, particularly in
low-resource and non-Latin script languages. Multimodal LLMs also perform
poorly with complex multimodal questions. We believe that M3Exam can be a
valuable resource for comprehensively evaluating LLMs by examining their
multilingual and multimodal abilities and tracking their development. Data and
evaluation code is available at \url{https://github.com/DAMO-NLP-SG/M3Exam}.
\\ ( https://arxiv.org/abs/2306.05179 ,  1442kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05196 (*cross-listing*)
Date: Thu, 8 Jun 2023 13:52:41 GMT   (4809kb,D)

Title: Channel prior convolutional attention for medical image segmentation
Authors: Hejun Huang, Zuguo Chen, Ying Zou, Ming Lu, Chaoyang Chen
Categories: eess.IV cs.CV
\\
 Characteristics such as low contrast and significant organ shape variations
are often exhibited in medical images. The improvement of segmentation
performance in medical imaging is limited by the generally insufficient
adaptive capabilities of existing attention mechanisms. An efficient Channel
Prior Convolutional Attention (CPCA) method is proposed in this paper,
supporting the dynamic distribution of attention weights in both channel and
spatial dimensions. Spatial relationships are effectively extracted while
preserving the channel prior by employing a multi-scale depth-wise
convolutional module. The ability to focus on informative channels and
important regions is possessed by CPCA. A segmentation network called CPCANet
for medical image segmentation is proposed based on CPCA. CPCANet is validated
on two publicly available datasets. Improved segmentation performance is
achieved by CPCANet while requiring fewer computational resources through
comparisons with state-of-the-art algorithms. Our code is publicly available at
\url{https://github.com/Cuthbert-Huang/CPCANet}.
\\ ( https://arxiv.org/abs/2306.05196 ,  4809kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05208 (*cross-listing*)
Date: Thu, 8 Jun 2023 14:05:06 GMT   (805kb,D)

Title: PriSampler: Mitigating Property Inference of Diffusion Models
Authors: Hailong Hu, Jun Pang
Categories: cs.CR cs.CV cs.LG
\\
 Diffusion models have been remarkably successful in data synthesis. Such
successes have also driven diffusion models to apply to sensitive data, such as
human face data, but this might bring about severe privacy concerns. In this
work, we systematically present the first privacy study about property
inference attacks against diffusion models, in which adversaries aim to extract
sensitive global properties of the training set from a diffusion model, such as
the proportion of the training data for certain sensitive properties.
Specifically, we consider the most practical attack scenario: adversaries are
only allowed to obtain synthetic data. Under this realistic scenario, we
evaluate the property inference attacks on different types of samplers and
diffusion models. A broad range of evaluations shows that various diffusion
models and their samplers are all vulnerable to property inference attacks.
Furthermore, one case study on off-the-shelf pre-trained diffusion models also
demonstrates the effectiveness of the attack in practice. Finally, we propose a
new model-agnostic plug-in method PriSampler to mitigate the property inference
of diffusion models. PriSampler can be directly applied to well-trained
diffusion models and support both stochastic and deterministic sampling.
Extensive experiments illustrate the effectiveness of our defense and it makes
adversaries infer the proportion of properties as close as random guesses.
PriSampler also shows its significantly superior performance to diffusion
models trained with differential privacy on both model utility and defense
performance.
\\ ( https://arxiv.org/abs/2306.05208 ,  805kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05233 (*cross-listing*)
Date: Thu, 8 Jun 2023 14:31:58 GMT   (461kb,D)

Title: Ownership Protection of Generative Adversarial Networks
Authors: Hailong Hu, Jun Pang
Categories: cs.CR cs.CV cs.LG
\\
 Generative adversarial networks (GANs) have shown remarkable success in image
synthesis, making GAN models themselves commercially valuable to legitimate
model owners. Therefore, it is critical to technically protect the intellectual
property of GANs. Prior works need to tamper with the training set or training
process, and they are not robust to emerging model extraction attacks. In this
paper, we propose a new ownership protection method based on the common
characteristics of a target model and its stolen models. Our method can be
directly applicable to all well-trained GANs as it does not require retraining
target models. Extensive experimental results show that our new method can
achieve the best protection performance, compared to the state-of-the-art
methods. Finally, we demonstrate the effectiveness of our method with respect
to the number of generations of model extraction attacks, the number of
generated samples, different datasets, as well as adaptive attacks.
\\ ( https://arxiv.org/abs/2306.05233 ,  461kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05297 (*cross-listing*)
Date: Thu, 8 Jun 2023 15:39:27 GMT   (19075kb)

Title: Connectional-Style-Guided Contextual Representation Learning for Brain
 Disease Diagnosis
Authors: Gongshu Wang, Ning Jiang, Yunxiao Ma, Tiantian Liu, Duanduan Chen,
 Jinglong Wu, Guoqi Li, Dong Liang, Tianyi Yan
Categories: eess.IV cs.CV
\\
 Structural magnetic resonance imaging (sMRI) has shown great clinical value
and has been widely used in deep learning (DL) based computer-aided brain
disease diagnosis. Previous approaches focused on local shapes and textures in
sMRI that may be significant only within a particular domain. The learned
representations are likely to contain spurious information and have a poor
generalization ability in other diseases and datasets. To facilitate capturing
meaningful and robust features, it is necessary to first comprehensively
understand the intrinsic pattern of the brain that is not restricted within a
single data/task domain. Considering that the brain is a complex connectome of
interlinked neurons, the connectional properties in the brain have strong
biological significance, which is shared across multiple domains and covers
most pathological information. In this work, we propose a connectional style
contextual representation learning model (CS-CRL) to capture the intrinsic
pattern of the brain, used for multiple brain disease diagnosis. Specifically,
it has a vision transformer (ViT) encoder and leverages mask reconstruction as
the proxy task and Gram matrices to guide the representation of connectional
information. It facilitates the capture of global context and the aggregation
of features with biological plausibility. The results indicate that CS-CRL
achieves superior accuracy in multiple brain disease diagnosis tasks across six
datasets and three diseases and outperforms state-of-the-art models.
Furthermore, we demonstrate that CS-CRL captures more brain-network-like
properties, better aggregates features, is easier to optimize and is more
robust to noise, which explains its superiority in theory. Our source code will
be released soon.
\\ ( https://arxiv.org/abs/2306.05297 ,  19075kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04769 (*cross-listing*)
Date: Wed, 7 Jun 2023 20:33:56 GMT   (2289kb,D)

Title: Achieving Consensus over Compact Submanifolds
Authors: Jiang Hu, Jiaojiao Zhang, Kangkang Deng
Categories: math.OC cs.DC
Comments: 25 pages
\\
 We consider the consensus problem in a decentralized network, focusing on a
compact submanifold that acts as a nonconvex constraint set. By leveraging the
proximal smoothness of the compact submanifold, which encompasses the local
singleton property and the local Lipschitz continuity of the projection
operator on the manifold, and establishing the connection between the
projection operator and general retraction, we show that the Riemannian
gradient descent with a unit step size has locally linear convergence if the
network has a satisfactory level of connectivity. Moreover, based on the
geometry of the compact submanifold, we prove that a convexity-like regularity
condition, referred to as the restricted secant inequality, always holds in an
explicitly characterized neighborhood around the solution set of the nonconvex
consensus problem. By leveraging this restricted secant inequality and imposing
a weaker connectivity requirement on the decentralized network, we present a
comprehensive analysis of the linear convergence of the Riemannian gradient
descent, taking into consideration appropriate initialization and step size.
Furthermore, if the network is well connected, we demonstrate that the local
Lipschitz continuity endowed by proximal smoothness is a sufficient condition
for the restricted secant inequality, thus contributing to the local error
bound. We believe that our established results will find more application in
the consensus problems over a more general proximally smooth set. Numerical
experiments are conducted to validate our theoretical findings.
\\ ( https://arxiv.org/abs/2306.04769 ,  2289kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05359 (*cross-listing*)
Date: Sat, 20 May 2023 16:59:01 GMT   (606kb,D)

Title: Safeguarding Physical Sneaker Sale Through a Decentralized Medium
Authors: Marwan Zeggari and Aydin Abadi and Renaud Lambiotte and Mohamad Kassab
Categories: cs.CR cs.GT
Comments: 27 pages, 6 figures, 7 tables
\\
 Sneakers were designated as the most counterfeited fashion item online, with
three times more risk in a trade than any other fashion purchase. As the market
expands, the current sneaker scene displays several vulnerabilities and trust
flaws, mostly related to the legitimacy of assets or actors. In this paper, we
investigate various blockchain-based mechanisms to address these large-scale
trust issues. We argue that (i) pre-certified and tracked assets through the
use of non-fungible tokens can ensure the genuine nature of an asset and
authenticate its owner more effectively during peer-to-peer trading across a
marketplace; (ii) a game-theoretic-based system with economic incentives for
participating users can greatly reduce the rate of online fraud and address
missed delivery deadlines; (iii) a decentralized dispute resolution system
biased in favour of an honest party can solve potential conflicts more
reliably.
\\ ( https://arxiv.org/abs/2306.05359 ,  606kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04647 (*cross-listing*)
Date: Mon, 5 Jun 2023 01:29:24 GMT   (536kb,D)

Title: Compressed Sensing: A Discrete Optimization Approach
Authors: Dimitris Bertsimas and Nicholas Johnson
Categories: eess.SP cs.LG stat.ML
\\
 We study the Compressed Sensing (CS) problem, which is the problem of finding
the most sparse vector that satisfies a set of linear measurements up to some
numerical tolerance. CS is a central problem in Statistics, Operations Research
and Machine Learning which arises in applications such as signal processing,
data compression and image reconstruction. We introduce an $\ell_2$ regularized
formulation of CS which we reformulate as a mixed integer second order cone
program. We derive a second order cone relaxation of this problem and show that
under mild conditions on the regularization parameter, the resulting relaxation
is equivalent to the well studied basis pursuit denoising problem. We present a
semidefinite relaxation that strengthens the second order cone relaxation and
develop a custom branch-and-bound algorithm that leverages our second order
cone relaxation to solve instances of CS to certifiable optimality. Our
numerical results show that our approach produces solutions that are on average
$6.22\%$ more sparse than solutions returned by state of the art benchmark
methods on synthetic data in minutes. On real world ECG data, for a given
$\ell_2$ reconstruction error our approach produces solutions that are on
average $9.95\%$ more sparse than benchmark methods, while for a given sparsity
level our approach produces solutions that have on average $10.77\%$ lower
reconstruction error than benchmark methods in minutes.
\\ ( https://arxiv.org/abs/2306.04647 ,  536kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04655 (*cross-listing*)
Date: Tue, 6 Jun 2023 16:14:15 GMT   (1060kb)

Title: Modulation Classification Through Deep Learning Using Resolution
 Transformed Spectrograms
Authors: Muhammad Waqas, Muhammad Ashraf, Muhammad Zakwan
Categories: eess.SP cs.LG cs.SD eess.AS
Comments: 15 pages, 12 figures
\\
 Modulation classification is an essential step of signal processing and has
been regularly applied in the field of tele-communication. Since variations of
frequency with respect to time remains a vital distinction among radio signals
having different modulation formats, these variations can be used for feature
extraction by converting 1-D radio signals into frequency domain. In this
paper, we propose a scheme for Automatic Modulation Classification (AMC) using
modern architectures of Convolutional Neural Networks (CNN), through generating
spectrum images of eleven different modulation types. Additionally, we perform
resolution transformation of spectrograms that results up to 99.61% of
computational load reduction and 8x faster conversion from the received I/Q
data. This proposed AMC is implemented on CPU and GPU, to recognize digital as
well as analogue signal modulation schemes on signals. The performance is
evaluated on existing CNN models including SqueezeNet, Resnet-50,
InceptionResnet-V2, Inception-V3, VGG-16 and Densenet-201. Best results of
91.2% are achieved in presence of AWGN and other noise impairments in the
signals, stating that the transformed spectrogram-based AMC has good
classification accuracy as the spectral features are highly discriminant, and
CNN based models have capability to extract these high-dimensional features.
The spectrograms were created under different SNRs ranging from 5 to 30db with
a step size of 5db to observe the experimental results at various SNR levels.
The proposed methodology is efficient to be applied in wireless communication
networks for real-time applications.
\\ ( https://arxiv.org/abs/2306.04655 ,  1060kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04658 (*cross-listing*)
Date: Tue, 6 Jun 2023 19:27:11 GMT   (273kb,D)

Title: Mathematics-assisted directed evolution and protein engineering
Authors: Yuchi Qiu, Guo-Wei Wei
Categories: q-bio.BM cs.LG
\\
 Directed evolution is a molecular biology technique that is transforming
protein engineering by creating proteins with desirable properties and
functions. However, it is experimentally impossible to perform the deep
mutational scanning of the entire protein library due to the enormous
mutational space, which scales as $20^N$ , where N is the number of amino
acids. This has led to the rapid growth of AI-assisted directed evolution
(AIDE) or AI-assisted protein engineering (AIPE) as an emerging research field.
Aided with advanced natural language processing (NLP) techniques, including
long short-term memory, autoencoder, and transformer, sequence-based embeddings
have been dominant approaches in AIDE and AIPE. Persistent Laplacians, an
emerging technique in topological data analysis (TDA), have made
structure-based embeddings a superb option in AIDE and AIPE. We argue that a
class of persistent topological Laplacians (PTLs), including persistent
Laplacians, persistent path Laplacians, persistent sheaf Laplacians, persistent
hypergraph Laplacians, persistent hyperdigraph Laplacians, and evolutionary de
Rham-Hodge theory, can effectively overcome the limitations of the current TDA
and offer a new generation of more powerful TDA approaches. In the general
framework of topological deep learning, mathematics-assisted directed evolution
(MADE) has a great potential for future protein engineering.
\\ ( https://arxiv.org/abs/2306.04658 ,  273kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04663 (*cross-listing*)
Date: Wed, 7 Jun 2023 08:27:36 GMT   (4860kb)

Title: U-PASS: an Uncertainty-guided deep learning Pipeline for Automated Sleep
 Staging
Authors: Elisabeth R. M. Heremans, Nabeel Seedat, Bertien Buyse, Dries
 Testelmans, Mihaela van der Schaar, Maarten De Vos
Categories: eess.SP cs.LG
\\
 As machine learning becomes increasingly prevalent in critical fields such as
healthcare, ensuring the safety and reliability of machine learning systems
becomes paramount. A key component of reliability is the ability to estimate
uncertainty, which enables the identification of areas of high and low
confidence and helps to minimize the risk of error. In this study, we propose a
machine learning pipeline called U-PASS tailored for clinical applications that
incorporates uncertainty estimation at every stage of the process, including
data acquisition, training, and model deployment. The training process is
divided into a supervised pre-training step and a semi-supervised finetuning
step. We apply our uncertainty-guided deep learning pipeline to the challenging
problem of sleep staging and demonstrate that it systematically improves
performance at every stage. By optimizing the training dataset, actively
seeking informative samples, and deferring the most uncertain samples to an
expert, we achieve an expert-level accuracy of 85% on a challenging clinical
dataset of elderly sleep apnea patients, representing a significant improvement
over the baseline accuracy of 75%. U-PASS represents a promising approach to
incorporating uncertainty estimation into machine learning pipelines, thereby
improving their reliability and unlocking their potential in clinical settings.
\\ ( https://arxiv.org/abs/2306.04663 ,  4860kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04667 (*cross-listing*)
Date: Wed, 7 Jun 2023 14:50:34 GMT   (4605kb,D)

Title: Neural Embeddings for Protein Graphs
Authors: Francesco Ceccarelli, Lorenzo Giusti, Sean B. Holden, Pietro Li\`o
Categories: q-bio.QM cs.LG
Comments: 10 pages, 5 figures
\\
 Proteins perform much of the work in living organisms, and consequently the
development of efficient computational methods for protein representation is
essential for advancing large-scale biological research. Most current
approaches struggle to efficiently integrate the wealth of information
contained in the protein sequence and structure. In this paper, we propose a
novel framework for embedding protein graphs in geometric vector spaces, by
learning an encoder function that preserves the structural distance between
protein graphs. Utilizing Graph Neural Networks (GNNs) and Large Language
Models (LLMs), the proposed framework generates structure- and sequence-aware
protein representations. We demonstrate that our embeddings are successful in
the task of comparing protein structures, while providing a significant
speed-up compared to traditional approaches based on structural alignment. Our
framework achieves remarkable results in the task of protein structure
classification; in particular, when compared to other work, the proposed method
shows an average F1-Score improvement of 26% on out-of-distribution (OOD)
samples and of 32% when tested on samples coming from the same distribution as
the training data. Our approach finds applications in areas such as drug
prioritization, drug re-purposing, disease sub-type analysis and elsewhere.
\\ ( https://arxiv.org/abs/2306.04667 ,  4605kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04689 (*cross-listing*)
Date: Wed, 7 Jun 2023 18:00:06 GMT   (5513kb,D)

Title: Multiscale Flow for Robust and Optimal Cosmological Analysis
Authors: Biwei Dai and Uros Seljak
Categories: astro-ph.CO cs.LG physics.data-an
Comments: 12 pages, 7 figures. Comments welcome
\\
 We propose Multiscale Flow, a generative Normalizing Flow that creates
samples and models the field-level likelihood of two-dimensional cosmological
data such as weak lensing. Multiscale Flow uses hierarchical decomposition of
cosmological fields via a wavelet basis, and then models different wavelet
components separately as Normalizing Flows. The log-likelihood of the original
cosmological field can be recovered by summing over the log-likelihood of each
wavelet term. This decomposition allows us to separate the information from
different scales and identify distribution shifts in the data such as unknown
scale-dependent systematics. The resulting likelihood analysis can not only
identify these types of systematics, but can also be made optimal, in the sense
that the Multiscale Flow can learn the full likelihood at the field without any
dimensionality reduction. We apply Multiscale Flow to weak lensing mock
datasets for cosmological inference, and show that it significantly outperforms
traditional summary statistics such as power spectrum and peak counts, as well
as novel Machine Learning based summary statistics such as scattering transform
and convolutional neural networks. We further show that Multiscale Flow is able
to identify distribution shifts not in the training data such as baryonic
effects. Finally, we demonstrate that Multiscale Flow can be used to generate
realistic samples of weak lensing data.
\\ ( https://arxiv.org/abs/2306.04689 ,  5513kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04712 (*cross-listing*)
Date: Wed, 7 Jun 2023 18:23:38 GMT   (7328kb,D)

Title: Differentiable Earth Mover's Distance for Data Compression at the
 High-Luminosity LHC
Authors: Rohan Shenoy and Javier Duarte and Christian Herwig and James
 Hirschauer and Daniel Noonan and Maurizio Pierini and Nhan Tran and Cristina
 Mantilla Suarez
Categories: hep-ex cs.LG physics.ins-det
Comments: 15 pages, 7 figures, submitted to Machine Learning: Science and
 Technology
Report-no: FERMILAB-PUB-23-288-CMS-CSAID
\\
 The Earth mover's distance (EMD) is a useful metric for image recognition and
classification, but its usual implementations are not differentiable or too
slow to be used as a loss function for training other algorithms via gradient
descent. In this paper, we train a convolutional neural network (CNN) to learn
a differentiable, fast approximation of the EMD and demonstrate that it can be
used as a substitute for computing-intensive EMD implementations. We apply this
differentiable approximation in the training of an autoencoder-inspired neural
network (encoder NN) for data compression at the high-luminosity LHC at CERN.
The goal of this encoder NN is to compress the data while preserving the
information related to the distribution of energy deposits in particle
detectors. We demonstrate that the performance of our encoder NN trained using
the differentiable EMD CNN surpasses that of training with loss functions based
on mean squared error.
\\ ( https://arxiv.org/abs/2306.04712 ,  7328kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04730 (*cross-listing*)
Date: Wed, 7 Jun 2023 18:49:19 GMT   (579kb,D)

Title: Stochastic Natural Thresholding Algorithms
Authors: Rachel Grotheer, Shuang Li, Anna Ma, Deanna Needell, and Jing Qin
Categories: eess.SP cs.LG cs.NA math.NA math.OC stat.ML
\\
 Sparse signal recovery is one of the most fundamental problems in various
applications, including medical imaging and remote sensing. Many greedy
algorithms based on the family of hard thresholding operators have been
developed to solve the sparse signal recovery problem. More recently, Natural
Thresholding (NT) has been proposed with improved computational efficiency.
This paper proposes and discusses convergence guarantees for stochastic natural
thresholding algorithms by extending the NT from the deterministic version with
linear measurements to the stochastic version with a general objective
function. We also conduct various numerical experiments on linear and nonlinear
measurements to demonstrate the performance of StoNT.
\\ ( https://arxiv.org/abs/2306.04730 ,  579kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04746 (*cross-listing*)
Date: Wed, 7 Jun 2023 19:49:41 GMT   (151kb,D)

Title: Using Large Language Model Annotations for Valid Downstream Statistical
 Inference in Social Science: Design-Based Semi-Supervised Learning
Authors: Naoki Egami, Musashi Jacobs-Harukawa, Brandon M. Stewart, Hanying Wei
Categories: stat.ME cs.CL cs.LG stat.ML
\\
 In computational social science (CSS), researchers analyze documents to
explain social and political phenomena. In most scenarios, CSS researchers
first obtain labels for documents and then explain labels using interpretable
regression analyses in the second step. The recent advancements in large
language models (LLMs) can lower costs for CSS research by annotating documents
cheaply at scale, but such surrogate labels are often imperfect and biased. We
present a new algorithm for using outputs from LLMs for downstream statistical
analyses while guaranteeing statistical properties -- like asymptotic
unbiasedness and proper uncertainty quantification -- which are fundamental to
CSS research. We show that direct use of LLM-predicted surrogate labels in
downstream statistical analyses leads to substantial bias and invalid
confidence intervals, even with high surrogate accuracy of 80--90\%. To address
this, we build on debiased machine learning to propose the design-based
semi-supervised learning (DSL) estimator. DSL employs a doubly-robust procedure
to combine surrogate labels with a smaller number of gold-standard labels. Our
approach guarantees valid inference for downstream statistical analyses, even
when surrogates are arbitrarily biased, without requiring stringent
assumptions, by controlling the probability of sampling documents for
gold-standard labeling. Both our theoretical analysis and experimental results
show that DSL provides valid statistical inference while achieving root mean
squared errors comparable to existing alternatives that focus only on
prediction without statistical guarantees.
\\ ( https://arxiv.org/abs/2306.04746 ,  151kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04787 (*cross-listing*)
Date: Wed, 7 Jun 2023 21:18:23 GMT   (1305kb,D)

Title: Absformer: Transformer-based Model for Unsupervised Multi-Document
 Abstractive Summarization
Authors: Mohamed Trabelsi and Huseyin Uzunalioglu
Categories: cs.CL cs.LG
Comments: ICDAR 2023 International Workshop on Machine Learning (WML)
\\
 Multi-document summarization (MDS) refers to the task of summarizing the text
in multiple documents into a concise summary. The generated summary can save
the time of reading many documents by providing the important content in the
form of a few sentences. Abstractive MDS aims to generate a coherent and fluent
summary for multiple documents using natural language generation techniques. In
this paper, we consider the unsupervised abstractive MDS setting where there
are only documents with no groundtruh summaries provided, and we propose
Absformer, a new Transformer-based method for unsupervised abstractive summary
generation. Our method consists of a first step where we pretrain a
Transformer-based encoder using the masked language modeling (MLM) objective as
the pretraining task in order to cluster the documents into semantically
similar groups; and a second step where we train a Transformer-based decoder to
generate abstractive summaries for the clusters of documents. To our knowledge,
we are the first to successfully incorporate a Transformer-based model to solve
the unsupervised abstractive MDS task. We evaluate our approach using three
real-world datasets from different domains, and we demonstrate both substantial
improvements in terms of evaluation metrics over state-of-the-art
abstractive-based methods, and generalization to datasets from different
domains.
\\ ( https://arxiv.org/abs/2306.04787 ,  1305kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04810 (*cross-listing*)
Date: Wed, 7 Jun 2023 22:14:33 GMT   (8678kb,D)

Title: Correlative Information Maximization: A Biologically Plausible Approach
 to Supervised Deep Neural Networks without Weight Symmetry
Authors: Bariscan Bozkurt, Cengiz Pehlevan, Alper T Erdogan
Categories: cs.NE cs.IT cs.LG math.IT q-bio.NC
Comments: Preprint, 31 pages
\\
 The backpropagation algorithm has experienced remarkable success in training
large-scale artificial neural networks, however, its biological-plausibility is
disputed, and it remains an open question whether the brain employs supervised
learning mechanisms akin to it. Here, we propose correlative information
maximization between layer activations as an alternative normative approach to
describe the signal propagation in biological neural networks in both forward
and backward directions. This new framework addresses many concerns about the
biological-plausibility of conventional artificial neural networks and the
backpropagation algorithm. The coordinate descent-based optimization of the
corresponding objective, combined with the mean square error loss function for
fitting labeled supervision data, gives rise to a neural network structure that
emulates a more biologically realistic network of multi-compartment pyramidal
neurons with dendritic processing and lateral inhibitory neurons. Furthermore,
our approach provides a natural resolution to the weight symmetry problem
between forward and backward signal propagation paths, a significant critique
against the plausibility of the conventional backpropagation algorithm. This is
achieved by leveraging two alternative, yet equivalent forms of the correlative
mutual information objective. These alternatives intrinsically lead to forward
and backward prediction networks without weight symmetry issues, providing a
compelling solution to this long-standing challenge.
\\ ( https://arxiv.org/abs/2306.04810 ,  8678kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04817 (*cross-listing*)
Date: Wed, 7 Jun 2023 22:41:04 GMT   (9158kb,D)

Title: SiBBlInGS: Similarity-driven Building-Block Inference using Graphs
 across States
Authors: Noga Mudrik, Gal Mishne, Adam S. Charles
Categories: stat.ML cs.LG
\\
 Interpretable methods for extracting meaningful building blocks (BBs)
underlying multi-dimensional time series are vital for discovering valuable
insights in complex systems. Existing techniques, however, encounter
limitations that restrict their applicability to real-world systems, like
reliance on orthogonality assumptions, inadequate incorporation of inter- and
intra-state variability, and incapability to handle sessions of varying
duration. Here, we present a framework for Similarity-driven Building Block
Inference using Graphs across States (SiBBlInGS). SiBBlInGS employs a
graph-based dictionary learning approach for BB discovery, simultaneously
considers both inter- and intra-state relationships in the data, can extract
non-orthogonal components, and allows for variations in session counts and
duration across states. Additionally, SiBBlInGS allows for cross-state
variations in BB structure and per-trial temporal variability, can identify
state-specific vs state-invariant BBs, and offers both supervised and
data-driven approaches for controlling the level of BB similarity between
states. We demonstrate SiBBlInGS on synthetic and real-world data to highlight
its ability to provide insights into the underlying mechanisms of complex
phenomena and its applicability to data in various fields.
\\ ( https://arxiv.org/abs/2306.04817 ,  9158kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04836 (*cross-listing*)
Date: Wed, 7 Jun 2023 23:55:12 GMT   (904kb,D)

Title: $K$-Nearest-Neighbor Resampling for Off-Policy Evaluation in Stochastic
 Control
Authors: Michael Giegrich, Roel Oomen, Christoph Reisinger
Categories: stat.ML cs.LG math.OC math.ST stat.ME stat.TH
\\
 We propose a novel $K$-nearest neighbor resampling procedure for estimating
the performance of a policy from historical data containing realized episodes
of a decision process generated under a different policy. We focus on feedback
policies that depend deterministically on the current state in environments
with continuous state-action spaces and system-inherent stochasticity effected
by chosen actions. Such settings are common in a wide range of high-stake
applications and are actively investigated in the context of stochastic
control. Our procedure exploits that similar state/action pairs (in a metric
sense) are associated with similar rewards and state transitions. This enables
our resampling procedure to tackle the counterfactual estimation problem
underlying off-policy evaluation (OPE) by simulating trajectories similarly to
Monte Carlo methods. Compared to other OPE methods, our algorithm does not
require optimization, can be efficiently implemented via tree-based nearest
neighbor search and parallelization and does not explicitly assume a parametric
model for the environment's dynamics. These properties make the proposed
resampling algorithm particularly useful for stochastic control environments.
We prove that our method is statistically consistent in estimating the
performance of a policy in the OPE setting under weak assumptions and for data
sets containing entire episodes rather than independent transitions. To
establish the consistency, we generalize Stone's Theorem, a well-known result
in nonparametric statistics on local averaging, to include episodic data and
the counterfactual estimation underlying OPE. Numerical experiments demonstrate
the effectiveness of the algorithm in a variety of stochastic control settings
including a linear quadratic regulator, trade execution in limit order books
and online stochastic bin packing.
\\ ( https://arxiv.org/abs/2306.04836 ,  904kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04843 (*cross-listing*)
Date: Thu, 8 Jun 2023 00:31:27 GMT   (158kb,D)

Title: Classical Verification of Quantum Learning
Authors: Matthias C. Caro, Marcel Hinsche, Marios Ioannou, Alexander Nietner,
 Ryan Sweke
Categories: quant-ph cs.CC cs.LG stat.ML
Comments: 12 + 43 + 22 pages, 1 table, 1 figure
\\
 Quantum data access and quantum processing can make certain classically
intractable learning tasks feasible. However, quantum capabilities will only be
available to a select few in the near future. Thus, reliable schemes that allow
classical clients to delegate learning to untrusted quantum servers are
required to facilitate widespread access to quantum learning advantages.
Building on a recently introduced framework of interactive proof systems for
classical machine learning, we develop a framework for classical verification
of quantum learning. We exhibit learning problems that a classical learner
cannot efficiently solve on their own, but that they can efficiently and
reliably solve when interacting with an untrusted quantum prover. Concretely,
we consider the problems of agnostic learning parities and Fourier-sparse
functions with respect to distributions with uniform input marginal. We propose
a new quantum data access model that we call "mixture-of-superpositions"
quantum examples, based on which we give efficient quantum learning algorithms
for these tasks. Moreover, we prove that agnostic quantum parity and
Fourier-sparse learning can be efficiently verified by a classical verifier
with only random example or statistical query access. Finally, we showcase two
general scenarios in learning and verification in which quantum
mixture-of-superpositions examples do not lead to sample complexity
improvements over classical data. Our results demonstrate that the potential
power of quantum data for learning tasks, while not unlimited, can be utilized
by classical agents through interaction with untrusted quantum entities.
\\ ( https://arxiv.org/abs/2306.04843 ,  158kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04859 (*cross-listing*)
Date: Thu, 8 Jun 2023 01:12:19 GMT   (13443kb,D)

Title: Island-based Random Dynamic Voltage Scaling vs ML-Enhanced Power
 Side-Channel Attacks
Authors: Dake Chen, Christine Goins, Maxwell Waugaman, Georgios D. Dimou, Peter
 A. Beerel
Categories: cs.CR cs.LG
Journal-ref: Proceedings of the Great Lakes Symposium on VLSI 2023
DOI: 10.1145/3583781.3590266
\\
 In this paper, we describe and analyze an island-based random dynamic voltage
scaling (iRDVS) approach to thwart power side-channel attacks. We first analyze
the impact of the number of independent voltage islands on the resulting
signal-to-noise ratio and trace misalignment. As part of our analysis of
misalignment, we propose a novel unsupervised machine learning (ML) based
attack that is effective on systems with three or fewer independent voltages.
Our results show that iRDVS with four voltage islands, however, cannot be
broken with 200k encryption traces, suggesting that iRDVS can be effective. We
finish the talk by describing an iRDVS test chip in a 12nm FinFet process that
incorporates three variants of an AES-256 accelerator, all originating from the
same RTL. This included a synchronous core, an asynchronous core with no
protection, and a core employing the iRDVS technique using asynchronous logic.
Lab measurements from the chips indicated that both unprotected variants failed
the test vector leakage assessment (TVLA) security metric test, while the iRDVS
was proven secure in a variety of configurations.
\\ ( https://arxiv.org/abs/2306.04859 ,  13443kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04884 (*cross-listing*)
Date: Thu, 8 Jun 2023 02:29:37 GMT   (928kb,D)

Title: Faster Approximation Algorithms for Parameterized Graph Clustering and
 Edge Labeling
Authors: Vedangi Bengali, Nate Veldt
Categories: cs.DS cs.DM cs.LG cs.SI
Comments: 12 pages,4 figures
\\
 Graph clustering is a fundamental task in network analysis where the goal is
to detect sets of nodes that are well-connected to each other but sparsely
connected to the rest of the graph. We present faster approximation algorithms
for an NP-hard parameterized clustering framework called LambdaCC, which is
governed by a tunable resolution parameter and generalizes many other
clustering objectives such as modularity, sparsest cut, and cluster deletion.
Previous LambdaCC algorithms are either heuristics with no approximation
guarantees, or computationally expensive approximation algorithms. We provide
fast new approximation algorithms that can be made purely combinatorial. These
rely on a new parameterized edge labeling problem we introduce that generalizes
previous edge labeling problems that are based on the principle of strong
triadic closure and are of independent interest in social network analysis. Our
methods are orders of magnitude more scalable than previous approximation
algorithms and our lower bounds allow us to obtain a posteriori approximation
guarantees for previous heuristics that have no approximation guarantees of
their own.
\\ ( https://arxiv.org/abs/2306.04884 ,  928kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04886 (*cross-listing*)
Date: Thu, 8 Jun 2023 02:29:49 GMT   (7952kb,D)

Title: Multi-task Bioassay Pre-training for Protein-ligand Binding Affinity
 Prediction
Authors: Jiaxian Yan, Zhaofeng Ye, Ziyi Yang, Chengqiang Lu, Shengyu Zhang, Qi
 Liu, Jiezhong Qiu
Categories: q-bio.BM cs.LG
Comments: 21 pages, 7 figures
\\
 Protein-ligand binding affinity (PLBA) prediction is the fundamental task in
drug discovery. Recently, various deep learning-based models predict binding
affinity by incorporating the three-dimensional structure of protein-ligand
complexes as input and achieving astounding progress. However, due to the
scarcity of high-quality training data, the generalization ability of current
models is still limited. In addition, different bioassays use varying affinity
measurement labels (i.e., IC50, Ki, Kd), and different experimental conditions
inevitably introduce systematic noise, which poses a significant challenge to
constructing high-precision affinity prediction models. To address these
issues, we (1) propose Multi-task Bioassay Pre-training (MBP), a pre-training
framework for structure-based PLBA prediction; (2) construct a pre-training
dataset called ChEMBL-Dock with more than 300k experimentally measured affinity
labels and about 2.8M docked three-dimensional structures. By introducing
multi-task pre-training to treat the prediction of different affinity labels as
different tasks and classifying relative rankings between samples from the same
bioassay, MBP learns robust and transferrable structural knowledge from our new
ChEMBL-Dock dataset with varied and noisy labels. Experiments substantiate the
capability of MBP as a general framework that can improve and be tailored to
mainstream structure-based PLBA prediction tasks. To the best of our knowledge,
MBP is the first affinity pre-training model and shows great potential for
future development.
\\ ( https://arxiv.org/abs/2306.04886 ,  7952kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04894 (*cross-listing*)
Date: Thu, 8 Jun 2023 02:48:37 GMT   (3046kb,D)

Title: A Bayesian Framework for learning governing Partial Differential
 Equation from Data
Authors: Kalpesh More and Tapas Tripura and Rajdip Nayek and Souvik Chakraborty
Categories: stat.ML cs.LG
\\
 The discovery of partial differential equations (PDEs) is a challenging task
that involves both theoretical and empirical methods. Machine learning
approaches have been developed and used to solve this problem; however, it is
important to note that existing methods often struggle to identify the
underlying equation accurately in the presence of noise. In this study, we
present a new approach to discovering PDEs by combining variational Bayes and
sparse linear regression. The problem of PDE discovery has been posed as a
problem to learn relevant basis from a predefined dictionary of basis
functions. To accelerate the overall process, a variational Bayes-based
approach for discovering partial differential equations is proposed. To ensure
sparsity, we employ a spike and slab prior. We illustrate the efficacy of our
strategy in several examples, including Burgers, Korteweg-de Vries, Kuramoto
Sivashinsky, wave equation, and heat equation (1D as well as 2D). Our method
offers a promising avenue for discovering PDEs from data and has potential
applications in fields such as physics, engineering, and biology.
\\ ( https://arxiv.org/abs/2306.04894 ,  3046kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04895 (*cross-listing*)
Date: Thu, 8 Jun 2023 02:49:12 GMT   (1840kb,D)

Title: Solution of physics-based inverse problems using conditional generative
 adversarial networks with full gradient penalty
Authors: Deep Ray, Javier Murgoitio-Esandi, Agnimitra Dasgupta, Assad A. Oberai
Categories: stat.ML cs.LG
Comments: 34 pages, 9 figures, 3 tables, 1 appendix
\\
 The solution of probabilistic inverse problems for which the corresponding
forward problem is constrained by physical principles is challenging. This is
especially true if the dimension of the inferred vector is large and the prior
information about it is in the form of a collection of samples. In this work, a
novel deep learning based approach is developed and applied to solving these
types of problems. The approach utilizes samples of the inferred vector drawn
from the prior distribution and a physics-based forward model to generate
training data for a conditional Wasserstein generative adversarial network
(cWGAN). The cWGAN learns the probability distribution for the inferred vector
conditioned on the measurement and produces samples from this distribution. The
cWGAN developed in this work differs from earlier versions in that its critic
is required to be 1-Lipschitz with respect to both the inferred and the
measurement vectors and not just the former. This leads to a loss term with the
full (and not partial) gradient penalty. It is shown that this rather simple
change leads to a stronger notion of convergence for the conditional density
learned by the cWGAN and a more robust and accurate sampling strategy. Through
numerical examples it is shown that this change also translates to better
accuracy when solving inverse problems. The numerical examples considered
include illustrative problems where the true distribution and/or statistics are
known, and a more complex inverse problem motivated by applications in
biomechanics.
\\ ( https://arxiv.org/abs/2306.04895 ,  1840kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04902 (*cross-listing*)
Date: Thu, 8 Jun 2023 03:09:49 GMT   (491kb,D)

Title: A Cover Time Study of a non-Markovian Algorithm
Authors: Guanhua Fang, Gennady Samorodnitsky, Zhiqiang Xu
Categories: cs.DS cs.LG math.ST stat.TH
Comments: 22 pages
\\
 Given a traversal algorithm, cover time is the expected number of steps
needed to visit all nodes in a given graph. A smaller cover time means a higher
exploration efficiency of traversal algorithm. Although random walk algorithms
have been studied extensively in the existing literature, there has been no
cover time result for any non-Markovian method. In this work, we stand on a
theoretical perspective and show that the negative feedback strategy (a
count-based exploration method) is better than the naive random walk search. In
particular, the former strategy can locally improve the search efficiency for
an arbitrary graph. It also achieves smaller cover times for special but
important graphs, including clique graphs, tree graphs, etc. Moreover, we make
connections between our results and reinforcement learning literature to give
new insights on why classical UCB and MCTS algorithms are so useful. Various
numerical results corroborate our theoretical findings.
\\ ( https://arxiv.org/abs/2306.04902 ,  491kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04925 (*cross-listing*)
Date: Thu, 8 Jun 2023 04:04:47 GMT   (611kb,D)

Title: Prefer to Classify: Improving Text Classifiers via Auxiliary Preference
 Learning
Authors: Jaehyung Kim, Jinwoo Shin, Dongyeop Kang
Categories: cs.CL cs.LG
Comments: 22 pages, accepted at ICML 2023
\\
 The development of largely human-annotated benchmarks has driven the success
of deep neural networks in various NLP tasks. To enhance the effectiveness of
existing benchmarks, collecting new additional input-output pairs is often too
costly and challenging, particularly considering their marginal impact on
improving the current model accuracy. Instead, additional or complementary
annotations on the existing input texts in the benchmarks can be preferable as
an efficient way to pay the additional human cost. In this paper, we
investigate task-specific preferences between pairs of input texts as a new
alternative way for such auxiliary data annotation. From 'pair-wise'
comparisons with respect to the task, the auxiliary preference learning enables
the model to learn an additional informative training signal that cannot be
captured with 'instance-wise' task labels. To this end, we propose a novel
multi-task learning framework, called prefer-to-classify (P2C), which can enjoy
the cooperative effect of learning both the given classification task and the
auxiliary preferences. Here, we provide three different ways to collect
preference signals in practice: (a) implicitly extracting from annotation
records (for free, but often unavailable), (b) collecting explicitly from crowd
workers (high paid), or (c) pre-trained large language models such as GPT-3
(low paid). Given existing classification NLP benchmarks, we demonstrate that
the proposed auxiliary preference learning via P2C on them is effective in
improving text classifiers. Our codes are publicly available.
\\ ( https://arxiv.org/abs/2306.04925 ,  611kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04930 (*cross-listing*)
Date: Thu, 8 Jun 2023 04:24:24 GMT   (865kb,D)

Title: When to Show a Suggestion? Integrating Human Feedback in AI-Assisted
 Programming
Authors: Hussein Mozannar, Gagan Bansal, Adam Fourney, Eric Horvitz
Categories: cs.HC cs.LG cs.SE
Comments: arXiv admin note: text overlap with arXiv:2210.14306
\\
 AI powered code-recommendation systems, such as Copilot and CodeWhisperer,
provide code suggestions inside a programmer's environment (e.g., an IDE) with
the aim to improve their productivity. Since, in these scenarios, programmers
accept and reject suggestions, ideally, such a system should use this feedback
in furtherance of this goal. In this work we leverage prior data of programmers
interacting with Copilot to develop interventions that can save programmer
time. We propose a utility theory framework, which models this interaction with
programmers and decides when and which suggestions to display. Our framework
Conditional suggestion Display from Human Feedback (CDHF) is based on
predictive models of programmer actions. Using data from 535 programmers we
build models that predict the likelihood of suggestion acceptance. In a
retrospective evaluation on real-world programming tasks solved with
AI-assisted programming, we find that CDHF can achieve favorable tradeoffs. Our
findings show the promise of integrating human feedback to improve interaction
with large language models in scenarios such as programming and possibly
writing tasks.
\\ ( https://arxiv.org/abs/2306.04930 ,  865kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04933 (*cross-listing*)
Date: Thu, 8 Jun 2023 04:31:48 GMT   (2080kb,D)

Title: InfoPrompt: Information-Theoretic Soft Prompt Tuning for Natural
 Language Understanding
Authors: Junda Wu, Tong Yu, Rui Wang, Zhao Song, Ruiyi Zhang, Handong Zhao,
 Chaochao Lu, Shuai Li, Ricardo Henao
Categories: cs.CL cs.LG stat.ML
\\
 Soft prompt tuning achieves superior performances across a wide range of
few-shot tasks. However, the performances of prompt tuning can be highly
sensitive to the initialization of the prompts. We also empirically observe
that conventional prompt tuning methods cannot encode and learn sufficient
task-relevant information from prompt tokens. In this work, we develop an
information-theoretic framework that formulates soft prompt tuning as
maximizing mutual information between prompts and other model parameters (or
encoded representations). This novel view helps us to develop a more efficient,
accurate and robust soft prompt tuning method InfoPrompt. With this framework,
we develop two novel mutual information based loss functions, to (i) discover
proper prompt initialization for the downstream tasks and learn sufficient
task-relevant information from prompt tokens and (ii) encourage the output
representation from the pretrained language model to be more aware of the
task-relevant information captured in the learnt prompt. Extensive experiments
validate that InfoPrompt can significantly accelerate the convergence of the
prompt tuning and outperform traditional prompt tuning methods. Finally, we
provide a formal theoretical result for showing to show that gradient descent
type algorithm can be used to train our mutual information loss.
\\ ( https://arxiv.org/abs/2306.04933 ,  2080kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04941 (*cross-listing*)
Date: Thu, 8 Jun 2023 05:17:03 GMT   (26kb,D)

Title: A modified model for topic detection from a corpus and a new metric
 evaluating the understandability of topics
Authors: Tomoya Kitano, Yuto Miyatake, Daisuke Furihata
Categories: cs.CL cs.LG
\\
 This paper presents a modified neural model for topic detection from a corpus
and proposes a new metric to evaluate the detected topics. The new model builds
upon the embedded topic model incorporating some modifications such as document
clustering. Numerical experiments suggest that the new model performs
favourably regardless of the document's length. The new metric, which can be
computed more efficiently than widely-used metrics such as topic coherence,
provides variable information regarding the understandability of the detected
topics.
\\ ( https://arxiv.org/abs/2306.04941 ,  26kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04952 (*cross-listing*)
Date: Thu, 8 Jun 2023 05:56:05 GMT   (2556kb,D)

Title: Entropy-based Training Methods for Scalable Neural Implicit Sampler
Authors: Weijian Luo and Boya Zhang and Zhihua Zhang
Categories: stat.ML cs.LG
\\
 Efficiently sampling from un-normalized target distributions is a fundamental
problem in scientific computing and machine learning. Traditional approaches
like Markov Chain Monte Carlo (MCMC) guarantee asymptotically unbiased samples
from such distributions but suffer from computational inefficiency,
particularly when dealing with high-dimensional targets, as they require
numerous iterations to generate a batch of samples. In this paper, we propose
an efficient and scalable neural implicit sampler that overcomes these
limitations. Our sampler can generate large batches of samples with low
computational costs by leveraging a neural transformation that directly maps
easily sampled latent vectors to target samples without the need for iterative
procedures. To train the neural implicit sampler, we introduce two novel
methods: the KL training method and the Fisher training method. The former
minimizes the Kullback-Leibler divergence, while the latter minimizes the
Fisher divergence. By employing these training methods, we effectively optimize
the neural implicit sampler to capture the desired target distribution. To
demonstrate the effectiveness, efficiency, and scalability of our proposed
samplers, we evaluate them on three sampling benchmarks with different scales.
These benchmarks include sampling from 2D targets, Bayesian inference, and
sampling from high-dimensional energy-based models (EBMs). Notably, in the
experiment involving high-dimensional EBMs, our sampler produces samples that
are comparable to those generated by MCMC-based methods while being more than
100 times more efficient, showcasing the efficiency of our neural sampler. We
believe that the theoretical and empirical contributions presented in this work
will stimulate further research on developing efficient samplers for various
applications beyond the ones explored in this study.
\\ ( https://arxiv.org/abs/2306.04952 ,  2556kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04956 (*cross-listing*)
Date: Thu, 8 Jun 2023 06:06:42 GMT   (939kb,D)

Title: Adaptive Fake Audio Detection with Low-Rank Model Squeezing
Authors: Xiaohui Zhang, Jiangyan Yi, Jianhua Tao, Chenlong Wang, Le Xu and
 Ruibo Fu
Categories: cs.SD cs.LG eess.AS
\\
 The rapid advancement of spoofing algorithms necessitates the development of
robust detection methods capable of accurately identifying emerging fake audio.
Traditional approaches, such as finetuning on new datasets containing these
novel spoofing algorithms, are computationally intensive and pose a risk of
impairing the acquired knowledge of known fake audio types. To address these
challenges, this paper proposes an innovative approach that mitigates the
limitations associated with finetuning. We introduce the concept of training
low-rank adaptation matrices tailored specifically to the newly emerging fake
audio types. During the inference stage, these adaptation matrices are combined
with the existing model to generate the final prediction output. Extensive
experimentation is conducted to evaluate the efficacy of the proposed method.
The results demonstrate that our approach effectively preserves the prediction
accuracy of the existing model for known fake audio types. Furthermore, our
approach offers several advantages, including reduced storage memory
requirements and lower equal error rates compared to conventional finetuning
methods, particularly on specific spoofing algorithms.
\\ ( https://arxiv.org/abs/2306.04956 ,  939kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04964 (*cross-listing*)
Date: Thu, 8 Jun 2023 06:43:10 GMT   (509kb,D)

Title: Leveraging Language Identification to Enhance Code-Mixed Text
 Classification
Authors: Gauri Takawane, Abhishek Phaltankar, Varad Patwardhan, Aryan Patil,
 Raviraj Joshi, Mukta S. Takalikar
Categories: cs.CL cs.LG
\\
 The usage of more than one language in the same text is referred to as Code
Mixed. It is evident that there is a growing degree of adaption of the use of
code-mixed data, especially English with a regional language, on social media
platforms. Existing deep-learning models do not take advantage of the implicit
language information in the code-mixed text. Our study aims to improve
BERT-based models performance on low-resource Code-Mixed Hindi-English Datasets
by experimenting with language augmentation approaches. We propose a pipeline
to improve code-mixed systems that comprise data preprocessing, word-level
language identification, language augmentation, and model training on
downstream tasks like sentiment analysis. For language augmentation in BERT
models, we explore word-level interleaving and post-sentence placement of
language information. We have examined the performance of vanilla BERT-based
models and their code-mixed HingBERT counterparts on respective benchmark
datasets, comparing their results with and without using word-level language
information. The models were evaluated using metrics such as accuracy,
precision, recall, and F1 score. Our findings show that the proposed language
augmentation approaches work well across different BERT models. We demonstrate
the importance of augmenting code-mixed text with language information on five
different code-mixed Hindi-English downstream datasets based on sentiment
analysis, hate speech detection, and emotion detection.
\\ ( https://arxiv.org/abs/2306.04964 ,  509kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04971 (*cross-listing*)
Date: Thu, 8 Jun 2023 06:59:21 GMT   (3799kb,D)

Title: A Melting Pot of Evolution and Learning
Authors: Moshe Sipper, Achiya Elyasaf, Tomer Halperin, Zvika Haramaty, Raz
 Lapid, Eyal Segal, Itai Tzruia, Snir Vitrack Tamam
Categories: cs.NE cs.LG
Comments: To Appear in Proceedings of Genetic Programming Theory & Practice XX,
 2023
\\
 We survey eight recent works by our group, involving the successful blending
of evolutionary algorithms with machine learning and deep learning: 1. Binary
and Multinomial Classification through Evolutionary Symbolic Regression, 2.
Classy Ensemble: A Novel Ensemble Algorithm for Classification, 3. EC-KitY:
Evolutionary Computation Tool Kit in Python, 4. Evolution of Activation
Functions for Deep Learning-Based Image Classification, 5. Adaptive Combination
of a Genetic Algorithm and Novelty Search for Deep Neuroevolution, 6. An
Evolutionary, Gradient-Free, Query-Efficient, Black-Box Algorithm for
Generating Adversarial Instances in Deep Networks, 7. Foiling Explanations in
Deep Neural Networks, 8. Patch of Invisibility: Naturalistic Black-Box
Adversarial Attacks on Object Detectors.
\\ ( https://arxiv.org/abs/2306.04971 ,  3799kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04984 (*cross-listing*)
Date: Thu, 8 Jun 2023 07:15:04 GMT   (661kb,D)

Title: G$^2$uardFL: Safeguarding Federated Learning Against Backdoor Attacks
 through Attributed Client Graph Clustering
Authors: Hao Yu, Chuan Ma, Meng Liu, Xinwang Liu, Zhe Liu, Ming Ding
Categories: cs.CR cs.LG
Comments: 20 pages, 7 figures
\\
 As a collaborative paradigm, Federated Learning (FL) empowers clients to
engage in collective model training without exchanging their respective local
data. Nevertheless, FL remains vulnerable to backdoor attacks in which an
attacker compromises malicious clients, and injects poisoned model weights into
the aggregation process to yield attacker-chosen predictions for particular
samples. Existing countermeasures, mainly based on anomaly detection, may
erroneously reject legitimate weights while accepting malicious ones, which is
due to inadequacies in quantifying client model similarities. Other defense
mechanisms prove effective exclusively when confronted with a restricted number
of malicious clients, e.g., less than 10%. To address these vulnerabilities, we
present G$^2$uardFL, a protective framework that reframes the detection of
malicious clients as an attributed graph clustering problem, thereby
safeguarding FL systems. This framework employs a client graph clustering
technique to identify malicious clients and incorporates an adaptive method to
amplify the disparity between the aggregated model and poisoned client models,
thereby eliminating previously embedded backdoors. A theoretical analysis of
convergence is also performed to demonstrate that the global model closely
approximates the model untouched by any backdoor. Through empirical evaluation
compared to cutting-edge defenses and against various backdoor attacks, our
experimental results indicate that G$^2$uardFL considerably undermines the
effectiveness of backdoor attacks while maintaining a negligible impact on the
benign sample performance.
\\ ( https://arxiv.org/abs/2306.04984 ,  661kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05011 (*cross-listing*)
Date: Thu, 8 Jun 2023 07:59:08 GMT   (222kb,D)

Title: Attention Weighted Mixture of Experts with Contrastive Learning for
 Personalized Ranking in E-commerce
Authors: Juan Gong, Zhenlin Chen, Chaoyi Ma, Zhuojian Xiao, Haonan Wang, Guoyu
 Tang, Lin Liu, Sulong Xu, Bo Long, Yunjiang Jiang
Categories: cs.IR cs.LG
Comments: Accepted by ICDE2023
\\
 Ranking model plays an essential role in e-commerce search and
recommendation. An effective ranking model should give a personalized ranking
list for each user according to the user preference. Existing algorithms
usually extract a user representation vector from the user behavior sequence,
then feed the vector into a feed-forward network (FFN) together with other
features for feature interactions, and finally produce a personalized ranking
score. Despite tremendous progress in the past, there is still room for
improvement. Firstly, the personalized patterns of feature interactions for
different users are not explicitly modeled. Secondly, most of existing
algorithms have poor personalized ranking results for long-tail users with few
historical behaviors due to the data sparsity. To overcome the two challenges,
we propose Attention Weighted Mixture of Experts (AW-MoE) with contrastive
learning for personalized ranking. Firstly, AW-MoE leverages the MoE framework
to capture personalized feature interactions for different users. To model the
user preference, the user behavior sequence is simultaneously fed into expert
networks and the gate network. Within the gate network, one gate unit and one
activation unit are designed to adaptively learn the fine-grained activation
vector for experts using an attention mechanism. Secondly, a random masking
strategy is applied to the user behavior sequence to simulate long-tail users,
and an auxiliary contrastive loss is imposed to the output of the gate network
to improve the model generalization for these users. This is validated by a
higher performance gain on the long-tail user test set. Experiment results on a
JD real production dataset and a public dataset demonstrate the effectiveness
of AW-MoE, which significantly outperforms state-of-art methods. Notably,
AW-MoE has been successfully deployed in the JD e-commerce search engine, ...
\\ ( https://arxiv.org/abs/2306.05011 ,  222kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05014 (*cross-listing*)
Date: Thu, 8 Jun 2023 08:07:54 GMT   (4832kb,D)

Title: Learning Closed-form Equations for Subgrid-scale Closures from
 High-fidelity Data: Promises and Challenges
Authors: Karan Jakhar, Yifei Guan, Rambod Mojgani, Ashesh Chattopadhyay, Pedram
 Hassanzadeh and Laura Zanna
Categories: physics.flu-dyn cs.LG physics.ao-ph
Comments: 40 pages, 4 figures. The codes and data used in this work can be
 found at https://github.com/jakharkaran/EqsDiscovery_2D-FHIT_RBC and
 https://doi.org/10.5281/zenodo.7500647, respectively
MSC-class: 76F65 (Primary) 86A08, 68T01, 76F05, 76F35 (Secondary)
ACM-class: J.2; I.2.0; G.1.8
\\
 There is growing interest in discovering interpretable, closed-form equations
for subgrid-scale (SGS) closures/parameterizations of complex processes in
Earth system. Here, we apply a common equation-discovery technique with
expansive libraries to learn closures from filtered direct numerical
simulations of 2D forced turbulence and Rayleigh-B\'enard convection (RBC).
Across common filters, we robustly discover closures of the same form for
momentum and heat fluxes. These closures depend on nonlinear combinations of
gradients of filtered variables (velocity, temperature), with constants that
are independent of the fluid/flow properties and only depend on filter
type/size. We show that these closures are the nonlinear gradient model (NGM),
which is derivable analytically using Taylor-series expansions. In fact, we
suggest that with common (physics-free) equation-discovery algorithms,
regardless of the system/physics, discovered closures are always consistent
with the Taylor-series. Like previous studies, we find that large-eddy
simulations with NGM closures are unstable, despite significant similarities
between the true and NGM-predicted fluxes (pattern correlations $> 0.95$). We
identify two shortcomings as reasons for these instabilities: in 2D, NGM
produces zero kinetic energy transfer between resolved and subgrid scales,
lacking both diffusion and backscattering. In RBC, backscattering of potential
energy is poorly predicted. Moreover, we show that SGS fluxes diagnosed from
data, presumed the "truth" for discovery, depend on filtering procedures and
are not unique. Accordingly, to learn accurate, stable closures from
high-fidelity data in future work, we propose several ideas around using
physics-informed libraries, loss functions, and metrics. These findings are
relevant beyond turbulence to closure modeling of any multi-scale system.
\\ ( https://arxiv.org/abs/2306.05014 ,  4832kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05017 (*cross-listing*)
Date: Thu, 8 Jun 2023 08:11:21 GMT   (309kb,D)

Title: Non-Intrusive Load Monitoring (NILM) using Deep Neural Networks: A
 Review
Authors: Mohammad Irani Azad, Roozbeh Rajabi, Abouzar Estebsari
Categories: eess.SP cs.LG
Comments: 6 pages, EEEIC 2023 conference
\\
 Demand-side management now encompasses more residential loads. To efficiently
apply demand response strategies, it's essential to periodically observe the
contribution of various domestic appliances to total energy consumption.
Non-intrusive load monitoring (NILM), also known as load disaggregation, is a
method for decomposing the total energy consumption profile into individual
appliance load profiles within the household. It has multiple applications in
demand-side management, energy consumption monitoring, and analysis. Various
methods, including machine learning and deep learning, have been used to
implement and improve NILM algorithms. This paper reviews some recent NILM
methods based on deep learning and introduces the most accurate methods for
residential loads. It summarizes public databases for NILM evaluation and
compares methods using standard performance metrics.
\\ ( https://arxiv.org/abs/2306.05017 ,  309kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05023 (*cross-listing*)
Date: Thu, 8 Jun 2023 08:22:27 GMT   (10356kb,D)

Title: Posterior Collapse in Linear Conditional and Hierarchical Variational
 Autoencoders
Authors: Hien Dang and Tho Tran and Tan Nguyen and Nhat Ho
Categories: stat.ML cs.LG
Comments: 50 pages, 10 figures
\\
 The posterior collapse phenomenon in variational autoencoders (VAEs), where
the variational posterior distribution closely matches the prior distribution,
can hinder the quality of the learned latent variables. As a consequence of
posterior collapse, the latent variables extracted by the encoder in VAEs
preserve less information from the input data and thus fail to produce
meaningful representations as input to the reconstruction process in the
decoder. While this phenomenon has been an actively addressed topic related to
VAEs performance, the theory for posterior collapse remains underdeveloped,
especially beyond the standard VAEs. In this work, we advance the theoretical
understanding of posterior collapse to two important and prevalent yet less
studied classes of VAEs: conditional VAEs and hierarchical VAEs. Specifically,
via a non-trivial theoretical analysis of linear conditional VAEs and
hierarchical VAEs with two levels of latent, we prove that the cause of
posterior collapses in these models includes the correlation between the input
and output of the conditional VAEs and the effect of learnable encoder variance
in the hierarchical VAEs. We empirically validate our theoretical findings for
linear conditional and hierarchical VAEs and demonstrate that these results are
also predictive for non-linear cases.
\\ ( https://arxiv.org/abs/2306.05023 ,  10356kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05032 (*cross-listing*)
Date: Thu, 8 Jun 2023 08:34:58 GMT   (414kb,D)

Title: Scalable and Adaptive Log-based Anomaly Detection with Expert in the
 Loop
Authors: Jinyang Liu, Junjie Huang, Yintong Huo, Zhihan Jiang, Jiazhen Gu,
 Zhuangbin Chen, Cong Feng, Minzhi Yan and Michael R. Lyu
Categories: cs.SE cs.LG
\\
 System logs play a critical role in maintaining the reliability of software
systems. Fruitful studies have explored automatic log-based anomaly detection
and achieved notable accuracy on benchmark datasets. However, when applied to
large-scale cloud systems, these solutions face limitations due to high
resource consumption and lack of adaptability to evolving logs. In this paper,
we present an accurate, lightweight, and adaptive log-based anomaly detection
framework, referred to as SeaLog. Our method introduces a Trie-based Detection
Agent (TDA) that employs a lightweight, dynamically-growing trie structure for
real-time anomaly detection. To enhance TDA's accuracy in response to evolving
log data, we enable it to receive feedback from experts. Interestingly, our
findings suggest that contemporary large language models, such as ChatGPT, can
provide feedback with a level of consistency comparable to human experts, which
can potentially reduce manual verification efforts. We extensively evaluate
SeaLog on two public datasets and an industrial dataset. The results show that
SeaLog outperforms all baseline methods in terms of effectiveness, runs 2X to
10X faster and only consumes 5% to 41% of the memory resource.
\\ ( https://arxiv.org/abs/2306.05032 ,  414kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05088 (*cross-listing*)
Date: Thu, 8 Jun 2023 10:42:44 GMT   (2187kb,D)

Title: The ART of Conversation: Measuring Phonetic Convergence and Deliberate
 Imitation in L2-Speech with a Siamese RNN
Authors: Zheng Yuan (1 and 2), Aldo Pastore (1 and 2), Dorina de Jong (1 and
 2), Hao Xu (3), Luciano Fadiga (1 and 2), Alessandro D'Ausilio (1 and 2) ((1)
 Istituto Italiano di Tecnologia, Italy, (2) Universit\`a degli Studi di
 Ferrara, Italy, (3) University of California San Diego, USA)
Categories: cs.CL cs.LG cs.SD eess.AS
Comments: Accepted at INTERSPEECH 2023
\\
 Phonetic convergence describes the automatic and unconscious speech
adaptation of two interlocutors in a conversation. This paper proposes a
Siamese recurrent neural network (RNN) architecture to measure the convergence
of the holistic spectral characteristics of speech sounds in an L2-L2
interaction. We extend an alternating reading task (the ART) dataset by adding
20 native Slovak L2 English speakers. We train and test the Siamese RNN model
to measure phonetic convergence of L2 English speech from three different
native language groups: Italian (9 dyads), French (10 dyads) and Slovak (10
dyads). Our results indicate that the Siamese RNN model effectively captures
the dynamics of phonetic convergence and the speaker's imitation ability.
Moreover, this text-independent model is scalable and capable of handling
L1-induced speaker variability.
\\ ( https://arxiv.org/abs/2306.05088 ,  2187kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05093 (*cross-listing*)
Date: Thu, 8 Jun 2023 10:52:55 GMT   (1162kb,D)

Title: Re-aligning Shadow Models can Improve White-box Membership Inference
 Attacks
Authors: Ana-Maria Cretu, Daniel Jones, Yves-Alexandre de Montjoye, Shruti
 Tople
Categories: cs.CR cs.LG
\\
 Machine learning models have been shown to leak sensitive information about
their training datasets. As models are being increasingly used, on devices, to
automate tasks and power new applications, there have been concerns that such
white-box access to its parameters, as opposed to the black-box setting which
only provides query access to the model, increases the attack surface. Directly
extending the shadow modelling technique from the black-box to the white-box
setting has been shown, in general, not to perform better than black-box only
attacks. A key reason is misalignment, a known characteristic of deep neural
networks. We here present the first systematic analysis of the causes of
misalignment in shadow models and show the use of a different weight
initialisation to be the main cause of shadow model misalignment. Second, we
extend several re-alignment techniques, previously developed in the model
fusion literature, to the shadow modelling context, where the goal is to
re-align the layers of a shadow model to those of the target model.We show
re-alignment techniques to significantly reduce the measured misalignment
between the target and shadow models. Finally, we perform a comprehensive
evaluation of white-box membership inference attacks (MIA). Our analysis
reveals that (1) MIAs suffer from misalignment between shadow models, but that
(2) re-aligning the shadow models improves, sometimes significantly, MIA
performance. On the CIFAR10 dataset with a false positive rate of 1\%,
white-box MIA using re-aligned shadow models improves the true positive rate by
4.5\%.Taken together, our results highlight that on-device deployment increase
the attack surface and that the newly available information can be used by an
attacker.
\\ ( https://arxiv.org/abs/2306.05093 ,  1162kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05100 (*cross-listing*)
Date: Thu, 8 Jun 2023 10:58:46 GMT   (133kb,D)

Title: Communication-Efficient Gradient Descent-Accent Methods for Distributed
 Variational Inequalities: Unified Analysis and Local Updates
Authors: Siqi Zhang, Sayantan Choudhury, Sebastian U Stich, Nicolas Loizou
Categories: math.OC cs.LG stat.ML
\\
 Distributed and federated learning algorithms and techniques associated
primarily with minimization problems. However, with the increase of minimax
optimization and variational inequality problems in machine learning, the
necessity of designing efficient distributed/federated learning approaches for
these problems is becoming more apparent. In this paper, we provide a unified
convergence analysis of communication-efficient local training methods for
distributed variational inequality problems (VIPs). Our approach is based on a
general key assumption on the stochastic estimates that allows us to propose
and analyze several novel local training algorithms under a single framework
for solving a class of structured non-monotone VIPs. We present the first local
gradient descent-accent algorithms with provable improved communication
complexity for solving distributed variational inequalities on heterogeneous
data. The general algorithmic framework recovers state-of-the-art algorithms
and their sharp convergence guarantees when the setting is specialized to
minimization or minimax optimization problems. Finally, we demonstrate the
strong performance of the proposed algorithms compared to state-of-the-art
methods when solving federated minimax optimization problems.
\\ ( https://arxiv.org/abs/2306.05100 ,  133kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05131 (*cross-listing*)
Date: Thu, 8 Jun 2023 11:54:58 GMT   (3621kb,D)

Title: Conformal Prediction for Federated Uncertainty Quantification Under
 Label Shift
Authors: Vincent Plassier, Mehdi Makni, Aleksandr Rubashevskii, Eric Moulines
 and Maxim Panov
Categories: stat.ML cs.LG
Comments: ICML 2023
\\
 Federated Learning (FL) is a machine learning framework where many clients
collaboratively train models while keeping the training data decentralized.
Despite recent advances in FL, the uncertainty quantification topic (UQ)
remains partially addressed. Among UQ methods, conformal prediction (CP)
approaches provides distribution-free guarantees under minimal assumptions. We
develop a new federated conformal prediction method based on quantile
regression and take into account privacy constraints. This method takes
advantage of importance weighting to effectively address the label shift
between agents and provides theoretical guarantees for both valid coverage of
the prediction sets and differential privacy. Extensive experimental studies
demonstrate that this method outperforms current competitors.
\\ ( https://arxiv.org/abs/2306.05131 ,  3621kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05185 (*cross-listing*)
Date: Thu, 8 Jun 2023 13:33:20 GMT   (1643kb)

Title: On the Identification and Optimization of Nonsmooth Superposition
 Operators in Semilinear Elliptic PDEs
Authors: Constantin Christof and Julia Kowalczyk
Categories: math.OC cs.LG
MSC-class: 35J61, 49J50, 49J52, 49K20, 49M05, 68T07
\\
 We study an infinite-dimensional optimization problem that aims to identify
the Nemytskii operator in the nonlinear part of a prototypical semilinear
elliptic partial differential equation (PDE) which minimizes the distance
between the PDE-solution and a given desired state. In contrast to previous
works, we consider this identification problem in a low-regularity regime in
which the function inducing the Nemytskii operator is a-priori only known to be
an element of $H^1_{loc}(\mathbb{R})$. This makes the studied problem class a
suitable point of departure for the rigorous analysis of training problems for
learning-informed PDEs in which an unknown superposition operator is
approximated by means of a neural network with nonsmooth activation functions
(ReLU, leaky-ReLU, etc.). We establish that, despite the low regularity of the
controls, it is possible to derive a classical stationarity system for local
minimizers and to solve the considered problem by means of a gradient
projection method. The convergence of the resulting algorithm is proven in the
function space setting. It is also shown that the established first-order
necessary optimality conditions imply that locally optimal superposition
operators share various characteristic properties with commonly used activation
functions: They are always sigmoidal, continuously differentiable away from the
origin, and typically possess a distinct kink at zero. The paper concludes with
numerical experiments which confirm the theoretical findings.
\\ ( https://arxiv.org/abs/2306.05185 ,  1643kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05245 (*cross-listing*)
Date: Thu, 8 Jun 2023 14:44:23 GMT   (4972kb,D)

Title: Matching Latent Encoding for Audio-Text based Keyword Spotting
Authors: Kumari Nishu, Minsik Cho, Devang Naik
Categories: eess.AS cs.LG cs.SD
\\
 Using audio and text embeddings jointly for Keyword Spotting (KWS) has shown
high-quality results, but the key challenge of how to semantically align two
embeddings for multi-word keywords of different sequence lengths remains
largely unsolved. In this paper, we propose an audio-text-based end-to-end
model architecture for flexible keyword spotting (KWS), which builds upon
learned audio and text embeddings. Our architecture uses a novel dynamic
programming-based algorithm, Dynamic Sequence Partitioning (DSP), to optimally
partition the audio sequence into the same length as the word-based text
sequence using the monotonic alignment of spoken content. Our proposed model
consists of an encoder block to get audio and text embeddings, a projector
block to project individual embeddings to a common latent space, and an
audio-text aligner containing a novel DSP algorithm, which aligns the audio and
text embeddings to determine if the spoken content is the same as the text.
Experimental results show that our DSP is more effective than other
partitioning schemes, and the proposed architecture outperformed the
state-of-the-art results on the public dataset in terms of Area Under the ROC
Curve (AUC) and Equal-Error-Rate (EER) by 14.4 % and 28.9%, respectively.
\\ ( https://arxiv.org/abs/2306.05245 ,  4972kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05261 (*cross-listing*)
Date: Thu, 8 Jun 2023 15:02:04 GMT   (25365kb,D)

Title: Representing and Learning Functions Invariant Under Crystallographic
 Groups
Authors: Ryan P. Adams and Peter Orbanz
Categories: stat.ML cond-mat.mtrl-sci cs.LG
\\
 Crystallographic groups describe the symmetries of crystals and other
repetitive structures encountered in nature and the sciences. These groups
include the wallpaper and space groups. We derive linear and nonlinear
representations of functions that are (1) smooth and (2) invariant under such a
group. The linear representation generalizes the Fourier basis to
crystallographically invariant basis functions. We show that such a basis
exists for each crystallographic group, that it is orthonormal in the relevant
$L_2$ space, and recover the standard Fourier basis as a special case for pure
shift groups. The nonlinear representation embeds the orbit space of the group
into a finite-dimensional Euclidean space. We show that such an embedding
exists for every crystallographic group, and that it factors functions through
a generalization of a manifold called an orbifold. We describe algorithms that,
given a standardized description of the group, compute the Fourier basis and an
embedding map. As examples, we construct crystallographically invariant neural
networks, kernel machines, and Gaussian processes.
\\ ( https://arxiv.org/abs/2306.05261 ,  25365kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05283 (*cross-listing*)
Date: Sun, 28 May 2023 22:21:31 GMT   (743kb,D)

Title: A Method for Detecting Murmurous Heart Sounds based on Self-similar
 Properties
Authors: Dixon Vimalajeewa, Chihoon Lee, Brani Vidakovic
Categories: eess.SP cs.LG
\\
 A heart murmur is an atypical sound produced by the flow of blood through the
heart. It can be a sign of a serious heart condition, so detecting heart
murmurs is critical for identifying and managing cardiovascular diseases.
However, current methods for identifying murmurous heart sounds do not fully
utilize the valuable insights that can be gained by exploring intrinsic
properties of heart sound signals. To address this issue, this study proposes a
new discriminatory set of multiscale features based on the self-similarity and
complexity properties of heart sounds, as derived in the wavelet domain.
Self-similarity is characterized by assessing fractal behaviors, while
complexity is explored by calculating wavelet entropy. We evaluated the
diagnostic performance of these proposed features for detecting murmurs using a
set of standard classifiers. When applied to a publicly available heart sound
dataset, our proposed wavelet-based multiscale features achieved comparable
performance to existing methods with fewer features. This suggests that
self-similarity and complexity properties in heart sounds could be potential
biomarkers for improving the accuracy of murmur detection.
\\ ( https://arxiv.org/abs/2306.05283 ,  743kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05285 (*cross-listing*)
Date: Tue, 30 May 2023 15:12:59 GMT   (1349kb,D)

Title: Unsupervised Statistical Feature-Guided Diffusion Model for Sensor-based
 Human Activity Recognition
Authors: Si Zuo, Vitor Fortes Rey, Sungho Suh, Stephan Sigg, Paul Lukowicz
Categories: eess.SP cs.LG
\\
 Recognizing human activities from sensor data is a vital task in various
domains, but obtaining diverse and labeled sensor data remains challenging and
costly. In this paper, we propose an unsupervised statistical feature-guided
diffusion model for sensor-based human activity recognition. The proposed
method aims to generate synthetic time-series sensor data without relying on
labeled data, addressing the scarcity and annotation difficulties associated
with real-world sensor data. By conditioning the diffusion model on statistical
information such as mean, standard deviation, Z-score, and skewness, we
generate diverse and representative synthetic sensor data. We conducted
experiments on public human activity recognition datasets and compared the
proposed method to conventional oversampling methods and state-of-the-art
generative adversarial network methods. The experimental results demonstrate
that the proposed method can improve the performance of human activity
recognition and outperform existing techniques.
\\ ( https://arxiv.org/abs/2306.05285 ,  1349kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05286 (*cross-listing*)
Date: Sat, 3 Jun 2023 02:45:03 GMT   (7050kb,D)

Title: JGAT: a joint spatio-temporal graph attention model for brain decoding
Authors: Han Yi Chiu, Liang Zhao, Anqi Wu
Categories: q-bio.NC cs.LG
\\
 The decoding of brain neural networks has been an intriguing topic in
neuroscience for a well-rounded understanding of different types of brain
disorders and cognitive stimuli. Integrating different types of connectivity,
e.g., Functional Connectivity (FC) and Structural Connectivity (SC), from
multi-modal imaging techniques can take their complementary information into
account and therefore have the potential to get better decoding capability.
However, traditional approaches for integrating FC and SC overlook the
dynamical variations, which stand a great chance to over-generalize the brain
neural network. In this paper, we propose a Joint kernel Graph Attention
Network (JGAT), which is a new multi-modal temporal graph attention network
framework. It integrates the data from functional Magnetic Resonance Images
(fMRI) and Diffusion Weighted Imaging (DWI) while preserving the dynamic
information at the same time. We conduct brain-decoding tasks with our JGAT on
four independent datasets: three of 7T fMRI datasets from the Human Connectome
Project (HCP) and one from animal neural recordings. Furthermore, with
Attention Scores (AS) and Frame Scores (FS) computed and learned from the
model, we can locate several informative temporal segments and build meaningful
dynamical pathways along the temporal domain for the HCP datasets. The URL to
the code of JGAT model: https://github.com/BRAINML-GT/JGAT.
\\ ( https://arxiv.org/abs/2306.05286 ,  7050kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05289 (*cross-listing*)
Date: Tue, 30 May 2023 10:32:04 GMT   (6431kb,D)

Title: Predictive and diagnosis models of stroke from hemodynamic signal
 monitoring
Authors: Luis Garc\'ia-Terriza, Jos\'e L. Risco-Mart\'in, Gemma Reig Rosell\'o
 and Jos\'e L. Ayala
Categories: eess.SP cs.LG
Journal-ref: Medical & Biological Engineering & Computing, 59(6), pp. 1325-1337
 (2021)
DOI: 10.1007/s11517-021-02354-6
\\
 This work presents a novel and promising approach to the clinical management
of acute stroke. Using machine learning techniques, our research has succeeded
in developing accurate diagnosis and prediction real-time models from
hemodynamic data. These models are able to diagnose stroke subtype with 30
minutes of monitoring, to predict the exitus during the first 3 hours of
monitoring, and to predict the stroke recurrence in just 15 minutes of
monitoring. Patients with difficult access to a \acrshort{CT} scan, and all
patients that arrive at the stroke unit of a specialized hospital will benefit
from these positive results. The results obtained from the real-time developed
models are the following: stroke diagnosis around $98\%$ precision ($97.8\%$
Sensitivity, $99.5\%$ Specificity), exitus prediction with $99.8\%$ precision
($99.8\%$ Sens., $99.9\%$ Spec.) and $98\%$ precision predicting stroke
recurrence ($98\%$ Sens., $99\%$ Spec.).
\\ ( https://arxiv.org/abs/2306.05289 ,  6431kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05292 (*cross-listing*)
Date: Thu, 8 Jun 2023 15:36:02 GMT   (1378kb,D)

Title: Safe Collaborative Filtering
Authors: Riku Togashi, Tatsushi Oka, Naoto Ohsaka, Tetsuro Morimura
Categories: cs.IR cs.LG
\\
 Excellent tail performance is crucial for modern machine learning tasks, such
as algorithmic fairness, class imbalance, and risk-sensitive decision making,
as it ensures the effective handling of challenging samples within a dataset.
Tail performance is also a vital determinant of success for personalised
recommender systems to reduce the risk of losing users with low satisfaction.
This study introduces a "safe" collaborative filtering method that prioritises
recommendation quality for less-satisfied users rather than focusing on the
average performance. Our approach minimises the conditional value at risk
(CVaR), which represents the average risk over the tails of users' loss. To
overcome computational challenges for web-scale recommender systems, we develop
a robust yet practical algorithm that extends the most scalable method,
implicit alternating least squares (iALS). Empirical evaluation on real-world
datasets demonstrates the excellent tail performance of our approach while
maintaining competitive computational efficiency.
\\ ( https://arxiv.org/abs/2306.05292 ,  1378kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05294 (*cross-listing*)
Date: Wed, 7 Jun 2023 08:18:56 GMT   (6471kb,D)

Title: Deep Learning with Partially Labeled Data for Radio Map Reconstruction
Authors: Alkesandra Malkova and Massih-Reza Amini and Benoit Denis and
 Christophe Villien
Categories: eess.SP cs.IT cs.LG math.IT
Comments: 42 pages, 39 figures
\\
 In this paper, we address the problem of Received Signal Strength map
reconstruction based on location-dependent radio measurements and utilizing
side knowledge about the local region; for example, city plan, terrain height,
gateway position. Depending on the quantity of such prior side information, we
employ Neural Architecture Search to find an optimized Neural Network model
with the best architecture for each of the supposed settings. We demonstrate
that using additional side information enhances the final accuracy of the
Received Signal Strength map reconstruction on three datasets that correspond
to three major cities, particularly in sub-areas near the gateways where larger
variations of the average received signal power are typically observed.
\\ ( https://arxiv.org/abs/2306.05294 ,  6471kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05307 (*cross-listing*)
Date: Thu, 8 Jun 2023 15:56:57 GMT   (10345kb,D)

Title: Are fairness metric scores enough to assess discrimination biases in
 machine learning?
Authors: Fanny Jourdan, Laurent Risser, Jean-Michel Loubes, Nicholas Asher
Categories: cs.CL cs.CY cs.LG stat.ML
Comments: Accepted for publication at Third Workshop on Trustworthy Natural
 Language Processing, ACL 2023
\\
 This paper presents novel experiments shedding light on the shortcomings of
current metrics for assessing biases of gender discrimination made by machine
learning algorithms on textual data. We focus on the Bios dataset, and our
learning task is to predict the occupation of individuals, based on their
biography. Such prediction tasks are common in commercial Natural Language
Processing (NLP) applications such as automatic job recommendations. We address
an important limitation of theoretical discussions dealing with group-wise
fairness metrics: they focus on large datasets, although the norm in many
industrial NLP applications is to use small to reasonably large linguistic
datasets for which the main practical constraint is to get a good prediction
accuracy. We then question how reliable are different popular measures of bias
when the size of the training set is simply sufficient to learn reasonably
accurate predictions. Our experiments sample the Bios dataset and learn more
than 200 models on different sample sizes. This allows us to statistically
study our results and to confirm that common gender bias indices provide
diverging and sometimes unreliable results when applied to relatively small
training and test samples. This highlights the crucial importance of variance
calculations for providing sound results in this field.
\\ ( https://arxiv.org/abs/2306.05307 ,  10345kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05319 (*cross-listing*)
Date: Thu, 8 Jun 2023 16:11:57 GMT   (2764kb,D)

Title: RNN-Based GNSS Positioning using Satellite Measurement Features and
 Pseudorange Residuals
Authors: Ibrahim Sbeity, Christophe Villien, Beno\^it Denis, and E. Veronica
 Belmega
Categories: eess.SP cs.LG
\\
 In the Global Navigation Satellite System (GNSS) context, the growing number
of available satellites has lead to many challenges when it comes to choosing
the most accurate pseudorange contributions, given the strong impact of biased
measurements on positioning accuracy, particularly in single-epoch scenarios.
This work leverages the potential of machine learning in predicting link-wise
measurement quality factors and, hence, optimize measurement weighting. For
this purpose, we use a customized matrix composed of heterogeneous features
such as conditional pseudorange residuals and per-link satellite metrics (e.g.,
carrier-to-noise power density ratio and its empirical statistics, satellite
elevation, carrier phase lock time). This matrix is then fed as an input to a
recurrent neural network (RNN) (i.e., a long-short term memory (LSTM) network).
Our experimental results on real data, obtained from extensive field
measurements, demonstrate the high potential of our proposed solution being
able to outperform traditional measurements weighting and selection strategies
from state-of-the-art.
\\ ( https://arxiv.org/abs/2306.05319 ,  2764kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05321 (*cross-listing*)
Date: Thu, 8 Jun 2023 16:13:29 GMT   (10171kb,D)

Title: Real-time whole-heart electromechanical simulations using Latent Neural
 Ordinary Differential Equations
Authors: Matteo Salvador, Marina Strocchi, Francesco Regazzoni, Luca Dede',
 Steven Niederer, Alfio Quarteroni
Categories: math.NA cs.LG cs.NA
\\
 Cardiac digital twins provide a physics and physiology informed framework to
deliver predictive and personalized medicine. However, high-fidelity
multi-scale cardiac models remain a barrier to adoption due to their extensive
computational costs and the high number of model evaluations needed for
patient-specific personalization. Artificial Intelligence-based methods can
make the creation of fast and accurate whole-heart digital twins feasible. In
this work, we use Latent Neural Ordinary Differential Equations (LNODEs) to
learn the temporal pressure-volume dynamics of a heart failure patient. Our
surrogate model based on LNODEs is trained from 400 3D-0D whole-heart
closed-loop electromechanical simulations while accounting for 43 model
parameters, describing single cell through to whole organ and cardiovascular
hemodynamics. The trained LNODEs provides a compact and efficient
representation of the 3D-0D model in a latent space by means of a feedforward
fully-connected Artificial Neural Network that retains 3 hidden layers with 13
neurons per layer and allows for 300x real-time numerical simulations of the
cardiac function on a single processor of a standard laptop. This surrogate
model is employed to perform global sensitivity analysis and robust parameter
estimation with uncertainty quantification in 3 hours of computations, still on
a single processor. We match pressure and volume time traces unseen by the
LNODEs during the training phase and we calibrate 4 to 11 model parameters
while also providing their posterior distribution. This paper introduces the
most advanced surrogate model of cardiac function available in the literature
and opens new important venues for parameter calibration in cardiac digital
twins.
\\ ( https://arxiv.org/abs/2306.05321 ,  10171kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05363 (*cross-listing*)
Date: Thu, 8 Jun 2023 17:07:24 GMT   (89kb,D)

Title: Subject clustering by IF-PCA and several recent methods
Authors: Dieyi Chen, Jiashun Jin, Zheng Tracy Ke
Categories: stat.ME cs.LG math.ST stat.AP stat.TH
\\
 Subject clustering (i.e., the use of measured features to cluster subjects,
such as patients or cells, into multiple groups) is a problem of great
interest. In recent years, many approaches were proposed, among which
unsupervised deep learning (UDL) has received a great deal of attention. Two
interesting questions are (a) how to combine the strengths of UDL and other
approaches, and (b) how these approaches compare to one other.
 We combine Variational Auto-Encoder (VAE), a popular UDL approach, with the
recent idea of Influential Feature PCA (IF-PCA), and propose IF-VAE as a new
method for subject clustering. We study IF-VAE and compare it with several
other methods (including IF-PCA, VAE, Seurat, and SC3) on $10$ gene microarray
data sets and $8$ single-cell RNA-seq data sets. We find that IF-VAE
significantly improves over VAE, but still underperforms IF-PCA. We also find
that IF-PCA is quite competitive, which slightly outperforms Seurat and SC3
over the $8$ single-cell data sets. IF-PCA is conceptually simple and permits
delicate analysis. We demonstrate that IF-PCA is capable of achieving the phase
transition in a Rare/Weak model. Comparatively, Seurat and SC3 are more complex
and theoretically difficult to analyze (for these reasons, their optimality
remains unclear).
\\ ( https://arxiv.org/abs/2306.05363 ,  89kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05373 (*cross-listing*)
Date: Mon, 5 Jun 2023 13:52:56 GMT   (160kb)

Title: A Computational Analysis of Oral Argument in the Supreme Court
Authors: Gregory M. Dickinson
Categories: cs.CY cs.LG
Journal-ref: 28 Cornell J.L. & Pub. Pol'y 449 (2019)
\\
 As the most public component of the Supreme Court's decision-making process,
oral argument receives an out-sized share of attention in the popular media.
Despite its prominence, however, the basic function and operation of oral
argument as an institution remains poorly understood, as political scientists
and legal scholars continue to debate even the most fundamental questions about
its role.
 Past study of oral argument has tended to focus on discrete, quantifiable
attributes of oral argument, such as the number of questions asked to each
advocate, the party of the Justices' appointing president, or the ideological
implications of the case on appeal. Such studies allow broad generalizations
about oral argument and judicial decision making: Justices tend to vote in
accordance with their ideological preferences, and they tend to ask more
questions when they are skeptical of a party's position. But they tell us
little about the actual goings on at oral argument -- the running dialog
between Justice and advocate that is the heart of the institution.
 This Article fills that void, using machine learning techniques to, for the
first time, construct predictive models of judicial decision making based not
on oral argument's superficial features or on factors external to oral
argument, such as where the case falls on a liberal-conservative spectrum, but
on the actual content of the oral argument itself -- the Justices' questions to
each side. The resultant models offer an important new window into aspects of
oral argument that have long resisted empirical study, including the Justices'
individual questioning styles, how each expresses skepticism, and which of the
Justices' questions are most central to oral argument dialog.
\\ ( https://arxiv.org/abs/2306.05373 ,  160kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05375 (*cross-listing*)
Date: Tue, 23 May 2023 17:25:51 GMT   (1573kb,D)

Title: Sequential Graph Neural Networks for Source Code Vulnerability
 Identification
Authors: Ammar Ahmed, Anwar Said, Mudassir Shabbir, Xenofon Koutsoukos
Categories: cs.CR cs.LG
Comments: 7 pages paper presented at HotSoS2023 conference
\\
 Vulnerability identification constitutes a task of high importance for cyber
security. It is quite helpful for locating and fixing vulnerable functions in
large applications. However, this task is rather challenging owing to the
absence of reliable and adequately managed datasets and learning models.
Existing solutions typically rely on human expertise to annotate datasets or
specify features, which is prone to error. In addition, the learning models
have a high rate of false positives. To bridge this gap, in this paper, we
present a properly curated C/C++ source code vulnerability dataset, denoted as
CVEFunctionGraphEmbeddings (CVEFGE), to aid in developing models. CVEFGE is
automatically crawled from the CVE database, which contains authentic and
publicly disclosed source code vulnerabilities. We also propose a learning
framework based on graph neural networks, denoted SEquential Graph Neural
Network (SEGNN) for learning a large number of code semantic representations.
SEGNN consists of a sequential learning module, graph convolution, pooling, and
fully connected layers. Our evaluations on two datasets and four baseline
methods in a graph classification setting demonstrate state-of-the-art results.
\\ ( https://arxiv.org/abs/2306.05375 ,  1573kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04906 (*cross-listing*)
Date: Thu, 8 Jun 2023 03:20:30 GMT   (3263kb)

Title: Spectrum Sharing between High Altitude Platform Network and Terrestrial
 Network: Modeling and Performance Analysis
Authors: Zhiqing Wei, Lin Wang, Zhan Gao, Huici Wu, Ning Zhang, Kaifeng Han,
 and Zhiyong Feng
Categories: cs.IT cs.RO math.IT
\\
 Achieving seamless global coverage is one of the ultimate goals of
space-air-ground integrated network, as a part of which High Altitude Platform
(HAP) network can provide wide-area coverage. However, deploying a large number
of HAPs will lead to severe congestion of existing frequency bands. Spectrum
sharing improves spectrum utilization. The coverage performance improvement and
interference caused by spectrum sharing need to be investigated. To this end,
this paper analyzes the performance of spectrum sharing between HAP network and
terrestrial network. We firstly generalize the Poisson Point Process (PPP) to
curves, surfaces and manifolds to model the distribution of terrestrial Base
Stations (BSs) and HAPs. Then, the closed-form expressions for coverage
probability of HAP network and terrestrial network are derived based on
differential geometry and stochastic geometry. We verify the accuracy of
closed-form expressions by Monte Carlo simulation. The results show that HAP
network has less interference to terrestrial network. Low height and suitable
deployment density can improve the coverage probability and transmission
capacity of HAP network.
\\ ( https://arxiv.org/abs/2306.04906 ,  3263kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05203 (*cross-listing*)
Date: Thu, 8 Jun 2023 13:59:09 GMT   (3311kb,D)

Title: A cognitive process approach to modeling gap acceptance in overtaking
Authors: Samir H.A. Mohammad, Haneen Farah, Arkady Zgonnikov
Categories: q-bio.NC cs.RO
\\
 Driving automation holds significant potential for enhancing traffic safety.
However, effectively handling interactions with human drivers in mixed traffic
remains a challenging task. Several models exist that attempt to capture human
behavior in traffic interactions, often focusing on gap acceptance. However, it
is not clear how models of an individual driver's gap acceptance can be
translated to dynamic human-AV interactions in the context of high-speed
scenarios like overtaking. In this study, we address this issue by employing a
cognitive process approach to describe the dynamic interactions by the oncoming
vehicle during overtaking maneuvers. Our findings reveal that by incorporating
an initial decision-making bias dependent on the initial velocity into existing
drift-diffusion models, we can accurately describe the qualitative patterns of
overtaking gap acceptance observed previously. Our results demonstrate the
potential of the cognitive process approach in modeling human overtaking
behavior when the oncoming vehicle is an AV. To this end, this study
contributes to the development of effective strategies for ensuring safe and
efficient overtaking interactions between human drivers and AVs.
\\ ( https://arxiv.org/abs/2306.05203 ,  3311kb)
%%--%%--%%--%%--%%--%%--%%--%%--%%--%%--%%--%%--%%--%%--%%--%%--%%--%%--%%--%%
------------------------------------------------------------------------------
\\
arXiv:2212.10802
replaced with revised version Tue, 6 Jun 2023 05:08:45 GMT   (41007kb)

Title: BTS: Bifold Teacher-Student in Semi-Supervised Learning for Indoor
 Two-Room Presence Detection Under Time-Varying CSI
Authors: Li-Hsiang Shen, Kai-Jui Chen, An-Hung Hsiao, Kai-Ten Feng
Categories: cs.AI cs.LG eess.SP
\\ ( https://arxiv.org/abs/2212.10802 ,  41007kb)
------------------------------------------------------------------------------
\\
arXiv:2303.02265
replaced with revised version Wed, 7 Jun 2023 21:10:12 GMT   (786kb,D)

Title: Learning to Influence Human Behavior with Offline Reinforcement Learning
Authors: Joey Hong, Anca Dragan, Sergey Levine
Categories: cs.AI cs.LG
Comments: 12 pages, 8 figures
\\ ( https://arxiv.org/abs/2303.02265 ,  786kb)
------------------------------------------------------------------------------
\\
arXiv:2303.06516
replaced with revised version Wed, 7 Jun 2023 20:06:02 GMT   (290kb,D)

Title: Efficient Computation of Shap Explanation Scores for Neural Network
 Classifiers via Knowledge Compilation
Authors: Leopoldo Bertossi and Jorge E. Leon
Categories: cs.AI cs.DB cs.LG
Comments: Conference submission. It replaces the previously uploaded paper
 "Opening Up the Neural Network Classifier for Shap Score Computation", by the
 same authors. This version considerably revised the previous one
\\ ( https://arxiv.org/abs/2303.06516 ,  290kb)
------------------------------------------------------------------------------
\\
arXiv:2305.10782
replaced with revised version Thu, 8 Jun 2023 00:42:10 GMT   (7516kb,D)

Title: Numeric Magnitude Comparison Effects in Large Language Models
Authors: Raj Sanjay Shah, Vijay Marupudi, Reba Koenen, Khushi Bhardwaj, Sashank
 Varma
Categories: cs.AI
Comments: ACL findings 2023
\\ ( https://arxiv.org/abs/2305.10782 ,  7516kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02019
replaced with revised version Wed, 7 Jun 2023 20:15:59 GMT   (732kb,D)

Title: Generative Adversarial Networks for Data Augmentation
Authors: Angona Biswas, MD Abdullah Al Nasim, Al Imran, Anika Tabassum Sejuty,
 Fabliha Fairooz, Sai Puppala, Sajedul Talukder
Categories: cs.AI
Comments: 13 pages, 6 figures, 1 table; Acceptance of the chapter for the
 Springer book "Data-driven approaches to medical imaging"
\\ ( https://arxiv.org/abs/2306.02019 ,  732kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02055
replaced with revised version Wed, 7 Jun 2023 19:31:06 GMT   (357kb,D)

Title: Case Studies on X-Ray Imaging, MRI and Nuclear Imaging
Authors: Shuvra Sarker, Angona Biswas, MD Abdullah Al Nasim, Md Shahin Ali, Sai
 Puppala, Sajedul Talukder
Categories: cs.AI
Comments: 15 pages, 3 figures, 4 tables; Acceptance of the chapter for the
 Springer book "Data-driven approaches to medical imaging"
\\ ( https://arxiv.org/abs/2306.02055 ,  357kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03604
replaced with revised version Thu, 8 Jun 2023 07:35:59 GMT   (588kb,D)

Title: Enabling Intelligent Interactions between an Agent and an LLM: A
 Reinforcement Learning Approach
Authors: Bin Hu, Chenyang Zhao, Pu Zhang, Zihao Zhou, Yuanhang Yang, Zenglin
 Xu, Bin Liu
Categories: cs.AI
Comments: 10 pages
\\ ( https://arxiv.org/abs/2306.03604 ,  588kb)
------------------------------------------------------------------------------
\\
arXiv:2112.08691
replaced with revised version Thu, 8 Jun 2023 09:04:56 GMT   (5394kb,D)

Title: Towards Robust Neural Image Compression: Adversarial Attack and Model
 Finetuning
Authors: Tong Chen and Zhan Ma
Categories: cs.CV cs.MM eess.IV
DOI: 10.1109/TCSVT.2023.3276442
\\ ( https://arxiv.org/abs/2112.08691 ,  5394kb)
------------------------------------------------------------------------------
\\
arXiv:2207.03132
replaced with revised version Thu, 8 Jun 2023 01:32:38 GMT   (3420kb,D)

Title: Style Interleaved Learning for Generalizable Person Re-identification
Authors: Wentao Tan and Changxing Ding and Pengfei Wang and Mingming Gong and
 Kui Jia
Categories: cs.CV
Comments: accepted version to IEEE Transactions on Multimedia
\\ ( https://arxiv.org/abs/2207.03132 ,  3420kb)
------------------------------------------------------------------------------
\\
arXiv:2208.08984
replaced with revised version Thu, 8 Jun 2023 06:35:33 GMT   (8918kb,D)

Title: Open-Vocabulary Universal Image Segmentation with MaskCLIP
Authors: Zheng Ding, Jieke Wang, Zhuowen Tu
Categories: cs.CV
Comments: ICML 2023 Camera Ready
\\ ( https://arxiv.org/abs/2208.08984 ,  8918kb)
------------------------------------------------------------------------------
\\
arXiv:2209.05044
replaced with revised version Thu, 8 Jun 2023 05:24:03 GMT   (1560kb,D)

Title: Predicting the Next Action by Modeling the Abstract Goal
Authors: Debaditya Roy and Basura Fernando
Categories: cs.CV cs.AI
Comments: This work has been submitted to the IEEE for possible publication.
 Copyright may be transferred without notice, after which this version may no
 longer be accessible
\\ ( https://arxiv.org/abs/2209.05044 ,  1560kb)
------------------------------------------------------------------------------
\\
arXiv:2210.06379
replaced with revised version Thu, 8 Jun 2023 15:42:13 GMT   (4067kb,D)

Title: One does not fit all! On the Complementarity of Vision Encoders for
 Vision and Language Tasks
Authors: Gregor Geigle, Chen Cecilia Liu, Jonas Pfeiffer and Iryna Gurevych
Categories: cs.CV cs.CL
Comments: Repl4NLP 2023
\\ ( https://arxiv.org/abs/2210.06379 ,  4067kb)
------------------------------------------------------------------------------
\\
arXiv:2210.07601
replaced with revised version Thu, 8 Jun 2023 08:57:28 GMT   (890kb,D)

Title: MCTNet: A Multi-Scale CNN-Transformer Network for Change Detection in
 Optical Remote Sensing Images
Authors: Weiming Li, Lihui Xue, Xueqian Wang, and Gang Li
Categories: cs.CV
\\ ( https://arxiv.org/abs/2210.07601 ,  890kb)
------------------------------------------------------------------------------
\\
arXiv:2210.10897
replaced with revised version Thu, 8 Jun 2023 14:47:19 GMT   (2768kb,D)

Title: Window-Based Distribution Shift Detection for Deep Neural Networks
Authors: Guy Bar-Shalom, Yonatan Geifman, Ran El-Yaniv
Categories: cs.CV
\\ ( https://arxiv.org/abs/2210.10897 ,  2768kb)
------------------------------------------------------------------------------
\\
arXiv:2211.13226
replaced with revised version Thu, 8 Jun 2023 06:14:30 GMT   (48396kb,D)

Title: ClimateNeRF: Extreme Weather Synthesis in Neural Radiance Field
Authors: Yuan Li, Zhi-Hao Lin, David Forsyth, Jia-Bin Huang, Shenlong Wang
Categories: cs.CV cs.GR
Comments: project page: https://climatenerf.github.io/
\\ ( https://arxiv.org/abs/2211.13226 ,  48396kb)
------------------------------------------------------------------------------
\\
arXiv:2211.14154
replaced with revised version Thu, 8 Jun 2023 04:16:45 GMT   (23019kb,D)

Title: Interaction Visual Transformer for Egocentric Action Anticipation
Authors: Debaditya Roy, Ramanathan Rajendiran and Basura Fernando
Categories: cs.CV
Comments: Top of the public leaderboard on EK100 Action Anticipation
 https://codalab.lisn.upsaclay.fr/competitions/702#results
\\ ( https://arxiv.org/abs/2211.14154 ,  23019kb)
------------------------------------------------------------------------------
\\
arXiv:2212.09262
replaced with revised version Thu, 8 Jun 2023 15:20:36 GMT   (33723kb,D)

Title: Out-of-domain GAN inversion via Invertibility Decomposition for
 Photo-Realistic Human Face Manipulation
Authors: Xin Yang, Xiaogang Xu, Yingcong Chen
Categories: cs.CV
\\ ( https://arxiv.org/abs/2212.09262 ,  33723kb)
------------------------------------------------------------------------------
\\
arXiv:2212.14871
replaced with revised version Wed, 7 Jun 2023 18:00:48 GMT   (32836kb,D)

Title: Equivariant Light Field Convolution and Transformer
Authors: Yinshuang Xu, Jiahui Lei, Kostas Daniilidis
Categories: cs.CV
Comments: 46 pages
\\ ( https://arxiv.org/abs/2212.14871 ,  32836kb)
------------------------------------------------------------------------------
\\
arXiv:2301.02311
replaced with revised version Thu, 8 Jun 2023 14:29:35 GMT   (1837kb,D)

Title: HierVL: Learning Hierarchical Video-Language Embeddings
Authors: Kumar Ashutosh, Rohit Girdhar, Lorenzo Torresani, Kristen Grauman
Categories: cs.CV
Comments: CVPR 2023
\\ ( https://arxiv.org/abs/2301.02311 ,  1837kb)
------------------------------------------------------------------------------
\\
arXiv:2301.04218
replaced with revised version Thu, 8 Jun 2023 17:13:55 GMT   (6714kb,D)

Title: Leveraging Diffusion For Strong and High Quality Face Morphing Attacks
Authors: Zander Blasingame and Chen Liu
Categories: cs.CV cs.CR cs.LG
Comments: Under Review
\\ ( https://arxiv.org/abs/2301.04218 ,  6714kb)
------------------------------------------------------------------------------
\\
arXiv:2302.03629
replaced with revised version Thu, 8 Jun 2023 01:09:17 GMT   (94kb)

Title: Principlism Guided Responsible Data Curation
Authors: Jerone T. A. Andrews and Dora Zhao and William Thong and Apostolos
 Modas and Orestis Papakyriakopoulos and Alice Xiang
Categories: cs.CV cs.AI cs.DB cs.LG
\\ ( https://arxiv.org/abs/2302.03629 ,  94kb)
------------------------------------------------------------------------------
\\
arXiv:2302.04304
replaced with revised version Thu, 8 Jun 2023 09:21:05 GMT   (11591kb,D)

Title: Q-Diffusion: Quantizing Diffusion Models
Authors: Xiuyu Li, Yijiang Liu, Long Lian, Huanrui Yang, Zhen Dong, Daniel
 Kang, Shanghang Zhang, Kurt Keutzer
Categories: cs.CV cs.LG
Comments: The code is available at https://github.com/Xiuyu-Li/q-diffusion
\\ ( https://arxiv.org/abs/2302.04304 ,  11591kb)
------------------------------------------------------------------------------
\\
arXiv:2302.06848
replaced with revised version Thu, 8 Jun 2023 01:49:33 GMT   (23418kb)

Title: YOWOv2: A Stronger yet Efficient Multi-level Detection Framework for
 Real-time Spatio-temporal Action Detection
Authors: Jianhua Yang and Kun Dai
Categories: cs.CV
\\ ( https://arxiv.org/abs/2302.06848 ,  23418kb)
------------------------------------------------------------------------------
\\
arXiv:2303.06138
replaced with revised version Thu, 8 Jun 2023 06:19:20 GMT   (2519kb,D)

Title: Learning Object-Centric Neural Scattering Functions for Free-Viewpoint
 Relighting and Scene Composition
Authors: Hong-Xing Yu, Michelle Guo, Alireza Fathi, Yen-Yu Chang, Eric Ryan
 Chan, Ruohan Gao, Thomas Funkhouser, Jiajun Wu
Categories: cs.CV cs.GR
Comments: Journal extension of arXiv:2012.08503 (TMLR 2023). The first two
 authors contributed equally to this work. Project page:
 https://kovenyu.com/osf/
Journal-ref: Transactions on Machine Learning Research (TMLR), 2023
\\ ( https://arxiv.org/abs/2303.06138 ,  2519kb)
------------------------------------------------------------------------------
\\
arXiv:2303.09026
replaced with revised version Thu, 8 Jun 2023 03:14:27 GMT   (1461kb)

Title: Commonsense Knowledge Assisted Deep Learning with Application to
 Size-Related Fine-Grained Object Detection
Authors: Pu Zhang, Bin Liu
Categories: cs.CV cs.AI
Comments: 15 pages
\\ ( https://arxiv.org/abs/2303.09026 ,  1461kb)
------------------------------------------------------------------------------
\\
arXiv:2303.12419
replaced with revised version Thu, 8 Jun 2023 09:36:40 GMT   (6477kb,D)

Title: BiCro: Noisy Correspondence Rectification for Multi-modality Data via
 Bi-directional Cross-modal Similarity Consistency
Authors: Shuo Yang, Zhaopan Xu, Kai Wang, Yang You, Hongxun Yao, Tongliang Liu,
 Min Xu
Categories: cs.CV
Comments: CVPR 2023
\\ ( https://arxiv.org/abs/2303.12419 ,  6477kb)
------------------------------------------------------------------------------
\\
arXiv:2305.07307
replaced with revised version Thu, 8 Jun 2023 07:18:47 GMT   (2249kb,D)

Title: Self-Learning Symmetric Multi-view Probabilistic Clustering
Authors: Junjie Liu, Junlong Liu, Rongxin Jiang, Yaowu Chen, Chen Shen, Jieping
 Ye
Categories: cs.CV
\\ ( https://arxiv.org/abs/2305.07307 ,  2249kb)
------------------------------------------------------------------------------
\\
arXiv:2305.07895
replaced with revised version Thu, 8 Jun 2023 15:14:16 GMT   (6183kb,D)

Title: On the Hidden Mystery of OCR in Large Multimodal Models
Authors: Yuliang Liu, Zhang Li, Hongliang Li, Wenwen Yu, Mingxin Huang, Dezhi
 Peng, Mingyu Liu, Mingrui Chen, Chunyuan Li, Cheng-lin Liu, Lianwen Jin,
 Xiang Bai
Categories: cs.CV cs.CL
\\ ( https://arxiv.org/abs/2305.07895 ,  6183kb)
------------------------------------------------------------------------------
\\
arXiv:2305.10657
replaced with revised version Thu, 8 Jun 2023 01:26:05 GMT   (11191kb,D)

Title: PTQD: Accurate Post-Training Quantization for Diffusion Models
Authors: Yefei He, Luping Liu, Jing Liu, Weijia Wu, Hong Zhou, Bohan Zhuang
Categories: cs.CV
Comments: 18 pages, 14 figures
\\ ( https://arxiv.org/abs/2305.10657 ,  11191kb)
------------------------------------------------------------------------------
\\
arXiv:2305.16283
replaced with revised version Thu, 8 Jun 2023 10:00:21 GMT   (34071kb,D)

Title: CommonScenes: Generating Commonsense 3D Indoor Scenes with Scene Graphs
Authors: Guangyao Zhai, Evin P{\i}nar \"Ornek, Shun-Cheng Wu, Yan Di, Federico
 Tombari, Nassir Navab, Benjamin Busam
Categories: cs.CV
Comments: 25 pages. Video: https://youtu.be/KowMOkI32N4
\\ ( https://arxiv.org/abs/2305.16283 ,  34071kb)
------------------------------------------------------------------------------
\\
arXiv:2305.17303
replaced with revised version Thu, 8 Jun 2023 06:00:55 GMT   (6456kb,D)

Title: Distilling BlackBox to Interpretable models for Efficient Transfer
 Learning
Authors: Shantanu Ghosh, Ke Yu, Kayhan Batmanghelich
Categories: cs.CV cs.LG
Comments: MICCAI, 2023, Early accept
\\ ( https://arxiv.org/abs/2305.17303 ,  6456kb)
------------------------------------------------------------------------------
\\
arXiv:2305.17797
replaced with revised version Thu, 8 Jun 2023 09:19:13 GMT   (3556kb,D)

Title: T2FNorm: Extremely Simple Scaled Train-time Feature Normalization for
 OOD Detection
Authors: Sudarshan Regmi, Bibek Panthi, Sakar Dotel, Prashnna K. Gyawali,
 Danail Stoyanov, Binod Bhattarai
Categories: cs.CV
\\ ( https://arxiv.org/abs/2305.17797 ,  3556kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03413
replaced with revised version Thu, 8 Jun 2023 08:15:06 GMT   (20244kb,D)

Title: DVIS: Decoupled Video Instance Segmentation Framework
Authors: Tao Zhang, Xingye Tian, Yu Wu, Shunping Ji, Xuebo Wang, Yuan Zhang,
 Pengfei Wan
Categories: cs.CV
\\ ( https://arxiv.org/abs/2306.03413 ,  20244kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03414
replaced with revised version Thu, 8 Jun 2023 02:50:03 GMT   (0kb,I)

Title: DreamSparse: Escaping from Plato's Cave with 2D Diffusion Model Given
 Sparse Views
Authors: Paul Yoo, Jiaxian Guo, Yutaka Matsuo, Shixiang Shane Gu
Categories: cs.CV cs.AI cs.GR
Comments: Some Mistakes
\\ ( https://arxiv.org/abs/2306.03414 ,  0kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03437
replaced with revised version Thu, 8 Jun 2023 03:22:59 GMT   (9047kb,D)

Title: DFormer: Diffusion-guided Transformer for Universal Image Segmentation
Authors: Hefeng Wang, Jiale Cao, Rao Muhammad Anwer, Jin Xie, Fahad Shahbaz
 Khan, Yanwei Pang
Categories: cs.CV
Comments: Project website: https://github.com/cp3wan/DFormer
\\ ( https://arxiv.org/abs/2306.03437 ,  9047kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04091
replaced with revised version Thu, 8 Jun 2023 08:19:27 GMT   (421kb,D)

Title: 1st Place Solution for PVUW Challenge 2023: Video Panoptic Segmentation
Authors: Tao Zhang and Xingye Tian and Haoran Wei and Yu Wu and Shunping Ji and
 Xuebo Wang and Xin Tao and Yuan Zhang and Pengfei Wan
Categories: cs.CV
\\ ( https://arxiv.org/abs/2306.04091 ,  421kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04236
replaced with revised version Thu, 8 Jun 2023 02:41:19 GMT   (18713kb,D)

Title: Flare7K++: Mixing Synthetic and Real Datasets for Nighttime Flare
 Removal and Beyond
Authors: Yuekun Dai, Chongyi Li, Shangchen Zhou, Ruicheng Feng, Yihang Luo,
 Chen Change Loy
Categories: cs.CV eess.IV
Comments: Extension of arXiv:2210.06570; Project page at
 https://ykdai.github.io/projects/Flare7K
\\ ( https://arxiv.org/abs/2306.04236 ,  18713kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04244
replaced with revised version Thu, 8 Jun 2023 06:30:36 GMT   (6347kb,D)

Title: Coarse Is Better? A New Pipeline Towards Self-Supervised Learning with
 Uncurated Images
Authors: Ke Zhu, Yin-Yin He, Jianxin Wu
Categories: cs.CV
\\ ( https://arxiv.org/abs/2306.04244 ,  6347kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04387
replaced with revised version Thu, 8 Jun 2023 13:44:24 GMT   (3659kb,D)

Title: M$^3$IT: A Large-Scale Dataset towards Multi-Modal Multilingual
 Instruction Tuning
Authors: Lei Li, Yuwei Yin, Shicheng Li, Liang Chen, Peiyi Wang, Shuhuai Ren,
 Mukai Li, Yazheng Yang, Jingjing Xu, Xu Sun, Lingpeng Kong, Qi Liu
Categories: cs.CV cs.CL
Comments: Fix dataset url: https://huggingface.co/datasets/MMInstruction/M3IT
 Project: https://m3-it.github.io/
\\ ( https://arxiv.org/abs/2306.04387 ,  3659kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04607
replaced with revised version Thu, 8 Jun 2023 08:21:55 GMT   (8986kb,D)

Title: Integrating Geometric Control into Text-to-Image Diffusion Models for
 High-Quality Detection Data Generation via Text Prompt
Authors: Kai Chen, Enze Xie, Zhe Chen, Lanqing Hong, Zhenguo Li, Dit-Yan Yeung
Categories: cs.CV cs.AI
\\ ( https://arxiv.org/abs/2306.04607 ,  8986kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02183
replaced with revised version Thu, 8 Jun 2023 14:11:30 GMT   (4698kb)

Title: brainlife.io: A decentralized and open source cloud platform to support
 neuroscience research
Authors: Soichi Hayashi, Bradley Caron, Anibal S. Heinsfeld, Sophia
 Vinci-Booher, Brent C. McPherson, Daniel N. Bullock, Giulia Berto, J. Guiomar
 Niso, Sandra Hanekamp, Daniel Levitas, Lindsey Kitchell, Josiah Leong, Filipi
 N. Silva, Serge Koudoro, Hanna Willis, Jasleen Jolly, Derek Pisner, Taylor
 Zuidema, Jan Kurzwaski, Koulla Mikellidou, Aurore Bussalb, Christopher
 Rorden, Conner Victory, Dheeraj Bhatia, D. Baran Aydogan, Frank C. Yeh,
 Franco Delogu, Javier Guaje, Jelle Veraart, Jeremy Fischer, Joshua Faskowitz,
 Maximilien Chaumon, Ricardo Fabrega, David Hunt, Shawn McKee, Shaw T. Brown,
 Stephanie Heyman, Vittorio Iacovella, Amanda Mejia, Daniele Marinazzo,
 Cameron Craddock, Emanuele Olivetti, Jamie Hanson, Paolo Avesani, Eleftherios
 Garyfallidis, Daniel Stanzione, James P. Carson, Robert Henschel, David Y.
 Hancock, Craig A. Stewart, David Schnyer, Damian Eke, Russell A. Poldrack,
 Nathalie George, Holly Bridge, Ilaria Sani, Winrich Freiwald, Aina Puce,
 Nicholas Port, and Franco Pestilli
Categories: cs.DC q-bio.NC q-bio.QM
\\ ( https://arxiv.org/abs/2306.02183 ,  4698kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04586
replaced with revised version Thu, 8 Jun 2023 08:54:21 GMT   (2511kb,D)

Title: Ultra-Precise Synchronization for TDoA-based Localization Using Signals
 of Opportunity
Authors: Thomas Maul, Sebastian Klob, Joerg Robert
Categories: cs.DC eess.SP
\\ ( https://arxiv.org/abs/2306.04586 ,  2511kb)
------------------------------------------------------------------------------
\\
arXiv:2305.11362
replaced with revised version Thu, 8 Jun 2023 04:48:59 GMT   (23kb)

Title: Differentially Private Online Item Pricing
Authors: Joon Suk Huh
Categories: cs.GT cs.CR cs.LG
Comments: 15 pages, v2, typo fixed & proof updated
\\ ( https://arxiv.org/abs/2305.11362 ,  23kb)
------------------------------------------------------------------------------
\\
arXiv:2012.06951
replaced with revised version Thu, 8 Jun 2023 05:58:43 GMT   (7872kb,D)

Title: Attentional-Biased Stochastic Gradient Descent
Authors: Qi Qi, Yi Xu, Rong Jin, Wotao Yin, Tianbao Yang
Categories: cs.LG cs.CV math.OC stat.ML
Comments: 29 pages
Journal-ref: Transanctions on Machine Learning Research, 2023
\\ ( https://arxiv.org/abs/2012.06951 ,  7872kb)
------------------------------------------------------------------------------
\\
arXiv:2109.06919
replaced with revised version Thu, 8 Jun 2023 15:53:37 GMT   (3733kb)

Title: Deploying clinical machine learning? Consider the following...
Authors: Charles Lu, Ken Chang, Praveer Singh, Stuart Pomerantz, Sean Doyle,
 Sujay Kakarmath, Christopher Bridge, Jayashree Kalpathy-Cramer
Categories: cs.LG cs.CY
Comments: Trustworthy AI for Healthcare workshop at AAAI 2022
\\ ( https://arxiv.org/abs/2109.06919 ,  3733kb)
------------------------------------------------------------------------------
\\
arXiv:2112.05445
replaced with revised version Wed, 7 Jun 2023 18:04:04 GMT   (55kb)

Title: Beyond Parallel Pancakes: Quasi-Polynomial Time Guarantees for
 Non-Spherical Gaussian Mixtures
Authors: Rares-Darius Buhai, David Steurer
Categories: cs.LG cs.DS stat.ML
Comments: 67 pages, the arxiv landing page contains a shortened abstract
\\ ( https://arxiv.org/abs/2112.05445 ,  55kb)
------------------------------------------------------------------------------
\\
arXiv:2201.08557
replaced with revised version Thu, 8 Jun 2023 08:35:07 GMT   (8661kb,D)

Title: Toward Enhanced Robustness in Unsupervised Graph Representation
 Learning: A Graph Information Bottleneck Perspective
Authors: Jihong Wang, Minnan Luo, Jundong Li, Ziqi Liu, Jun Zhou, Qinghua Zheng
Categories: cs.LG
\\ ( https://arxiv.org/abs/2201.08557 ,  8661kb)
------------------------------------------------------------------------------
\\
arXiv:2205.10044
replaced with revised version Thu, 8 Jun 2023 06:31:40 GMT   (5122kb,D)

Title: Towards biologically plausible Dreaming and Planning in recurrent
 spiking networks
Authors: Cristiano Capone and Pier Stanislao Paolucci
Categories: cs.LG q-bio.NC
\\ ( https://arxiv.org/abs/2205.10044 ,  5122kb)
------------------------------------------------------------------------------
\\
arXiv:2205.11786
replaced with revised version Wed, 7 Jun 2023 22:20:05 GMT   (316kb,D)

Title: Transition to Linearity of General Neural Networks with Directed Acyclic
 Graph Architecture
Authors: Libin Zhu, Chaoyue Liu, Mikhail Belkin
Categories: cs.LG
Comments: NeurIPS 2022
\\ ( https://arxiv.org/abs/2205.11786 ,  316kb)
------------------------------------------------------------------------------
\\
arXiv:2205.11787
replaced with revised version Wed, 7 Jun 2023 22:26:44 GMT   (4383kb,D)

Title: Quadratic models for understanding neural network dynamics
Authors: Libin Zhu, Chaoyue Liu, Adityanarayanan Radhakrishnan, Mikhail Belkin
Categories: cs.LG
Comments: made correction to proof
\\ ( https://arxiv.org/abs/2205.11787 ,  4383kb)
------------------------------------------------------------------------------
\\
arXiv:2206.08005
replaced with revised version Thu, 8 Jun 2023 15:52:21 GMT   (6036kb,D)

Title: Evaluating Self-Supervised Learning for Molecular Graph Embeddings
Authors: Hanchen Wang, Jean Kaddour, Shengchao Liu, Jian Tang, Joan Lasenby, Qi
 Liu
Categories: cs.LG q-bio.QM
Comments: update results
\\ ( https://arxiv.org/abs/2206.08005 ,  6036kb)
------------------------------------------------------------------------------
\\
arXiv:2207.01955
replaced with revised version Thu, 8 Jun 2023 04:08:53 GMT   (845kb,D)

Title: Ask-AC: An Initiative Advisor-in-the-Loop Actor-Critic Framework
Authors: Shunyu Liu, Kaixuan Chen, Na Yu, Jie Song, Zunlei Feng, Mingli Song
Categories: cs.LG cs.AI
\\ ( https://arxiv.org/abs/2207.01955 ,  845kb)
------------------------------------------------------------------------------
\\
arXiv:2207.02338
replaced with revised version Wed, 7 Jun 2023 20:19:38 GMT   (38008kb,D)

Title: Mitigating Propagation Failures in Physics-informed Neural Networks
 using Retain-Resample-Release (R3) Sampling
Authors: Arka Daw, Jie Bu, Sifan Wang, Paris Perdikaris, Anuj Karpatne
Categories: cs.LG cs.AI
Comments: 39 pages, 53 figures, 6 tables
\\ ( https://arxiv.org/abs/2207.02338 ,  38008kb)
------------------------------------------------------------------------------
\\
arXiv:2208.08934
replaced with revised version Thu, 8 Jun 2023 10:05:43 GMT   (5022kb,D)

Title: A Hybrid Self-Supervised Learning Framework for Vertical Federated
 Learning
Authors: Yuanqin He, Yan Kang, Xinyuan Zhao, Jiahuan Luo, Lixin Fan, Yuxing
 Han, Qiang Yang
Categories: cs.LG
Comments: Add preliminaries and experiments
\\ ( https://arxiv.org/abs/2208.08934 ,  5022kb)
------------------------------------------------------------------------------
\\
arXiv:2208.12401
replaced with revised version Thu, 8 Jun 2023 05:50:50 GMT   (2935kb,D)

Title: Scalable Set Encoding with Universal Mini-Batch Consistency and Unbiased
 Full Set Gradient Approximation
Authors: Jeffrey Willette, Seanie Lee, Bruno Andreis, Kenji Kawaguchi, Juho
 Lee, Sung Ju Hwang
Categories: cs.LG stat.ML
Comments: ICML 2023
\\ ( https://arxiv.org/abs/2208.12401 ,  2935kb)
------------------------------------------------------------------------------
\\
arXiv:2209.07805
replaced with revised version Wed, 7 Jun 2023 21:03:43 GMT   (8104kb,D)

Title: A Comprehensive Benchmark for COVID-19 Predictive Modeling Using
 Electronic Health Records in Intensive Care
Authors: Junyi Gao, Yinghao Zhu, Wenqing Wang, Yasha Wang, Wen Tang, Ewen M.
 Harrison, Liantao Ma
Categories: cs.LG
Comments: Junyi Gao, Yinghao Zhu and Wenqing Wang contributed equally
\\ ( https://arxiv.org/abs/2209.07805 ,  8104kb)
------------------------------------------------------------------------------
\\
arXiv:2209.14013
replaced with revised version Thu, 8 Jun 2023 10:02:27 GMT   (628kb,D)

Title: On the Robustness of Random Forest Against Untargeted Data Poisoning: An
 Ensemble-Based Approach
Authors: Marco Anisetti, Claudio A. Ardagna, Alessandro Balestrucci, Nicola
 Bena, Ernesto Damiani, Chan Yeob Yeun
Categories: cs.LG
Comments: 15 pages, 8 figures
\\ ( https://arxiv.org/abs/2209.14013 ,  628kb)
------------------------------------------------------------------------------
\\
arXiv:2210.07213
replaced with revised version Thu, 8 Jun 2023 13:20:01 GMT   (2700kb,D)

Title: FARE: Provably Fair Representation Learning with Practical Certificates
Authors: Nikola Jovanovi\'c, Mislav Balunovi\'c, Dimitar I. Dimitrov, Martin
 Vechev
Categories: cs.LG cs.AI cs.CY
Comments: ICML 2023
\\ ( https://arxiv.org/abs/2210.07213 ,  2700kb)
------------------------------------------------------------------------------
\\
arXiv:2210.17101
replaced with revised version Thu, 8 Jun 2023 12:39:59 GMT   (650kb,D)

Title: Unrolled Graph Learning for Multi-Agent Collaboration
Authors: Enpei Zhang, Shuo Tang, Xiaowen Dong, Siheng Chen, Yanfeng Wang
Categories: cs.LG cs.MA
Comments: This work was accepted to be presented at the Graph Signal Processing
 Workshop 2023
\\ ( https://arxiv.org/abs/2210.17101 ,  650kb)
------------------------------------------------------------------------------
\\
arXiv:2211.01244
replaced with revised version Thu, 8 Jun 2023 14:31:31 GMT   (523kb,D)

Title: EquiMod: An Equivariance Module to Improve Self-Supervised Learning
Authors: Alexandre Devillers and Mathieu Lefort
Categories: cs.LG cs.CV
\\ ( https://arxiv.org/abs/2211.01244 ,  523kb)
------------------------------------------------------------------------------
\\
arXiv:2211.03991
replaced with revised version Wed, 7 Jun 2023 18:39:11 GMT   (1040kb,D)

Title: Dynamic Interpretable Change Point Detection
Authors: Kopal Garg and Jennifer Yu and Tina Behrouzi and Sana Tonekaboni and
 Anna Goldenberg
Categories: cs.LG
\\ ( https://arxiv.org/abs/2211.03991 ,  1040kb)
------------------------------------------------------------------------------
\\
arXiv:2212.00309
replaced with revised version Wed, 7 Jun 2023 20:22:57 GMT   (12622kb,D)

Title: Differentially Private Adaptive Optimization with Delayed
 Preconditioners
Authors: Tian Li, Manzil Zaheer, Ken Ziyu Liu, Sashank J. Reddi, H. Brendan
 McMahan, Virginia Smith
Categories: cs.LG cs.CR
Comments: Accepted by ICLR 2023
\\ ( https://arxiv.org/abs/2212.00309 ,  12622kb)
------------------------------------------------------------------------------
\\
arXiv:2212.06641
replaced with revised version Thu, 8 Jun 2023 13:33:01 GMT   (630kb,D)

Title: Simplicity Bias Leads to Amplified Performance Disparities
Authors: Samuel J. Bell and Levent Sagun
Categories: cs.LG cs.CY
Comments: In 2023 ACM Conference on Fairness, Accountability, and Transparency
 (FAccT '23). ACM
DOI: 10.1145/3593013.3594003
\\ ( https://arxiv.org/abs/2212.06641 ,  630kb)
------------------------------------------------------------------------------
\\
arXiv:2301.00557
replaced with revised version Thu, 8 Jun 2023 07:32:18 GMT   (476kb,D)

Title: Learning to Maximize Mutual Information for Dynamic Feature Selection
Authors: Ian Covert, Wei Qiu, Mingyu Lu, Nayoon Kim, Nathan White, Su-In Lee
Categories: cs.LG cs.IT math.IT stat.ML
Comments: ICML 2023 camera-ready
\\ ( https://arxiv.org/abs/2301.00557 ,  476kb)
------------------------------------------------------------------------------
\\
arXiv:2301.08618
replaced with revised version Thu, 8 Jun 2023 11:42:32 GMT   (4721kb,D)

Title: Solving PDEs with Unmeasurable Source Terms Using Coupled
 Physics-Informed Neural Network with Recurrent Prediction in Soft Sensor
 Modeling
Authors: Aina Wang, Pan Qin, Xi-Ming Sun
Categories: cs.LG cs.NA math.NA
\\ ( https://arxiv.org/abs/2301.08618 ,  4721kb)
------------------------------------------------------------------------------
\\
arXiv:2301.12601
replaced with revised version Thu, 8 Jun 2023 07:47:46 GMT   (224kb,D)

Title: Regret Bounds for Markov Decision Processes with Recursive Optimized
 Certainty Equivalents
Authors: Wenhao Xu, Xuefeng Gao, Xuedong He
Categories: cs.LG cs.AI math.OC
\\ ( https://arxiv.org/abs/2301.12601 ,  224kb)
------------------------------------------------------------------------------
\\
arXiv:2302.00058
replaced with revised version Thu, 8 Jun 2023 16:44:12 GMT   (10082kb,D)

Title: Graph-based Time-Series Anomaly Detection: A Survey
Authors: Thi Kieu Khanh Ho, Ali Karami, Narges Armanfard
Categories: cs.LG
Comments: 19 pages, 4 figures, 2 tables
\\ ( https://arxiv.org/abs/2302.00058 ,  10082kb)
------------------------------------------------------------------------------
\\
arXiv:2302.01416
replaced with revised version Wed, 7 Jun 2023 20:23:14 GMT   (10589kb,D)

Title: Neural Insights for Digital Marketing Content Design
Authors: Fanjie Kong, Yuan Li, Houssam Nassif, Tanner Fiez, Ricardo Henao,
 Shreya Chakrabarti
Categories: cs.LG cs.AI
DOI: 10.1145/3580305.3599875
\\ ( https://arxiv.org/abs/2302.01416 ,  10589kb)
------------------------------------------------------------------------------
\\
arXiv:2302.01539
replaced with revised version Thu, 8 Jun 2023 15:05:18 GMT   (923kb,D)

Title: A Lipschitz Bandits Approach for Continuous Hyperparameter Optimization
Authors: Yasong Feng, Weijian Luo, Yimin Huang, Tianyu Wang
Categories: cs.LG stat.ML
Comments: Some preliminaries and backgrounds are drawn from arXiv:2110.09722 by
 the first author and the last author, and their coauthor Z. Huang
\\ ( https://arxiv.org/abs/2302.01539 ,  923kb)
------------------------------------------------------------------------------
\\
arXiv:2302.02607
replaced with revised version Thu, 8 Jun 2023 17:39:05 GMT   (13810kb,D)

Title: Target-based Surrogates for Stochastic Optimization
Authors: Jonathan Wilder Lavington, Sharan Vaswani, Reza Babanezhad, Mark
 Schmidt, Nicolas Le Roux
Categories: cs.LG math.OC
\\ ( https://arxiv.org/abs/2302.02607 ,  13810kb)
------------------------------------------------------------------------------
\\
arXiv:2302.02984
replaced with revised version Thu, 8 Jun 2023 17:31:49 GMT   (416kb,D)

Title: Robust Subtask Learning for Compositional Generalization
Authors: Kishor Jothimurugan, Steve Hsu, Osbert Bastani and Rajeev Alur
Categories: cs.LG
Journal-ref: Proceedings of the 40th International Conference on Machine
 Learning, Honolulu, Hawaii, USA. PMLR 202, 2023
\\ ( https://arxiv.org/abs/2302.02984 ,  416kb)
------------------------------------------------------------------------------
\\
arXiv:2302.04178
replaced with revised version Wed, 7 Jun 2023 19:08:54 GMT   (1470kb,D)

Title: DynGFN: Towards Bayesian Inference of Gene Regulatory Networks with
 GFlowNets
Authors: Lazar Atanackovic, Alexander Tong, Jason Hartford, Leo J. Lee, Bo
 Wang, Yoshua Bengio
Categories: cs.LG cs.AI
\\ ( https://arxiv.org/abs/2302.04178 ,  1470kb)
------------------------------------------------------------------------------
\\
arXiv:2302.04216
replaced with revised version Wed, 7 Jun 2023 20:13:14 GMT   (3290kb)

Title: Combining Variational Autoencoders and Physical Bias for Improved
 Microscopy Data Analysis
Authors: Arpan Biswas, Maxim Ziatdinov and Sergei V. Kalinin
Categories: cs.LG eess.IV
Comments: 20 pages, 7 figures in main text, 4 figures in Supp Mat
\\ ( https://arxiv.org/abs/2302.04216 ,  3290kb)
------------------------------------------------------------------------------
\\
arXiv:2302.08551
replaced with revised version Wed, 7 Jun 2023 22:55:07 GMT   (1281kb,D)

Title: Infinite Action Contextual Bandits with Reusable Data Exhaust
Authors: Mark Rucker, Yinglun Zhu, Paul Mineiro
Categories: cs.LG
Comments: Final version after responding to reviewers
\\ ( https://arxiv.org/abs/2302.08551 ,  1281kb)
------------------------------------------------------------------------------
\\
arXiv:2302.10912
replaced with revised version Thu, 8 Jun 2023 06:58:05 GMT   (1724kb,D)

Title: Balanced Audiovisual Dataset for Imbalance Analysis
Authors: Wenke Xia, Xu Zhao, Xincheng Pang, Changqing Zhang, Di Hu
Categories: cs.LG cs.CV cs.MM
Comments: website:https://gewu-lab.github.io/Balanced-Audiovisual-Dataset/
\\ ( https://arxiv.org/abs/2302.10912 ,  1724kb)
------------------------------------------------------------------------------
\\
arXiv:2302.11552
replaced with revised version Thu, 8 Jun 2023 17:39:01 GMT   (20569kb,D)

Title: Reduce, Reuse, Recycle: Compositional Generation with Energy-Based
 Diffusion Models and MCMC
Authors: Yilun Du, Conor Durkan, Robin Strudel, Joshua B. Tenenbaum, Sander
 Dieleman, Rob Fergus, Jascha Sohl-Dickstein, Arnaud Doucet, Will Grathwohl
Categories: cs.LG cs.AI cs.CV stat.ML
Comments: ICML 2023, Project Webpage:
 https://energy-based-model.github.io/reduce-reuse-recycle/
\\ ( https://arxiv.org/abs/2302.11552 ,  20569kb)
------------------------------------------------------------------------------
\\
arXiv:2302.13483
replaced with revised version Thu, 8 Jun 2023 02:20:09 GMT   (2052kb,D)

Title: CrystalBox: Future-Based Explanations for DRL Network Controllers
Authors: Sagar Patel, Sangeetha Abdu Jyothi, Nina Narodytska
Categories: cs.LG cs.NI cs.SY eess.SY
\\ ( https://arxiv.org/abs/2302.13483 ,  2052kb)
------------------------------------------------------------------------------
\\
arXiv:2303.06171
replaced with revised version Thu, 8 Jun 2023 17:13:13 GMT   (645kb,D)

Title: DP-Fast MH: Private, Fast, and Accurate Metropolis-Hastings for
 Large-Scale Bayesian Inference
Authors: Wanrong Zhang, Ruqi Zhang
Categories: cs.LG stat.ML
Journal-ref: published at ICML 2023
\\ ( https://arxiv.org/abs/2303.06171 ,  645kb)
------------------------------------------------------------------------------
\\
arXiv:2303.16458
replaced with revised version Thu, 8 Jun 2023 17:48:57 GMT   (2466kb,D)

Title: When to Pre-Train Graph Neural Networks? From Data Generation
 Perspective!
Authors: Yuxuan Cao, Jiarong Xu, Carl Yang, Jiaan Wang, Yunchao Zhang, Chunping
 Wang, Lei Chen, Yang Yang
Categories: cs.LG
\\ ( https://arxiv.org/abs/2303.16458 ,  2466kb)
------------------------------------------------------------------------------
\\
arXiv:2304.01545
replaced with revised version Thu, 8 Jun 2023 02:08:19 GMT   (3958kb)

Title: How Regional Wind Characteristics Affect CNN-based wind predictions:
 Insights from Spatiotemporal Correlation Analysis
Authors: Heesoo Shin, Mario R\"uttgers, Sangseung Lee
Categories: cs.LG physics.comp-ph
Comments: 27 pages, 18 figures
\\ ( https://arxiv.org/abs/2304.01545 ,  3958kb)
------------------------------------------------------------------------------
\\
arXiv:2304.03279
replaced with revised version Thu, 8 Jun 2023 02:04:23 GMT   (799kb,D)

Title: Do the Rewards Justify the Means? Measuring Trade-Offs Between Rewards
 and Ethical Behavior in the MACHIAVELLI Benchmark
Authors: Alexander Pan, Jun Shern Chan, Andy Zou, Nathaniel Li, Steven Basart,
 Thomas Woodside, Jonathan Ng, Hanlin Zhang, Scott Emmons, Dan Hendrycks
Categories: cs.LG cs.AI cs.CL cs.CY
Comments: ICML 2023 Oral (camera-ready); 31 pages, 5 figures
\\ ( https://arxiv.org/abs/2304.03279 ,  799kb)
------------------------------------------------------------------------------
\\
arXiv:2304.09362
replaced with revised version Wed, 7 Jun 2023 20:55:04 GMT   (3589kb,D)

Title: Long-Term Fairness with Unknown Dynamics
Authors: Tongxin Yin, Reilly Raab, Mingyan Liu, Yang Liu
Categories: cs.LG
Comments: Best paper runner-up at ICLR 2023 Workshop on Trustworthy and
 Reliable Large-Scale Machine Learning Models (Non Archival)
\\ ( https://arxiv.org/abs/2304.09362 ,  3589kb)
------------------------------------------------------------------------------
\\
arXiv:2304.12579
replaced with revised version Thu, 8 Jun 2023 03:13:04 GMT   (1026kb,D)

Title: Learning Trajectories are Generalization Indicators
Authors: Jingwen Fu, Zhizheng Zhang, Dacheng Yin, Yan Lu, Nanning Zheng
Categories: cs.LG
\\ ( https://arxiv.org/abs/2304.12579 ,  1026kb)
------------------------------------------------------------------------------
\\
arXiv:2305.00316
replaced with revised version Thu, 8 Jun 2023 03:39:48 GMT   (710kb,D)

Title: The Ideal Continual Learner: An Agent That Never Forgets
Authors: Liangzu Peng, Paris V. Giampouras, Ren\'e Vidal
Categories: cs.LG
Comments: Accepted to ICML 2023
\\ ( https://arxiv.org/abs/2305.00316 ,  710kb)
------------------------------------------------------------------------------
\\
arXiv:2305.08841
replaced with revised version Thu, 8 Jun 2023 11:53:51 GMT   (627kb,D)

Title: A Theoretical Analysis of Optimistic Proximal Policy Optimization in
 Linear Markov Decision Processes
Authors: Han Zhong, Tong Zhang
Categories: cs.LG cs.AI math.OC stat.ML
\\ ( https://arxiv.org/abs/2305.08841 ,  627kb)
------------------------------------------------------------------------------
\\
arXiv:2305.11699
replaced with revised version Thu, 8 Jun 2023 10:42:01 GMT   (285kb)

Title: RGCVAE: Relational Graph Conditioned Variational Autoencoder for
 Molecule Design
Authors: Davide Rigoni, Nicol\`o Navarin, Alessandro Sperduti
Categories: cs.LG cs.AI q-bio.BM
\\ ( https://arxiv.org/abs/2305.11699 ,  285kb)
------------------------------------------------------------------------------
\\
arXiv:2305.14035
replaced with revised version Thu, 8 Jun 2023 13:32:43 GMT   (1286kb,D)

Title: Can Self-Supervised Neural Representations Pre-Trained on Human Speech
 distinguish Animal Callers?
Authors: Eklavya Sarkar and Mathew Magimai.-Doss
Categories: cs.LG cs.SD eess.AS
Comments: Accepted at Interspeech 2023
\\ ( https://arxiv.org/abs/2305.14035 ,  1286kb)
------------------------------------------------------------------------------
\\
arXiv:2305.16317
replaced with revised version Thu, 8 Jun 2023 17:37:04 GMT   (5102kb,D)

Title: Parallel Sampling of Diffusion Models
Authors: Andy Shih, Suneel Belkhale, Stefano Ermon, Dorsa Sadigh, Nima Anari
Categories: cs.LG cs.AI
\\ ( https://arxiv.org/abs/2305.16317 ,  5102kb)
------------------------------------------------------------------------------
\\
arXiv:2305.17155
replaced with revised version Thu, 8 Jun 2023 13:29:44 GMT   (163kb,D)

Title: Stability of implicit neural networks for long-term forecasting in
 dynamical systems
Authors: Leon Migus, Julien Salomon and Patrick Gallinari
Categories: cs.LG cs.AI cs.NA math.NA
Comments: ICLR 2023 Workshop on Physics for Machine Learning
\\ ( https://arxiv.org/abs/2305.17155 ,  163kb)
------------------------------------------------------------------------------
\\
arXiv:2305.18655
replaced with revised version Wed, 7 Jun 2023 23:14:34 GMT   (354kb,D)

Title: Parity Calibration
Authors: Youngseog Chung, Aaron Rumack, Chirag Gupta
Categories: cs.LG cs.AI stat.ML
Comments: To appear at UAI 2023 (Oral); 19 pages and 10 figures
\\ ( https://arxiv.org/abs/2305.18655 ,  354kb)
------------------------------------------------------------------------------
\\
arXiv:2306.01103
replaced with revised version Thu, 8 Jun 2023 16:02:32 GMT   (6558kb,D)

Title: Joint Learning of Label and Environment Causal Independence for Graph
 Out-of-Distribution Generalization
Authors: Shurui Gui, Meng Liu, Xiner Li, Youzhi Luo, Shuiwang Ji
Categories: cs.LG cs.AI
\\ ( https://arxiv.org/abs/2306.01103 ,  6558kb)
------------------------------------------------------------------------------
\\
arXiv:2306.01925
replaced with revised version Thu, 8 Jun 2023 02:53:20 GMT   (10152kb,D)

Title: Improving the generalizability and robustness of large-scale traffic
 signal control
Authors: Tianyu Shi and Francois-Xavier Devailly and Denis Larocque and Laurent
 Charlin
Categories: cs.LG
\\ ( https://arxiv.org/abs/2306.01925 ,  10152kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02081
replaced with revised version Thu, 8 Jun 2023 12:47:48 GMT   (569kb,D)

Title: Message-passing selection: Towards interpretable GNNs for graph
 classification
Authors: Wenda Li, Kaixuan Chen, Shunyu Liu, Wenjie Huang, Haofei Zhang,
 Yingjie Tian, Yun Su, Mingli Song
Categories: cs.LG cs.AI
Comments: 6 pages, 1 figures
\\ ( https://arxiv.org/abs/2306.02081 ,  569kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02947
replaced with revised version Thu, 8 Jun 2023 07:43:36 GMT   (2744kb,D)

Title: Continual Learning with Pretrained Backbones by Tuning in the Input
 Space
Authors: Simone Marullo and Matteo Tiezzi and Marco Gori and Stefano Melacci
 and Tinne Tuytelaars
Categories: cs.LG cs.CV
\\ ( https://arxiv.org/abs/2306.02947 ,  2744kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04220
replaced with revised version Thu, 8 Jun 2023 10:34:48 GMT   (18642kb,D)

Title: Look Beneath the Surface: Exploiting Fundamental Symmetry for
 Sample-Efficient Offline RL
Authors: Peng Cheng, Xianyuan Zhan, Zhihao Wu, Wenjia Zhang, Shoucheng Song,
 Han Wang, Youfang Lin, Li Jiang
Categories: cs.LG cs.AI
Comments: The first two authors contributed equally
\\ ( https://arxiv.org/abs/2306.04220 ,  18642kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04252
replaced with revised version Thu, 8 Jun 2023 08:43:40 GMT   (428kb,D)

Title: Adversarial Sample Detection Through Neural Network Transport Dynamics
Authors: Skander Karkar and Patrick Gallinari and Alain Rakotomamonjy
Categories: cs.LG
Comments: ECML PKDD 2023
\\ ( https://arxiv.org/abs/2306.04252 ,  428kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04262
replaced with revised version Thu, 8 Jun 2023 10:32:01 GMT   (15971kb,D)

Title: Self-Adjusting Weighted Expected Improvement for Bayesian Optimization
Authors: Carolin Benjamins and Elena Raponi and Anja Jankovic and Carola Doerr
 and Marius Lindauer
Categories: cs.LG
Comments: AutoML Conference 2023
\\ ( https://arxiv.org/abs/2306.04262 ,  15971kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04288
replaced with revised version Thu, 8 Jun 2023 06:27:37 GMT   (2581kb,D)

Title: Revising deep learning methods in parking lot occupancy detection
Authors: Anastasia Martynova, Mikhail Kuznetsov, Vadim Porvatov, Vladislav
 Tishin, Andrey Kuznetsov, Natalia Semenova, Ksenia Kuznetsova
Categories: cs.LG cs.CV
Comments: 15 pages, 7 figures
\\ ( https://arxiv.org/abs/2306.04288 ,  2581kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04431
replaced with revised version Thu, 8 Jun 2023 09:50:27 GMT   (753kb,D)

Title: Faithful Knowledge Distillation
Authors: Tom A. Lamb, Rudy Brunel, Krishnamurthy DJ Dvijotham, M. Pawan Kumar,
 Philip H. S. Torr, Francisco Eiras
Categories: cs.LG
Comments: 12pgs (main content), 3 figures
\\ ( https://arxiv.org/abs/2306.04431 ,  753kb)
------------------------------------------------------------------------------
\\
arXiv:2201.01247
replaced with revised version Thu, 8 Jun 2023 05:44:57 GMT   (970kb,D)

Title: Value Functions Factorization with Latent State Information Sharing in
 Decentralized Multi-Agent Policy Gradients
Authors: Hanhan Zhou, Tian Lan, Vaneet Aggarwal
Categories: cs.MA cs.LG
Comments: Accepted to IEEE Transactions on Emerging Topics in Computational
 Intelligence (TETCI)
\\ ( https://arxiv.org/abs/2201.01247 ,  970kb)
------------------------------------------------------------------------------
\\
arXiv:2203.10174
replaced with revised version Thu, 8 Jun 2023 15:32:50 GMT   (7555kb,D)

Title: Are We Ready for Radar to Replace Lidar in All-Weather Mapping and
 Localization?
Authors: Keenan Burnett, Yuchen Wu, David J. Yoon, Angela P. Schoellig, Timothy
 D. Barfoot
Categories: cs.RO
Comments: Version 3: Accepted to RA-L, presented at IROS 2022. Localization
 results updated due to improved ground truth and calibration. Also switched
 Huber Loss for Cauchy Loss for the radar-based approaches
\\ ( https://arxiv.org/abs/2203.10174 ,  7555kb)
------------------------------------------------------------------------------
\\
arXiv:2210.10254
replaced with revised version Thu, 8 Jun 2023 04:46:57 GMT   (2899kb,D)

Title: Safe Planning in Dynamic Environments using Conformal Prediction
Authors: Lars Lindemann, Matthew Cleaveland, Gihyun Shim, George J. Pappas
Categories: cs.RO cs.SY eess.SY
\\ ( https://arxiv.org/abs/2210.10254 ,  2899kb)
------------------------------------------------------------------------------
\\
arXiv:2301.12587
replaced with revised version Thu, 8 Jun 2023 01:16:00 GMT   (5464kb,D)

Title: Zero-Shot Transfer of Haptics-Based Object Insertion Policies
Authors: Samarth Brahmbhatt, Ankur Deka, Andrew Spielberg, Matthias M\"uller
Categories: cs.RO cs.AI
Comments: Accepted for publication at 2023 IEEE International Conference on
 Robotics and Automation (ICRA)
\\ ( https://arxiv.org/abs/2301.12587 ,  5464kb)
------------------------------------------------------------------------------
\\
arXiv:2302.11834
replaced with revised version Thu, 8 Jun 2023 09:48:45 GMT   (1785kb,D)

Title: Generalization of Auto-Regressive Hidden Markov Models to Non-Linear
 Dynamics and Unit Quaternion Observation Space
Authors: Michele Ginesi and Paolo Fiorini
Categories: cs.RO cs.LG
\\ ( https://arxiv.org/abs/2302.11834 ,  1785kb)
------------------------------------------------------------------------------
\\
arXiv:2303.03616
replaced with revised version Thu, 8 Jun 2023 01:43:29 GMT   (6773kb,D)

Title: Geometry-Aware Coverage Path Planning for Depowdering on Complex 3D
 Surfaces
Authors: Van-Thach Do and Quang-Cuong Pham
Categories: cs.RO cs.CG
Comments: 8 pages, 8 figures
\\ ( https://arxiv.org/abs/2303.03616 ,  6773kb)
------------------------------------------------------------------------------
\\
arXiv:2305.19075
replaced with revised version Thu, 8 Jun 2023 10:38:49 GMT   (14237kb,D)

Title: Language-Conditioned Imitation Learning with Base Skill Priors under
 Unstructured Data
Authors: Hongkuan Zhou, Zhenshan Bing, Xiangtong Yao, Xiaojie Su, Chenguang
 Yang, Kai Huang, Alois Knoll
Categories: cs.RO cs.AI
\\ ( https://arxiv.org/abs/2305.19075 ,  14237kb)
------------------------------------------------------------------------------
\\
arXiv:2306.01263
replaced with revised version Thu, 8 Jun 2023 03:20:28 GMT   (4616kb,D)

Title: Adaptive Robotic Information Gathering via Non-Stationary Gaussian
 Processes
Authors: Weizhe Chen, Roni Khardon, Lantao Liu
Categories: cs.RO
Comments: International Journal of Robotics Research (IJRR). Code:
 pypolo.readthedocs.io. arXiv admin note: text overlap with arXiv:2205.06426
\\ ( https://arxiv.org/abs/2306.01263 ,  4616kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02586
replaced with revised version Thu, 8 Jun 2023 15:10:00 GMT   (34kb,D)

Title: Internet of Things Meets Robotics: A Survey of Cloud-based Robots
Authors: Chrisantus Eze
Categories: cs.RO cs.NI
\\ ( https://arxiv.org/abs/2306.02586 ,  34kb)
------------------------------------------------------------------------------
\\
arXiv:2012.04175
replaced with revised version Thu, 8 Jun 2023 11:13:23 GMT   (1062kb,D)

Title: Topology Identification under Spatially Correlated Noise
Authors: Mishfad Shaikh Veedu, Murti V. Salapaka
Categories: eess.SY cs.SY
Comments: 16 pages, 7 figures, Accepted as Regular Paper, Automatica
\\ ( https://arxiv.org/abs/2012.04175 ,  1062kb)
------------------------------------------------------------------------------
\\
arXiv:2109.07630
replaced with revised version Wed, 7 Jun 2023 23:36:25 GMT   (165kb,D)

Title: Reinforcement Learning Policies in Continuous-Time Linear Systems
Authors: Mohamad Kazem Shirani Faradonbeh, Mohamad Sadegh Shirani Faradonbeh
Categories: eess.SY cs.LG cs.SY
\\ ( https://arxiv.org/abs/2109.07630 ,  165kb)
------------------------------------------------------------------------------
\\
arXiv:2202.12744
replaced with revised version Thu, 8 Jun 2023 13:06:35 GMT   (1119kb,D)

Title: A Lyapunov function for robust stability of moving horizon estimation
Authors: Julian D. Schiller, Simon Muntwiler, Johannes K\"ohler, Melanie N.
 Zeilinger, Matthias A. M\"uller
Categories: eess.SY cs.SY
Comments: *Julian D. Schiller and Simon Muntwiler contributed equally to this
 paper. 16 pages, 3 figures. Published in: IEEE Transactions on Automatic
 Control. This version contains an additional numerical example in Section V.B
DOI: 10.1109/TAC.2023.3280344
\\ ( https://arxiv.org/abs/2202.12744 ,  1119kb)
------------------------------------------------------------------------------
\\
arXiv:2211.05793 (*cross-listing*)
replaced with revised version Thu, 8 Jun 2023 15:16:52 GMT   (2398kb,D)

Title: A fermion neural network with efficient optimization and quantum
 applicability
Authors: Pei-Lin Zheng, Jia-Bao Wang and Yi Zhang
Categories: quant-ph cond-mat.dis-nn cs.AI cs.LG
Comments: 19 pages, 12 figures
\\ ( https://arxiv.org/abs/2211.05793 ,  2398kb)
------------------------------------------------------------------------------
\\
arXiv:2212.10029
replaced with revised version Thu, 8 Jun 2023 17:27:44 GMT   (17830kb,D)

Title: Do language models have coherent mental models of everyday things?
Authors: Yuling Gu, Bhavana Dalvi Mishra, Peter Clark
Categories: cs.CL cs.AI
Comments: ACL 2023
\\ ( https://arxiv.org/abs/2212.10029 ,  17830kb)
------------------------------------------------------------------------------
\\
arXiv:2304.14293
replaced with revised version Thu, 8 Jun 2023 06:33:23 GMT   (7761kb,D)

Title: Controlled Text Generation with Natural Language Instructions
Authors: Wangchunshu Zhou, Yuchen Eleanor Jiang, Ethan Wilcox, Ryan Cotterell,
 Mrinmaya Sachan
Categories: cs.CL cs.AI cs.LG
Comments: ICML 2023
\\ ( https://arxiv.org/abs/2304.14293 ,  7761kb)
------------------------------------------------------------------------------
\\
arXiv:2305.08714
replaced with revised version Thu, 8 Jun 2023 02:14:20 GMT   (7721kb,D)

Title: Sensitivity and Robustness of Large Language Models to Prompt Template
 in Japanese Text Classification Tasks
Authors: Chengguang Gan and Tatsunori Mori
Categories: cs.CL cs.AI
Comments: Under Review. 11 pages, 8 figures
\\ ( https://arxiv.org/abs/2305.08714 ,  7721kb)
------------------------------------------------------------------------------
\\
arXiv:2305.12837
replaced with revised version Thu, 8 Jun 2023 12:38:20 GMT   (1564kb,D)

Title: Capturing Conversion Rate Fluctuation during Sales Promotions: A Novel
 Historical Data Reuse Approach
Authors: Zhangming Chan, Yu Zhang, Shuguang Han, Yong Bai, Xiang-Rong Sheng,
 Siyuan Lou, Jiacen Hu, Baolin Liu, Yuning Jiang, Jian Xu, Bo Zheng
Categories: cs.IR cs.AI cs.LG
Comments: Accepted at KDD 2023. This work has already been deployed on the
 display advertising system in Alibaba, bringing substantial economic gains
\\ ( https://arxiv.org/abs/2305.12837 ,  1564kb)
------------------------------------------------------------------------------
\\
arXiv:2305.14825
replaced with revised version Thu, 8 Jun 2023 16:38:51 GMT   (402kb,D)

Title: Large Language Models are In-Context Semantic Reasoners rather than
 Symbolic Reasoners
Authors: Xiaojuan Tang, Zilong Zheng, Jiaqi Li, Fanxu Meng, Song-Chun Zhu,
 Yitao Liang, Muhan Zhang
Categories: cs.CL cs.AI
\\ ( https://arxiv.org/abs/2305.14825 ,  402kb)
------------------------------------------------------------------------------
\\
arXiv:2305.18486
replaced with revised version Thu, 8 Jun 2023 03:27:16 GMT   (9298kb,D)

Title: A Systematic Study and Comprehensive Evaluation of ChatGPT on Benchmark
 Datasets
Authors: Md Tahmid Rahman Laskar, M Saiful Bari, Mizanur Rahman, Md Amran
 Hossen Bhuiyan, Shafiq Joty, Jimmy Xiangji Huang
Categories: cs.CL cs.AI cs.LG
Comments: Accepted by ACL 2023 Findings. The first three authors contributed
 equally
\\ ( https://arxiv.org/abs/2305.18486 ,  9298kb)
------------------------------------------------------------------------------
\\
arXiv:2306.01788
replaced with revised version Wed, 7 Jun 2023 21:55:28 GMT   (350kb,D)

Title: Responsible Design Patterns for Machine Learning Pipelines
Authors: Saud Hakem Al Harbi, Lionel Nganyewou Tidjon and Foutse Khomh
Categories: cs.SE cs.AI cs.LG
Comments: 20 pages, 4 figures, 5 tables
\\ ( https://arxiv.org/abs/2306.01788 ,  350kb)
------------------------------------------------------------------------------
\\
arXiv:2306.01981 (*cross-listing*)
replaced with revised version Thu, 8 Jun 2023 03:24:01 GMT   (485kb,D)

Title: SGEM: Test-Time Adaptation for Automatic Speech Recognition via
 Sequential-Level Generalized Entropy Minimization
Authors: Changhun Kim, Joonhyung Park, Hajin Shim and Eunho Yang
Categories: eess.AS cs.AI cs.LG
Comments: Accepted to INTERSPEECH 2023; Our code is available at
 https://github.com/drumpt/SGEM
\\ ( https://arxiv.org/abs/2306.01981 ,  485kb)
------------------------------------------------------------------------------
\\
arXiv:2304.10691 (*cross-listing*)
replaced with revised version Thu, 8 Jun 2023 10:32:56 GMT   (3891kb,D)

Title: SkinGPT-4: An Interactive Dermatology Diagnostic System with Visual
 Large Language Model
Authors: Juexiao Zhou, Xiaonan He, Liyuan Sun, Jiannan Xu, Xiuying Chen, Yuetan
 Chu, Longxi Zhou, Xingyu Liao, Bin Zhang, Xin Gao
Categories: eess.IV cs.CV cs.LG
\\ ( https://arxiv.org/abs/2304.10691 ,  3891kb)
------------------------------------------------------------------------------
\\
arXiv:2102.13244 (*cross-listing*)
replaced with revised version Thu, 8 Jun 2023 16:24:22 GMT   (262kb,D)

Title: Cyclic Coordinate Dual Averaging with Extrapolation
Authors: Chaobing Song and Jelena Diakonikolas
Categories: math.OC cs.LG
Comments: 27 pages, 2 figures. Accepted to SIAM Journal on Optimization.
 Version prior to final copy editing
\\ ( https://arxiv.org/abs/2102.13244 ,  262kb)
------------------------------------------------------------------------------
\\
arXiv:2110.15317
replaced with revised version Thu, 8 Jun 2023 02:43:02 GMT   (8012kb,D)

Title: Bridge the Gap Between CV and NLP! A Gradient-based Textual Adversarial
 Attack Framework
Authors: Lifan Yuan, Yichi Zhang, Yangyi Chen, Wei Wei
Categories: cs.CL cs.CR cs.LG
Comments: Accepted to Findings of ACL 2023. Codes are available at:
 https://github.com/Phantivia/T-PGD
\\ ( https://arxiv.org/abs/2110.15317 ,  8012kb)
------------------------------------------------------------------------------
\\
arXiv:2112.14233 (*cross-listing*)
replaced with revised version Thu, 8 Jun 2023 16:51:46 GMT   (2798kb,D)

Title: Multitask Learning and Bandits via Robust Statistics
Authors: Kan Xu, Hamsa Bastani
Categories: stat.ML cs.LG math.ST stat.TH
\\ ( https://arxiv.org/abs/2112.14233 ,  2798kb)
------------------------------------------------------------------------------
\\
arXiv:2207.00076 (*cross-listing*)
replaced with revised version Wed, 7 Jun 2023 18:16:31 GMT   (49kb,D)

Title: Efficient computation of rankings from pairwise comparisons
Authors: M. E. J. Newman
Categories: stat.ML cs.LG
Comments: 25 pages, 1 figure, 1 table; additional material on MAP estimation
 and rates of convergence
\\ ( https://arxiv.org/abs/2207.00076 ,  49kb)
------------------------------------------------------------------------------
\\
arXiv:2207.09874 (*cross-listing*)
replaced with revised version Thu, 8 Jun 2023 11:03:15 GMT   (3184kb,D)

Title: Stream-based active learning with linear models
Authors: Davide Cacciarelli, Murat Kulahci, John S{\o}lve Tyssedal
Categories: stat.ML cs.LG
Comments: Published in Knowledge-Based Systems (2022)
DOI: 10.1016/j.knosys.2022.109664
\\ ( https://arxiv.org/abs/2207.09874 ,  3184kb)
------------------------------------------------------------------------------
\\
arXiv:2208.04705
replaced with revised version Thu, 8 Jun 2023 14:46:47 GMT   (1344kb,D)

Title: Classification of Stress via Ambulatory ECG and GSR Data
Authors: Zachary Dair, Muhammad Muneeb Saad, Urja Pawar, Samantha Dockray,
 Ruairi O'Reilly
Categories: cs.CY cs.LG cs.SY eess.SY
Comments: Associated Code to enable reproducible experimental work -
 https://github.com/ZacDair/EMBC_Release SMILE dataset provided by
 Computational Wellbeing Group (COMPWELL)
 https://compwell.rice.edu/workshops/embc2022/dataset -
 https://compwell.rice.edu/
ACM-class: I.2.m; J.3; J.4
Journal-ref: EMBC 2022 Compwell Workshop
\\ ( https://arxiv.org/abs/2208.04705 ,  1344kb)
------------------------------------------------------------------------------
\\
arXiv:2210.06723 (*cross-listing*)
replaced with revised version Thu, 8 Jun 2023 15:31:46 GMT   (6585kb,D)

Title: Stochastic noise can be helpful for variational quantum algorithms
Authors: Junyu Liu, Frederik Wilde, Antonio Anna Mele, Liang Jiang, Jens Eisert
Categories: quant-ph cs.LG
Comments: 16 pages, 14 figures, presentation improved, proofs extended
\\ ( https://arxiv.org/abs/2210.06723 ,  6585kb)
------------------------------------------------------------------------------
\\
arXiv:2210.07535
replaced with revised version Wed, 7 Jun 2023 22:41:40 GMT   (7477kb,D)

Title: AutoMoE: Heterogeneous Mixture-of-Experts with Adaptive Computation for
 Efficient Neural Machine Translation
Authors: Ganesh Jawahar, Subhabrata Mukherjee, Xiaodong Liu, Young Jin Kim,
 Muhammad Abdul-Mageed, Laks V. S. Lakshmanan, Ahmed Hassan Awadallah,
 Sebastien Bubeck, Jianfeng Gao
Categories: cs.CL cs.LG
Comments: ACL 2023 Findings
\\ ( https://arxiv.org/abs/2210.07535 ,  7477kb)
------------------------------------------------------------------------------
\\
arXiv:2210.12023
replaced with revised version Wed, 7 Jun 2023 22:03:16 GMT   (1157kb,D)

Title: A Causal Framework to Quantify the Robustness of Mathematical Reasoning
 with Language Models
Authors: Alessandro Stolfo, Zhijing Jin, Kumar Shridhar, Bernhard Sch\"olkopf
 and Mrinmaya Sachan
Categories: cs.CL cs.LG
Comments: ACL 2023. A shorter version of the paper was accepted at the MATH-AI
 Workshop at NeurIPS 2022. 15 pages, 8 figures
\\ ( https://arxiv.org/abs/2210.12023 ,  1157kb)
------------------------------------------------------------------------------
\\
arXiv:2211.10354 (*cross-listing*)
replaced with revised version Mon, 5 Jun 2023 21:55:23 GMT   (35613kb)

Title: CRONOS: Colorization and Contrastive Learning for Device-Free NLoS Human
 Presence Detection using Wi-Fi CSI
Authors: Li-Hsiang Shen, Chia-Che Hsieh, An-Hung Hsiao, Kai-Ten Feng
Categories: eess.SP cs.LG
\\ ( https://arxiv.org/abs/2211.10354 ,  35613kb)
------------------------------------------------------------------------------
\\
arXiv:2301.02554 (*cross-listing*)
replaced with revised version Thu, 8 Jun 2023 09:25:14 GMT   (3156kb,D)

Title: MSCDA: Multi-level Semantic-guided Contrast Improves Unsupervised Domain
 Adaptation for Breast MRI Segmentation in Small Datasets
Authors: Sheng Kuang, Henry C. Woodruff, Renee Granzier, Thiemo J.A. van
 Nijnatten, Marc B.I. Lobbes, Marjolein L. Smidt, Philippe Lambin, Siamak
 Mehrkanoon
Categories: q-bio.QM cs.LG
Comments: 17 pages, 8 figures
ACM-class: I.2; I.5
\\ ( https://arxiv.org/abs/2301.02554 ,  3156kb)
------------------------------------------------------------------------------
\\
arXiv:2301.09554 (*cross-listing*)
replaced with revised version Thu, 8 Jun 2023 16:42:49 GMT   (925kb,D)

Title: Deep Learning Meets Sparse Regularization: A Signal Processing
 Perspective
Authors: Rahul Parhi and Robert D. Nowak
Categories: stat.ML cs.LG eess.SP
\\ ( https://arxiv.org/abs/2301.09554 ,  925kb)
------------------------------------------------------------------------------
\\
arXiv:2301.11401 (*cross-listing*)
replaced with revised version Thu, 8 Jun 2023 17:11:38 GMT   (126kb,D)

Title: Causal Bandits without Graph Learning
Authors: Mikhail Konobeev, Jalal Etesami, Negar Kiyavash
Categories: stat.ML cs.LG
\\ ( https://arxiv.org/abs/2301.11401 ,  126kb)
------------------------------------------------------------------------------
\\
arXiv:2302.00422 (*cross-listing*)
replaced with revised version Thu, 8 Jun 2023 11:15:41 GMT   (15508kb,D)

Title: Robust online active learning
Authors: Davide Cacciarelli, Murat Kulahci, John S{\o}lve Tyssedal
Categories: stat.ML cs.LG
Comments: Published in Quality and Reliability Engineering International (2023)
DOI: 10.1002/qre.3392
\\ ( https://arxiv.org/abs/2302.00422 ,  15508kb)
------------------------------------------------------------------------------
\\
arXiv:2302.04686 (*cross-listing*)
replaced with revised version Wed, 7 Jun 2023 21:44:19 GMT   (657kb,D)

Title: Global and Preference-based Optimization with Mixed Variables using
 Piecewise Affine Surrogates
Authors: Mengjia Zhu, Alberto Bemporad
Categories: math.OC cs.LG
Comments: code available at https://github.com/mjzhu-p/PWAS
\\ ( https://arxiv.org/abs/2302.04686 ,  657kb)
------------------------------------------------------------------------------
\\
arXiv:2303.04288 (*cross-listing*)
replaced with revised version Wed, 7 Jun 2023 23:35:37 GMT   (70kb)

Title: Polynomial Time and Private Learning of Unbounded Gaussian Mixture
 Models
Authors: Jamil Arbas, Hassan Ashtiani and Christopher Liaw
Categories: stat.ML cs.CR cs.DS cs.IT cs.LG math.IT
Comments: Accepted in ICML 2023
\\ ( https://arxiv.org/abs/2303.04288 ,  70kb)
------------------------------------------------------------------------------
\\
arXiv:2304.04095 (*cross-listing*)
replaced with revised version Thu, 8 Jun 2023 16:31:07 GMT   (24kb)

Title: A Simple Proof of the Mixing of Metropolis-Adjusted Langevin Algorithm
 under Smoothness and Isoperimetry
Authors: Yuansi Chen and Khashayar Gatmiry
Categories: stat.ML cs.CC cs.LG stat.CO
Comments: 17 pages
\\ ( https://arxiv.org/abs/2304.04095 ,  24kb)
------------------------------------------------------------------------------
\\
arXiv:2304.13178
replaced with revised version Wed, 7 Jun 2023 23:00:22 GMT   (1091kb,D)

Title: Robust Non-Linear Feedback Coding via Power-Constrained Deep Learning
Authors: Junghoon Kim, Taejoon Kim, David Love, Christopher Brinton
Categories: cs.IT cs.LG math.IT
Comments: To appear in International Conference on Machine Learning (ICML) 2023
\\ ( https://arxiv.org/abs/2304.13178 ,  1091kb)
------------------------------------------------------------------------------
\\
arXiv:2305.03712 (*cross-listing*)
replaced with revised version Thu, 8 Jun 2023 05:51:40 GMT   (1037kb,D)

Title: Statistical Inference for Fairness Auditing
Authors: John J. Cherian, Emmanuel J. Cand\`es
Categories: stat.ME cs.CY cs.LG
Comments: 44 pages, 8 figures
\\ ( https://arxiv.org/abs/2305.03712 ,  1037kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03718
replaced with revised version Thu, 8 Jun 2023 13:43:12 GMT   (2203kb,D)

Title: Emotion-Conditioned Melody Harmonization with Hierarchical Variational
 Autoencoder
Authors: Shulei Ji and Xinyu Yang
Categories: cs.SD cs.LG cs.MM eess.AS
Comments: Accepted by IEEE SMC 2023
\\ ( https://arxiv.org/abs/2306.03718 ,  2203kb)
------------------------------------------------------------------------------
\\
arXiv:2204.14145 (*cross-listing*)
replaced with revised version Thu, 8 Jun 2023 09:12:26 GMT   (3933kb,D)

Title: Automatic Scenario Generation for Robust Optimal Control Problems
Authors: Marta Zagorowska, Paola Falugi, Edward O'Dwyer, Eric C. Kerrigan
Categories: math.OC cs.SY eess.SY
\\ ( https://arxiv.org/abs/2204.14145 ,  3933kb)
------------------------------------------------------------------------------
\\
arXiv:2303.10243 (*cross-listing*)
replaced with revised version Thu, 8 Jun 2023 17:51:50 GMT   (424kb)

Title: Safety-Critical Control for Systems with Impulsive Actuators and Dwell
 Time Constraints
Authors: Joseph Breeden and Dimitra Panagou
Categories: math.OC cs.SY eess.SY
Comments: Accepted to IEEE Control Systems Letters, extended version includes
 full proof of Corollary 1
\\ ( https://arxiv.org/abs/2303.10243 ,  424kb)
%%%---%%%---%%%---%%%---%%%---%%%---%%%---%%%---%%%---%%%---%%%---%%%---%%%---
