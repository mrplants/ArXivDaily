------------------------------------------------------------------------------
------------------------------------------------------------------------------
Send any comments regarding submissions directly to submitter.
------------------------------------------------------------------------------
Archives at http://arxiv.org/
To unsubscribe, e-mail To: cs@arXiv.org, Subject: cancel
------------------------------------------------------------------------------
Submissions to:
Artificial Intelligence
Computer Vision and Pattern Recognition
Computer Science and Game Theory
Machine Learning
Multiagent Systems
Robotics
Systems and Control
received from  Tue  6 Jun 23 18:00:00 GMT  to  Wed  7 Jun 23 18:00:00 GMT
------------------------------------------------------------------------------
------------------------------------------------------------------------------
\\
arXiv:2306.03937
Date: Tue, 6 Jun 2023 18:02:02 GMT   (12775kb,D)

Title: Guiding The Last Layer in Federated Learning with Pre-Trained Models
Authors: Gwen Legate, Nicolas Bernier, Lucas Caccia, Edouard Oyallon, Eugene
 Belilovsky
Categories: cs.AI cs.LG
\\
 Federated Learning (FL) is an emerging paradigm that allows a model to be
trained across a number of participants without sharing data. Recent works have
begun to consider the effects of using pre-trained models as an initialization
point for existing FL algorithms; however, these approaches ignore the vast
body of efficient transfer learning literature from the centralized learning
setting. Here we revisit the problem of FL from a pre-trained model considered
in prior work and expand it to a set of computer vision transfer learning
problems. We first observe that simply fitting a linear classification head can
be efficient and effective in many cases. We then show that in the FL setting,
fitting a classifier using the Nearest Class Means (NCM) can be done exactly
and orders of magnitude more efficiently than existing proposals, while
obtaining strong performance. Finally, we demonstrate that using a two-phase
approach of obtaining the classifier and then fine-tuning the model can yield
rapid convergence and improved generalization in the federated setting. We
demonstrate the potential our method has to reduce communication and compute
costs while achieving better model performance.
\\ ( https://arxiv.org/abs/2306.03937 ,  12775kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03976
Date: Tue, 6 Jun 2023 19:18:46 GMT   (491kb,D)

Title: Explainable AI using expressive Boolean formulas
Authors: Gili Rosenberg, J. Kyle Brubaker, Martin J. A. Schuetz, Grant Salton,
 Zhihuai Zhu, Elton Yechao Zhu, Serdar Kad{\i}o\u{g}lu, Sima E. Borujeni,
 Helmut G. Katzgraber
Categories: cs.AI cs.LG math.OC quant-ph
Comments: 28 pages, 16 figures, 4 tables
\\
 We propose and implement an interpretable machine learning classification
model for Explainable AI (XAI) based on expressive Boolean formulas. Potential
applications include credit scoring and diagnosis of medical conditions. The
Boolean formula defines a rule with tunable complexity (or interpretability),
according to which input data are classified. Such a formula can include any
operator that can be applied to one or more Boolean variables, thus providing
higher expressivity compared to more rigid rule-based and tree-based
approaches. The classifier is trained using native local optimization
techniques, efficiently searching the space of feasible formulas. Shallow rules
can be determined by fast Integer Linear Programming (ILP) or Quadratic
Unconstrained Binary Optimization (QUBO) solvers, potentially powered by
special purpose hardware or quantum devices. We combine the expressivity and
efficiency of the native local optimizer with the fast operation of these
devices by executing non-local moves that optimize over subtrees of the full
Boolean formula. We provide extensive numerical benchmarking results featuring
several baselines on well-known public datasets. Based on the results, we find
that the native local rule classifier is generally competitive with the other
classifiers. The addition of non-local moves achieves similar results with
fewer iterations, and therefore using specialized or quantum hardware could
lead to a speedup by fast proposal of non-local moves.
\\ ( https://arxiv.org/abs/2306.03976 ,  491kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03980
Date: Tue, 6 Jun 2023 19:33:03 GMT   (614kb,D)

Title: Counterfactual Explanations and Predictive Models to Enhance Clinical
 Decision-Making in Schizophrenia using Digital Phenotyping
Authors: Juan Sebastian Canas, Francisco Gomez, Omar Costilla-Reyes
Categories: cs.AI
\\
 Clinical practice in psychiatry is burdened with the increased demand for
healthcare services and the scarce resources available. New paradigms of health
data powered with machine learning techniques could open the possibility to
improve clinical workflow in critical stages of clinical assessment and
treatment in psychiatry. In this work, we propose a machine learning system
capable of predicting, detecting, and explaining individual changes in symptoms
of patients with Schizophrenia by using behavioral digital phenotyping data. We
forecast symptoms of patients with an error rate below 10%. The system detects
decreases in symptoms using changepoint algorithms and uses counterfactual
explanations as a recourse in a simulated continuous monitoring scenario in
healthcare. Overall, this study offers valuable insights into the performance
and potential of counterfactual explanations, predictive models, and
change-point detection within a simulated clinical workflow. These findings lay
the foundation for further research to explore additional facets of the
workflow, aiming to enhance its effectiveness and applicability in real-world
healthcare settings. By leveraging these components, the goal is to develop an
actionable, interpretable, and trustworthy integrative decision support system
that combines real-time clinical assessments with sensor-based inputs.
\\ ( https://arxiv.org/abs/2306.03980 ,  614kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04018
Date: Tue, 6 Jun 2023 21:19:03 GMT   (1459kb,D)

Title: PyTrial: A Comprehensive Platform for Artificial Intelligence for Drug
 Development
Authors: Zifeng Wang and Brandon Theodorou and Tianfan Fu and Cao Xiao and
 Jimeng Sun
Categories: cs.AI q-bio.QM
\\
 Drug development is a complex process that aims to test the efficacy and
safety of candidate drugs in the human body for regulatory approval via
clinical trials. Recently, machine learning has emerged as a vital tool for
drug development, offering new opportunities to improve the efficiency and
success rates of the process. To facilitate the research and development of
artificial intelligence (AI) for drug development, we developed a Python
package, namely PyTrial, that implements various clinical trial tasks supported
by AI algorithms.
 To be specific, PyTrial implements 6 essential drug development tasks,
including patient outcome prediction, trial site selection, trial outcome
prediction, patient-trial matching, trial similarity search, and synthetic data
generation. In PyTrial, all tasks are defined by four steps: load data, model
definition, model training, and model evaluation, which can be done with a
couple of lines of code. In addition, the modular API design allows
practitioners to extend the framework to new algorithms and tasks easily.
 PyTrial is featured for a unified API, detailed documentation, and
interactive examples with preprocessed benchmark data for all implemented
algorithms. This package can be installed through Python Package Index (PyPI)
and is publicly available at https://github.com/RyanWangZf/PyTrial.
\\ ( https://arxiv.org/abs/2306.04018 ,  1459kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04019
Date: Tue, 6 Jun 2023 21:22:32 GMT   (79kb,D)

Title: Learning Search-Space Specific Heuristics Using Neural Networks
Authors: Yu Liu and Ryo Kuroiwa and Alex Fukunaga
Categories: cs.AI
Comments: Proceedings of ICAPS Workshop on Heuristics and Search for
 Domain-independent Planning (HSDIP) 2020, pp.1-8
\\
 We propose and evaluate a system which learns a neuralnetwork heuristic
function for forward search-based, satisficing classical planning. Our system
learns distance-to-goal estimators from scratch, given a single PDDL training
instance. Training data is generated by backward regression search or by
backward search from given or guessed goal states. In domains such as the
24-puzzle where all instances share the same search space, such heuristics can
also be reused across all instances in the domain. We show that this relatively
simple system can perform surprisingly well, sometimes competitive with
well-known domain-independent heuristics.
\\ ( https://arxiv.org/abs/2306.04019 ,  79kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04025
Date: Tue, 6 Jun 2023 21:38:09 GMT   (510kb,D)

Title: Designing explainable artificial intelligence with active inference: A
 framework for transparent introspection and decision-making
Authors: Mahault Albarracin, In\^es Hip\'olito, Safae Essafi Tremblay, Jason G.
 Fox, Gabriel Ren\'e, Karl Friston, Maxwell J. D. Ramstead
Categories: cs.AI
\\
 This paper investigates the prospect of developing human-interpretable,
explainable artificial intelligence (AI) systems based on active inference and
the free energy principle. We first provide a brief overview of active
inference, and in particular, of how it applies to the modeling of
decision-making, introspection, as well as the generation of overt and covert
actions. We then discuss how active inference can be leveraged to design
explainable AI systems, namely, by allowing us to model core features of
``introspective'' processes and by generating useful, human-interpretable
models of the processes involved in decision-making. We propose an architecture
for explainable AI systems using active inference. This architecture
foregrounds the role of an explicit hierarchical generative model, the
operation of which enables the AI system to track and explain the factors that
contribute to its own decisions, and whose structure is designed to be
interpretable and auditable by human users. We outline how this architecture
can integrate diverse sources of information to make informed decisions in an
auditable manner, mimicking or reproducing aspects of human-like consciousness
and introspection. Finally, we discuss the implications of our findings for
future research in AI, and the potential ethical considerations of developing
AI systems with (the appearance of) introspective capabilities.
\\ ( https://arxiv.org/abs/2306.04025 ,  510kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04031
Date: Tue, 6 Jun 2023 21:49:00 GMT   (3104kb,D)

Title: Certified Reasoning with Language Models
Authors: Gabriel Poesia, Kanishk Gandhi, Eric Zelikman, Noah D. Goodman
Categories: cs.AI
\\
 Language models often achieve higher accuracy when reasoning step-by-step in
complex tasks. However, their reasoning can be unsound, inconsistent, or rely
on undesirable prior assumptions. To tackle these issues, we introduce a class
of tools for language models called guides that use state and incremental
constraints to guide generation. A guide can be invoked by the model to
constrain its own generation to a set of valid statements given by the tool. In
turn, the model's choices can change the guide's state. We show how a general
system for logical reasoning can be used as a guide, which we call LogicGuide.
Given a reasoning problem in natural language, a model can formalize its
assumptions for LogicGuide and then guarantee that its reasoning steps are
sound. In experiments with the PrOntoQA and ProofWriter reasoning datasets,
LogicGuide significantly improves the performance of GPT-3, GPT-3.5 Turbo and
LLaMA (accuracy gains up to 35%). LogicGuide also drastically reduces content
effects: the interference of prior and current assumptions that both humans and
language models have been shown to suffer from. Finally, we explore
bootstrapping LLaMA 13B from its own reasoning and find that LogicGuide is
critical: by training only on certified self-generated reasoning, LLaMA can
self-improve, avoiding learning from its own hallucinations.
\\ ( https://arxiv.org/abs/2306.04031 ,  3104kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04090
Date: Wed, 7 Jun 2023 01:23:38 GMT   (14932kb,D)

Title: Professional Basketball Player Behavior Synthesis via Planning with
 Diffusion
Authors: Xiusi Chen, Wei-Yao Wang, Ziniu Hu, Curtis Chou, Lam Hoang, Kun Jin,
 Mingyan Liu, P. Jeffrey Brantingham, Wei Wang
Categories: cs.AI cs.MA
\\
 Dynamically planning in multi-agent systems has been explored to improve
decision-making in various domains. Professional basketball serves as a
compelling example of a dynamic spatio-temporal game, encompassing both
concealed strategic policies and decision-making. However, processing the
diverse on-court signals and navigating the vast space of potential actions and
outcomes makes it difficult for existing approaches to swiftly identify optimal
strategies in response to evolving circumstances. In this study, we first
formulate the sequential decision-making process as a conditional trajectory
generation process. We further introduce PLAYBEST (PLAYer BEhavior SynThesis),
a method for enhancing player decision-making. We extend the state-of-the-art
generative model, diffusion probabilistic model, to learn challenging
multi-agent environmental dynamics from historical National Basketball
Association (NBA) player motion tracking data. To incorporate data-driven
strategies, an auxiliary value function is trained using the play-by-play data
with corresponding rewards acting as the plan guidance. To accomplish
reward-guided trajectory generation, conditional sampling is introduced to
condition the diffusion model on the value function and conduct
classifier-guided sampling. We validate the effectiveness of PLAYBEST via
comprehensive simulation studies from real-world data, contrasting the
generated trajectories and play strategies with those employed by professional
basketball teams. Our results reveal that the model excels at generating
high-quality basketball trajectories that yield efficient plays, surpassing
conventional planning techniques in terms of adaptability, flexibility, and
overall performance. Moreover, the synthesized play strategies exhibit a
remarkable alignment with professional tactics, highlighting the model's
capacity to capture the intricate dynamics of basketball games.
\\ ( https://arxiv.org/abs/2306.04090 ,  14932kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04123
Date: Wed, 7 Jun 2023 03:38:03 GMT   (5992kb,D)

Title: Retrosynthesis Prediction with Local Template Retrieval
Authors: Shufang Xie, Rui Yan, Junliang Guo, Yingce Xia, Lijun Wu, Tao Qin
Categories: cs.AI cs.LG
Comments: AAAI-2023 camera ready
\\
 Retrosynthesis, which predicts the reactants of a given target molecule, is
an essential task for drug discovery. In recent years, the machine learing
based retrosynthesis methods have achieved promising results. In this work, we
introduce RetroKNN, a local reaction template retrieval method to further boost
the performance of template-based systems with non-parametric retrieval. We
first build an atom-template store and a bond-template store that contain the
local templates in the training data, then retrieve from these templates with a
k-nearest-neighbor (KNN) search during inference. The retrieved templates are
combined with neural network predictions as the final output. Furthermore, we
propose a lightweight adapter to adjust the weights when combing neural network
and KNN predictions conditioned on the hidden representation and the retrieved
templates. We conduct comprehensive experiments on two widely used benchmarks,
the USPTO-50K and USPTO-MIT. Especially for the top-1 accuracy, we improved
7.1% on the USPTO-50K dataset and 12.0% on the USPTO-MIT dataset. These results
demonstrate the effectiveness of our method.
\\ ( https://arxiv.org/abs/2306.04123 ,  5992kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04141
Date: Wed, 7 Jun 2023 04:27:51 GMT   (983kb,D)

Title: Art and the science of generative AI: A deeper dive
Authors: Ziv Epstein, Aaron Hertzmann, Laura Herman, Robert Mahari, Morgan R.
 Frank, Matthew Groh, Hope Schroeder, Amy Smith, Memo Akten, Jessica Fjeld,
 Hany Farid, Neil Leach, Alex Pentland, and Olga Russakovsky
Categories: cs.AI
Comments: This white paper is an expanded version of Epstein et al 2023
 published in Science Perspectives on July 16, 2023 which you can find at the
 following DOI: 10.1126/science.adh4451
\\
 A new class of tools, colloquially called generative AI, can produce
high-quality artistic media for visual arts, concept art, music, fiction,
literature, video, and animation. The generative capabilities of these tools
are likely to fundamentally alter the creative processes by which creators
formulate ideas and put them into production. As creativity is reimagined, so
too may be many sectors of society. Understanding the impact of generative AI -
and making policy decisions around it - requires new interdisciplinary
scientific inquiry into culture, economics, law, algorithms, and the
interaction of technology and creativity. We argue that generative AI is not
the harbinger of art's demise, but rather is a new medium with its own distinct
affordances. In this vein, we consider the impacts of this new medium on
creators across four themes: aesthetics and culture, legal questions of
ownership and credit, the future of creative work, and impacts on the
contemporary media ecosystem. Across these themes, we highlight key research
questions and directions to inform policy and beneficial uses of the
technology.
\\ ( https://arxiv.org/abs/2306.04141 ,  983kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04152
Date: Wed, 7 Jun 2023 05:00:01 GMT   (8371kb,D)

Title: A Unified One-Step Solution for Aspect Sentiment Quad Prediction
Authors: Junxian Zhou, Haiqin Yang, Yuxuan He, Hao Mou, Junbo Yang
Categories: cs.AI
Comments: 15 pages, 12 tables, 3 figures, ACL Findings
\\
 Aspect sentiment quad prediction (ASQP) is a challenging yet significant
subtask in aspect-based sentiment analysis as it provides a complete
aspect-level sentiment structure. However, existing ASQP datasets are usually
small and low-density, hindering technical advancement. To expand the capacity,
in this paper, we release two new datasets for ASQP, which contain the
following characteristics: larger size, more words per sample, and higher
density. With such datasets, we unveil the shortcomings of existing strong ASQP
baselines and therefore propose a unified one-step solution for ASQP, namely
One-ASQP, to detect the aspect categories and to identify the
aspect-opinion-sentiment (AOS) triplets simultaneously. Our One-ASQP holds
several unique advantages: (1) by separating ASQP into two subtasks and solving
them independently and simultaneously, we can avoid error propagation in
pipeline-based methods and overcome slow training and inference in
generation-based methods; (2) by introducing sentiment-specific horns tagging
schema in a token-pair-based two-dimensional matrix, we can exploit deeper
interactions between sentiment elements and efficiently decode the AOS
triplets; (3) we design ``[NULL]'' token can help us effectively identify the
implicit aspects or opinions. Experiments on two benchmark datasets and our
released two datasets demonstrate the advantages of our One-ASQP. The two new
datasets are publicly released at
\url{https://www.github.com/Datastory-CN/ASQP-Datasets}.
\\ ( https://arxiv.org/abs/2306.04152 ,  8371kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04235
Date: Wed, 7 Jun 2023 08:25:51 GMT   (387kb,D)

Title: MobileNMT: Enabling Translation in 15MB and 30ms
Authors: Ye Lin, Xiaohui Wang, Zhexi Zhang, Mingxuan Wang, Tong Xiao, Jingbo
 Zhu
Categories: cs.AI
Comments: accepted by ACL2023 Industry Track
\\
 Deploying NMT models on mobile devices is essential for privacy, low latency,
and offline scenarios. For high model capacity, NMT models are rather large.
Running these models on devices is challenging with limited storage, memory,
computation, and power consumption. Existing work either only focuses on a
single metric such as FLOPs or general engine which is not good at
auto-regressive decoding. In this paper, we present MobileNMT, a system that
can translate in 15MB and 30ms on devices. We propose a series of principles
for model compression when combined with quantization. Further, we implement an
engine that is friendly to INT8 and decoding. With the co-design of model and
engine, compared with the existing system, we speed up 47.0x and save 99.5% of
memory with only 11.6% loss of BLEU. The code is publicly available at
https://github.com/zjersey/Lightseq-ARM.
\\ ( https://arxiv.org/abs/2306.04235 ,  387kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04274
Date: Wed, 7 Jun 2023 09:18:56 GMT   (1100kb,D)

Title: Decentralized Technologies for AI Hubs
Authors: Richard Blythman, Mohamed Arshath, Salvatore Vivona, Jakub Sm\'ekal,
 Hithesh Shaji
Categories: cs.AI
Comments: arXiv admin note: substantial text overlap with arXiv:2210.16651
Journal-ref: 2022 Conference on Neural Information Processing Systems Workshops
\\
 AI requires heavy amounts of storage and compute with assets that are
commonly stored in AI Hubs. AI Hubs have contributed significantly to the
democratization of AI. However, existing implementations are associated with
certain benefits and limitations that stem from the underlying infrastructure
and governance systems with which they are built. These limitations include
high costs, lack of monetization and reward, lack of control and difficulty of
reproducibility. In the current work, we explore the potential of decentralized
technologies - such as Web3 wallets, peer-to-peer marketplaces, storage and
compute, and DAOs - to address some of these issues. We suggest that these
infrastructural components can be used in combination in the design and
construction of decentralized AI Hubs.
\\ ( https://arxiv.org/abs/2306.04274 ,  1100kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04287
Date: Wed, 7 Jun 2023 09:40:13 GMT   (568kb)

Title: Extension of the Blackboard Architecture with Common Properties and
 Generic Rules
Authors: Jonathan Rivard, Jeremy Straub
Categories: cs.AI
\\
 The Blackboard Architecture provides a mechanism for embodying data, decision
making and actuation. Its versatility has been demonstrated across a wide
number of application areas. However, it lacks the capability to directly model
organizational, spatial and other relationships which may be useful in
decision-making, in addition to the propositional logic embodied in the
rule-fact-action network. Previous work has proposed the use of container
objects and links as a mechanism to simultaneously model these organizational
and other relationships, while leaving the operational logic modeled in the
rules, facts and actions. While containers facilitate this modeling, their
utility is limited by the need to manually define them. For systems which may
have multiple instances of a particular type of object and which may build
their network autonomously, based on sensing, the reuse of logical structures
facilitates operations and reduces storage and processing needs. This paper,
thus, presents and assesses two additional concepts to add to the Blackboard
Architecture: common properties and generic rules. Common properties are facts
associated with containers which are defined as representing the same
information across the various objects that they are associated with. Generic
rules provide logical propositions that use these generic rules across links
and apply to any objects matching their definition. The potential uses of these
two new concepts are discussed herein and their impact on system performance is
characterized.
\\ ( https://arxiv.org/abs/2306.04287 ,  568kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04289
Date: Wed, 7 Jun 2023 09:41:46 GMT   (597kb)

Title: Introduction and Assessment of the Addition of Links and Containers to
 the Blackboard Architecture
Authors: Jordan Milbrath, Jeremy Straub
Categories: cs.AI
\\
 The Blackboard Architecture provides a mechanism for storing data and logic
and using it to make decisions that impact the application environment that the
Blackboard Architecture network models. While rule-fact-action networks can
represent numerous types of data, the relationships that can be easily modeled
are limited by the propositional logic nature of the rule-fact network
structure. This paper proposes and evaluates the inclusion of containers and
links in the Blackboard Architecture. These objects are designed to allow them
to model organizational, physical, spatial and other relationships that cannot
be readily or efficiently implemented as Boolean logic rules. Containers group
related facts together and can be nested to implement complex relationships.
Links interconnect containers that have a relationship that is relevant to
their organizational purpose. Both objects, together, facilitate new ways of
using the Blackboard Architecture and enable or simply its use for complex
tasks that have multiple types of relationships that need to be considered
during operations.
\\ ( https://arxiv.org/abs/2306.04289 ,  597kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04292
Date: Wed, 7 Jun 2023 09:46:38 GMT   (4169kb,D)

Title: Dear XAI Community, We Need to Talk! Fundamental Misconceptions in
 Current XAI Research
Authors: Timo Freiesleben and Gunnar K\"onig
Categories: cs.AI stat.ML
Comments: A revised version of this preprint has been accepted at the World XAI
 Conference. It will be referenced as soon as it is published
\\
 Despite progress in the field, significant parts of current XAI research are
still not on solid conceptual, ethical, or methodological grounds.
Unfortunately, these unfounded parts are not on the decline but continue to
grow. Many explanation techniques are still proposed without clarifying their
purpose. Instead, they are advertised with ever more fancy-looking heatmaps or
only seemingly relevant benchmarks. Moreover, explanation techniques are
motivated with questionable goals, such as building trust, or rely on strong
assumptions about the 'concepts' that deep learning algorithms learn. In this
paper, we highlight and discuss these and other misconceptions in current XAI
research. We also suggest steps to make XAI a more substantive area of
research.
\\ ( https://arxiv.org/abs/2306.04292 ,  4169kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04308
Date: Wed, 7 Jun 2023 10:14:17 GMT   (244kb)

Title: Personality testing of GPT-3: Limited temporal reliability, but
 highlighted social desirability of GPT-3's personality instruments results
Authors: Bojana Bodroza (1), Bojana M. Dinic (1) and Ljubisa Bojic (2) ((1)
 Department of Psychology, Faculty of Philosophy, University of Novi Sad,
 Serbia, (2) Digital Society Lab, Institute for Philosophy and Social Theory,
 University of Belgrade, Serbia)
Categories: cs.AI cs.CL cs.HC
Comments: 18 pages, 1 table
\\
 To assess the potential applications and limitations of chatbot GPT-3
Davinci-003, this study explored the temporal reliability of personality
questionnaires applied to the chatbot and its personality profile.
Psychological questionnaires were administered to the chatbot on two separate
occasions, followed by a comparison of the responses to human normative data.
The findings revealed varying levels of agreement in the chatbot's responses
over time, with some scales displaying excellent while others demonstrated poor
agreement. Overall, Davinci-003 displayed a socially desirable and pro-social
personality profile, particularly in the domain of communion. However, the
underlying basis of the chatbot's responses, whether driven by conscious
self-reflection or predetermined algorithms, remains uncertain.
\\ ( https://arxiv.org/abs/2306.04308 ,  244kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04321
Date: Wed, 7 Jun 2023 10:36:36 GMT   (46907kb,D)

Title: Generative Semantic Communication: Diffusion Models Beyond Bit Recovery
Authors: Eleonora Grassucci, Sergio Barbarossa, Danilo Comminiello
Categories: cs.AI
\\
 Semantic communication is expected to be one of the cores of next-generation
AI-based communications. One of the possibilities offered by semantic
communication is the capability to regenerate, at the destination side, images
or videos semantically equivalent to the transmitted ones, without necessarily
recovering the transmitted sequence of bits. The current solutions still lack
the ability to build complex scenes from the received partial information.
Clearly, there is an unmet need to balance the effectiveness of generation
methods and the complexity of the transmitted information, possibly taking into
account the goal of communication. In this paper, we aim to bridge this gap by
proposing a novel generative diffusion-guided framework for semantic
communication that leverages the strong abilities of diffusion models in
synthesizing multimedia content while preserving semantic features. We reduce
bandwidth usage by sending highly-compressed semantic information only. Then,
the diffusion model learns to synthesize semantic-consistent scenes through
spatially-adaptive normalizations from such denoised semantic information. We
prove, through an in-depth assessment of multiple scenarios, that our method
outperforms existing solutions in generating high-quality images with preserved
semantic information even in cases where the received content is significantly
degraded. More specifically, our results show that objects, locations, and
depths are still recognizable even in the presence of extremely noisy
conditions of the communication channel. The code is available at
https://github.com/ispamm/GESCO.
\\ ( https://arxiv.org/abs/2306.04321 ,  46907kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04324
Date: Wed, 7 Jun 2023 10:44:13 GMT   (2068kb,D)

Title: GCT-TTE: Graph Convolutional Transformer for Travel Time Estimation
Authors: Vladimir Mashurov, Vaagn Chopurian, Vadim Porvatov, Arseny Ivanov,
 Natalia Semenova
Categories: cs.AI
\\
 This paper introduces a new transformer-based model for the problem of travel
time estimation. The key feature of the proposed GCT-TTE architecture is the
utilization of different data modalities capturing different properties of an
input path. Along with the extensive study regarding the model configuration,
we implemented and evaluated a sufficient number of actual baselines for
path-aware and path-blind settings. The conducted computational experiments
have confirmed the viability of our pipeline, which outperformed
state-of-the-art models on both considered datasets. Additionally, GCT-TTE was
deployed as a web service accessible for further experiments with user-defined
routes.
\\ ( https://arxiv.org/abs/2306.04324 ,  2068kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04335
Date: Wed, 7 Jun 2023 11:02:35 GMT   (1846kb,D)

Title: Semantic Technologies in Sensor-Based Personal Health Monitoring
 Systems: A Systematic Mapping Study
Authors: Mbithe Nzomo and Deshendran Moodley
Categories: cs.AI
Comments: 40 pages, 6 figures. Under review in the Semantic Web Journal (SWJ).
 https://www.semantic-web-journal.net/content/semantic-technologies-sensor-based-personal-health-monitoring-systems-systematic-mapping
\\
 In recent years, there has been an increased focus on early detection,
prevention, and prediction of diseases. This, together with advances in sensor
technology and the Internet of Things, has led to accelerated efforts in the
development of personal health monitoring systems. Semantic technologies have
emerged as an effective way to not only deal with the issue of interoperability
associated with heterogeneous health sensor data, but also to represent expert
health knowledge to support complex reasoning required for decision-making.
This study evaluates the state of the art in the use of semantic technologies
in sensor-based personal health monitoring systems. Using a systematic
approach, a total of 40 systems representing the state of the art in the field
are analysed. Through this analysis, six key challenges that such systems must
overcome for optimal and effective health monitoring are identified:
interoperability, context awareness, situation detection, situation prediction,
decision support, and uncertainty handling. The study critically evaluates the
extent to which these systems incorporate semantic technologies to deal with
these challenges and identifies the prominent architectures, system development
and evaluation methodologies that are used. The study provides a comprehensive
mapping of the field, identifies inadequacies in the state of the art, and
provides recommendations for future research directions.
\\ ( https://arxiv.org/abs/2306.04335 ,  1846kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04410
Date: Wed, 7 Jun 2023 13:08:46 GMT   (525kb,D)

Title: Meta-Learning in Spiking Neural Networks with Reward-Modulated STDP
Authors: Arsham Gholamzadeh Khoee, Alireza Javaheri, Saeed Reza Kheradpisheh
 and Mohammad Ganjtabesh
Categories: cs.AI
\\
 The human brain constantly learns and rapidly adapts to new situations by
integrating acquired knowledge and experiences into memory. Developing this
capability in machine learning models is considered an important goal of AI
research since deep neural networks perform poorly when there is limited data
or when they need to adapt quickly to new unseen tasks. Meta-learning models
are proposed to facilitate quick learning in low-data regimes by employing
absorbed information from the past. Although some models have recently been
introduced that reached high-performance levels, they are not biologically
plausible. We have proposed a bio-plausible meta-learning model inspired by the
hippocampus and the prefrontal cortex using spiking neural networks with a
reward-based learning system. Our proposed model includes a memory designed to
prevent catastrophic forgetting, a phenomenon that occurs when meta-learning
models forget what they have learned as soon as the new task begins. Also, our
new model can easily be applied to spike-based neuromorphic devices and enables
fast learning in neuromorphic hardware. The final analysis will discuss the
implications and predictions of the model for solving few-shot classification
tasks. In solving these tasks, our model has demonstrated the ability to
compete with the existing state-of-the-art meta-learning techniques.
\\ ( https://arxiv.org/abs/2306.04410 ,  525kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04411
Date: Wed, 7 Jun 2023 13:10:08 GMT   (16238kb,D)

Title: Synthesizing realistic sand assemblies with denoising diffusion in
 latent space
Authors: Nikolaos N. Vlassis, WaiChing Sun, Khalid A. Alshibli, Richard A.
 Regueiro
Categories: cs.AI
Comments: 28 pages, 13 figures, 4 tables
\\
 The shapes and morphological features of grains in sand assemblies have
far-reaching implications in many engineering applications, such as
geotechnical engineering, computer animations, petroleum engineering, and
concentrated solar power. Yet, our understanding of the influence of grain
geometries on macroscopic response is often only qualitative, due to the
limited availability of high-quality 3D grain geometry data. In this paper, we
introduce a denoising diffusion algorithm that uses a set of point clouds
collected from the surface of individual sand grains to generate grains in the
latent space. By employing a point cloud autoencoder, the three-dimensional
point cloud structures of sand grains are first encoded into a
lower-dimensional latent space. A generative denoising diffusion probabilistic
model is trained to produce synthetic sand that maximizes the log-likelihood of
the generated samples belonging to the original data distribution measured by a
Kullback-Leibler divergence. Numerical experiments suggest that the proposed
method is capable of generating realistic grains with morphology, shapes and
sizes consistent with the training data inferred from an F50 sand database . We
then use a rigid contact dynamic simulator to pour the synthetic sand in a
confined volume to form granular assemblies in a static equilibrium state with
targeted distribution properties. To ensure third-party validation, 50,000
synthetic sand grains and the 1,542 real synchrotron microcomputed tomography
(SMT) scans of the F50 sand, as well as the granular assemblies composed of
synthetic sand grains are made available in an open-source repository.
\\ ( https://arxiv.org/abs/2306.04411 ,  16238kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04422
Date: Wed, 7 Jun 2023 13:30:24 GMT   (3668kb,D)

Title: Social robots to improve therapeutic adherence in pediatric asthma
Authors: Laura Montalbano, Agnese Augello, Giovanni Pilato, Stefania La Grutta
Categories: cs.AI cs.HC cs.RO
\\
 In chronic diseases, obtaining a correct diagnosis and providing the most
appropriate treatments often is not enough to guarantee an improvement of the
clinical condition of a patient. Poor adherence to medical prescriptions
constitutes one of the main causes preventing achievement of therapeutic goals.
This is generally true especially for certain diseases and specific target
patients, such as children. An engaging and entertaining technology can be
exploited in support of clinical practices to achieve better health outcomes.
Our assumption is that a gamified session with a humanoid robot, compared to
the usual methodologies for therapeutic education, can be more incisive in
learning the correct inhalation procedure in children affected by asthma. In
this perspective, we describe an interactive module implemented on the Pepper
robotic platform and the setting of a study that was planned in 2020 to be held
at the Pneumoallergology Pediatric clinic of CNR in Palermo. The study was
canceled due to the pandemic and the subsequent and permanent closure of the
clinic. Our long-term goal is to assess, by means of a qualitative-quantitative
survey plan, the impact of such an educational action, evaluating possible
improvement in the adherence to the treatment.
\\ ( https://arxiv.org/abs/2306.04422 ,  3668kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04440
Date: Wed, 7 Jun 2023 13:58:45 GMT   (2117kb,D)

Title: Dual policy as self-model for planning
Authors: Jaesung Yoo, Fernanda de la Torre, Robert Guangyu Yang
Categories: cs.AI cs.LG
\\
 Planning is a data efficient decision-making strategy where an agent selects
candidate actions by exploring possible future states. To simulate future
states when there is a high-dimensional action space, the knowledge of one's
decision making strategy must be used to limit the number of actions to be
explored. We refer to the model used to simulate one's decisions as the agent's
self-model. While self-models are implicitly used widely in conjunction with
world models to plan actions, it remains unclear how self-models should be
designed. Inspired by current reinforcement learning approaches and
neuroscience, we explore the benefits and limitations of using a distilled
policy network as the self-model. In such dual-policy agents, a model-free
policy and a distilled policy are used for model-free actions and planned
actions, respectively. Our results on a ecologically relevant, parametric
environment indicate that distilled policy network for self-model stabilizes
training, has faster inference than using model-free policy, promotes better
exploration, and could learn a comprehensive understanding of its own
behaviors, at the cost of distilling a new network apart from the model-free
policy.
\\ ( https://arxiv.org/abs/2306.04440 ,  2117kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04449
Date: Mon, 5 Jun 2023 17:30:07 GMT   (389kb)

Title: Neural Networks from Biological to Artificial and Vice Versa
Authors: Abdullatif Baba
Categories: cs.AI q-bio.QM
\\
 In this paper, we examine how deep learning can be utilized to investigate
neural health and the difficulties in interpreting neurological analyses within
algorithmic models. The key contribution of this paper is the investigation of
the impact of a dead neuron on the performance of artificial neural networks
(ANNs). Therefore, we conduct several tests using different training algorithms
and activation functions to identify the precise influence of the training
process on neighboring neurons and the overall performance of the ANN in such
cases. The aim is to assess the potential application of the findings in the
biological domain, the expected results may have significant implications for
the development of effective treatment strategies for neurological disorders.
Successive training phases that incorporate visual and acoustic data derived
from past social and familial experiences could be suggested to achieve this
goal. Finally, we explore the conceptual analogy between the Adam optimizer and
the learning process of the brain by delving into the specifics of both systems
while acknowledging their fundamental differences.
\\ ( https://arxiv.org/abs/2306.04449 ,  389kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04484
Date: Wed, 7 Jun 2023 14:53:12 GMT   (1678kb)

Title: Artificial Intelligence can facilitate selfish decisions by altering the
 appearance of interaction partners
Authors: Nils K\"obis, Philipp Lorenz-Spreen, Tamer Ajaj, Jean-Francois
 Bonnefon, Ralph Hertwig, Iyad Rahwan
Categories: cs.AI cs.HC
\\
 The increasing prevalence of image-altering filters on social media and video
conferencing technologies has raised concerns about the ethical and
psychological implications of using Artificial Intelligence (AI) to manipulate
our perception of others. In this study, we specifically investigate the
potential impact of blur filters, a type of appearance-altering technology, on
individuals' behavior towards others. Our findings consistently demonstrate a
significant increase in selfish behavior directed towards individuals whose
appearance is blurred, suggesting that blur filters can facilitate moral
disengagement through depersonalization. These results emphasize the need for
broader ethical discussions surrounding AI technologies that modify our
perception of others, including issues of transparency, consent, and the
awareness of being subject to appearance manipulation by others. We also
emphasize the importance of anticipatory experiments in informing the
development of responsible guidelines and policies prior to the widespread
adoption of such technologies.
\\ ( https://arxiv.org/abs/2306.04484 ,  1678kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04510
Date: Wed, 7 Jun 2023 15:23:59 GMT   (1842kb,D)

Title: Unified Model for Crystalline Material Generation
Authors: Astrid Klipfel and Ya\"el Fr\'egier and Adlane Sayede and Zied
 Bouraoui
Categories: cs.AI
\\
 One of the greatest challenges facing our society is the discovery of new
innovative crystal materials with specific properties. Recently, the problem of
generating crystal materials has received increasing attention, however, it
remains unclear to what extent, or in what way, we can develop generative
models that consider both the periodicity and equivalence geometric of crystal
structures. To alleviate this issue, we propose two unified models that act at
the same time on crystal lattice and atomic positions using periodic
equivariant architectures. Our models are capable to learn any arbitrary
crystal lattice deformation by lowering the total energy to reach thermodynamic
stability. Code and data are available at https://github.com/aklipf/GemsNet.
\\ ( https://arxiv.org/abs/2306.04510 ,  1842kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04528
Date: Wed, 7 Jun 2023 15:37:00 GMT   (423kb,D)

Title: PromptBench: Towards Evaluating the Robustness of Large Language Models
 on Adversarial Prompts
Authors: Kaijie Zhu, Jindong Wang, Jiaheng Zhou, Zichen Wang, Hao Chen, Yidong
 Wang, Linyi Yang, Wei Ye, Neil Zhenqiang Gong, Yue Zhang, Xing Xie
Categories: cs.AI cs.LG
Comments: Technical report; 23 pages
\\
 The increasing reliance on Large Language Models (LLMs) across academia and
industry necessitates a comprehensive understanding of their robustness to
prompts. In response to this vital need, we introduce PromptBench, a robustness
benchmark designed to measure LLMs' resilience to adversarial prompts. This
study uses a plethora of adversarial textual attacks targeting prompts across
multiple levels: character, word, sentence, and semantic. These prompts are
then employed in diverse tasks, such as sentiment analysis, natural language
inference, reading comprehension, machine translation, and math
problem-solving. Our study generates 4,032 adversarial prompts, meticulously
evaluated over 8 tasks and 13 datasets, with 567,084 test samples in total. Our
findings demonstrate that contemporary LLMs are vulnerable to adversarial
prompts. Furthermore, we present comprehensive analysis to understand the
mystery behind prompt robustness and its transferability. We then offer
insightful robustness analysis and pragmatic recommendations for prompt
composition, beneficial to both researchers and everyday users. We make our
code, prompts, and methodologies to generate adversarial prompts publicly
accessible, thereby enabling and encouraging collaborative exploration in this
pivotal field: https://github.com/microsoft/promptbench.
\\ ( https://arxiv.org/abs/2306.04528 ,  423kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04541
Date: Wed, 7 Jun 2023 15:46:28 GMT   (25kb)

Title: Top-Down Knowledge Compilation for Counting Modulo Theories
Authors: Vincent Derkinderen, Pedro Zuidberg Dos Martires, Samuel Kolb, Paolo
 Morettin
Categories: cs.AI
Comments: 9 pages; submitted to Workshop on Counting and Sampling 2023 at
 SAT2023
\\
 Propositional model counting (#SAT) can be solved efficiently when the input
formula is in deterministic decomposable negation normal form (d-DNNF).
Translating an arbitrary formula into a representation that allows inference
tasks, such as counting, to be performed efficiently, is called knowledge
compilation. Top-down knowledge compilation is a state-of-the-art technique for
solving #SAT problems that leverages the traces of exhaustive DPLL search to
obtain d-DNNF representations. While knowledge compilation is well studied for
propositional approaches, knowledge compilation for the (quantifier free)
counting modulo theory setting (#SMT) has been studied to a much lesser degree.
In this paper, we discuss compilation strategies for #SMT. We specifically
advocate for a top-down compiler based on the traces of exhaustive DPLL(T)
search.
\\ ( https://arxiv.org/abs/2306.04541 ,  25kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04546
Date: Wed, 7 Jun 2023 15:50:15 GMT   (181kb,D)

Title: Querying Circumscribed Description Logic Knowledge Bases
Authors: Carsten Lutz, Quentin Mani\`ere, Robin Nolte
Categories: cs.AI cs.CC cs.LO
Comments: 42 pages - Extended version of a paper accepted at KR 2023
\\
 Circumscription is one of the main approaches for defining non-monotonic
description logics (DLs). While the decidability and complexity of traditional
reasoning tasks such as satisfiability of circumscribed DL knowledge bases
(KBs) is well understood, for evaluating conjunctive queries (CQs) and unions
thereof (UCQs), not even decidability had been established. In this paper, we
prove decidability of (U)CQ evaluation on circumscribed DL KBs and obtain a
rather complete picture of both the combined complexity and the data
complexity, for DLs ranging from ALCHIO via EL to various versions of DL-Lite.
We also study the much simpler atomic queries (AQs).
\\ ( https://arxiv.org/abs/2306.04546 ,  181kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04563
Date: Wed, 7 Jun 2023 16:10:21 GMT   (599kb,D)

Title: ChatGPT is fun, but it is not funny! Humor is still challenging Large
 Language Models
Authors: Sophie Jentzsch, Kristian Kersting
Categories: cs.AI cs.CL cs.HC cs.LG
\\
 Humor is a central aspect of human communication that has not been solved for
artificial agents so far. Large language models (LLMs) are increasingly able to
capture implicit and contextual information. Especially, OpenAI's ChatGPT
recently gained immense public attention. The GPT3-based model almost seems to
communicate on a human level and can even tell jokes. Humor is an essential
component of human communication. But is ChatGPT really funny? We put ChatGPT's
sense of humor to the test. In a series of exploratory experiments around
jokes, i.e., generation, explanation, and detection, we seek to understand
ChatGPT's capability to grasp and reproduce human humor. Since the model itself
is not accessible, we applied prompt-based experiments. Our empirical evidence
indicates that jokes are not hard-coded but mostly also not newly generated by
the model. Over 90% of 1008 generated jokes were the same 25 Jokes. The system
accurately explains valid jokes but also comes up with fictional explanations
for invalid jokes. Joke-typical characteristics can mislead ChatGPT in the
classification of jokes. ChatGPT has not solved computational humor yet but it
can be a big leap toward "funny" machines.
\\ ( https://arxiv.org/abs/2306.04563 ,  599kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03932
Date: Tue, 6 Jun 2023 18:00:47 GMT   (8849kb,D)

Title: Q: How to Specialize Large Vision-Language Models to Data-Scarce VQA
 Tasks? A: Self-Train on Unlabeled Images!
Authors: Zaid Khan, Vijay Kumar BG, Samuel Schulter, Xiang Yu, Yun Fu, Manmohan
 Chandraker
Categories: cs.CV
Comments: CVPR 2023
\\
 Finetuning a large vision language model (VLM) on a target dataset after
large scale pretraining is a dominant paradigm in visual question answering
(VQA). Datasets for specialized tasks such as knowledge-based VQA or VQA in non
natural-image domains are orders of magnitude smaller than those for
general-purpose VQA. While collecting additional labels for specialized tasks
or domains can be challenging, unlabeled images are often available. We
introduce SelTDA (Self-Taught Data Augmentation), a strategy for finetuning
large VLMs on small-scale VQA datasets. SelTDA uses the VLM and target dataset
to build a teacher model that can generate question-answer pseudolabels
directly conditioned on an image alone, allowing us to pseudolabel unlabeled
images. SelTDA then finetunes the initial VLM on the original dataset augmented
with freshly pseudolabeled images. We describe a series of experiments showing
that our self-taught data augmentation increases robustness to adversarially
searched questions, counterfactual examples and rephrasings, improves domain
generalization, and results in greater retention of numerical reasoning skills.
The proposed strategy requires no additional annotations or architectural
modifications, and is compatible with any modern encoder-decoder multimodal
transformer. Code available at https://github.com/codezakh/SelTDA.
\\ ( https://arxiv.org/abs/2306.03932 ,  8849kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03954
Date: Tue, 6 Jun 2023 18:30:51 GMT   (7825kb,D)

Title: Recognition of Handwritten Japanese Characters Using Ensemble of
 Convolutional Neural Networks
Authors: Angel I. Solis, Justin Zarkovacki, John Ly and Adham Atyabi
Categories: cs.CV cs.AI cs.CL cs.LG
\\
 The Japanese writing system is complex, with three character types of
Hiragana, Katakana, and Kanji. Kanji consists of thousands of unique
characters, further adding to the complexity of character identification and
literature understanding. Being able to translate handwritten Japanese
characters into digital text is useful for data analysis, translation, learning
and cultural preservation. In this study, a machine learning approach to
analyzing and recognizing handwritten Japanese characters (Kanji) is proposed.
The study used an ensemble of three convolutional neural networks (CNNs) for
recognizing handwritten Kanji characters and utilized four datasets of MNIST,
K-MNIST, Kuzushiji-49 (K49) and the top 150 represented classes in the
Kuzushiji-Kanji (K-Kanji) dataset for its performance evaluation. The results
indicate feasibility of using proposed CNN-ensemble architecture for
recognizing handwritten characters, achieving 99.4%, 96.4%, 95.0% and 96.4%
classification accuracy on MNIST, K-MNIS, K49, and K-Kanji datasets
respectively.
\\ ( https://arxiv.org/abs/2306.03954 ,  7825kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03988
Date: Tue, 6 Jun 2023 19:50:02 GMT   (41141kb,D)

Title: Learn the Force We Can: Multi-Object Video Generation from Pixel-Level
 Interactions
Authors: Aram Davtyan and Paolo Favaro
Categories: cs.CV cs.AI
Comments: Project website: https://araachie.github.io/yoda
\\
 We propose a novel unsupervised method to autoregressively generate videos
from a single frame and a sparse motion input. Our trained model can generate
realistic object-to-object interactions and separate the dynamics and the
extents of multiple objects despite only observing them under correlated motion
activities. Key components in our method are the randomized conditioning
scheme, the encoding of the input motion control, and the randomized and sparse
sampling to break correlations. Our model, which we call YODA, has the ability
to move objects without physically touching them. We show both qualitatively
and quantitatively that YODA accurately follows the user control, while
yielding a video quality that is on par with or better than state of the art
video generation prior work on several datasets. For videos, visit our project
website https://araachie.github.io/yoda.
\\ ( https://arxiv.org/abs/2306.03988 ,  41141kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03993
Date: Tue, 6 Jun 2023 20:08:54 GMT   (12966kb,D)

Title: Real-Time Online Unsupervised Domain Adaptation for Real-World Person
 Re-identification
Authors: Christopher Neff, Armin Danesh Pazho, Hamed Tabkhi
Categories: cs.CV cs.AI cs.LG
\\
 Following the popularity of Unsupervised Domain Adaptation (UDA) in person
re-identification, the recently proposed setting of Online Unsupervised Domain
Adaptation (OUDA) attempts to bridge the gap towards practical applications by
introducing a consideration of streaming data. However, this still falls short
of truly representing real-world applications. This paper defines the setting
of Real-world Real-time Online Unsupervised Domain Adaptation (R$^2$OUDA) for
Person Re-identification. The R$^2$OUDA setting sets the stage for true
real-world real-time OUDA, bringing to light four major limitations found in
real-world applications that are often neglected in current research: system
generated person images, subset distribution selection, time-based data stream
segmentation, and a segment-based time constraint. To address all aspects of
this new R$^2$OUDA setting, this paper further proposes Real-World Real-Time
Online Streaming Mutual Mean-Teaching (R$^2$MMT), a novel multi-camera system
for real-world person re-identification. Taking a popular person
re-identification dataset, R$^2$MMT was used to construct over 100 data subsets
and train more than 3000 models, exploring the breadth of the R$^2$OUDA setting
to understand the training time and accuracy trade-offs and limitations for
real-world applications. R$^2$MMT, a real-world system able to respect the
strict constraints of the proposed R$^2$OUDA setting, achieves accuracies
within 0.1% of comparable OUDA methods that cannot be applied directly to
real-world applications.
\\ ( https://arxiv.org/abs/2306.03993 ,  12966kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04000
Date: Tue, 6 Jun 2023 20:28:04 GMT   (38264kb,D)

Title: A Quality Aware Sample-to-Sample Comparison for Face Recognition
Authors: Mohammad Saeed Ebrahimi Saadabadi, Sahar Rahimi Malakshan, Ali Zafari,
 Moktari Mostofa, Nasser M. Nasrabadi
Categories: cs.CV
Comments: IEEE/CVF Winter Conference on Applications of Computer Vision
 (WACV23)
\\
 Currently available face datasets mainly consist of a large number of
high-quality and a small number of low-quality samples. As a result, a Face
Recognition (FR) network fails to learn the distribution of low-quality samples
since they are less frequent during training (underrepresented). Moreover,
current state-of-the-art FR training paradigms are based on the
sample-to-center comparison (i.e., Softmax-based classifier), which results in
a lack of uniformity between train and test metrics. This work integrates a
quality-aware learning process at the sample level into the classification
training paradigm (QAFace). In this regard, Softmax centers are adaptively
guided to pay more attention to low-quality samples by using a quality-aware
function. Accordingly, QAFace adds a quality-based adjustment to the updating
procedure of the Softmax-based classifier to improve the performance on the
underrepresented low-quality samples. Our method adaptively finds and assigns
more attention to the recognizable low-quality samples in the training
datasets. In addition, QAFace ignores the unrecognizable low-quality samples
using the feature magnitude as a proxy for quality. As a result, QAFace
prevents class centers from getting distracted from the optimal direction. The
proposed method is superior to the state-of-the-art algorithms in extensive
experimental results on the CFP-FP, LFW, CPLFW, CALFW, AgeDB, IJB-B, and IJB-C
datasets.
\\ ( https://arxiv.org/abs/2306.04000 ,  38264kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04021
Date: Tue, 6 Jun 2023 21:27:08 GMT   (26197kb,D)

Title: Energy-Based Models for Cross-Modal Localization using Convolutional
 Transformers
Authors: Alan Wu and Michael S. Ryoo
Categories: cs.CV cs.AI cs.LG cs.RO
Comments: ICRA 2023
\\
 We present a novel framework using Energy-Based Models (EBMs) for localizing
a ground vehicle mounted with a range sensor against satellite imagery in the
absence of GPS. Lidar sensors have become ubiquitous on autonomous vehicles for
describing its surrounding environment. Map priors are typically built using
the same sensor modality for localization purposes. However, these map building
endeavors using range sensors are often expensive and time-consuming.
Alternatively, we leverage the use of satellite images as map priors, which are
widely available, easily accessible, and provide comprehensive coverage. We
propose a method using convolutional transformers that performs accurate
metric-level localization in a cross-modal manner, which is challenging due to
the drastic difference in appearance between the sparse range sensor readings
and the rich satellite imagery. We train our model end-to-end and demonstrate
our approach achieving higher accuracy than the state-of-the-art on KITTI,
Pandaset, and a custom dataset.
\\ ( https://arxiv.org/abs/2306.04021 ,  26197kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04032
Date: Tue, 6 Jun 2023 21:49:56 GMT   (9518kb,D)

Title: BokehOrNot: Transforming Bokeh Effect with Image Transformer and Lens
 Metadata Embedding
Authors: Zhihao Yang, Wenyi Lian, Siyuan Lai
Categories: cs.CV cs.LG eess.IV
\\
 Bokeh effect is an optical phenomenon that offers a pleasant visual
experience, typically generated by high-end cameras with wide aperture lenses.
The task of bokeh effect transformation aims to produce a desired effect in one
set of lenses and apertures based on another combination. Current models are
limited in their ability to render a specific set of bokeh effects, primarily
transformations from sharp to blur. In this paper, we propose a novel universal
method for embedding lens metadata into the model and introducing a loss
calculation method using alpha masks from the newly released Bokeh Effect
Transformation Dataset(BETD) [3]. Based on the above techniques, we propose the
BokehOrNot model, which is capable of producing both blur-to-sharp and
sharp-to-blur bokeh effect with various combinations of lenses and aperture
sizes. Our proposed model outperforms current leading bokeh rendering and image
restoration models and renders visually natural bokeh effects. Our code is
available at: https://github.com/indicator0/bokehornot.
\\ ( https://arxiv.org/abs/2306.04032 ,  9518kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04047
Date: Tue, 6 Jun 2023 22:32:49 GMT   (8525kb,D)

Title: Active Sparse Conversations for Improved Audio-Visual Embodied
 Navigation
Authors: Xiulong Liu, Sudipta Paul, Moitreya Chatterjee, Anoop Cherian
Categories: cs.CV cs.AI cs.CL cs.LG
\\
 Efficient navigation towards an audio-goal necessitates an embodied agent to
not only possess the ability to use audio-visual cues effectively, but also be
equipped to actively (but occasionally) seek human/oracle assistance without
sacrificing autonomy, e.g., when it is uncertain of where to navigate towards
locating a noisy or sporadic audio goal. To this end, we present CAVEN -- a
conversational audio-visual embodied navigation agent that is capable of posing
navigation questions to a human/oracle and processing the oracle responses;
both in free-form natural language. At the core of CAVEN is a multimodal
hierarchical reinforcement learning (RL) setup that is equipped with a
high-level policy that is trained to choose from one of three low-level
policies (at every step), namely: (i) to navigate using audio-visual cues, or
(ii) to frame a question to the oracle and receive a short or detailed
response, or (iii) ask generic questions (when unsure of what to ask) and
receive instructions. Key to generating the agent's questions is our novel
TrajectoryNet that forecasts the most likely next steps to the goal and a
QuestionNet that uses these steps to produce a question. All the policies are
learned end-to-end via the RL setup, with penalties to enforce sparsity in
receiving navigation instructions from the oracle. To evaluate the performance
of CAVEN, we present extensive experiments on the SoundSpaces framework for the
task of semantic audio-visual navigation. Our results show that CAVEN achieves
upto 12% gain in performance over competing methods, especially in localizing
new sound sources, even in the presence of auditory distractions.
\\ ( https://arxiv.org/abs/2306.04047 ,  8525kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04091
Date: Wed, 7 Jun 2023 01:24:48 GMT   (421kb,D)

Title: 1st Place Solution for PVUW Challenge 2023: Video Panoptic Segmentation
Authors: Tao Zhang and Xingye Tian and Haoran Wei and Yu Wu and Shunping Ji and
 Xuebo Wang and Yuan Zhang and Pengfei Wan
Categories: cs.CV
\\
 Video panoptic segmentation is a challenging task that serves as the
cornerstone of numerous downstream applications, including video editing and
autonomous driving. We believe that the decoupling strategy proposed by DVIS
enables more effective utilization of temporal information for both "thing" and
"stuff" objects. In this report, we successfully validated the effectiveness of
the decoupling strategy in video panoptic segmentation. Finally, our method
achieved a VPQ score of 51.4 and 53.7 in the development and test phases,
respectively, and ultimately ranked 1st in the VPS track of the 2nd PVUW
Challenge. The code is available at https://github.com/zhang-tao-whu/DVIS
\\ ( https://arxiv.org/abs/2306.04091 ,  421kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04114
Date: Wed, 7 Jun 2023 02:55:09 GMT   (11446kb,D)

Title: Manga Rescreening with Interpretable Screentone Representation
Authors: Minshan Xie, Chengze Li, and Tien-Tsin Wong
Categories: cs.CV eess.IV
Comments: 10 pages, 11 figures
\\
 The process of adapting or repurposing manga pages is a time-consuming task
that requires manga artists to manually work on every single screentone region
and apply new patterns to create novel screentones across multiple panels. To
address this issue, we propose an automatic manga rescreening pipeline that
aims to minimize the human effort involved in manga adaptation. Our pipeline
automatically recognizes screentone regions and generates novel screentones
with newly specified characteristics (e.g., intensity or type). Existing manga
generation methods have limitations in understanding and synthesizing complex
tone- or intensity-varying regions. To overcome these limitations, we propose a
novel interpretable representation of screentones that disentangles their
intensity and type features, enabling better recognition and synthesis of
screentones. This interpretable screentone representation reduces ambiguity in
recognizing intensity-varying regions and provides fine-grained controls during
screentone synthesis by decoupling and anchoring the type or the intensity
feature. Our proposed method is demonstrated to be effective and convenient
through various experiments, showcasing the superiority of the newly proposed
pipeline with the interpretable screentone representations.
\\ ( https://arxiv.org/abs/2306.04114 ,  11446kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04121
Date: Wed, 7 Jun 2023 03:31:39 GMT   (6579kb,D)

Title: Matte Anything: Interactive Natural Image Matting with Segment Anything
 Models
Authors: Jingfeng Yao, Xinggang Wang, Lang Ye, and Wenyu Liu
Categories: cs.CV
Comments: Technical Report
\\
 Natural image matting algorithms aim to predict the transparency map
(alpha-matte) with the trimap guidance. However, the production of trimaps
often requires significant labor, which limits the widespread application of
matting algorithms on a large scale. To address the issue, we propose Matte
Anything model (MatAny), an interactive natural image matting model which could
produce high-quality alpha-matte with various simple hints. The key insight of
MatAny is to generate pseudo trimap automatically with contour and transparency
prediction. We leverage task-specific vision models to enhance the performance
of natural image matting. Specifically, we use the segment anything model (SAM)
to predict high-quality contour with user interaction and an open-vocabulary
(OV) detector to predict the transparency of any object. Subsequently, a
pretrained image matting model generates alpha mattes with pseudo trimaps.
MatAny is the interactive matting algorithm with the most supported interaction
methods and the best performance to date. It consists of orthogonal vision
models without any additional training. We evaluate the performance of MatAny
against several current image matting algorithms, and the results demonstrate
the significant potential of our approach.
\\ ( https://arxiv.org/abs/2306.04121 ,  6579kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04147
Date: Wed, 7 Jun 2023 04:49:26 GMT   (5572kb,D)

Title: CFDP: Common Frequency Domain Pruning
Authors: Samir Khaki, Weihan Luo
Categories: cs.CV
Comments: CVPR ECV 2023 Accepted Paper
\\
 As the saying goes, sometimes less is more -- and when it comes to neural
networks, that couldn't be more true. Enter pruning, the art of selectively
trimming away unnecessary parts of a network to create a more streamlined,
efficient architecture. In this paper, we introduce a novel end-to-end pipeline
for model pruning via the frequency domain. This work aims to shed light on the
interoperability of intermediate model outputs and their significance beyond
the spatial domain. Our method, dubbed Common Frequency Domain Pruning (CFDP)
aims to extrapolate common frequency characteristics defined over the feature
maps to rank the individual channels of a layer based on their level of
importance in learning the representation. By harnessing the power of CFDP, we
have achieved state-of-the-art results on CIFAR-10 with GoogLeNet reaching an
accuracy of 95.25%, that is, +0.2% from the original model. We also outperform
all benchmarks and match the original model's performance on ImageNet, using
only 55% of the trainable parameters and 60% of the FLOPs. In addition to
notable performances, models produced via CFDP exhibit robustness to a variety
of configurations including pruning from untrained neural architectures, and
resistance to adversarial attacks. The implementation code can be found at
https://github.com/Skhaki18/CFDP.
\\ ( https://arxiv.org/abs/2306.04147 ,  5572kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04166
Date: Wed, 7 Jun 2023 05:36:45 GMT   (6562kb,D)

Title: BAA-NGP: Bundle-Adjusting Accelerated Neural Graphics Primitives
Authors: Sainan Liu, Shan Lin, Jingpei Lu, Shreya Saha, Alexey Supikov, Michael
 Yip
Categories: cs.CV
\\
 Implicit neural representation has emerged as a powerful method for
reconstructing 3D scenes from 2D images. Given a set of camera poses and
associated images, the models can be trained to synthesize novel, unseen views.
In order to expand the use cases for implicit neural representations, we need
to incorporate camera pose estimation capabilities as part of the
representation learning, as this is necessary for reconstructing scenes from
real-world video sequences where cameras are generally not being tracked.
Existing approaches like COLMAP and, most recently, bundle-adjusting neural
radiance field methods often suffer from lengthy processing times. These delays
ranging from hours to days, arise from laborious feature matching, hardware
limitations, dense point sampling, and long training times required by a
multi-layer perceptron structure with a large number of parameters. To address
these challenges, we propose a framework called bundle-adjusting accelerated
neural graphics primitives (BAA-NGP). Our approach leverages accelerated
sampling and hash encoding to expedite both pose refinement/estimation and 3D
scene reconstruction. Experimental results demonstrate that our method achieves
a more than 10 to 20 $\times$ speed improvement in novel view synthesis
compared to other bundle-adjusting neural radiance field methods without
sacrificing the quality of pose estimation.
\\ ( https://arxiv.org/abs/2306.04166 ,  6562kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04175
Date: Wed, 7 Jun 2023 05:59:20 GMT   (2878kb,D)

Title: ScoreCL: Augmentation-Adaptive Contrastive Learning via Score-Matching
 Function
Authors: JinYoung Kim, Soonwoo Kwon, Hyojun Go, Yunsung Lee, and Seungtaek Choi
Categories: cs.CV
\\
 Self-supervised contrastive learning (CL) has achieved state-of-the-art
performance in representation learning by minimizing the distance between
positive pairs while maximizing that of negative ones. Recently, it has been
verified that the model learns better representation with diversely augmented
positive pairs because they enable the model to be more view-invariant.
However, only a few studies on CL have considered the difference between
augmented views, and have not gone beyond the hand-crafted findings. In this
paper, we first observe that the score-matching function can measure how much
data has changed from the original through augmentation. With the observed
property, every pair in CL can be weighted adaptively by the difference of
score values, resulting in boosting the performance of the existing CL method.
We show the generality of our method, referred to as ScoreCL, by consistently
improving various CL methods, SimCLR, SimSiam, W-MSE, and VICReg, up to 3%p in
k-NN evaluation on CIFAR-10, CIFAR-100, and ImageNet-100. Moreover, we have
conducted exhaustive experiments and ablations, including results on diverse
downstream tasks, comparison with possible baselines, and improvement when used
with other proposed augmentation methods. We hope our exploration will inspire
more research in exploiting the score matching for CL.
\\ ( https://arxiv.org/abs/2306.04175 ,  2878kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04180
Date: Wed, 7 Jun 2023 06:29:03 GMT   (4213kb,D)

Title: FusedRF: Fusing Multiple Radiance Fields
Authors: Rahul Goel, Dhawal Sirikonda, Rajvi Shah, PJ Narayanan
Categories: cs.CV
Comments: XRNeRF CVPR Workshop Paper
\\
 Radiance Fields (RFs) have shown great potential to represent scenes from
casually captured discrete views. Compositing parts or whole of multiple
captured scenes could greatly interest several XR applications. Prior works can
generate new views of such scenes by tracing each scene in parallel. This
increases the render times and memory requirements with the number of
components. In this work, we provide a method to create a single, compact,
fused RF representation for a scene composited using multiple RFs. The fused RF
has the same render times and memory utilizations as a single RF. Our method
distills information from multiple teacher RFs into a single student RF while
also facilitating further manipulations like addition and deletion into the
fused representation.
\\ ( https://arxiv.org/abs/2306.04180 ,  4213kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04184
Date: Wed, 7 Jun 2023 06:40:54 GMT   (11644kb,D)

Title: StructuredMesh: 3D Structured Optimization of Fa\c{c}ade Components on
 Photogrammetric Mesh Models using Binary Integer Programming
Authors: Libin Wang, Han Hu, Qisen Shang, Bo Xu, Qing Zhu
Categories: cs.CV
Comments: 30 pages,15 figures
MSC-class: 68U05
ACM-class: I.5.3
\\
 The lack of fa\c{c}ade structures in photogrammetric mesh models renders them
inadequate for meeting the demands of intricate applications. Moreover, these
mesh models exhibit irregular surfaces with considerable geometric noise and
texture quality imperfections, making the restoration of structures
challenging. To address these shortcomings, we present StructuredMesh, a novel
approach for reconstructing fa\c{c}ade structures conforming to the regularity
of buildings within photogrammetric mesh models. Our method involves capturing
multi-view color and depth images of the building model using a virtual camera
and employing a deep learning object detection pipeline to semi-automatically
extract the bounding boxes of fa\c{c}ade components such as windows, doors, and
balconies from the color image. We then utilize the depth image to remap these
boxes into 3D space, generating an initial fa\c{c}ade layout. Leveraging
architectural knowledge, we apply binary integer programming (BIP) to optimize
the 3D layout's structure, encompassing the positions, orientations, and sizes
of all components. The refined layout subsequently informs fa\c{c}ade modeling
through instance replacement. We conducted experiments utilizing building mesh
models from three distinct datasets, demonstrating the adaptability,
robustness, and noise resistance of our proposed methodology. Furthermore, our
3D layout evaluation metrics reveal that the optimized layout enhances
precision, recall, and F-score by 6.5%, 4.5%, and 5.5%, respectively, in
comparison to the initial layout.
\\ ( https://arxiv.org/abs/2306.04184 ,  11644kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04216
Date: Wed, 7 Jun 2023 07:43:11 GMT   (30721kb,D)

Title: MultiSum: A Dataset for Multimodal Summarization and Thumbnail
 Generation of Videos
Authors: Jielin Qiu, Jiacheng Zhu, William Han, Aditesh Kumar, Karthik Mittal,
 Claire Jin, Zhengyuan Yang, Linjie Li, Jianfeng Wang, Bo Li, Ding Zhao,
 Lijuan Wang
Categories: cs.CV
Comments: Project website: https://multisum-dataset.github.io/
\\
 Multimodal summarization with multimodal output (MSMO) has emerged as a
promising research direction. Nonetheless, numerous limitations exist within
existing public MSMO datasets, including insufficient upkeep, data
inaccessibility, limited size, and the absence of proper categorization, which
pose significant challenges to effective research. To address these challenges
and provide a comprehensive dataset for this new direction, we have
meticulously curated the MultiSum dataset. Our new dataset features (1)
Human-validated summaries for both video and textual content, providing
superior human instruction and labels for multimodal learning. (2)
Comprehensively and meticulously arranged categorization, spanning 17 principal
categories and 170 subcategories to encapsulate a diverse array of real-world
scenarios. (3) Benchmark tests performed on the proposed dataset to assess
varied tasks and methods, including video temporal segmentation, video
summarization, text summarization, and multimodal summarization. To champion
accessibility and collaboration, we release the MultiSum dataset and the data
collection tool as fully open-source resources, fostering transparency and
accelerating future developments. Our project website can be found at
https://multisum-dataset.github.io/.
\\ ( https://arxiv.org/abs/2306.04216 ,  30721kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04225
Date: Wed, 7 Jun 2023 08:02:17 GMT   (3540kb,D)

Title: Efficient Vision Transformer for Human Pose Estimation via Patch
 Selection
Authors: Kaleab A. Kinfu and Ren\'e Vidal
Categories: cs.CV cs.LG
\\
 While Convolutional Neural Networks (CNNs) have been widely successful in 2D
human pose estimation, Vision Transformers (ViTs) have emerged as a promising
alternative to CNNs, boosting state-of-the-art performance. However, the
quadratic computational complexity of ViTs has limited their applicability for
processing high-resolution images and long videos. To address this challenge,
we propose a simple method for reducing ViT's computational complexity based on
selecting and processing a small number of most informative patches while
disregarding others. We leverage a lightweight pose estimation network to guide
the patch selection process, ensuring that the selected patches contain the
most important information. Our experimental results on three widely used 2D
pose estimation benchmarks, namely COCO, MPII and OCHuman, demonstrate the
effectiveness of our proposed methods in significantly improving speed and
reducing computational complexity with a slight drop in performance.
\\ ( https://arxiv.org/abs/2306.04225 ,  3540kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04231
Date: Wed, 7 Jun 2023 08:14:17 GMT   (17294kb,D)

Title: Learning Probabilistic Coordinate Fields for Robust Correspondences
Authors: Weiyue Zhao, Hao Lu, Xinyi Ye, Zhiguo Cao, Xin Li
Categories: cs.CV
Comments: Accepted by IEEE Transactions on Pattern Analysis and Machine
 Intelligence
\\
 We introduce Probabilistic Coordinate Fields (PCFs), a novel
geometric-invariant coordinate representation for image correspondence
problems. In contrast to standard Cartesian coordinates, PCFs encode
coordinates in correspondence-specific barycentric coordinate systems (BCS)
with affine invariance. To know \textit{when and where to trust} the encoded
coordinates, we implement PCFs in a probabilistic network termed PCF-Net, which
parameterizes the distribution of coordinate fields as Gaussian mixture models.
By jointly optimizing coordinate fields and their confidence conditioned on
dense flows, PCF-Net can work with various feature descriptors when quantifying
the reliability of PCFs by confidence maps. An interesting observation of this
work is that the learned confidence map converges to geometrically coherent and
semantically consistent regions, which facilitates robust coordinate
representation. By delivering the confident coordinates to keypoint/feature
descriptors, we show that PCF-Net can be used as a plug-in to existing
correspondence-dependent approaches. Extensive experiments on both indoor and
outdoor datasets suggest that accurate geometric invariant coordinates help to
achieve the state of the art in several correspondence problems, such as sparse
feature matching, dense image registration, camera pose estimation, and
consistency filtering. Further, the interpretable confidence map predicted by
PCF-Net can also be leveraged to other novel applications from texture transfer
to multi-homography classification.
\\ ( https://arxiv.org/abs/2306.04231 ,  17294kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04236
Date: Wed, 7 Jun 2023 08:27:44 GMT   (16334kb,D)

Title: Flare7K++: Mixing Synthetic and Real Datasets for Nighttime Flare
 Removal and Beyond
Authors: Yuekun Dai, Chongyi Li, Shangchen Zhou, Ruicheng Feng, Yihang Luo,
 Chen Change Loy
Categories: cs.CV eess.IV
Comments: Extension of arXiv:2210.06570; Project page at
 https://ykdai.github.io/projects/Flare7K
\\
 Artificial lights commonly leave strong lens flare artifacts on the images
captured at night, degrading both the visual quality and performance of vision
algorithms. Existing flare removal approaches mainly focus on removing daytime
flares and fail in nighttime cases. Nighttime flare removal is challenging due
to the unique luminance and spectrum of artificial lights, as well as the
diverse patterns and image degradation of the flares. The scarcity of the
nighttime flare removal dataset constraints the research on this crucial task.
In this paper, we introduce Flare7K++, the first comprehensive nighttime flare
removal dataset, consisting of 962 real-captured flare images (Flare-R) and
7,000 synthetic flares (Flare7K). Compared to Flare7K, Flare7K++ is
particularly effective in eliminating complicated degradation around the light
source, which is intractable by using synthetic flares alone. Besides, the
previous flare removal pipeline relies on the manual threshold and blur kernel
settings to extract light sources, which may fail when the light sources are
tiny or not overexposed. To address this issue, we additionally provide the
annotations of light sources in Flare7K++ and propose a new end-to-end pipeline
to preserve the light source while removing lens flares. Our dataset and
pipeline offer a valuable foundation and benchmark for future investigations
into nighttime flare removal studies. Extensive experiments demonstrate that
Flare7K++ supplements the diversity of existing flare datasets and pushes the
frontier of nighttime flare removal towards real-world scenarios.
\\ ( https://arxiv.org/abs/2306.04236 ,  16334kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04237
Date: Wed, 7 Jun 2023 08:28:38 GMT   (4753kb,D)

Title: Randomized 3D Scene Generation for Generalizable Self-supervised
 Pre-training
Authors: Lanxiao Li and Michael Heizmann
Categories: cs.CV
\\
 Capturing and labeling real-world 3D data is laborious and time-consuming,
which makes it costly to train strong 3D models. To address this issue,
previous works generate randomized 3D scenes and pre-train models on generated
data. Although the pre-trained models gain promising performance boosts,
previous works have two major shortcomings. First, they focus on only one
downstream task (i.e., object detection). Second, a fair comparison of
generated data is still lacking. In this work, we systematically compare data
generation methods using a unified setup. To clarify the generalization of the
pre-trained models, we evaluate their performance in multiple tasks (e.g.,
object detection and semantic segmentation) and with different pre-training
methods (e.g., masked autoencoder and contrastive learning). Moreover, we
propose a new method to generate 3D scenes with spherical harmonics. It
surpasses the previous formula-driven method with a clear margin and achieves
on-par results with methods using real-world scans and CAD models.
\\ ( https://arxiv.org/abs/2306.04237 ,  4753kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04240
Date: Wed, 7 Jun 2023 08:30:44 GMT   (756kb,D)

Title: T-ADAF: Adaptive Data Augmentation Framework for Image Classification
 Network based on Tensor T-product Operator
Authors: Feiyang Han, Yun Miao, Zhaoyi Sun, Yimin Wei
Categories: cs.CV cs.NA math.NA
\\
 Image classification is one of the most fundamental tasks in Computer Vision.
In practical applications, the datasets are usually not as abundant as those in
the laboratory and simulation, which is always called as Data Hungry. How to
extract the information of data more completely and effectively is very
important. Therefore, an Adaptive Data Augmentation Framework based on the
tensor T-product Operator is proposed in this paper, to triple one image data
to be trained and gain the result from all these three images together with
only less than 0.1% increase in the number of parameters. At the same time,
this framework serves the functions of column image embedding and global
feature intersection, enabling the model to obtain information in not only
spatial but frequency domain, and thus improving the prediction accuracy of the
model. Numerical experiments have been designed for several models, and the
results demonstrate the effectiveness of this adaptive framework. Numerical
experiments show that our data augmentation framework can improve the
performance of original neural network model by 2%, which provides competitive
results to state-of-the-art methods.
\\ ( https://arxiv.org/abs/2306.04240 ,  756kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04244
Date: Wed, 7 Jun 2023 08:35:27 GMT   (6347kb,D)

Title: Coarse Is Better? A New Pipeline Towards Self-Supervised Learning with
 Uncurated Images
Authors: Ke Zhu, Yin-Yin He, Jianxin Wu
Categories: cs.CV
\\
 Most self-supervised learning (SSL) methods often work on curated datasets
where the object-centric assumption holds. This assumption breaks down in
uncurated scene images. Existing scene image SSL methods try to find the two
views from original scene images that are well matched or dense, which is both
complex and computationally heavy. This paper proposes a conceptually different
pipeline: first find regions that are coarse objects (with adequate
objectness), crop them out as pseudo object-centric images, then any SSL method
can be directly applied as in a real object-centric dataset. That is, cropping
benefits scene images SSL. A novel cropping strategy is proposed to find coarse
object regions in scene images. The proposed pipeline and cropping strategy
successfully learn high quality visual representation from uncurated scene
datasets like MS-COCO, and the learning does not rely on external
object-centric datasets such as ImageNet. Experiments show that our pipeline
outperforms existing SSL methods on scene images, and is friendly for
non-contrastive SSL methods like MAE. Ablations further verify that the
proposed cropping strategy does not rely on pretrained SSL models, too.
\\ ( https://arxiv.org/abs/2306.04244 ,  6347kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04269
Date: Wed, 7 Jun 2023 09:09:35 GMT   (16762kb,D)

Title: ColNav: Real-Time Colon Navigation for Colonoscopy
Authors: Netanel Frank and Erez Posner and Emmanuelle Muhlethaler and Adi
 Zholkover and Moshe Bouhnik
Categories: cs.CV cs.HC cs.LG
\\
 Colorectal cancer screening through colonoscopy continues to be the dominant
global standard, as it allows identifying pre-cancerous or adenomatous lesions
and provides the ability to remove them during the procedure itself.
Nevertheless, failure by the endoscopist to identify such lesions increases the
likelihood of lesion progression to subsequent colorectal cancer. Ultimately,
colonoscopy remains operator-dependent, and the wide range of quality in
colonoscopy examinations among endoscopists is influenced by variations in
their technique, training, and diligence. This paper presents a novel real-time
navigation guidance system for Optical Colonoscopy (OC). Our proposed system
employs a real-time approach that displays both an unfolded representation of
the colon and a local indicator directing to un-inspected areas. These
visualizations are presented to the physician during the procedure, providing
actionable and comprehensible guidance to un-surveyed areas in real-time, while
seamlessly integrating into the physician's workflow. Through coverage
experimental evaluation, we demonstrated that our system resulted in a higher
polyp recall (PR) and high inter-rater reliability with physicians for coverage
prediction. These results suggest that our real-time navigation guidance system
has the potential to improve the quality and effectiveness of Optical
Colonoscopy and ultimately benefit patient outcomes.
\\ ( https://arxiv.org/abs/2306.04269 ,  16762kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04272
Date: Wed, 7 Jun 2023 09:13:56 GMT   (840kb,D)

Title: On the Generalization of Multi-modal Contrastive Learning
Authors: Qi Zhang, Yifei Wang, Yisen Wang
Categories: cs.CV
\\
 Multi-modal contrastive learning (MMCL) has recently garnered considerable
interest due to its superior performance in visual tasks, achieved by embedding
multi-modal data, such as visual-language pairs. However, there still lack
theoretical understandings of how MMCL extracts useful visual representation
from multi-modal pairs, and particularly, how MMCL outperforms previous
approaches like self-supervised contrastive learning (SSCL). In this paper, by
drawing an intrinsic connection between MMCL and asymmetric matrix
factorization, we establish the first generalization guarantees of MMCL for
visual downstream tasks. Based on this framework, we further unify MMCL and
SSCL by showing that MMCL implicitly performs SSCL with (pseudo) positive pairs
induced by text pairs. Through this unified perspective, we characterize the
advantage of MMCL by showing that text pairs induce more semantically
consistent and diverse positive pairs, which, according to our analysis,
provably benefit downstream generalization. Inspired by this finding, we
propose CLIP-guided resampling methods to significantly improve the downstream
performance of SSCL on ImageNet by leveraging multi-modal information. Code is
available at https://github.com/PKU-ML/CLIP-Help-SimCLR.
\\ ( https://arxiv.org/abs/2306.04272 ,  840kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04300
Date: Wed, 7 Jun 2023 10:02:29 GMT   (4883kb,D)

Title: CorrMatch: Label Propagation via Correlation Matching for
 Semi-Supervised Semantic Segmentation
Authors: Boyuan Sun, Yuqi Yang, Le Zhang, Ming-Ming Cheng, Qibin Hou
Categories: cs.CV
\\
 In this paper, we present a simple but performant semi-supervised semantic
segmentation approach, termed CorrMatch. Our goal is to mine more high-quality
regions from the unlabeled images to leverage the unlabeled data more
efficiently via consistency regularization. The key contributions of our
CorrMatch are two novel and complementary strategies. First, we introduce an
adaptive threshold updating strategy with a relaxed initialization to expand
the high-quality regions. Furthermore, we propose to propagate high-confidence
predictions through measuring the pairwise similarities between pixels. Despite
its simplicity, we show that CorrMatch achieves great performance on popular
semi-supervised semantic segmentation benchmarks. Taking the DeepLabV3+
framework with ResNet-101 backbone as our segmentation model, we receive a 76%+
mIoU score on the Pascal VOC 2012 segmentation benchmark with only 92 annotated
images provided. We also achieve a consistent improvement over previous
semi-supervised semantic segmentation models. Code will be made publicly
available.
\\ ( https://arxiv.org/abs/2306.04300 ,  4883kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04344
Date: Wed, 7 Jun 2023 11:18:53 GMT   (4151kb,D)

Title: ViDA: Homeostatic Visual Domain Adapter for Continual Test Time
 Adaptation
Authors: Jiaming Liu, Senqiao Yang, Peidong Jia, Ming Lu, Yandong Guo, Wei Xue,
 Shanghang Zhang
Categories: cs.CV
\\
 Since real-world machine systems are running in non-stationary and
continually changing environments, Continual Test-Time Adaptation (CTTA) task
is proposed to adapt the pre-trained model to continually changing target
domains. Recently, existing methods mainly focus on model-based adaptation,
which aims to leverage a self-training manner to extract the target domain
knowledge. However, pseudo labels can be noisy and the updated model parameters
are uncertain under dynamic data distributions, leading to error accumulation
and catastrophic forgetting in the continual adaptation process. To tackle
these challenges and maintain the model plasticity, we tactfully design a
Visual Domain Adapter (ViDA) for CTTA, explicitly handling both domain-specific
and domain-agnostic knowledge. Specifically, we first comprehensively explore
the different domain representations of the adapters with trainable high and
low-rank embedding space. Then we inject ViDAs into the pre-trained model,
which leverages high-rank and low-rank prototypes to adapt the current domain
distribution and maintain the continual domain-shared knowledge, respectively.
To adapt to the various distribution shifts of each sample in target domains,
we further propose a Homeostatic Knowledge Allotment (HKA) strategy, which
adaptively merges knowledge from each ViDA with different rank prototypes.
Extensive experiments conducted on four widely-used benchmarks demonstrate that
our proposed method achieves state-of-the-art performance in both
classification and segmentation CTTA tasks. In addition, our method can be
regarded as a novel transfer paradigm and showcases promising results in
zero-shot adaptation of foundation models to continual downstream tasks and
distributions.
\\ ( https://arxiv.org/abs/2306.04344 ,  4151kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04345
Date: Wed, 7 Jun 2023 11:20:01 GMT   (2023kb,D)

Title: An Overview of Challenges in Egocentric Text-Video Retrieval
Authors: Burak Satar, Hongyuan Zhu, Hanwang Zhang, Joo Hwee Lim
Categories: cs.CV cs.IR cs.MM
Comments: 4 pages, CVPR 2023 Joint Ego4D&EPIC Workshop, Extended Abstract
\\
 Text-video retrieval contains various challenges, including biases coming
from diverse sources. We highlight some of them supported by illustrations to
open a discussion. Besides, we address one of the biases, frame length bias,
with a simple method which brings a very incremental but promising increase. We
conclude with future directions.
\\ ( https://arxiv.org/abs/2306.04345 ,  2023kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04356
Date: Wed, 7 Jun 2023 11:39:56 GMT   (4544kb,D)

Title: Fine-Grained Visual Prompting
Authors: Lingfeng Yang, Yueze Wang, Xiang Li, Xinlong Wang, Jian Yang
Categories: cs.CV
\\
 Vision-Language Models (VLMs), such as CLIP, have demonstrated impressive
zero-shot transfer capabilities in image-level visual perception. However,
these models have shown limited performance in instance-level tasks that demand
precise localization and recognition. Previous works have suggested that
incorporating visual prompts, such as colorful boxes or circles, can improve
the ability of models to recognize objects of interest. Nonetheless, compared
to language prompting, visual prompting designs are rarely explored. Existing
approaches, which employ coarse visual cues such as colorful boxes or circles,
often result in sub-optimal performance due to the inclusion of irrelevant and
noisy pixels. In this paper, we carefully study the visual prompting designs by
exploring more fine-grained markings, such as segmentation masks and their
variations. In addition, we introduce a new zero-shot framework that leverages
pixel-level annotations acquired from a generalist segmentation model for
fine-grained visual prompting. Consequently, our investigation reveals that a
straightforward application of blur outside the target mask, referred to as the
Blur Reverse Mask, exhibits exceptional effectiveness. This proposed prompting
strategy leverages the precise mask annotations to reduce focus on weakly
related regions while retaining spatial coherence between the target and the
surrounding background. Our Fine-Grained Visual Prompting (FGVP) demonstrates
superior performance in zero-shot comprehension of referring expressions on the
RefCOCO, RefCOCO+, and RefCOCOg benchmarks. It outperforms prior methods by an
average margin of 3.0% to 4.6%, with a maximum improvement of 12.5% on the
RefCOCO+ testA subset. The part detection experiments conducted on the PACO
dataset further validate the preponderance of FGVP over existing visual
prompting techniques. Code and models will be made available.
\\ ( https://arxiv.org/abs/2306.04356 ,  4544kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04362
Date: Wed, 7 Jun 2023 11:52:36 GMT   (6306kb,D)

Title: Youku-mPLUG: A 10 Million Large-scale Chinese Video-Language Dataset for
 Pre-training and Benchmarks
Authors: Haiyang Xu, Qinghao Ye, Xuan Wu, Ming Yan, Yuan Miao, Jiabo Ye, Guohai
 Xu, Anwen Hu, Yaya Shi, Guangwei Xu, Chenliang Li, Qi Qian, Maofei Que, Ji
 Zhang, Xiao Zeng, Fei Huang
Categories: cs.CV cs.CL
Comments: Working in progress
\\
 To promote the development of Vision-Language Pre-training (VLP) and
multimodal Large Language Model (LLM) in the Chinese community, we firstly
release the largest public Chinese high-quality video-language dataset named
Youku-mPLUG, which is collected from Youku, a well-known Chinese video-sharing
website, with strict criteria of safety, diversity, and quality. Youku-mPLUG
contains 10 million Chinese video-text pairs filtered from 400 million raw
videos across a wide range of 45 diverse categories for large-scale
pre-training. In addition, to facilitate a comprehensive evaluation of
video-language models, we carefully build the largest human-annotated Chinese
benchmarks covering three popular video-language tasks of cross-modal
retrieval, video captioning, and video category classification. Youku-mPLUG can
enable researchers to conduct more in-depth multimodal research and develop
better applications in the future. Furthermore, we release popular
video-language pre-training models, ALPRO and mPLUG-2, and our proposed
modularized decoder-only model mPLUG-video pre-trained on Youku-mPLUG.
Experiments show that models pre-trained on Youku-mPLUG gain up to 23.1%
improvement in video category classification. Besides, mPLUG-video achieves a
new state-of-the-art result on these benchmarks with 80.5% top-1 accuracy in
video category classification and 68.9 CIDEr score in video captioning,
respectively. Finally, we scale up mPLUG-video based on the frozen Bloomz with
only 1.7% trainable parameters as Chinese multimodal LLM, and demonstrate
impressive instruction and video understanding ability. The zero-shot
instruction understanding experiment indicates that pretraining with
Youku-mPLUG can enhance the ability to comprehend overall and detailed visual
semantics, recognize scene text, and leverage open-domain knowledge.
\\ ( https://arxiv.org/abs/2306.04362 ,  6306kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04385
Date: Wed, 7 Jun 2023 12:34:55 GMT   (39783kb,D)

Title: SF-FSDA: Source-Free Few-Shot Domain Adaptive Object Detection with
 Efficient Labeled Data Factory
Authors: Han Sun, Rui Gong, Konrad Schindler, Luc Van Gool
Categories: cs.CV
\\
 Domain adaptive object detection aims to leverage the knowledge learned from
a labeled source domain to improve the performance on an unlabeled target
domain. Prior works typically require the access to the source domain data for
adaptation, and the availability of sufficient data on the target domain.
However, these assumptions may not hold due to data privacy and rare data
collection. In this paper, we propose and investigate a more practical and
challenging domain adaptive object detection problem under both source-free and
few-shot conditions, named as SF-FSDA. To overcome this problem, we develop an
efficient labeled data factory based approach. Without accessing the source
domain, the data factory renders i) infinite amount of synthesized
target-domain like images, under the guidance of the few-shot image samples and
text description from the target domain; ii) corresponding bounding box and
category annotations, only demanding minimum human effort, i.e., a few manually
labeled examples. On the one hand, the synthesized images mitigate the
knowledge insufficiency brought by the few-shot condition. On the other hand,
compared to the popular pseudo-label technique, the generated annotations from
data factory not only get rid of the reliance on the source pretrained object
detection model, but also alleviate the unavoidably pseudo-label noise due to
domain shift and source-free condition. The generated dataset is further
utilized to adapt the source pretrained object detection model, realizing the
robust object detection under SF-FSDA. The experiments on different settings
showcase that our proposed approach outperforms other state-of-the-art methods
on SF-FSDA problem. Our codes and models will be made publicly available.
\\ ( https://arxiv.org/abs/2306.04385 ,  39783kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04387
Date: Wed, 7 Jun 2023 12:35:37 GMT   (7285kb,D)

Title: M$^3$IT: A Large-Scale Dataset towards Multi-Modal Multilingual
 Instruction Tuning
Authors: Lei Li, Yuwei Yin, Shicheng Li, Liang Chen, Peiyi Wang, Shuhuai Ren,
 Mukai Li, Yazheng Yang, Jingjing Xu, Xu Sun, Lingpeng Kong, Qi Liu
Categories: cs.CV cs.CL
Comments: Dataset available at: https://huggingface.co/MMInstruction/M3IT
\\
 Instruction tuning has significantly advanced large language models (LLMs)
such as ChatGPT, enabling them to align with human instructions across diverse
tasks. However, progress in open vision-language models (VLMs) has been limited
due to the scarcity of high-quality instruction datasets. To tackle this
challenge and promote research in the vision-language field, we introduce the
Multi-Modal, Multilingual Instruction Tuning (M$^3$IT) dataset, designed to
optimize VLM alignment with human instructions. Our M$^3$IT dataset comprises
40 carefully curated datasets, including 2.4 million instances and 400 manually
written task instructions, reformatted into a vision-to-text structure. Key
tasks are translated into 80 languages with an advanced translation system,
ensuring broader accessibility. M$^3$IT surpasses previous datasets regarding
task coverage, instruction number and instance scale. Moreover, we develop
Ying-VLM, a VLM model trained on our M$^3$IT dataset, showcasing its potential
to answer complex questions requiring world knowledge, generalize to unseen
video tasks, and comprehend unseen instructions in Chinese. To encourage
further research, we have open-sourced both the dataset and trained models.
\\ ( https://arxiv.org/abs/2306.04387 ,  7285kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04396
Date: Wed, 7 Jun 2023 12:56:56 GMT   (8546kb,D)

Title: Improving Diffusion-based Image Translation using Asymmetric Gradient
 Guidance
Authors: Gihyun Kwon, Jong Chul Ye
Categories: cs.CV cs.AI cs.LG stat.ML
\\
 Diffusion models have shown significant progress in image translation tasks
recently. However, due to their stochastic nature, there's often a trade-off
between style transformation and content preservation. Current strategies aim
to disentangle style and content, preserving the source image's structure while
successfully transitioning from a source to a target domain under text or
one-shot image conditions. Yet, these methods often require computationally
intense fine-tuning of diffusion models or additional neural networks. To
address these challenges, here we present an approach that guides the reverse
process of diffusion sampling by applying asymmetric gradient guidance. This
results in quicker and more stable image manipulation for both text-guided and
image-guided image translation. Our model's adaptability allows it to be
implemented with both image- and latent-diffusion models. Experiments show that
our method outperforms various state-of-the-art models in image translation
tasks.
\\ ( https://arxiv.org/abs/2306.04396 ,  8546kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04451
Date: Tue, 6 Jun 2023 07:58:59 GMT   (2758kb,D)

Title: Referring Expression Comprehension Using Language Adaptive Inference
Authors: Wei Su, Peihan Miao, Huanzhang Dou, Yongjian Fu, and Xi Li
Categories: cs.CV
Comments: Accepted by AAAI2023
\\
 Different from universal object detection, referring expression comprehension
(REC) aims to locate specific objects referred to by natural language
expressions. The expression provides high-level concepts of relevant visual and
contextual patterns, which vary significantly with different expressions and
account for only a few of those encoded in the REC model. This leads us to a
question: do we really need the entire network with a fixed structure for
various referring expressions? Ideally, given an expression, only
expression-relevant components of the REC model are required. These components
should be small in number as each expression only contains very few visual and
contextual clues. This paper explores the adaptation between expressions and
REC models for dynamic inference. Concretely, we propose a neat yet efficient
framework named Language Adaptive Dynamic Subnets (LADS), which can extract
language-adaptive subnets from the REC model conditioned on the referring
expressions. By using the compact subnet, the inference can be more economical
and efficient. Extensive experiments on RefCOCO, RefCOCO+, RefCOCOg, and
Referit show that the proposed method achieves faster inference speed and
higher accuracy against state-of-the-art approaches.
\\ ( https://arxiv.org/abs/2306.04451 ,  2758kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04466
Date: Sun, 4 Jun 2023 10:30:28 GMT   (268kb,D)

Title: Point Cloud Video Anomaly Detection Based on Point Spatio-Temporal
 Auto-Encoder
Authors: Tengjiao He and Wenguang Wang
Categories: cs.CV eess.SP
\\
 Video anomaly detection has great potential in enhancing safety in the
production and monitoring of crucial areas. Currently, most video anomaly
detection methods are based on RGB modality, but its redundant semantic
information may breach the privacy of residents or patients. The 3D data
obtained by depth camera and LiDAR can accurately locate anomalous events in 3D
space while preserving human posture and motion information. Identifying
individuals through the point cloud is difficult due to its sparsity, which
protects personal privacy. In this study, we propose Point Spatio-Temporal
Auto-Encoder (PSTAE), an autoencoder framework that uses point cloud videos as
input to detect anomalies in point cloud videos. We introduce PSTOp and
PSTTransOp to maintain spatial geometric and temporal motion information in
point cloud videos. To measure the reconstruction loss of the proposed
autoencoder framework, we propose a reconstruction loss measurement strategy
based on a shallow feature extractor. Experimental results on the TIMo dataset
show that our method outperforms currently representative depth modality-based
methods in terms of AUROC and has superior performance in detecting Medical
Issue anomalies. These results suggest the potential of point cloud modality in
video anomaly detection. Our method sets a new state-of-the-art (SOTA) on the
TIMo dataset.
\\ ( https://arxiv.org/abs/2306.04466 ,  268kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04474
Date: Wed, 7 Jun 2023 14:45:24 GMT   (5003kb,D)

Title: FoSp: Focus and Separation Network for Early Smoke Segmentation
Authors: Lujian Yao, Haitao Zhao, Jingchao Peng, Zhongze Wang, Kaijie Zhao
Categories: cs.CV
\\
 Early smoke segmentation (ESS) enables the accurate identification of smoke
sources, facilitating the prompt extinguishing of fires and preventing
large-scale gas leaks. But ESS poses greater challenges than conventional
object and regular smoke segmentation due to its small scale and transparent
appearance, which can result in high miss detection rate and low precision. To
address these issues, a Focus and Separation Network (FoSp) is proposed. We
first introduce a Focus module employing bidirectional cascade which guides
low-resolution and high-resolution features towards mid-resolution to locate
and determine the scope of smoke, reducing the miss detection rate. Next, we
propose a Separation module that separates smoke images into a pure smoke
foreground and a smoke-free background, enhancing the contrast between smoke
and background fundamentally, improving segmentation precision. Finally, a
Domain Fusion module is developed to integrate the distinctive features of the
two modules which can balance recall and precision to achieve high F_beta.
Futhermore, to promote the development of ESS, we introduce a high-quality
real-world dataset called SmokeSeg, which contains more small and transparent
smoke than the existing datasets. Experimental results show that our model
achieves the best performance on three available datasets: SYN70K (mIoU:
83.00%), SMOKE5K (F_beta: 81.6%) and SmokeSeg (F_beta: 72.05%). Especially, our
FoSp outperforms SegFormer by 7.71% (F_beta) for early smoke segmentation on
SmokeSeg.
\\ ( https://arxiv.org/abs/2306.04474 ,  5003kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04482
Date: Wed, 7 Jun 2023 17:42:42 GMT   (15361kb,D)

Title: ICON$^2$: Reliably Benchmarking Predictive Inequity in Object Detection
Authors: Sruthi Sudhakar, Viraj Prabhu, Olga Russakovsky, Judy Hoffman
Categories: cs.CV
Comments: Accepted to CVPR 2023 SSAD Workshop
\\
 As computer vision systems are being increasingly deployed at scale in
high-stakes applications like autonomous driving, concerns about social bias in
these systems are rising. Analysis of fairness in real-world vision systems,
such as object detection in driving scenes, has been limited to observing
predictive inequity across attributes such as pedestrian skin tone, and lacks a
consistent methodology to disentangle the role of confounding variables e.g.
does my model perform worse for a certain skin tone, or are such scenes in my
dataset more challenging due to occlusion and crowds? In this work, we
introduce ICON$^2$, a framework for robustly answering this question. ICON$^2$
leverages prior knowledge on the deficiencies of object detection systems to
identify performance discrepancies across sub-populations, compute correlations
between these potential confounders and a given sensitive attribute, and
control for the most likely confounders to obtain a more reliable estimate of
model bias. Using our approach, we conduct an in-depth study on the performance
of object detection with respect to income from the BDD100K driving dataset,
revealing useful insights.
\\ ( https://arxiv.org/abs/2306.04482 ,  15361kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04506
Date: Wed, 7 Jun 2023 15:15:13 GMT   (18460kb,D)

Title: Defocus to focus: Photo-realistic bokeh rendering by fusing defocus and
 radiance priors
Authors: Xianrui Luo, Juewen Peng, Ke Xian, Zijin Wu, Zhiguo Cao
Categories: cs.CV
Comments: Published at Information Fusion 2023
 https://www.sciencedirect.com/science/article/pii/S1566253522001221
Journal-ref: [J]. Information Fusion, 2023, 89: 320-335
DOI: 10.1016/j.inffus.2022.08.023
\\
 We consider the problem of realistic bokeh rendering from a single
all-in-focus image. Bokeh rendering mimics aesthetic shallow depth-of-field
(DoF) in professional photography, but these visual effects generated by
existing methods suffer from simple flat background blur and blurred in-focus
regions, giving rise to unrealistic rendered results. In this work, we argue
that realistic bokeh rendering should (i) model depth relations and distinguish
in-focus regions, (ii) sustain sharp in-focus regions, and (iii) render
physically accurate Circle of Confusion (CoC). To this end, we present a
Defocus to Focus (D2F) framework to learn realistic bokeh rendering by fusing
defocus priors with the all-in-focus image and by implementing radiance priors
in layered fusion. Since no depth map is provided, we introduce defocus
hallucination to integrate depth by learning to focus. The predicted defocus
map implies the blur amount of bokeh and is used to guide weighted layered
rendering. In layered rendering, we fuse images blurred by different kernels
based on the defocus map. To increase the reality of the bokeh, we adopt
radiance virtualization to simulate scene radiance. The scene radiance used in
weighted layered rendering reassigns weights in the soft disk kernel to produce
the CoC. To ensure the sharpness of in-focus regions, we propose to fuse
upsampled bokeh images and original images. We predict the initial fusion mask
from our defocus map and refine the mask with a deep network. We evaluate our
model on a large-scale bokeh dataset. Extensive experiments show that our
approach is capable of rendering visually pleasing bokeh effects in complex
scenes. In particular, our solution receives the runner-up award in the AIM
2020 Rendering Realistic Bokeh Challenge.
\\ ( https://arxiv.org/abs/2306.04506 ,  18460kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04507
Date: Wed, 7 Jun 2023 15:17:54 GMT   (13467kb,D)

Title: Improving neural network representations using human similarity
 judgments
Authors: Lukas Muttenthaler and Lorenz Linhardt and Jonas Dippel and Robert A.
 Vandermeulen and Katherine Hermann and Andrew K. Lampinen and Simon Kornblith
Categories: cs.CV cs.LG
\\
 Deep neural networks have reached human-level performance on many computer
vision tasks. However, the objectives used to train these networks enforce only
that similar images are embedded at similar locations in the representation
space, and do not directly constrain the global structure of the resulting
space. Here, we explore the impact of supervising this global structure by
linearly aligning it with human similarity judgments. We find that a naive
approach leads to large changes in local representational structure that harm
downstream performance. Thus, we propose a novel method that aligns the global
structure of representations while preserving their local structure. This
global-local transform considerably improves accuracy across a variety of
few-shot learning and anomaly detection tasks. Our results indicate that human
visual representations are globally organized in a way that facilitates
learning from few examples, and incorporating this global structure into neural
network representations improves performance on downstream tasks.
\\ ( https://arxiv.org/abs/2306.04507 ,  13467kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04540
Date: Wed, 7 Jun 2023 15:46:15 GMT   (3694kb,D)

Title: NeMO: Neural Map Growing System for Spatiotemporal Fusion in
 Bird's-Eye-View and BDD-Map Benchmark
Authors: Xi Zhu, Xiya Cao, Zhiwei Dong, Caifa Zhou, Qiangbo Liu, Wei Li,
 Yongliang Wang
Categories: cs.CV
\\
 Vision-centric Bird's-Eye View (BEV) representation is essential for
autonomous driving systems (ADS). Multi-frame temporal fusion which leverages
historical information has been demonstrated to provide more comprehensive
perception results. While most research focuses on ego-centric maps of fixed
settings, long-range local map generation remains less explored. This work
outlines a new paradigm, named NeMO, for generating local maps through the
utilization of a readable and writable big map, a learning-based fusion module,
and an interaction mechanism between the two. With an assumption that the
feature distribution of all BEV grids follows an identical pattern, we adopt a
shared-weight neural network for all grids to update the big map. This paradigm
supports the fusion of longer time series and the generation of long-range BEV
local maps. Furthermore, we release BDD-Map, a BDD100K-based dataset
incorporating map element annotations, including lane lines, boundaries, and
pedestrian crossing. Experiments on the NuScenes and BDD-Map datasets
demonstrate that NeMO outperforms state-of-the-art map segmentation methods. We
also provide a new scene-level BEV map evaluation setting along with the
corresponding baseline for a more comprehensive comparison.
\\ ( https://arxiv.org/abs/2306.04540 ,  3694kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04557
Date: Wed, 7 Jun 2023 16:04:08 GMT   (14216kb,D)

Title: PhenoBench -- A Large Dataset and Benchmarks for Semantic Image
 Interpretation in the Agricultural Domain
Authors: Jan Weyler and Federico Magistri and Elias Marks and Yue Linn Chong
 and Matteo Sodano and Gianmarco Roggiolani and Nived Chebrolu and Cyrill
 Stachniss and Jens Behley
Categories: cs.CV cs.RO
\\
 The production of food, feed, fiber, and fuel is a key task of agriculture.
Especially crop production has to cope with a multitude of challenges in the
upcoming decades caused by a growing world population, climate change, the need
for sustainable production, lack of skilled workers, and generally the limited
availability of arable land. Vision systems could help cope with these
challenges by offering tools to make better and more sustainable field
management decisions and support the breeding of new varieties of crops by
allowing temporally dense and reproducible measurements. Recently, tackling
perception tasks in the agricultural domain got increasing interest in the
computer vision and robotics community since agricultural robotics are one
promising solution for coping with the lack of workers and enable a more
sustainable agricultural production at the same time. While large datasets and
benchmarks in other domains are readily available and have enabled significant
progress toward more reliable vision systems, agricultural datasets and
benchmarks are comparably rare. In this paper, we present a large dataset and
benchmarks for the semantic interpretation of images of real agricultural
fields. Our dataset recorded with a UAV provides high-quality, dense
annotations of crops and weeds, but also fine-grained labels of crop leaves at
the same time, which enable the development of novel algorithms for visual
perception in the agricultural domain. Together with the labeled data, we
provide novel benchmarks for evaluating different visual perception tasks on a
hidden test set comprised of different fields: known fields covered by the
training data and a completely unseen field. The tasks cover semantic
segmentation, panoptic segmentation of plants, leaf instance segmentation,
detection of plants and leaves, and hierarchical panoptic segmentation for
jointly identifying plants and leaves.
\\ ( https://arxiv.org/abs/2306.04557 ,  14216kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04593
Date: Wed, 7 Jun 2023 16:46:44 GMT   (17251kb,D)

Title: MarineVRS: Marine Video Retrieval System with Explainability via
 Semantic Understanding
Authors: Tan-Sang Ha, Hai Nguyen-Truong, Tuan-Anh Vu, Sai-Kit Yeung
Categories: cs.CV cs.IR
Comments: Accepted to OCEANS 2023 Limerick. Website:
 https://marinevrs.hkustvgd.com/
\\
 Building a video retrieval system that is robust and reliable, especially for
the marine environment, is a challenging task due to several factors such as
dealing with massive amounts of dense and repetitive data, occlusion,
blurriness, low lighting conditions, and abstract queries. To address these
challenges, we present MarineVRS, a novel and flexible video retrieval system
designed explicitly for the marine domain. MarineVRS integrates
state-of-the-art methods for visual and linguistic object representation to
enable efficient and accurate search and analysis of vast volumes of underwater
video data. In addition, unlike the conventional video retrieval system, which
only permits users to index a collection of images or videos and search using a
free-form natural language sentence, our retrieval system includes an
additional Explainability module that outputs the segmentation masks of the
objects that the input query referred to. This feature allows users to identify
and isolate specific objects in the video footage, leading to more detailed
analysis and understanding of their behavior and movements. Finally, with its
adaptability, explainability, accuracy, and scalability, MarineVRS is a
powerful tool for marine researchers and scientists to efficiently and
accurately process vast amounts of data and gain deeper insights into the
behavior and movements of marine species.
\\ ( https://arxiv.org/abs/2306.04593 ,  17251kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04607
Date: Wed, 7 Jun 2023 17:17:58 GMT   (8986kb,D)

Title: Integrating Geometric Control into Text-to-Image Diffusion Models for
 High-Quality Detection Data Generation via Text Prompt
Authors: Kai Chen, Enze Xie, Zhe Chen, Lanqing Hong, Zhenguo Li, Dit-Yan Yeung
Categories: cs.CV cs.AI
\\
 Diffusion models have attracted significant attention due to their remarkable
ability to create content and generate data for tasks such as image
classification. However, the usage of diffusion models to generate high-quality
object detection data remains an underexplored area, where not only the
image-level perceptual quality but also geometric conditions such as bounding
boxes and camera views are essential. Previous studies have utilized either
copy-paste synthesis or layout-to-image (L2I) generation with specifically
designed modules to encode semantic layouts. In this paper, we propose
GeoDiffusion, a simple framework that can flexibly translate various geometric
conditions into text prompts and empower the pre-trained text-to-image (T2I)
diffusion models for high-quality detection data generation. Unlike previous
L2I methods, our GeoDiffusion is able to encode not only bounding boxes but
also extra geometric conditions such as camera views in self-driving scenes.
Extensive experiments demonstrate GeoDiffusion outperforms previous L2I methods
while maintaining 4x training time faster. To the best of our knowledge, this
is the first work to adopt diffusion models for layout-to-image generation with
geometric conditions and demonstrate that L2I-generated images can be
beneficial for improving the performance of object detectors.
\\ ( https://arxiv.org/abs/2306.04607 ,  8986kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04619
Date: Wed, 7 Jun 2023 17:47:50 GMT   (17117kb,D)

Title: ARTIC3D: Learning Robust Articulated 3D Shapes from Noisy Web Image
 Collections
Authors: Chun-Han Yao, Amit Raj, Wei-Chih Hung, Yuanzhen Li, Michael
 Rubinstein, Ming-Hsuan Yang, Varun Jampani
Categories: cs.CV
Comments: Project page: https://chhankyao.github.io/artic3d/
\\
 Estimating 3D articulated shapes like animal bodies from monocular images is
inherently challenging due to the ambiguities of camera viewpoint, pose,
texture, lighting, etc. We propose ARTIC3D, a self-supervised framework to
reconstruct per-instance 3D shapes from a sparse image collection in-the-wild.
Specifically, ARTIC3D is built upon a skeleton-based surface representation and
is further guided by 2D diffusion priors from Stable Diffusion. First, we
enhance the input images with occlusions/truncation via 2D diffusion to obtain
cleaner mask estimates and semantic features. Second, we perform
diffusion-guided 3D optimization to estimate shape and texture that are of
high-fidelity and faithful to input images. We also propose a novel technique
to calculate more stable image-level gradients via diffusion models compared to
existing alternatives. Finally, we produce realistic animations by fine-tuning
the rendered shape and texture under rigid part transformations. Extensive
evaluations on multiple existing datasets as well as newly introduced noisy web
image collections with occlusions and truncation demonstrate that ARTIC3D
outputs are more robust to noisy images, higher quality in terms of shape and
texture details, and more realistic when animated. Project page:
https://chhankyao.github.io/artic3d/
\\ ( https://arxiv.org/abs/2306.04619 ,  17117kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04632
Date: Wed, 7 Jun 2023 17:56:02 GMT   (7887kb,D)

Title: Designing a Better Asymmetric VQGAN for StableDiffusion
Authors: Zixin Zhu and Xuelu Feng and Dongdong Chen and Jianmin Bao and Le Wang
 and Yinpeng Chen and Lu Yuan and Gang Hua
Categories: cs.CV cs.GR
Comments: code is available at
 https://github.com/buxiangzhiren/Asymmetric_VQGAN
\\
 StableDiffusion is a revolutionary text-to-image generator that is causing a
stir in the world of image generation and editing. Unlike traditional methods
that learn a diffusion model in pixel space, StableDiffusion learns a diffusion
model in the latent space via a VQGAN, ensuring both efficiency and quality. It
not only supports image generation tasks, but also enables image editing for
real images, such as image inpainting and local editing. However, we have
observed that the vanilla VQGAN used in StableDiffusion leads to significant
information loss, causing distortion artifacts even in non-edited image
regions. To this end, we propose a new asymmetric VQGAN with two simple
designs. Firstly, in addition to the input from the encoder, the decoder
contains a conditional branch that incorporates information from task-specific
priors, such as the unmasked image region in inpainting. Secondly, the decoder
is much heavier than the encoder, allowing for more detailed recovery while
only slightly increasing the total inference cost. The training cost of our
asymmetric VQGAN is cheap, and we only need to retrain a new asymmetric decoder
while keeping the vanilla VQGAN encoder and StableDiffusion unchanged. Our
asymmetric VQGAN can be widely used in StableDiffusion-based inpainting and
local editing methods. Extensive experiments demonstrate that it can
significantly improve the inpainting and editing performance, while maintaining
the original text-to-image capability. The code is available at
\url{https://github.com/buxiangzhiren/Asymmetric_VQGAN}.
\\ ( https://arxiv.org/abs/2306.04632 ,  7887kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04633
Date: Wed, 7 Jun 2023 17:57:45 GMT   (25711kb,D)

Title: Contrastive Lift: 3D Object Instance Segmentation by Slow-Fast
 Contrastive Fusion
Authors: Yash Bhalgat, Iro Laina, Jo\~ao F. Henriques, Andrew Zisserman, Andrea
 Vedaldi
Categories: cs.CV cs.AI cs.LG
\\
 Instance segmentation in 3D is a challenging task due to the lack of
large-scale annotated datasets. In this paper, we show that this task can be
addressed effectively by leveraging instead 2D pre-trained models for instance
segmentation. We propose a novel approach to lift 2D segments to 3D and fuse
them by means of a neural field representation, which encourages multi-view
consistency across frames. The core of our approach is a slow-fast clustering
objective function, which is scalable and well-suited for scenes with a large
number of objects. Unlike previous approaches, our method does not require an
upper bound on the number of objects or object tracking across frames. To
demonstrate the scalability of the slow-fast clustering, we create a new
semi-realistic dataset called the Messy Rooms dataset, which features scenes
with up to 500 objects per scene. Our approach outperforms the state-of-the-art
on challenging scenes from the ScanNet, Hypersim, and Replica datasets, as well
as on our newly created Messy Rooms dataset, demonstrating the effectiveness
and scalability of our slow-fast clustering method.
\\ ( https://arxiv.org/abs/2306.04633 ,  25711kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04636
Date: Wed, 7 Jun 2023 17:59:22 GMT   (13449kb,D)

Title: GP-UNIT: Generative Prior for Versatile Unsupervised Image-to-Image
 Translation
Authors: Shuai Yang, Liming Jiang, Ziwei Liu, Chen Change Loy
Categories: cs.CV cs.LG
Comments: Accepted by IEEE Transactions on Pattern Analysis and Machine
 Intelligence (TPAMI). Code: https://github.com/williamyang1991/GP-UNIT
 Project page: https://www.mmlab-ntu.com/project/gpunit/. arXiv admin note:
 substantial text overlap with arXiv:2204.03641
\\
 Recent advances in deep learning have witnessed many successful unsupervised
image-to-image translation models that learn correspondences between two visual
domains without paired data. However, it is still a great challenge to build
robust mappings between various domains especially for those with drastic
visual discrepancies. In this paper, we introduce a novel versatile framework,
Generative Prior-guided UNsupervised Image-to-image Translation (GP-UNIT), that
improves the quality, applicability and controllability of the existing
translation models. The key idea of GP-UNIT is to distill the generative prior
from pre-trained class-conditional GANs to build coarse-level cross-domain
correspondences, and to apply the learned prior to adversarial translations to
excavate fine-level correspondences. With the learned multi-level content
correspondences, GP-UNIT is able to perform valid translations between both
close domains and distant domains. For close domains, GP-UNIT can be
conditioned on a parameter to determine the intensity of the content
correspondences during translation, allowing users to balance between content
and style consistency. For distant domains, semi-supervised learning is
explored to guide GP-UNIT to discover accurate semantic correspondences that
are hard to learn solely from the appearance. We validate the superiority of
GP-UNIT over state-of-the-art translation models in robust, high-quality and
diversified translations between various domains through extensive experiments.
\\ ( https://arxiv.org/abs/2306.04636 ,  13449kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04305
Date: Wed, 7 Jun 2023 10:09:22 GMT   (1013kb,D)

Title: Self-Resolving Prediction Markets for Unverifiable Outcomes
Authors: Siddarth Srinivasan, Ezra Karger, Yiling Chen
Categories: cs.GT econ.TH
\\
 Prediction markets elicit and aggregate beliefs by paying agents based on how
close their predictions are to a verifiable future outcome. However, outcomes
of many important questions are difficult to verify or unverifiable, in that
the ground truth may be hard or impossible to access. Examples include
questions about causal effects where it is infeasible or unethical to run
randomized trials; crowdsourcing and content moderation tasks where it is
prohibitively expensive to verify ground truth; and questions asked over long
time horizons, where the delay until the realization of the outcome skews
agents' incentives to report their true beliefs. We present a novel and
unintuitive result showing that it is possible to run an
$\varepsilon-$incentive compatible prediction market to elicit and efficiently
aggregate information from a pool of agents without observing the outcome by
paying agents the negative cross-entropy between their prediction and that of a
carefully chosen reference agent. Our key insight is that a reference agent
with access to more information can serve as a reasonable proxy for the ground
truth. We use this insight to propose self-resolving prediction markets that
terminate with some probability after every report and pay all but a few agents
based on the final prediction. We show that it is an $\varepsilon-$Perfect
Bayesian Equilibrium for all agents to report truthfully in our mechanism and
to believe that all other agents report truthfully. Although primarily of
interest for unverifiable outcomes, this design is also applicable for
verifiable outcomes.
\\ ( https://arxiv.org/abs/2306.04305 ,  1013kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03911
Date: Tue, 6 Jun 2023 14:13:16 GMT   (569kb)

Title: Multi-constrained Symmetric Nonnegative Latent Factor Analysis for
 Accurately Representing Large-scale Undirected Weighted Networks
Authors: Yurong Zhong, Zhe Xie, Weiling Li, and Xin Luo
Categories: cs.LG
Comments: arXiv admin note: text overlap with arXiv:2306.03647
\\
 An Undirected Weighted Network (UWN) is frequently encountered in a
big-data-related application concerning the complex interactions among numerous
nodes, e.g., a protein interaction network from a bioinformatics application. A
Symmetric High-Dimensional and Incomplete (SHDI) matrix can smoothly illustrate
such an UWN, which contains rich knowledge like node interaction behaviors and
local complexes. To extract desired knowledge from an SHDI matrix, an analysis
model should carefully consider its symmetric-topology for describing an UWN's
intrinsic symmetry. Representation learning to an UWN borrows the success of a
pyramid of symmetry-aware models like a Symmetric Nonnegative Matrix
Factorization (SNMF) model whose objective function utilizes a sole Latent
Factor (LF) matrix for representing SHDI's symmetry rigorously. However, they
suffer from the following drawbacks: 1) their computational complexity is high;
and 2) their modeling strategy narrows their representation features, making
them suffer from low learning ability. Aiming at addressing above critical
issues, this paper proposes a Multi-constrained Symmetric Nonnegative
Latent-factor-analysis (MSNL) model with two-fold ideas: 1) introducing
multi-constraints composed of multiple LF matrices, i.e., inequality and
equality ones into a data-density-oriented objective function for precisely
representing the intrinsic symmetry of an SHDI matrix with broadened feature
space; and 2) implementing an Alternating Direction Method of Multipliers
(ADMM)-incorporated learning scheme for precisely solving such a
multi-constrained model. Empirical studies on three SHDI matrices from a real
bioinformatics or industrial application demonstrate that the proposed MSNL
model achieves stronger representation learning ability to an SHDI matrix than
state-of-the-art models do.
\\ ( https://arxiv.org/abs/2306.03911 ,  569kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03928
Date: Tue, 6 Jun 2023 18:00:09 GMT   (3295kb,D)

Title: Designing Decision Support Systems Using Counterfactual Prediction Sets
Authors: Eleni Straitouri and Manuel Gomez Rodriguez
Categories: cs.LG cs.HC
\\
 Decision support systems for classification tasks are predominantly designed
to predict the value of the ground truth labels. However, since their
predictions are not perfect, these systems also need to make human experts
understand when and how to use these predictions to update their own
predictions. Unfortunately, this has been proven challenging. In this context,
it has been recently argued that an alternative type of decision support
systems may circumvent this challenge. Rather than providing a single label
prediction, these systems provide a set of label prediction values constructed
using a conformal predictor, namely a prediction set, and forcefully ask
experts to predict a label value from the prediction set. However, the design
and evaluation of these systems have so far relied on stylized expert models,
questioning their promise. In this paper, we revisit the design of this type of
systems from the perspective of online learning and develop a methodology that
does not require, nor assumes, an expert model. Our methodology leverages the
nested structure of the prediction sets provided by any conformal predictor and
a natural counterfactual monotonicity assumption on the experts' predictions
over the prediction sets to achieve an exponential improvement in regret in
comparison with vanilla bandit algorithms. We conduct a large-scale human
subject study ($n = 2{,}751$) to verify our counterfactual monotonicity
assumption and compare our methodology to several competitive baselines. The
results suggest that decision support systems that limit experts' level of
agency may be practical and may offer greater performance than those allowing
experts to always exercise their own agency.
\\ ( https://arxiv.org/abs/2306.03928 ,  3295kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03929
Date: Tue, 6 Jun 2023 18:00:29 GMT   (1376kb,D)

Title: Finding Counterfactually Optimal Action Sequences in Continuous State
 Spaces
Authors: Stratis Tsirtsis, Manuel Gomez-Rodriguez
Categories: cs.LG cs.AI cs.CY
\\
 Humans performing tasks that involve taking a series of multiple dependent
actions over time often learn from experience by reflecting on specific cases
and points in time, where different actions could have led to significantly
better outcomes. While recent machine learning methods to retrospectively
analyze sequential decision making processes promise to aid decision makers in
identifying such cases, they have focused on environments with finitely many
discrete states. However, in many practical applications, the state of the
environment is inherently continuous in nature. In this paper, we aim to fill
this gap. We start by formally characterizing a sequence of discrete actions
and continuous states using finite horizon Markov decision processes and a
broad class of bijective structural causal models. Building upon this
characterization, we formalize the problem of finding counterfactually optimal
action sequences and show that, in general, we cannot expect to solve it in
polynomial time. Then, we develop a search method based on the $A^*$ algorithm
that, under a natural form of Lipschitz continuity of the environment's
dynamics, is guaranteed to return the optimal solution to the problem.
Experiments on real clinical data show that our method is very efficient in
practice, and it has the potential to offer interesting insights for sequential
decision making tasks.
\\ ( https://arxiv.org/abs/2306.03929 ,  1376kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03938
Date: Mon, 5 Jun 2023 13:11:33 GMT   (2647kb,D)

Title: Learning Causal Mechanisms through Orthogonal Neural Networks
Authors: Peyman Sheikholharam Mashhadi, Slawomir Nowaczyk
Categories: cs.LG cs.AI
\\
 A fundamental feature of human intelligence is the ability to infer
high-level abstractions from low-level sensory data. An essential component of
such inference is the ability to discover modularized generative mechanisms.
Despite many efforts to use statistical learning and pattern recognition for
finding disentangled factors, arguably human intelligence remains unmatched in
this area.
 In this paper, we investigate a problem of learning, in a fully unsupervised
manner, the inverse of a set of independent mechanisms from distorted data
points. We postulate, and justify this claim with experimental results, that an
important weakness of existing machine learning solutions lies in the
insufficiency of cross-module diversification. Addressing this crucial
discrepancy between human and machine intelligence is an important challenge
for pattern recognition systems.
 To this end, our work proposes an unsupervised method that discovers and
disentangles a set of independent mechanisms from unlabeled data, and learns
how to invert them. A number of experts compete against each other for
individual data points in an adversarial setting: one that best inverses the
(unknown) generative mechanism is the winner. We demonstrate that introducing
an orthogonalization layer into the expert architectures enforces additional
diversity in the outputs, leading to significantly better separability.
Moreover, we propose a procedure for relocating data points between experts to
further prevent any one from claiming multiple mechanisms. We experimentally
illustrate that these techniques allow discovery and modularization of much
less pronounced transformations, in addition to considerably faster
convergence.
\\ ( https://arxiv.org/abs/2306.03938 ,  2647kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03949
Date: Tue, 6 Jun 2023 18:27:20 GMT   (47kb,D)

Title: Partial Inference in Structured Prediction
Authors: Chuyang Ke, Jean Honorio
Categories: cs.LG stat.ML
\\
 In this paper, we examine the problem of partial inference in the context of
structured prediction. Using a generative model approach, we consider the task
of maximizing a score function with unary and pairwise potentials in the space
of labels on graphs. Employing a two-stage convex optimization algorithm for
label recovery, we analyze the conditions under which a majority of the labels
can be recovered. We introduce a novel perspective on the Karush-Kuhn-Tucker
(KKT) conditions and primal and dual construction, and provide statistical and
topological requirements for partial recovery with provable guarantees.
\\ ( https://arxiv.org/abs/2306.03949 ,  47kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03962
Date: Tue, 6 Jun 2023 18:45:05 GMT   (1182kb,D)

Title: PILLAR: How to make semi-private learning more effective
Authors: Francesco Pinto, Yaxi Hu, Fanny Yang, Amartya Sanyal
Categories: cs.LG cs.AI cs.CR stat.ML
\\
 In Semi-Supervised Semi-Private (SP) learning, the learner has access to both
public unlabelled and private labelled data. We propose a computationally
efficient algorithm that, under mild assumptions on the data, provably achieves
significantly lower private labelled sample complexity and can be efficiently
run on real-world datasets. For this purpose, we leverage the features
extracted by networks pre-trained on public (labelled or unlabelled) data,
whose distribution can significantly differ from the one on which SP learning
is performed. To validate its empirical effectiveness, we propose a wide
variety of experiments under tight privacy constraints (\(\epsilon=0.1\)) and
with a focus on low-data regimes. In all of these settings, our algorithm
exhibits significantly improved performance over available baselines that use
similar amounts of public data.
\\ ( https://arxiv.org/abs/2306.03962 ,  1182kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03982
Date: Tue, 6 Jun 2023 19:35:09 GMT   (48kb)

Title: Globally injective and bijective neural operators
Authors: Takashi Furuya, Michael Puthawala, Matti Lassas, Maarten V. de Hoop
Categories: cs.LG stat.ML
Comments: 39 pages
\\
 Recently there has been great interest in operator learning, where networks
learn operators between function spaces from an essentially
infinite-dimensional perspective. In this work we present results for when the
operators learned by these networks are injective and surjective. As a warmup,
we combine prior work in both the finite-dimensional ReLU and operator learning
setting by giving sharp conditions under which ReLU layers with linear neural
operators are injective. We then consider the case the case when the activation
function is pointwise bijective and obtain sufficient conditions for the layer
to be injective. We remark that this question, while trivial in the finite-rank
case, is subtler in the infinite-rank case and is proved using tools from
Fredholm theory. Next, we prove that our supplied injective neural operators
are universal approximators and that their implementation, with finite-rank
neural networks, are still injective. This ensures that injectivity is not
`lost' in the transcription from analytical operators to their finite-rank
implementation with networks. Finally, we conclude with an increase in
abstraction and consider general conditions when subnetworks, which may be many
layers deep, are injective and surjective and provide an exact inversion from a
`linearization.' This section uses general arguments from Fredholm theory and
Leray-Schauder degree theory for non-linear integral equations to analyze the
mapping properties of neural operators in function spaces. These results apply
to subnetworks formed from the layers considered in this work, under natural
conditions. We believe that our work has applications in Bayesian UQ where
injectivity enables likelihood estimation and in inverse problems where
surjectivity and injectivity corresponds to existence and uniqueness,
respectively.
\\ ( https://arxiv.org/abs/2306.03982 ,  48kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03985
Date: Tue, 6 Jun 2023 19:44:37 GMT   (740kb,D)

Title: Agent Performing Autonomous Stock Trading under Good and Bad Situations
Authors: Yunfei Luo and Zhangqi Duan
Categories: cs.LG
Comments: Published in ICML Workshop: AI for Agent Based Modeling, 2023
\\
 Stock trading is one of the popular ways for financial management. However,
the market and the environment of economy is unstable and usually not
predictable. Furthermore, engaging in stock trading requires time and effort to
analyze, create strategies, and make decisions. It would be convenient and
effective if an agent could assist or even do the task of analyzing and
modeling the past data and then generate a strategy for autonomous trading.
Recently, reinforcement learning has been shown to be robust in various tasks
that involve achieving a goal with a decision making strategy based on
time-series data. In this project, we have developed a pipeline that simulates
the stock trading environment and have trained an agent to automate the stock
trading process with deep reinforcement learning methods, including deep
Q-learning, deep SARSA, and the policy gradient method. We evaluate our
platform during relatively good (before 2021) and bad (2021 - 2022) situations.
The stocks we've evaluated on including Google, Apple, Tesla, Meta, Microsoft,
and IBM. These stocks are among the popular ones, and the changes in trends are
representative in terms of having good and bad situations. We showed that
before 2021, the three reinforcement methods we have tried always provide
promising profit returns with total annual rates around $70\%$ to $90\%$, while
maintain a positive profit return after 2021 with total annual rates around 2%
to 7%.
\\ ( https://arxiv.org/abs/2306.03985 ,  740kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04001
Date: Tue, 6 Jun 2023 20:28:37 GMT   (586kb,D)

Title: One-Dimensional Deep Image Prior for Curve Fitting of S-Parameters from
 Electromagnetic Solvers
Authors: Sriram Ravula, Varun Gorti, Bo Deng, Swagato Chakraborty, James
 Pingenot, Bhyrav Mutnury, Doug Wallace, Doug Winterberg, Adam Klivans,
 Alexandros G. Dimakis
Categories: cs.LG cs.AI
\\
 A key problem when modeling signal integrity for passive filters and
interconnects in IC packages is the need for multiple S-parameter measurements
within a desired frequency band to obtain adequate resolution. These samples
are often computationally expensive to obtain using electromagnetic (EM) field
solvers. Therefore, a common approach is to select a small subset of the
necessary samples and use an appropriate fitting mechanism to recreate a
densely-sampled broadband representation. We present the first deep generative
model-based approach to fit S-parameters from EM solvers using one-dimensional
Deep Image Prior (DIP). DIP is a technique that optimizes the weights of a
randomly-initialized convolutional neural network to fit a signal from noisy or
under-determined measurements. We design a custom architecture and propose a
novel regularization inspired by smoothing splines that penalizes discontinuous
jumps. We experimentally compare DIP to publicly available and proprietary
industrial implementations of Vector Fitting (VF), the industry-standard tool
for fitting S-parameters. Relative to publicly available implementations of VF,
our method shows superior performance on nearly all test examples using only
5-15% of the frequency samples. Our method is also competitive to proprietary
VF tools and often outperforms them for challenging input instances.
\\ ( https://arxiv.org/abs/2306.04001 ,  586kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04004
Date: Tue, 6 Jun 2023 20:35:20 GMT   (1701kb,D)

Title: Randomized Schur Complement Views for Graph Contrastive Learning
Authors: Vignesh Kothapalli
Categories: cs.LG
Comments: ICML 2023
\\
 We introduce a randomized topological augmentor based on Schur complements
for Graph Contrastive Learning (GCL). Given a graph laplacian matrix, the
technique generates unbiased approximations of its Schur complements and treats
the corresponding graphs as augmented views. We discuss the benefits of our
approach, provide theoretical justifications and present connections with graph
diffusion. Unlike previous efforts, we study the empirical effectiveness of the
augmentor in a controlled fashion by varying the design choices for subsequent
GCL phases, such as encoding and contrasting. Extensive experiments on node and
graph classification benchmarks demonstrate that our technique consistently
outperforms pre-defined and adaptive augmentation approaches to achieve
state-of-the-art results.
\\ ( https://arxiv.org/abs/2306.04004 ,  1701kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04026
Date: Tue, 6 Jun 2023 21:41:31 GMT   (1589kb,D)

Title: Your Value Function is a Control Barrier Function: Verification of
 Learned Policies using Control Theory
Authors: Daniel C.H. Tan and Fernando Acero and Robert McCarthy and Dimitrios
 Kanoulas and Zhibin Alex Li
Categories: cs.LG cs.AI cs.RO
\\
 Although RL is highly general and scalable, the difficulty of verifying
policy behaviours poses challenges for safety-critical applications. To remedy
this, we propose to apply verification methods used in control theory to
learned value functions. By analyzing a simple task structure for safety
preservation, we derive original theorems linking value functions to control
barrier functions. Inspired by this, we propose novel metrics for verification
of value functions in safe control tasks, and practical implementation details
that improve learning. Besides proposing a novel method for certificate
learning, our work unlocks a wealth of verification methods in control theory
for RL policies, and represents a first step towards a framework for general,
scalable, and verifiable design of control systems.
\\ ( https://arxiv.org/abs/2306.04026 ,  1589kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04037
Date: Tue, 6 Jun 2023 22:04:45 GMT   (1775kb,D)

Title: Quantitative Analysis of Primary Attribution Explainable Artificial
 Intelligence Methods for Remote Sensing Image Classification
Authors: Akshatha Mohan and Joshua Peeples
Categories: cs.LG cs.AI cs.CV
Comments: 4 pages, 3 figures, Accepted to 2023 IGARSS Community-Contributed
 Sessions - Opening the Black Box: Explainable AI/ML in Remote Sensing
 Analysis
\\
 We present a comprehensive analysis of quantitatively evaluating explainable
artificial intelligence (XAI) techniques for remote sensing image
classification. Our approach leverages state-of-the-art machine learning
approaches to perform remote sensing image classification across multiple
modalities. We investigate the results of the models qualitatively through XAI
methods. Additionally, we compare the XAI methods quantitatively through
various categories of desired properties. Through our analysis, we offer
insights and recommendations for selecting the most appropriate XAI method(s)
to gain a deeper understanding of the models' decision-making processes. The
code for this work is publicly available.
\\ ( https://arxiv.org/abs/2306.04037 ,  1775kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04039
Date: Tue, 6 Jun 2023 22:08:42 GMT   (8268kb,D)

Title: Revisiting Neural Retrieval on Accelerators
Authors: Jiaqi Zhai, Zhaojie Gong, Yueming Wang, Xiao Sun, Zheng Yan, Fu Li,
 Xing Liu
Categories: cs.LG cs.IR
Comments: To appear in the 29th ACM SIGKDD Conference on Knowledge Discovery
 and Data Mining (KDD 2023)
DOI: 10.1145/3580305.3599897
\\
 Retrieval finds a small number of relevant candidates from a large corpus for
information retrieval and recommendation applications. A key component of
retrieval is to model (user, item) similarity, which is commonly represented as
the dot product of two learned embeddings. This formulation permits efficient
inference, commonly known as Maximum Inner Product Search (MIPS). Despite its
popularity, dot products cannot capture complex user-item interactions, which
are multifaceted and likely high rank. We hence examine non-dot-product
retrieval settings on accelerators, and propose \textit{mixture of logits}
(MoL), which models (user, item) similarity as an adaptive composition of
elementary similarity functions. This new formulation is expressive, capable of
modeling high rank (user, item) interactions, and further generalizes to the
long tail. When combined with a hierarchical retrieval strategy,
\textit{h-indexer}, we are able to scale up MoL to 100M corpus on a single GPU
with latency comparable to MIPS baselines. On public datasets, our approach
leads to uplifts of up to 77.3\% in hit rate (HR). Experiments on a large
recommendation surface at Meta showed strong metric gains and reduced
popularity bias, validating the proposed approach's performance and improved
generalization.
\\ ( https://arxiv.org/abs/2306.04039 ,  8268kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04040
Date: Tue, 6 Jun 2023 22:11:13 GMT   (2326kb,D)

Title: FedVal: Different good or different bad in federated learning
Authors: Viktor Valadi, Xinchi Qiu, Pedro Porto Buarque de Gusm\~ao, Nicholas
 D. Lane, Mina Alibeigi
Categories: cs.LG cs.AI cs.CR
Comments: To appear in the proceedings of the USENIX Security Symposium 2023
\\
 Federated learning (FL) systems are susceptible to attacks from malicious
actors who might attempt to corrupt the training model through various
poisoning attacks. FL also poses new challenges in addressing group bias, such
as ensuring fair performance for different demographic groups. Traditional
methods used to address such biases require centralized access to the data,
which FL systems do not have. In this paper, we present a novel approach FedVal
for both robustness and fairness that does not require any additional
information from clients that could raise privacy concerns and consequently
compromise the integrity of the FL system. To this end, we propose an
innovative score function based on a server-side validation method that
assesses client updates and determines the optimal aggregation balance between
locally-trained models. Our research shows that this approach not only provides
solid protection against poisoning attacks but can also be used to reduce group
bias and subsequently promote fairness while maintaining the system's
capability for differential privacy. Extensive experiments on the CIFAR-10,
FEMNIST, and PUMS ACSIncome datasets in different configurations demonstrate
the effectiveness of our method, resulting in state-of-the-art performances. We
have proven robustness in situations where 80% of participating clients are
malicious. Additionally, we have shown a significant increase in accuracy for
underrepresented labels from 32% to 53%, and increase in recall rate for
underrepresented features from 19% to 50%.
\\ ( https://arxiv.org/abs/2306.04040 ,  2326kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04049
Date: Tue, 6 Jun 2023 22:35:16 GMT   (4296kb,D)

Title: One-sided Matrix Completion from Two Observations Per Row
Authors: Steven Cao, Percy Liang, Gregory Valiant
Categories: cs.LG cs.DS stat.ML
Comments: ICML 2023
\\
 Given only a few observed entries from a low-rank matrix $X$, matrix
completion is the problem of imputing the missing entries, and it formalizes a
wide range of real-world settings that involve estimating missing data.
However, when there are too few observed entries to complete the matrix, what
other aspects of the underlying matrix can be reliably recovered? We study one
such problem setting, that of "one-sided" matrix completion, where our goal is
to recover the right singular vectors of $X$, even in the regime where
recovering the left singular vectors is impossible, which arises when there are
more rows than columns and very few observations. We propose a natural
algorithm that involves imputing the missing values of the matrix $X^TX$ and
show that even with only two observations per row in $X$, we can provably
recover $X^TX$ as long as we have at least $\Omega(r^2 d \log d)$ rows, where
$r$ is the rank and $d$ is the number of columns. We evaluate our algorithm on
one-sided recovery of synthetic data and low-coverage genome sequencing. In
these settings, our algorithm substantially outperforms standard matrix
completion and a variety of direct factorization methods.
\\ ( https://arxiv.org/abs/2306.04049 ,  4296kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04064
Date: Tue, 6 Jun 2023 23:24:02 GMT   (614kb,D)

Title: Transferable Adversarial Robustness for Categorical Data via Universal
 Robust Embeddings
Authors: Klim Kireev, Maksym Andriushchenko, Carmela Troncoso, Nicolas
 Flammarion
Categories: cs.LG
\\
 Research on adversarial robustness is primarily focused on image and text
data. Yet, many scenarios in which lack of robustness can result in serious
risks, such as fraud detection, medical diagnosis, or recommender systems often
do not rely on images or text but instead on tabular data. Adversarial
robustness in tabular data poses two serious challenges. First, tabular
datasets often contain categorical features, and therefore cannot be tackled
directly with existing optimization procedures. Second, in the tabular domain,
algorithms that are not based on deep networks are widely used and offer great
performance, but algorithms to enhance robustness are tailored to neural
networks (e.g. adversarial training).
 In this paper, we tackle both challenges. We present a method that allows us
to train adversarially robust deep networks for tabular data and to transfer
this robustness to other classifiers via universal robust embeddings tailored
to categorical data. These embeddings, created using a bilevel alternating
minimization framework, can be transferred to boosted trees or random forests
making them robust without the need for adversarial training while preserving
their high accuracy on tabular data. We show that our methods outperform
existing techniques within a practical threat model suitable for tabular data.
\\ ( https://arxiv.org/abs/2306.04064 ,  614kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04066
Date: Tue, 6 Jun 2023 23:54:01 GMT   (1385kb,D)

Title: Intelligent sampling for surrogate modeling, hyperparameter
 optimization, and data analysis
Authors: Chandrika Kamath
Categories: cs.LG stat.CO
Comments: 4 Tables, 18 Figures
Report-no: LLNL-TR-829837
Journal-ref: Machine Learning with Applications, Volume 9, September 2022
DOI: 10.1016/j.mlwa.2022.100373
\\
 Sampling techniques are used in many fields, including design of experiments,
image processing, and graphics. The techniques in each field are designed to
meet the constraints specific to that field such as uniform coverage of the
range of each dimension or random samples that are at least a certain distance
apart from each other. When an application imposes new constraints, for
example, by requiring samples in a non-rectangular domain or the addition of
new samples to an existing set, a common solution is to modify the algorithm
currently in use, often with less than satisfactory results. As an alternative,
we propose the concept of intelligent sampling, where we devise algorithms
specifically tailored to meet our sampling needs, either by creating new
algorithms or by modifying suitable algorithms from other fields. Surprisingly,
both qualitative and quantitative comparisons indicate that some relatively
simple algorithms can be easily modified to meet the many sampling requirements
of surrogate modeling, hyperparameter optimization, and data analysis; these
algorithms outperform their more sophisticated counterparts currently in use,
resulting in better use of time and computer resources.
\\ ( https://arxiv.org/abs/2306.04066 ,  1385kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04072
Date: Wed, 7 Jun 2023 00:13:21 GMT   (4868kb)

Title: Simple High Quality OoD Detection with L2 Normalization
Authors: Jarrod Haas, William Yolland, Bernhard Rabus
Categories: cs.LG
\\
 We propose a simple modification to standard ResNet architectures during
training--L2 normalization over feature space--that produces results
competitive with state-of-the-art Out-of-Distribution (OoD) detection
performance. When L2 normalization is removed at test time, the L2 norm of
feature vectors becomes a surprisingly good proxy for network uncertainty,
whereas this behaviour is not nearly as effective when training without L2
normalization. Intuitively, familiar images result in large magnitude vectors,
while unfamiliar images result in small magnitudes. Notably, this is achievable
with almost no additional cost during training, and no cost at test time.
\\ ( https://arxiv.org/abs/2306.04072 ,  4868kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04073
Date: Wed, 7 Jun 2023 00:16:10 GMT   (3259kb,D)

Title: Patch-level Routing in Mixture-of-Experts is Provably Sample-efficient
 for Convolutional Neural Networks
Authors: Mohammed Nowaz Rabbani Chowdhury, Shuai Zhang, Meng Wang, Sijia Liu
 and Pin-Yu Chen
Categories: cs.LG
\\
 In deep learning, mixture-of-experts (MoE) activates one or few experts
(sub-networks) on a per-sample or per-token basis, resulting in significant
computation reduction. The recently proposed \underline{p}atch-level routing in
\underline{MoE} (pMoE) divides each input into $n$ patches (or tokens) and
sends $l$ patches ($l\ll n$) to each expert through prioritized routing. pMoE
has demonstrated great empirical success in reducing training and inference
costs while maintaining test accuracy. However, the theoretical explanation of
pMoE and the general MoE remains elusive. Focusing on a supervised
classification task using a mixture of two-layer convolutional neural networks
(CNNs), we show for the first time that pMoE provably reduces the required
number of training samples to achieve desirable generalization (referred to as
the sample complexity) by a factor in the polynomial order of $n/l$, and
outperforms its single-expert counterpart of the same or even larger capacity.
The advantage results from the discriminative routing property, which is
justified in both theory and practice that pMoE routers can filter
label-irrelevant patches and route similar class-discriminative patches to the
same expert. Our experimental results on MNIST, CIFAR-10, and CelebA support
our theoretical findings on pMoE's generalization and show that pMoE can avoid
learning spurious correlations.
\\ ( https://arxiv.org/abs/2306.04073 ,  3259kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04096
Date: Wed, 7 Jun 2023 01:36:37 GMT   (4154kb,D)

Title: A novel deeponet model for learning moving-solution operators with
 applications to earthquake hypocenter localization
Authors: Ehsan Haghighat, Umair bin Waheed, George Karniadakis
Categories: cs.LG cs.CE physics.comp-ph
\\
 Seismicity induced by human activities poses a significant threat to public
safety, emphasizing the need for accurate and timely earthquake hypocenter
localization. In this study, we introduce X-DeepONet, a novel variant of deep
operator networks (DeepONets), for learning moving-solution operators of
parametric partial differential equations (PDEs), with application to real-time
earthquake localization. Leveraging the power of neural operators, X-DeepONet
learns to estimate traveltime fields associated with earthquake sources by
incorporating information from seismic arrival times and velocity models.
Similar to the DeepONet, X-DeepONet includes a trunk net and a branch net.
Additionally, we introduce a root network that not only takes the standard
DeepONet's multiplication operator as input, it also takes addition and
subtraction operators. We show that for problems with moving fields, the
standard multiplication operation of DeepONet is insufficient to capture field
relocation, while addition and subtraction operators along with the eXtended
root significantly improve its accuracy both under data-driven (supervised) and
physics-informed (unsupervised) training. We demonstrate the effectiveness of
X-DeepONet through various experiments, including scenarios with variable
velocity models and arrival times. The results show remarkable accuracy in
earthquake localization, even for heterogeneous and complex velocity models.
The proposed framework also exhibits excellent generalization capabilities and
robustness against noisy arrival times. The method provides a computationally
efficient approach for quantifying uncertainty in hypocenter locations
resulting from traveltime pick errors and velocity model variations. Our
results underscore X-DeepONet's potential to improve seismic monitoring
systems, aiding the development of early warning systems for seismic hazard
mitigation.
\\ ( https://arxiv.org/abs/2306.04096 ,  4154kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04098
Date: Wed, 7 Jun 2023 01:43:09 GMT   (17292kb,D)

Title: Phoenix: A Federated Generative Diffusion Model
Authors: Fiona Victoria Stanley Jothiraj and Afra Mashhadi
Categories: cs.LG cs.CV
\\
 Generative AI has made impressive strides in enabling users to create diverse
and realistic visual content such as images, videos, and audio. However,
training generative models on large centralized datasets can pose challenges in
terms of data privacy, security, and accessibility. Federated learning (FL) is
an approach that uses decentralized techniques to collaboratively train a
shared deep learning model while retaining the training data on individual edge
devices to preserve data privacy. This paper proposes a novel method for
training a Denoising Diffusion Probabilistic Model (DDPM) across multiple data
sources using FL techniques. Diffusion models, a newly emerging generative
model, show promising results in achieving superior quality images than
Generative Adversarial Networks (GANs). Our proposed method Phoenix is an
unconditional diffusion model that leverages strategies to improve the data
diversity of generated samples even when trained on data with statistical
heterogeneity or Non-IID (Non-Independent and Identically Distributed) data. We
demonstrate how our approach outperforms the default diffusion model in an FL
setting. These results indicate that high-quality samples can be generated by
maintaining data diversity, preserving privacy, and reducing communication
between data sources, offering exciting new possibilities in the field of
generative AI.
\\ ( https://arxiv.org/abs/2306.04098 ,  17292kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04099
Date: Wed, 7 Jun 2023 01:43:47 GMT   (1161kb,D)

Title: NTKCPL: Active Learning on Top of Self-Supervised Model by Estimating
 True Coverage
Authors: Ziting Wen, Oscar Pizarro, Stefan Williams
Categories: cs.LG
\\
 High annotation cost for training machine learning classifiers has driven
extensive research in active learning and self-supervised learning. Recent
research has shown that in the context of supervised learning different active
learning strategies need to be applied at various stages of the training
process to ensure improved performance over the random baseline. We refer to
the point where the number of available annotations changes the suitable active
learning strategy as the phase transition point. In this paper, we establish
that when combining active learning with self-supervised models to achieve
improved performance, the phase transition point occurs earlier. It becomes
challenging to determine which strategy should be used for previously unseen
datasets. We argue that existing active learning algorithms are heavily
influenced by the phase transition because the empirical risk over the entire
active learning pool estimated by these algorithms is inaccurate and influenced
by the number of labeled samples. To address this issue, we propose a novel
active learning strategy, neural tangent kernel clustering-pseudo-labels
(NTKCPL). It estimates empirical risk based on pseudo-labels and the model
prediction with NTK approximation. We analyze the factors affecting this
approximation error and design a pseudo-label clustering generation method to
reduce the approximation error. We validate our method on five datasets,
empirically demonstrating that it outperforms the baseline methods in most
cases and is valid over a wider range of training budgets.
\\ ( https://arxiv.org/abs/2306.04099 ,  1161kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04107
Date: Wed, 7 Jun 2023 02:16:36 GMT   (1235kb,D)

Title: BeMap: Balanced Message Passing for Fair Graph Neural Network
Authors: Xiao Lin, Jian Kang, Weilin Cong, Hanghang Tong
Categories: cs.LG cs.AI cs.SI
Comments: 13 pages, 4 figures
\\
 Graph Neural Network (GNN) has shown strong empirical performance in many
downstream tasks by iteratively aggregating information from the local
neighborhood of each node, i.e., message passing. However, concrete evidence
has revealed that a graph neural network could be biased against certain
demographic groups, which calls for the consideration of algorithmic fairness.
Despite the increasing efforts in ensuring algorithmic fairness on graph neural
networks, they often do not explicitly consider the induced bias caused by
message passing in GNN during training. In this paper, we first investigate the
problem of bias amplification in message passing. We empirically and
theoretically demonstrate that message passing could amplify the bias when the
1-hop neighbors from different demographic groups are unbalanced. Guided by
such analyses, we propose BeMap, a fair message passing method, that leverages
a balance-aware sampling strategy to balance the number of the 1-hop neighbors
of each node among different demographic groups. Extensive experiments on node
classification demonstrate the efficacy of our proposed BeMap method in
mitigating bias while maintaining classification accuracy.
\\ ( https://arxiv.org/abs/2306.04107 ,  1235kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04109
Date: Wed, 7 Jun 2023 02:29:58 GMT   (5508kb,D)

Title: Membership inference attack with relative decision boundary distance
Authors: JiaCheng Xu and ChengXiang Tan
Categories: cs.LG
Comments: 12 pages,9 figures, 5 tables
\\
 Membership inference attack is one of the most popular privacy attacks in
machine learning, which aims to predict whether a given sample was contained in
the target model's training set. Label-only membership inference attack is a
variant that exploits sample robustness and attracts more attention since it
assumes a practical scenario in which the adversary only has access to the
predicted labels of the input samples. However, since the decision boundary
distance, which measures robustness, is strongly affected by the random initial
image, the adversary may get opposite results even for the same input samples.
In this paper, we propose a new attack method, called muti-class adaptive
membership inference attack in the label-only setting. All decision boundary
distances for all target classes have been traversed in the early attack
iterations, and the subsequent attack iterations continue with the shortest
decision boundary distance to obtain a stable and optimal decision boundary
distance. Instead of using a single boundary distance, the relative boundary
distance between samples and neighboring points has also been employed as a new
membership score to distinguish between member samples inside the training set
and nonmember samples outside the training set. Experiments show that previous
label-only membership inference attacks using the untargeted HopSkipJump
algorithm fail to achieve optimal decision bounds in more than half of the
samples, whereas our multi-targeted HopSkipJump algorithm succeeds in almost
all samples. In addition, extensive experiments show that our multi-class
adaptive MIA outperforms current label-only membership inference attacks in the
CIFAR10, and CIFAR100 datasets, especially for the true positive rate at low
false positive rates metric.
\\ ( https://arxiv.org/abs/2306.04109 ,  5508kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04111
Date: Wed, 7 Jun 2023 02:33:20 GMT   (258kb,D)

Title: Quasi-Newton Updating for Large-Scale Distributed Learning
Authors: Wu Shuyuan, Huang Danyang, Wang Hansheng
Categories: cs.LG cs.DC stat.ME
Comments: 56 pages, 3 figures
\\
 Distributed computing is critically important for modern statistical
analysis. Herein, we develop a distributed quasi-Newton (DQN) framework with
excellent statistical, computation, and communication efficiency. In the DQN
method, no Hessian matrix inversion or communication is needed. This
considerably reduces the computation and communication complexity of the
proposed method. Notably, related existing methods only analyze numerical
convergence and require a diverging number of iterations to converge. However,
we investigate the statistical properties of the DQN method and theoretically
demonstrate that the resulting estimator is statistically efficient over a
small number of iterations under mild conditions. Extensive numerical analyses
demonstrate the finite sample performance.
\\ ( https://arxiv.org/abs/2306.04111 ,  258kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04118
Date: Wed, 7 Jun 2023 03:20:44 GMT   (376kb)

Title: M$^3$Fair: Mitigating Bias in Healthcare Data through Multi-Level and
 Multi-Sensitive-Attribute Reweighting Method
Authors: Yinghao Zhu, Jingkun An, Enshen Zhou, Lu An, Junyi Gao, Hao Li, Haoran
 Feng, Bo Hou, Wen Tang, Chengwei Pan, Liantao Ma
Categories: cs.LG cs.AI
Comments: 4 pages, 1 table, Beijing Health Data Science Summit 2023
\\
 In the data-driven artificial intelligence paradigm, models heavily rely on
large amounts of training data. However, factors like sampling distribution
imbalance can lead to issues of bias and unfairness in healthcare data.
Sensitive attributes, such as race, gender, age, and medical condition, are
characteristics of individuals that are commonly associated with discrimination
or bias. In healthcare AI, these attributes can play a significant role in
determining the quality of care that individuals receive. For example, minority
groups often receive fewer procedures and poorer-quality medical care than
white individuals in US. Therefore, detecting and mitigating bias in data is
crucial to enhancing health equity. Bias mitigation methods include
pre-processing, in-processing, and post-processing. Among them, Reweighting
(RW) is a widely used pre-processing method that performs well in balancing
machine learning performance and fairness performance. RW adjusts the weights
for samples within each (group, label) combination, where these weights are
utilized in loss functions. However, RW is limited to considering only a single
sensitive attribute when mitigating bias and assumes that each sensitive
attribute is equally important. This may result in potential inaccuracies when
addressing intersectional bias. To address these limitations, we propose
M3Fair, a multi-level and multi-sensitive-attribute reweighting method by
extending the RW method to multiple sensitive attributes at multiple levels.
Our experiments on real-world datasets show that the approach is effective,
straightforward, and generalizable in addressing the healthcare fairness
issues.
\\ ( https://arxiv.org/abs/2306.04118 ,  376kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04120
Date: Wed, 7 Jun 2023 03:28:47 GMT   (706kb,D)

Title: MESSY Estimation: Maximum-Entropy based Stochastic and Symbolic densitY
 Estimation
Authors: Tony Tohme, Mohsen Sadr, Kamal Youcef-Toumi, Nicolas G.
 Hadjiconstantinou
Categories: cs.LG cs.AI cs.IT math.IT math.ST stat.ML stat.TH
\\
 We introduce MESSY estimation, a Maximum-Entropy based Stochastic and
Symbolic densitY estimation method. The proposed approach recovers probability
density functions symbolically from samples using moments of a Gradient flow in
which the ansatz serves as the driving force. In particular, we construct a
gradient-based drift-diffusion process that connects samples of the unknown
distribution function to a guess symbolic expression. We then show that when
the guess distribution has the maximum entropy form, the parameters of this
distribution can be found efficiently by solving a linear system of equations
constructed using the moments of the provided samples. Furthermore, we use
Symbolic regression to explore the space of smooth functions and find optimal
basis functions for the exponent of the maximum entropy functional leading to
good conditioning. The cost of the proposed method in each iteration of the
random search is linear with the number of samples and quadratic with the
number of basis functions. We validate the proposed MESSY estimation method
against other benchmark methods for the case of a bi-modal and a discontinuous
density, as well as a density at the limit of physical realizability. We find
that the addition of a symbolic search for basis functions improves the
accuracy of the estimation at a reasonable additional computational cost. Our
results suggest that the proposed method outperforms existing density recovery
methods in the limit of a small to moderate number of samples by providing a
low-bias and tractable symbolic description of the unknown density at a
reasonable computational cost.
\\ ( https://arxiv.org/abs/2306.04120 ,  706kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04125
Date: Wed, 7 Jun 2023 03:44:50 GMT   (1306kb,D)

Title: Multimodal Fusion Interactions: A Study of Human and Automatic
 Quantification
Authors: Paul Pu Liang, Yun Cheng, Ruslan Salakhutdinov, Louis-Philippe Morency
Categories: cs.LG cs.CL cs.HC
\\
 Multimodal fusion of multiple heterogeneous and interconnected signals is a
fundamental challenge in almost all multimodal problems and applications. In
order to perform multimodal fusion, we need to understand the types of
interactions that modalities can exhibit: how each modality individually
provides information useful for a task and how this information changes in the
presence of other modalities. In this paper, we perform a comparative study of
how human annotators can be leveraged to annotate two categorizations of
multimodal interactions: (1) partial labels, where different randomly assigned
annotators annotate the label given the first, second, and both modalities, and
(2) counterfactual labels, where the same annotator is tasked to annotate the
label given the first modality before giving them the second modality and
asking them to explicitly reason about how their answer changes, before
proposing an alternative taxonomy based on (3) information decomposition, where
annotators annotate the degrees of redundancy: the extent to which modalities
individually and together give the same predictions on the task, uniqueness:
the extent to which one modality enables a task prediction that the other does
not, and synergy: the extent to which only both modalities enable one to make a
prediction about the task that one would not otherwise make using either
modality individually. Through extensive experiments and annotations, we
highlight several opportunities and limitations of each approach and propose a
method to automatically convert annotations of partial and counterfactual
labels to information decomposition, yielding an accurate and efficient method
for quantifying interactions in multimodal datasets.
\\ ( https://arxiv.org/abs/2306.04125 ,  1306kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04139
Date: Wed, 7 Jun 2023 04:26:41 GMT   (46kb)

Title: A Survey on Generative Diffusion Models for Structured Data
Authors: Heejoon Koo
Categories: cs.LG cs.AI
Comments: Work in progress
\\
 In recent years, generative diffusion models have achieved a rapid paradigm
shift in deep generative models by showing groundbreaking performance across
various applications. Meanwhile, structured data, encompassing tabular and time
series data, has been received comparatively limited attention from the deep
learning research community, despite its omnipresence and extensive
applications. Thus, there is still a lack of literature and its review on
structured data modelling via diffusion models, compared to other data
modalities such as computer vision and natural language processing. Hence, in
this paper, we present a comprehensive review of recently proposed diffusion
models in the field of structured data. First, this survey provides a concise
overview of the score-based diffusion model theory, subsequently proceeding to
the technical descriptions of the majority of pioneering works using structured
data in both data-driven general tasks and domain-specific applications.
Thereafter, we analyse and discuss the limitations and challenges shown in
existing works and suggest potential research directions. We hope this review
serves as a catalyst for the research community, promoting the developments in
generative diffusion models for structured data.
\\ ( https://arxiv.org/abs/2306.04139 ,  46kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04144
Date: Wed, 7 Jun 2023 04:36:21 GMT   (3129kb,D)

Title: UCTB: An Urban Computing Tool Box for Spatiotemporal Crowd Flow
 Prediction
Authors: Liyue Chen, Di Chai, Leye Wang
Categories: cs.LG
\\
 Spatiotemporal crowd flow prediction is one of the key technologies in smart
cities. Currently, there are two major pain points that plague related research
and practitioners. Firstly, crowd flow is related to multiple domain knowledge
factors; however, due to the diversity of application scenarios, it is
difficult for subsequent work to make reasonable and comprehensive use of
domain knowledge. Secondly, with the development of deep learning technology,
the implementation of relevant techniques has become increasingly complex;
reproducing advanced models has become a time-consuming and increasingly
cumbersome task. To address these issues, we design and implement a
spatiotemporal crowd flow prediction toolbox called UCTB (Urban Computing Tool
Box), which integrates multiple spatiotemporal domain knowledge and
state-of-the-art models simultaneously. The relevant code and supporting
documents have been open-sourced at https://github.com/uctb/UCTB.
\\ ( https://arxiv.org/abs/2306.04144 ,  3129kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04160
Date: Wed, 7 Jun 2023 05:18:27 GMT   (122kb,D)

Title: Rethinking Weak Supervision in Helping Contrastive Learning
Authors: Jingyi Cui, Weiran Huang, Yifei Wang, Yisen Wang
Categories: cs.LG
Comments: Accepted to ICML2023
\\
 Contrastive learning has shown outstanding performances in both supervised
and unsupervised learning, and has recently been introduced to solve weakly
supervised learning problems such as semi-supervised learning and noisy label
learning. Despite the empirical evidence showing that semi-supervised labels
improve the representations of contrastive learning, it remains unknown if
noisy supervised information can be directly used in training instead of after
manual denoising. Therefore, to explore the mechanical differences between
semi-supervised and noisy-labeled information in helping contrastive learning,
we establish a unified theoretical framework of contrastive learning under weak
supervision. Specifically, we investigate the most intuitive paradigm of
jointly training supervised and unsupervised contrastive losses. By translating
the weakly supervised information into a similarity graph under the framework
of spectral clustering based on the posterior probability of weak labels, we
establish the downstream classification error bound. We prove that
semi-supervised labels improve the downstream error bound whereas noisy labels
have limited effects under such a paradigm. Our theoretical findings here
provide new insights for the community to rethink the role of weak supervision
in helping contrastive learning.
\\ ( https://arxiv.org/abs/2306.04160 ,  122kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04169
Date: Wed, 7 Jun 2023 05:38:55 GMT   (47kb)

Title: Efficient Alternating Minimization with Applications to Weighted Low
 Rank Approximation
Authors: Zhao Song, Mingquan Ye, Junze Yin, Lichen Zhang
Categories: cs.LG
Comments: arXiv admin note: text overlap with arXiv:2302.11068
\\
 Weighted low rank approximation is a fundamental problem in numerical linear
algebra, and it has many applications in machine learning. Given a matrix $M
\in \mathbb{R}^{n \times n}$, a weight matrix $W \in \mathbb{R}_{\geq 0}^{n
\times n}$, a parameter $k$, the goal is to output two matrices $U, V \in
\mathbb{R}^{n \times k}$ such that $\| W \circ (M - U V) \|_F$ is minimized,
where $\circ$ denotes the Hadamard product. Such a problem is known to be
NP-hard and even hard to approximate [RSW16]. Meanwhile, alternating
minimization is a good heuristic solution for approximating weighted low rank
approximation. The work [LLR16] shows that, under mild assumptions, alternating
minimization does provide provable guarantees. In this work, we develop an
efficient and robust framework for alternating minimization. For weighted low
rank approximation, this improves the runtime of [LLR16] from $n^2 k^2$ to
$n^2k$. At the heart of our work framework is a high-accuracy multiple response
regression solver together with a robust analysis of alternating minimization.
\\ ( https://arxiv.org/abs/2306.04169 ,  47kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04178
Date: Wed, 7 Jun 2023 06:15:12 GMT   (1055kb,D)

Title: Optimal Transport Model Distributional Robustness
Authors: Van-Anh Nguyen, Trung Le, Anh Tuan Bui, Thanh-Toan Do, and Dinh Phung
Categories: cs.LG cs.CG
\\
 Distributional robustness is a promising framework for training deep learning
models that are less vulnerable to adversarial examples and data distribution
shifts. Previous works have mainly focused on exploiting distributional
robustness in data space. In this work, we explore an optimal transport-based
distributional robustness framework on model spaces. Specifically, we examine a
model distribution in a Wasserstein ball of a given center model distribution
that maximizes the loss. We have developed theories that allow us to learn the
optimal robust center model distribution. Interestingly, through our developed
theories, we can flexibly incorporate the concept of sharpness awareness into
training a single model, ensemble models, and Bayesian Neural Networks by
considering specific forms of the center model distribution, such as a Dirac
delta distribution over a single model, a uniform distribution over several
models, and a general Bayesian Neural Network. Furthermore, we demonstrate that
sharpness-aware minimization (SAM) is a specific case of our framework when
using a Dirac delta distribution over a single model, while our framework can
be viewed as a probabilistic extension of SAM. We conduct extensive experiments
to demonstrate the usefulness of our framework in the aforementioned settings,
and the results show remarkable improvements in our approaches to the
baselines.
\\ ( https://arxiv.org/abs/2306.04178 ,  1055kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04201
Date: Wed, 7 Jun 2023 07:15:08 GMT   (1028kb,D)

Title: Improving Hyperparameter Learning under Approximate Inference in
 Gaussian Process Models
Authors: Rui Li, ST John, Arno Solin
Categories: cs.LG stat.ML
Comments: International Conference on Machine Learning (ICML) 2023
\\
 Approximate inference in Gaussian process (GP) models with non-conjugate
likelihoods gets entangled with the learning of the model hyperparameters. We
improve hyperparameter learning in GP models and focus on the interplay between
variational inference (VI) and the learning target. While VI's lower bound to
the marginal likelihood is a suitable objective for inferring the approximate
posterior, we show that a direct approximation of the marginal likelihood as in
Expectation Propagation (EP) is a better learning objective for hyperparameter
optimization. We design a hybrid training procedure to bring the best of both
worlds: it leverages conjugate-computation VI for inference and uses an EP-like
marginal likelihood approximation for hyperparameter learning. We compare VI,
EP, Laplace approximation, and our proposed training procedure and empirically
demonstrate the effectiveness of our proposal across a wide range of data sets.
\\ ( https://arxiv.org/abs/2306.04201 ,  1028kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04212
Date: Wed, 7 Jun 2023 07:37:01 GMT   (2250kb,D)

Title: Migrate Demographic Group For Fair GNNs
Authors: YanMing Hu, TianChi Liao, JiaLong Chen, Chuan Chen, Jing Bian, and
 ZiBin Zheng
Categories: cs.LG cs.CY
\\
 Graph Neural networks (GNNs) have been applied in many scenarios due to the
superior performance of graph learning. However, fairness is always ignored
when designing GNNs. As a consequence, biased information in training data can
easily affect vanilla GNNs, causing biased results toward particular
demographic groups (divided by sensitive attributes, such as race and age).
There have been efforts to address the fairness issue. However, existing fair
techniques generally divide the demographic groups by raw sensitive attributes
and assume that are fixed. The biased information correlated with raw sensitive
attributes will run through the training process regardless of the implemented
fair techniques. It is urgent to resolve this problem for training fair GNNs.
To tackle this problem, we propose a brand new framework, FairMigration, which
can dynamically migrate the demographic groups instead of keeping that fixed
with raw sensitive attributes. FairMigration is composed of two training
stages. In the first stage, the GNNs are initially optimized by personalized
self-supervised learning, and the demographic groups are adjusted dynamically.
In the second stage, the new demographic groups are frozen and supervised
learning is carried out under the constraints of new demographic groups and
adversarial training. Extensive experiments reveal that FairMigration balances
model performance and fairness well.
\\ ( https://arxiv.org/abs/2306.04212 ,  2250kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04214
Date: Wed, 7 Jun 2023 07:40:04 GMT   (9397kb,D)

Title: DualHGNN: A Dual Hypergraph Neural Network for Semi-Supervised Node
 Classification based on Multi-View Learning and Density Awareness
Authors: Jianpeng Liao, Jun Yan and Qian Tao
Categories: cs.LG cs.CV
Comments: This work has been accepted by 2023 International Joint Conference on
 Neural Networks (IJCNN 2023). arXiv admin note: text overlap with
 arXiv:2201.11511
\\
 Graph-based semi-supervised node classification has been shown to become a
state-of-the-art approach in many applications with high research value and
significance. Most existing methods are only based on the original intrinsic or
artificially established graph structure which may not accurately reflect the
"true" correlation among data and are not optimal for semi-supervised node
classification in the downstream graph neural networks. Besides, while existing
graph-based methods mostly utilize the explicit graph structure, some implicit
information, for example, the density information, can also provide latent
information that can be further exploited. To address these limitations, this
paper proposes the Dual Hypergraph Neural Network (DualHGNN), a new dual
connection model integrating both hypergraph structure learning and hypergraph
representation learning simultaneously in a unified architecture. The DualHGNN
first leverages a multi-view hypergraph learning network to explore the optimal
hypergraph structure from multiple views, constrained by a consistency loss
proposed to improve its generalization. Then, DualHGNN employs a density-aware
hypergraph attention network to explore the high-order semantic correlation
among data points based on the density-aware attention mechanism. Extensive
experiments are conducted in various benchmark datasets, and the results
demonstrate the effectiveness of the proposed approach.
\\ ( https://arxiv.org/abs/2306.04214 ,  9397kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04220
Date: Wed, 7 Jun 2023 07:51:05 GMT   (18642kb,D)

Title: Look Beneath the Surface: Exploiting Fundamental Symmetry for
 Sample-Efficient Offline RL
Authors: Peng Cheng, Xianyuan Zhan, Zhihao Wu, Wenjia Zhang, Shoucheng Song,
 Han Wang, Youfang Lin, Li Jiang
Categories: cs.LG cs.AI
Comments: The first two authors contributed equally
\\
 Offline reinforcement learning (RL) offers an appealing approach to
real-world tasks by learning policies from pre-collected datasets without
interacting with the environment. However, the performance of existing offline
RL algorithms heavily depends on the scale and state-action space coverage of
datasets. Real-world data collection is often expensive and uncontrollable,
leading to small and narrowly covered datasets and posing significant
challenges for practical deployments of offline RL. In this paper, we provide a
new insight that leveraging the fundamental symmetry of system dynamics can
substantially enhance offline RL performance under small datasets.
Specifically, we propose a Time-reversal symmetry (T-symmetry) enforced
Dynamics Model (TDM), which establishes consistency between a pair of forward
and reverse latent dynamics. TDM provides both well-behaved representations for
small datasets and a new reliability measure for OOD samples based on
compliance with the T-symmetry. These can be readily used to construct a new
offline RL algorithm (TSRL) with less conservative policy constraints and a
reliable latent space data augmentation procedure. Based on extensive
experiments, we find TSRL achieves great performance on small benchmark
datasets with as few as 1% of the original samples, which significantly
outperforms the recent offline RL algorithms in terms of data efficiency and
generalizability.
\\ ( https://arxiv.org/abs/2306.04220 ,  18642kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04226
Date: Wed, 7 Jun 2023 08:05:46 GMT   (161kb,D)

Title: Normalization Layers Are All That Sharpness-Aware Minimization Needs
Authors: Maximilian Mueller, Tiffany Vlaar, David Rolnick, Matthias Hein
Categories: cs.LG cs.CV
\\
 Sharpness-aware minimization (SAM) was proposed to reduce sharpness of minima
and has been shown to enhance generalization performance in various settings.
In this work we show that perturbing only the affine normalization parameters
(comprising less than 0.1% of the total parameters) in the adversarial step of
SAM outperforms perturbing all of the parameters. This finding generalizes to
different SAM variants and both ResNet (Batch Normalization) and Vision
Transformer (Layer Normalization) architectures. We consider alternative sparse
perturbation approaches and find that these do not achieve similar performance
enhancement at such extreme sparsity levels, showing that this behaviour is
unique to the normalization layers. Although our findings reaffirm the
effectiveness of SAM in improving generalization performance, they cast doubt
on whether this is solely caused by reduced sharpness. The code for our
experiments is publicly available at https://github.com/mueller-mp/SAM-ON.
\\ ( https://arxiv.org/abs/2306.04226 ,  161kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04228
Date: Wed, 7 Jun 2023 08:06:50 GMT   (2077kb,D)

Title: Data Mining for Faster, Interpretable Solutions to Inverse Problems: A
 Case Study Using Additive Manufacturing
Authors: Chandrika Kamath, Juliette Franzman, Ravi Ponmalai
Categories: cs.LG cs.NA math.NA
Comments: 16 figures and 4 tables
Report-no: LLNL-TR-818722
Journal-ref: Machine Learning with Applications, Volume 6, December 2021
DOI: 10.1016/j.mlwa.2021.100122
\\
 Solving inverse problems, where we find the input values that result in
desired values of outputs, can be challenging. The solution process is often
computationally expensive and it can be difficult to interpret the solution in
high-dimensional input spaces. In this paper, we use a problem from additive
manufacturing to address these two issues with the intent of making it easier
to solve inverse problems and exploit their results. First, focusing on
Gaussian process surrogates that are used to solve inverse problems, we
describe how a simple modification to the idea of tapering can substantially
speed up the surrogate without losing accuracy in prediction. Second, we
demonstrate that Kohonen self-organizing maps can be used to visualize and
interpret the solution to the inverse problem in the high-dimensional input
space. For our data set, as not all input dimensions are equally important, we
show that using weighted distances results in a better organized map that makes
the relationships among the inputs obvious.
\\ ( https://arxiv.org/abs/2306.04228 ,  2077kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04251
Date: Wed, 7 Jun 2023 08:44:51 GMT   (15960kb,D)

Title: Stochastic Collapse: How Gradient Noise Attracts SGD Dynamics Towards
 Simpler Subnetworks
Authors: Feng Chen, Daniel Kunin, Atsushi Yamamura, Surya Ganguli
Categories: cs.LG cs.AI stat.ML
Comments: 30 pages, 10 figures
\\
 In this work, we reveal a strong implicit bias of stochastic gradient descent
(SGD) that drives overly expressive networks to much simpler subnetworks,
thereby dramatically reducing the number of independent parameters, and
improving generalization. To reveal this bias, we identify invariant sets, or
subsets of parameter space that remain unmodified by SGD. We focus on two
classes of invariant sets that correspond to simpler subnetworks and commonly
appear in modern architectures. Our analysis uncovers that SGD exhibits a
property of stochastic attractivity towards these simpler invariant sets. We
establish a sufficient condition for stochastic attractivity based on a
competition between the loss landscape's curvature around the invariant set and
the noise introduced by stochastic gradients. Remarkably, we find that an
increased level of noise strengthens attractivity, leading to the emergence of
attractive invariant sets associated with saddle-points or local maxima of the
train loss. We observe empirically the existence of attractive invariant sets
in trained deep neural networks, implying that SGD dynamics often collapses to
simple subnetworks with either vanishing or redundant neurons. We further
demonstrate how this simplifying process of stochastic collapse benefits
generalization in a linear teacher-student framework. Finally, through this
analysis, we mechanistically explain why early training with large learning
rates for extended periods benefits subsequent generalization.
\\ ( https://arxiv.org/abs/2306.04251 ,  15960kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04252
Date: Wed, 7 Jun 2023 08:47:41 GMT   (428kb,D)

Title: Adversarial Sample Detection Through Neural Network Transport Dynamics
Authors: Skander Karkar and Patrick Gallinari and Alain Rakotomamonjy
Categories: cs.LG
Comments: ECML PKDD 2023
\\
 We propose a detector of adversarial samples that is based on the view of
neural networks as discrete dynamic systems. The detector tells clean inputs
from abnormal ones by comparing the discrete vector fields they follow through
the layers. We also show that regularizing this vector field during training
makes the network more regular on the data distribution's support, thus making
the activations of clean inputs more distinguishable from those of abnormal
ones. Experimentally, we compare our detector favorably to other detectors on
seen and unseen attacks, and show that the regularization of the network's
dynamics improves the performance of adversarial detectors that use the
internal embeddings as inputs, while also improving test accuracy.
\\ ( https://arxiv.org/abs/2306.04252 ,  428kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04262
Date: Wed, 7 Jun 2023 09:00:19 GMT   (15971kb,D)

Title: Self-Adjusting Weighted Expected Improvement for Bayesian Optimization
Authors: Carolin Benjamins and Elena Raponi and Anja Jankovic and Carola Doerr
 and Marius Lindauer
Categories: cs.LG
Comments: AutoML Conference 2023
\\
 Bayesian Optimization (BO) is a class of surrogate-based, sample-efficient
algorithms for optimizing black-box problems with small evaluation budgets. The
BO pipeline itself is highly configurable with many different design choices
regarding the initial design, surrogate model, and acquisition function (AF).
Unfortunately, our understanding of how to select suitable components for a
problem at hand is very limited. In this work, we focus on the definition of
the AF, whose main purpose is to balance the trade-off between exploring
regions with high uncertainty and those with high promise for good solutions.
We propose Self-Adjusting Weighted Expected Improvement (SAWEI), where we let
the exploration-exploitation trade-off self-adjust in a data-driven manner,
based on a convergence criterion for BO. On the noise-free black-box BBOB
functions of the COCO benchmarking platform, our method exhibits a favorable
any-time performance compared to handcrafted baselines and serves as a robust
default choice for any problem structure. The suitability of our method also
transfers to HPOBench. With SAWEI, we are a step closer to on-the-fly,
data-driven, and robust BO designs that automatically adjust their sampling
behavior to the problem at hand.
\\ ( https://arxiv.org/abs/2306.04262 ,  15971kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04265
Date: Wed, 7 Jun 2023 09:05:56 GMT   (1170kb,D)

Title: Permutaion Equivariant Graph Framelets for Heterophilous Semi-supervised
 Learning
Authors: Jianfei Li, Ruigang Zheng, Han Feng, Xiaosheng Zhuang
Categories: cs.LG cs.AI math.FA
\\
 The nature of heterophilous graphs is significantly different with that of
homophilous graphs, which suggests aggregations beyond 1-hop neighborhood and
causes difficulties in early graph neural network models. In this paper, we
develop a new way to implement multi-scale extraction via constructing
Haar-type graph framelets with desired properties of permutation equivariance,
efficiency, and sparsity, for deep learning tasks on graphs. We further deisgn
a graph framelet neural network model PEGFAN using our constructed graph
framelets. The experiments are conducted on a synthetic dataset and 9 benchmark
datasets to compare performance with other state-of-the-art models. The result
shows that our model can achieve best performance on certain datasets of
heterophilous graphs (including the majority of heterophilous datasets with
relatively larger sizes and denser connections) and competitive performance on
the remaining.
\\ ( https://arxiv.org/abs/2306.04265 ,  1170kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04288
Date: Wed, 7 Jun 2023 09:40:18 GMT   (2581kb,D)

Title: Revising deep learning methods in parking lot occupancy detection
Authors: Anastasia Martynova, Mikhail Kuznetsov, Vadim Porvatov, Vladislav
 Tishin, Andrey Kuznetsov, Natalia Semenova, Ksenia Kuznetsova
Categories: cs.LG cs.CV
\\
 Parking guidance systems have recently become a popular trend as a part of
the smart cities' paradigm of development. The crucial part of such systems is
the algorithm allowing drivers to search for available parking lots across
regions of interest. The classic approach to this task is based on the
application of neural network classifiers to camera records. However, existing
systems demonstrate a lack of generalization ability and appropriate testing
regarding specific visual conditions. In this study, we extensively evaluate
state-of-the-art parking lot occupancy detection algorithms, compare their
prediction quality with the recently emerged vision transformers, and propose a
new pipeline based on EfficientNet architecture. Performed computational
experiments have demonstrated the performance increase in the case of our
model, which was evaluated on 5 different datasets.
\\ ( https://arxiv.org/abs/2306.04288 ,  2581kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04299
Date: Wed, 7 Jun 2023 10:02:16 GMT   (366kb,D)

Title: Timing Process Interventions with Causal Inference and Reinforcement
 Learning
Authors: Hans Weytjens, Wouter Verbeke, Jochen De Weerdt
Categories: cs.LG
DOI: 10.13140/RG.2.2.11746.71360
\\
 The shift from the understanding and prediction of processes to their
optimization offers great benefits to businesses and other organizations.
Precisely timed process interventions are the cornerstones of effective
optimization. Prescriptive process monitoring (PresPM) is the sub-field of
process mining that concentrates on process optimization. The emerging PresPM
literature identifies state-of-the-art methods, causal inference (CI) and
reinforcement learning (RL), without presenting a quantitative comparison. Most
experiments are carried out using historical data, causing problems with the
accuracy of the methods' evaluations and preempting online RL. Our contribution
consists of experiments on timed process interventions with synthetic data that
renders genuine online RL and the comparison to CI possible, and allows for an
accurate evaluation of the results. Our experiments reveal that RL's policies
outperform those from CI and are more robust at the same time. Indeed, the RL
policies approach perfect policies. Unlike CI, the unaltered online RL approach
can be applied to other, more generic PresPM problems such as next best
activity recommendations. Nonetheless, CI has its merits in settings where
online learning is not an option.
\\ ( https://arxiv.org/abs/2306.04299 ,  366kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04319
Date: Wed, 7 Jun 2023 10:32:53 GMT   (7233kb,D)

Title: CaptAinGlove: Capacitive and Inertial Fusion-Based Glove for Real-Time
 on Edge Hand Gesture Recognition for Drone Control
Authors: Hymalai Bello, Sungho Suh, Daniel Gei{\ss}ler, Lala Ray, Bo Zhou and
 Paul Lukowicz
Categories: cs.LG cs.HC cs.RO
\\
 We present CaptAinGlove, a textile-based, low-power (1.15Watts),
privacy-conscious, real-time on-the-edge (RTE) glove-based solution with a tiny
memory footprint (2MB), designed to recognize hand gestures used for drone
control. We employ lightweight convolutional neural networks as the backbone
models and a hierarchical multimodal fusion to reduce power consumption and
improve accuracy. The system yields an F1-score of 80% for the offline
evaluation of nine classes; eight hand gesture commands and null activity. For
the RTE, we obtained an F1-score of 67% (one user).
\\ ( https://arxiv.org/abs/2306.04319 ,  7233kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04343
Date: Wed, 7 Jun 2023 11:17:07 GMT   (202kb,D)

Title: Bayesian Optimisation Against Climate Change: Applications and
 Benchmarks
Authors: Sigrid Passano Hellan, Christopher G. Lucas, Nigel H. Goddard
Categories: cs.LG
\\
 Bayesian optimisation is a powerful method for optimising black-box
functions, popular in settings where the true function is expensive to evaluate
and no gradient information is available. Bayesian optimisation can improve
responses to many optimisation problems within climate change for which
simulator models are unavailable or expensive to sample from. While there have
been several feasibility demonstrations of Bayesian optimisation in
climate-related applications, there has been no unifying review of applications
and benchmarks. We provide such a review here, to encourage the use of Bayesian
optimisation in important and well-suited application domains. We identify four
main application domains: material discovery, wind farm layout, optimal
renewable control and environmental monitoring. For each domain we identify a
public benchmark or data set that is easy to use and evaluate systems against,
while being representative of real-world problems. Due to the lack of a
suitable benchmark for environmental monitoring, we propose LAQN-BO, based on
air pollution data. Our contributions are: a) identifying a representative
range of benchmarks, providing example code where necessary; b) introducing a
new benchmark, LAQN-BO; and c) promoting a wider use of climate change
applications among Bayesian optimisation practitioners.
\\ ( https://arxiv.org/abs/2306.04343 ,  202kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04400
Date: Wed, 7 Jun 2023 12:58:52 GMT   (822kb,D)

Title: A Fair Classifier Embracing Triplet Collapse
Authors: A. Martzloff (1), N. Posocco (2), Q. Ferr\'e (1) ((1) Euranova,
 Marseille, France, (2) Euranova, Mont-Saint-Guibert, Belgique)
Categories: cs.LG cs.AI cs.CY
Comments: 9 pages, 7 figures, CAp2023
ACM-class: I.2.6; I.5.1; K.4.2
\\
 In this paper, we study the behaviour of the triplet loss and show that it
can be exploited to limit the biases created and perpetuated by machine
learning models. Our fair classifier uses the collapse of the triplet loss when
its margin is greater than the maximum distance between two points in the
latent space, in the case of stochastic triplet selection.
\\ ( https://arxiv.org/abs/2306.04400 ,  822kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04403
Date: Wed, 7 Jun 2023 13:02:24 GMT   (2869kb,D)

Title: Policy-Based Self-Competition for Planning Problems
Authors: Jonathan Pirnay, Quirin G\"ottl, Jakob Burger, Dominik Gerhard Grimm
Categories: cs.LG
Comments: 24 pages, 5 figures
Journal-ref: The Eleventh International Conference on Learning Representations,
 2023
\\
 AlphaZero-type algorithms may stop improving on single-player tasks in case
the value network guiding the tree search is unable to approximate the outcome
of an episode sufficiently well. One technique to address this problem is
transforming the single-player task through self-competition. The main idea is
to compute a scalar baseline from the agent's historical performances and to
reshape an episode's reward into a binary output, indicating whether the
baseline has been exceeded or not. However, this baseline only carries limited
information for the agent about strategies how to improve. We leverage the idea
of self-competition and directly incorporate a historical policy into the
planning process instead of its scalar performance. Based on the recently
introduced Gumbel AlphaZero (GAZ), we propose our algorithm GAZ 'Play-to-Plan'
(GAZ PTP), in which the agent learns to find strong trajectories by planning
against possible strategies of its past self. We show the effectiveness of our
approach in two well-known combinatorial optimization problems, the Traveling
Salesman Problem and the Job-Shop Scheduling Problem. With only half of the
simulation budget for search, GAZ PTP consistently outperforms all selected
single-player variants of GAZ.
\\ ( https://arxiv.org/abs/2306.04403 ,  2869kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04406
Date: Wed, 7 Jun 2023 13:04:34 GMT   (6839kb,D)

Title: Generalized Teacher Forcing for Learning Chaotic Dynamics
Authors: Florian Hess, Zahra Monfared, Manuel Brenner, Daniel Durstewitz
Categories: cs.LG cs.AI math.DS nlin.CD
Comments: To be published in the Proceedings of the 40th International
 Conference on Machine Learning (ICML 2023)
\\
 Chaotic dynamical systems (DS) are ubiquitous in nature and society. Often we
are interested in reconstructing such systems from observed time series for
prediction or mechanistic insight, where by reconstruction we mean learning
geometrical and invariant temporal properties of the system in question (like
attractors). However, training reconstruction algorithms like recurrent neural
networks (RNNs) on such systems by gradient-descent based techniques faces
severe challenges. This is mainly due to exploding gradients caused by the
exponential divergence of trajectories in chaotic systems. Moreover, for
(scientific) interpretability we wish to have as low dimensional
reconstructions as possible, preferably in a model which is mathematically
tractable. Here we report that a surprisingly simple modification of teacher
forcing leads to provably strictly all-time bounded gradients in training on
chaotic systems, and, when paired with a simple architectural rearrangement of
a tractable RNN design, piecewise-linear RNNs (PLRNNs), allows for faithful
reconstruction in spaces of at most the dimensionality of the observed system.
We show on several DS that with these amendments we can reconstruct DS better
than current SOTA algorithms, in much lower dimensions. Performance differences
were particularly compelling on real world data with which most other methods
severely struggled. This work thus led to a simple yet powerful DS
reconstruction algorithm which is highly interpretable at the same time.
\\ ( https://arxiv.org/abs/2306.04406 ,  6839kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04423
Date: Wed, 7 Jun 2023 13:30:43 GMT   (32kb)

Title: On Computing Optimal Tree Ensembles
Authors: Christian Komusiewicz, Pascal Kunz, Frank Sommer and Manuel Sorge
Categories: cs.LG cs.DS
Comments: Accepted at ICML 2023
\\
 Random forests and, more generally, (decision\nobreakdash-)tree ensembles are
widely used methods for classification and regression. Recent algorithmic
advances allow to compute decision trees that are optimal for various measures
such as their size or depth. We are not aware of such research for tree
ensembles and aim to contribute to this area. Mainly, we provide two novel
algorithms and corresponding lower bounds. First, we are able to carry over and
substantially improve on tractability results for decision trees, obtaining a
$(6\delta D S)^S \cdot poly$-time algorithm, where $S$ is the number of cuts in
the tree ensemble, $D$ the largest domain size, and $\delta$ is the largest
number of features in which two examples differ. To achieve this, we introduce
the witness-tree technique which also seems promising for practice. Second, we
show that dynamic programming, which has been successful for decision trees,
may also be viable for tree ensembles, providing an $\ell^n \cdot poly$-time
algorithm, where $\ell$ is the number of trees and $n$ the number of examples.
Finally, we compare the number of cuts necessary to classify training data sets
for decision trees and tree ensembles, showing that ensembles may need
exponentially fewer cuts for increasing number of trees.
\\ ( https://arxiv.org/abs/2306.04423 ,  32kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04425
Date: Wed, 7 Jun 2023 13:31:57 GMT   (2524kb,D)

Title: Towards High-Performance Exploratory Data Analysis (EDA) Via Stable
 Equilibrium Point
Authors: Yuxuan Song, Yongyu Wang
Categories: cs.LG cs.AI
\\
 Exploratory data analysis (EDA) is a vital procedure for data science
projects. In this work, we introduce a stable equilibrium point (SEP) - based
framework for improving the efficiency and solution quality of EDA. By
exploiting the SEPs to be the representative points, our approach aims to
generate high-quality clustering and data visualization for large-scale data
sets. A very unique property of the proposed method is that the SEPs will
directly encode the clustering properties of data sets. Compared with prior
state-of-the-art clustering and data visualization methods, the proposed
methods allow substantially improving computing efficiency and solution quality
for large-scale data analysis tasks.
\\ ( https://arxiv.org/abs/2306.04425 ,  2524kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04429
Date: Wed, 7 Jun 2023 13:40:20 GMT   (2061kb,D)

Title: Balancing of competitive two-player Game Levels with Reinforcement
 Learning
Authors: Florian Rupp, Manuel Eberhardinger, Kai Eckert
Categories: cs.LG
Comments: 8 pages, 8 figures, 1 table. Accepted at IEEE Conference on Games
 2023
\\
 The balancing process for game levels in a competitive two-player context
involves a lot of manual work and testing, particularly in non-symmetrical game
levels. In this paper, we propose an architecture for automated balancing of
tile-based levels within the recently introduced PCGRL framework (procedural
content generation via reinforcement learning). Our architecture is divided
into three parts: (1) a level generator, (2) a balancing agent and, (3) a
reward modeling simulation. By playing the level in a simulation repeatedly,
the balancing agent is rewarded for modifying it towards the same win rates for
all players. To this end, we introduce a novel family of swap-based
representations to increase robustness towards playability. We show that this
approach is capable to teach an agent how to alter a level for balancing better
and faster than plain PCGRL. In addition, by analyzing the agent's swapping
behavior, we can draw conclusions about which tile types influence the
balancing most. We test and show our results using the Neural MMO (NMMO)
environment in a competitive two-player setting.
\\ ( https://arxiv.org/abs/2306.04429 ,  2061kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04431
Date: Wed, 7 Jun 2023 13:41:55 GMT   (753kb,D)

Title: Faithful Knowledge Distillation
Authors: Tom A. Lamb, Rudy Brunel, Krishnamurthy (Dj) Dvijotham, M. Pawan
 Kumar, Philip H. S. Torr, Francisco Eiras
Categories: cs.LG
Comments: 12pgs (main content), 3 figures
\\
 Knowledge distillation (KD) has received much attention due to its success in
compressing networks to allow for their deployment in resource-constrained
systems. While the problem of adversarial robustness has been studied before in
the KD setting, previous works overlook what we term the relative calibration
of the student network with respect to its teacher in terms of soft
confidences. In particular, we focus on two crucial questions with regard to a
teacher-student pair: (i) do the teacher and student disagree at points close
to correctly classified dataset examples, and (ii) is the distilled student as
confident as the teacher around dataset examples? These are critical questions
when considering the deployment of a smaller student network trained from a
robust teacher within a safety-critical setting. To address these questions, we
introduce a faithful imitation framework to discuss the relative calibration of
confidences, as well as provide empirical and certified methods to evaluate the
relative calibration of a student w.r.t. its teacher. Further, to verifiably
align the relative calibration incentives of the student to those of its
teacher, we introduce faithful distillation. Our experiments on the MNIST and
Fashion-MNIST datasets demonstrate the need for such an analysis and the
advantages of the increased verifiability of faithful distillation over
alternative adversarial distillation methods.
\\ ( https://arxiv.org/abs/2306.04431 ,  753kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04444
Date: Wed, 7 Jun 2023 14:07:35 GMT   (383kb,D)

Title: Fast Optimal Locally Private Mean Estimation via Random Projections
Authors: Hilal Asi, Vitaly Feldman, Jelani Nelson, Huy L. Nguyen, Kunal Talwar
Categories: cs.LG cs.CR stat.ML
\\
 We study the problem of locally private mean estimation of high-dimensional
vectors in the Euclidean ball. Existing algorithms for this problem either
incur sub-optimal error or have high communication and/or run-time complexity.
We propose a new algorithmic framework, ProjUnit, for private mean estimation
that yields algorithms that are computationally efficient, have low
communication complexity, and incur optimal error up to a $1+o(1)$-factor. Our
framework is deceptively simple: each randomizer projects its input to a random
low-dimensional subspace, normalizes the result, and then runs an optimal
algorithm such as PrivUnitG in the lower-dimensional space. In addition, we
show that, by appropriately correlating the random projection matrices across
devices, we can achieve fast server run-time. We mathematically analyze the
error of the algorithm in terms of properties of the random projections, and
study two instantiations. Lastly, our experiments for private mean estimation
and private federated learning demonstrate that our algorithms empirically
obtain nearly the same utility as optimal ones while having significantly lower
communication and computational cost.
\\ ( https://arxiv.org/abs/2306.04444 ,  383kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04445
Date: Wed, 7 Jun 2023 14:16:44 GMT   (21267kb,D)

Title: Multi-modal Latent Diffusion
Authors: Mustapha Bounoua, Giulio Franzese, Pietro Michiardi
Categories: cs.LG
\\
 Multi-modal data-sets are ubiquitous in modern applications, and multi-modal
Variational Autoencoders are a popular family of models that aim to learn a
joint representation of the different modalities. However, existing approaches
suffer from a coherence-quality tradeoff, where models with good generation
quality lack generative coherence across modalities, and vice versa. We discuss
the limitations underlying the unsatisfactory performance of existing methods,
to motivate the need for a different approach. We propose a novel method that
uses a set of independently trained, uni-modal, deterministic autoencoders.
Individual latent variables are concatenated into a common latent space, which
is fed to a masked diffusion model to enable generative modeling. We also
introduce a new multi-time training method to learn the conditional score
network for multi-modal diffusion. Our methodology substantially outperforms
competitors in both generation quality and coherence, as shown through an
extensive experimental campaign.
\\ ( https://arxiv.org/abs/2306.04445 ,  21267kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04454
Date: Wed, 7 Jun 2023 14:28:42 GMT   (17205kb,D)

Title: Training-Free Neural Active Learning with Initialization-Robustness
 Guarantees
Authors: Apivich Hemachandra, Zhongxiang Dai, Jasraj Singh, See-Kiong Ng and
 Bryan Kian Hsiang Low
Categories: cs.LG cs.AI
Comments: Accepted to 40th International Conference on Machine Learning (ICML
 2023), 41 pages
\\
 Existing neural active learning algorithms have aimed to optimize the
predictive performance of neural networks (NNs) by selecting data for
labelling. However, other than a good predictive performance, being robust
against random parameter initializations is also a crucial requirement in
safety-critical applications. To this end, we introduce our expected variance
with Gaussian processes (EV-GP) criterion for neural active learning, which is
theoretically guaranteed to select data points which lead to trained NNs with
both (a) good predictive performances and (b) initialization robustness.
Importantly, our EV-GP criterion is training-free, i.e., it does not require
any training of the NN during data selection, which makes it computationally
efficient. We empirically demonstrate that our EV-GP criterion is highly
correlated with both initialization robustness and generalization performance,
and show that it consistently outperforms baseline methods in terms of both
desiderata, especially in situations with limited initial data or large batch
sizes.
\\ ( https://arxiv.org/abs/2306.04454 ,  17205kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04488
Date: Wed, 7 Jun 2023 14:58:15 GMT   (8507kb,D)

Title: Rewarded soups: towards Pareto-optimal alignment by interpolating
 weights fine-tuned on diverse rewards
Authors: Alexandre Rame, Guillaume Couairon, Mustafa Shukor, Corentin Dancette,
 Jean-Baptiste Gaya, Laure Soulier and Matthieu Cord
Categories: cs.LG cs.AI cs.CV
\\
 Foundation models are first pre-trained on vast unsupervised datasets and
then fine-tuned on labeled data. Reinforcement learning, notably from human
feedback (RLHF), can further align the network with the intended usage. Yet the
imperfections in the proxy reward may hinder the training and lead to
suboptimal results; the diversity of objectives in real-world tasks and human
opinions exacerbate the issue. This paper proposes embracing the heterogeneity
of diverse rewards by following a multi-policy strategy. Rather than focusing
on a single a priori reward, we aim for Pareto-optimal generalization across
the entire space of preferences. To this end, we propose rewarded soup, first
specializing multiple networks independently (one for each proxy reward) and
then interpolating their weights linearly. This succeeds empirically because we
show that the weights remain linearly connected when fine-tuned on diverse
rewards from a shared pre-trained initialization. We demonstrate the
effectiveness of our approach for text-to-text (summarization, Q&A, helpful
assistant, review), text-image (image captioning, text-to-image generation,
visual grounding, VQA), and control (locomotion) tasks. We hope to enhance the
alignment of deep models, and how they interact with the world in all its
diversity.
\\ ( https://arxiv.org/abs/2306.04488 ,  8507kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04489
Date: Wed, 7 Jun 2023 15:00:38 GMT   (284kb,D)

Title: Fair Column Subset Selection
Authors: Antonis Matakos, Bruno Ordozgoiti, Suhas Thejaswi
Categories: cs.LG
\\
 We consider the problem of fair column subset selection. In particular, we
assume that two groups are present in the data, and the chosen column subset
must provide a good approximation for both, relative to their respective best
rank-k approximations. We show that this fair setting introduces significant
challenges: in order to extend known results, one cannot do better than the
trivial solution of simply picking twice as many columns as the original
methods. We adopt a known approach based on deterministic leverage-score
sampling, and show that merely sampling a subset of appropriate size becomes
NP-hard in the presence of two groups. Whereas finding a subset of two times
the desired size is trivial, we provide an efficient algorithm that achieves
the same guarantees with essentially 1.5 times that size. We validate our
methods through an extensive set of experiments on real-world data.
\\ ( https://arxiv.org/abs/2306.04489 ,  284kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04495
Date: Wed, 7 Jun 2023 15:04:58 GMT   (513kb)

Title: Limits, approximation and size transferability for GNNs on sparse graphs
 via graphops
Authors: Thien Le and Stefanie Jegelka
Categories: cs.LG
Comments: NeurIPS 2023 submission, 34 pages
\\
 Can graph neural networks generalize to graphs that are different from the
graphs they were trained on, e.g., in size? In this work, we study this
question from a theoretical perspective. While recent work established such
transferability and approximation results via graph limits, e.g., via graphons,
these only apply non-trivially to dense graphs. To include frequently
encountered sparse graphs such as bounded-degree or power law graphs, we take a
perspective of taking limits of operators derived from graphs, such as the
aggregation operation that makes up GNNs. This leads to the recently introduced
limit notion of graphops (Backhausz and Szegedy, 2022). We demonstrate how the
operator perspective allows us to develop quantitative bounds on the distance
between a finite GNN and its limit on an infinite graph, as well as the
distance between the GNN on graphs of different sizes that share structural
properties, under a regularity assumption verified for various graph sequences.
Our results hold for dense and sparse graphs, and various notions of graph
limits.
\\ ( https://arxiv.org/abs/2306.04495 ,  513kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04498
Date: Wed, 7 Jun 2023 15:05:53 GMT   (2083kb,D)

Title: Optimal Fair Multi-Agent Bandits
Authors: Amir Leshem
Categories: cs.LG cs.DC
Comments: 17 pages, 3 figures
\\
 In this paper, we study the problem of fair multi-agent multi-arm bandit
learning when agents do not communicate with each other, except collision
information, provided to agents accessing the same arm simultaneously. We
provide an algorithm with regret $O\left(N^3 \log N \log T \right)$ (assuming
bounded rewards, with unknown bound). This significantly improves previous
results which had regret of order $O(\log T \log\log T)$ and exponential
dependence on the number of agents. The result is attained by using a
distributed auction algorithm to learn the sample-optimal matching, a new type
of exploitation phase whose length is derived from the observed samples, and a
novel order-statistics-based regret analysis. Simulation results present the
dependence of the regret on $\log T$.
\\ ( https://arxiv.org/abs/2306.04498 ,  2083kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04502
Date: Wed, 7 Jun 2023 15:10:01 GMT   (1861kb,D)

Title: Learning with Noisy Labels by Adaptive Gradient-Based Outlier Removal
Authors: Anastasiia Sedova, Lena Zellinger, Benjamin Roth
Categories: cs.LG cs.AI
Comments: Accepted for ECML PKDD 2023
\\
 An accurate and substantial dataset is necessary to train a reliable and
well-performing model. However, even manually labeled datasets contain errors,
not to mention automatically labeled ones. The problem of data denoising was
addressed in different existing research, most of which focuses on the
detection of outliers and their permanent removal - a process that is likely to
over- or underfilter the dataset. In this work, we propose AGRA: a new method
for Adaptive GRAdient-based outlier removal. Instead of cleaning the dataset
prior to model training, the dataset is adjusted during the training process.
By comparing the aggregated gradient of a batch of samples and an individual
example gradient, our method dynamically decides whether a corresponding
example is helpful for the model at this point or is counter-productive and
should be left out for the current update. Extensive evaluation on several
datasets demonstrates the AGRA effectiveness, while comprehensive results
analysis supports our initial hypothesis: permanent hard outlier removal is not
always what model benefits the most from.
\\ ( https://arxiv.org/abs/2306.04502 ,  1861kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04505
Date: Wed, 7 Jun 2023 15:12:16 GMT   (1867kb,D)

Title: Hardness of Deceptive Certificate Selection
Authors: Stephan W\"aldchen
Categories: cs.LG cs.AI cs.CC
Comments: 15 pages, 3 figures
MSC-class: 68T01, 91A06
ACM-class: I.2.0
\\
 Recent progress towards theoretical interpretability guarantees for AI has
been made with classifiers that are based on interactive proof systems. A
prover selects a certificate from the datapoint and sends it to a verifier who
decides the class. In the context of machine learning, such a certificate can
be a feature that is informative of the class. For a setup with high soundness
and completeness, the exchanged certificates must have a high mutual
information with the true class of the datapoint. However, this guarantee
relies on a bound on the Asymmetric Feature Correlation of the dataset, a
property that so far is difficult to estimate for high-dimensional data. It was
conjectured in W\"aldchen et al. that it is computationally hard to exploit the
AFC, which is what we prove here.
 We consider a malicious prover-verifier duo that aims to exploit the AFC to
achieve high completeness and soundness while using uninformative certificates.
We show that this task is $\mathsf{NP}$-hard and cannot be approximated better
than $\mathcal{O}(m^{1/8 - \epsilon})$, where $m$ is the number of possible
certificates, for $\epsilon>0$ under the Dense-vs-Random conjecture. This is
some evidence that AFC should not prevent the use of interactive classification
for real-world tasks, as it is computationally hard to be exploited.
\\ ( https://arxiv.org/abs/2306.04505 ,  1867kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04519
Date: Wed, 7 Jun 2023 15:29:46 GMT   (200kb,D)

Title: Sample-Level Weighting for Multi-Task Learning with Auxiliary Tasks
Authors: Emilie Gr\'egoire, Hafeez Chaudhary and Sam Verboven
Categories: cs.LG cs.AI
Comments: 16 pages, 7 figures
ACM-class: I.2.6
\\
 Multi-task learning (MTL) can improve the generalization performance of
neural networks by sharing representations with related tasks. Nonetheless, MTL
can also degrade performance through harmful interference between tasks. Recent
work has pursued task-specific loss weighting as a solution for this
interference. However, existing algorithms treat tasks as atomic, lacking the
ability to explicitly separate harmful and helpful signals beyond the task
level. To this end, we propose SLGrad, a sample-level weighting algorithm for
multi-task learning with auxiliary tasks. Through sample-specific task weights,
SLGrad reshapes the task distributions during training to eliminate harmful
auxiliary signals and augment useful task signals. Substantial generalization
performance gains are observed on (semi-) synthetic datasets and common
supervised multi-task problems.
\\ ( https://arxiv.org/abs/2306.04519 ,  200kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04529
Date: Wed, 7 Jun 2023 15:37:50 GMT   (253kb,D)

Title: Git-Theta: A Git Extension for Collaborative Development of Machine
 Learning Models
Authors: Nikhil Kandpal, Brian Lester, Mohammed Muqeeth, Anisha Mascarenhas,
 Monty Evans, Vishal Baskaran, Tenghao Huang, Haokun Liu, Colin Raffel
Categories: cs.LG
\\
 Currently, most machine learning models are trained by centralized teams and
are rarely updated. In contrast, open-source software development involves the
iterative development of a shared artifact through distributed collaboration
using a version control system. In the interest of enabling collaborative and
continual improvement of machine learning models, we introduce Git-Theta, a
version control system for machine learning models. Git-Theta is an extension
to Git, the most widely used version control software, that allows fine-grained
tracking of changes to model parameters alongside code and other artifacts.
Unlike existing version control systems that treat a model checkpoint as a blob
of data, Git-Theta leverages the structure of checkpoints to support
communication-efficient updates, automatic model merges, and meaningful
reporting about the difference between two versions of a model. In addition,
Git-Theta includes a plug-in system that enables users to easily add support
for new functionality. In this paper, we introduce Git-Theta's design and
features and include an example use-case of Git-Theta where a pre-trained model
is continually adapted and modified. We publicly release Git-Theta in hopes of
kickstarting a new era of collaborative model development.
\\ ( https://arxiv.org/abs/2306.04529 ,  253kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04539
Date: Wed, 7 Jun 2023 15:44:53 GMT   (3320kb,D)

Title: Multimodal Learning Without Labeled Multimodal Data: Guarantees and
 Applications
Authors: Paul Pu Liang, Chun Kai Ling, Yun Cheng, Alex Obolenskiy, Yudong Liu,
 Rohan Pandey, Alex Wilf, Louis-Philippe Morency, Ruslan Salakhutdinov
Categories: cs.LG cs.CL cs.CV cs.IT math.IT stat.ML
Comments: Code available at: https://github.com/pliang279/PID
\\
 In many machine learning systems that jointly learn from multiple modalities,
a core research question is to understand the nature of multimodal
interactions: the emergence of new task-relevant information during learning
from both modalities that was not present in either alone. We study this
challenge of interaction quantification in a semi-supervised setting with only
labeled unimodal data and naturally co-occurring multimodal data (e.g.,
unlabeled images and captions, video and corresponding audio) but when labeling
them is time-consuming. Using a precise information-theoretic definition of
interactions, our key contributions are the derivations of lower and upper
bounds to quantify the amount of multimodal interactions in this
semi-supervised setting. We propose two lower bounds based on the amount of
shared information between modalities and the disagreement between separately
trained unimodal classifiers, and derive an upper bound through connections to
approximate algorithms for min-entropy couplings. We validate these estimated
bounds and show how they accurately track true interactions. Finally, two
semi-supervised multimodal applications are explored based on these theoretical
results: (1) analyzing the relationship between multimodal performance and
estimated interactions, and (2) self-supervised learning that embraces
disagreement between modalities beyond agreement as is typically done.
\\ ( https://arxiv.org/abs/2306.04539 ,  3320kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04542
Date: Wed, 7 Jun 2023 15:46:47 GMT   (6000kb,D)

Title: On the Design Fundamentals of Diffusion Models: A Survey
Authors: Ziyi Chang, George A. Koulieris, Hubert P. H. Shum
Categories: cs.LG cs.AI cs.CV
\\
 Diffusion models are generative models, which gradually add and remove noise
to learn the underlying distribution of training data for data generation. The
components of diffusion models have gained significant attention with many
design choices proposed. Existing reviews have primarily focused on
higher-level solutions, thereby covering less on the design fundamentals of
components. This study seeks to address this gap by providing a comprehensive
and coherent review on component-wise design choices in diffusion models.
Specifically, we organize this review according to their three key components,
namely the forward process, the reverse process, and the sampling procedure.
This allows us to provide a fine-grained perspective of diffusion models,
benefiting future studies in the analysis of individual components, the
applicability of design choices, and the implementation of diffusion models.
\\ ( https://arxiv.org/abs/2306.04542 ,  6000kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04548
Date: Wed, 7 Jun 2023 15:51:06 GMT   (19kb)

Title: Convergence of SARSA with linear function approximation: The random
 horizon case
Authors: Lina Palmborg
Categories: cs.LG
\\
 The reinforcement learning algorithm SARSA combined with linear function
approximation has been shown to converge for infinite horizon discounted Markov
decision problems (MDPs). In this paper, we investigate the convergence of the
algorithm for random horizon MDPs, which has not previously been shown. We
show, similar to earlier results for infinite horizon discounted MDPs, that if
the behaviour policy is $\varepsilon$-soft and Lipschitz continuous with
respect to the weight vector of the linear function approximation, with small
enough Lipschitz constant, then the algorithm will converge with probability
one when considering a random horizon MDP.
\\ ( https://arxiv.org/abs/2306.04548 ,  19kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04556
Date: Wed, 7 Jun 2023 16:03:55 GMT   (192kb,D)

Title: StudentEval: A Benchmark of Student-Written Prompts for Large Language
 Models of Code
Authors: Hannah McLean Babe, Sydney Nguyen, Yangtian Zi, Arjun Guha, Molly Q
 Feldman, Carolyn Jane Anderson
Categories: cs.LG cs.HC
\\
 Code LLMs are being rapidly deployed and there is evidence that they can make
professional programmers more productive. Current benchmarks for code
generation measure whether models generate correct programs given an expert
prompt. In this paper, we present a new benchmark containing multiple prompts
per problem, written by a specific population of non-expert prompters:
beginning programmers. StudentEval contains 1,749 prompts for 48 problems,
written by 80 students who have only completed one semester of Python
programming. Our students wrote these prompts while working interactively with
a Code LLM, and we observed very mixed success rates. We use StudentEval to
evaluate 5 Code LLMs and find that StudentEval is a better discriminator of
model performance than existing benchmarks. We analyze the prompts and find
significant variation in students' prompting techniques. We also find that
nondeterministic LLM sampling could mislead students into thinking that their
prompts are more (or less) effective than they actually are, which has
implications for how to teach with Code LLMs.
\\ ( https://arxiv.org/abs/2306.04556 ,  192kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04566
Date: Wed, 7 Jun 2023 16:13:16 GMT   (2176kb,D)

Title: Recent applications of machine learning, remote sensing, and iot
 approaches in yield prediction: a critical review
Authors: Fatima Zahra Bassine, Terence Epule Epule, Ayoub Kechchour, Abdelghani
 Chehbouni
Categories: cs.LG cs.AI cs.NI cs.SE
Comments: 35 pages, 12 figures, 14 tables
\\
 The integration of remote sensing and machine learning in agriculture is
transforming the industry by providing insights and predictions through data
analysis. This combination leads to improved yield prediction and water
management, resulting in increased efficiency, better yields, and more
sustainable agricultural practices. Achieving the United Nations' Sustainable
Development Goals, especially "zero hunger," requires the investigation of crop
yield and precipitation gaps, which can be accomplished through, the usage of
artificial intelligence (AI), machine learning (ML), remote sensing (RS), and
the internet of things (IoT). By integrating these technologies, a robust
agricultural mobile or web application can be developed, providing farmers and
decision-makers with valuable information and tools for improving crop
management and increasing efficiency. Several studies have investigated these
new technologies and their potential for diverse tasks such as crop monitoring,
yield prediction, irrigation management, etc. Through a critical review, this
paper reviews relevant articles that have used RS, ML, cloud computing, and IoT
in crop yield prediction. It reviews the current state-of-the-art in this field
by critically evaluating different machine-learning approaches proposed in the
literature for crop yield prediction and water management. It provides insights
into how these methods can improve decision-making in agricultural production
systems. This work will serve as a compendium for those interested in yield
prediction in terms of primary literature but, most importantly, what
approaches can be used for real-time and robust prediction.
\\ ( https://arxiv.org/abs/2306.04566 ,  2176kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04581
Date: Wed, 7 Jun 2023 16:33:52 GMT   (1550kb,D)

Title: Divide and Repair: Using Options to Improve Performance of Imitation
 Learning Against Adversarial Demonstrations
Authors: Prithviraj Dasgupta
Categories: cs.LG cs.AI
Comments: 33 pages, 4 figures, 3 tables
ACM-class: I.2.3
\\
 We consider the problem of learning to perform a task from demonstrations
given by teachers or experts, when some of the experts' demonstrations might be
adversarial and demonstrate an incorrect way to perform the task. We propose a
novel technique that can identify parts of demonstrated trajectories that have
not been significantly modified by the adversary and utilize them for learning,
using temporally extended policies or options. We first define a trajectory
divergence measure based on the spatial and temporal features of demonstrated
trajectories to detect and discard parts of the trajectories that have been
significantly modified by an adversarial expert, and, could degrade the
learner's performance, if used for learning, We then use an options-based
algorithm that partitions trajectories and learns only from the parts of
trajectories that have been determined as admissible. We provide theoretical
results of our technique to show that repairing partial trajectories improves
the sample efficiency of the demonstrations without degrading the learner's
performance. We then evaluate the proposed algorithm for learning to play an
Atari-like, computer-based game called LunarLander in the presence of different
types and degrees of adversarial attacks of demonstrated trajectories. Our
experimental results show that our technique can identify adversarially
modified parts of the demonstrated trajectories and successfully prevent the
learning performance from degrading due to adversarial demonstrations.
\\ ( https://arxiv.org/abs/2306.04581 ,  1550kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04590
Date: Wed, 7 Jun 2023 16:40:51 GMT   (2939kb,D)

Title: Proximity-Informed Calibration for Deep Neural Networks
Authors: Miao Xiong, Ailin Deng, Pang Wei Koh, Jiaying Wu, Shen Li, Jianqing
 Xu, Bryan Hooi
Categories: cs.LG cs.AI
\\
 Confidence calibration is central to providing accurate and interpretable
uncertainty estimates, especially under safety-critical scenarios. However, we
find that existing calibration algorithms often overlook the issue of proximity
bias, a phenomenon where models tend to be more overconfident in low proximity
data (i.e., lying in the sparse region of the data distribution) compared to
high proximity samples, and thus suffer from inconsistent miscalibration across
different proximity samples. We examine the problem over pretrained ImageNet
models and observe that: 1) Proximity bias exists across a wide variety of
model architectures and sizes; 2) Transformer-based models are more susceptible
to proximity bias than CNN-based models; 3) Proximity bias persists even after
performing popular calibration algorithms like temperature scaling; 4) Models
tend to overfit more heavily on low proximity samples than on high proximity
samples. Motivated by the empirical findings, we propose ProCal, a
plug-and-play algorithm with a theoretical guarantee to adjust sample
confidence based on proximity. To further quantify the effectiveness of
calibration algorithms in mitigating proximity bias, we introduce
proximity-informed expected calibration error (PIECE) with theoretical
analysis. We show that ProCal is effective in addressing proximity bias and
improving calibration on balanced, long-tail, and distribution-shift settings
under four metrics over various model architectures.
\\ ( https://arxiv.org/abs/2306.04590 ,  2939kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04595
Date: Wed, 7 Jun 2023 16:49:03 GMT   (586kb,D)

Title: Generalization Across Observation Shifts in Reinforcement Learning
Authors: Anuj Mahajan and Amy Zhang
Categories: cs.LG cs.AI cs.RO
\\
 Learning policies which are robust to changes in the environment are critical
for real world deployment of Reinforcement Learning agents. They are also
necessary for achieving good generalization across environment shifts. We focus
on bisimulation metrics, which provide a powerful means for abstracting task
relevant components of the observation and learning a succinct representation
space for training the agent using reinforcement learning. In this work, we
extend the bisimulation framework to also account for context dependent
observation shifts. Specifically, we focus on the simulator based learning
setting and use alternate observations to learn a representation space which is
invariant to observation shifts using a novel bisimulation based objective.
This allows us to deploy the agent to varying observation settings during test
time and generalize to unseen scenarios. We further provide novel theoretical
bounds for simulator fidelity and performance transfer guarantees for using a
learnt policy to unseen shifts. Empirical analysis on the high-dimensional
image based control domains demonstrates the efficacy of our method.
\\ ( https://arxiv.org/abs/2306.04595 ,  586kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04620
Date: Wed, 7 Jun 2023 17:48:29 GMT   (15806kb,D)

Title: Goal-conditioned GFlowNets for Controllable Multi-Objective Molecular
 Design
Authors: Julien Roy, Pierre-Luc Bacon, Christopher Pal and Emmanuel Bengio
Categories: cs.LG q-bio.BM
Comments: 14 pages
\\
 In recent years, in-silico molecular design has received much attention from
the machine learning community. When designing a new compound for
pharmaceutical applications, there are usually multiple properties of such
molecules that need to be optimised: binding energy to the target,
synthesizability, toxicity, EC50, and so on. While previous approaches have
employed a scalarization scheme to turn the multi-objective problem into a
preference-conditioned single objective, it has been established that this kind
of reduction may produce solutions that tend to slide towards the extreme
points of the objective space when presented with a problem that exhibits a
concave Pareto front. In this work we experiment with an alternative
formulation of goal-conditioned molecular generation to obtain a more
controllable conditional model that can uniformly explore solutions along the
entire Pareto front.
\\ ( https://arxiv.org/abs/2306.04620 ,  15806kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04621
Date: Wed, 7 Jun 2023 17:50:59 GMT   (33kb)

Title: Align, Distill, and Augment Everything All at Once for Imbalanced
 Semi-Supervised Learning
Authors: Emanuel Sanchez Aimar and Hannah Helgesen and Michael Felsberg and
 Marco Kuhlmann
Categories: cs.LG cs.CV
Comments: Under review, 12 pages
\\
 Addressing the class imbalance in long-tailed semi-supervised learning (SSL)
poses a few significant challenges stemming from differences between the
marginal distributions of unlabeled data and the labeled data, as the former is
often unknown and potentially distinct from the latter. The first challenge is
to avoid biasing the pseudo-labels towards an incorrect distribution, such as
that of the labeled data or a balanced distribution, during training. However,
we still wish to ensure a balanced unlabeled distribution during inference,
which is the second challenge. To address both of these challenges, we propose
a three-faceted solution: a flexible distribution alignment that progressively
aligns the classifier from a dynamically estimated unlabeled prior towards a
balanced distribution, a soft consistency regularization that exploits
underconfident pseudo-labels discarded by threshold-based methods, and a schema
for expanding the unlabeled set with input data from the labeled partition.
This last facet comes in as a response to the commonly-overlooked fact that
disjoint partitions of labeled and unlabeled data prevent the benefits of
strong data augmentation on the labeled set. Our overall framework requires no
additional training cycles, so it will align, distill, and augment everything
all at once (ADALLO). Our extensive evaluations of ADALLO on imbalanced SSL
benchmark datasets, including CIFAR10-LT, CIFAR100-LT, and STL10-LT with
varying degrees of class imbalance, amount of labeled data, and distribution
mismatch, demonstrate significant improvements in the performance of imbalanced
SSL under large distribution mismatch, as well as competitiveness with
state-of-the-art methods when the labeled and unlabeled data follow the same
marginal distribution. Our code will be released upon paper acceptance.
\\ ( https://arxiv.org/abs/2306.04621 ,  33kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04622
Date: Wed, 7 Jun 2023 17:52:29 GMT   (3728kb,D)

Title: Yet Another Algorithm for Supervised Principal Component Analysis:
 Supervised Linear Centroid-Encoder
Authors: Tomojit Ghosh, Michael Kirby
Categories: cs.LG cs.CV
Comments: A novel algorithm for supervised PCA. 22 pages (including 2 reference
 pages), 8 figures and mathematical analysis of the proposed algorithm. The
 article is under review now
\\
 We propose a new supervised dimensionality reduction technique called
Supervised Linear Centroid-Encoder (SLCE), a linear counterpart of the
nonlinear Centroid-Encoder (CE) \citep{ghosh2022supervised}. SLCE works by
mapping the samples of a class to its class centroid using a linear
transformation. The transformation is a projection that reconstructs a point
such that its distance from the corresponding class centroid, i.e.,
centroid-reconstruction loss, is minimized in the ambient space. We derive a
closed-form solution using an eigendecomposition of a symmetric matrix. We did
a detailed analysis and presented some crucial mathematical properties of the
proposed approach. %We also provide an iterative solution approach based
solving the optimization problem using a descent method. We establish a
connection between the eigenvalues and the centroid-reconstruction loss. In
contrast to Principal Component Analysis (PCA) which reconstructs a sample in
the ambient space, the transformation of SLCE uses the instances of a class to
rebuild the corresponding class centroid. Therefore the proposed method can be
considered a form of supervised PCA. Experimental results show the performance
advantage of SLCE over other supervised methods.
\\ ( https://arxiv.org/abs/2306.04622 ,  3728kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04634
Date: Wed, 7 Jun 2023 17:58:48 GMT   (14947kb,D)

Title: On the Reliability of Watermarks for Large Language Models
Authors: John Kirchenbauer, Jonas Geiping, Yuxin Wen, Manli Shu, Khalid
 Saifullah, Kezhi Kong, Kasun Fernando, Aniruddha Saha, Micah Goldblum and Tom
 Goldstein
Categories: cs.LG cs.CL cs.CR
Comments: 14 pages in the main body. Code is available at
 https://github.com/jwkirchenbauer/lm-watermarking
\\
 Large language models (LLMs) are now deployed to everyday use and positioned
to produce large quantities of text in the coming decade. Machine-generated
text may displace human-written text on the internet and has the potential to
be used for malicious purposes, such as spearphishing attacks and social media
bots. Watermarking is a simple and effective strategy for mitigating such harms
by enabling the detection and documentation of LLM-generated text. Yet, a
crucial question remains: How reliable is watermarking in realistic settings in
the wild? There, watermarked text might be mixed with other text sources,
paraphrased by human writers or other language models, and used for
applications in a broad number of domains, both social and technical. In this
paper, we explore different detection schemes, quantify their power at
detecting watermarks, and determine how much machine-generated text needs to be
observed in each scenario to reliably detect the watermark. We especially
highlight our human study, where we investigate the reliability of watermarking
when faced with human paraphrasing. We compare watermark-based detection to
other detection strategies, finding overall that watermarking is a reliable
solution, especially because of its sample complexity - for all attacks we
consider, the watermark evidence compounds the more examples are given, and the
watermark is eventually detected.
\\ ( https://arxiv.org/abs/2306.04634 ,  14947kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04637
Date: Wed, 7 Jun 2023 17:59:31 GMT   (387kb,D)

Title: Transformers as Statisticians: Provable In-Context Learning with
 In-Context Algorithm Selection
Authors: Yu Bai, Fan Chen, Huan Wang, Caiming Xiong, Song Mei
Categories: cs.LG cs.AI cs.CL math.ST stat.ML stat.TH
\\
 Neural sequence models based on the transformer architecture have
demonstrated remarkable \emph{in-context learning} (ICL) abilities, where they
can perform new tasks when prompted with training and test examples, without
any parameter update to the model. This work first provides a comprehensive
statistical theory for transformers to perform ICL. Concretely, we show that
transformers can implement a broad class of standard machine learning
algorithms in context, such as least squares, ridge regression, Lasso, learning
generalized linear models, and gradient descent on two-layer neural networks,
with near-optimal predictive power on various in-context data distributions.
Using an efficient implementation of in-context gradient descent as the
underlying mechanism, our transformer constructions admit mild size bounds, and
can be learned with polynomially many pretraining sequences.
 Building on these ``base'' ICL algorithms, intriguingly, we show that
transformers can implement more complex ICL procedures involving
\emph{in-context algorithm selection}, akin to what a statistician can do in
real life -- A \emph{single} transformer can adaptively select different base
ICL algorithms -- or even perform qualitatively different tasks -- on different
input sequences, without any explicit prompting of the right algorithm or task.
We both establish this in theory by explicit constructions, and also observe
this phenomenon experimentally. In theory, we construct two general mechanisms
for algorithm selection with concrete examples: pre-ICL testing, and post-ICL
validation. As an example, we use the post-ICL validation mechanism to
construct a transformer that can perform nearly Bayes-optimal ICL on a
challenging task -- noisy linear models with mixed noise levels.
Experimentally, we demonstrate the strong in-context algorithm selection
capabilities of standard transformer architectures.
\\ ( https://arxiv.org/abs/2306.04637 ,  387kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04083
Date: Wed, 7 Jun 2023 00:54:56 GMT   (21712kb,D)

Title: Coverage Path Planning with Budget Constraints for Multiple Unmanned
 Ground Vehicles
Authors: Vu Phi Tran, Asanka Perera, Matthew A. Garratt, Kathryn Kasmarik,
 Sreenatha Anavatti
Categories: cs.MA
\\
 This paper proposes a state-machine model for a multi-modal, multi-robot
environmental sensing algorithm. This multi-modal algorithm integrates two
different exploration algorithms: (1) coverage path planning using variable
formations and (2) collaborative active sensing using multi-robot swarms. The
state machine provides the logic for when to switch between these different
sensing algorithms. We evaluate the performance of the proposed approach on a
gas source localisation and mapping task. We use hardware-in-the-loop
experiments and real-time experiments with a radio source simulating a real gas
field. We compare the proposed approach with a single-mode, state-of-the-art
collaborative active sensing approach. Our results indicate that our
multi-modal switching approach can converge more rapidly than single-mode
active sensing.
\\ ( https://arxiv.org/abs/2306.04083 ,  21712kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04137
Date: Wed, 7 Jun 2023 04:21:08 GMT   (21338kb,D)

Title: Multi-Agent Reinforcement Learning for Cooperative Air Transportation
 Services in City-Wide Autonomous Urban Air Mobility
Authors: Chanyoung Park, Gyu Seon Kim, Soohyun Park, Soyi Jung, and Joongheon
 Kim
Categories: cs.MA
Comments: 15 pages, 14 figures
\\
 The development of urban-air-mobility (UAM) is rapidly progressing with
spurs, and the demand for efficient transportation management systems is a
rising need due to the multifaceted environmental uncertainties. Thus, this
paper proposes a novel air transportation service management algorithm based on
multi-agent deep reinforcement learning (MADRL) to address the challenges of
multi-UAM cooperation. Specifically, the proposed algorithm in this paper is
based on communication network (CommNet) method utilizing centralized training
and distributed execution (CTDE) in multiple UAMs for providing efficient air
transportation services to passengers collaboratively. Furthermore, this paper
adopts actual vertiport maps and UAM specifications for constructing realistic
air transportation networks. By evaluating the performance of the proposed
algorithm in data-intensive simulations, the results show that the proposed
algorithm outperforms existing approaches in terms of air transportation
service quality. Furthermore, there are no inferior UAMs by utilizing parameter
sharing in CommNet and a centralized critic network in CTDE. Therefore, it can
be confirmed that the research results in this paper can provide a promising
solution for autonomous air transportation management systems in city-wide
urban areas.
\\ ( https://arxiv.org/abs/2306.04137 ,  21338kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03951
Date: Tue, 6 Jun 2023 18:29:10 GMT   (2223kb,D)

Title: Reinforcement Learning-Based Control of CrazyFlie 2.X Quadrotor
Authors: Arshad Javeed, Valent\'in L\'opez Jim\'enez, Johan Gr\"onqvist
Categories: cs.RO cs.LG
\\
 The objective of the project is to explore synergies between classical
control algorithms such as PID and contemporary reinforcement learning
algorithms to come up with a pragmatic control mechanism to control the
CrazyFlie 2.X quadrotor. The primary objective would be performing PID tuning
using reinforcement learning strategies. The secondary objective is to leverage
the learnings from the first task to implement control for navigation by
integrating with the lighthouse positioning system. Two approaches are
considered for navigation, a discrete navigation problem using Deep Q-Learning
with finite predefined motion primitives, and deep reinforcement learning for a
continuous navigation approach. Simulations for RL training will be performed
on gym-pybullet-drones, an open-source gym-based environment for reinforcement
learning, and the RL implementations are provided by stable-baselines3
\\ ( https://arxiv.org/abs/2306.03951 ,  2223kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03953
Date: Tue, 6 Jun 2023 18:30:03 GMT   (4495kb,D)

Title: Rao-Blackwellized Particle Smoothing for Simultaneous Localization and
 Mapping
Authors: Manon Kok, Arno Solin, Thomas B. Sch\"on
Categories: cs.RO cs.SY eess.SP eess.SY
Comments: 19 pages, 7 figures
\\
 Simultaneous localization and mapping (SLAM) is the task of building a map
representation of an unknown environment while it at the same time is used for
positioning. A probabilistic interpretation of the SLAM task allows for
incorporating prior knowledge and for operation under uncertainty. Contrary to
the common practice of computing point estimates of the system states, we
capture the full posterior density through approximate Bayesian inference. This
dynamic learning task falls under state estimation, where the state-of-the-art
is in sequential Monte Carlo methods that tackle the forward filtering problem.
In this paper, we introduce a framework for probabilistic SLAM using particle
smoothing that does not only incorporate observed data in current state
estimates, but it also back-tracks the updated knowledge to correct for past
drift and ambiguities in both the map and in the states. Our solution can
efficiently handle both dense and sparse map representations by
Rao-Blackwellization of conditionally linear and conditionally linearized
models. We show through simulations and real-world experiments how the
principles apply to radio (BLE/Wi-Fi), magnetic field, and visual SLAM. The
proposed solution is general, efficient, and works well under confounding
noise.
\\ ( https://arxiv.org/abs/2306.03953 ,  4495kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04048
Date: Tue, 6 Jun 2023 22:34:00 GMT   (6470kb,D)

Title: Finite Element Modeling of Pneumatic Bending Actuators for Inflated-Beam
 Robots
Authors: Cosima du Pasquier, Sehui Jeong, Allison M. Okamura
Categories: cs.RO
\\
 Inflated-beam soft robots, such as tip-everting vine robots, can control
their curvature by contracting one side of the beam using pneumatic actuation.
In this work, a general finite element modeling approach is developed and
applied to characterize bending of inflated-beam soft robots. The model is
tested on four types of pneumatic actuators used in these robots (series,
compression, embedded, and fabric pneumatic artificial muscles) and can be
extended to other designs. Actuators rely on two types of bending mechanisms:
geometry-based contraction and material-based contraction. Geometry-based
contraction implies shape-change of the muscles from a flat to an inflated
shortened configuration that causes buckling of the inflated beam.
Material-based contraction relies on material anisotropy to produce a
contraction effect. The model depicts both mechanisms and accommodates for the
complex and highly nonlinear effects of buckling and anisotropy. Simulation
results are verified experimentally for each actuator type at three working
pressures (10, 20, and 30 kPa). Geometry-based contraction achieves the largest
deformation at accuracy values of 92.1% and higher once the buckling pattern is
established, and 80.7% and higher for lower pressures due to the stress
singularities occurring with buckling formation. Material-based contraction
achieves smaller bending angles but is at least 96.7% accurate. The models are
freely available online, and can thus be used by others to design inflated-beam
robots, such as tip-everting vine robots. Labor and material waste can be
reduced with this tool by optimizing designs that use knowledge of material
properties and stress to distributions to enable bending and manage stress
peaks.
\\ ( https://arxiv.org/abs/2306.04048 ,  6470kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04079
Date: Wed, 7 Jun 2023 00:40:41 GMT   (2687kb,D)

Title: RGBlimp: Robotic Gliding Blimp -- Design, Modeling, Development, and
 Aerodynamics Analysis
Authors: Hao Cheng, Zeyu Sha, Yongjian Zhu, Feitian Zhang
Categories: cs.RO cs.SY eess.SY
\\
 A miniature robotic blimp, as one type of lighter-than-air aerial vehicle,
has attracted increasing attention in the science and engineering field for its
long flight duration and safe aerial locomotion. While a variety of miniature
robotic blimps have been developed over the past decade, most of them utilize
the buoyant lift and neglect the aerodynamic lift in their design, thus leading
to a mediocre aerodynamic performance. This letter proposes a new design of
miniature robotic blimp that combines desirable features of both a robotic
blimp and a fixed-wing glider, named the Robotic Gliding Blimp, or RGBlimp.
This robot, equipped with an envelope filled with helium and a pair of wings,
uses an internal moving mass and a pair of propellers for its locomotion
control. This letter presents the design, dynamic modeling, prototyping, and
system identification of the RGBlimp. To the best of the authors' knowledge,
this is the first effort to systematically design and develop such a miniature
robotic blimp with hybrid lifts and moving mass control. Experimental results
are presented to validate the design and the dynamic model of the RGBlimp.
Analysis of the RGBlimp aerodynamics is conducted which confirms the
performance improvement of the proposed RGBlimp in aerodynamic efficiency and
flight stability.
\\ ( https://arxiv.org/abs/2306.04079 ,  2687kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04117
Date: Wed, 7 Jun 2023 03:07:30 GMT   (4654kb,D)

Title: A Robust Hybrid Observer for Side-slip Angle Estimation
Authors: Agapius Bou Ghosn, Marcus Nolte, Philip Polack, Arnaud de La Fortelle
Categories: cs.RO
\\
 For autonomous driving or advanced driving assistance, it is key to monitor
the vehicle dynamics behavior. Accurate models of this behavior include
acceleration, but also the side-slip angle, that eventually results from the
complex interaction between the tires and the road. Though it is an essential
quantity (e.g. for stability assessment), as opposed to accelerations, it is
not measurable through conventional off-the-shelf sensors. Therefore, accurate
side-slip angle observers are necessary for the proper planning and control of
vehicles. In this paper, we introduce a novel approach that combines
model-based side-slip angle estimation with neural networks. We apply our
approach to real vehicle data. We prove that the proposed method is able to
outperform state-of-the-art methods for normal driving maneuvers, and for
near-limits maneuvers where providing accurate estimations becomes challenging.
\\ ( https://arxiv.org/abs/2306.04117 ,  4654kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04130
Date: Wed, 7 Jun 2023 04:00:51 GMT   (7783kb,D)

Title: Collision-free Motion Generation Based on Stochastic Optimization and
 Composite Signed Distance Field Networks of Articulated Robot
Authors: Baolin Liu, Gedong Jiang, Fei Zhao, Xuesong Mei
Categories: cs.RO
Comments: 8 pages, 9 figures, under review of IEEE Robotics and Automation
 Letters
\\
 Safe robot motion generation is critical for practical applications from
manufacturing to homes. In this work, we proposed a stochastic
optimization-based motion generation method to generate collision-free and
time-optimal motion for the articulated robot represented by composite signed
distance field (SDF) networks. First, we propose composite SDF networks to
learn the SDF for articulated robots. The learned composite SDF networks
combined with the kinematics of the robot allow for quick and accurate
estimates of the minimum distance between the robot and obstacles in a batch
fashion. Then, a stochastic optimization-based trajectory planning algorithm
generates a spatial-optimized and collision-free trajectory offline with the
learned composite SDF networks. This stochastic trajectory planner is
formulated as a Bayesian Inference problem with a time-normalized Gaussian
process prior and exponential likelihood function. The Gaussian process prior
can enforce initial and goal position constraints in Configuration Space.
Besides, it can encode the correlation of waypoints in time series. The
likelihood function aims at encoding task-related cost terms, such as collision
avoidance, trajectory length penalty, boundary avoidance, etc. The kernel
updating strategies combined with model-predictive path integral (MPPI) is
proposed to solve the maximum a posteriori inference problems. Lastly, we
integrate the learned composite SDF networks into the trajectory planning
algorithm and apply it to a Franka Emika Panda robot. The simulation and
experiment results validate the effectiveness of the proposed method.
\\ ( https://arxiv.org/abs/2306.04130 ,  7783kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04167
Date: Wed, 7 Jun 2023 05:36:51 GMT   (3625kb,D)

Title: Fairness-Sensitive Policy-Gradient Reinforcement Learning for Reducing
 Bias in Robotic Assistance
Authors: Jie Zhu, Mengsha Hu, Xueyao Liang, Amy Zhang, Ruoming Jin, Rui Liu
Categories: cs.RO
\\
 Robots assist humans in various activities, from daily living public service
(e.g., airports and restaurants), and to collaborative manufacturing. However,
it is risky to assume that the knowledge and strategies robots learned from one
group of people can apply to other groups. The discriminatory performance of
robots will undermine their service quality for some people, ignore their
service requests, and even offend them. Therefore, it is critically important
to mitigate bias in robot decision-making for more fair services. In this
paper, we designed a self-reflective mechanism -- Fairness-Sensitive Policy
Gradient Reinforcement Learning (FSPGRL), to help robots to self-identify
biased behaviors during interactions with humans. FSPGRL identifies bias by
examining the abnormal update along particular gradients and updates the policy
network to support fair decision-making for robots. To validate FSPGRL's
effectiveness, a human-centered service scenario, "A robot is serving people in
a restaurant," was designed. A user study was conducted; 24 human subjects
participated in generating 1,000 service demonstrations. Four commonly-seen
issues "Willingness Issue," "Priority Issue," "Quality Issue," "Risk Issue"
were observed from robot behaviors. By using FSPGRL to improve robot decisions,
robots were proven to have a self-bias detection capability for a more fair
service. We have achieved the suppression of bias and improved the quality
during the process of robot learning to realize a relatively fair model.
\\ ( https://arxiv.org/abs/2306.04167 ,  3625kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04485
Date: Wed, 7 Jun 2023 14:55:00 GMT   (345kb,D)

Title: RotorPy: A Python-based Multirotor Simulator with Aerodynamics for
 Education and Research
Authors: Spencer Folk, James Paulos, Vijay Kumar
Categories: cs.RO
Comments: Appearing as a contributed paper in "The Role of Robotics Simulators
 for Unmanned Aerial Vehicles" workshop at the 2023 International Conference
 on Robotics and Automation (ICRA). See more at
 https://imrclab.github.io/workshop-uav-sims-icra2023/
\\
 Simulators play a critical role in aerial robotics both in and out of the
classroom. We present RotorPy, a simulation environment written entirely in
Python intentionally designed to be a lightweight and accessible tool for
robotics students and researchers alike to probe concepts in estimation,
planning, and control for aerial robots. RotorPy simulates the 6-DoF dynamics
of a multirotor robot including aerodynamic wrenches, obstacles, actuator
dynamics and saturation, realistic sensors, and wind models. This work
describes the modeling choices for RotorPy, benchmark testing against real
data, and a case study using the simulator to design and evaluate a model-based
wind estimator.
\\ ( https://arxiv.org/abs/2306.04485 ,  345kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04570
Date: Wed, 7 Jun 2023 16:17:47 GMT   (496kb,D)

Title: Towards Decentralized Heterogeneous Multi-Robot SLAM and Target Tracking
Authors: Ofer Dagan, Tycho L. Cinquini, Luke Morrissey, Kristen Such, Nisar R.
 Ahmed, Christoffer Heckman
Categories: cs.RO
Comments: 5 pages, 2 figures, presented at the ICRA 2023 workshop on
 "Distributed Graph Algorithms for Robotics"
\\
 In many robotics problems, there is a significant gain in collaborative
information sharing between multiple robots, for exploration, search and
rescue, tracking multiple targets, or mapping large environments. One of the
key implicit assumptions when solving cooperative multi-robot problems is that
all robots use the same (homogeneous) underlying algorithm. However, in
practice, we want to allow collaboration between robots possessing different
capabilities and that therefore must rely on heterogeneous algorithms. We
present a system architecture and the supporting theory, to enable
collaboration in a decentralized network of robots, where each robot relies on
different estimation algorithms. To develop our approach, we focus on
multi-robot simultaneous localization and mapping (SLAM) with multi-target
tracking. Our theoretical framework builds on our idea of exploiting the
conditional independence structure inherent to many robotics applications to
separate between each robot's local inference (estimation) tasks and fuse only
relevant parts of their non-equal, but overlapping probability density function
(pdfs). We present a new decentralized graph-based approach to the multi-robot
SLAM and tracking problem. We leverage factor graphs to split between different
parts of the problem for efficient data sharing between robots in the network
while enabling robots to use different local sparse
landmark/dense/metric-semantic SLAM algorithms.
\\ ( https://arxiv.org/abs/2306.04570 ,  496kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04020
Date: Tue, 6 Jun 2023 21:24:20 GMT   (402kb)

Title: Microcontroller Based Portable Measurement System for GaN and SiC
 Devices Characterization
Authors: Alberto Vella, Giuseppe Galioto and Giuseppe Costantino Giaconia
Categories: eess.SY cs.SY
Comments: 6 pages, 3 figures
\\
 The aim of this work is to design and implement an embedded system capable to
characterize some relevant figures of merit of Gallium Nitride and Silicon
Carbide transistors in a wide range of frequencies. In particular, the designed
system is focused on measuring the parameters involved in both the power loss
phenomena and the reliability of the device during switching operations. Both
the employment of a low-cost microcontroller unit and the equivalent-time
sampling technique contributed to make the measurement system flexible,
affordable and capable of enhanced sampling performance. As a result, different
GaN and SiC devices were compared, in order to characterize the behavior of the
measured quantities with respect to the switching frequency.
\\ ( https://arxiv.org/abs/2306.04020 ,  402kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04464
Date: Wed, 7 Jun 2023 14:38:45 GMT   (277kb)

Title: Constraints on OPF Surrogates for Learning Stable Local Volt/Var
 Controllers
Authors: Zhenyi Yuan, Guido Cavraro, Jorge Cort\'es
Categories: eess.SY cs.SY
\\
 We consider the problem of learning local Volt/Var controllers in
distribution grids (DGs). Our approach starts from learning separable
surrogates that take both local voltages and reactive powers as arguments and
predict the reactive power setpoints that approximate optimal power flow (OPF)
solutions. We propose an incremental control algorithm and identify two
different sets of slope conditions on the local surrogates such that the
network is collectively steered toward desired configurations asymptotically.
Our results reveal the trade-offs between each set of conditions, with coupled
voltage-power slope constraints allowing an arbitrary shape of surrogate
functions but risking limitations on exploiting generation capabilities, and
reactive power slope constraints taking full advantage of generation
capabilities but constraining the shape of surrogate functions. AC power flow
simulations on the IEEE 37-bus feeder illustrate their guaranteed stability
properties and respective advantages in two DG scenarios.
\\ ( https://arxiv.org/abs/2306.04464 ,  277kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04476
Date: Wed, 7 Jun 2023 14:46:04 GMT   (2572kb,D)

Title: Energy-based Assessment and Driving Behavior of ACC Systems and Humans
 Inside Platoons
Authors: Theocharis Apostolakis, Michail A. Makridis, Anastasios Kouvelas and
 Konstantinos Ampountolas
Categories: eess.SY cs.SY
Comments: 10 pages, 7 figures, 2 Tables
\\
 Evidence in the literature shows that automated and human driving modes
demonstrate different driving characteristics, i.e., headway policy, spacing
policy, reaction time, comfortable acceleration, and others. These differences
alter observed traffic dynamics and have an impact on energy consumption. This
paper assesses the energy footprint of commercially implemented adaptive cruise
control (ACC) systems and human drivers in car-following formation via
different models using empirical observations on very similar driving cycles
and/or routes. Most importantly, it initiates a critical discussion of the
findings under the behavioral properties of each mode. Findings show that: ACC
systems propagate an increasing energy consumption upstream, while human
drivers do not; they succeed in maintaining a constant time-headway policy,
operating very reliably; they develop a strong bond with their leader compared
to their human counterparts; the two modes (humans and ACCs) are operating in
different phase-space areas with room for improvement. Overall, findings show
that ACC systems must be optimized to achieve a trade-off between functional
requirements and eco-driving instructions.
\\ ( https://arxiv.org/abs/2306.04476 ,  2572kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04515
Date: Wed, 7 Jun 2023 15:27:06 GMT   (14715kb,D)

Title: Active Reconfigurable Intelligent Surfaces for the Millimeter-Wave
 Frequency Band: System Design and Measurement
Authors: Hamed Radpour, Markus Hofer, Lukas Walter Mayer, Andreas Hofmann,
 Martin Schiefer and Thomas Zemen
Categories: eess.SY cs.SY eess.SP
Comments: Submitted to IEEE International Symposium on Personal, Indoor and
 Mobile Radio Communications (PIMRC), Toronto, Canada, 5-8 September 2023
\\
 Reconfigurable intelligent surfaces (RISs) will play a key role to establish
millimeter wave (mmWave) ultra-reliable low-latency communication systems for
sixth-generation (6G) applications. Currently, there are a few working
prototypes of RISs operating in the mmWave frequency band and all of them are
based on passive reflective elements. However, to fabricate an efficiently
working RIS at mmWave frequencies, it is crucial to take care of the strong
signal attenuation, reflective element losses and undesired radio frequency
(RF) circuit effects. In this paper, we provide measurement campaign results
for an active RIS in the mmWave frequency band as well as its analysis and
system design. The obtained results demonstrate that an active RIS outperforms
a RIS working in passive mode and provides a higher signal-to-noise-ratio
(SNR). The active RIS consists of active reflective elements that amplify the
impinging signal and reflect the signal to the desired beam direction. To
obtain an efficient RIS in terms of power consumption and RIS state switch
time, we design a hexagonal RIS with 37 elements working at 26 GHz. These
elements are designed to work whether in passive state (binary phase shifting)
or in active state (switch OFF or amplifying). We provide a comparison between
the performance of a RIS working in passive and active mode using numerical
simulations and empirical measurements. This comparison reveals that the active
reflective intelligent surface (RIS) provides a received power that is at least
4 dB higher than that of the equivalent passive RIS. These results demonstrate
the strong advantage of using active RISs for future ultra-reliable low-latency
wireless communications.
\\ ( https://arxiv.org/abs/2306.04515 ,  14715kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04549
Date: Wed, 7 Jun 2023 15:55:01 GMT   (921kb)

Title: Dynamic Geometry-Based Stochastic Channel Modeling for Polarized MIMO
 Systems with Moving Scatterers
Authors: Hamed Radpour, Laxmikant Minz, Seong-Ook Park, Duck-Yong Kim,
 Young-Chan Moon
Categories: eess.SY cs.SY eess.SP
Comments: 10 pages, 10 Figures
\\
 This paper introduces a four-dimensional (4D) geometry-based stochastic model
(GBSM) for polarized multiple-input multiple-output (MIMO) systems with moving
scatterers. We propose a novel motion path model with high degrees of freedom
based on the Brownian Motion (BM) random process for randomly moving
scatterers. This model is capable of analyzing the effect of both
deterministically and randomly moving scatterers on channel properties. The
mixture of Von Mises Fisher (VMF) distribution is considered for scatterers
resulting in a more general and practical model. The proposed motion path model
is applied to the clusters of scatterers with the mixture of VMF distribution,
and a closed form formula for calculating space time correlation function
(STCF) is achieved, allowing the study of the behavior of channel correlation
and channel capacity in the time domain with the presence of stationary and
moving scatterers. To obtain numerical results for channel capacity, we
employed Monte Carlo simulation method for channel realization purpose. The
impact of moving scatterers on the performance of polarized MIMO systems is
evaluated using 2 by 2 MIMO configurations with various dual polarizations,
i.e. V/V, V/H, and slanted 45{\deg} polarizations for different signal-to-noise
(SNR) regimes. The proposed motion path model can be applied to study various
dynamic systems with moving objects. The presented process and achieved formula
are general and can be applied to polarized MIMO systems with any arbitrary
number of antennas and polarizations.
\\ ( https://arxiv.org/abs/2306.04549 ,  921kb)
%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-
------------------------------------------------------------------------------
\\
arXiv:2306.03933 (*cross-listing*)
Date: Tue, 6 Jun 2023 18:01:03 GMT   (400kb,D)

Title: High-dimensional and Permutation Invariant Anomaly Detection
Authors: Vinicius Mikuni, Benjamin Nachman
Categories: hep-ph cs.AI cs.LG hep-ex
Comments: 7 pages, 5 figures
\\
 Methods for anomaly detection of new physics processes are often limited to
low-dimensional spaces due to the difficulty of learning high-dimensional
probability densities. Particularly at the constituent level, incorporating
desirable properties such as permutation invariance and variable-length inputs
becomes difficult within popular density estimation methods. In this work, we
introduce a permutation-invariant density estimator for particle physics data
based on diffusion models, specifically designed to handle variable-length
inputs. We demonstrate the efficacy of our methodology by utilizing the learned
density as a permutation-invariant anomaly detection score, effectively
identifying jets with low likelihood under the background-only hypothesis. To
validate our density estimation method, we investigate the ratio of learned
densities and compare to those obtained by a supervised classification
algorithm.
\\ ( https://arxiv.org/abs/2306.03933 ,  400kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04009 (*cross-listing*)
Date: Tue, 6 Jun 2023 20:45:18 GMT   (333kb,D)

Title: Triggering Multi-Hop Reasoning for Question Answering in Language Models
 using Soft Prompts and Random Walks
Authors: Kanishka Misra and Cicero Nogueira dos Santos and Siamak Shakeri
Categories: cs.CL cs.AI
Comments: Findings of ACL 2023
\\
 Despite readily memorizing world knowledge about entities, pre-trained
language models (LMs) struggle to compose together two or more facts to perform
multi-hop reasoning in question-answering tasks. In this work, we propose
techniques that improve upon this limitation by relying on random walks over
structured knowledge graphs. Specifically, we use soft prompts to guide LMs to
chain together their encoded knowledge by learning to map multi-hop questions
to random walk paths that lead to the answer. Applying our methods on two T5
LMs shows substantial improvements over standard tuning approaches in answering
questions that require 2-hop reasoning.
\\ ( https://arxiv.org/abs/2306.04009 ,  333kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04027 (*cross-listing*)
Date: Tue, 6 Jun 2023 21:44:23 GMT   (854kb,D)

Title: Intervention Generalization: A View from Factor Graph Models
Authors: Gecia Bravo-Hermsdorff, David S. Watson, Jialin Yu, Jakob Zeitler, and
 Ricardo Silva
Categories: stat.ML cs.AI cs.LG
\\
 One of the goals of causal inference is to generalize from past experiments
and observational data to novel conditions. While it is in principle possible
to eventually learn a mapping from a novel experimental condition to an outcome
of interest, provided a sufficient variety of experiments is available in the
training data, coping with a large combinatorial space of possible
interventions is hard. Under a typical sparse experimental design, this mapping
is ill-posed without relying on heavy regularization or prior distributions.
Such assumptions may or may not be reliable, and can be hard to defend or test.
In this paper, we take a close look at how to warrant a leap from past
experiments to novel conditions based on minimal assumptions about the
factorization of the distribution of the manipulated system, communicated in
the well-understood language of factor graph models. A postulated
$\textit{interventional factor model}$ (IFM) may not always be informative, but
it conveniently abstracts away a need for explicit unmeasured confounding and
feedback mechanisms, leading to directly testable claims. We derive necessary
and sufficient conditions for causal effect identifiability with IFMs using
data from a collection of experimental settings, and implement practical
algorithms for generalizing expected outcomes to novel conditions never
observed in the data.
\\ ( https://arxiv.org/abs/2306.04027 ,  854kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04061 (*cross-listing*)
Date: Tue, 6 Jun 2023 23:20:57 GMT   (1193kb,D)

Title: Deploying a Robust Active Preference Elicitation Algorithm: Experiment
 Design, Interface, and Evaluation for COVID-19 Patient Prioritization
Authors: Caroline M. Johnston, Patrick Vossler, Simon Blessenohl, Phebe Vayanos
Categories: cs.HC cs.AI
Comments: 10 pages, 5 figures, 1 table
\\
 Preference elicitation leverages AI or optimization to learn stakeholder
preferences in settings ranging from marketing to public policy. The online
robust preference elicitation procedure of arXiv:2003.01899 has been shown in
simulation to outperform various other elicitation procedures in terms of
effectively learning individuals' true utilities. However, as with any
simulation, the method makes a series of assumptions that cannot easily be
verified to hold true beyond simulation. Thus, we propose to validate the
robust method's performance in deployment, focused on the particular challenge
of selecting policies for prioritizing COVID-19 patients for scarce hospital
resources during the pandemic. To this end, we develop an online platform for
preference elicitation where users report their preferences between
alternatives over a moderate number of pairwise comparisons chosen by a
particular elicitation procedure. We recruit Amazon Mechanical Turk workers
($n$ = 193) to report their preferences and demonstrate that the robust method
outperforms asking random queries by 21%, the next best performing method in
the simulated results of arXiv:2003.01899, in terms of recommending policies
with a higher utility.
\\ ( https://arxiv.org/abs/2306.04061 ,  1193kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04101 (*cross-listing*)
Date: Wed, 7 Jun 2023 01:44:43 GMT   (709kb,D)

Title: Gotta: Generative Few-shot Question Answering by Prompt-based Cloze Data
 Augmentation
Authors: Xiusi Chen, Yu Zhang, Jinliang Deng, Jyun-Yu Jiang, Wei Wang
Categories: cs.CL cs.AI
\\
 Few-shot question answering (QA) aims at precisely discovering answers to a
set of questions from context passages while only a few training samples are
available. Although existing studies have made some progress and can usually
achieve proper results, they suffer from understanding deep semantics for
reasoning out the questions. In this paper, we develop Gotta, a Generative
prOmpT-based daTa Augmentation framework to mitigate the challenge above.
Inspired by the human reasoning process, we propose to integrate the cloze task
to enhance few-shot QA learning. Following the recent success of prompt-tuning,
we present the cloze task in the same format as the main QA task, allowing the
model to learn both tasks seamlessly together to fully take advantage of the
power of prompt-tuning. Extensive experiments on widely used benchmarks
demonstrate that Gotta consistently outperforms competitive baselines,
validating the effectiveness of our proposed prompt-tuning-based cloze task,
which not only fine-tunes language models but also learns to guide reasoning in
QA tasks. Further analysis shows that the prompt-based loss incorporates the
auxiliary task better than the multi-task loss, highlighting the strength of
prompt-tuning on the few-shot QA task.
\\ ( https://arxiv.org/abs/2306.04101 ,  709kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04161 (*cross-listing*)
Date: Wed, 7 Jun 2023 05:21:36 GMT   (5355kb,D)

Title: Bidirectional GaitNet: A Bidirectional Prediction Model of Human Gait
 and Anatomical Conditions
Authors: Jungnam Park, Moon Seok Park, Jehee Lee, Jungdam Won
Categories: cs.GR cs.AI
ACM-class: I.3; I.6
DOI: 10.1145/3588432.3591492
\\
 We present a novel generative model, called Bidirectional GaitNet, that
learns the relationship between human anatomy and its gait. The simulation
model of human anatomy is a comprehensive, full-body, simulation-ready,
musculoskeletal model with 304 Hill-type musculotendon units. The Bidirectional
GaitNet consists of forward and backward models. The forward model predicts a
gait pattern of a person with specific physical conditions, while the backward
model estimates the physical conditions of a person when his/her gait pattern
is provided. Our simulation-based approach first learns the forward model by
distilling the simulation data generated by a state-of-the-art predictive gait
simulator and then constructs a Variational Autoencoder (VAE) with the learned
forward model as its decoder. Once it is learned its encoder serves as the
backward model. We demonstrate our model on a variety of healthy/impaired gaits
and validate it in comparison with physical examination data of real patients.
\\ ( https://arxiv.org/abs/2306.04161 ,  5355kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04163 (*cross-listing*)
Date: Wed, 7 Jun 2023 05:26:38 GMT   (1922kb,D)

Title: Enhancing Virtual Assistant Intelligence: Precise Area Targeting for
 Instance-level User Intents beyond Metadata
Authors: Mengyu Chen, Zhenchang Xing, Jieshan Chen, Chunyang Chen and Qinghua
 Lu
Categories: cs.HC cs.AI cs.CV
\\
 Virtual assistants have been widely used by mobile phone users in recent
years. Although their capabilities of processing user intents have been
developed rapidly, virtual assistants in most platforms are only capable of
handling pre-defined high-level tasks supported by extra manual efforts of
developers. However, instance-level user intents containing more detailed
objectives with complex practical situations, are yet rarely studied so far. In
this paper, we explore virtual assistants capable of processing instance-level
user intents based on pixels of application screens, without the requirements
of extra extensions on the application side. We propose a novel cross-modal
deep learning pipeline, which understands the input vocal or textual
instance-level user intents, predicts the targeting operational area, and
detects the absolute button area on screens without any metadata of
applications. We conducted a user study with 10 participants to collect a
testing dataset with instance-level user intents. The testing dataset is then
utilized to evaluate the performance of our model, which demonstrates that our
model is promising with the achievement of 64.43% accuracy on our testing
dataset.
\\ ( https://arxiv.org/abs/2306.04163 ,  1922kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04176 (*cross-listing*)
Date: Wed, 7 Jun 2023 06:03:39 GMT   (12138kb,D)

Title: When to Read Documents or QA History: On Unified and Selective
 Open-domain QA
Authors: Kyungjae Lee, Sang-eun Han, Seung-won Hwang, Moontae Lee
Categories: cs.CL cs.AI
Comments: Findings of ACL 2023 camera ready
ACM-class: I.2.7
\\
 This paper studies the problem of open-domain question answering, with the
aim of answering a diverse range of questions leveraging knowledge resources.
Two types of sources, QA-pair and document corpora, have been actively
leveraged with the following complementary strength. The former is highly
precise when the paraphrase of given question $q$ was seen and answered during
training, often posed as a retrieval problem, while the latter generalizes
better for unseen questions. A natural follow-up is thus leveraging both
models, while a naive pipelining or integration approaches have failed to bring
additional gains over either model alone. Our distinction is interpreting the
problem as calibration, which estimates the confidence of predicted answers as
an indicator to decide when to use a document or QA-pair corpus. The
effectiveness of our method was validated on widely adopted benchmarks such as
Natural Questions and TriviaQA.
\\ ( https://arxiv.org/abs/2306.04176 ,  12138kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04189 (*cross-listing*)
Date: Wed, 7 Jun 2023 06:49:01 GMT   (63kb,D)

Title: Synthesising Recursive Functions for First-Order Model Counting:
 Challenges, Progress, and Conjectures
Authors: Paulius Dilkas, Vaishak Belle
Categories: cs.LO cs.AI
Comments: The full version of the paper to be published in KR 2023: 12 pages, 1
 figure
\\
 First-order model counting (FOMC) is a computational problem that asks to
count the models of a sentence in finite-domain first-order logic. In this
paper, we argue that the capabilities of FOMC algorithms to date are limited by
their inability to express many types of recursive computations. To enable such
computations, we relax the restrictions that typically accompany domain
recursion and generalise the circuits used to express a solution to an FOMC
problem to directed graphs that may contain cycles. To this end, we adapt the
most well-established (weighted) FOMC algorithm ForcLift to work with such
graphs and introduce new compilation rules that can create cycle-inducing edges
that encode recursive function calls. These improvements allow the algorithm to
find efficient solutions to counting problems that were previously beyond its
reach, including those that cannot be solved efficiently by any other exact
FOMC algorithm. We end with a few conjectures on what classes of instances
could be domain-liftable as a result.
\\ ( https://arxiv.org/abs/2306.04189 ,  63kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04286 (*cross-listing*)
Date: Wed, 7 Jun 2023 09:39:07 GMT   (812kb,D)

Title: A Mask Free Neural Network for Monaural Speech Enhancement
Authors: Liang Liu, Haixin Guan, Jinlong Ma, Wei Dai, Guangyong Wang, Shaowei
 Ding
Categories: cs.SD cs.AI
\\
 In speech enhancement, the lack of clear structural characteristics in the
target speech phase requires the use of conservative and cumbersome network
frameworks. It seems difficult to achieve competitive performance using direct
methods and simple network architectures. However, we propose the MFNet, a
direct and simple network that can not only map speech but also map reverse
noise. This network is constructed by stacking global local former blocks
(GLFBs), which combine the advantages of Mobileblock for global processing and
Metaformer architecture for local interaction. Our experimental results
demonstrate that our network using mapping method outperforms masking methods,
and direct mapping of reverse noise is the optimal solution in strong noise
environments. In a horizontal comparison on the 2020 Deep Noise Suppression
(DNS) challenge test set without reverberation, to the best of our knowledge,
MFNet is the current state-of-the-art (SOTA) mapping model.
\\ ( https://arxiv.org/abs/2306.04286 ,  812kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04339 (*cross-listing*)
Date: Wed, 7 Jun 2023 11:10:10 GMT   (3302kb,D)

Title: Unpaired Deep Learning for Pharmacokinetic Parameter Estimation from
 Dynamic Contrast-Enhanced MRI
Authors: Gyutaek Oh, Won-Jin Moon, and Jong Chul Ye
Categories: eess.IV cs.AI cs.CV cs.LG physics.med-ph
\\
 DCE-MRI provides information about vascular permeability and tissue perfusion
through the acquisition of pharmacokinetic parameters. However, traditional
methods for estimating these pharmacokinetic parameters involve fitting tracer
kinetic models, which often suffer from computational complexity and low
accuracy due to noisy arterial input function (AIF) measurements. Although some
deep learning approaches have been proposed to tackle these challenges, most
existing methods rely on supervised learning that requires paired input DCE-MRI
and labeled pharmacokinetic parameter maps. This dependency on labeled data
introduces significant time and resource constraints, as well as potential
noise in the labels, making supervised learning methods often impractical. To
address these limitations, here we present a novel unpaired deep learning
method for estimating both pharmacokinetic parameters and the AIF using a
physics-driven CycleGAN approach. Our proposed CycleGAN framework is designed
based on the underlying physics model, resulting in a simpler architecture with
a single generator and discriminator pair. Crucially, our experimental results
indicate that our method, which does not necessitate separate AIF measurements,
produces more reliable pharmacokinetic parameters than other techniques.
\\ ( https://arxiv.org/abs/2306.04339 ,  3302kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04340 (*cross-listing*)
Date: Wed, 7 Jun 2023 11:11:12 GMT   (1605kb,D)

Title: Co-evolving Graph Reasoning Network for Emotion-Cause Pair Extraction
Authors: Bowen Xing and Ivor W. Tsang
Categories: cs.CL cs.AI
Comments: Accepted by ECML-PKDD 2023
\\
 Emotion-Cause Pair Extraction (ECPE) aims to extract all emotion clauses and
their corresponding cause clauses from a document. Existing approaches tackle
this task through multi-task learning (MTL) framework in which the two subtasks
provide indicative clues for ECPE. However, the previous MTL framework
considers only one round of multi-task reasoning and ignores the reverse
feedbacks from ECPE to the subtasks. Besides, its multi-task reasoning only
relies on semantics-level interactions, which cannot capture the explicit
dependencies, and both the encoder sharing and multi-task hidden states
concatenations can hardly capture the causalities. To solve these issues, we
first put forward a new MTL framework based on Co-evolving Reasoning. It (1)
models the bidirectional feedbacks between ECPE and its subtasks; (2) allows
the three tasks to evolve together and prompt each other recurrently; (3)
integrates prediction-level interactions to capture explicit dependencies. Then
we propose a novel multi-task relational graph (MRG) to sufficiently exploit
the causal relations. Finally, we propose a Co-evolving Graph Reasoning Network
(CGR-Net) that implements our MTL framework and conducts Co-evolving Reasoning
on MRG. Experimental results show that our model achieves new state-of-the-art
performance, and further analysis confirms the advantages of our method.
\\ ( https://arxiv.org/abs/2306.04340 ,  1605kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04357 (*cross-listing*)
Date: Wed, 7 Jun 2023 11:40:07 GMT   (181kb,D)

Title: ConTextual Masked Auto-Encoder for Retrieval-based Dialogue Systems
Authors: Zhenpeng Su and Xing Wu and Wei Zhou and Guangyuan Ma and Songlin
Categories: cs.CL cs.AI
\\
 Dialogue response selection aims to select an appropriate response from
several candidates based on a given user and system utterance history. Recent
studies have been improving the accuracy of dialogue response selection through
post-training, mostly relying on naive masked language modeling methods.
However, the recently developed generative methods have shown promising text
representation capabilities in IR community, which could potentially lead to
better dialogue semantics modeling. Thus, in this paper, we propose Dial-MAE
(Dialogue Contextual Masking Auto-encoder), a straightforward yet effective
post-training technique tailored for dialogue response selection. Dial-MAE uses
an asymmetric encoder-decoder architecture that learns to better compress the
semantics of the dialogue into dialogue-dense vectors. The process of Dial-MAE
involves a deep encoder creating a dialogue embedding with the masked dialogue
context, followed by a shallow decoder that uses this embedding along with the
highly masked response to restore the original response. Our experiments have
demonstrated that Dial-MAE is highly effective, achieving state-of-the-art
performance on two commonly evaluated benchmarks.
\\ ( https://arxiv.org/abs/2306.04357 ,  181kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04360 (*cross-listing*)
Date: Wed, 7 Jun 2023 11:46:14 GMT   (27479kb,D)

Title: Robust and Efficient Fault Diagnosis of mm-Wave Active Phased Arrays
 using Baseband Signal
Authors: Martin H. Nielsen, Yufeng Zhang, Changbin Xue, Jian Ren, Yingzeng Yin,
 Ming Shen, and Gert F. Pedersen
Categories: eess.SP cs.AI
Comments: 10 pages
Journal-ref: in IEEE Transactions on Antennas and Propagation, vol. 70, no. 7,
 pp. 5044-5053, July 2022
DOI: 10.1109/TAP.2022.3179898
\\
 One key communication block in 5G and 6G radios is the active phased array
(APA). To ensure reliable operation, efficient and timely fault diagnosis of
APAs on-site is crucial. To date, fault diagnosis has relied on measurement of
frequency domain radiation patterns using costly equipment and multiple
strictly controlled measurement probes, which are time-consuming, complex, and
therefore infeasible for on-site deployment. This paper proposes a novel method
exploiting a Deep Neural Network (DNN) tailored to extract the features hidden
in the baseband in-phase and quadrature signals for classifying the different
faults. It requires only a single probe in one measurement point for fast and
accurate diagnosis of the faulty elements and components in APAs.
 Validation of the proposed method is done using a commercial 28 GHz APA.
Accuracies of 99% and 80% have been demonstrated for single- and multi-element
failure detection, respectively. Three different test scenarios are
investigated: on-off antenna elements, phase variations, and magnitude
attenuation variations. In a low signal to noise ratio of 4 dB, stable fault
detection accuracy above 90% is maintained. This is all achieved with a
detection time of milliseconds (e.g 6~ms), showing a high potential for on-site
deployment.
\\ ( https://arxiv.org/abs/2306.04360 ,  27479kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04366 (*cross-listing*)
Date: Wed, 7 Jun 2023 11:59:45 GMT   (2026kb,D)

Title: Efficient Recruitment Strategy for Collaborative Mobile Crowd Sensing
 Based on GCN Trustworthiness Prediction
Authors: Zhongwei Zhan, Yingjie Wang, Peiyong Duan, Akshita Maradapu Vera
 Venkata Sai, Zhaowei Liu, Chaocan Xiang, Xiangrong Tong, Weilong Wang,
 Zhipeng Cai
Categories: cs.SI cs.AI cs.LG
\\
 Collaborative Mobile Crowd Sensing (CMCS) enhances data quality and coverage
by promoting teamwork in task sensing, with worker recruitment representing a
complex multi-objective optimization problem. Existing strategies mainly focus
on the characteristics of workers themselves, neglecting the asymmetric trust
relationships between them, which affects the rationality of task utility
evaluation. To address this, this paper first employs the Mini-Batch K-Means
clustering algorithm and deploys edge servers to enable efficient distributed
worker recruitment. Historical data and task requirements are utilized to
obtain workers' ability types and distances. A trust-directed graph in the
worker's social network is input into the Graph Convolutional Network (GCN)
framework for training, capturing asymmetric trustworthiness between worker
pairs. Privacy leakage is prevented in CMCS scenarios through high trust values
between workers. Ultimately, an undirected recruitment graph is constructed
using workers' abilities, trust values, and distance weights, transforming the
worker recruitment problem into a Maximum Weight Average Subgraph Problem
(MWASP). A Tabu Search Recruitment (TSR) algorithm is proposed to rationally
recruit a balanced multi-objective optimal task utility worker set for each
task. Extensive simulation experiments on four real-world datasets demonstrate
the effectiveness of the proposed strategy, outperforming other strategies.
\\ ( https://arxiv.org/abs/2306.04366 ,  2026kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04376 (*cross-listing*)
Date: Wed, 7 Jun 2023 12:17:34 GMT   (13788kb)

Title: Label Shift Quantification with Robustness Guarantees via Distribution
 Feature Matching
Authors: Bastien Dussap, Gilles Blanchard, Badr-Eddine Ch\'erief-Abdellatif
Categories: stat.ML cs.AI cs.LG
Comments: Accepted at the European Conference on Machine Learning and
 Principles and Practice of Knowledge Discovery in Databases (ECML) 2023
\\
 Quantification learning deals with the task of estimating the target label
distribution under label shift. In this paper, we first present a unifying
framework, distribution feature matching (DFM), that recovers as particular
instances various estimators introduced in previous literature. We derive a
general performance bound for DFM procedures, improving in several key aspects
upon previous bounds derived in particular cases. We then extend this analysis
to study robustness of DFM procedures in the misspecified setting under
departure from the exact label shift hypothesis, in particular in the case of
contamination of the target by an unknown distribution. These theoretical
findings are confirmed by a detailed numerical study on simulated and
real-world datasets. We also introduce an efficient, scalable and robust
version of kernel-based DFM using the Random Fourier Feature principle.
\\ ( https://arxiv.org/abs/2306.04376 ,  13788kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04384 (*cross-listing*)
Date: Wed, 7 Jun 2023 12:31:07 GMT   (47kb,D)

Title: Multilingual Clinical NER: Translation or Cross-lingual Transfer?
Authors: Xavier Fontaine, F\'elix Gaschi, Parisa Rastin and Yannick Toussaint
Categories: cs.CL cs.AI cs.LG
Comments: 23 pages, Proceedings of the 5th Clinical Natural Language Processing
 Workshop
\\
 Natural language tasks like Named Entity Recognition (NER) in the clinical
domain on non-English texts can be very time-consuming and expensive due to the
lack of annotated data. Cross-lingual transfer (CLT) is a way to circumvent
this issue thanks to the ability of multilingual large language models to be
fine-tuned on a specific task in one language and to provide high accuracy for
the same task in another language. However, other methods leveraging
translation models can be used to perform NER without annotated data in the
target language, by either translating the training set or test set. This paper
compares cross-lingual transfer with these two alternative methods, to perform
clinical NER in French and in German without any training data in those
languages. To this end, we release MedNERF a medical NER test set extracted
from French drug prescriptions and annotated with the same guidelines as an
English dataset. Through extensive experiments on this dataset and on a German
medical dataset (Frei and Kramer, 2021), we show that translation-based methods
can achieve similar performance to CLT but require more care in their design.
And while they can take advantage of monolingual clinical language models,
those do not guarantee better results than large general-purpose multilingual
models, whether with cross-lingual transfer or translation.
\\ ( https://arxiv.org/abs/2306.04384 ,  47kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04433 (*cross-listing*)
Date: Wed, 7 Jun 2023 13:46:49 GMT   (1578kb,D)

Title: Cross-Database and Cross-Channel ECG Arrhythmia Heartbeat Classification
 Based on Unsupervised Domain Adaptation
Authors: Md Niaz Imtiaz and Naimul Khan
Categories: eess.SP cs.AI
\\
 The classification of electrocardiogram (ECG) plays a crucial role in the
development of an automatic cardiovascular diagnostic system. However,
considerable variances in ECG signals between individuals is a significant
challenge. Changes in data distribution limit cross-domain utilization of a
model. In this study, we propose a solution to classify ECG in an unlabeled
dataset by leveraging knowledge obtained from labeled source domain. We present
a domain-adaptive deep network based on cross-domain feature discrepancy
optimization. Our method comprises three stages: pre-training, cluster-centroid
computing, and adaptation. In pre-training, we employ a Distributionally Robust
Optimization (DRO) technique to deal with the vanishing worst-case training
loss. To enhance the richness of the features, we concatenate three temporal
features with the deep learning features. The cluster computing stage involves
computing centroids of distinctly separable clusters for the source using true
labels, and for the target using confident predictions. We propose a novel
technique to select confident predictions in the target domain. In the
adaptation stage, we minimize compacting loss within the same cluster,
separating loss across different clusters, inter-domain cluster discrepancy
loss, and running combined loss to produce a domain-robust model. Experiments
conducted in both cross-domain and cross-channel paradigms show the efficacy of
the proposed method. Our method achieves superior performance compared to other
state-of-the-art approaches in detecting ventricular ectopic beats (V),
supraventricular ectopic beats (S), and fusion beats (F). Our method achieves
an average improvement of 11.78% in overall accuracy over the
non-domain-adaptive baseline method on the three test datasets.
\\ ( https://arxiv.org/abs/2306.04433 ,  1578kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04508 (*cross-listing*)
Date: Wed, 7 Jun 2023 15:20:24 GMT   (1048kb,D)

Title: Enhancing In-Context Learning with Answer Feedback for Multi-Span
 Question Answering
Authors: Zixian Huang, Jiaying Zhou, Gengyang Xiao, Gong Cheng
Categories: cs.CL cs.AI
Comments: 12 pages, submitted to NLPCC 2023
\\
 Whereas the recent emergence of large language models (LLMs) like ChatGPT has
exhibited impressive general performance, it still has a large gap with
fully-supervised models on specific tasks such as multi-span question
answering. Previous researches found that in-context learning is an effective
approach to exploiting LLM, by using a few task-related labeled data as
demonstration examples to construct a few-shot prompt for answering new
questions. A popular implementation is to concatenate a few questions and their
correct answers through simple templates, informing LLM of the desired output.
In this paper, we propose a novel way of employing labeled data such that it
also informs LLM of some undesired output, by extending demonstration examples
with feedback about answers predicted by an off-the-shelf model, e.g., correct,
incorrect, or incomplete. Experiments on three multi-span question answering
datasets as well as a keyphrase extraction dataset show that our new prompting
strategy consistently improves LLM's in-context learning performance.
\\ ( https://arxiv.org/abs/2306.04508 ,  1048kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04544 (*cross-listing*)
Date: Wed, 7 Jun 2023 15:49:04 GMT   (7470kb,D)

Title: Contrastive Bootstrapping for Label Refinement
Authors: Shudi Hou, Yu Xia, Muhao Chen, Sujian Li
Categories: cs.CL cs.AI
Comments: ACL 2023
\\
 Traditional text classification typically categorizes texts into pre-defined
coarse-grained classes, from which the produced models cannot handle the
real-world scenario where finer categories emerge periodically for accurate
services. In this work, we investigate the setting where fine-grained
classification is done only using the annotation of coarse-grained categories
and the coarse-to-fine mapping. We propose a lightweight contrastive
clustering-based bootstrapping method to iteratively refine the labels of
passages. During clustering, it pulls away negative passage-prototype pairs
under the guidance of the mapping from both global and local perspectives.
Experiments on NYT and 20News show that our method outperforms the
state-of-the-art methods by a large margin.
\\ ( https://arxiv.org/abs/2306.04544 ,  7470kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04605 (*cross-listing*)
Date: Mon, 5 Jun 2023 19:49:50 GMT   (644kb)

Title: Empowering Business Transformation: The Positive Impact and Ethical
 Considerations of Generative AI in Software Product Management -- A
 Systematic Literature Review
Authors: Nishant A. Parikh
Categories: cs.SE cs.AI
Comments: 24 pages, 4 figures
\\
 Generative Artificial Intelligence (GAI) has made outstanding strides in
recent years, with a good-sized impact on software product management. Drawing
on pertinent articles from 2016 to 2023, this systematic literature evaluation
reveals generative AI's potential applications, benefits, and constraints in
this area. The study shows that technology can assist in idea generation,
market research, customer insights, product requirements engineering, and
product development. It can help reduce development time and costs through
automatic code generation, customer feedback analysis, and more. However, the
technology's accuracy, reliability, and ethical consideration persist.
Ultimately, generative AI's practical application can significantly improve
software product management activities, leading to more efficient use of
resources, better product outcomes, and improved end-user experiences.
\\ ( https://arxiv.org/abs/2306.04605 ,  644kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04610 (*cross-listing*)
Date: Wed, 7 Jun 2023 17:22:03 GMT   (346kb)

Title: The Two Word Test: A Semantic Benchmark for Large Language Models
Authors: Nicholas Riccardi and Rutvik H. Desai
Categories: cs.CL cs.AI
Comments: 12 pages, 5 figures, 3 tables, submitted to NeurIPS 2023 Datasets and
 Benchmarks Track
\\
 Large Language Models (LLMs) have shown remarkable abilities recently,
including passing advanced professional exams and demanding benchmark tests.
This performance has led many to suggest that they are close to achieving
humanlike or 'true' understanding of language, and even Artificial General
Intelligence (AGI). Here, we provide a new open-source benchmark that can
assess semantic abilities of LLMs using two-word phrases using a task that can
be performed relatively easily by humans without advanced training. Combining
multiple words into a single concept is a fundamental aspect of human language
and intelligence. The test requires meaningfulness judgments of 1768 noun-noun
combinations that have been rated as meaningful (e.g., baby boy) or not
meaningful (e.g., goat sky). by 150 human raters. We provide versions of the
task that probe meaningfulness ratings on a 0-4 scale as well as binary
judgments. We conducted a series of experiments using the TWT on GPT-4,
GPT-3.5, and Bard, with both versions. Results demonstrated that, compared to
humans, all models perform poorly at rating meaningfulness of these phrases.
GPT-3.5 and Bard are also unable to make binary discriminations between
sensible and nonsense phrases as making sense. GPT-4 makes a substantial
improvement in binary discrimination of combinatorial phrases but is still
significantly worse than human performance. The TWT can be used to understand
the limitations and weaknesses of current LLMs, and potentially improve them.
The test also reminds us that caution is warranted in attributing 'true
understanding' or AGI to LLMs. TWT is available at:
https://github.com/NickRiccardi/two-word-test
\\ ( https://arxiv.org/abs/2306.04610 ,  346kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04640 (*cross-listing*)
Date: Wed, 7 Jun 2023 17:59:57 GMT   (406kb,D)

Title: ModuleFormer: Learning Modular Large Language Models From Uncurated Data
Authors: Yikang Shen, Zheyu Zhang, Tianyou Cao, Shawn Tan, Zhenfang Chen,
 Chuang Gan
Categories: cs.CL cs.AI cs.LG
\\
 Large Language Models (LLMs) have achieved remarkable results. But existing
models are expensive to train and deploy, and it is also difficult to expand
their knowledge beyond pre-training data without forgetting previous knowledge.
This paper proposes a new neural network architecture, ModuleFormer, that
leverages modularity to improve the efficiency and flexibility of large
language models. ModuleFormer is based on the Sparse Mixture of Experts (SMoE).
Unlike the previous SMoE-based modular language model [Gururangan et al.,
2021], which requires domain-labeled data to learn domain-specific experts,
ModuleFormer can induce modularity from uncurated data with its new load
balancing and load concentration losses. ModuleFormer is a modular architecture
that includes two different types of modules, new stick-breaking attention
heads, and feedforward experts. Different modules are sparsely activated
conditions on the input token during training and inference. In our experiment,
we found that the modular architecture enables three important abilities for
large pre-trained language models: 1) Efficiency, since ModuleFormer only
activates a subset of its modules for each input token, thus it could achieve
the same performance as dense LLMs with more than two times throughput; 2)
Extendability, ModuleFormer is more immune to catastrophic forgetting than
dense LLMs and can be easily extended with new modules to learn new knowledge
that is not included in the training data; 3) Specialisation, finetuning
ModuleFormer could specialize a subset of modules to the finetuning task, and
the task-unrelated modules could be easily pruned for a lightweight deployment.
\\ ( https://arxiv.org/abs/2306.04640 ,  406kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03934 (*cross-listing*)
Date: Tue, 6 Jun 2023 18:01:08 GMT   (30056kb,D)

Title: Accurate Fine-Grained Segmentation of Human Anatomy in Radiographs via
 Volumetric Pseudo-Labeling
Authors: Constantin Seibold, Alexander Jaus, Matthias A. Fink, Moon Kim, Simon
 Rei{\ss}, Ken Herrmann, Jens Kleesiek, Rainer Stiefelhagen
Categories: eess.IV cs.CV cs.LG
Comments: 28 pages, 1 table, 10 figures
ACM-class: I.4.6; I.4.7; I.4.8
\\
 Purpose: Interpreting chest radiographs (CXR) remains challenging due to the
ambiguity of overlapping structures such as the lungs, heart, and bones. To
address this issue, we propose a novel method for extracting fine-grained
anatomical structures in CXR using pseudo-labeling of three-dimensional
computed tomography (CT) scans.
 Methods: We created a large-scale dataset of 10,021 thoracic CTs with 157
labels and applied an ensemble of 3D anatomy segmentation models to extract
anatomical pseudo-labels. These labels were projected onto a two-dimensional
plane, similar to the CXR, allowing the training of detailed semantic
segmentation models for CXR without any manual annotation effort.
 Results: Our resulting segmentation models demonstrated remarkable
performance on CXR, with a high average model-annotator agreement between two
radiologists with mIoU scores of 0.93 and 0.85 for frontal and lateral anatomy,
while inter-annotator agreement remained at 0.95 and 0.83 mIoU. Our anatomical
segmentations allowed for the accurate extraction of relevant explainable
medical features such as the cardio-thoracic-ratio.
 Conclusion: Our method of volumetric pseudo-labeling paired with CT
projection offers a promising approach for detailed anatomical segmentation of
CXR with a high agreement with human annotators. This technique may have
important clinical implications, particularly in the analysis of various
thoracic pathologies.
\\ ( https://arxiv.org/abs/2306.03934 ,  30056kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03983 (*cross-listing*)
Date: Tue, 6 Jun 2023 19:36:11 GMT   (23059kb,D)

Title: Unsupervised Iterative U-Net with an Internal Guidance Layer for
 Vertebrae Contrast Enhancement in Chest X-Ray Images
Authors: Ella Eidlin, Assaf Hoogi, Nathan S. Netanyahu
Categories: eess.IV cs.CV
Comments: 10 pages, 11 figures, submitted to Transactions on Medical Imaging
ACM-class: I.4; I.4.3
\\
 X-ray imaging is a fundamental clinical tool for screening and diagnosing
various diseases. However, the spatial resolution of radiographs is often
limited, making it challenging to diagnose small image details and leading to
difficulties in identifying vertebrae anomalies at an early stage in chest
radiographs. To address this limitation, we propose a novel and robust approach
to significantly improve the quality of X-ray images by iteratively training a
deep neural network. Our framework includes an embedded internal guidance layer
that enhances the fine structures of spinal vertebrae in chest X-ray images
through fully unsupervised training, utilizing an iterative procedure that
employs the same network architecture in each enhancement phase. Additionally,
we have designed an optimized loss function that accurately identifies object
boundaries and enhances spinal features, thereby further enhancing the quality
of the images. Experimental results demonstrate that our proposed method
surpasses existing detail enhancement methods in terms of BRISQUE scores, and
is comparable in terms of LPC-SI. Furthermore, our approach exhibits superior
performance in restoring hidden fine structures, as evidenced by our
qualitative results. This innovative approach has the potential to
significantly enhance the diagnostic accuracy and early detection of diseases,
making it a promising advancement in X-ray imaging technology.
\\ ( https://arxiv.org/abs/2306.03983 ,  23059kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04086 (*cross-listing*)
Date: Wed, 7 Jun 2023 01:14:16 GMT   (4871kb,D)

Title: TEC-Net: Vision Transformer Embrace Convolutional Neural Networks for
 Medical Image Segmentation
Authors: Tao Lei, Rui Sun, Yong Wan, Yong Xia, Xiaogang Du, Asoke K. Nandi
Categories: eess.IV cs.CV
Comments: arXiv admin note: substantial text overlap with arXiv:2306.03373
\\
 The hybrid architecture of convolution neural networks (CNN) and Transformer
has been the most popular method for medical image segmentation. However, the
existing networks based on the hybrid architecture suffer from two problems.
First, although the CNN branch can capture image local features by using
convolution operation, the vanilla convolution is unable to achieve adaptive
extraction of image features. Second, although the Transformer branch can model
the global information of images, the conventional self-attention only focuses
on the spatial self-attention of images and ignores the channel and
cross-dimensional self-attention leading to low segmentation accuracy for
medical images with complex backgrounds. To solve these problems, we propose
vision Transformer embrace convolutional neural networks for medical image
segmentation (TEC-Net). Our network has two advantages. First, dynamic
deformable convolution (DDConv) is designed in the CNN branch, which not only
overcomes the difficulty of adaptive feature extraction using fixed-size
convolution kernels, but also solves the defect that different inputs share the
same convolution kernel parameters, effectively improving the feature
expression ability of CNN branch. Second, in the Transformer branch, a
(shifted)-window adaptive complementary attention module ((S)W-ACAM) and
compact convolutional projection are designed to enable the network to fully
learn the cross-dimensional long-range dependency of medical images with few
parameters and calculations. Experimental results show that the proposed
TEC-Net provides better medical image segmentation results than SOTA methods
including CNN and Transformer networks. In addition, our TEC-Net requires fewer
parameters and computational costs and does not rely on pre-training. The code
is publicly available at https://github.com/SR0920/TEC-Net.
\\ ( https://arxiv.org/abs/2306.04086 ,  4871kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04202 (*cross-listing*)
Date: Wed, 7 Jun 2023 07:15:18 GMT   (4071kb,D)

Title: Video Compression with Arbitrary Rescaling Network
Authors: Mengxi Guo, Shijie Zhao, Hao Jiang, Junlin Li and Li Zhang
Categories: cs.MM cs.CV eess.IV
Comments: Accepted as a one-page poster by 2023 Data Compression Conference
 (DCC). This is the full paper
\\
 Most video platforms provide video streaming services with different
qualities, and the quality of the services is usually adjusted by the
resolution of the videos. So high-resolution videos need to be downsampled for
compression. In order to solve the problem of video coding at different
resolutions, we propose a rate-guided arbitrary rescaling network (RARN) for
video resizing before encoding. To help the RARN be compatible with standard
codecs and generate compression-friendly results, an iteratively optimized
transformer-based virtual codec (TVC) is introduced to simulate the key
components of video encoding and perform bitrate estimation. By iteratively
training the TVC and the RARN, we achieved 5%-29% BD-Rate reduction anchored by
linear interpolation under different encoding configurations and resolutions,
exceeding the previous methods on most test videos. Furthermore, the
lightweight RARN structure can process FHD (1080p) content at real-time speed
(91 FPS) and obtain a considerable rate reduction.
\\ ( https://arxiv.org/abs/2306.04202 ,  4071kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04249 (*cross-listing*)
Date: Wed, 7 Jun 2023 08:40:25 GMT   (7676kb,D)

Title: DEMIST: A deep-learning-based task-specific denoising approach for
 myocardial perfusion SPECT
Authors: Md Ashequr Rahman, Zitong Yu, Craig K. Abbey, Barry A. Siegel, Abhinav
 K. Jha
Categories: physics.med-ph cs.CV eess.IV
\\
 There is an important need for methods to reduce radiation dose and imaging
time in myocardial perfusion imaging (MPI) SPECT. Deep learning (DL) methods
have demonstrated promise in predicting normal-count images from low-count
images for MPI SPECT, but the methods that have been objectively evaluated on
the clinical task of detecting perfusion defects have not shown improved
performance compared with low-count images. To address this need, we build upon
concepts from model-observer theory and our understanding of the human visual
system to propose a Detection task-specific DL-based approach for denoising MPI
SPECT images (DEMIST). The approach, while performing denoising, is designed to
preserve features that are known to impact observer performance on detection
tasks. We objectively evaluated the proposed method on the task of detecting
perfusion defects using a retrospective study with anonymized clinical data in
patients who underwent MPI studies (N = 338). Performance on the task of
detecting perfusion defects was quantified with an anthropomorphic channelized
Hotelling observer. Images denoised with DEMIST yielded significantly improved
detection performance compared to the corresponding low-dose images and images
denoised with a commonly used task-agnostic DL-based denoising method. Similar
results were observed with stratified analysis based on patient sex and defect
type. Additionally, the proposed method significantly improved performance
compared to the low-dose images in terms of the task-agnostic metrics of root
mean squared error and structural similarity index metric. A mathematical
analysis reveals that DEMIST preserves detection-task-specific features while
improving the noise properties, thus resulting in improved observer
performance. The results provide strong evidence for further clinical
evaluation of DEMIST to denoise low-count images in MPI SPECT.
\\ ( https://arxiv.org/abs/2306.04249 ,  7676kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04512 (*cross-listing*)
Date: Wed, 7 Jun 2023 15:25:27 GMT   (9970kb,D)

Title: Cross-attention learning enables real-time nonuniform rotational
 distortion correction in OCT
Authors: Haoran Zhang, Jianlong Yang, Jingqian Zhang, Shiqing Zhao, Aili Zhang
Categories: eess.IV cs.CV physics.med-ph
Comments: 4 pages, 6 figures
\\
 Nonuniform rotational distortion (NURD) correction is vital for endoscopic
optical coherence tomography (OCT) imaging and its functional extensions, such
as angiography and elastography. Current NURD correction methods require
time-consuming feature tracking or cross-correlation calculations and thus
sacrifice temporal resolution. Here we propose a cross-attention learning
method for the NURD correction in OCT. Our method is inspired by the recent
success of the self-attention mechanism in natural language processing and
computer vision. By leveraging its ability to model long-range dependencies, we
can directly obtain the correlation between OCT A-lines at any distance, thus
accelerating the NURD correction. We develop an end-to-end stacked
cross-attention network and design three types of optimization constraints. We
compare our method with two traditional feature-based methods and a CNN-based
method, on two publicly-available endoscopic OCT datasets and a private dataset
collected on our home-built endoscopic OCT system. Our method achieved a
$\sim3\times$ speedup to real time ($26\pm 3$ fps), and superior correction
performance.
\\ ( https://arxiv.org/abs/2306.04512 ,  9970kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04527 (*cross-listing*)
Date: Wed, 7 Jun 2023 15:36:26 GMT   (14071kb,D)

Title: ContriMix: Unsupervised disentanglement of content and attribute for
 domain generalization in microscopy image analysis
Authors: Tan H. Nguyen, Dinkar Juyal, Jin Li, Aaditya Prakash, Shima Nofallah,
 Chintan Shah, Sai Chowdary Gullapally, Michael Griffin, Anand Sampat, John
 Abel, Justin Lee, Amaro Taylor-Weiner
Categories: eess.IV cs.CV cs.LG
\\
 Domain generalization is critical for real-world applications of machine
learning models to microscopy images, including histopathology and fluorescence
imaging. Artifacts in histopathology arise through a complex combination of
factors relating to tissue collection and laboratory processing, as well as
factors intrinsic to patient samples. In fluorescence imaging, these artifacts
stem from variations across experimental batches. The complexity and subtlety
of these artifacts make the enumeration of data domains intractable. Therefore,
augmentation-based methods of domain generalization that require domain
identifiers and manual fine-tuning are inadequate in this setting. To overcome
this challenge, we introduce ContriMix, a domain generalization technique that
learns to generate synthetic images by disentangling and permuting the
biological content ("content") and technical variations ("attributes") in
microscopy images. ContriMix does not rely on domain identifiers or handcrafted
augmentations and makes no assumptions about the input characteristics of
images. We assess the performance of ContriMix on two pathology datasets
(Camelyon17-WILDS and a prostate cell classification dataset) and one
fluorescence microscopy dataset (RxRx1-WILDS). ContriMix outperforms current
state-of-the-art methods in all datasets, motivating its usage for microscopy
image analysis in real-world settings where domain information is hard to come
by.
\\ ( https://arxiv.org/abs/2306.04527 ,  14071kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04579 (*cross-listing*)
Date: Wed, 7 Jun 2023 16:28:53 GMT   (6376kb,D)

Title: A Dataset for Deep Learning-based Bone Structure Analyses in Total Hip
 Arthroplasty
Authors: Kaidong Zhang, Ziyang Gan, Dong Liu, Xifu Shang
Categories: eess.IV cs.CV
Comments: 16 pages, 17 figures
\\
 Total hip arthroplasty (THA) is a widely used surgical procedure in
orthopedics. For THA, it is of clinical significance to analyze the bone
structure from the CT images, especially to observe the structure of the
acetabulum and femoral head, before the surgical procedure. For such bone
structure analyses, deep learning technologies are promising but require
high-quality labeled data for the learning, while the data labeling is costly.
We address this issue and propose an efficient data annotation pipeline for
producing a deep learning-oriented dataset. Our pipeline consists of
non-learning-based bone extraction (BE) and acetabulum and femoral head
segmentation (AFS) and active-learning-based annotation refinement (AAR). For
BE we use the classic graph-cut algorithm. For AFS we propose an improved
algorithm, including femoral head boundary localization using first-order and
second-order gradient regularization, line-based non-maximum suppression, and
anatomy prior-based femoral head extraction. For AAR, we refine the
algorithm-produced pseudo labels with the help of trained deep models: we
measure the uncertainty based on the disagreement between the original pseudo
labels and the deep model predictions, and then find out the samples with the
largest uncertainty to ask for manual labeling. Using the proposed pipeline, we
construct a large-scale bone structure analyses dataset from more than 300
clinical and diverse CT scans. We perform careful manual labeling for the test
set of our data. We then benchmark multiple state-of-the art deep
learning-based methods of medical image segmentation using the training and
test sets of our data. The extensive experimental results validate the efficacy
of the proposed data annotation pipeline. The dataset, related codes and models
will be publicly available at https://github.com/hitachinsk/THA.
\\ ( https://arxiv.org/abs/2306.04579 ,  6376kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03917 (*cross-listing*)
Date: Tue, 6 Jun 2023 18:00:01 GMT   (223kb,D)

Title: Turning large language models into cognitive models
Authors: Marcel Binz, Eric Schulz
Categories: cs.CL cs.LG
\\
 Large language models are powerful systems that excel at many tasks, ranging
from translation to mathematical reasoning. Yet, at the same time, these models
often show unhuman-like characteristics. In the present paper, we address this
gap and ask whether large language models can be turned into cognitive models.
We find that -- after finetuning them on data from psychological experiments --
these models offer accurate representations of human behavior, even
outperforming traditional cognitive models in two decision-making domains. In
addition, we show that their representations contain the information necessary
to model behavior on the level of individual subjects. Finally, we demonstrate
that finetuning on multiple tasks enables large language models to predict
human behavior in a previously unseen task. Taken together, these results
suggest that large, pre-trained models can be adapted to become generalist
cognitive models, thereby opening up new research directions that could
transform cognitive psychology and the behavioral sciences as a whole.
\\ ( https://arxiv.org/abs/2306.03917 ,  223kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03941 (*cross-listing*)
Date: Thu, 1 Jun 2023 18:26:37 GMT   (3393kb,D)

Title: A scientometric analysis of the effect of COVID-19 on the spread of
 research outputs
Authors: Gianpaolo Zammarchi, Andrea Carta, Silvia Columbu, Luca Frigau, Monica
 Musio
Categories: cs.DL cs.LG
\\
 The spread of the Sars-COV-2 pandemic in 2020 had a huge impact on the life
course of all of us. This rapid spread has also caused an increase in the
research production in topics related to COVID-19 with regard to different
aspects. Italy has, unfortunately, been one of the first countries to be
massively involved in the outbreak of the disease. In this paper we present an
extensive scientometric analysis of the research production both at global
(entire literature produced in the first 2 years after the beginning of the
pandemic) and local level (COVID-19 literature produced by authors with an
Italian affiliation). Our results showed that US and China are the most active
countries in terms of number of publications and that the number of
collaborations between institutions varies according to geographical distance.
Moreover, we identified the medical-biological as the fields with the greatest
growth in terms of literature production. Furthermore, we also better explored
the relationship between the number of citations and variables obtained from
the data set (e.g. number of authors per article). Using multiple
correspondence analysis and quantile regression we shed light on the role of
journal topics and impact factor, the type of article, the field of study and
how these elements affect citations.
\\ ( https://arxiv.org/abs/2306.03941 ,  3393kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03968 (*cross-listing*)
Date: Tue, 6 Jun 2023 19:02:57 GMT   (5652kb,D)

Title: Stochastic Marginal Likelihood Gradients using Neural Tangent Kernels
Authors: Alexander Immer, Tycho F. A. van der Ouderaa, Mark van der Wilk,
 Gunnar R\"atsch, Bernhard Sch\"olkopf
Categories: stat.ML cs.LG
Comments: ICML 2023
\\
 Selecting hyperparameters in deep learning greatly impacts its effectiveness
but requires manual effort and expertise. Recent works show that Bayesian model
selection with Laplace approximations can allow to optimize such
hyperparameters just like standard neural network parameters using gradients
and on the training data. However, estimating a single hyperparameter gradient
requires a pass through the entire dataset, limiting the scalability of such
algorithms. In this work, we overcome this issue by introducing lower bounds to
the linearized Laplace approximation of the marginal likelihood. In contrast to
previous estimators, these bounds are amenable to stochastic-gradient-based
optimization and allow to trade off estimation accuracy against computational
complexity. We derive them using the function-space form of the linearized
Laplace, which can be estimated using the neural tangent kernel.
Experimentally, we show that the estimators can significantly accelerate
gradient-based hyperparameter optimization.
\\ ( https://arxiv.org/abs/2306.03968 ,  5652kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03984 (*cross-listing*)
Date: Tue, 6 Jun 2023 19:43:29 GMT   (7560kb,D)

Title: Toward More Accurate and Generalizable Evaluation Metrics for
 Task-Oriented Dialogs
Authors: Abishek Komma, Nagesh Panyam Chandrasekarasastry, Timothy Leffel Anuj
 Goyal, Angeliki Metallinou, Spyros Matsoukas, Aram Galstyan
Categories: cs.CL cs.LG
\\
 Measurement of interaction quality is a critical task for the improvement of
spoken dialog systems. Existing approaches to dialog quality estimation either
focus on evaluating the quality of individual turns, or collect dialog-level
quality measurements from end users immediately following an interaction. In
contrast to these approaches, we introduce a new dialog-level annotation
workflow called Dialog Quality Annotation (DQA). DQA expert annotators evaluate
the quality of dialogs as a whole, and also label dialogs for attributes such
as goal completion and user sentiment. In this contribution, we show that: (i)
while dialog quality cannot be completely decomposed into dialog-level
attributes, there is a strong relationship between some objective dialog
attributes and judgments of dialog quality; (ii) for the task of dialog-level
quality estimation, a supervised model trained on dialog-level annotations
outperforms methods based purely on aggregating turn-level features; and (iii)
the proposed evaluation model shows better domain generalization ability
compared to the baselines. On the basis of these results, we argue that having
high-quality human-annotated data is an important component of evaluating
interaction quality for large industrial-scale voice assistant platforms.
\\ ( https://arxiv.org/abs/2306.03984 ,  7560kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04008 (*cross-listing*)
Date: Tue, 6 Jun 2023 20:43:07 GMT   (1539kb)

Title: Green Steganalyzer: A Green Learning Approach to Image Steganalysis
Authors: Yao Zhu, Xinyu Wang, Hong-Shuo Chen, Ronald Salloum, C.-C. Jay Kuo
Categories: eess.IV cs.CR cs.LG
\\
 A novel learning solution to image steganalysis based on the green learning
paradigm, called Green Steganalyzer (GS), is proposed in this work. GS consists
of three modules: 1) pixel-based anomaly prediction, 2) embedding location
detection, and 3) decision fusion for image-level detection. In the first
module, GS decomposes an image into patches, adopts Saab transforms for feature
extraction, and conducts self-supervised learning to predict an anomaly score
of their center pixel. In the second module, GS analyzes the anomaly scores of
a pixel and its neighborhood to find pixels of higher embedding probabilities.
In the third module, GS focuses on pixels of higher embedding probabilities and
fuses their anomaly scores to make final image-level classification. Compared
with state-of-the-art deep-learning models, GS achieves comparable detection
performance against S-UNIWARD, WOW and HILL steganography schemes with
significantly lower computational complexity and a smaller model size, making
it attractive for mobile/edge applications. Furthermore, GS is mathematically
transparent because of its modular design.
\\ ( https://arxiv.org/abs/2306.04008 ,  1539kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04050 (*cross-listing*)
Date: Tue, 6 Jun 2023 22:42:00 GMT   (22kb)

Title: LLMZip: Lossless Text Compression using Large Language Models
Authors: Chandra Shekhara Kaushik Valmeekam, Krishna Narayanan, Dileep
 Kalathil, Jean-Francois Chamberland, Srinivas Shakkottai
Categories: cs.IT cs.LG math.IT
Comments: 7 pages, 4 figures, 4 tables, preprint
\\
 We provide new estimates of an asymptotic upper bound on the entropy of
English using the large language model LLaMA-7B as a predictor for the next
token given a window of past tokens. This estimate is significantly smaller
than currently available estimates in \cite{cover1978convergent},
\cite{lutati2023focus}. A natural byproduct is an algorithm for lossless
compression of English text which combines the prediction from the large
language model with a lossless compression scheme. Preliminary results from
limited experiments suggest that our scheme outperforms state-of-the-art text
compression schemes such as BSC, ZPAQ, and paq8h.
\\ ( https://arxiv.org/abs/2306.04050 ,  22kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04054 (*cross-listing*)
Date: Tue, 6 Jun 2023 23:04:22 GMT   (691kb,D)

Title: RescueSpeech: A German Corpus for Speech Recognition in Search and
 Rescue Domain
Authors: Sangeet Sagar, Mirco Ravanelli, Bernd Kiefer, Ivana Kruijff Korbayova,
 Josef van Genabith
Categories: eess.AS cs.LG cs.SD eess.SP
\\
 Despite recent advancements in speech recognition, there are still
difficulties in accurately transcribing conversational and emotional speech in
noisy and reverberant acoustic environments. This poses a particular challenge
in the search and rescue (SAR) domain, where transcribing conversations among
rescue team members is crucial to support real-time decision-making. The
scarcity of speech data and associated background noise in SAR scenarios make
it difficult to deploy robust speech recognition systems.
 To address this issue, we have created and made publicly available a German
speech dataset called RescueSpeech. This dataset includes real speech
recordings from simulated rescue exercises. Additionally, we have released
competitive training recipes and pre-trained models. Our study indicates that
the current level of performance achieved by state-of-the-art methods is still
far from being acceptable.
\\ ( https://arxiv.org/abs/2306.04054 ,  691kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04116 (*cross-listing*)
Date: Wed, 7 Jun 2023 03:03:41 GMT   (534kb,D)

Title: Unbalanced Optimal Transport for Unbalanced Word Alignment
Authors: Yuki Arase, Han Bao, Sho Yokoi
Categories: cs.CL cs.LG
Comments: Accepted for the Annual Meeting of the Association for Computational
 Linguistics (ACL 2023)
\\
 Monolingual word alignment is crucial to model semantic interactions between
sentences. In particular, null alignment, a phenomenon in which words have no
corresponding counterparts, is pervasive and critical in handling semantically
divergent sentences. Identification of null alignment is useful on its own to
reason about the semantic similarity of sentences by indicating there exists
information inequality. To achieve unbalanced word alignment that values both
alignment and null alignment, this study shows that the family of optimal
transport (OT), i.e., balanced, partial, and unbalanced OT, are natural and
powerful approaches even without tailor-made techniques. Our extensive
experiments covering unsupervised and supervised settings indicate that our
generic OT-based alignment methods are competitive against the
state-of-the-arts specially designed for word alignment, remarkably on
challenging datasets with high null alignment frequencies.
\\ ( https://arxiv.org/abs/2306.04116 ,  534kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04133 (*cross-listing*)
Date: Wed, 7 Jun 2023 04:04:36 GMT   (46kb)

Title: Answering Compositional Queries with Set-Theoretic Embeddings
Authors: Shib Dasgupta, Andrew McCallum, Steffen Rendle, Li Zhang
Categories: cs.IR cs.LG
\\
 The need to compactly and robustly represent item-attribute relations arises
in many important tasks, such as faceted browsing and recommendation systems. A
popular machine learning approach for this task denotes that an item has an
attribute by a high dot-product between vectors for the item and attribute -- a
representation that is not only dense, but also tends to correct noisy and
incomplete data. While this method works well for queries retrieving items by a
single attribute (such as \emph{movies that are comedies}), we find that vector
embeddings do not so accurately support compositional queries (such as movies
that are comedies and British but not romances). To address these set-theoretic
compositions, this paper proposes to replace vectors with box embeddings, a
region-based representation that can be thought of as learnable Venn diagrams.
We introduce a new benchmark dataset for compositional queries, and present
experiments and analysis providing insights into the behavior of both. We find
that, while vector and box embeddings are equally suited to single attribute
queries, for compositional queries box embeddings provide substantial
advantages over vectors, particularly at the moderate and larger retrieval set
sizes that are most useful for users' search and browsing.
\\ ( https://arxiv.org/abs/2306.04133 ,  46kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04148 (*cross-listing*)
Date: Wed, 7 Jun 2023 04:50:09 GMT   (72kb,D)

Title: SANGEET: A XML based Open Dataset for Research in Hindustani Sangeet
Authors: Chandan Misra and Swarup Chattopadhyay
Categories: cs.SD cs.IR cs.LG
\\
 It is very important to access a rich music dataset that is useful in a wide
variety of applications. Currently, available datasets are mostly focused on
storing vocal or instrumental recording data and ignoring the requirement of
its visual representation and retrieval. This paper attempts to build an
XML-based public dataset, called SANGEET, that stores comprehensive information
of Hindustani Sangeet (North Indian Classical Music) compositions written by
famous musicologist Pt. Vishnu Narayan Bhatkhande. SANGEET preserves all the
required information of any given composition including metadata, structural,
notational, rhythmic, and melodic information in a standardized way for easy
and efficient storage and extraction of musical information. The dataset is
intended to provide the ground truth information for music information research
tasks, thereby supporting several data-driven analysis from a machine learning
perspective. We present the usefulness of the dataset by demonstrating its
application on music information retrieval using XQuery, visualization through
Omenad rendering system. Finally, we propose approaches to transform the
dataset for performing statistical and machine learning tasks for a better
understanding of Hindustani Sangeet. The dataset can be found at
https://github.com/cmisra/Sangeet.
\\ ( https://arxiv.org/abs/2306.04148 ,  72kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04174 (*cross-listing*)
Date: Wed, 7 Jun 2023 05:55:45 GMT   (1784kb,D)

Title: End-to-End Learning for Stochastic Optimization: A Bayesian Perspective
Authors: Yves Rychener, Daniel Kuhn Tobias Sutter
Categories: math.OC cs.LG stat.ML
Comments: Accepted at ICML 2023
\\
 We develop a principled approach to end-to-end learning in stochastic
optimization. First, we show that the standard end-to-end learning algorithm
admits a Bayesian interpretation and trains a posterior Bayes action map.
Building on the insights of this analysis, we then propose new end-to-end
learning algorithms for training decision maps that output solutions of
empirical risk minimization and distributionally robust optimization problems,
two dominant modeling paradigms in optimization under uncertainty. Numerical
results for a synthetic newsvendor problem illustrate the key differences
between alternative training schemes. We also investigate an economic dispatch
problem based on real data to showcase the impact of the neural network
architecture of the decision maps on their test performance.
\\ ( https://arxiv.org/abs/2306.04174 ,  1784kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04181 (*cross-listing*)
Date: Wed, 7 Jun 2023 06:29:58 GMT   (5238kb,D)

Title: Benchmarking Foundation Models with Language-Model-as-an-Examiner
Authors: Yushi Bai, Jiahao Ying, Yixin Cao, Xin Lv, Yuze He, Xiaozhi Wang,
 Jifan Yu, Kaisheng Zeng, Yijia Xiao, Haozhe Lyu, Jiayin Zhang, Juanzi Li, Lei
 Hou
Categories: cs.CL cs.LG
Comments: 23 pages, 8 figures
\\
 Numerous benchmarks have been established to assess the performance of
foundation models on open-ended question answering, which serves as a
comprehensive test of a model's ability to understand and generate language in
a manner similar to humans. Most of these works focus on proposing new
datasets, however, we see two main issues within previous benchmarking
pipelines, namely testing leakage and evaluation automation. In this paper, we
propose a novel benchmarking framework, Language-Model-as-an-Examiner, where
the LM serves as a knowledgeable examiner that formulates questions based on
its knowledge and evaluates responses in a reference-free manner. Our framework
allows for effortless extensibility as various LMs can be adopted as the
examiner, and the questions can be constantly updated given more diverse
trigger topics. For a more comprehensive and equitable evaluation, we devise
three strategies: (1) We instruct the LM examiner to generate questions across
a multitude of domains to probe for a broad acquisition, and raise follow-up
questions to engage in a more in-depth assessment. (2) Upon evaluation, the
examiner combines both scoring and ranking measurements, providing a reliable
result as it aligns closely with human annotations. (3) We additionally propose
a decentralized Peer-examination method to address the biases in a single
examiner. Our data and benchmarking results are available at:
https://lmexam.com.
\\ ( https://arxiv.org/abs/2306.04181 ,  5238kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04186 (*cross-listing*)
Date: Wed, 7 Jun 2023 06:42:07 GMT   (4745kb,D)

Title: Self-supervised Audio Teacher-Student Transformer for Both Clip-level
 and Frame-level Tasks
Authors: Xian Li, Nian Shao, and Xiaofei Li
Categories: eess.AS cs.LG
Comments: Submitted to IEEE TASLP. arXiv admin note: text overlap with
 arXiv:2204.12076
\\
 In recent years, self-supervised learning (SSL) has emerged as a popular
approach for learning audio representations. The ultimate goal of audio
self-supervised pre-training is to transfer knowledge to downstream audio
tasks, generally including clip-level and frame-level tasks. Clip-level tasks
classify the scene or sound of an entire audio clip, e.g. audio tagging,
instrument recognition, etc. While frame-level tasks detect event-level
timestamps from an audio clip, e.g. sound event detection, speaker diarization,
etc. Prior studies primarily evaluate on clip-level downstream tasks.
Frame-level tasks are important for fine-grained acoustic scene/event
understanding, and are generally more challenging than clip-level tasks. In
order to tackle both clip-level and frame-level tasks, this paper proposes two
self-supervised audio representation learning methods: ATST-Clip and
ATST-Frame, responsible for learning clip-level and frame-level
representations, respectively. ATST stands for Audio Teacher-Student
Transformer, which means both methods use a transformer encoder and a
teacher-student training scheme.Experimental results show that our ATST-Frame
model obtains state-of-the-art (SOTA) performance on most of the clip-level and
frame-level downstream tasks. Especially, it outperforms other models by a
large margin on the frame-level sound event detection task. In addition, the
performance can be further improved by combining the two models through
knowledge distillation.
\\ ( https://arxiv.org/abs/2306.04186 ,  4745kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04190 (*cross-listing*)
Date: Wed, 7 Jun 2023 06:58:38 GMT   (342kb)

Title: An ASR-Based Tutor for Learning to Read: How to Optimize Feedback to
 First Graders
Authors: Yu Bai, Cristian Tejedor-Garcia, Ferdy Hubers, Catia Cucchiarini,
 Helmer Strik
Categories: cs.CL cs.LG cs.SD eess.AS
Comments: Published (double-blind peer-reviewed) on SPECOM 2021
Journal-ref: In: Karpov A., Potapova R. (eds) Speech and Computer. SPECOM 2021.
 Lecture Notes in Computer Science, vol 12997. Springer, Cham
DOI: 10.1007/978-3-030-87802-3_6
\\
 The interest in employing automatic speech recognition (ASR) in applications
for reading practice has been growing in recent years. In a previous study, we
presented an ASR-based Dutch reading tutor application that was developed to
provide instantaneous feedback to first-graders learning to read. We saw that
ASR has potential at this stage of the reading process, as the results
suggested that pupils made progress in reading accuracy and fluency by using
the software. In the current study, we used children's speech from an existing
corpus (JASMIN) to develop two new ASR systems, and compared the results to
those of the previous study. We analyze correct/incorrect classification of the
ASR systems using human transcripts at word level, by means of evaluation
measures such as Cohen's Kappa, Matthews Correlation Coefficient (MCC),
precision, recall and F-measures. We observe improvements for the newly
developed ASR systems regarding the agreement with human-based judgment and
correct rejection (CR). The accuracy of the ASR systems varies for different
reading tasks and word types. Our results suggest that, in the current
configuration, it is difficult to classify isolated words. We discuss these
results, possible ways to improve our systems and avenues for future research.
\\ ( https://arxiv.org/abs/2306.04190 ,  342kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04203 (*cross-listing*)
Date: Wed, 7 Jun 2023 07:15:20 GMT   (290kb,D)

Title: Leveraging Knowledge Graph Embeddings to Enhance Contextual
 Representations for Relation Extraction
Authors: Fr\'ejus A. A. Laleye, Lo\"ic Rakotoson, Sylvain Massip
Categories: cs.CL cs.LG
Comments: 15 pages, 1 figures, The 17th International Conference on Document
 Analysis and Recognition
\\
 Relation extraction task is a crucial and challenging aspect of Natural
Language Processing. Several methods have surfaced as of late, exhibiting
notable performance in addressing the task; however, most of these approaches
rely on vast amounts of data from large-scale knowledge graphs or language
models pretrained on voluminous corpora. In this paper, we hone in on the
effective utilization of solely the knowledge supplied by a corpus to create a
high-performing model. Our objective is to showcase that by leveraging the
hierarchical structure and relational distribution of entities within a corpus
without introducing external knowledge, a relation extraction model can achieve
significantly enhanced performance. We therefore proposed a relation extraction
approach based on the incorporation of pretrained knowledge graph embeddings at
the corpus scale into the sentence-level contextual representation. We
conducted a series of experiments which revealed promising and very interesting
results for our proposed approach.The obtained results demonstrated an
outperformance of our method compared to context-based relation extraction
models.
\\ ( https://arxiv.org/abs/2306.04203 ,  290kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04223 (*cross-listing*)
Date: Wed, 7 Jun 2023 07:58:58 GMT   (1260kb,D)

Title: Causally Learning an Optimal Rework Policy
Authors: Oliver Schacht, Sven Klaassen, Philipp Schwarz, Martin Spindler,
 Daniel Gr\"unbaum, Sebastian Imhof
Categories: stat.ML cs.LG
Comments: 22 pages, 15 figures
\\
 In manufacturing, rework refers to an optional step of a production process
which aims to eliminate errors or remedy products that do not meet the desired
quality standards. Reworking a production lot involves repeating a previous
production stage with adjustments to ensure that the final product meets the
required specifications. While offering the chance to improve the yield and
thus increase the revenue of a production lot, a rework step also incurs
additional costs. Additionally, the rework of parts that already meet the
target specifications may damage them and decrease the yield. In this paper, we
apply double/debiased machine learning (DML) to estimate the conditional
treatment effect of a rework step during the color conversion process in
opto-electronic semiconductor manufacturing on the final product yield. We
utilize the implementation DoubleML to develop policies for the rework of
components and estimate their value empirically. From our causal machine
learning analysis we derive implications for the coating of monochromatic LEDs
with conversion layers.
\\ ( https://arxiv.org/abs/2306.04223 ,  1260kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04255 (*cross-listing*)
Date: Wed, 7 Jun 2023 08:51:06 GMT   (2384kb,D)

Title: Accounting For Informative Sampling When Learning to Forecast Treatment
 Outcomes Over Time
Authors: Toon Vanderschueren, Alicia Curth, Wouter Verbeke and Mihaela van der
 Schaar
Categories: stat.ML cs.LG
Comments: To appear in the Proceedings of the 40th International Conference on
 Machine Learning, Honolulu, Hawaii, USA. PMLR 202, 2023
\\
 Machine learning (ML) holds great potential for accurately forecasting
treatment outcomes over time, which could ultimately enable the adoption of
more individualized treatment strategies in many practical applications.
However, a significant challenge that has been largely overlooked by the ML
literature on this topic is the presence of informative sampling in
observational data. When instances are observed irregularly over time, sampling
times are typically not random, but rather informative -- depending on the
instance's characteristics, past outcomes, and administered treatments. In this
work, we formalize informative sampling as a covariate shift problem and show
that it can prohibit accurate estimation of treatment outcomes if not properly
accounted for. To overcome this challenge, we present a general framework for
learning treatment outcomes in the presence of informative sampling using
inverse intensity-weighting, and propose a novel method, TESAR-CDE, that
instantiates this framework using Neural CDEs. Using a simulation environment
based on a clinical use case, we demonstrate the effectiveness of our approach
in learning under informative sampling.
\\ ( https://arxiv.org/abs/2306.04255 ,  2384kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04293 (*cross-listing*)
Date: Wed, 7 Jun 2023 09:46:38 GMT   (7227kb,D)

Title: Phrase Retrieval for Open-Domain Conversational Question Answering with
 Conversational Dependency Modeling via Contrastive Learning
Authors: Soyeong Jeong, Jinheon Baek, Sung Ju Hwang, Jong C. Park
Categories: cs.CL cs.IR cs.LG
Comments: Findings of ACL 2023
\\
 Open-Domain Conversational Question Answering (ODConvQA) aims at answering
questions through a multi-turn conversation based on a retriever-reader
pipeline, which retrieves passages and then predicts answers with them.
However, such a pipeline approach not only makes the reader vulnerable to the
errors propagated from the retriever, but also demands additional effort to
develop both the retriever and the reader, which further makes it slower since
they are not runnable in parallel. In this work, we propose a method to
directly predict answers with a phrase retrieval scheme for a sequence of
words, reducing the conventional two distinct subtasks into a single one. Also,
for the first time, we study its capability for ODConvQA tasks. However, simply
adopting it is largely problematic, due to the dependencies between previous
and current turns in a conversation. To address this problem, we further
introduce a novel contrastive learning strategy, making sure to reflect
previous turns when retrieving the phrase for the current context, by
maximizing representational similarities of consecutive turns in a conversation
while minimizing irrelevant conversational contexts. We validate our model on
two ODConvQA datasets, whose experimental results show that it substantially
outperforms the relevant baselines with the retriever-reader. Code is available
at: https://github.com/starsuzi/PRO-ConvQA.
\\ ( https://arxiv.org/abs/2306.04293 ,  7227kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04338 (*cross-listing*)
Date: Wed, 7 Jun 2023 11:08:12 GMT   (31kb,D)

Title: Changing Data Sources in the Age of Machine Learning for Official
 Statistics
Authors: Cedric De Boom and Michael Reusens
Categories: stat.ML cs.LG
Comments: Presented at UNECE Machine Learning for Official Statistics Workshop
 2023
Journal-ref: UNECE Machine Learning for Official Statistics Workshop 2023
\\
 Data science has become increasingly essential for the production of official
statistics, as it enables the automated collection, processing, and analysis of
large amounts of data. With such data science practices in place, it enables
more timely, more insightful and more flexible reporting. However, the quality
and integrity of data-science-driven statistics rely on the accuracy and
reliability of the data sources and the machine learning techniques that
support them. In particular, changes in data sources are inevitable to occur
and pose significant risks that are crucial to address in the context of
machine learning for official statistics.
 This paper gives an overview of the main risks, liabilities, and
uncertainties associated with changing data sources in the context of machine
learning for official statistics. We provide a checklist of the most prevalent
origins and causes of changing data sources; not only on a technical level but
also regarding ownership, ethics, regulation, and public perception. Next, we
highlight the repercussions of changing data sources on statistical reporting.
These include technical effects such as concept drift, bias, availability,
validity, accuracy and completeness, but also the neutrality and potential
discontinuation of the statistical offering. We offer a few important
precautionary measures, such as enhancing robustness in both data sourcing and
statistical techniques, and thorough monitoring. In doing so, machine
learning-based official statistics can maintain integrity, reliability,
consistency, and relevance in policy-making, decision-making, and public
discourse.
\\ ( https://arxiv.org/abs/2306.04338 ,  31kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04365 (*cross-listing*)
Date: Wed, 7 Jun 2023 11:55:20 GMT   (3110kb)

Title: Edge conductivity in PtSe$_2$ nanostructures
Authors: Roman Kempt, Agnieszka Kuc, Thomas Brumme, Thomas Heine
Categories: cond-mat.mtrl-sci cs.LG
\\
 PtSe$_2$ is a promising 2D material for nanoelectromechanical sensing and
photodetection in the infrared regime. One of its most compelling features is
the facile synthesis at temperatures below 500 {\deg}C, which is compatible
with current back-end-of-line semiconductor processing. However, this process
generates polycrystalline thin films with nanoflake-like domains of 5 to 100 nm
size. To investigate the lateral quantum confinement effect in this size
regime, we train a deep neural network to obtain an interatomic potential at
DFT accuracy and use that to model ribbons, surfaces, nanoflakes, and
nanoplatelets of PtSe$_2$ with lateral widths between 5 to 15 nm. We determine
which edge terminations are the most stable and find evidence that the
electrical conductivity is localized on the edges for lateral sizes below 10
nm. This suggests that the transport channels in thin films of PtSe$_2$ might
be dominated by networks of edges, instead of transport through the layers
themselves.
\\ ( https://arxiv.org/abs/2306.04365 ,  3110kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04374 (*cross-listing*)
Date: Wed, 7 Jun 2023 12:14:16 GMT   (721kb,D)

Title: Label Aware Speech Representation Learning For Language Identification
Authors: Shikhar Vashishth, Shikhar Bharadwaj, Sriram Ganapathy, Ankur Bapna,
 Min Ma, Wei Han, Vera Axelrod, Partha Talukdar
Categories: cs.CL cs.LG cs.SD eess.AS
Comments: Accepted at Interspeech 2023
\\
 Speech representation learning approaches for non-semantic tasks such as
language recognition have either explored supervised embedding extraction
methods using a classifier model or self-supervised representation learning
approaches using raw data. In this paper, we propose a novel framework of
combining self-supervised representation learning with the language label
information for the pre-training task. This framework, termed as Label Aware
Speech Representation (LASR) learning, uses a triplet based objective function
to incorporate language labels along with the self-supervised loss function.
The speech representations are further fine-tuned for the downstream task. The
language recognition experiments are performed on two public datasets - FLEURS
and Dhwani. In these experiments, we illustrate that the proposed LASR
framework improves over the state-of-the-art systems on language
identification. We also report an analysis of the robustness of LASR approach
to noisy/missing labels as well as its application to multi-lingual speech
recognition tasks.
\\ ( https://arxiv.org/abs/2306.04374 ,  721kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04375 (*cross-listing*)
Date: Wed, 7 Jun 2023 12:17:17 GMT   (38kb)

Title: Learning via Wasserstein-Based High Probability Generalisation Bounds
Authors: Paul Viallard, Maxime Haddouche, Umut Simsekli, Benjamin Guedj
Categories: stat.ML cs.LG
\\
 Minimising upper bounds on the population risk or the generalisation gap has
been widely used in structural risk minimisation (SRM) - this is in particular
at the core of PAC-Bayesian learning. Despite its successes and unfailing surge
of interest in recent years, a limitation of the PAC-Bayesian framework is that
most bounds involve a Kullback-Leibler (KL) divergence term (or its
variations), which might exhibit erratic behavior and fail to capture the
underlying geometric structure of the learning problem - hence restricting its
use in practical applications. As a remedy, recent studies have attempted to
replace the KL divergence in the PAC-Bayesian bounds with the Wasserstein
distance. Even though these bounds alleviated the aforementioned issues to a
certain extent, they either hold in expectation, are for bounded losses, or are
nontrivial to minimize in an SRM framework. In this work, we contribute to this
line of research and prove novel Wasserstein distance-based PAC-Bayesian
generalisation bounds for both batch learning with independent and identically
distributed (i.i.d.) data, and online learning with potentially non-i.i.d.
data. Contrary to previous art, our bounds are stronger in the sense that (i)
they hold with high probability, (ii) they apply to unbounded (potentially
heavy-tailed) losses, and (iii) they lead to optimizable training objectives
that can be used in SRM. As a result we derive novel Wasserstein-based
PAC-Bayesian learning algorithms and we illustrate their empirical advantage on
a variety of experiments.
\\ ( https://arxiv.org/abs/2306.04375 ,  38kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04377 (*cross-listing*)
Date: Wed, 7 Jun 2023 12:18:36 GMT   (906kb,D)

Title: Get More for Less in Decentralized Learning Systems
Authors: Akash Dhasade, Anne-Marie Kermarrec, Rafael Pires, Rishi Sharma, Milos
 Vujasinovic, Jeffrey Wigger
Categories: cs.DC cs.LG
Journal-ref: 2023 IEEE 43rd International Conference on Distributed Computing
 Systems (ICDCS 2023)
\\
 Decentralized learning (DL) systems have been gaining popularity because they
avoid raw data sharing by communicating only model parameters, hence preserving
data confidentiality. However, the large size of deep neural networks poses a
significant challenge for decentralized training, since each node needs to
exchange gigabytes of data, overloading the network. In this paper, we address
this challenge with JWINS, a communication-efficient and fully decentralized
learning system that shares only a subset of parameters through sparsification.
JWINS uses wavelet transform to limit the information loss due to
sparsification and a randomized communication cut-off that reduces
communication usage without damaging the performance of trained models. We
demonstrate empirically with 96 DL nodes on non-IID datasets that JWINS can
achieve similar accuracies to full-sharing DL while sending up to 64% fewer
bytes. Additionally, on low communication budgets, JWINS outperforms the
state-of-the-art communication-efficient DL algorithm CHOCO-SGD by up to 4x in
terms of network savings and time.
\\ ( https://arxiv.org/abs/2306.04377 ,  906kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04504 (*cross-listing*)
Date: Wed, 7 Jun 2023 15:11:26 GMT   (6929kb,D)

Title: Evaluation of ChatGPT on Biomedical Tasks: A Zero-Shot Comparison with
 Fine-Tuned Generative Transformers
Authors: Israt Jahan, Md Tahmid Rahman Laskar, Chun Peng, Jimmy Huang
Categories: cs.CL cs.LG
Comments: Accepted by BioNLP@ACL 2023
\\
 ChatGPT is a large language model developed by OpenAI. Despite its impressive
performance across various tasks, no prior work has investigated its capability
in the biomedical domain yet. To this end, this paper aims to evaluate the
performance of ChatGPT on various benchmark biomedical tasks, such as relation
extraction, document classification, question answering, and summarization. To
the best of our knowledge, this is the first work that conducts an extensive
evaluation of ChatGPT in the biomedical domain. Interestingly, we find based on
our evaluation that in biomedical datasets that have smaller training sets,
zero-shot ChatGPT even outperforms the state-of-the-art fine-tuned generative
transformer models, such as BioGPT and BioBART. This suggests that ChatGPT's
pre-training on large text corpora makes it quite specialized even in the
biomedical domain. Our findings demonstrate that ChatGPT has the potential to
be a valuable tool for various tasks in the biomedical domain that lack large
annotated data.
\\ ( https://arxiv.org/abs/2306.04504 ,  6929kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04518 (*cross-listing*)
Date: Wed, 7 Jun 2023 15:29:12 GMT   (13599kb,D)

Title: Optimal sensor placement for reconstructing wind pressure field around
 buildings using compressed sensing
Authors: Xihaier Luo and Ahsan Kareem and Shinjae Yoo
Categories: physics.flu-dyn cs.LG
Comments: 31 pages, 19 figures
Journal-ref: Journal of Building Engineering, p.106855 (2023)
DOI: 10.1016/j.jobe.2023.106855
\\
 Deciding how to optimally deploy sensors in a large, complex, and spatially
extended structure is critical to ensure that the surface pressure field is
accurately captured for subsequent analysis and design. In some cases,
reconstruction of missing data is required in downstream tasks such as the
development of digital twins. This paper presents a data-driven sparse sensor
selection algorithm, aiming to provide the most information contents for
reconstructing aerodynamic characteristics of wind pressures over tall building
structures parsimoniously. The algorithm first fits a set of basis functions to
the training data, then applies a computationally efficient QR algorithm that
ranks existing pressure sensors in order of importance based on the state
reconstruction to this tailored basis. The findings of this study show that the
proposed algorithm successfully reconstructs the aerodynamic characteristics of
tall buildings from sparse measurement locations, generating stable and optimal
solutions across a range of conditions. As a result, this study serves as a
promising first step toward leveraging the success of data-driven and machine
learning algorithms to supplement traditional genetic algorithms currently used
in wind engineering.
\\ ( https://arxiv.org/abs/2306.04518 ,  13599kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04520 (*cross-listing*)
Date: Wed, 7 Jun 2023 15:30:03 GMT   (4437kb,D)

Title: Estimating Koopman operators with sketching to provably learn large
 scale dynamical systems
Authors: Giacomo Meanti, Antoine Chatalic, Vladimir R. Kostic, Pietro Novelli,
 Massimiliano Pontil, Lorenzo Rosasco
Categories: stat.ML cs.LG
Comments: 9 pages, 4 figures
\\
 The theory of Koopman operators allows to deploy non-parametric machine
learning algorithms to predict and analyze complex dynamical systems.
Estimators such as principal component regression (PCR) or reduced rank
regression (RRR) in kernel spaces can be shown to provably learn Koopman
operators from finite empirical observations of the system's time evolution.
Scaling these approaches to very long trajectories is a challenge and requires
introducing suitable approximations to make computations feasible. In this
paper, we boost the efficiency of different kernel-based Koopman operator
estimators using random projections (sketching). We derive, implement and test
the new "sketched" estimators with extensive experiments on synthetic and
large-scale molecular dynamics datasets. Further, we establish non asymptotic
error bounds giving a sharp characterization of the trade-offs between
statistical learning rates and computational efficiency. Our empirical and
theoretical analysis shows that the proposed estimators provide a sound and
efficient way to learn large scale dynamical systems. In particular our
experiments indicate that the proposed estimators retain the same accuracy of
PCR or RRR, while being much faster.
\\ ( https://arxiv.org/abs/2306.04520 ,  4437kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04551 (*cross-listing*)
Date: Wed, 7 Jun 2023 15:55:34 GMT   (207kb,D)

Title: Multi-Task Training with In-Domain Language Models for Diagnostic
 Reasoning
Authors: Brihat Sharma, Yanjun Gao, Timothy Miller, Matthew M. Churpek, Majid
 Afshar and Dmitriy Dligach
Categories: cs.CL cs.LG
Comments: Accepted to 2023 ClinicalNLP Workshop
\\
 Generative artificial intelligence (AI) is a promising direction for
augmenting clinical diagnostic decision support and reducing diagnostic errors,
a leading contributor to medical errors. To further the development of clinical
AI systems, the Diagnostic Reasoning Benchmark (DR.BENCH) was introduced as a
comprehensive generative AI framework, comprised of six tasks representing key
components in clinical reasoning. We present a comparative analysis of
in-domain versus out-of-domain language models as well as multi-task versus
single task training with a focus on the problem summarization task in DR.BENCH
(Gao et al., 2023). We demonstrate that a multi-task, clinically trained
language model outperforms its general domain counterpart by a large margin,
establishing a new state-of-the-art performance, with a ROUGE-L score of 28.55.
This research underscores the value of domain-specific training for optimizing
clinical diagnostic reasoning tasks.
\\ ( https://arxiv.org/abs/2306.04551 ,  207kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04597 (*cross-listing*)
Date: Wed, 7 Jun 2023 16:50:03 GMT   (7072kb,D)

Title: Language Models Get a Gender Makeover: Mitigating Gender Bias with
 Few-Shot Data Interventions
Authors: Himanshu Thakur, Atishay Jain, Praneetha Vaddamanu, Paul Pu Liang and
 Louis-Philippe Morency
Categories: cs.CL cs.LG
Comments: Accepted to ACL 2023 Main Conference
\\
 Societal biases present in pre-trained large language models are a critical
issue as these models have been shown to propagate biases in countless
downstream applications, rendering them unfair towards specific groups of
people. Since large-scale retraining of these models from scratch is both time
and compute-expensive, a variety of approaches have been previously proposed
that de-bias a pre-trained model. While the majority of current
state-of-the-art debiasing methods focus on changes to the training regime, in
this paper, we propose data intervention strategies as a powerful yet simple
technique to reduce gender bias in pre-trained models. Specifically, we
empirically show that by fine-tuning a pre-trained model on only 10 de-biased
(intervened) training examples, the tendency to favor any gender is
significantly reduced. Since our proposed method only needs a few training
examples, our few-shot debiasing approach is highly feasible and practical.
Through extensive experimentation, we show that our debiasing technique
performs better than competitive state-of-the-art baselines with minimal loss
in language modeling ability.
\\ ( https://arxiv.org/abs/2306.04597 ,  7072kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04600 (*cross-listing*)
Date: Wed, 7 Jun 2023 17:04:36 GMT   (2836kb,D)

Title: Uncovering solutions from data corrupted by systematic errors: A
 physics-constrained convolutional neural network approach
Authors: Daniel Kelshaw, Luca Magri
Categories: physics.flu-dyn cs.LG
\\
 Information on natural phenomena and engineering systems is typically
contained in data. Data can be corrupted by systematic errors in models and
experiments. In this paper, we propose a tool to uncover the spatiotemporal
solution of the underlying physical system by removing the systematic errors
from data. The tool is the physics-constrained convolutional neural network
(PC-CNN), which combines information from both the systems governing equations
and data. We focus on fundamental phenomena that are modelled by partial
differential equations, such as linear convection, Burgers equation, and
two-dimensional turbulence. First, we formulate the problem, describe the
physics-constrained convolutional neural network, and parameterise the
systematic error. Second, we uncover the solutions from data corrupted by large
multimodal systematic errors. Third, we perform a parametric study for
different systematic errors. We show that the method is robust. Fourth, we
analyse the physical properties of the uncovered solutions. We show that the
solutions inferred from the PC-CNN are physical, in contrast to the data
corrupted by systematic errors that does not fulfil the governing equations.
This work opens opportunities for removing epistemic errors from models, and
systematic errors from measurements.
\\ ( https://arxiv.org/abs/2306.04600 ,  2836kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04618 (*cross-listing*)
Date: Wed, 7 Jun 2023 17:47:03 GMT   (547kb,D)

Title: Revisiting Out-of-distribution Robustness in NLP: Benchmark, Analysis,
 and LLMs Evaluations
Authors: Lifan Yuan, Yangyi Chen, Ganqu Cui, Hongcheng Gao, Fangyuan Zou,
 Xingyi Cheng, Heng Ji, Zhiyuan Liu, Maosong Sun
Categories: cs.CL cs.CR cs.LG
Comments: Code is available at \url{https://github.com/lifan-yuan/OOD_NLP}
\\
 This paper reexamines the research on out-of-distribution (OOD) robustness in
the field of NLP. We find that the distribution shift settings in previous
studies commonly lack adequate challenges, hindering the accurate evaluation of
OOD robustness. To address these issues, we propose a benchmark construction
protocol that ensures clear differentiation and challenging distribution
shifts. Then we introduce BOSS, a Benchmark suite for Out-of-distribution
robustneSS evaluation covering 5 tasks and 20 datasets. Based on BOSS, we
conduct a series of experiments on pre-trained language models for analysis and
evaluation of OOD robustness. First, for vanilla fine-tuning, we examine the
relationship between in-distribution (ID) and OOD performance. We identify
three typical types that unveil the inner learning mechanism, which could
potentially facilitate the forecasting of OOD robustness, correlating with the
advancements on ID datasets. Then, we evaluate 5 classic methods on BOSS and
find that, despite exhibiting some effectiveness in specific cases, they do not
offer significant improvement compared to vanilla fine-tuning. Further, we
evaluate 5 LLMs with various adaptation paradigms and find that when sufficient
ID data is available, fine-tuning domain-specific models outperform LLMs on ID
examples significantly. However, in the case of OOD instances, prioritizing
LLMs with in-context learning yields better results. We identify that both
fine-tuned small models and LLMs face challenges in effectively addressing
downstream tasks. The code is public at
\url{https://github.com/lifan-yuan/OOD_NLP}.
\\ ( https://arxiv.org/abs/2306.04618 ,  547kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04629 (*cross-listing*)
Date: Wed, 24 May 2023 15:42:38 GMT   (44413kb,D)

Title: Generative Adversarial Shaders for Real-Time Realism Enhancement
Authors: Arturo Salmi, Szabolcs Cs\'efalvay, James Imber
Categories: cs.GR cs.LG
Comments: 12 pages, 9 figures, 2 tables
ACM-class: I.2; I.3; I.4
\\
 Application of realism enhancement methods, particularly in real-time and
resource-constrained settings, has been frustrated by the expense of existing
methods. These achieve high quality results only at the cost of long runtimes
and high bandwidth, memory, and power requirements. We present an efficient
alternative: a high-performance, generative shader-based approach that adapts
machine learning techniques to real-time applications, even in
resource-constrained settings such as embedded and mobile GPUs. The proposed
learnable shader pipeline comprises differentiable functions that can be
trained in an end-to-end manner using an adversarial objective, allowing for
faithful reproduction of the appearance of a target image set without manual
tuning. The shader pipeline is optimized for highly efficient execution on the
target device, providing temporally stable, faster-than-real time results with
quality competitive with many neural network-based methods.
\\ ( https://arxiv.org/abs/2306.04629 ,  44413kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04242 (*cross-listing*)
Date: Wed, 7 Jun 2023 08:33:00 GMT   (1781kb,D)

Title: 4D Millimeter-Wave Radar in Autonomous Driving: A Survey
Authors: Zeyu Han, Jiahao Wang, Zikun Xu, Shuocheng Yang, Lei He, Shaobing Xu,
 Jianqiang Wang
Categories: eess.SP cs.RO
Comments: 8 pages, 5 figures
\\
 The 4D millimeter-wave (mmWave) radar, capable of measuring the range,
azimuth, elevation, and velocity of targets, has attracted considerable
interest in the autonomous driving community. This is attributed to its
robustness in extreme environments and outstanding velocity and elevation
measurement capabilities. However, despite the rapid development of research
related to its sensing theory and application, there is a notable lack of
surveys on the topic of 4D mmWave radar. To address this gap and foster future
research in this area, this paper presents a comprehensive survey on the use of
4D mmWave radar in autonomous driving. Reviews on the theoretical background
and progress of 4D mmWave radars are presented first, including the signal
processing flow, resolution improvement ways, extrinsic calibration process,
and point cloud generation methods. Then it introduces related datasets and
application algorithms in autonomous driving perception and localization and
mapping tasks. Finally, this paper concludes by predicting future trends in the
field of 4D mmWave radar. To the best of our knowledge, this is the first
survey specifically for the 4D mmWave radar.
\\ ( https://arxiv.org/abs/2306.04242 ,  1781kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04089 (*cross-listing*)
Date: Wed, 7 Jun 2023 01:21:41 GMT   (2961kb)

Title: Fully Automated Verification of Linear Time-Invariant Systems against
 Signal Temporal Logic Specifications via Reachability Analysis
Authors: Niklas Kochdumper and Stanley Bak
Categories: cs.LO cs.SY eess.SY math.DS
\\
 While reachability analysis is one of the most promising approaches for the
formal verification of dynamic systems, a major disadvantage preventing a more
widespread application is the requirement to manually tune algorithm parameters
such as the time step size. Manual tuning is especially problematic if one aims
to verify that the system satisfies complicated specifications described by
signal temporal logic formulas since the effect the tightness of the reachable
set has on the satisfaction of the specification is often non-trivial to see
for humans. We address this problem with a fully-automated verifier for linear
systems, which automatically refines all parameters for reachability analysis
until it can either prove or disprove that the system satisfies a signal
temporal logic formula for all initial states and all uncertain inputs. Our
verifier combines reachset temporal logic with dependency preservation to
obtain a model checking approach whose over-approximation error converges to
zero for adequately tuned parameters. While we in this work focus on linear
systems for simplicity, the general concept we present can equivalently be
applied for nonlinear and hybrid systems.
\\ ( https://arxiv.org/abs/2306.04089 ,  2961kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04499 (*cross-listing*)
Date: Wed, 7 Jun 2023 15:08:49 GMT   (2379kb,D)

Title: Anticipating Accidents through Reasoned Simulation
Authors: Craig Innes, Andrew Ireland, Yuhui Lin, Subramanian Ramamoorthy
Categories: cs.LO cs.SY eess.SY
Comments: 11 pages
DOI: 10.1145/3597512.3599698
\\
 A key goal of the System-Theoretic Process Analysis (STPA) hazard analysis
technique is the identification of loss scenarios - causal factors that could
potentially lead to an accident. We propose an approach that aims to assist
engineers in identifying potential loss scenarios that are associated with
flawed assumptions about a system's intended operational environment. Our
approach combines aspects of STPA with formal modelling and simulation.
Currently, we are at a proof-of-concept stage and illustrate the approach using
a case study based upon a simple car door locking system. In terms of the
formal modelling, we use Extended Logic Programming (ELP) and on the simulation
side, we use the CARLA simulator for autonomous driving. We make use of the
problem frames approach to requirements engineering to bridge between the
informal aspects of STPA and our formal modelling.
\\ ( https://arxiv.org/abs/2306.04499 ,  2379kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04584 (*cross-listing*)
Date: Fri, 2 Jun 2023 14:22:07 GMT   (1371kb,D)

Title: A Control Flow based Static Analysis of GRAFCET using Abstract
 Interpretation
Authors: Aron Schnakenbeck and Robin Mro{\ss} and Marcus V\"olker and Stefan
 Kowalewski and Alexander Fay
Categories: cs.PL cs.LO cs.SY eess.SY
Comments: Submitted to INDIN 23
\\
 The graphical modeling language GRAFCET is used as a formal specification
language in industrial control design. This paper proposes a static analysis
approach based on the control flow of GRAFCET using abstract interpretation to
allow verification on specification level. GRAFCET has different elements
leading to concurrent behavior, which in general results in a large state
space. To get precise results and reduce the state space, we propose an
analysis suitable for GRAFCET instances without concurrent behavior. We point
out how to check for the absence of concurrency and present a flow-sensitive
analysis for these GRAFCET instances. The proposed approach is evaluated on an
industrial-sized example.
\\ ( https://arxiv.org/abs/2306.04584 ,  1371kb)
%%--%%--%%--%%--%%--%%--%%--%%--%%--%%--%%--%%--%%--%%--%%--%%--%%--%%--%%--%%
------------------------------------------------------------------------------
\\
arXiv:2209.13873
replaced with revised version Wed, 7 Jun 2023 03:17:14 GMT   (3029kb,D)

Title: InFi: End-to-End Learning to Filter Input for Resource-Efficiency in
 Mobile-Centric Inference
Authors: Mu Yuan, Lan Zhang, Fengxiang He, Xueting Tong, Miao-Hui Song,
 Zhengyuan Xu, Xiang-Yang Li
Categories: cs.AI
Comments: IEEE Transactions on Mobile Computing (TMC) 2023
\\ ( https://arxiv.org/abs/2209.13873 ,  3029kb)
------------------------------------------------------------------------------
\\
arXiv:2209.13883
replaced with revised version Wed, 7 Jun 2023 03:15:06 GMT   (3712kb,D)

Title: MLink: Linking Black-Box Models from Multiple Domains for Collaborative
 Inference
Authors: Mu Yuan, Lan Zhang, Zimu Zheng, Yi-Nan Zhang, Xiang-Yang Li
Categories: cs.AI
Comments: Transactions on Pattern Analysis and Machine Intelligence (TPAMI)
 2023
\\ ( https://arxiv.org/abs/2209.13883 ,  3712kb)
------------------------------------------------------------------------------
\\
arXiv:2211.02918
replaced with revised version Wed, 7 Jun 2023 15:13:33 GMT   (1724kb,D)

Title: A Filtering-based General Approach to Learning Rational Constraints of
 Epistemic Graphs
Authors: Xiao Chi
Categories: cs.AI cs.LG
Comments: 18 pages, 6 figures, submitted to CLAR 2023
\\ ( https://arxiv.org/abs/2211.02918 ,  1724kb)
------------------------------------------------------------------------------
\\
arXiv:2305.18015
replaced with revised version Wed, 7 Jun 2023 15:06:33 GMT   (525kb)

Title: On the Correspondence Between Monotonic Max-Sum GNNs and Datalog
Authors: David Tena Cucala, Bernardo Cuenca Grau, Boris Motik, Egor V. Kostylev
Categories: cs.AI
\\ ( https://arxiv.org/abs/2305.18015 ,  525kb)
------------------------------------------------------------------------------
\\
arXiv:2306.00932
replaced with revised version Wed, 7 Jun 2023 11:16:52 GMT   (2102kb)

Title: Cross Modal Data Discovery over Structured and Unstructured Data Lakes
Authors: Mohamed Y. Eltabakh, Mayuresh Kunjir, Ahmed Elmagarmid, Mohammad
 Shahmeer Ahmad
Categories: cs.AI cs.DB
Report-no: 17
\\ ( https://arxiv.org/abs/2306.00932 ,  2102kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03901
replaced with revised version Wed, 7 Jun 2023 17:22:22 GMT   (298kb,D)

Title: ChatDB: Augmenting LLMs with Databases as Their Symbolic Memory
Authors: Chenxu Hu, Jie Fu, Chenzhuang Du, Simian Luo, Junbo Zhao, Hang Zhao
Categories: cs.AI cs.CL cs.DB cs.LG
\\ ( https://arxiv.org/abs/2306.03901 ,  298kb)
------------------------------------------------------------------------------
\\
arXiv:2008.01701
replaced with revised version Wed, 7 Jun 2023 17:28:39 GMT   (11680kb,D)

Title: Progressive Update Guided Interdependent Networks for Single Image
 Dehazing
Authors: Aupendu Kar, Sobhan Kanti Dhara, Debashis Sen, Prabir Kumar Biswas
Categories: cs.CV
Comments: First two authors contributed equally. This work has been submitted
 to the IEEE for possible publication. Copyright may be transferred without
 notice, after which this version may no longer be accessible. Project
 Website: https://aupendu.github.io/progressive-dehaze
\\ ( https://arxiv.org/abs/2008.01701 ,  11680kb)
------------------------------------------------------------------------------
\\
arXiv:2111.10056
replaced with revised version Wed, 7 Jun 2023 00:37:15 GMT   (4635kb,D)

Title: Medical Visual Question Answering: A Survey
Authors: Zhihong Lin, Donghao Zhang, Qingyi Tao, Danli Shi, Gholamreza Haffari,
 Qi Wu, Mingguang He, and Zongyuan Ge
Categories: cs.CV cs.AI
\\ ( https://arxiv.org/abs/2111.10056 ,  4635kb)
------------------------------------------------------------------------------
\\
arXiv:2111.12971
replaced with revised version Wed, 7 Jun 2023 10:28:12 GMT   (12998kb,D)

Title: Natural & Adversarial Bokeh Rendering via Circle-of-Confusion Predictive
 Network
Authors: Yihao Huang, Felix Juefei-Xu, Qing Guo, Geguang Pu, Yang Liu
Categories: cs.CV
Comments: 11 pages
\\ ( https://arxiv.org/abs/2111.12971 ,  12998kb)
------------------------------------------------------------------------------
\\
arXiv:2202.05411
replaced with revised version Wed, 7 Jun 2023 05:00:32 GMT   (4793kb,D)

Title: Incremental Learning of Structured Memory via Closed-Loop Transcription
Authors: Shengbang Tong, Xili Dai, Ziyang Wu, Mingyang Li, Brent Yi, Yi Ma
Categories: cs.CV
Comments: 20 pages
\\ ( https://arxiv.org/abs/2202.05411 ,  4793kb)
------------------------------------------------------------------------------
\\
arXiv:2203.10247
replaced with revised version Wed, 7 Jun 2023 01:39:31 GMT   (21205kb,D)

Title: HIPA: Hierarchical Patch Transformer for Single Image Super Resolution
Authors: Qing Cai, Yiming Qian, Jinxing Li, Jun Lv, Yee-Hong Yang, Feng Wu,
 David Zhang
Categories: cs.CV
\\ ( https://arxiv.org/abs/2203.10247 ,  21205kb)
------------------------------------------------------------------------------
\\
arXiv:2204.13382
replaced with revised version Wed, 7 Jun 2023 09:46:10 GMT   (5684kb,D)

Title: Reducing Predictive Feature Suppression in Resource-Constrained
 Contrastive Image-Caption Retrieval
Authors: Maurits Bleeker, Andrew Yates, Maarten de Rijke
Categories: cs.CV cs.AI
Comments: Published in Transactions on Machine Learning Research OpenReview:
 https://openreview.net/forum?id=T1XtOqrVKn Code:
 https://github.com/MauritsBleeker/reducing-predictive-feature-suppression.
 Video: https://www.youtube.com/watch?v=oxa5AbGrKCY
\\ ( https://arxiv.org/abs/2204.13382 ,  5684kb)
------------------------------------------------------------------------------
\\
arXiv:2206.05260
replaced with revised version Wed, 7 Jun 2023 17:52:01 GMT   (9339kb,D)

Title: Balanced Product of Calibrated Experts for Long-Tailed Recognition
Authors: Emanuel Sanchez Aimar, Arvi Jonnarth, Michael Felsberg, Marco Kuhlmann
Categories: cs.CV cs.LG
Comments: Accepted at CVPR 2023, 19 pages
\\ ( https://arxiv.org/abs/2206.05260 ,  9339kb)
------------------------------------------------------------------------------
\\
arXiv:2208.02797
replaced with revised version Wed, 7 Jun 2023 03:32:39 GMT   (18021kb,D)

Title: Vision-Centric BEV Perception: A Survey
Authors: Yuexin Ma, Tai Wang, Xuyang Bai, Huitong Yang, Yuenan Hou, Yaming
 Wang, Yu Qiao, Ruigang Yang, Dinesh Manocha, Xinge Zhu
Categories: cs.CV
Comments: project page at
 https://github.com/4DVLab/Vision-Centric-BEV-Perception; 22 pages, 15 figures
\\ ( https://arxiv.org/abs/2208.02797 ,  18021kb)
------------------------------------------------------------------------------
\\
arXiv:2209.11526
replaced with revised version Tue, 6 Jun 2023 20:17:36 GMT   (3211kb,D)

Title: Statistical shape representations for temporal registration of plant
 components in 3D
Authors: Karoline Heiwolt, Cengiz \"Oztireli, Grzegorz Cielniak
Categories: cs.CV
Comments: 6 pages plus references, 7 figures, presented at ICRA 2023
\\ ( https://arxiv.org/abs/2209.11526 ,  3211kb)
------------------------------------------------------------------------------
\\
arXiv:2210.16467
replaced with revised version Wed, 7 Jun 2023 07:12:45 GMT   (11809kb)

Title: ImplantFormer: Vision Transformer based Implant Position Regression
 Using Dental CBCT Data
Authors: Xinquan Yang and Xuguang Li and Xuechen Li and Peixi Wu and Linlin
 Shen and Yongqiang Deng
Categories: cs.CV
\\ ( https://arxiv.org/abs/2210.16467 ,  11809kb)
------------------------------------------------------------------------------
\\
arXiv:2211.16582
replaced with revised version Tue, 6 Jun 2023 20:42:41 GMT   (36532kb,D)

Title: SinDDM: A Single Image Denoising Diffusion Model
Authors: Vladimir Kulikov, Shahar Yadin, Matan Kleiner, Tomer Michaeli
Categories: cs.CV cs.LG eess.IV
Comments: Updated for ICML 2023 and added the Appendix. Note that the images
 are lightly compressed. Visit our project page for uncompressed results:
 https://matankleiner.github.io/sinddm/
\\ ( https://arxiv.org/abs/2211.16582 ,  36532kb)
------------------------------------------------------------------------------
\\
arXiv:2212.03752
replaced with revised version Wed, 7 Jun 2023 03:34:34 GMT   (2766kb,D)

Title: GLeaD: Improving GANs with A Generator-Leading Task
Authors: Qingyan Bai, Ceyuan Yang, Yinghao Xu, Xihui Liu, Yujiu Yang, Yujun
 Shen
Categories: cs.CV eess.IV
Comments: CVPR2023. Project page: https://ezioby.github.io/glead/ Code:
 https://github.com/EzioBy/glead/
\\ ( https://arxiv.org/abs/2212.03752 ,  2766kb)
------------------------------------------------------------------------------
\\
arXiv:2212.05861
replaced with revised version Wed, 7 Jun 2023 07:14:26 GMT   (8211kb,D)

Title: CountingMOT: Joint Counting, Detection and Re-Identification for
 Multiple Object Tracking
Authors: Weihong Ren, Denglu Wu, Hui Cao, Bowen Chen, Yuhang Shi, Weibo Jiang
 and Honghai Liu
Categories: cs.CV
\\ ( https://arxiv.org/abs/2212.05861 ,  8211kb)
------------------------------------------------------------------------------
\\
arXiv:2212.09737
replaced with revised version Wed, 7 Jun 2023 06:28:18 GMT   (4973kb,D)

Title: Position-guided Text Prompt for Vision-Language Pre-training
Authors: Alex Jinpeng Wang, Pan Zhou, Mike Zheng Shou, Shuicheng Yan
Categories: cs.CV
Comments: Camera-ready version, code is in https://github.com/sail-sg/ptp
\\ ( https://arxiv.org/abs/2212.09737 ,  4973kb)
------------------------------------------------------------------------------
\\
arXiv:2301.07053
replaced with revised version Wed, 7 Jun 2023 11:02:35 GMT   (580kb)

Title: Preserving Privacy in Surgical Video Analysis Using Artificial
 Intelligence: A Deep Learning Classifier to Identify Out-of-Body Scenes in
 Endoscopic Videos
Authors: Jo\"el L. Lavanchy, Armine Vardazaryan, Pietro Mascagni, AI4SafeChole
 Consortium, Didier Mutter, Nicolas Padoy
Categories: cs.CV
Comments: Jo\"el L. Lavanchy and Armine Vardazaryan contributed equally and
 share first co-authorship
Journal-ref: Scientific Reports 13, 9235 (2023)
DOI: 10.1038/s41598-023-36453-1
\\ ( https://arxiv.org/abs/2301.07053 ,  580kb)
------------------------------------------------------------------------------
\\
arXiv:2301.08951
replaced with revised version Wed, 7 Jun 2023 15:54:03 GMT   (36996kb,D)

Title: Time-Conditioned Generative Modeling of Object-Centric Representations
 for Video Decomposition and Prediction
Authors: Chengmin Gao and Bin Li
Categories: cs.CV cs.LG
\\ ( https://arxiv.org/abs/2301.08951 ,  36996kb)
------------------------------------------------------------------------------
\\
arXiv:2303.01239
replaced with revised version Wed, 7 Jun 2023 12:02:51 GMT   (1004kb,D)

Title: MixPHM: Redundancy-Aware Parameter-Efficient Tuning for Low-Resource
 Visual Question Answering
Authors: Jingjing Jiang, Nanning Zheng
Categories: cs.CV
Comments: 13 pages, 6 figures, 9 tables. Accepted to CVPR 2023
\\ ( https://arxiv.org/abs/2303.01239 ,  1004kb)
------------------------------------------------------------------------------
\\
arXiv:2303.02230
replaced with revised version Tue, 6 Jun 2023 21:08:52 GMT   (23789kb,D)

Title: Building Floorspace in China: A Dataset and Learning Pipeline
Authors: Peter Egger, Susie Xi Rao, Sebastiano Papini
Categories: cs.CV cs.AI econ.GN q-fin.EC
\\ ( https://arxiv.org/abs/2303.02230 ,  23789kb)
------------------------------------------------------------------------------
\\
arXiv:2303.11926
replaced with revised version Wed, 7 Jun 2023 08:08:16 GMT   (3049kb,D)

Title: Exploring Object-Centric Temporal Modeling for Efficient Multi-View 3D
 Object Detection
Authors: Shihao Wang, Yingfei Liu, Tiancai Wang, Ying Li, Xiangyu Zhang
Categories: cs.CV
\\ ( https://arxiv.org/abs/2303.11926 ,  3049kb)
------------------------------------------------------------------------------
\\
arXiv:2303.17152
replaced with revised version Wed, 7 Jun 2023 17:27:03 GMT   (5318kb,D)

Title: Mixed Autoencoder for Self-supervised Visual Representation Learning
Authors: Kai Chen, Zhili Liu, Lanqing Hong, Hang Xu, Zhenguo Li, Dit-Yan Yeung
Categories: cs.CV cs.LG
Comments: Accepted by CVPR 2023
\\ ( https://arxiv.org/abs/2303.17152 ,  5318kb)
------------------------------------------------------------------------------
\\
arXiv:2304.05977
replaced with revised version Tue, 6 Jun 2023 19:13:51 GMT   (18538kb,D)

Title: ImageReward: Learning and Evaluating Human Preferences for Text-to-Image
 Generation
Authors: Jiazheng Xu, Xiao Liu, Yuchen Wu, Yuxuan Tong, Qinkai Li, Ming Ding,
 Jie Tang, Yuxiao Dong
Categories: cs.CV cs.LG
Comments: 32 pages
\\ ( https://arxiv.org/abs/2304.05977 ,  18538kb)
------------------------------------------------------------------------------
\\
arXiv:2304.06009
replaced with revised version Wed, 7 Jun 2023 10:05:59 GMT   (255kb,D)

Title: Literature Review: Computer Vision Applications in Transportation
 Logistics and Warehousing
Authors: Alexander Naumann, Felix Hertlein, Laura D\"orr, Steffen Thoma, Kai
 Furmans
Categories: cs.CV cs.LG
\\ ( https://arxiv.org/abs/2304.06009 ,  255kb)
------------------------------------------------------------------------------
\\
arXiv:2304.06051
replaced with revised version Wed, 7 Jun 2023 12:29:25 GMT   (9114kb,D)

Title: Open-TransMind: A New Baseline and Benchmark for 1st Foundation Model
 Challenge of Intelligent Transportation
Authors: Yifeng Shi and Feng Lv and Xinliang Wang and Chunlong Xia and Shaojie
 Li and Shujie Yang and Teng Xi and Gang Zhang
Categories: cs.CV cs.AI cs.LG
\\ ( https://arxiv.org/abs/2304.06051 ,  9114kb)
------------------------------------------------------------------------------
\\
arXiv:2304.08451
replaced with revised version Wed, 7 Jun 2023 16:04:17 GMT   (8138kb,D)

Title: Efficient Video Action Detection with Token Dropout and Context
 Refinement
Authors: Lei Chen, Zhan Tong, Yibing Song, Gangshan Wu, Limin Wang
Categories: cs.CV
Comments: technical report
\\ ( https://arxiv.org/abs/2304.08451 ,  8138kb)
------------------------------------------------------------------------------
\\
arXiv:2304.10712
replaced with revised version Wed, 7 Jun 2023 02:59:51 GMT   (5992kb,D)

Title: Adversarial Infrared Blocks: A Black-box Attack to Thermal Infrared
 Detectors at Multiple Angles in Physical World
Authors: Chengyin Hu, Weiwen Shi, Tingsong Jiang, Wen Yao, Ling Tian, Xiaoqian
 Chen
Categories: cs.CV cs.AI
\\ ( https://arxiv.org/abs/2304.10712 ,  5992kb)
------------------------------------------------------------------------------
\\
arXiv:2304.14400
replaced with revised version Wed, 7 Jun 2023 03:45:20 GMT   (1041kb,D)

Title: IconShop: Text-Guided Vector Icon Synthesis with Autoregressive
 Transformers
Authors: Ronghuan Wu, Wanchao Su, Kede Ma, Jing Liao
Categories: cs.CV cs.GR
Comments: Project Page: https://icon-shop.github.io/
\\ ( https://arxiv.org/abs/2304.14400 ,  1041kb)
------------------------------------------------------------------------------
\\
arXiv:2305.08685
replaced with revised version Wed, 7 Jun 2023 10:55:19 GMT   (8226kb,D)

Title: CLIP-VG: Self-paced Curriculum Adapting of CLIP for Visual Grounding
Authors: Linhui Xiao, Xiaoshan Yang, Fang Peng, Ming Yan, Yaowei Wang,
 Changsheng Xu
Categories: cs.CV
Comments: 13 pages, 11 figures. Code will be released at
 https://github.com/linhuixiao/CLIP-VG
\\ ( https://arxiv.org/abs/2305.08685 ,  8226kb)
------------------------------------------------------------------------------
\\
arXiv:2305.09397
replaced with revised version Tue, 6 Jun 2023 18:24:21 GMT   (5331kb,D)

Title: EXPRESSNET: An Explainable Residual Slim Network for Fingerprint
 Presentation Attack Detection
Authors: Anuj Rai, Somnath Dey
Categories: cs.CV
Comments: arXiv admin note: text overlap with arXiv:2303.01465
\\ ( https://arxiv.org/abs/2305.09397 ,  5331kb)
------------------------------------------------------------------------------
\\
arXiv:2305.09948
replaced with revised version Wed, 7 Jun 2023 06:53:07 GMT   (1445kb,D)

Title: HICO-DET-SG and V-COCO-SG: New Data Splits for Evaluating the Systematic
 Generalization Performance of Human-Object Interaction Detection Models
Authors: Kentaro Takemoto, Moyuru Yamada, Tomotake Sasaki, Hisanao Akima
Categories: cs.CV cs.AI
Comments: 19 pages, 3 figures, 4 tables
\\ ( https://arxiv.org/abs/2305.09948 ,  1445kb)
------------------------------------------------------------------------------
\\
arXiv:2305.10657
replaced with revised version Wed, 7 Jun 2023 02:21:58 GMT   (11338kb,D)

Title: PTQD: Accurate Post-Training Quantization for Diffusion Models
Authors: Yefei He, Luping Liu, Jing Liu, Weijia Wu, Hong Zhou, Bohan Zhuang
Categories: cs.CV
Comments: 18 pages, 14 figures
\\ ( https://arxiv.org/abs/2305.10657 ,  11338kb)
------------------------------------------------------------------------------
\\
arXiv:2305.10855
replaced with revised version Wed, 7 Jun 2023 05:55:26 GMT   (46691kb,D)

Title: TextDiffuser: Diffusion Models as Text Painters
Authors: Jingye Chen, Yupan Huang, Tengchao Lv, Lei Cui, Qifeng Chen, Furu Wei
Categories: cs.CV
\\ ( https://arxiv.org/abs/2305.10855 ,  46691kb)
------------------------------------------------------------------------------
\\
arXiv:2305.18723
replaced with revised version Wed, 7 Jun 2023 08:23:09 GMT   (4457kb,D)

Title: Towards Accurate Data-free Quantization for Diffusion Models
Authors: Changyuan Wang, Ziwei Wang, Xiuwei Xu, Yansong Tang, Jie Zhou, Jiwen
 Lu
Categories: cs.CV
\\ ( https://arxiv.org/abs/2305.18723 ,  4457kb)
------------------------------------------------------------------------------
\\
arXiv:2305.18829
replaced with revised version Wed, 7 Jun 2023 07:53:51 GMT   (2172kb,D)

Title: Occ-BEV: Multi-Camera Unified Pre-training via 3D Scene Reconstruction
Authors: Chen Min, Xinli Xu, Fuyang Li, Shubin Si, Hanzhang Xue, Weizhong
 Jiang, Zhichao Zhang, Jimei Li, Dawei Zhao, Liang Xiao, Jiaolong Xu, Yiming
 Nie, Bin Dai
Categories: cs.CV cs.MM cs.RO
Comments: 8 pages, 5 figures
\\ ( https://arxiv.org/abs/2305.18829 ,  2172kb)
------------------------------------------------------------------------------
\\
arXiv:2306.00595
replaced with revised version Wed, 7 Jun 2023 06:59:23 GMT   (24834kb,D)

Title: Revisit Weakly-Supervised Audio-Visual Video Parsing from the Language
 Perspective
Authors: Yingying Fan and Yu Wu and Yutian Lin and Bo Du
Categories: cs.CV
\\ ( https://arxiv.org/abs/2306.00595 ,  24834kb)
------------------------------------------------------------------------------
\\
arXiv:2306.00693
replaced with revised version Wed, 7 Jun 2023 13:59:25 GMT   (1340kb,D)

Title: GPT4Image: Can Large Pre-trained Models Help Vision Models on Perception
 Tasks?
Authors: Ning Ding, Yehui Tang, Zhongqian Fu, Chao Xu, Kai Han, Yunhe Wang
Categories: cs.CV
Comments: GitHub:
 https://github.com/huawei-noah/Efficient-Computing/tree/master/GPT4Image/
\\ ( https://arxiv.org/abs/2306.00693 ,  1340kb)
------------------------------------------------------------------------------
\\
arXiv:2306.00823
replaced with revised version Wed, 7 Jun 2023 16:23:59 GMT   (6486kb,D)

Title: Geo-Tiles for Semantic Segmentation of Earth Observation Imagery
Authors: Sebastian Bullinger and Florian Fervers and Christoph Bodensteiner and
 Michael Arens
Categories: cs.CV eess.IV
\\ ( https://arxiv.org/abs/2306.00823 ,  6486kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02760
replaced with revised version Wed, 7 Jun 2023 05:21:09 GMT   (8669kb,D)

Title: A2B: Anchor to Barycentric Coordinate for Robust Correspondence
Authors: Weiyue Zhao, Hao Lu, Zhiguo Cao, Xin Li
Categories: cs.CV
Comments: Accepted by International Journal of Computer Vision
\\ ( https://arxiv.org/abs/2306.02760 ,  8669kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03514
replaced with revised version Wed, 7 Jun 2023 04:24:55 GMT   (443kb,D)

Title: Recognize Anything: A Strong Image Tagging Model
Authors: Youcai Zhang, Xinyu Huang, Jinyu Ma, Zhaoyang Li, Zhaochuan Luo,
 Yanchun Xie, Yuzhuo Qin, Tong Luo, Yaqian Li, Shilong Liu, Yandong Guo, Lei
 Zhang
Categories: cs.CV
\\ ( https://arxiv.org/abs/2306.03514 ,  443kb)
------------------------------------------------------------------------------
\\
arXiv:1911.11049
replaced with revised version Wed, 7 Jun 2023 11:06:28 GMT   (395kb,D)

Title: ROIPCA: An online memory-restricted PCA algorithm based on rank-one
 updates
Authors: Roy Mitz, Yoel Shkolnisky
Categories: cs.LG stat.ML
Comments: 23 pages, 2 figures
\\ ( https://arxiv.org/abs/1911.11049 ,  395kb)
------------------------------------------------------------------------------
\\
arXiv:2009.02476
replaced with revised version Wed, 7 Jun 2023 05:28:39 GMT   (5966kb,D)

Title: Using Machine Teaching to Investigate Human Assumptions when Teaching
 Reinforcement Learners
Authors: Yun-Shiuan Chuang, Xuezhou Zhang, Yuzhe Ma, Mark K. Ho, Joseph L.
 Austerweil, Xiaojin Zhu
Categories: cs.LG cs.AI cs.HC
Comments: 21 pages, 4 figures
\\ ( https://arxiv.org/abs/2009.02476 ,  5966kb)
------------------------------------------------------------------------------
\\
arXiv:2202.07960
replaced with revised version Wed, 7 Jun 2023 12:18:33 GMT   (376kb,D)

Title: Temporal Difference Learning with Continuous Time and State in the
 Stochastic Setting
Authors: Ziad Kobeissi (SIERRA), Francis Bach (SIERRA, DI-ENS, PSL)
Categories: cs.LG cs.AI math.AP math.OC
\\ ( https://arxiv.org/abs/2202.07960 ,  376kb)
------------------------------------------------------------------------------
\\
arXiv:2203.07475
replaced with revised version Wed, 7 Jun 2023 04:37:57 GMT   (75kb,D)

Title: Invariance in Policy Optimisation and Partial Identifiability in Reward
 Learning
Authors: Joar Skalse, Matthew Farrugia-Roberts, Stuart Russell, Alessandro
 Abate, Adam Gleave
Categories: cs.LG cs.AI stat.ML
Comments: ICML 2023. 9 pages main paper, 26 pages total, 3 figures
ACM-class: I.2.6
\\ ( https://arxiv.org/abs/2203.07475 ,  75kb)
------------------------------------------------------------------------------
\\
arXiv:2204.06895
replaced with revised version Wed, 7 Jun 2023 16:12:41 GMT   (283kb,D)

Title: Gradient boosting for convex cone predict and optimize problems
Authors: Andrew Butler and Roy H. Kwon
Categories: cs.LG math.OC stat.ML
\\ ( https://arxiv.org/abs/2204.06895 ,  283kb)
------------------------------------------------------------------------------
\\
arXiv:2205.13225
replaced with revised version Wed, 7 Jun 2023 07:01:45 GMT   (20430kb,D)

Title: DevFormer: A Symmetric Transformer for Context-Aware Device Placement
Authors: Haeyeon Kim, Minsu Kim, Federico Berto, Joungho Kim, Jinkyoo Park
Categories: cs.LG
Comments: International Conference on Machine Learning (ICML) 2023. Extended
 version of NeurIPS 2022 Offline RL Workshop "Collaborative symmetricity
 exploitation for offline learning of hardware design solver"
\\ ( https://arxiv.org/abs/2205.13225 ,  20430kb)
------------------------------------------------------------------------------
\\
arXiv:2206.12977
replaced with revised version Wed, 7 Jun 2023 13:27:57 GMT   (39kb)

Title: Adversarially Robust PAC Learnability of Real-Valued Functions
Authors: Idan Attias and Steve Hanneke
Categories: cs.LG stat.ML
Comments: accepted to ICML2023
\\ ( https://arxiv.org/abs/2206.12977 ,  39kb)
------------------------------------------------------------------------------
\\
arXiv:2210.05337
replaced with revised version Wed, 7 Jun 2023 09:50:21 GMT   (4077kb,D)

Title: SGD with Large Step Sizes Learns Sparse Features
Authors: Maksym Andriushchenko, Aditya Varre, Loucas Pillaud-Vivien, Nicolas
 Flammarion
Categories: cs.LG stat.ML
Comments: The camera-ready version (ICML 2023): extended experiments on deep
 networks (DenseNets on CIFAR-10, CIFAR-100, and Tiny ImageNet), empirically
 validated the SDE modelling, improved the clarity of the paper
\\ ( https://arxiv.org/abs/2210.05337 ,  4077kb)
------------------------------------------------------------------------------
\\
arXiv:2210.08371
replaced with revised version Tue, 6 Jun 2023 22:18:21 GMT   (61kb)

Title: Sketching for First Order Method: Efficient Algorithm for Low-Bandwidth
 Channel and Vulnerability
Authors: Zhao Song, Yitan Wang, Zheng Yu, Lichen Zhang
Categories: cs.LG cs.CR
Comments: ICML 2023
\\ ( https://arxiv.org/abs/2210.08371 ,  61kb)
------------------------------------------------------------------------------
\\
arXiv:2210.10048
replaced with revised version Tue, 6 Jun 2023 22:29:13 GMT   (5313kb)

Title: AnalogVNN: A fully modular framework for modeling and optimizing
 photonic neural networks
Authors: Vivswan Shah, Nathan Youngblood
Categories: cs.LG cs.ET physics.optics
Comments: 28 pages; replace figure 6C; better format; updated links
\\ ( https://arxiv.org/abs/2210.10048 ,  5313kb)
------------------------------------------------------------------------------
\\
arXiv:2210.12874
replaced with revised version Wed, 7 Jun 2023 04:38:19 GMT   (7114kb,D)

Title: Global Contrastive Batch Sampling via Optimization on Sample
 Permutations
Authors: Vin Sachidananda, Ziyi Yang, Chenguang Zhu
Categories: cs.LG cs.CL stat.ML
Comments: ICML 2023; 21 pages, 7 figures
\\ ( https://arxiv.org/abs/2210.12874 ,  7114kb)
------------------------------------------------------------------------------
\\
arXiv:2210.15304
replaced with revised version Wed, 7 Jun 2023 07:09:58 GMT   (7275kb,D)

Title: Explaining the Explainers in Graph Neural Networks: a Comparative Study
Authors: Antonio Longa, Steve Azzolin, Gabriele Santin, Giulia Cencetti, Pietro
 Li\`o, Bruno Lepri and Andrea Passerini
Categories: cs.LG cs.AI
DOI: 10.1016/j.aml.2022.108489
\\ ( https://arxiv.org/abs/2210.15304 ,  7275kb)
------------------------------------------------------------------------------
\\
arXiv:2211.00181
replaced with revised version Tue, 6 Jun 2023 23:22:11 GMT   (4848kb,D)

Title: The Numerical Stability of Hyperbolic Representation Learning
Authors: Gal Mishne, Zhengchao Wan, Yusu Wang, Sheng Yang
Categories: cs.LG cs.NA math.NA
\\ ( https://arxiv.org/abs/2211.00181 ,  4848kb)
------------------------------------------------------------------------------
\\
arXiv:2211.13585
replaced with revised version Wed, 7 Jun 2023 16:06:18 GMT   (2710kb,D)

Title: Learning to Suggest Breaks: Sustainable Optimization of Long-Term User
 Engagement
Authors: Eden Saig, Nir Rosenfeld
Categories: cs.LG cs.CY cs.IR cs.SY eess.SY
Comments: Accepted for publication in ICML 2023
\\ ( https://arxiv.org/abs/2211.13585 ,  2710kb)
------------------------------------------------------------------------------
\\
arXiv:2211.14666
replaced with revised version Tue, 6 Jun 2023 18:02:14 GMT   (4528kb,D)

Title: Synergies between Disentanglement and Sparsity: Generalization and
 Identifiability in Multi-Task Learning
Authors: S\'ebastien Lachapelle, Tristan Deleu, Divyat Mahajan, Ioannis
 Mitliagkas, Yoshua Bengio, Simon Lacoste-Julien, Quentin Bertrand
Categories: cs.LG stat.ML
Comments: Appears in: Fortieth International Conference on Machine Learning
 (ICML 2023). 36 pages
ACM-class: I.2.6; I.5.1
\\ ( https://arxiv.org/abs/2211.14666 ,  4528kb)
------------------------------------------------------------------------------
\\
arXiv:2211.15046
replaced with revised version Wed, 7 Jun 2023 07:36:59 GMT   (3097kb,D)

Title: PCT-CycleGAN: Paired Complementary Temporal Cycle-Consistent Adversarial
 Networks for Radar-Based Precipitation Nowcasting
Authors: Jaeho Choi, Yura Kim, Kwang-Ho Kim, Sung-Hwa Jung, Ikhyun Cho
Categories: cs.LG cs.AI cs.CV
\\ ( https://arxiv.org/abs/2211.15046 ,  3097kb)
------------------------------------------------------------------------------
\\
arXiv:2212.09567
replaced with revised version Wed, 7 Jun 2023 06:57:09 GMT   (599kb,D)

Title: Answering Complex Logical Queries on Knowledge Graphs via Query
 Computation Tree Optimization
Authors: Yushi Bai, Xin Lv, Juanzi Li, Lei Hou
Categories: cs.LG cs.AI cs.DB cs.SI
Comments: To appear in ICML 2023
\\ ( https://arxiv.org/abs/2212.09567 ,  599kb)
------------------------------------------------------------------------------
\\
arXiv:2212.10439
replaced with revised version Wed, 7 Jun 2023 12:20:17 GMT   (610kb,D)

Title: Policy Gradient in Robust MDPs with Global Convergence Guarantee
Authors: Qiuhao Wang, Chin Pang Ho, Marek Petrik
Categories: cs.LG
\\ ( https://arxiv.org/abs/2212.10439 ,  610kb)
------------------------------------------------------------------------------
\\
arXiv:2301.00437
replaced with revised version Wed, 7 Jun 2023 08:32:16 GMT   (7290kb,D)

Title: Neural Collapse in Deep Linear Networks: From Balanced to Imbalanced
 Data
Authors: Hien Dang and Tho Tran and Stanley Osher and Hung Tran-The and Nhat Ho
 and Tan Nguyen
Categories: cs.LG stat.ML
Comments: 75 pages, 20 figures, 4 tables. Hien Dang and Tho Tran contributed
 equally to this work
\\ ( https://arxiv.org/abs/2301.00437 ,  7290kb)
------------------------------------------------------------------------------
\\
arXiv:2301.05062
replaced with revised version Wed, 7 Jun 2023 13:21:51 GMT   (1153kb,D)

Title: Tracr: Compiled Transformers as a Laboratory for Interpretability
Authors: David Lindner and J\'anos Kram\'ar and Sebastian Farquhar and Matthew
 Rahtz and Thomas McGrath and Vladimir Mikulik
Categories: cs.LG cs.AI stat.ML
\\ ( https://arxiv.org/abs/2301.05062 ,  1153kb)
------------------------------------------------------------------------------
\\
arXiv:2301.08839
replaced with revised version Wed, 7 Jun 2023 10:06:21 GMT   (19512kb,D)

Title: A Trustworthiness Score to Evaluate CNNs Predictions
Authors: Abanoub Ghobrial, Darryl Hond, Hamid Asgari, Kerstin Eder
Categories: cs.LG
\\ ( https://arxiv.org/abs/2301.08839 ,  19512kb)
------------------------------------------------------------------------------
\\
arXiv:2301.11040
replaced with revised version Wed, 7 Jun 2023 08:50:15 GMT   (7979kb,D)

Title: Random Grid Neural Processes for Parametric Partial Differential
 Equations
Authors: Arnaud Vadeboncoeur, Ieva Kazlauskaite, Yanni Papandreou, Fehmi Cirak,
 Mark Girolami, \"Omer Deniz Akyildiz
Categories: cs.LG cs.NA math.NA stat.CO stat.ML
\\ ( https://arxiv.org/abs/2301.11040 ,  7979kb)
------------------------------------------------------------------------------
\\
arXiv:2301.11355
replaced with revised version Wed, 7 Jun 2023 09:01:03 GMT   (1605kb,D)

Title: Rigid Body Flows for Sampling Molecular Crystal Structures
Authors: Jonas K\"ohler, Michele Invernizzi, Pim de Haan, Frank No\'e
Categories: cs.LG physics.chem-ph physics.comp-ph stat.ML
Comments: International Conference on Machine Learning, 2023
\\ ( https://arxiv.org/abs/2301.11355 ,  1605kb)
------------------------------------------------------------------------------
\\
arXiv:2301.12366
replaced with revised version Wed, 7 Jun 2023 17:32:00 GMT   (1774kb,D)

Title: Smooth Non-Stationary Bandits
Authors: Su Jia, Qian Xie, Nathan Kallus, Peter I. Frazier
Categories: cs.LG cs.AI math.OC math.ST stat.TH
Comments: Accepted by ICML 2023
\\ ( https://arxiv.org/abs/2301.12366 ,  1774kb)
------------------------------------------------------------------------------
\\
arXiv:2301.12802
replaced with revised version Wed, 7 Jun 2023 10:48:02 GMT   (655kb,D)

Title: Planning Multiple Epidemic Interventions with Reinforcement Learning
Authors: Anh Mai and Nikunj Gupta and Azza Abouzied and Dennis Shasha
Categories: cs.LG
\\ ( https://arxiv.org/abs/2301.12802 ,  655kb)
------------------------------------------------------------------------------
\\
arXiv:2302.01228
replaced with revised version Wed, 7 Jun 2023 08:48:04 GMT   (921kb,D)

Title: Dual Propagation: Accelerating Contrastive Hebbian Learning with Dyadic
 Neurons
Authors: Rasmus H{\o}ier, D. Staudt, Christopher Zach
Categories: cs.LG
Comments: Added reflections on biological plausibility and results comparisons
 to state-of-the-art versions of equilibrium propagation and difference target
 propagation
\\ ( https://arxiv.org/abs/2302.01228 ,  921kb)
------------------------------------------------------------------------------
\\
arXiv:2302.01633
replaced with revised version Wed, 7 Jun 2023 13:54:02 GMT   (2203kb,D)

Title: Convergence Analysis of Sequencial Split Learning on Heterogeneous Data
Authors: Yipeng Li and Xinchen Lyu
Categories: cs.LG
\\ ( https://arxiv.org/abs/2302.01633 ,  2203kb)
------------------------------------------------------------------------------
\\
arXiv:2302.02209
replaced with revised version Wed, 7 Jun 2023 15:46:12 GMT   (55kb)

Title: A Theory of Link Prediction via Relational Weisfeiler-Leman
Authors: Xingyue Huang, Miguel Romero Orth, \.Ismail \.Ilkan Ceylan, Pablo
 Barcel\'o
Categories: cs.LG cs.AI
\\ ( https://arxiv.org/abs/2302.02209 ,  55kb)
------------------------------------------------------------------------------
\\
arXiv:2302.02502
replaced with revised version Tue, 6 Jun 2023 20:08:59 GMT   (7696kb,D)

Title: Rethinking Robust Contrastive Learning from the Adversarial Perspective
Authors: Fatemeh Ghofrani, Mehdi Yaghouti, Pooyan Jamshidi
Categories: cs.LG cs.CV
\\ ( https://arxiv.org/abs/2302.02502 ,  7696kb)
------------------------------------------------------------------------------
\\
arXiv:2302.02713
replaced with revised version Wed, 7 Jun 2023 06:53:51 GMT   (3115kb,D)

Title: Flat Seeking Bayesian Neural Networks
Authors: Van-Anh Nguyen, Tung-Long Vuong, Hoang Phan, Thanh-Toan Do, Dinh
 Phung, Trung Le
Categories: cs.LG cs.IT math.IT
Comments: Under review
\\ ( https://arxiv.org/abs/2302.02713 ,  3115kb)
------------------------------------------------------------------------------
\\
arXiv:2302.03542
replaced with revised version Wed, 7 Jun 2023 11:51:35 GMT   (198kb,D)

Title: Two Losses Are Better Than One: Faster Optimization Using a Cheaper
 Proxy
Authors: Blake Woodworth (SIERRA), Konstantin Mishchenko, Francis Bach (SIERRA,
 PSL)
Categories: cs.LG math.OC
\\ ( https://arxiv.org/abs/2302.03542 ,  198kb)
------------------------------------------------------------------------------
\\
arXiv:2302.07011
replaced with revised version Wed, 7 Jun 2023 09:03:01 GMT   (10188kb,D)

Title: A Modern Look at the Relationship between Sharpness and Generalization
Authors: Maksym Andriushchenko, Francesco Croce, Maximilian M\"uller, Matthias
 Hein, Nicolas Flammarion
Categories: cs.LG
Comments: The camera-ready version (accepted at ICML 2023)
\\ ( https://arxiv.org/abs/2302.07011 ,  10188kb)
------------------------------------------------------------------------------
\\
arXiv:2302.07221
replaced with revised version Wed, 7 Jun 2023 13:11:24 GMT   (255kb,D)

Title: On the Role of Randomization in Adversarially Robust Classification
Authors: Lucas Gnecco-Heredia, Yann Chevaleyre, Benjamin Negrevergne, Laurent
 Meunier, Muni Sreenivas Pydi
Categories: cs.LG
Comments: 9 pages + bibliography and appendix, 2 figures. This is a replacement
 with important changes, including a refinement of the main result in the last
 paper and a new section on passing from deterministic to randomized
\\ ( https://arxiv.org/abs/2302.07221 ,  255kb)
------------------------------------------------------------------------------
\\
arXiv:2302.07348
replaced with revised version Wed, 7 Jun 2023 00:09:34 GMT   (183kb,D)

Title: Cliff-Learning
Authors: Tony T. Wang, Igor Zablotchi, Nir Shavit, Jonathan S. Rosenfeld
Categories: cs.LG cs.AI stat.ML
Comments: 16 pages; v2 updates: improved layout, added acknowledgements
\\ ( https://arxiv.org/abs/2302.07348 ,  183kb)
------------------------------------------------------------------------------
\\
arXiv:2302.08077
replaced with revised version Wed, 7 Jun 2023 12:33:50 GMT   (1762kb,D)

Title: Group Fairness with Uncertainty in Sensitive Attributes
Authors: Abhin Shah, Maohao Shen, Jongha Jon Ryu, Subhro Das, Prasanna
 Sattigeri, Yuheng Bu, and Gregory W. Wornell
Categories: cs.LG
\\ ( https://arxiv.org/abs/2302.08077 ,  1762kb)
------------------------------------------------------------------------------
\\
arXiv:2303.01433
replaced with revised version Tue, 6 Jun 2023 23:22:16 GMT   (7345kb,D)

Title: Do Machine Learning Models Learn Statistical Rules Inferred from Data?
Authors: Aaditya Naik, Yinjun Wu, Mayur Naik, Eric Wong
Categories: cs.LG cs.AI
\\ ( https://arxiv.org/abs/2303.01433 ,  7345kb)
------------------------------------------------------------------------------
\\
arXiv:2303.02535
replaced with revised version Tue, 6 Jun 2023 23:34:01 GMT   (17443kb,D)

Title: Streaming Active Learning with Deep Neural Networks
Authors: Akanksha Saran, Safoora Yousefi, Akshay Krishnamurthy, John Langford,
 Jordan T. Ash
Categories: cs.LG
Comments: ICML 2023
\\ ( https://arxiv.org/abs/2303.02535 ,  17443kb)
------------------------------------------------------------------------------
\\
arXiv:2303.02691
replaced with revised version Wed, 7 Jun 2023 06:44:28 GMT   (309kb,D)

Title: Revisiting Weighted Strategy for Non-stationary Parametric Bandits
Authors: Jing Wang, Peng Zhao, Zhi-Hua Zhou
Categories: cs.LG stat.ML
Comments: AISTATS 2023
\\ ( https://arxiv.org/abs/2303.02691 ,  309kb)
------------------------------------------------------------------------------
\\
arXiv:2303.04562
replaced with revised version Wed, 7 Jun 2023 15:34:38 GMT   (7852kb,D)

Title: Extrapolative Controlled Sequence Generation via Iterative Refinement
Authors: Vishakh Padmakumar, Richard Yuanzhe Pang, He He, Ankur P. Parikh
Categories: cs.LG cs.CL q-bio.QM
Comments: ICML 2023 - Camera Ready Version
\\ ( https://arxiv.org/abs/2303.04562 ,  7852kb)
------------------------------------------------------------------------------
\\
arXiv:2303.11249
replaced with revised version Wed, 7 Jun 2023 05:20:40 GMT   (1284kb,D)

Title: What Makes Data Suitable for a Locally Connected Neural Network? A
 Necessary and Sufficient Condition Based on Quantum Entanglement
Authors: Yotam Alexander, Nimrod De La Vega, Noam Razin, Nadav Cohen
Categories: cs.LG cs.AI quant-ph
\\ ( https://arxiv.org/abs/2303.11249 ,  1284kb)
------------------------------------------------------------------------------
\\
arXiv:2303.14068
replaced with revised version Wed, 7 Jun 2023 00:23:57 GMT   (5629kb,D)

Title: A CNN-LSTM Architecture for Marine Vessel Track Association Using
 Automatic Identification System (AIS) Data
Authors: Md Asif Bin Syed and Imtiaz Ahmed
Categories: cs.LG
Comments: No results has been changed, Changed Figures, increased the
 resolution of the figures, changed slightly in the description in section
 3.3.3
\\ ( https://arxiv.org/abs/2303.14068 ,  5629kb)
------------------------------------------------------------------------------
\\
arXiv:2303.17727
replaced with revised version Tue, 6 Jun 2023 18:33:35 GMT   (2632kb,D)

Title: BOLT: An Automated Deep Learning Framework for Training and Deploying
 Large-Scale Search and Recommendation Models on Commodity CPU Hardware
Authors: Nicholas Meisburger, Vihan Lakshman, Benito Geordie, Joshua Engels,
 David Torres Ramos, Pratik Pranav, Benjamin Coleman, Benjamin Meisburger,
 Shubh Gupta, Yashwanth Adunukota, Tharun Medini, Anshumali Shrivastava
Categories: cs.LG
Comments: 6 pages, 5 tables, 3 figures
\\ ( https://arxiv.org/abs/2303.17727 ,  2632kb)
------------------------------------------------------------------------------
\\
arXiv:2304.03392
replaced with revised version Tue, 6 Jun 2023 22:57:41 GMT   (1174kb,D)

Title: Personalising Digital Health Behaviour Change Interventions using
 Machine Learning and Domain Knowledge
Authors: Aneta Lisowska, Szymon Wilk, Mor Peleg
Categories: cs.LG cs.AI
Comments: 8 pages,3 figures, Knowledge Representation for Health Care (HR4HC)
 2023
\\ ( https://arxiv.org/abs/2304.03392 ,  1174kb)
------------------------------------------------------------------------------
\\
arXiv:2304.13840
replaced with revised version Wed, 7 Jun 2023 09:33:04 GMT   (756kb,D)

Title: A Deep Learning Framework for Verilog Autocompletion Towards Design and
 Verification Automation
Authors: Enrique Dehaerne and Bappaditya Dey and Sandip Halder and Stefan De
 Gendt
Categories: cs.LG cs.SE
Comments: Updated text to correct language errors and added a link to
 supplementary code and data
 (https://github.com/99EnriqueD/verilog_autocompletion). 6 pages, 3 figures, 4
 tables. To be presented as a WIP poster at DAC 2023
ACM-class: I.2.2
\\ ( https://arxiv.org/abs/2304.13840 ,  756kb)
------------------------------------------------------------------------------
\\
arXiv:2305.02757
replaced with revised version Wed, 7 Jun 2023 03:06:16 GMT   (351kb,D)

Title: Multi-Domain Learning From Insufficient Annotations
Authors: Rui He, Shengcai Liu, Jiahao Wu, Shan He, Ke Tang
Categories: cs.LG
Comments: 8 pages, 11 figures
\\ ( https://arxiv.org/abs/2305.02757 ,  351kb)
------------------------------------------------------------------------------
\\
arXiv:2305.11930
replaced with revised version Wed, 7 Jun 2023 14:25:19 GMT   (1577kb,D)

Title: PyTorch Hyperparameter Tuning - A Tutorial for spotPython
Authors: Thomas Bartz-Beielstein
Categories: cs.LG cs.AI cs.NA math.NA
Comments: Refers to spotPython version 0.2.15
MSC-class: 68T07
ACM-class: A.1; B.8.0; G.1.6; G.4; I.2.8
\\ ( https://arxiv.org/abs/2305.11930 ,  1577kb)
------------------------------------------------------------------------------
\\
arXiv:2305.19903
replaced with revised version Wed, 7 Jun 2023 13:07:52 GMT   (3997kb,D)

Title: Improving Expressivity of GNNs with Subgraph-specific Factor Embedded
 Normalization
Authors: Kaixuan Chen and Shunyu Liu and Tongtian Zhu and Tongya Zheng and
 Haofei Zhang and Zunlei Feng and Jingwen Ye and Mingli Song
Categories: cs.LG cs.AI
Comments: 13 pages, 7 figures
\\ ( https://arxiv.org/abs/2305.19903 ,  3997kb)
------------------------------------------------------------------------------
\\
arXiv:2306.00088
replaced with revised version Wed, 7 Jun 2023 04:25:10 GMT   (1016kb,D)

Title: Auto-Differentiation of Relational Computations for Very Large Scale
 Machine Learning
Authors: Yuxin Tang, Zhimin Ding, Dimitrije Jankov, Binhang Yuan, Daniel
 Bourgeois, Chris Jermaine
Categories: cs.LG cs.DB
Comments: ICML 2023
\\ ( https://arxiv.org/abs/2306.00088 ,  1016kb)
------------------------------------------------------------------------------
\\
arXiv:2306.00390
replaced with revised version Wed, 7 Jun 2023 13:07:38 GMT   (1442kb,D)

Title: Learning Gaussian Mixture Representations for Tensor Time Series
 Forecasting
Authors: Jiewen Deng, Jinliang Deng, Renhe Jiang, Xuan Song
Categories: cs.LG
Comments: Accepted by IJCAI 2023 Main Track
\\ ( https://arxiv.org/abs/2306.00390 ,  1442kb)
------------------------------------------------------------------------------
\\
arXiv:2306.01204
replaced with revised version Wed, 7 Jun 2023 00:05:25 GMT   (2754kb)

Title: Physics-informed UNets for Discovering Hidden Elasticity in
 Heterogeneous Materials
Authors: Ali Kamali, Kaveh Laksari
Categories: cs.LG cond-mat.soft
Comments: 25 pages, 9 figures
\\ ( https://arxiv.org/abs/2306.01204 ,  2754kb)
------------------------------------------------------------------------------
\\
arXiv:2306.01951
replaced with revised version Wed, 7 Jun 2023 16:12:13 GMT   (3224kb,D)

Title: GAD-NR: Graph Anomaly Detection via Neighborhood Reconstruction
Authors: Amit Roy, Juan Shu, Jia Li, Carl Yang, Olivier Elshocht, Jeroen Smeets
 and Pan Li
Categories: cs.LG
\\ ( https://arxiv.org/abs/2306.01951 ,  3224kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02688
replaced with revised version Wed, 7 Jun 2023 05:30:30 GMT   (923kb,D)

Title: Meta-SAGE: Scale Meta-Learning Scheduled Adaptation with Guided
 Exploration for Mitigating Scale Shift on Combinatorial Optimization
Authors: Jiwoo Son, Minsu Kim, Hyeonah Kim, Jinkyoo Park
Categories: cs.LG stat.ML
Comments: 18 pages, 9 figures, International Conference on Machine Learning
 (ICML) 2023
\\ ( https://arxiv.org/abs/2306.02688 ,  923kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02689
replaced with revised version Wed, 7 Jun 2023 05:34:34 GMT   (2106kb,D)

Title: Solving NP-hard Min-max Routing Problems as Sequential Generation with
 Equity Context
Authors: Jiwoo Son, Minsu Kim, Sanghyeok Choi, Jinkyoo Park
Categories: cs.LG math.OC stat.ML
Comments: 18 pages, 7 figures
\\ ( https://arxiv.org/abs/2306.02689 ,  2106kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02738
replaced with revised version Wed, 7 Jun 2023 10:42:23 GMT   (2183kb,D)

Title: A Large-Scale Study of Probabilistic Calibration in Neural Network
 Regression
Authors: Victor Dheur and Souhaib Ben Taieb
Categories: cs.LG
Comments: Accepted at the 40th International Conference on Machine Learning
 (ICML 2023)
\\ ( https://arxiv.org/abs/2306.02738 ,  2183kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03291
replaced with revised version Wed, 7 Jun 2023 00:35:34 GMT   (7071kb,D)

Title: Switching Autoregressive Low-rank Tensor Models
Authors: Hyun Dong Lee, Andrew Warrington, Joshua I. Glaser, Scott W. Linderman
Categories: cs.LG stat.ME stat.ML
\\ ( https://arxiv.org/abs/2306.03291 ,  7071kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03341
replaced with revised version Wed, 7 Jun 2023 00:27:45 GMT   (1677kb,D)

Title: Inference-Time Intervention: Eliciting Truthful Answers from a Language
 Model
Authors: Kenneth Li, Oam Patel, Fernanda Vi\'egas, Hanspeter Pfister, Martin
 Wattenberg
Categories: cs.LG cs.AI cs.CL
Comments: code: https://github.com/likenneth/honest_llama
\\ ( https://arxiv.org/abs/2306.03341 ,  1677kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03360
replaced with revised version Wed, 7 Jun 2023 11:39:52 GMT   (2764kb,D)

Title: Vid2Act: Activate Offline Videos for Visual RL
Authors: Minting Pan, Yitao Zheng, Wendong Zhang, Yunbo Wang, Xiaokang Yang
Categories: cs.LG cs.AI cs.RO
\\ ( https://arxiv.org/abs/2306.03360 ,  2764kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03833
replaced with revised version Wed, 7 Jun 2023 14:36:30 GMT   (2397kb)

Title: Patient Dropout Prediction in Virtual Health: A Multimodal Dynamic
 Knowledge Graph and Text Mining Approach
Authors: Shuang Geng, Wenli Zhang, Jiaheng Xie, Gemin Liang, Ben Niu
Categories: cs.LG
MSC-class: K.5
ACM-class: H.4.m
\\ ( https://arxiv.org/abs/2306.03833 ,  2397kb)
------------------------------------------------------------------------------
\\
arXiv:2302.04445
replaced with revised version Wed, 7 Jun 2023 04:06:53 GMT   (2438kb,D)

Title: Quantum Multi-Agent Actor-Critic Networks for Cooperative Mobile Access
 in Multi-UAV Systems
Authors: Chanyoung Park, Won Joon Yun, Jae Pyoung Kim, Tiago Koketsu Rodrigues,
 Soohyun Park, Soyi Jung, and Joongheon Kim
Categories: cs.MA cs.AI cs.LG
Comments: 16 pages, 9 figures
\\ ( https://arxiv.org/abs/2302.04445 ,  2438kb)
------------------------------------------------------------------------------
\\
arXiv:2304.13383
replaced with revised version Wed, 7 Jun 2023 11:33:22 GMT   (5811kb,D)

Title: N$\text{A}^\text{2}$Q: Neural Attention Additive Model for Interpretable
 Multi-Agent Q-Learning
Authors: Zichuan Liu, Yuanyang Zhu, Chunlin Chen
Categories: cs.MA
\\ ( https://arxiv.org/abs/2304.13383 ,  5811kb)
------------------------------------------------------------------------------
\\
arXiv:2209.11808
replaced with revised version Tue, 6 Jun 2023 23:19:30 GMT   (37032kb,D)

Title: Nonlinear Model Predictive Control of a 3D Hopping Robot: Leveraging Lie
 Group Integrators for Dynamically Stable Behaviors
Authors: Noel Csomay-Shanklin, Victor D. Dorobantu, and Aaron D. Ames
Categories: cs.RO
Comments: 7 pages, 7 figures, submitted to ICRA 2023
\\ ( https://arxiv.org/abs/2209.11808 ,  37032kb)
------------------------------------------------------------------------------
\\
arXiv:2305.19111
replaced with revised version Wed, 7 Jun 2023 13:14:23 GMT   (1583kb,D)

Title: GAN-MPC: Training Model Predictive Controllers with Parameterized Cost
 Functions using Demonstrations from Non-identical Experts
Authors: Returaj Burnwal, Anirban Santara, Nirav P. Bhatt, Balaraman Ravindran,
 Gaurav Aggarwal
Categories: cs.RO cs.AI cs.LG
Comments: Recipient of the best paper award at RBCDSAI-DAI 2023, IIT Madras
 (https://rbcdsai.iitm.ac.in/DAI-2023/)
\\ ( https://arxiv.org/abs/2305.19111 ,  1583kb)
------------------------------------------------------------------------------
\\
arXiv:2205.04521
replaced with revised version Wed, 7 Jun 2023 03:57:24 GMT   (196kb,D)

Title: Implicit Particle Filtering via a Bank of Nonlinear Kalman Filters
Authors: Iman Askari, Mulugeta A. Haile, Xuemin Tu, Huazhen Fang
Categories: eess.SY cs.SY
Comments: To appear in Automatica
Journal-ref: Automatica, 145, (2022), 110469
DOI: 10.1016/j.automatica.2022.110469
\\ ( https://arxiv.org/abs/2205.04521 ,  196kb)
------------------------------------------------------------------------------
\\
arXiv:2302.05491
replaced with revised version Tue, 6 Jun 2023 18:48:37 GMT   (925kb)

Title: An Overview of Uncertain Control Co-Design Formulations
Authors: Saeed Azad and Daniel R.Herber
Categories: eess.SY cs.SY
Comments: 20 pages; 8 Figures
\\ ( https://arxiv.org/abs/2302.05491 ,  925kb)
------------------------------------------------------------------------------
\\
arXiv:2302.14296
replaced with revised version Tue, 6 Jun 2023 21:05:19 GMT   (511kb,D)

Title: Discrete-time Optimal Covariance Steering via Semidefinite Programming
Authors: George Rapakoulias and Panagiotis Tsiotras
Categories: eess.SY cs.SY
\\ ( https://arxiv.org/abs/2302.14296 ,  511kb)
------------------------------------------------------------------------------
\\
arXiv:2303.03133
replaced with revised version Wed, 7 Jun 2023 11:59:58 GMT   (184kb,D)

Title: Generalized Filippov solutions for systems with prescribed-time
 convergence
Authors: Richard Seeber
Categories: eess.SY cs.SY math.DS
\\ ( https://arxiv.org/abs/2303.03133 ,  184kb)
------------------------------------------------------------------------------
\\
arXiv:2111.10635
replaced with revised version Wed, 7 Jun 2023 13:33:11 GMT   (4366kb,D)

Title: HeterPS: Distributed Deep Learning With Reinforcement Learning Based
 Scheduling in Heterogeneous Environments
Authors: Ji Liu, Zhihua Wu, Dianhai Yu, Yanjun Ma, Danlei Feng, Minxu Zhang,
 Xinxuan Wu, Xuefeng Yao, Dejing Dou
Categories: cs.DC cs.AI cs.LG cs.SY eess.SY
Comments: 14 pages, 11 figures, 2 tables; To appear in Future Generation
 Computer Systems (FGCS)
\\ ( https://arxiv.org/abs/2111.10635 ,  4366kb)
------------------------------------------------------------------------------
\\
arXiv:2202.03033
replaced with revised version Wed, 7 Jun 2023 07:02:40 GMT   (6013kb,D)

Title: Human Stress Assessment: A Comprehensive Review of Methods Using
 Wearable Sensors and Non-wearable Techniques
Authors: Aamir Arsalan, Muhammad Majid, Imran Fareed Nizami, Waleed Manzoor,
 Syed Muhammad Anwar, and Jihyoung Ryu
Categories: cs.HC cs.AI
Comments: Submitted in MDPI Sensors
\\ ( https://arxiv.org/abs/2202.03033 ,  6013kb)
------------------------------------------------------------------------------
\\
arXiv:2203.09280
replaced with revised version Wed, 7 Jun 2023 10:20:26 GMT   (4394kb,D)

Title: Knowledge Graph Embedding Methods for Entity Alignment: An Experimental
 Review
Authors: Nikolaos Fanourakis, Vasilis Efthymiou, Dimitris Kotzinos, Vassilis
 Christophides
Categories: cs.DB cs.AI
Comments: This preprint has not undergone peer review (when applicable) or any
 post-submission improvements or corrections. The Version of Record of this
 article is published in Data Mining and Knowledge Discovery, and is available
 online at https://doi.org/10.1007/s10618-023-00941-9
\\ ( https://arxiv.org/abs/2203.09280 ,  4394kb)
------------------------------------------------------------------------------
\\
arXiv:2203.12026
replaced with revised version Wed, 7 Jun 2023 09:24:31 GMT   (3654kb,D)

Title: Machine Learning Testing in an ADAS Case Study Using
 Simulation-Integrated Bio-Inspired Search-Based Testing
Authors: Mahshid Helali Moghadam, Markus Borg, Mehrdad Saadatmand, Seyed
 Jalaleddin Mousavirad, Markus Bohlin, Bj\"orn Lisper
Categories: cs.SE cs.AI cs.LG cs.NE
Comments: Accepted for publication in Journal Of Software: Evolution And
 Process
\\ ( https://arxiv.org/abs/2203.12026 ,  3654kb)
------------------------------------------------------------------------------
\\
arXiv:2207.08230
replaced with revised version Wed, 7 Jun 2023 12:25:00 GMT   (245kb)

Title: A Context-Sensitive Word Embedding Approach for The Detection of Troll
 Tweets
Authors: Seyhmus Yilmaz and Sultan Zavrak
Categories: cs.CL cs.AI
ACM-class: I.2; I.2.7
\\ ( https://arxiv.org/abs/2207.08230 ,  245kb)
------------------------------------------------------------------------------
\\
arXiv:2208.09770
replaced with revised version Wed, 7 Jun 2023 17:13:29 GMT   (7394kb,D)

Title: Z-Code++: A Pre-trained Language Model Optimized for Abstractive
 Summarization
Authors: Pengcheng He, Baolin Peng, Liyang Lu, Song Wang, Jie Mei, Yang Liu,
 Ruochen Xu, Hany Hassan Awadalla, Yu Shi, Chenguang Zhu, Wayne Xiong, Michael
 Zeng, Jianfeng Gao, Xuedong Huang
Categories: cs.CL cs.AI
Comments: 16 pages, 3 figures. Accepted as long paper in main conference of ACL
 2023
MSC-class: cs.CL, cs.GL
ACM-class: I.2; I.7
\\ ( https://arxiv.org/abs/2208.09770 ,  7394kb)
------------------------------------------------------------------------------
\\
arXiv:2209.12573
replaced with revised version Wed, 7 Jun 2023 10:24:37 GMT   (274kb,D)

Title: Digital Audio Forensics: Blind Human Voice Mimicry Detection
Authors: Sahar Al Ajmi, Khizar Hayat, Alaa M. Al Obaidi, Naresh Kumar, Munaf
 Najmuldeen and Baptiste Magnier
Categories: cs.SD cs.AI cs.LG cs.MM cs.NE eess.AS
Comments: 14 pages, 4 figures (6 if you count subfigures), 2 tables
MSC-class: 68T05, 68T07, 68T10
ACM-class: I.2; I.5; I.m
\\ ( https://arxiv.org/abs/2209.12573 ,  274kb)
------------------------------------------------------------------------------
\\
arXiv:2210.09440
replaced with revised version Wed, 7 Jun 2023 10:18:44 GMT   (7096kb,D)

Title: Using Bottleneck Adapters to Identify Cancer in Clinical Notes under
 Low-Resource Constraints
Authors: Omid Rohanian, Hannah Jauncey, Mohammadmahdi Nouriborji, Vinod Kumar
 Chauhan, Bronner P. Gon\c{c}alves, Christiana Kartsonaki, ISARIC Clinical
 Characterisation Group, Laura Merson, David Clifton
Categories: cs.CL cs.AI
MSC-class: 68T50
ACM-class: I.2.7
\\ ( https://arxiv.org/abs/2210.09440 ,  7096kb)
------------------------------------------------------------------------------
\\
arXiv:2303.01586
replaced with revised version Wed, 7 Jun 2023 08:54:46 GMT   (35278kb,D)

Title: Alexa Arena: A User-Centric Interactive Platform for Embodied AI
Authors: Qiaozi Gao, Govind Thattai, Suhaila Shakiah, Xiaofeng Gao, Shreyas
 Pansare, Vasu Sharma, Gaurav Sukhatme, Hangjie Shi, Bofei Yang, Desheng
 Zheng, Lucy Hu, Karthika Arumugam, Shui Hu, Matthew Wen, Dinakar Guthy,
 Cadence Chung, Rohan Khanna, Osman Ipek, Leslie Ball, Kate Bland, Heather
 Rocker, Yadunandana Rao, Michael Johnston, Reza Ghanadan, Arindam Mandal,
 Dilek Hakkani Tur, Prem Natarajan
Categories: cs.HC cs.AI cs.RO
\\ ( https://arxiv.org/abs/2303.01586 ,  35278kb)
------------------------------------------------------------------------------
\\
arXiv:2303.17491
replaced with revised version Wed, 7 Jun 2023 17:50:44 GMT   (1575kb,D)

Title: Language Models can Solve Computer Tasks
Authors: Geunwoo Kim, Pierre Baldi, Stephen McAleer
Categories: cs.CL cs.AI cs.HC cs.LG
\\ ( https://arxiv.org/abs/2303.17491 ,  1575kb)
------------------------------------------------------------------------------
\\
arXiv:2304.07438
replaced with revised version Wed, 7 Jun 2023 08:23:55 GMT   (319kb,D)

Title: Tractable Control for Autoregressive Language Generation
Authors: Honghua Zhang, Meihua Dang, Nanyun Peng, Guy Van den Broeck
Categories: cs.CL cs.AI
\\ ( https://arxiv.org/abs/2304.07438 ,  319kb)
------------------------------------------------------------------------------
\\
arXiv:2305.07622
replaced with revised version Wed, 7 Jun 2023 17:55:58 GMT   (2454kb,D)

Title: PALR: Personalization Aware LLMs for Recommendation
Authors: Fan Yang, Zheng Chen, Ziyan Jiang, Eunah Cho, Xiaojiang Huang, Yanbin
 Lu
Categories: cs.IR cs.AI cs.CL
ACM-class: I.2.6; I.2.7
\\ ( https://arxiv.org/abs/2305.07622 ,  2454kb)
------------------------------------------------------------------------------
\\
arXiv:2305.13040
replaced with revised version Wed, 7 Jun 2023 16:04:30 GMT   (7844kb,D)

Title: SpokenWOZ: A Large-Scale Speech-Text Dataset for Spoken Task-Oriented
 Dialogue in Multiple Domains
Authors: Shuzheng Si, Wentao Ma, Haoyu Gao, Yuchuan Wu, Ting-En Lin, Yinpei
 Dai, Hangyu Li, Rui Yan, Fei Huang, Yongbin Li
Categories: cs.CL cs.AI
\\ ( https://arxiv.org/abs/2305.13040 ,  7844kb)
------------------------------------------------------------------------------
\\
arXiv:2305.16259
replaced with revised version Wed, 7 Jun 2023 06:03:49 GMT   (1635kb,D)

Title: Neural Natural Language Processing for Long Texts: A Survey of the
 State-of-the-Art
Authors: Dimitrios Tsirmpas, Ioannis Gkionis, Ioannis Mademlis
Categories: cs.CL cs.AI
Comments: 51 pages, 2 figures, 168 citations
ACM-class: I.2.7
\\ ( https://arxiv.org/abs/2305.16259 ,  1635kb)
------------------------------------------------------------------------------
\\
arXiv:2305.18226
replaced with revised version Wed, 7 Jun 2023 11:43:44 GMT   (1854kb,D)

Title: HowkGPT: Investigating the Detection of ChatGPT-generated University
 Student Homework through Context-Aware Perplexity Analysis
Authors: Christoforos Vasilatos, Manaar Alam, Talal Rahwan, Yasir Zaki and
 Michail Maniatakos
Categories: cs.CL cs.AI
\\ ( https://arxiv.org/abs/2305.18226 ,  1854kb)
------------------------------------------------------------------------------
\\
arXiv:2306.00739
replaced with revised version Wed, 7 Jun 2023 07:23:56 GMT   (389kb,D)

Title: SQL-PaLM: Improved Large Language Model Adaptation for Text-to-SQL
Authors: Ruoxi Sun, Sercan O. Arik, Hootan Nakhost, Hanjun Dai, Rajarishi
 Sinha, Pengcheng Yin, Tomas Pfister
Categories: cs.CL cs.AI cs.DB
Comments: 16 pages
\\ ( https://arxiv.org/abs/2306.00739 ,  389kb)
------------------------------------------------------------------------------
\\
arXiv:2306.01981 (*cross-listing*)
replaced with revised version Wed, 7 Jun 2023 03:29:03 GMT   (485kb,D)

Title: SGEM: Test-Time Adaptation for Automatic Speech Recognition via
 Sequential-Level Generalized Entropy Minimization
Authors: Changhun Kim, Joonhyung Park, Hajin Shim and Eunho Yang
Categories: eess.AS cs.AI cs.LG
Comments: Accepted to INTERSPEECH 2023; Our code is available at
 $\href{https://github.com/drumpt/SGEM}{\text{here}}$
\\ ( https://arxiv.org/abs/2306.01981 ,  485kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02231
replaced with revised version Tue, 6 Jun 2023 23:04:34 GMT   (114kb,D)

Title: Fine-Tuning Language Models with Advantage-Induced Policy Alignment
Authors: Banghua Zhu, Hiteshi Sharma, Felipe Vieira Frujeri, Shi Dong,
 Chenguang Zhu, Michael I. Jordan, Jiantao Jiao
Categories: cs.CL cs.AI cs.LG cs.SY eess.SY
\\ ( https://arxiv.org/abs/2306.02231 ,  114kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03457
replaced with revised version Wed, 7 Jun 2023 05:24:25 GMT   (793kb,D)

Title: TwistList: Resources and Baselines for Tongue Twister Generation
Authors: Tyler Loakman, Chen Tang and Chenghua Lin
Categories: cs.CL cs.AI
Journal-ref: ACL 2023
\\ ( https://arxiv.org/abs/2306.03457 ,  793kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03763 (*cross-listing*)
replaced with revised version Wed, 7 Jun 2023 01:50:14 GMT   (241kb,D)

Title: ChatGPT Informed Graph Neural Network for Stock Movement Prediction
Authors: Zihan Chen, Lei Nico Zheng, Cheng Lu, Jialu Yuan, Di Zhu
Categories: q-fin.ST cs.AI cs.CL cs.LG q-fin.CP
Comments: Under Review. 10 pages, 2 figures
ACM-class: I.2.7; J.1
DOI: 10.2139/ssrn.4464002
\\ ( https://arxiv.org/abs/2306.03763 ,  241kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03872
replaced with revised version Wed, 7 Jun 2023 00:37:34 GMT   (402kb,D)

Title: Deductive Verification of Chain-of-Thought Reasoning
Authors: Zhan Ling, Yunhao Fang, Xuanlin Li, Zhiao Huang, Mingu Lee, Roland
 Memisevic and Hao Su
Categories: cs.CL cs.AI cs.LG
\\ ( https://arxiv.org/abs/2306.03872 ,  402kb)
------------------------------------------------------------------------------
\\
arXiv:2205.01676 (*cross-listing*)
replaced with revised version Tue, 6 Jun 2023 19:41:33 GMT   (4188kb,D)

Title: FundusQ-Net: a Regression Quality Assessment Deep Learning Algorithm for
 Fundus Images Quality Grading
Authors: Or Abramovich, Hadas Pizem, Jan Van Eijgen, Ilan Oren, Joshua Melamed,
 Ingeborg Stalmans, Eytan Z. Blumenthal and Joachim A. Behar
Categories: eess.IV cs.CV
Comments: 12 pages, 9 figures, published in Computer Methods and Programs in
 Biomedicine
ACM-class: I.2.10
Journal-ref: Computer Methods and Programs in Biomedicine, Volume 239,
 September 2023, 107522, ISSN 0169-2607
DOI: 10.1016/j.cmpb.2023.107522
\\ ( https://arxiv.org/abs/2205.01676 ,  4188kb)
------------------------------------------------------------------------------
\\
arXiv:2211.03759
replaced with revised version Wed, 7 Jun 2023 16:36:13 GMT   (43814kb,D)

Title: Easily Accessible Text-to-Image Generation Amplifies Demographic
 Stereotypes at Large Scale
Authors: Federico Bianchi, Pratyusha Kalluri, Esin Durmus, Faisal Ladhak, Myra
 Cheng, Debora Nozza, Tatsunori Hashimoto, Dan Jurafsky, James Zou, Aylin
 Caliskan
Categories: cs.CL cs.CV
Comments: FAccT 2023 paper. The published version is available at
 10.1145/3593013.3594095
DOI: 10.1145/3593013.3594095
\\ ( https://arxiv.org/abs/2211.03759 ,  43814kb)
------------------------------------------------------------------------------
\\
arXiv:2302.05195 (*cross-listing*)
replaced with revised version Wed, 7 Jun 2023 16:05:44 GMT   (33663kb,D)

Title: Self-supervised learning-based cervical cytology for the triage of
 HPV-positive women in resource-limited settings and low-data regime
Authors: Thomas Stegm\"uller, Christian Abbet, Behzad Bozorgtabar, Holly
 Clarke, Patrick Petignat, Pierre Vassilakos, and Jean-Philippe Thiran
Categories: eess.IV cs.CV
\\ ( https://arxiv.org/abs/2302.05195 ,  33663kb)
------------------------------------------------------------------------------
\\
arXiv:2303.05745 (*cross-listing*)
replaced with revised version Wed, 7 Jun 2023 11:38:27 GMT   (8295kb,D)

Title: Multi-site, Multi-domain Airway Tree Modeling
Authors: Minghui Zhang, Yangqian Wu, Hanxiao Zhang, Yulei Qin, Hao Zheng, Wen
 Tang, Corey Arnold, Chenhao Pei, Pengxin Yu, Yang Nan, Guang Yang, Simon
 Walsh, Dominic C. Marshall, Matthieu Komorowski, Puyang Wang, Dazhou Guo,
 Dakai Jin, Ya'nan Wu, Shuiqing Zhao, Runsheng Chang, Boyu Zhang, Xing Lu,
 Abdul Qayyum, Moona Mazher, Qi Su, Yonghuang Wu, Ying'ao Liu, Yufei Zhu,
 Jiancheng Yang, Ashkan Pakzad, Bojidar Rangelov, Raul San Jose Estepar,
 Carlos Cano Espinosa, Jiayuan Sun, Guang-Zhong Yang, Yun Gu
Categories: eess.IV cs.CV
Comments: 32 pages, 16 figures. Homepage: https://atm22.grand-challenge.org/.
 Submitted
\\ ( https://arxiv.org/abs/2303.05745 ,  8295kb)
------------------------------------------------------------------------------
\\
arXiv:2303.07852 (*cross-listing*)
replaced with revised version Wed, 7 Jun 2023 14:56:10 GMT   (5134kb,D)

Title: FPUS23: An Ultrasound Fetus Phantom Dataset with Deep Neural Network
 Evaluations for Fetus Orientations, Fetal Planes, and Anatomical Features
Authors: Bharath Srinivas Prabakaran and Paul Hamelmann and Erik Ostrowski and
 Muhammad Shafique
Categories: eess.IV cs.CV cs.LG
Comments: Accepted for Publication at IEEE Access
DOI: 10.1109/ACCESS.2023.3284315
\\ ( https://arxiv.org/abs/2303.07852 ,  5134kb)
------------------------------------------------------------------------------
\\
arXiv:2303.13933 (*cross-listing*)
replaced with revised version Tue, 6 Jun 2023 20:22:06 GMT   (3474kb,D)

Title: DisC-Diff: Disentangled Conditional Diffusion Model for Multi-Contrast
 MRI Super-Resolution
Authors: Ye Mao, Lan Jiang, Xi Chen, and Chao Li
Categories: eess.IV cs.CV
Comments: Early Accepted by MICCAI 2023
\\ ( https://arxiv.org/abs/2303.13933 ,  3474kb)
------------------------------------------------------------------------------
\\
arXiv:2304.04027 (*cross-listing*)
replaced with revised version Wed, 7 Jun 2023 06:25:40 GMT   (19318kb,D)

Title: Estimating 3D Dental Structures using Simulated Panoramic Radiographs
 and Neural Ray Tracing
Authors: Sihwa Park, Seongjun Kim, Doeyoung Kwon, Yohan Jang, In-Seok Song,
 Seungjun Baek
Categories: eess.IV cs.CV cs.LG
Comments: 16 pages, 11 figures
\\ ( https://arxiv.org/abs/2304.04027 ,  19318kb)
------------------------------------------------------------------------------
\\
arXiv:2305.04294 (*cross-listing*)
replaced with revised version Wed, 7 Jun 2023 04:59:12 GMT   (0kb,I)

Title: PELE scores: Pelvic X-ray Landmark Detection by Pelvis Extraction and
 Enhancement
Authors: Zhen Huang, Han Li, Shitong Shao, Heqin Zhu, Huijie Hu, Zhiwei Cheng,
 Jianji Wang, and S.Kevin Zhou
Categories: eess.IV cs.CV
Comments: will revise it and resubmit it again later
\\ ( https://arxiv.org/abs/2305.04294 ,  0kb)
------------------------------------------------------------------------------
\\
arXiv:2306.00421 (*cross-listing*)
replaced with revised version Wed, 7 Jun 2023 14:38:06 GMT   (2062kb,D)

Title: Introduction to Medical Imaging Informatics
Authors: Md. Zihad Bin Jahangir, Ruksat Hossain, Riadul Islam, MD Abdullah Al
 Nasim, Md. Mahim Anjum Haque, Md Jahangir Alam, Sajedul Talukder
Categories: eess.IV cs.CV cs.LG
Comments: 18 pages, 11 figures, 2 tables; Acceptance of the chapter for the
 Springer book "Data-driven approaches to medical imaging"
\\ ( https://arxiv.org/abs/2306.00421 ,  2062kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03619
replaced with revised version Wed, 7 Jun 2023 09:40:36 GMT   (613kb,D)

Title: Digitization of Pathology Labs: A Review of Lessons Learned
Authors: Lars Ole Schwen, Tim-Rasmus Kiehl, Rita Carvalho, Norman Zerbe,
 Andr\'e Homeyer
Categories: cs.HC cs.CV eess.IV
Comments: 22 pages, 1 figure; corrected typo
\\ ( https://arxiv.org/abs/2306.03619 ,  613kb)
------------------------------------------------------------------------------
\\
arXiv:2002.10855 (*cross-listing*)
replaced with revised version Wed, 7 Jun 2023 08:51:11 GMT   (1188kb,D)

Title: Gaussian Hierarchical Latent Dirichlet Allocation: Bringing Polysemy
 Back
Authors: Takahiro Yoshida, Ryohei Hisano, Takaaki Ohnishi
Categories: stat.ML cs.LG
\\ ( https://arxiv.org/abs/2002.10855 ,  1188kb)
------------------------------------------------------------------------------
\\
arXiv:2110.05854 (*cross-listing*)
replaced with revised version Wed, 7 Jun 2023 04:45:38 GMT   (4084kb,D)

Title: A scalable and fast artificial neural network syndrome decoder for
 surface codes
Authors: Spiro Gicev, Lloyd C. L. Hollenberg, Muhammad Usman
Categories: quant-ph cs.ET cs.LG
Comments: 11 pages, 6 figures
\\ ( https://arxiv.org/abs/2110.05854 ,  4084kb)
------------------------------------------------------------------------------
\\
arXiv:2202.05098 (*cross-listing*)
replaced with revised version Wed, 7 Jun 2023 02:39:51 GMT   (1730kb,D)

Title: AD-NEGF: An End-to-End Differentiable Quantum Transport Simulator for
 Sensitivity Analysis and Inverse Problems
Authors: Yingzhanghao Zhou, Xiang Chen, Peng Zhang, Jun Wang, Lei Wang, Hong
 Guo
Categories: cond-mat.mes-hall cs.LG quant-ph
Comments: 13 pages including references
\\ ( https://arxiv.org/abs/2202.05098 ,  1730kb)
------------------------------------------------------------------------------
\\
arXiv:2205.12933 (*cross-listing*)
replaced with revised version Wed, 7 Jun 2023 10:13:20 GMT   (996kb,D)

Title: Boosting Tail Neural Network for Realtime Custom Keyword Spotting
Authors: Sihao Xue, Qianyao Shen, Guoqing Li
Categories: eess.AS cs.LG cs.SD
Comments: 4 pages, 8 figures, 2 tables
\\ ( https://arxiv.org/abs/2205.12933 ,  996kb)
------------------------------------------------------------------------------
\\
arXiv:2206.03992 (*cross-listing*)
replaced with revised version Tue, 6 Jun 2023 21:13:54 GMT   (2807kb,D)

Title: Neural Diffusion Processes
Authors: Vincent Dutordoir, Alan Saul, Zoubin Ghahramani, Fergus Simpson
Categories: stat.ML cs.LG
Comments: 23 pages, Proceedings of the 40th International Conference on Machine
 Learning, PMLR 202
\\ ( https://arxiv.org/abs/2206.03992 ,  2807kb)
------------------------------------------------------------------------------
\\
arXiv:2206.12543 (*cross-listing*)
replaced with revised version Wed, 7 Jun 2023 15:07:14 GMT   (278kb,D)

Title: A Fast, Well-Founded Approximation to the Empirical Neural Tangent
 Kernel
Authors: Mohamad Amin Mohamadi, Wonho Bae, Danica J. Sutherland
Categories: stat.ML cs.LG
Journal-ref: Published at ICML 2023
DOI: 10.48550/arXiv.2206.12543
\\ ( https://arxiv.org/abs/2206.12543 ,  278kb)
------------------------------------------------------------------------------
\\
arXiv:2207.02434
replaced with revised version Wed, 7 Jun 2023 04:51:48 GMT   (514kb)

Title: Early Discovery of Emerging Entities in Persian Twitter with Semantic
 Similarity
Authors: Shahin Yousefi, Mohsen Hooshmand, Mohsen Afsharchi
Categories: cs.CL cs.LG cs.SI
DOI: 10.1109/ICWR57742.2023.10139028
\\ ( https://arxiv.org/abs/2207.02434 ,  514kb)
------------------------------------------------------------------------------
\\
arXiv:2207.04600 (*cross-listing*)
replaced with revised version Wed, 7 Jun 2023 03:25:39 GMT   (3142kb,D)

Title: Optimal Clustering by Lloyd Algorithm for Low-Rank Mixture Model
Authors: Zhongyuan Lyu and Dong Xia
Categories: math.ST cs.IT cs.LG math.IT stat.ME stat.TH
\\ ( https://arxiv.org/abs/2207.04600 ,  3142kb)
------------------------------------------------------------------------------
\\
arXiv:2212.02457 (*cross-listing*)
replaced with revised version Wed, 7 Jun 2023 05:00:40 GMT   (61kb,D)

Title: Blessings and Curses of Covariate Shifts: Adversarial Learning Dynamics,
 Directional Convergence, and Equilibria
Authors: Tengyuan Liang
Categories: stat.ML cs.LG math.OC math.ST stat.TH
Comments: 22 pages, 2 figures
\\ ( https://arxiv.org/abs/2212.02457 ,  61kb)
------------------------------------------------------------------------------
\\
arXiv:2301.10937 (*cross-listing*)
replaced with revised version Wed, 7 Jun 2023 01:02:28 GMT   (9746kb,D)

Title: Super-Resolution Analysis via Machine Learning: A Survey for Fluid Flows
Authors: Kai Fukami, Koji Fukagata, Kunihiko Taira
Categories: physics.flu-dyn cs.LG physics.comp-ph
\\ ( https://arxiv.org/abs/2301.10937 ,  9746kb)
------------------------------------------------------------------------------
\\
arXiv:2301.12485 (*cross-listing*)
replaced with revised version Tue, 6 Jun 2023 21:54:16 GMT   (10561kb,D)

Title: Generating Novel, Designable, and Diverse Protein Structures by
 Equivariantly Diffusing Oriented Residue Clouds
Authors: Yeqing Lin, Mohammed AlQuraishi
Categories: q-bio.BM cs.LG
\\ ( https://arxiv.org/abs/2301.12485 ,  10561kb)
------------------------------------------------------------------------------
\\
arXiv:2301.13778 (*cross-listing*)
replaced with revised version Wed, 7 Jun 2023 09:07:48 GMT   (266kb,D)

Title: Differentially Private Distributed Bayesian Linear Regression with MCMC
Authors: Bar{\i}\c{s} Alparslan, Sinan Y{\i}ld{\i}r{\i}m, \c{S}. \.Ilker Birbil
Categories: stat.ML cs.LG stat.CO
Comments: 15 pages, 4 figures, code available at:
 https://github.com/sinanyildirim/Bayesian_DP_dist_LR
\\ ( https://arxiv.org/abs/2301.13778 ,  266kb)
------------------------------------------------------------------------------
\\
arXiv:2302.00860 (*cross-listing*)
replaced with revised version Tue, 6 Jun 2023 22:43:39 GMT   (112kb,D)

Title: Interventional and Counterfactual Inference with Diffusion Models
Authors: Patrick Chao, Patrick Bl\"obaum, Shiva Prasad Kasiviswanathan
Categories: stat.ML cs.LG stat.ME
\\ ( https://arxiv.org/abs/2302.00860 ,  112kb)
------------------------------------------------------------------------------
\\
arXiv:2302.02228 (*cross-listing*)
replaced with revised version Tue, 6 Jun 2023 21:50:52 GMT   (8774kb,D)

Title: Counterfactual Identifiability of Bijective Causal Models
Authors: Arash Nasr-Esfahany, Mohammad Alizadeh, Devavrat Shah
Categories: stat.ML cs.LG
\\ ( https://arxiv.org/abs/2302.02228 ,  8774kb)
------------------------------------------------------------------------------
\\
arXiv:2302.03162
replaced with revised version Tue, 6 Jun 2023 23:46:10 GMT   (457kb,D)

Title: Protecting Language Generation Models via Invisible Watermarking
Authors: Xuandong Zhao, Yu-Xiang Wang, Lei Li
Categories: cs.CR cs.CL cs.LG
Comments: ICML 2023
\\ ( https://arxiv.org/abs/2302.03162 ,  457kb)
------------------------------------------------------------------------------
\\
arXiv:2302.09738 (*cross-listing*)
replaced with revised version Wed, 7 Jun 2023 02:26:50 GMT   (939kb,D)

Title: Simplifying Momentum-based Positive-definite Submanifold Optimization
 with Applications to Deep Learning
Authors: Wu Lin, Valentin Duruisseaux, Melvin Leok, Frank Nielsen, Mohammad
 Emtiyaz Khan, Mark Schmidt
Categories: stat.ML cs.LG
Comments: ICML 2023
\\ ( https://arxiv.org/abs/2302.09738 ,  939kb)
------------------------------------------------------------------------------
\\
arXiv:2302.12235 (*cross-listing*)
replaced with revised version Tue, 6 Jun 2023 22:00:01 GMT   (552kb,D)

Title: Q-Flow: Generative Modeling for Differential Equations of Open Quantum
 Dynamics with Normalizing Flows
Authors: Owen Dugan, Peter Y. Lu, Rumen Dangovski, Di Luo, Marin Solja\v{c}i\'c
Categories: quant-ph cond-mat.dis-nn cond-mat.quant-gas cs.LG physics.comp-ph
Report-no: MIT-CTP/5533
\\ ( https://arxiv.org/abs/2302.12235 ,  552kb)
------------------------------------------------------------------------------
\\
arXiv:2303.04756 (*cross-listing*)
replaced with revised version Wed, 7 Jun 2023 15:57:30 GMT   (356kb,D)

Title: Meta-learning Control Variates: Variance Reduction with Limited Data
Authors: Zhuo Sun, Chris J. Oates, Fran\c{c}ois-Xavier Briol
Categories: stat.ME cs.LG stat.ML
Comments: Accepted for publication (with an oral presentation) at UAI 2023
\\ ( https://arxiv.org/abs/2303.04756 ,  356kb)
------------------------------------------------------------------------------
\\
arXiv:2304.13835
replaced with revised version Wed, 7 Jun 2023 14:53:55 GMT   (1464kb,D)

Title: Multi-Party Chat: Conversational Agents in Group Settings with Humans
 and Models
Authors: Jimmy Wei, Kurt Shuster, Arthur Szlam, Jason Weston, Jack Urbanek,
 Mojtaba Komeili
Categories: cs.CL cs.LG
\\ ( https://arxiv.org/abs/2304.13835 ,  1464kb)
------------------------------------------------------------------------------
\\
arXiv:2305.05089
replaced with revised version Wed, 7 Jun 2023 06:05:18 GMT   (83kb,D)

Title: Functional Equivalence and Path Connectivity of Reducible Hyperbolic
 Tangent Networks
Authors: Matthew Farrugia-Roberts (The University of Melbourne)
Categories: cs.NE cs.LG
Comments: 15 pages, 3 figures
\\ ( https://arxiv.org/abs/2305.05089 ,  83kb)
------------------------------------------------------------------------------
\\
arXiv:2305.09674
replaced with revised version Wed, 7 Jun 2023 07:56:11 GMT   (1586kb,D)

Title: Quantum Machine Learning for Malware Classification
Authors: Gr\'egoire Barru\'e and Tony Quertier
Categories: cs.CR cs.ET cs.LG quant-ph
\\ ( https://arxiv.org/abs/2305.09674 ,  1586kb)
------------------------------------------------------------------------------
\\
arXiv:2305.17341
replaced with revised version Wed, 7 Jun 2023 05:19:18 GMT   (150kb)

Title: Improved Privacy-Preserving PCA Using Space-optimized Homomorphic Matrix
 Multiplication
Authors: Xirong Ma
Categories: cs.CR cs.LG
\\ ( https://arxiv.org/abs/2305.17341 ,  150kb)
------------------------------------------------------------------------------
\\
arXiv:2305.18088 (*cross-listing*)
replaced with revised version Tue, 6 Jun 2023 22:11:29 GMT   (1349kb)

Title: Drug Repurposing Targeting COVID-19 3CL Protease using Molecular Docking
 and Machine Learning Regression Approach
Authors: Imra Aqeel, Abdul Majid
Categories: q-bio.BM cs.LG
Comments: 23 Pages
\\ ( https://arxiv.org/abs/2305.18088 ,  1349kb)
------------------------------------------------------------------------------
\\
arXiv:2305.18466
replaced with revised version Wed, 7 Jun 2023 06:21:30 GMT   (286kb,D)

Title: Test-Time Training on Nearest Neighbors for Large Language Models
Authors: Moritz Hardt and Yu Sun
Categories: cs.CL cs.LG
Comments: Corrected Figure 8. Code repository here:
 https://github.com/socialfoundations/tttlm
\\ ( https://arxiv.org/abs/2305.18466 ,  286kb)
------------------------------------------------------------------------------
\\
arXiv:2306.00674
replaced with revised version Wed, 7 Jun 2023 03:16:32 GMT   (1151kb)

Title: CRS-FL: Conditional Random Sampling for Communication-Efficient and
 Privacy-Preserving Federated Learning
Authors: Jianhua Wang, Xiaolin Chang, Jelena Mi\v{s}i\'c, Vojislav B.
 Mi\v{s}i\'c, Lin Li, and Yingying Yao
Categories: cs.CR cs.DC cs.LG
\\ ( https://arxiv.org/abs/2306.00674 ,  1151kb)
------------------------------------------------------------------------------
\\
arXiv:2306.00934
replaced with revised version Tue, 6 Jun 2023 22:42:53 GMT   (8832kb,D)

Title: Interpreting GNN-based IDS Detections Using Provenance Graph Structural
 Features
Authors: Kunal Mukherjee, Joshua Wiedemeier, Tianhao Wang, Muhyun Kim, Feng
 Chen, Murat Kantarcioglu and Kangkook Jee
Categories: cs.CR cs.LG
\\ ( https://arxiv.org/abs/2306.00934 ,  8832kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02349
replaced with revised version Wed, 7 Jun 2023 03:57:51 GMT   (402kb,D)

Title: bgGLUE: A Bulgarian General Language Understanding Evaluation Benchmark
Authors: Momchil Hardalov, Pepa Atanasova, Todor Mihaylov, Galia Angelova,
 Kiril Simov, Petya Osenova, Ves Stoyanov, Ivan Koychev, Preslav Nakov,
 Dragomir Radev
Categories: cs.CL cs.IR cs.LG
Comments: Accepted to ACL 2023 (Main Conference)
MSC-class: 68T50
ACM-class: F.2.2; I.2.7
Journal-ref: ACL 2023
\\ ( https://arxiv.org/abs/2306.02349 ,  402kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02715
replaced with revised version Wed, 7 Jun 2023 08:35:35 GMT   (311kb,D)

Title: Federated Deep Learning for Intrusion Detection in IoT Networks
Authors: Othmane Belarbi, Theodoros Spyridopoulos, Eirini Anthi, Ioannis
 Mavromatis, Pietro Carnelli, Aftab Khan
Categories: cs.CR cs.LG
Comments: 14 pages, 5 figues, 3 tables
\\ ( https://arxiv.org/abs/2306.02715 ,  311kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03025 (*cross-listing*)
replaced with revised version Tue, 6 Jun 2023 19:11:24 GMT   (1747kb)

Title: AI Techniques for Cone Beam Computed Tomography in Dentistry: Trends and
 Practices
Authors: Saba Sarwar, Suraiya Jabin
Categories: eess.IV cs.LG
Comments: Recent Advances in Electrical, Electronics & Digital Healthcare
 Technologies REEDCON 2023
ACM-class: I.5.1; I.4.6; I.4.7; I.4.8
\\ ( https://arxiv.org/abs/2306.03025 ,  1747kb)
%%%---%%%---%%%---%%%---%%%---%%%---%%%---%%%---%%%---%%%---%%%---%%%---%%%---
