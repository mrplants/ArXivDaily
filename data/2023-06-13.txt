------------------------------------------------------------------------------
------------------------------------------------------------------------------
Send any comments regarding submissions directly to submitter.
------------------------------------------------------------------------------
Archives at http://arxiv.org/
To unsubscribe, e-mail To: cs@arXiv.org, Subject: cancel
------------------------------------------------------------------------------
Submissions to:
Artificial Intelligence
Computer Vision and Pattern Recognition
Distributed, Parallel, and Cluster Computing
Computer Science and Game Theory
Machine Learning
Multiagent Systems
Robotics
Systems and Control
received from  Fri  9 Jun 23 18:00:00 GMT  to  Mon 12 Jun 23 18:00:00 GMT
------------------------------------------------------------------------------
------------------------------------------------------------------------------
\\
arXiv:2306.06130
Date: Thu, 8 Jun 2023 11:14:51 GMT   (4711kb,D)

Title: Towards Understanding the Interplay of Generative Artificial
 Intelligence and the Internet
Authors: Gonzalo Mart\'inez, Lauren Watson, Pedro Reviriego, Jos\'e Alberto
 Hern\'andez, Marc Juarez, Rik Sarkar
Categories: cs.AI cs.CV cs.LG
\\
 The rapid adoption of generative Artificial Intelligence (AI) tools that can
generate realistic images or text, such as DALL-E, MidJourney, or ChatGPT, have
put the societal impacts of these technologies at the center of public debate.
These tools are possible due to the massive amount of data (text and images)
that is publicly available through the Internet. At the same time, these
generative AI tools become content creators that are already contributing to
the data that is available to train future models. Therefore, future versions
of generative AI tools will be trained with a mix of human-created and
AI-generated content, causing a potential feedback loop between generative AI
and public data repositories. This interaction raises many questions: how will
future versions of generative AI tools behave when trained on a mixture of real
and AI generated data? Will they evolve and improve with the new data sets or
on the contrary will they degrade? Will evolution introduce biases or reduce
diversity in subsequent generations of generative AI tools? What are the
societal implications of the possible degradation of these models? Can we
mitigate the effects of this feedback loop? In this document, we explore the
effect of this interaction and report some initial results using simple
diffusion models trained with various image datasets. Our results show that the
quality and diversity of the generated images can degrade over time suggesting
that incorporating AI-created data can have undesired effects on future
versions of generative models.
\\ ( https://arxiv.org/abs/2306.06130 ,  4711kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06272
Date: Fri, 9 Jun 2023 21:54:13 GMT   (5510kb,D)

Title: A Domain-Independent Agent Architecture for Adaptive Operation in
 Evolving Open Worlds
Authors: Shiwali Mohan, Wiktor Piotrowski, Roni Stern, Sachin Grover, Sookyung
 Kim, Jacob Le, Johan De Kleer
Categories: cs.AI
Comments: Under review in Artificial Intelligence Journal - Open World Learning
 track
ACM-class: I.2.4; I.2.6
\\
 Model-based reasoning agents are ill-equipped to act in novel situations in
which their model of the environment no longer sufficiently represents the
world. We propose HYDRA - a framework for designing model-based agents
operating in mixed discrete-continuous worlds, that can autonomously detect
when the environment has evolved from its canonical setup, understand how it
has evolved, and adapt the agents' models to perform effectively. HYDRA is
based upon PDDL+, a rich modeling language for planning in mixed,
discrete-continuous environments. It augments the planning module with visual
reasoning, task selection, and action execution modules for closed-loop
interaction with complex environments. HYDRA implements a novel meta-reasoning
process that enables the agent to monitor its own behavior from a variety of
aspects. The process employs a diverse set of computational methods to maintain
expectations about the agent's own behavior in an environment. Divergences from
those expectations are useful in detecting when the environment has evolved and
identifying opportunities to adapt the underlying models. HYDRA builds upon
ideas from diagnosis and repair and uses a heuristics-guided search over model
changes such that they become competent in novel conditions. The HYDRA
framework has been used to implement novelty-aware agents for three diverse
domains - CartPole++ (a higher dimension variant of a classic control problem),
Science Birds (an IJCAI competition problem), and PogoStick (a specific problem
domain in Minecraft). We report empirical observations from these domains to
demonstrate the efficacy of various components in the novelty meta-reasoning
process.
\\ ( https://arxiv.org/abs/2306.06272 ,  5510kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06294
Date: Fri, 9 Jun 2023 22:53:16 GMT   (168kb,D)

Title: Explaining SAT Solving Using Causal Reasoning
Authors: Jiong Yang, Arijit Shaw, Teodora Baluta, Mate Soos, and Kuldeep S.
 Meel
Categories: cs.AI
Comments: 17 pages, 3 figures, to be published in SAT23
\\
 The past three decades have witnessed notable success in designing efficient
SAT solvers, with modern solvers capable of solving industrial benchmarks
containing millions of variables in just a few seconds. The success of modern
SAT solvers owes to the widely-used CDCL algorithm, which lacks comprehensive
theoretical investigation. Furthermore, it has been observed that CDCL solvers
still struggle to deal with specific classes of benchmarks comprising only
hundreds of variables, which contrasts with their widespread use in real-world
applications. Consequently, there is an urgent need to uncover the inner
workings of these seemingly weak yet powerful black boxes.
 In this paper, we present a first step towards this goal by introducing an
approach called CausalSAT, which employs causal reasoning to gain insights into
the functioning of modern SAT solvers. CausalSAT initially generates
observational data from the execution of SAT solvers and learns a structured
graph representing the causal relationships between the components of a SAT
solver. Subsequently, given a query such as whether a clause with low literals
blocks distance (LBD) has a higher clause utility, CausalSAT calculates the
causal effect of LBD on clause utility and provides an answer to the question.
We use CausalSAT to quantitatively verify hypotheses previously regarded as
"rules of thumb" or empirical findings such as the query above. Moreover,
CausalSAT can address previously unexplored questions, like which branching
heuristic leads to greater clause utility in order to study the relationship
between branching and clause management. Experimental evaluations using
practical benchmarks demonstrate that CausalSAT effectively fits the data,
verifies four "rules of thumb", and provides answers to three questions closely
related to implementing modern solvers.
\\ ( https://arxiv.org/abs/2306.06294 ,  168kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06499
Date: Sat, 10 Jun 2023 18:05:16 GMT   (1808kb)

Title: Defining and Explorting the Intelligence Space
Authors: Paul S. Rosenbloom
Categories: cs.AI cs.LG
Comments: May ultimately appear as a journal article and/or a book chapter
\\
 Intelligence is a difficult concept to define, despite many attempts at doing
so. Rather than trying to settle on a single definition, this article
introduces a broad perspective on what intelligence is, by laying out a cascade
of definitions that induces both a nested hierarchy of three levels of
intelligence and a wider-ranging space that is built around them and
approximations to them. Within this intelligence space, regions are identified
that correspond to both natural -- most particularly, human -- intelligence and
artificial intelligence (AI), along with the crossover notion of humanlike
intelligence. These definitions are then exploited in early explorations of
four more advanced, and likely more controversial, topics: the singularity,
generative AI, ethics, and intellectual property.
\\ ( https://arxiv.org/abs/2306.06499 ,  1808kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06770
Date: Sun, 11 Jun 2023 20:50:14 GMT   (4166kb,D)

Title: Improving Knowledge Extraction from LLMs for Robotic Task Learning
 through Agent Analysis
Authors: James R. Kirk Robert E. Wray Peter Lindes
Categories: cs.AI cs.HC cs.RO
Comments: 8 pages, 8 figures, 1 table, bibliography, appendix (30 pages total)
ACM-class: I.2.6; I.2.7
\\
 Large language models (LLMs) offer significant promise as a knowledge source
for robotic task learning. Prompt engineering has been shown to be effective
for eliciting knowledge from an LLM but alone is insufficient for acquiring
relevant, situationally grounded knowledge for an embodied robotic agent
learning novel tasks. We describe a cognitive-agent approach that extends and
complements prompt engineering, mitigating its limitations, and thus enabling a
robot to acquire new task knowledge matched to its native language
capabilities, embodiment, environment, and user preferences. The approach is to
increase the response space of LLMs and deploy general strategies, embedded
within the autonomous robot, to evaluate, repair, and select among candidate
responses produced by the LLM. We describe the approach and experiments that
show how a robot, by retrieving and evaluating a breadth of responses from the
LLM, can achieve >75% task completion in one-shot learning without user
oversight. The approach achieves 100% task completion when human oversight
(such as indication of preference) is provided, while greatly reducing how much
human oversight is needed.
\\ ( https://arxiv.org/abs/2306.06770 ,  4166kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06808
Date: Sun, 11 Jun 2023 23:53:29 GMT   (3016kb,D)

Title: Multi-Agent Reinforcement Learning Guided by Signal Temporal Logic
 Specifications
Authors: Jiangwei Wang, Shuo Yang, Ziyan An, Songyang Han, Zhili Zhang, Rahul
 Mangharam, Meiyi Ma, Fei Miao
Categories: cs.AI
\\
 There has been growing interest in deep reinforcement learning (DRL)
algorithm design, and reward design is one key component of DRL. Among the
various techniques, formal methods integrated with DRL have garnered
considerable attention due to their expressiveness and ability to define the
requirements for the states and actions of the agent. However, the literature
of Signal Temporal Logic (STL) in guiding multi-agent reinforcement learning
(MARL) reward design remains limited. In this paper, we propose a novel
STL-guided multi-agent reinforcement learning algorithm. The STL specifications
are designed to include both task specifications according to the objective of
each agent and safety specifications, and the robustness values of the STL
specifications are leveraged to generate rewards. We validate the advantages of
our method through empirical studies. The experimental results demonstrate
significant performance improvements compared to MARL without STL guidance,
along with a remarkable increase in the overall safety rate of the multi-agent
systems.
\\ ( https://arxiv.org/abs/2306.06808 ,  3016kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06821
Date: Mon, 12 Jun 2023 02:00:22 GMT   (1329kb)

Title: Towards end-to-end ASP computation
Authors: Taisuke Sato, Akihiro Takemura, Tatsumi Inoue
Categories: cs.AI
Comments: 29 pages, 9 figures
ACM-class: I.2.4
\\
 We propose an end-to-end approach for answer set programming (ASP) and linear
algebraically compute stable models satisfying given constraints. The idea is
to implement Lin-Zhao's theorem \cite{Lin04} together with constraints directly
in vector spaces as numerical minimization of a cost function constructed from
a matricized normal logic program, loop formulas in Lin-Zhao's theorem and
constraints, thereby no use of symbolic ASP or SAT solvers involved in our
approach. We also propose precomputation that shrinks the program size and
heuristics for loop formulas to reduce computational difficulty. We empirically
test our approach with programming examples including the 3-coloring and
Hamiltonian cycle problems. As our approach is purely numerical and only
contains vector/matrix operations, acceleration by parallel technologies such
as many-cores and GPUs is expected.
\\ ( https://arxiv.org/abs/2306.06821 ,  1329kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06841
Date: Mon, 12 Jun 2023 03:23:22 GMT   (1145kb,D)

Title: Leveraging Skill-to-Skill Supervision for Knowledge Tracing
Authors: Hyeondey Kim, Jinwoo Nam, Minjae Lee, Yun Jegal, Kyungwoo Song
Categories: cs.AI
Comments: AAAI2023 Artificial Intelligence for Education
\\
 Knowledge tracing plays a pivotal role in intelligent tutoring systems. This
task aims to predict the probability of students answering correctly to
specific questions. To do so, knowledge tracing systems should trace the
knowledge state of the students by utilizing their problem-solving history and
knowledge about the problems. Recent advances in knowledge tracing models have
enabled better exploitation of problem solving history. However, knowledge
about problems has not been studied, as well compared to students' answering
histories. Knowledge tracing algorithms that incorporate knowledge directly are
important to settings with limited data or cold starts. Therefore, we consider
the problem of utilizing skill-to-skill relation to knowledge tracing. In this
work, we introduce expert labeled skill-to-skill relationships. Moreover, we
also provide novel methods to construct a knowledge-tracing model to leverage
human experts' insight regarding relationships between skills. The results of
an extensive experimental analysis show that our method outperformed a baseline
Transformer model. Furthermore, we found that the extent of our model's
superiority was greater in situations with limited data, which allows a smooth
cold start of our model.
\\ ( https://arxiv.org/abs/2306.06841 ,  1145kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06924
Date: Mon, 12 Jun 2023 07:55:18 GMT   (8623kb,D)

Title: TASRA: A Taxonomy and Analysis of Societal-Scale Risks from AI
Authors: Andrew Critch and Stuart Russell
Categories: cs.AI cs.CR cs.CY cs.LG
MSC-class: 68T01
ACM-class: I.2.0
\\
 While several recent works have identified societal-scale and
extinction-level risks to humanity arising from artificial intelligence, few
have attempted an {\em exhaustive taxonomy} of such risks. Many exhaustive
taxonomies are possible, and some are useful -- particularly if they reveal new
risks or practical approaches to safety. This paper explores a taxonomy based
on accountability: whose actions lead to the risk, are the actors unified, and
are they deliberate? We also provide stories to illustrate how the various risk
types could each play out, including risks arising from unanticipated
interactions of many AI systems, as well as risks from deliberate misuse, for
which combined technical and policy solutions are indicated.
\\ ( https://arxiv.org/abs/2306.06924 ,  8623kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07012
Date: Mon, 12 Jun 2023 10:31:16 GMT   (2443kb,D)

Title: Generating Language Corrections for Teaching Physical Control Tasks
Authors: Megha Srivastava, Noah Goodman, Dorsa Sadigh
Categories: cs.AI cs.CL cs.HC cs.RO
Comments: International Conference on Machine Learning (ICML) 2023, 9 pages
\\
 AI assistance continues to help advance applications in education, from
language learning to intelligent tutoring systems, yet current methods for
providing students feedback are still quite limited. Most automatic feedback
systems either provide binary correctness feedback, which may not help a
student understand how to improve, or require hand-coding feedback templates,
which may not generalize to new domains. This can be particularly challenging
for physical control tasks, where the rich diversity in student behavior and
specialized domains make it challenging to leverage general-purpose assistive
tools for providing feedback. We design and build CORGI, a model trained to
generate language corrections for physical control tasks, such as learning to
ride a bike. CORGI takes in as input a pair of student and expert trajectories,
and then generates natural language corrections to help the student improve. We
collect and train CORGI over data from three diverse physical control tasks
(drawing, steering, and joint movement). Through both automatic and human
evaluations, we show that CORGI can (i) generate valid feedback for novel
student trajectories, (ii) outperform baselines on domains with novel control
dynamics, and (iii) improve student learning in an interactive drawing task.
\\ ( https://arxiv.org/abs/2306.07012 ,  2443kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07126
Date: Mon, 12 Jun 2023 14:01:38 GMT   (32kb)

Title: Argumentative Characterizations of (Extended) Disjunctive Logic Programs
Authors: Jesse Heyninck and Ofer Arieli
Categories: cs.AI
Comments: Under consideration in Theory and Practice of Logic Programming
 (TPLP)
\\
 This paper continues an established line of research about the relations
between argumentation theory, particularly assumption-based argumentation, and
different kinds of logic programs. In particular, we extend known result of
Caminada, Schultz and Toni by showing that assumption-based argumentation can
represent not only normal logic programs, but also disjunctive logic programs
and their extensions. For this, we consider some inference rules for
disjunction that the core logic of the argumentation frameworks should respect,
and show the correspondence to the handling of disjunctions in the heads of the
logic programs' rules.
\\ ( https://arxiv.org/abs/2306.07126 ,  32kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06113
Date: Thu, 1 Jun 2023 06:37:19 GMT   (34764kb,D)

Title: SAM-helps-Shadow:When Segment Anything Model meet shadow removal
Authors: Xiaofeng Zhang, Chaochen Gu, Shanying Zhu
Categories: cs.CV
\\
 The challenges surrounding the application of image shadow removal to
real-world images and not just constrained datasets like ISTD/SRD have
highlighted an urgent need for zero-shot learning in this field. In this study,
we innovatively adapted the SAM (Segment anything model) for shadow removal by
introducing SAM-helps-Shadow, effectively integrating shadow detection and
removal into a single stage. Our approach utilized the model's detection
results as a potent prior for facilitating shadow detection, followed by shadow
removal using a second-order deep unfolding network. The source code of
SAM-helps-Shadow can be obtained from
https://github.com/zhangbaijin/SAM-helps-Shadow.
\\ ( https://arxiv.org/abs/2306.06113 ,  34764kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06126
Date: Thu, 8 Jun 2023 07:33:05 GMT   (3995kb,D)

Title: Deep Learning Method for Object Tracking, Velocity Estimation and
 Projection of Sensor Data over Time
Authors: Marco Braun, Moritz Luszek, Mirko Meuter, Dominic Spata, Kevin Kollek
 and Anton Kummert
Categories: cs.CV cs.LG
Comments: Preprint submitted to 2022 IEEE 25th International Conference on
 Intelligent Transportation Systems (ITSC), Macau, China, 7 pages
DOI: 10.1109/ITSC55140.2022.9921760
\\
 Current Deep Learning methods for environment segmentation and velocity
estimation rely on Convolutional Recurrent Neural Networks to exploit
spatio-temporal relationships within obtained sensor data. These approaches
derive scene dynamics implicitly by correlating novel input and memorized data
utilizing ConvNets. We show how ConvNets suffer from architectural restrictions
for this task. Based on these findings, we then provide solutions to various
issues on exploiting spatio-temporal correlations in a sequence of sensor
recordings by presenting a novel Recurrent Neural Network unit utilizing
Transformer mechanisms. Within this unit, object encodings are tracked across
consecutive frames by correlating key-query pairs derived from sensor inputs
and memory states, respectively. We then use resulting tracking patterns to
obtain scene dynamics and regress velocities. In a last step, the memory state
of the Recurrent Neural Network is projected based on extracted velocity
estimates to resolve aforementioned spatio-temporal misalignment.
\\ ( https://arxiv.org/abs/2306.06126 ,  3995kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06149
Date: Fri, 9 Jun 2023 12:23:20 GMT   (4788kb,D)

Title: Read, look and detect: Bounding box annotation from image-caption pairs
Authors: Eduardo Hugo Sanchez
Categories: cs.CV cs.AI
\\
 Various methods have been proposed to detect objects while reducing the cost
of data annotation. For instance, weakly supervised object detection (WSOD)
methods rely only on image-level annotations during training. Unfortunately,
data annotation remains expensive since annotators must provide the categories
describing the content of each image and labeling is restricted to a fixed set
of categories. In this paper, we propose a method to locate and label objects
in an image by using a form of weaker supervision: image-caption pairs. By
leveraging recent advances in vision-language (VL) models and self-supervised
vision transformers (ViTs), our method is able to perform phrase grounding and
object detection in a weakly supervised manner. Our experiments demonstrate the
effectiveness of our approach by achieving a 47.51% recall@1 score in phrase
grounding on Flickr30k Entities and establishing a new state-of-the-art in
object detection by achieving 21.1 mAP 50 and 10.5 mAP 50:95 on MS COCO when
exclusively relying on image-caption pairs.
\\ ( https://arxiv.org/abs/2306.06149 ,  4788kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06157
Date: Sat, 10 Jun 2023 23:50:02 GMT   (1245kb,D)

Title: Fault Localization for Framework Conversions of Image Recognition Models
Authors: Nikolaos Louloudakis, Perry Gibson, Jos\'e Cano, and Ajitha Rajan
Categories: cs.CV cs.LG cs.SE cs.SY eess.SY
Comments: 5 pages, 3 figures, 1 table
\\
 When deploying Deep Neural Networks (DNNs), developers often convert models
from one deep learning framework to another (e.g., TensorFlow to PyTorch).
However, this process is error-prone and can impact target model accuracy. To
identify the extent of such impact, we perform and briefly present a
differential analysis against three DNNs used for image recognition
(MobileNetV2, ResNet101, and InceptionV3), converted across four well-known
deep learning frameworks (PyTorch, Keras, TensorFlow (TF), and TFLite), which
revealed numerous model crashes and output label discrepancies of up to 100%.
To mitigate such errors, we present a novel approach towards fault localization
and repair of buggy deep learning framework conversions, focusing on
pre-trained image recognition models. Our technique consists of four primary
stages of analysis: 1) conversion tools, 2) model parameters, 3) model
hyperparameters, and 4) graph representation. In addition, we propose a number
of strategies towards fault repair of the faults detected. We implement our
technique on top of Apache TVM deep learning compiler, and we test it by
conducting a preliminary fault localization analysis for the conversion of
InceptionV3, from TF to TFLite. Our approach detected that the tf2onnx tool
used in the conversion process introduced precision errors to model weights for
convolutional layers in particular, which negatively affected the model
accuracy. We then repaired the target model by replacing the affected weights
with those from source model.
\\ ( https://arxiv.org/abs/2306.06157 ,  1245kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06189
Date: Fri, 9 Jun 2023 18:41:37 GMT   (1392kb,D)

Title: FasterViT: Fast Vision Transformers with Hierarchical Attention
Authors: Ali Hatamizadeh, Greg Heinrich, Hongxu Yin, Andrew Tao, Jose M.
 Alvarez, Jan Kautz, Pavlo Molchanov
Categories: cs.CV cs.AI cs.LG
Comments: Tech report
\\
 We design a new family of hybrid CNN-ViT neural networks, named FasterViT,
with a focus on high image throughput for computer vision (CV) applications.
FasterViT combines the benefits of fast local representation learning in CNNs
and global modeling properties in ViT. Our newly introduced Hierarchical
Attention (HAT) approach decomposes global self-attention with quadratic
complexity into a multi-level attention with reduced computational costs. We
benefit from efficient window-based self-attention. Each window has access to
dedicated carrier tokens that participate in local and global representation
learning. At a high level, global self-attentions enable the efficient
cross-window communication at lower costs. FasterViT achieves a SOTA
Pareto-front in terms of accuracy \vs image throughput. We have extensively
validated its effectiveness on various CV tasks including classification,
object detection and segmentation. We also show that HAT can be used as a
plug-and-play module for existing networks and enhance them. We further
demonstrate significantly faster and more accurate performance than competitive
counterparts for images with high resolution. Code is available at
https://github.com/NVlabs/FasterViT.
\\ ( https://arxiv.org/abs/2306.06189 ,  1392kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06206
Date: Sat, 27 May 2023 17:38:16 GMT   (979kb)

Title: PotatoPestNet: A CTInceptionV3-RS-Based Neural Network for Accurate
 Identification of Potato Pests
Authors: Md. Simul Hasan Talukder, Rejwan Bin Sulaiman, Mohammad Raziuddin
 Chowdhury, Musarrat Saberin Nipun, Ben Hadj Hassine
Categories: cs.CV cs.LG
\\
 Potatoes are the third-largest food crop globally, but their production
frequently encounters difficulties because of aggressive pest infestations. The
aim of this study is to investigate the various types and characteristics of
these pests and propose an efficient PotatoPestNet AI-based automatic potato
pest identification system. To accomplish this, we curated a reliable dataset
consisting of eight types of potato pests. We leveraged the power of transfer
learning by employing five customized, pre-trained transfer learning models:
CMobileNetV2, CNASLargeNet, CXception, CDenseNet201, and CInceptionV3, in
proposing a robust PotatoPestNet model to accurately classify potato pests. To
improve the models' performance, we applied various augmentation techniques,
incorporated a global average pooling layer, and implemented proper
regularization methods. To further enhance the performance of the models, we
utilized random search (RS) optimization for hyperparameter tuning. This
optimization technique played a significant role in fine-tuning the models and
achieving improved performance. We evaluated the models both visually and
quantitatively, utilizing different evaluation metrics. The robustness of the
models in handling imbalanced datasets was assessed using the Receiver
Operating Characteristic (ROC) curve. Among the models, the Customized Tuned
Inception V3 (CTInceptionV3) model, optimized through random search,
demonstrated outstanding performance. It achieved the highest accuracy (91%),
precision (91%), recall (91%), and F1-score (91%), showcasing its superior
ability to accurately identify and classify potato pests.
\\ ( https://arxiv.org/abs/2306.06206 ,  979kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06208
Date: Mon, 5 Jun 2023 23:07:01 GMT   (7170kb,D)

Title: A Differential Testing Framework to Evaluate Image Recognition Model
 Robustness
Authors: Nikolaos Louloudakis, Perry Gibson, Jos\'e Cano, and Ajitha Rajan
Categories: cs.CV cs.LG cs.SE cs.SY eess.SY
Comments: 12 pages, 10 figures, 2 tables. arXiv admin note: text overlap with
 arXiv:2211.00471
\\
 Image recognition tasks typically use deep learning and require enormous
processing power, thus relying on hardware accelerators like GPUs and TPUs for
fast, timely processing. Failure in real-time image recognition tasks can occur
due to sub-optimal mapping on hardware accelerators during model deployment,
which may lead to timing uncertainty and erroneous behavior. Mapping on
hardware accelerators is done through multiple software components like deep
learning frameworks, compilers, device libraries, that we refer to as the
computational environment. Owing to the increased use of image recognition
tasks in safety-critical applications like autonomous driving and medical
imaging, it is imperative to assess their robustness to changes in the
computational environment, as the impact of parameters like deep learning
frameworks, compiler optimizations, and hardware devices on model performance
and correctness is not well understood.
 In this paper we present a differential testing framework, which allows deep
learning model variant generation, execution, differential analysis and testing
for a number of computational environment parameters. Using our framework, we
conduct an empirical study of robustness analysis of three popular image
recognition models using the ImageNet dataset, assessing the impact of changing
deep learning frameworks, compiler optimizations, and hardware devices. We
report the impact in terms of misclassifications and inference time differences
across different settings. In total, we observed up to 72% output label
differences across deep learning frameworks, and up to 82% unexpected
performance degradation in terms of inference time, when applying compiler
optimizations. Using the analysis tools in our framework, we also perform fault
analysis to understand the reasons for the observed differences.
\\ ( https://arxiv.org/abs/2306.06208 ,  7170kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06209
Date: Thu, 11 May 2023 10:05:57 GMT   (5617kb,D)

Title: Backdoor Attack with Sparse and Invisible Trigger
Authors: Yinghua Gao, Yiming Li, Xueluan Gong, Shu-Tao Xia, Qian Wang
Categories: cs.CV cs.CR cs.LG
Comments: The first two authors contributed equally to this work. 13 pages
\\
 Deep neural networks (DNNs) are vulnerable to backdoor attacks, where the
adversary manipulates a small portion of training data such that the victim
model predicts normally on the benign samples but classifies the triggered
samples as the target class. The backdoor attack is an emerging yet threatening
training-phase threat, leading to serious risks in DNN-based applications. In
this paper, we revisit the trigger patterns of existing backdoor attacks. We
reveal that they are either visible or not sparse and therefore are not
stealthy enough. More importantly, it is not feasible to simply combine
existing methods to design an effective sparse and invisible backdoor attack.
To address this problem, we formulate the trigger generation as a bi-level
optimization problem with sparsity and invisibility constraints and propose an
effective method to solve it. The proposed method is dubbed sparse and
invisible backdoor attack (SIBA). We conduct extensive experiments on benchmark
datasets under different settings, which verify the effectiveness of our attack
and its resistance to existing backdoor defenses. The codes for reproducing
main experiments are available at \url{https://github.com/YinghuaGao/SIBA}.
\\ ( https://arxiv.org/abs/2306.06209 ,  5617kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06210
Date: Fri, 26 May 2023 13:06:38 GMT   (2564kb,D)

Title: Single-Model Attribution via Final-Layer Inversion
Authors: Mike Laszkiewicz, Jonas Ricker, Johannes Lederer, Asja Fischer
Categories: cs.CV cs.LG
\\
 Recent groundbreaking developments on generative modeling have sparked
interest in practical single-model attribution. Such methods predict whether a
sample was generated by a specific generator or not, for instance, to prove
intellectual property theft. However, previous works are either limited to the
closed-world setting or require undesirable changes of the generative model. We
address these shortcomings by proposing FLIPAD, a new approach for single-model
attribution in the open-world setting based on final-layer inversion and
anomaly detection. We show that the utilized final-layer inversion can be
reduced to a convex lasso optimization problem, making our approach
theoretically sound and computationally efficient. The theoretical findings are
accompanied by an experimental study demonstrating the effectiveness of our
approach, outperforming the existing methods.
\\ ( https://arxiv.org/abs/2306.06210 ,  2564kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06211
Date: Fri, 12 May 2023 07:21:59 GMT   (5789kb,D)

Title: A Survey on Segment Anything Model (SAM): Vision Foundation Model Meets
 Prompt Engineering
Authors: Chaoning Zhang, Sheng Zheng, Chenghao Li, Yu Qiao, Taegoo Kang, Xinru
 Shan, Chenshuang Zhang, Caiyan Qin, Francois Rameau, Sung-Ho Bae, Choong Seon
 Hong
Categories: cs.CV
Comments: First survey on Segment Anything Model (SAM), work under progress
\\
 Segment anything model (SAM) developed by Meta AI Research has recently
attracted significant attention. Trained on a large segmentation dataset of
over 1 billion masks, SAM is capable of segmenting any object on a certain
image. In the original SAM work, the authors turned to zero-short transfer
tasks (like edge detection) for evaluating the performance of SAM. Recently,
numerous works have attempted to investigate the performance of SAM in various
scenarios to recognize and segment objects. Moreover, numerous projects have
emerged to show the versatility of SAM as a foundation model by combining it
with other models, like Grounding DINO, Stable Diffusion, ChatGPT, etc. With
the relevant papers and projects increasing exponentially, it is challenging
for the readers to catch up with the development of SAM. To this end, this work
conducts the first yet comprehensive survey on SAM. This is an ongoing project
and we intend to update the manuscript on a regular basis. Therefore, readers
are welcome to contact us if they complete new works related to SAM so that we
can include them in our next version.
\\ ( https://arxiv.org/abs/2306.06211 ,  5789kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06212
Date: Fri, 9 Jun 2023 19:24:39 GMT   (47748kb,D)

Title: Aladdin: Zero-Shot Hallucination of Stylized 3D Assets from Abstract
 Scene Descriptions
Authors: Ian Huang, Vrishab Krishna, Omoruyi Atekha, Leonidas Guibas
Categories: cs.CV cs.GR
\\
 What constitutes the "vibe" of a particular scene? What should one find in "a
busy, dirty city street", "an idyllic countryside", or "a crime scene in an
abandoned living room"? The translation from abstract scene descriptions to
stylized scene elements cannot be done with any generality by extant systems
trained on rigid and limited indoor datasets. In this paper, we propose to
leverage the knowledge captured by foundation models to accomplish this
translation. We present a system that can serve as a tool to generate stylized
assets for 3D scenes described by a short phrase, without the need to enumerate
the objects to be found within the scene or give instructions on their
appearance. Additionally, it is robust to open-world concepts in a way that
traditional methods trained on limited data are not, affording more creative
freedom to the 3D artist. Our system demonstrates this using a foundation model
"team" composed of a large language model, a vision-language model and several
image diffusion models, which communicate using an interpretable and
user-editable intermediate representation, thus allowing for more versatile and
controllable stylized asset generation for 3D artists. We introduce novel
metrics for this task, and show through human evaluations that in 91% of the
cases, our system outputs are judged more faithful to the semantics of the
input scene description than the baseline, thus highlighting the potential of
this approach to radically accelerate the 3D content creation process for 3D
artists.
\\ ( https://arxiv.org/abs/2306.06212 ,  47748kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06254
Date: Fri, 9 Jun 2023 20:52:44 GMT   (1157kb,D)

Title: Understanding the Benefits of Image Augmentations
Authors: Matthew Iceland, Christopher Kanan
Categories: cs.CV cs.LG eess.IV
\\
 Image Augmentations are widely used to reduce overfitting in neural networks.
However, the explainability of their benefits largely remains a mystery. We
study which layers of residual neural networks (ResNets) are most affected by
augmentations using Centered Kernel Alignment (CKA). We do so by analyzing
models of varying widths and depths, as well as whether their weights are
initialized randomly or through transfer learning. We find that the pattern of
how the layers are affected depends on the model's depth, and that networks
trained with augmentation that use information from two images affect the
learned weights significantly more than augmentations that operate on a single
image. Deeper layers of ResNets initialized with ImageNet-1K weights and
fine-tuned receive more impact from the augmentations than early layers.
Understanding the effects of image augmentations on CNNs will have a variety of
applications, such as determining how far back one needs to fine-tune a network
and which layers should be frozen when implementing layer freezing algorithms.
\\ ( https://arxiv.org/abs/2306.06254 ,  1157kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06269
Date: Fri, 9 Jun 2023 21:42:29 GMT   (386kb,D)

Title: DeepLCZChange: A Remote Sensing Deep Learning Model Architecture for
 Urban Climate Resilience
Authors: Wenlu Sun, Yao Sun, Chenying Liu, Conrad M Albrecht
Categories: cs.CV cs.AI cs.LG
Comments: accepted for publication in 2023 IGARSS conference
\\
 Urban land use structures impact local climate conditions of metropolitan
areas. To shed light on the mechanism of local climate wrt. urban land use, we
present a novel, data-driven deep learning architecture and pipeline,
DeepLCZChange, to correlate airborne LiDAR data statistics with the Landsat 8
satellite's surface temperature product. A proof-of-concept numerical
experiment utilizes corresponding remote sensing data for the city of New York
to verify the cooling effect of urban forests.
\\ ( https://arxiv.org/abs/2306.06269 ,  386kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06288
Date: Fri, 9 Jun 2023 22:29:42 GMT   (1266kb,D)

Title: SAGE-NDVI: A Stereotype-Breaking Evaluation Metric for Remote Sensing
 Image Dehazing Using Satellite-to-Ground NDVI Knowledge
Authors: Zepeng Liu, Zhicheng Yang, Mingye Zhu, Andy Wong, Yibing Wei, Mei Han,
 Jun Yu, Jui-Hsin Lai
Categories: cs.CV
Comments: Accepted by ICME 2023 Industry Track
\\
 Image dehazing is a meaningful low-level computer vision task and can be
applied to a variety of contexts. In our industrial deployment scenario based
on remote sensing (RS) images, the quality of image dehazing directly affects
the grade of our crop identification and growth monitoring products. However,
the widely used peak signal-to-noise ratio (PSNR) and structural similarity
index (SSIM) provide ambiguous visual interpretation. In this paper, we design
a new objective metric for RS image dehazing evaluation. Our proposed metric
leverages a ground-based phenology observation resource to calculate the
vegetation index error between RS and ground images at a hazy date. Extensive
experiments validate that our metric appropriately evaluates different dehazing
models and is in line with human visual perception.
\\ ( https://arxiv.org/abs/2306.06288 ,  1266kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06289
Date: Fri, 9 Jun 2023 22:29:56 GMT   (6758kb,D)

Title: SegViTv2: Exploring Efficient and Continual Semantic Segmentation with
 Plain Vision Transformers
Authors: Bowen Zhang, Liyang Liu, Minh Hieu Phan, Zhi Tian, Chunhua Shen, Yifan
 Liu
Categories: cs.CV
Comments: 21 pages, 8 figures, 12 tables
\\
 We explore the capability of plain Vision Transformers (ViTs) for semantic
segmentation using the encoder-decoder framework and introduce SegViTv2. In our
work, we implement the decoder with the global attention mechanism inherent in
ViT backbones and propose the lightweight Attention-to-Mask module that
effectively converts the global attention map into semantic masks for
high-quality segmentation results. Our decoder can outperform the most
commonly-used decoder UpperNet in various ViT backbones while consuming only
about 5\% of the computational cost. For the encoder, we address the concern of
the relatively high computational cost in the ViT-based encoders and propose a
Shrunk++ structure that incorporates edge-aware query-based down-sampling (EQD)
and query-based up-sampling (QU) modules. The Shrunk++ structure reduces the
computational cost of the encoder by up to $50\%$ while maintaining competitive
performance. Furthermore, due to the flexibility of our ViT-based architecture,
SegVit can be easily extended to semantic segmentation under the setting of
continual learning, achieving nearly zero forgetting. Experiments show that our
proposed SegViT outperforms recent segmentation methods on three popular
benchmarks including ADE20k, COCO-Stuff-10k and PASCAL-Context datasets. The
code is available through the following link:
\url{https://github.com/zbwxp/SegVit}.
\\ ( https://arxiv.org/abs/2306.06289 ,  6758kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06300
Date: Fri, 9 Jun 2023 23:28:33 GMT   (1460kb)

Title: NERFBK: A High-Quality Benchmark for NERF-Based 3D Reconstruction
Authors: Ali Karami, Simone Rigon, Gabriele Mazzacca, Ziyang Yan, Fabio
 Remondino
Categories: cs.CV cs.AI cs.GR
Comments: 9 pages, 6 figures, 1 table, conference
\\
 This paper introduces a new real and synthetic dataset called NeRFBK
specifically designed for testing and comparing NeRF-based 3D reconstruction
algorithms. High-quality 3D reconstruction has significant potential in various
fields, and advancements in image-based algorithms make it essential to
evaluate new advanced techniques. However, gathering diverse data with precise
ground truth is challenging and may not encompass all relevant applications.
The NeRFBK dataset addresses this issue by providing multi-scale, indoor and
outdoor datasets with high-resolution images and videos and camera parameters
for testing and comparing NeRF-based algorithms. This paper presents the design
and creation of the NeRFBK benchmark, various examples and application
scenarios, and highlights its potential for advancing the field of 3D
reconstruction.
\\ ( https://arxiv.org/abs/2306.06300 ,  1460kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06306
Date: Fri, 9 Jun 2023 23:51:11 GMT   (3332kb,D)

Title: DocumentCLIP: Linking Figures and Main Body Text in Reflowed Documents
Authors: Fuxiao Liu, Hao Tan, Chris Tensmeyer
Categories: cs.CV cs.AI
Comments: 8 pages, 5 figures. In submission
\\
 Vision-language pretraining models have achieved great success in supporting
multimedia applications by understanding the alignments between images and
text. While existing vision-language pretraining models primarily focus on
understanding single image associated with a single piece of text, they often
ignore the alignment at the intra-document level, consisting of multiple
sentences with multiple images. In this work, we propose DocumentCLIP, a
salience-aware contrastive learning framework to enforce vision-language
pretraining models to comprehend the interaction between images and longer text
within documents. Our model is beneficial for the real-world multimodal
document understanding like news article, magazines, product descriptions,
which contain linguistically and visually richer content. To the best of our
knowledge, we are the first to explore multimodal intra-document links by
contrastive learning. In addition, we collect a large Wikipedia dataset for
pretraining, which provides various topics and structures. Experiments show
DocumentCLIP not only outperforms the state-of-the-art baselines in the
supervised setting, but also achieves the best zero-shot performance in the
wild after human evaluation. Our code is available at
https://github.com/FuxiaoLiu/DocumentCLIP.
\\ ( https://arxiv.org/abs/2306.06306 ,  3332kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06323
Date: Sat, 10 Jun 2023 00:27:37 GMT   (36881kb,D)

Title: Learning Joint Latent Space EBM Prior Model for Multi-layer Generator
Authors: Jiali Cui, Ying Nian Wu, Tian Han
Categories: cs.CV cs.LG
\\
 This paper studies the fundamental problem of learning multi-layer generator
models. The multi-layer generator model builds multiple layers of latent
variables as a prior model on top of the generator, which benefits learning
complex data distribution and hierarchical representations. However, such a
prior model usually focuses on modeling inter-layer relations between latent
variables by assuming non-informative (conditional) Gaussian distributions,
which can be limited in model expressivity. To tackle this issue and learn more
expressive prior models, we propose an energy-based model (EBM) on the joint
latent space over all layers of latent variables with the multi-layer generator
as its backbone. Such joint latent space EBM prior model captures the
intra-layer contextual relations at each layer through layer-wise energy terms,
and latent variables across different layers are jointly corrected. We develop
a joint training scheme via maximum likelihood estimation (MLE), which involves
Markov Chain Monte Carlo (MCMC) sampling for both prior and posterior
distributions of the latent variables from different layers. To ensure
efficient inference and learning, we further propose a variational training
scheme where an inference model is used to amortize the costly posterior MCMC
sampling. Our experiments demonstrate that the learned model can be expressive
in generating high-quality images and capturing hierarchical features for
better outlier detection.
\\ ( https://arxiv.org/abs/2306.06323 ,  36881kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06339
Date: Sat, 10 Jun 2023 04:22:13 GMT   (10391kb,D)

Title: Two-Stage Holistic and Contrastive Explanation of Image Classification
Authors: Weiyan Xie, Xiao-Hui Li, Zhi Lin, Leonard K. M. Poon, Caleb Chen Cao,
 Nevin L. Zhang
Categories: cs.CV
Comments: To appear at UAI 2023
\\
 The need to explain the output of a deep neural network classifier is now
widely recognized. While previous methods typically explain a single class in
the output, we advocate explaining the whole output, which is a probability
distribution over multiple classes. A whole-output explanation can help a human
user gain an overall understanding of model behaviour instead of only one
aspect of it. It can also provide a natural framework where one can examine the
evidence used to discriminate between competing classes, and thereby obtain
contrastive explanations. In this paper, we propose a contrastive whole-output
explanation (CWOX) method for image classification, and evaluate it using
quantitative metrics and through human subject studies. The source code of CWOX
is available at https://github.com/vaynexie/CWOX.
\\ ( https://arxiv.org/abs/2306.06339 ,  10391kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06354
Date: Sat, 10 Jun 2023 06:05:35 GMT   (2454kb,D)

Title: EventCLIP: Adapting CLIP for Event-based Object Recognition
Authors: Ziyi Wu, Xudong Liu, Igor Gilitschenski
Categories: cs.CV
Comments: Pre-print, work in progress
\\
 Recent advances in 2D zero-shot and few-shot recognition often leverage large
pre-trained vision-language models (VLMs) such as CLIP. Due to a shortage of
suitable datasets, it is currently infeasible to train such models for event
camera data. Thus, leveraging existing models across modalities is an important
research challenge. In this work, we propose EventCLIP, a new method that
utilizes CLIP for zero-shot and few-shot recognition on event camera data.
First, we demonstrate the suitability of CLIP's image embeddings for zero-shot
event classification by converting raw events to 2D grid-based representations.
Second, we propose a feature adapter that aggregates temporal information over
event frames and refines text embeddings to better align with the visual
inputs. We evaluate our work on N-Caltech, N-Cars, and N-ImageNet datasets
under the few-shot learning setting, where EventCLIP achieves state-of-the-art
performance. Finally, we show that the robustness of existing event-based
classifiers against data variations can be further boosted by ensembling with
EventCLIP.
\\ ( https://arxiv.org/abs/2306.06354 ,  2454kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06359
Date: Sat, 10 Jun 2023 06:39:25 GMT   (14600kb,D)

Title: NeRFool: Uncovering the Vulnerability of Generalizable Neural Radiance
 Fields against Adversarial Perturbations
Authors: Yonggan Fu, Ye Yuan, Souvik Kundu, Shang Wu, Shunyao Zhang, Yingyan
 Lin
Categories: cs.CV
Comments: Accepted by ICML 2023
\\
 Generalizable Neural Radiance Fields (GNeRF) are one of the most promising
real-world solutions for novel view synthesis, thanks to their cross-scene
generalization capability and thus the possibility of instant rendering on new
scenes. While adversarial robustness is essential for real-world applications,
little study has been devoted to understanding its implication on GNeRF. We
hypothesize that because GNeRF is implemented by conditioning on the source
views from new scenes, which are often acquired from the Internet or
third-party providers, there are potential new security concerns regarding its
real-world applications. Meanwhile, existing understanding and solutions for
neural networks' adversarial robustness may not be applicable to GNeRF, due to
its 3D nature and uniquely diverse operations. To this end, we present NeRFool,
which to the best of our knowledge is the first work that sets out to
understand the adversarial robustness of GNeRF. Specifically, NeRFool unveils
the vulnerability patterns and important insights regarding GNeRF's adversarial
robustness. Built upon the above insights gained from NeRFool, we further
develop NeRFool+, which integrates two techniques capable of effectively
attacking GNeRF across a wide range of target views, and provide guidelines for
defending against our proposed attacks. We believe that our NeRFool/NeRFool+
lays the initial foundation for future innovations in developing robust
real-world GNeRF solutions. Our codes are available at:
https://github.com/GATECH-EIC/NeRFool.
\\ ( https://arxiv.org/abs/2306.06359 ,  14600kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06360
Date: Sat, 10 Jun 2023 06:39:28 GMT   (29115kb,D)

Title: 3D reconstruction using Structure for Motion
Authors: Kshitij Karnawat, Hritvik Choudhari, Abhimanyu Saxena, Mudit Singal,
 Raajith Gadam
Categories: cs.CV cs.AI cs.LG cs.RO
Comments: Implementation code can be found at
 https://github.com/KshitijKarnawat/Structure-from-Motion
MSC-class: 65D19
\\
 We are working towards 3D reconstruction of indoor spaces using a pair of HDR
cameras in a stereo vision configuration mounted on an indoor mobile floor
robot that captures various textures and spatial features as 2D images and this
data is simultaneously utilized as a feed to our algorithm which will allow us
to visualize the depth map.
\\ ( https://arxiv.org/abs/2306.06360 ,  29115kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06362
Date: Sat, 10 Jun 2023 06:46:32 GMT   (40261kb,D)

Title: Aria Digital Twin: A New Benchmark Dataset for Egocentric 3D Machine
 Perception
Authors: Xiaqing Pan, Nicholas Charron, Yongqian Yang, Scott Peters, Thomas
 Whelan, Chen Kong, Omkar Parkhi, Richard Newcombe, Carl (Yuheng) Ren
Categories: cs.CV cs.AI cs.LG
\\
 We introduce the Aria Digital Twin (ADT) - an egocentric dataset captured
using Aria glasses with extensive object, environment, and human level ground
truth. This ADT release contains 200 sequences of real-world activities
conducted by Aria wearers in two real indoor scenes with 398 object instances
(324 stationary and 74 dynamic). Each sequence consists of: a) raw data of two
monochrome camera streams, one RGB camera stream, two IMU streams; b) complete
sensor calibration; c) ground truth data including continuous
6-degree-of-freedom (6DoF) poses of the Aria devices, object 6DoF poses, 3D eye
gaze vectors, 3D human poses, 2D image segmentations, image depth maps; and d)
photo-realistic synthetic renderings. To the best of our knowledge, there is no
existing egocentric dataset with a level of accuracy, photo-realism and
comprehensiveness comparable to ADT. By contributing ADT to the research
community, our mission is to set a new standard for evaluation in the
egocentric machine perception domain, which includes very challenging research
problems such as 3D object detection and tracking, scene reconstruction and
understanding, sim-to-real learning, human pose prediction - while also
inspiring new machine perception tasks for augmented reality (AR) applications.
To kick start exploration of the ADT research use cases, we evaluated several
existing state-of-the-art methods for object detection, segmentation and image
translation tasks that demonstrate the usefulness of ADT as a benchmarking
dataset.
\\ ( https://arxiv.org/abs/2306.06362 ,  40261kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06365
Date: Sat, 10 Jun 2023 07:01:08 GMT   (4397kb,D)

Title: FalconNet: Factorization for the Light-weight ConvNets
Authors: Zhicheng Cai, Qiu Shen
Categories: cs.CV
\\
 Designing light-weight CNN models with little parameters and Flops is a
prominent research concern. However, three significant issues persist in the
current light-weight CNNs: i) the lack of architectural consistency leads to
redundancy and hindered capacity comparison, as well as the ambiguity in
causation between architectural choices and performance enhancement; ii) the
utilization of a single-branch depth-wise convolution compromises the model
representational capacity; iii) the depth-wise convolutions account for large
proportions of parameters and Flops, while lacking efficient method to make
them light-weight. To address these issues, we factorize the four vital
components of light-weight CNNs from coarse to fine and redesign them: i) we
design a light-weight overall architecture termed LightNet, which obtains
better performance by simply implementing the basic blocks of other
light-weight CNNs; ii) we abstract a Meta Light Block, which consists of
spatial operator and channel operator and uniformly describes current basic
blocks; iii) we raise RepSO which constructs multiple spatial operator branches
to enhance the representational ability; iv) we raise the concept of receptive
range, guided by which we raise RefCO to sparsely factorize the channel
operator. Based on above four vital components, we raise a novel light-weight
CNN model termed as FalconNet. Experimental results validate that FalconNet can
achieve higher accuracy with lower number of parameters and Flops compared to
existing light-weight CNNs.
\\ ( https://arxiv.org/abs/2306.06365 ,  4397kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06367
Date: Sat, 10 Jun 2023 07:14:59 GMT   (2580kb,D)

Title: Shuffled Autoregression For Motion Interpolation
Authors: Shuo Huang, Jia Jia, Zongxin Yang, Wei Wang, Haozhe Wu, Yi Yang,
 Junliang Xing
Categories: cs.CV cs.AI
Comments: accepted by ICASSP 2023
\\
 This work aims to provide a deep-learning solution for the motion
interpolation task. Previous studies solve it with geometric weight functions.
Some other works propose neural networks for different problem settings with
consecutive pose sequences as input. However, motion interpolation is a more
complex problem that takes isolated poses (e.g., only one start pose and one
end pose) as input. When applied to motion interpolation, these deep learning
methods have limited performance since they do not leverage the flexible
dependencies between interpolation frames as the original geometric formulas
do. To realize this interpolation characteristic, we propose a novel framework,
referred to as \emph{Shuffled AutoRegression}, which expands the autoregression
to generate in arbitrary (shuffled) order and models any inter-frame
dependencies as a directed acyclic graph. We further propose an approach to
constructing a particular kind of dependency graph, with three stages assembled
into an end-to-end spatial-temporal motion Transformer. Experimental results on
one of the current largest datasets show that our model generates vivid and
coherent motions from only one start frame to one end frame and outperforms
competing methods by a large margin. The proposed model is also extensible to
multiple keyframes' motion interpolation tasks and other areas' interpolation.
\\ ( https://arxiv.org/abs/2306.06367 ,  2580kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06370
Date: Sat, 10 Jun 2023 07:27:00 GMT   (18369kb,D)

Title: AutoSAM: Adapting SAM to Medical Images by Overloading the Prompt
 Encoder
Authors: Tal Shaharabany, Aviad Dahan, Raja Giryes and Lior Wolf
Categories: cs.CV
\\
 The recently introduced Segment Anything Model (SAM) combines a clever
architecture and large quantities of training data to obtain remarkable image
segmentation capabilities. However, it fails to reproduce such results for
Out-Of-Distribution (OOD) domains such as medical images. Moreover, while SAM
is conditioned on either a mask or a set of points, it may be desirable to have
a fully automatic solution. In this work, we replace SAM's conditioning with an
encoder that operates on the same input image. By adding this encoder and
without further fine-tuning SAM, we obtain state-of-the-art results on multiple
medical images and video benchmarks. This new encoder is trained via gradients
provided by a frozen SAM. For inspecting the knowledge within it, and providing
a lightweight segmentation solution, we also learn to decode it into a mask by
a shallow deconvolution network.
\\ ( https://arxiv.org/abs/2306.06370 ,  18369kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06378
Date: Sat, 10 Jun 2023 08:25:16 GMT   (291kb,D)

Title: An Optimization-based Deep Equilibrium Model for Hyperspectral Image
 Deconvolution with Convergence Guarantees
Authors: Alexandros Gkillas, Dimitris Ampeliotis, Kostas Berberidis
Categories: cs.CV eess.IV
\\
 In this paper, we propose a novel methodology for addressing the
hyperspectral image deconvolution problem. This problem is highly ill-posed,
and thus, requires proper priors (regularizers) to model the inherent
spectral-spatial correlations of the HSI signals. To this end, a new
optimization problem is formulated, leveraging a learnable regularizer in the
form of a neural network. To tackle this problem, an effective solver is
proposed using the half quadratic splitting methodology. The derived iterative
solver is then expressed as a fixed-point calculation problem within the Deep
Equilibrium (DEQ) framework, resulting in an interpretable architecture, with
clear explainability to its parameters and convergence properties with
practical benefits. The proposed model is a first attempt to handle the
classical HSI degradation problem with different blurring kernels and noise
levels via a single deep equilibrium model with significant computational
efficiency. Extensive numerical experiments validate the superiority of the
proposed methodology over other state-of-the-art methods. This superior
restoration performance is achieved while requiring 99.85\% less computation
time as compared to existing methods.
\\ ( https://arxiv.org/abs/2306.06378 ,  291kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06388
Date: Sat, 10 Jun 2023 09:19:19 GMT   (48725kb,D)

Title: From NeRFLiX to NeRFLiX++: A General NeRF-Agnostic Restorer Paradigm
Authors: Kun Zhou, Wenbo Li, Nianjuan Jiang, Xiaoguang Han, Jiangbo Lu
Categories: cs.CV
Comments: 15 pages, 15 figures. arXiv admin note: text overlap with
 arXiv:2303.06919
\\
 Neural radiance fields (NeRF) have shown great success in novel view
synthesis. However, recovering high-quality details from real-world scenes is
still challenging for the existing NeRF-based approaches, due to the potential
imperfect calibration information and scene representation inaccuracy. Even
with high-quality training frames, the synthetic novel views produced by NeRF
models still suffer from notable rendering artifacts, such as noise and blur.
To address this, we propose NeRFLiX, a general NeRF-agnostic restorer paradigm
that learns a degradation-driven inter-viewpoint mixer. Specially, we design a
NeRF-style degradation modeling approach and construct large-scale training
data, enabling the possibility of effectively removing NeRF-native rendering
artifacts for deep neural networks. Moreover, beyond the degradation removal,
we propose an inter-viewpoint aggregation framework that fuses highly related
high-quality training images, pushing the performance of cutting-edge NeRF
models to entirely new levels and producing highly photo-realistic synthetic
views. Based on this paradigm, we further present NeRFLiX++ with a stronger
two-stage NeRF degradation simulator and a faster inter-viewpoint mixer,
achieving superior performance with significantly improved computational
efficiency. Notably, NeRFLiX++ is capable of restoring photo-realistic
ultra-high-resolution outputs from noisy low-resolution NeRF-rendered views.
Extensive experiments demonstrate the excellent restoration ability of
NeRFLiX++ on various novel view synthesis benchmarks.
\\ ( https://arxiv.org/abs/2306.06388 ,  48725kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06406
Date: Sat, 10 Jun 2023 10:41:54 GMT   (1359kb,D)

Title: D3L: Decomposition of 3D Rotation and Lift from 2D Joint to 3D for Human
 Mesh Recovery
Authors: Xiaoyang Hao (1 and 2), Han Li (1), Jun Cheng (2), Lei Wang (2) ((1)
 Southern University of Science and Technology, (2) Shenzhen Institute of
 Advanced Technology, Chinese Academy of Sciences)
Categories: cs.CV
Comments: 11 pages, 4 figures
\\
 Existing methods for 3D human mesh recovery always directly estimate SMPL
parameters, which involve both joint rotations and shape parameters. However,
these methods present rotation semantic ambiguity, rotation error accumulation,
and shape estimation overfitting, which also leads to errors in the estimated
pose. Additionally, these methods have not efficiently leveraged the
advancements in another hot topic, human pose estimation. To address these
issues, we propose a novel approach, Decomposition of 3D Rotation and Lift from
2D Joint to 3D mesh (D3L). We disentangle 3D joint rotation into bone direction
and bone twist direction so that the human mesh recovery task is broken down
into estimation of pose, twist, and shape, which can be handled independently.
Then we design a 2D-to-3D lifting network for estimating twist direction and 3D
joint position from 2D joint position sequences and introduce a nonlinear
optimization method for fitting shape parameters and bone directions. Our
approach can leverage human pose estimation methods, and avoid pose errors
introduced by shape estimation overfitting. We conduct experiments on the
Human3.6M dataset and demonstrate improved performance compared to existing
methods by a large margin.
\\ ( https://arxiv.org/abs/2306.06406 ,  1359kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06414
Date: Sat, 10 Jun 2023 11:20:04 GMT   (1766kb,D)

Title: Revealing Model Biases: Assessing Deep Neural Networks via Recovered
 Sample Analysis
Authors: Mohammad Mahdi Mehmanchi, Mahbod Nouri, Mohammad Sabokrou
Categories: cs.CV
\\
 This paper proposes a straightforward and cost-effective approach to assess
whether a deep neural network (DNN) relies on the primary concepts of training
samples or simply learns discriminative, yet simple and irrelevant features
that can differentiate between classes. The paper highlights that DNNs, as
discriminative classifiers, often find the simplest features to discriminate
between classes, leading to a potential bias towards irrelevant features and
sometimes missing generalization. While a generalization test is one way to
evaluate a trained model's performance, it can be costly and may not cover all
scenarios to ensure that the model has learned the primary concepts.
Furthermore, even after conducting a generalization test, identifying bias in
the model may not be possible. Here, the paper proposes a method that involves
recovering samples from the parameters of the trained model and analyzing the
reconstruction quality. We believe that if the model's weights are optimized to
discriminate based on some features, these features will be reflected in the
reconstructed samples. If the recovered samples contain the primary concepts of
the training data, it can be concluded that the model has learned the essential
and determining features. On the other hand, if the recovered samples contain
irrelevant features, it can be concluded that the model is biased towards these
features. The proposed method does not require any test or generalization
samples, only the parameters of the trained model and the training data that
lie on the margin. Our experiments demonstrate that the proposed method can
determine whether the model has learned the desired features of the training
data. The paper highlights that our understanding of how these models work is
limited, and the proposed approach addresses this issue.
\\ ( https://arxiv.org/abs/2306.06414 ,  1766kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06434
Date: Sat, 10 Jun 2023 12:57:57 GMT   (18162kb,D)

Title: Sliding Window Neural Generated Tracking Based on Measurement Model
Authors: Haya Ejjawi, Amal El Fallah Seghrouchni, Frederic Barbaresco, and Raed
 Abu Zitar
Categories: cs.CV eess.SP
Comments: 7 pages
\\
 In the pursuit of further advancement in the field of target tracking, this
paper explores the efficacy of a feedforward neural network in predicting
drones tracks, aiming to eventually, compare the tracks created by the
well-known Kalman filter and the ones created by our proposed neural network.
The unique feature of our proposed neural network tracker is that it is using
only a measurement model to estimate the next states of the track. Object model
selection and linearization is one of the challenges that always face in the
tracking process. The neural network uses a sliding window to incorporate the
history of measurements when applying estimations of the track values. The
testing results are comparable to the ones generated by the Kalman filter,
especially for the cases where there is low measurement covariance. The
complexity of linearization is avoided when using this proposed model.
\\ ( https://arxiv.org/abs/2306.06434 ,  18162kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06441
Date: Sat, 10 Jun 2023 13:41:02 GMT   (15948kb,D)

Title: Image Vectorization: a Review
Authors: Maria Dziuba, Ivan Jarsky, Valeria Efimova and Andrey Filchenkov
Categories: cs.CV cs.GR
\\
 Nowadays, there are many diffusion and autoregressive models that show
impressive results for generating images from text and other input domains.
However, these methods are not intended for ultra-high-resolution image
synthesis. Vector graphics are devoid of this disadvantage, so the generation
of images in this format looks very promising. Instead of generating vector
images directly, you can first synthesize a raster image and then apply
vectorization. Vectorization is the process of converting a raster image into a
similar vector image using primitive shapes. Besides being similar, generated
vector image is also required to contain the minimum number of shapes for
rendering. In this paper, we focus specifically on machine learning-compatible
vectorization methods. We are considering Mang2Vec, Deep Vectorization of
Technical Drawings, DiffVG, and LIVE models. We also provide a brief overview
of existing online methods. We also recall other algorithmic methods, Im2Vec
and ClipGEN models, but they do not participate in the comparison, since there
is no open implementation of these methods or their official implementations do
not work correctly. Our research shows that despite the ability to directly
specify the number and type of shapes, existing machine learning methods work
for a very long time and do not accurately recreate the original image. We
believe that there is no fast universal automatic approach and human control is
required for every method.
\\ ( https://arxiv.org/abs/2306.06441 ,  15948kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06494
Date: Sat, 10 Jun 2023 17:27:33 GMT   (1250kb,D)

Title: Multi-modal Pre-training for Medical Vision-language Understanding and
 Generation: An Empirical Study with A New Benchmark
Authors: Li Xu, Bo Liu, Ameer Hamza Khan, Lu Fan, Xiao-Ming Wu
Categories: cs.CV cs.AI
Comments: Published as oral paper in CHIL 2023
\\
 With the availability of large-scale, comprehensive, and general-purpose
vision-language (VL) datasets such as MSCOCO, vision-language pre-training
(VLP) has become an active area of research and proven to be effective for
various VL tasks such as visual-question answering. However, studies on VLP in
the medical domain have so far been scanty. To provide a comprehensive
perspective on VLP for medical VL tasks, we conduct a thorough experimental
analysis to study key factors that may affect the performance of VLP with a
unified vision-language Transformer. To allow making sound and quick
pre-training decisions, we propose RadioGraphy Captions (RGC), a high-quality,
multi-modality radiographic dataset containing 18,434 image-caption pairs
collected from an open-access online database MedPix. RGC can be used as a
pre-training dataset or a new benchmark for medical report generation and
medical image-text retrieval. By utilizing RGC and other available datasets for
pre-training, we develop several key insights that can guide future medical VLP
research and new strong baselines for various medical VL tasks.
\\ ( https://arxiv.org/abs/2306.06494 ,  1250kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06505
Date: Sat, 10 Jun 2023 18:42:36 GMT   (14127kb,D)

Title: Vista-Morph: Unsupervised Image Registration of Visible-Thermal Facial
 Pairs
Authors: Catherine Ordun, Edward Raff, Sanjay Purushotham
Categories: cs.CV
\\
 For a variety of biometric cross-spectral tasks, Visible-Thermal (VT) facial
pairs are used. However, due to a lack of calibration in the lab, photographic
capture between two different sensors leads to severely misaligned pairs that
can lead to poor results for person re-identification and generative AI. To
solve this problem, we introduce our approach for VT image registration called
Vista Morph. Unlike existing VT facial registration that requires manual,
hand-crafted features for pixel matching and/or a supervised thermal reference,
Vista Morph is completely unsupervised without the need for a reference. By
learning the affine matrix through a Vision Transformer (ViT)-based Spatial
Transformer Network (STN) and Generative Adversarial Networks (GAN), Vista
Morph successfully aligns facial and non-facial VT images. Our approach learns
warps in Hard, No, and Low-light visual settings and is robust to geometric
perturbations and erasure at test time. We conduct a downstream generative AI
task to show that registering training data with Vista Morph improves subject
identity of generated thermal faces when performing V2T image translation.
\\ ( https://arxiv.org/abs/2306.06505 ,  14127kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06513
Date: Sat, 10 Jun 2023 19:32:47 GMT   (18006kb,D)

Title: Learning Image-Adaptive Codebooks for Class-Agnostic Image Restoration
Authors: Kechun Liu, Yitong Jiang, Inchang Choi, Jinwei Gu
Categories: cs.CV
\\
 Recent work on discrete generative priors, in the form of codebooks, has
shown exciting performance for image reconstruction and restoration, as the
discrete prior space spanned by the codebooks increases the robustness against
diverse image degradations. Nevertheless, these methods require separate
training of codebooks for different image categories, which limits their use to
specific image categories only (e.g. face, architecture, etc.), and fail to
handle arbitrary natural images. In this paper, we propose AdaCode for learning
image-adaptive codebooks for class-agnostic image restoration. Instead of
learning a single codebook for each image category, we learn a set of basis
codebooks. For a given input image, AdaCode learns a weight map with which we
compute a weighted combination of these basis codebooks for adaptive image
restoration. Intuitively, AdaCode is a more flexible and expressive discrete
generative prior than previous work. Experimental results demonstrate that
AdaCode achieves state-of-the-art performance on image reconstruction and
restoration tasks, including image super-resolution and inpainting.
\\ ( https://arxiv.org/abs/2306.06513 ,  18006kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06553
Date: Sun, 11 Jun 2023 00:58:38 GMT   (1644kb,D)

Title: Hinting Pipeline and Multivariate Regression CNN for Maize Kernel
 Counting on the Ear
Authors: Felipe Ara\'ujo, Igor Gadelha, Rodrigo Tsukahara, Luiz Pita, Filipe
 Costa, Igor Vaz, Andreza Santos and Guilherme F\^olego
Categories: cs.CV cs.AI cs.LG
\\
 Maize is a highly nutritional cereal widely used for human and animal
consumption and also as raw material by the biofuels industries. This
highlights the importance of precisely quantifying the corn grain productivity
in season, helping the commercialization process, operationalization, and
critical decision-making. Considering the manual labor cost of counting maize
kernels, we propose in this work a novel preprocessing pipeline named hinting
that guides the attention of the model to the center of the corn kernels and
enables a deep learning model to deliver better performance, given a picture of
one side of the corn ear. Also, we propose a multivariate CNN regressor that
outperforms single regression results. Experiments indicated that the proposed
approach excels the current manual estimates, obtaining MAE of 34.4 and R2 of
0.74 against 35.38 and 0.72 for the manual estimate, respectively.
\\ ( https://arxiv.org/abs/2306.06553 ,  1644kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06577
Date: Sun, 11 Jun 2023 03:58:09 GMT   (10059kb,D)

Title: Semantically-aware Mask CycleGAN for Translating Artistic Portraits to
 Photo-realistic Visualizations
Authors: Zhuohao Yin
Categories: cs.CV
\\
 Image-to-image translation (I2I) is defined as a computer vision task where
the aim is to transfer images in a source domain to a target domain with
minimal loss or alteration of the content representations. Major progress has
been made since I2I was proposed with the invention of a variety of
revolutionary generative models. Among them, GAN-based models perform
exceptionally well as they are mostly tailor-made for specific domains or
tasks. However, few works proposed a tailor-made method for the artistic
domain. In this project, I propose the Semantic-aware Mask CycleGAN
(SMCycleGAN) architecture which can translate artistic portraits to
photo-realistic visualizations. This model can generate realistic human
portraits by feeding the discriminators semantically masked fake samples, thus
enforcing them to make discriminative decisions with partial information so
that the generators can be optimized to synthesize more realistic human
portraits instead of increasing the similarity of other irrelevant components,
such as the background. Experiments have shown that the SMCycleGAN generate
images with significantly increased realism and minimal loss of content
representations.
\\ ( https://arxiv.org/abs/2306.06577 ,  10059kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06583
Date: Sun, 11 Jun 2023 04:15:56 GMT   (7307kb,D)

Title: REACT2023: the first Multi-modal Multiple Appropriate Facial Reaction
 Generation Challenge
Authors: Siyang Song, Micol Spitale, Cheng Luo, German Barquero, Cristina
 Palmero, Sergio Escalera, Michel Valstar, Tobias Baur, Fabien Ringeval,
 Elisabeth Andre and Hatice Gunes
Categories: cs.CV
MSC-class: 68T40
\\
 The Multi-modal Multiple Appropriate Facial Reaction Generation Challenge
(REACT2023) is the first competition event focused on evaluating multimedia
processing and machine learning techniques for generating human-appropriate
facial reactions in various dyadic interaction scenarios, with all participants
competing strictly under the same conditions. The goal of the challenge is to
provide the first benchmark test set for multi-modal information processing and
to foster collaboration among the audio, visual, and audio-visual affective
computing communities, to compare the relative merits of the approaches to
automatic appropriate facial reaction generation under different spontaneous
dyadic interaction conditions. This paper presents: (i) novelties,
contributions and guidelines of the REACT2023 challenge; (ii) the dataset
utilized in the challenge; and (iii) the performance of baseline systems on the
two proposed sub-challenges: Offline Multiple Appropriate Facial Reaction
Generation and Online Multiple Appropriate Facial Reaction Generation,
respectively. The challenge baseline code is publicly available at
\url{https://github.com/reactmultimodalchallenge/baseline_react2023}.
\\ ( https://arxiv.org/abs/2306.06583 ,  7307kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06584
Date: Sun, 11 Jun 2023 04:16:12 GMT   (977kb,D)

Title: Compositional Prototypical Networks for Few-Shot Classification
Authors: Qiang Lyu, Weiqiang Wang
Categories: cs.CV
Comments: Accepted by AAAI 2023
\\
 It is assumed that pre-training provides the feature extractor with strong
class transferability and that high novel class generalization can be achieved
by simply reusing the transferable feature extractor. In this work, our
motivation is to explicitly learn some fine-grained and transferable
meta-knowledge so that feature reusability can be further improved. Concretely,
inspired by the fact that humans can use learned concepts or components to help
them recognize novel classes, we propose Compositional Prototypical Networks
(CPN) to learn a transferable prototype for each human-annotated attribute,
which we call a component prototype. We empirically demonstrate that the
learned component prototypes have good class transferability and can be reused
to construct compositional prototypes for novel classes. Then a learnable
weight generator is utilized to adaptively fuse the compositional and visual
prototypes. Extensive experiments demonstrate that our method can achieve
state-of-the-art results on different datasets and settings. The performance
gains are especially remarkable in the 5-way 1-shot setting. The code is
available at https://github.com/fikry102/CPN.
\\ ( https://arxiv.org/abs/2306.06584 ,  977kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06595
Date: Sun, 11 Jun 2023 05:33:10 GMT   (33317kb,D)

Title: Neural Projection Mapping Using Reflectance Fields
Authors: Yotam Erel, Daisuke Iwai and Amit H. Bermano
Categories: cs.CV
Comments: Project page: https://yoterel.github.io/nepmap-project-page/
\\
 We introduce a high resolution spatially adaptive light source, or a
projector, into a neural reflectance field that allows to both calibrate the
projector and photo realistic light editing. The projected texture is fully
differentiable with respect to all scene parameters, and can be optimized to
yield a desired appearance suitable for applications in augmented reality and
projection mapping. Our neural field consists of three neural networks,
estimating geometry, material, and transmittance. Using an analytical BRDF
model and carefully selected projection patterns, our acquisition process is
simple and intuitive, featuring a fixed uncalibrated projected and a handheld
camera with a co-located light source. As we demonstrate, the virtual projector
incorporated into the pipeline improves scene understanding and enables various
projection mapping applications, alleviating the need for time consuming
calibration steps performed in a traditional setting per view or projector
location. In addition to enabling novel viewpoint synthesis, we demonstrate
state-of-the-art performance projector compensation for novel viewpoints,
improvement over the baselines in material and scene reconstruction, and three
simply implemented scenarios where projection image optimization is performed,
including the use of a 2D generative model to consistently dictate scene
appearance from multiple viewpoints. We believe that neural projection mapping
opens up the door to novel and exciting downstream tasks, through the joint
optimization of the scene and projection images.
\\ ( https://arxiv.org/abs/2306.06595 ,  33317kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06622
Date: Sun, 11 Jun 2023 08:46:42 GMT   (4317kb,D)

Title: Weakly Supervised Visual Question Answer Generation
Authors: Charani Alampalle, Shamanthak Hegde, Soumya Jahagirdar, Shankar
 Gangisetty
Categories: cs.CV
Journal-ref: Proceedings of the IEEE/CVF Conference on Computer Vision and
 Pattern Recognition, Pages: 5588-5596, 2023
\\
 Growing interest in conversational agents promote twoway human-computer
communications involving asking and answering visual questions have become an
active area of research in AI. Thus, generation of visual questionanswer
pair(s) becomes an important and challenging task. To address this issue, we
propose a weakly-supervised visual question answer generation method that
generates a relevant question-answer pairs for a given input image and
associated caption. Most of the prior works are supervised and depend on the
annotated question-answer datasets. In our work, we present a weakly supervised
method that synthetically generates question-answer pairs procedurally from
visual information and captions. The proposed method initially extracts list of
answer words, then does nearest question generation that uses the caption and
answer word to generate synthetic question. Next, the relevant question
generator converts the nearest question to relevant language question by
dependency parsing and in-order tree traversal, finally, fine-tune a ViLBERT
model with the question-answer pair(s) generated at end. We perform an
exhaustive experimental analysis on VQA dataset and see that our model
significantly outperform SOTA methods on BLEU scores. We also show the results
wrt baseline models and ablation study.
\\ ( https://arxiv.org/abs/2306.06622 ,  4317kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06634
Date: Sun, 11 Jun 2023 09:38:45 GMT   (937kb,D)

Title: Adaptive Multi-Teacher Knowledge Distillation with Meta-Learning
Authors: Hailin Zhang, Defang Chen, Can Wang
Categories: cs.CV
Comments: ICME 2023
\\
 Multi-Teacher knowledge distillation provides students with additional
supervision from multiple pre-trained teachers with diverse information
sources. Most existing methods explore different weighting strategies to obtain
a powerful ensemble teacher, while ignoring the student with poor learning
ability may not benefit from such specialized integrated knowledge. To address
this problem, we propose Adaptive Multi-teacher Knowledge Distillation with
Meta-Learning (MMKD) to supervise student with appropriate knowledge from a
tailored ensemble teacher. With the help of a meta-weight network, the diverse
yet compatible teacher knowledge in the output layer and intermediate layers is
jointly leveraged to enhance the student performance. Extensive experiments on
multiple benchmark datasets validate the effectiveness and flexibility of our
methods. Code is available: https://github.com/Rorozhl/MMKD.
\\ ( https://arxiv.org/abs/2306.06634 ,  937kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06635
Date: Sun, 11 Jun 2023 09:41:37 GMT   (9071kb,D)

Title: 2-D SSM: A General Spatial Layer for Visual Transformers
Authors: Ethan Baron, Itamar Zimerman, Lior Wolf
Categories: cs.CV cs.LG
Comments: 16 pages, 5 figures
MSC-class: F.2.2, I.2.7
\\
 A central objective in computer vision is to design models with appropriate
2-D inductive bias. Desiderata for 2D inductive bias include two-dimensional
position awareness, dynamic spatial locality, and translation and permutation
invariance. To address these goals, we leverage an expressive variation of the
multidimensional State Space Model (SSM). Our approach introduces efficient
parameterization, accelerated computation, and a suitable normalization scheme.
Empirically, we observe that incorporating our layer at the beginning of each
transformer block of Vision Transformers (ViT) significantly enhances
performance for multiple ViT backbones and across datasets. The new layer is
effective even with a negligible amount of additional parameters and inference
time. Ablation studies and visualizations demonstrate that the layer has a
strong 2-D inductive bias. For example, vision transformers equipped with our
layer exhibit effective performance even without positional encoding
\\ ( https://arxiv.org/abs/2306.06635 ,  9071kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06638
Date: Sun, 11 Jun 2023 09:52:03 GMT   (19359kb,D)

Title: Face0: Instantaneously Conditioning a Text-to-Image Model on a Face
Authors: Dani Valevski, Danny Wasserman, Yossi Matias, Yaniv Leviathan
Categories: cs.CV cs.AI cs.GR cs.LG
\\
 We present Face0, a novel way to instantaneously condition a text-to-image
generation model on a face, in sample time, without any optimization procedures
such as fine-tuning or inversions. We augment a dataset of annotated images
with embeddings of the included faces and train an image generation model, on
the augmented dataset. Once trained, our system is practically identical at
inference time to the underlying base model, and is therefore able to generate
images, given a user-supplied face image and a prompt, in just a couple of
seconds. Our method achieves pleasing results, is remarkably simple, extremely
fast, and equips the underlying model with new capabilities, like controlling
the generated images both via text or via direct manipulation of the input face
embeddings. In addition, when using a fixed random vector instead of a face
embedding from a user supplied image, our method essentially solves the problem
of consistent character generation across images. Finally, while requiring
further research, we hope that our method, which decouples the model's textual
biases from its biases on faces, might be a step towards some mitigation of
biases in future text-to-image models.
\\ ( https://arxiv.org/abs/2306.06638 ,  19359kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06656
Date: Sun, 11 Jun 2023 12:00:33 GMT   (4358kb,D)

Title: VPUFormer: Visual Prompt Unified Transformer for Interactive Image
 Segmentation
Authors: Xu Zhang, Kailun Yang, Jiacheng Lin, Jin Yuan, Zhiyong Li, Shutao Li
Categories: cs.CV cs.RO eess.IV
Comments: Code will be made publicly available at
 https://github.com/XuZhang1211/VPUFormer
\\
 The integration of diverse visual prompts like clicks, scribbles, and boxes
in interactive image segmentation could significantly facilitate user
interaction as well as improve interaction efficiency. Most existing studies
focus on a single type of visual prompt by simply concatenating prompts and
images as input for segmentation prediction, which suffers from low-efficiency
prompt representation and weak interaction issues. This paper proposes a simple
yet effective Visual Prompt Unified Transformer (VPUFormer), which introduces a
concise unified prompt representation with deeper interaction to boost the
segmentation performance. Specifically, we design a Prompt-unified Encoder
(PuE) by using Gaussian mapping to generate a unified one-dimensional vector
for click, box, and scribble prompts, which well captures users' intentions as
well as provides a denser representation of user prompts. In addition, we
present a Prompt-to-Pixel Contrastive Loss (P2CL) that leverages user feedback
to gradually refine candidate semantic features, aiming to bring image semantic
features closer to the features that are similar to the user prompt, while
pushing away those image semantic features that are dissimilar to the user
prompt, thereby correcting results that deviate from expectations. On this
basis, our approach injects prompt representations as queries into Dual-cross
Merging Attention (DMA) blocks to perform a deeper interaction between image
and query inputs. A comprehensive variety of experiments on seven challenging
datasets demonstrates that the proposed VPUFormer with PuE, DMA, and P2CL
achieves consistent improvements, yielding state-of-the-art segmentation
performance. Our code will be made publicly available at
https://github.com/XuZhang1211/VPUFormer.
\\ ( https://arxiv.org/abs/2306.06656 ,  4358kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06663
Date: Sun, 11 Jun 2023 12:26:41 GMT   (10655kb,D)

Title: LF-PGVIO: A Visual-Inertial-Odometry Framework for Large Field-of-View
 Cameras using Points and Geodesic Segments
Authors: Ze Wang, Kailun Yang, Hao Shi, Yufan Zhang, Fei Gao, Kaiwei Wang
Categories: cs.CV cs.RO eess.IV
Comments: Code will be open-sourced at https://github.com/flysoaryun/LF-PGVIO
\\
 In this paper, we propose LF-PGVIO, a Visual-Inertial-Odometry (VIO)
framework for large Field-of-View (FoV) cameras with a negative plane using
points and geodesic segments. Notoriously, when the FoV of a panoramic camera
reaches the negative half-plane, the image cannot be unfolded into a single
pinhole image. Moreover, if a traditional straight-line detection method is
directly applied to the original panoramic image, it cannot be normally used
due to the large distortions in the panoramas and remains under-explored in the
literature. To address these challenges, we put forward LF-PGVIO, which can
provide line constraints for cameras with large FoV, even for cameras with
negative-plane FoV, and directly extract omnidirectional curve segments from
the raw omnidirectional image. We propose an Omnidirectional Curve Segment
Detection (OCSD) method combined with a camera model which is applicable to
images with large distortions, such as panoramic annular images, fisheye
images, and various panoramic images. Each point on the image is projected onto
the sphere, and the detected omnidirectional curve segments in the image named
geodesic segments must satisfy the criterion of being a geodesic segment on the
unit sphere. The detected geodesic segment is sliced into multiple
straight-line segments according to the radian of the geodesic, and descriptors
are extracted separately and recombined to obtain new descriptors. Based on
descriptor matching, we obtain the constraint relationship of the 3D line
segments between multiple frames. In our VIO system, we use sliding window
optimization using point feature residuals, line feature residuals, and IMU
residuals. Our evaluation of the proposed system on public datasets
demonstrates that LF-PGVIO outperforms state-of-the-art methods in terms of
accuracy and robustness. Code will be open-sourced at
https://github.com/flysoaryun/LF-PGVIO.
\\ ( https://arxiv.org/abs/2306.06663 ,  10655kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06684
Date: Sun, 11 Jun 2023 13:58:36 GMT   (1950kb,D)

Title: Happy People -- Image Synthesis as Black-Box Optimization Problem in the
 Discrete Latent Space of Deep Generative Models
Authors: Steffen Jung, Jan Christian Schwedhelm, Claudia Schillings, Margret
 Keuper
Categories: cs.CV
Comments: CVPR 2023 workshop: Generative Models for Computer Vision
\\
 In recent years, optimization in the learned latent space of deep generative
models has been successfully applied to black-box optimization problems such as
drug design, image generation or neural architecture search. Existing models
thereby leverage the ability of neural models to learn the data distribution
from a limited amount of samples such that new samples from the distribution
can be drawn. In this work, we propose a novel image generative approach that
optimizes the generated sample with respect to a continuously quantifiable
property. While we anticipate absolutely no practically meaningful application
for the proposed framework, it is theoretically principled and allows to
quickly propose samples at the mere boundary of the training data distribution.
Specifically, we propose to use tree-based ensemble models as mathematical
programs over the discrete latent space of vector quantized VAEs, which can be
globally solved. Subsequent weighted retraining on these queries allows to
induce a distribution shift. In lack of a practically relevant problem, we
consider a visually appealing application: the generation of happily smiling
faces (where the training distribution only contains less happy people) - and
show the principled behavior of our approach in terms of improved FID and
higher smile degree over baseline approaches.
\\ ( https://arxiv.org/abs/2306.06684 ,  1950kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06687
Date: Sun, 11 Jun 2023 14:01:17 GMT   (2189kb,D)

Title: LAMM: Language-Assisted Multi-Modal Instruction-Tuning Dataset,
 Framework, and Benchmark
Authors: Zhenfei Yin, Jiong Wang, Jianjian Cao, Zhelun Shi, Dingning Liu, Mukai
 Li, Lu Sheng, Lei Bai, Xiaoshui Huang, Zhiyong Wang, Wanli Ouyang, Jing Shao
Categories: cs.CV
\\
 Large language models have become a potential pathway toward achieving
artificial general intelligence. Recent works on multi-modal large language
models have demonstrated their effectiveness in handling visual modalities. In
this work, we extend the research of MLLMs to point clouds and present the
LAMM-Dataset and LAMM-Benchmark for 2D image and 3D point cloud understanding.
We also establish an extensible framework to facilitate the extension of MLLMs
to additional modalities. Our main contribution is three-fold: 1) We present
the LAMM-Dataset and LAMM-Benchmark, which cover almost all high-level vision
tasks for 2D and 3D vision. Extensive experiments validate the effectiveness of
our dataset and benchmark. 2) We demonstrate the detailed methods of
constructing instruction-tuning datasets and benchmarks for MLLMs, which will
enable future research on MLLMs to scale up and extend to other domains, tasks,
and modalities faster. 3) We provide a primary but potential MLLM training
framework optimized for modalities' extension. We also provide baseline models,
comprehensive experimental observations, and analysis to accelerate future
research.
\\ ( https://arxiv.org/abs/2306.06687 ,  2189kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06691
Date: Sun, 11 Jun 2023 14:25:38 GMT   (443kb,D)

Title: Self-Enhancement Improves Text-Image Retrieval in Foundation
 Visual-Language Models
Authors: Yuguang Yang, Yiming Wang, Shupeng Geng, Runqi Wang, Yimi Wang, Sheng
 Wu, Baochang Zhang
Categories: cs.CV
Comments: Accepted by CVPR 2023 Workshop
\\
 The emergence of cross-modal foundation models has introduced numerous
approaches grounded in text-image retrieval. However, on some domain-specific
retrieval tasks, these models fail to focus on the key attributes required. To
address this issue, we propose a self-enhancement framework, A^{3}R, based on
the CLIP-ViT/G-14, one of the largest cross-modal models. First, we perform an
Attribute Augmentation strategy to enrich the textual description for
fine-grained representation before model learning. Then, we propose an Adaption
Re-ranking method to unify the representation space of textual query and
candidate images and re-rank candidate images relying on the adapted query
after model learning. The proposed framework is validated to achieve a salient
improvement over the baseline and other teams' solutions in the cross-modal
image retrieval track of the 1st foundation model challenge without introducing
any additional samples. The code is available at
\url{https://github.com/CapricornGuang/A3R}.
\\ ( https://arxiv.org/abs/2306.06691 ,  443kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06696
Date: Sun, 11 Jun 2023 14:59:20 GMT   (1192kb,D)

Title: Toward Fair Facial Expression Recognition with Improved Distribution
 Alignment
Authors: Mojtaba Kolahdouzi and Ali Etemad
Categories: cs.CV
\\
 We present a novel approach to mitigate bias in facial expression recognition
(FER) models. Our method aims to reduce sensitive attribute information such as
gender, age, or race, in the embeddings produced by FER models. We employ a
kernel mean shrinkage estimator to estimate the kernel mean of the
distributions of the embeddings associated with different sensitive attribute
groups, such as young and old, in the Hilbert space. Using this estimation, we
calculate the maximum mean discrepancy (MMD) distance between the distributions
and incorporate it in the classifier loss along with an adversarial loss, which
is then minimized through the learning process to improve the distribution
alignment. Our method makes sensitive attributes less recognizable for the
model, which in turn promotes fairness. Additionally, for the first time, we
analyze the notion of attractiveness as an important sensitive attribute in FER
models and demonstrate that FER models can indeed exhibit biases towards more
attractive faces. To prove the efficacy of our model in reducing bias regarding
different sensitive attributes (including the newly proposed attractiveness
attribute), we perform several experiments on two widely used datasets, CelebA
and RAF-DB. The results in terms of both accuracy and fairness measures
outperform the state-of-the-art in most cases, demonstrating the effectiveness
of the proposed method.
\\ ( https://arxiv.org/abs/2306.06696 ,  1192kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06717
Date: Sun, 11 Jun 2023 16:36:31 GMT   (227kb,D)

Title: PWR-Align: Leveraging Part-Whole Relationships for Part-wise Rigid Point
 Cloud Registration in Mixed Reality Applications
Authors: Manorama Jha, Bhaskar Banerjee
Categories: cs.CV cs.GR
Comments: Accepted for presentation at WiCV @ CVPR 2023
\\
 We present an efficient and robust point cloud registration (PCR) workflow
for part-wise rigid point cloud alignment using the Microsoft HoloLens 2. Point
Cloud Registration (PCR) is an important problem in Augmented and Mixed Reality
use cases, and we present a study for a special class of non-rigid
transformations. Many commonly encountered objects are composed of rigid parts
that move relative to one another about joints resulting in non-rigid
deformation of the whole object such as robots with manipulators, and machines
with hinges. The workflow presented allows us to register the point cloud with
various configurations of the point cloud.
\\ ( https://arxiv.org/abs/2306.06717 ,  227kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06722
Date: Sun, 11 Jun 2023 16:48:03 GMT   (1671kb,D)

Title: $E(2)$-Equivariant Vision Transformer
Authors: Renjun Xu and Kaifan Yang and Ke Liu and Fengxiang He
Categories: cs.CV cs.AI
Comments: Accept to UAI2023
\\
 Vision Transformer (ViT) has achieved remarkable performance in computer
vision. However, positional encoding in ViT makes it substantially difficult to
learn the intrinsic equivariance in data. Initial attempts have been made on
designing equivariant ViT but are proved defective in some cases in this paper.
To address this issue, we design a Group Equivariant Vision Transformer
(GE-ViT) via a novel, effective positional encoding operator. We prove that
GE-ViT meets all the theoretical requirements of an equivariant neural network.
Comprehensive experiments are conducted on standard benchmark datasets,
demonstrating that GE-ViT significantly outperforms non-equivariant
self-attention networks. The code is available at
https://github.com/ZJUCDSYangKaifan/GEVit.
\\ ( https://arxiv.org/abs/2306.06722 ,  1671kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06753
Date: Sun, 11 Jun 2023 19:44:40 GMT   (7379kb,D)

Title: 3rd Place Solution for PVUW Challenge 2023: Video Panoptic Segmentation
Authors: Jinming Su, Wangwang Yang, Junfeng Luo and Xiaolin Wei
Categories: cs.CV
Comments: 3rd Place Solution for PVUW Challenge 2023: Video Panoptic
 Segmentation
\\
 In order to deal with the task of video panoptic segmentation in the wild, we
propose a robust integrated video panoptic segmentation solution. In our
solution, we regard the video panoptic segmentation task as a segmentation
target querying task, represent both semantic and instance targets as a set of
queries, and then combine these queries with video features extracted by neural
networks to predict segmentation masks. In order to improve the learning
accuracy and convergence speed of the solution, we add additional tasks of
video semantic segmentation and video instance segmentation for joint training.
In addition, we also add an additional image semantic segmentation model to
further improve the performance of semantic classes. In addition, we also add
some additional operations to improve the robustness of the model. Extensive
experiments on the VIPSeg dataset show that the proposed solution achieves
state-of-the-art performance with 50.04\% VPQ on the VIPSeg test set, which is
3rd place on the video panoptic segmentation track of the PVUW Challenge 2023.
\\ ( https://arxiv.org/abs/2306.06753 ,  7379kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06767
Date: Sun, 11 Jun 2023 20:39:13 GMT   (122kb,D)

Title: The Impact of ChatGPT and LLMs on Medical Imaging Stakeholders:
 Perspectives and Use Cases
Authors: Jiancheng Yang, Hongwei Bran Li, Donglai Wei
Categories: cs.CV cs.AI cs.LG
\\
 This study investigates the transformative potential of Large Language Models
(LLMs), such as OpenAI ChatGPT, in medical imaging. With the aid of public
data, these models, which possess remarkable language understanding and
generation capabilities, are augmenting the interpretive skills of
radiologists, enhancing patient-physician communication, and streamlining
clinical workflows. The paper introduces an analytic framework for presenting
the complex interactions between LLMs and the broader ecosystem of medical
imaging stakeholders, including businesses, insurance entities, governments,
research institutions, and hospitals (nicknamed BIGR-H). Through detailed
analyses, illustrative use cases, and discussions on the broader implications
and future directions, this perspective seeks to raise discussion in strategic
planning and decision-making in the era of AI-enabled healthcare.
\\ ( https://arxiv.org/abs/2306.06767 ,  122kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06797
Date: Sun, 11 Jun 2023 22:30:23 GMT   (3378kb,D)

Title: VBSF-TLD: Validation-Based Approach for Soft Computing-Inspired Transfer
 Learning in Drone Detection
Authors: Jaskaran Singh
Categories: cs.CV cs.AI
\\
 With the increasing utilization of Internet of Things (IoT) enabled drones in
diverse applications like photography, delivery, and surveillance, concerns
regarding privacy and security have become more prominent. Drones have the
ability to capture sensitive information, compromise privacy, and pose security
risks. As a result, the demand for advanced technology to automate drone
detection has become crucial. This paper presents a project on a transfer-based
drone detection scheme, which forms an integral part of a computer vision-based
module and leverages transfer learning to enhance performance. By harnessing
the knowledge of pre-trained models from a related domain, transfer learning
enables improved results even with limited training data. To evaluate the
scheme's performance, we conducted tests on benchmark datasets, including the
Drone-vs-Bird Dataset and the UAVDT dataset. Notably, the scheme's
effectiveness is highlighted by its IOU-based validation results, demonstrating
the potential of deep learning-based technology in automating drone detection
in critical areas such as airports, military bases, and other high-security
zones.
\\ ( https://arxiv.org/abs/2306.06797 ,  3378kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06803
Date: Sun, 11 Jun 2023 23:11:29 GMT   (3752kb,D)

Title: Stable Remaster: Bridging the Gap Between Old Content and New Displays
Authors: Nathan Paull, Shuvam Keshari, Yian Wong
Categories: cs.CV cs.AI
\\
 The invention of modern displays has enhanced the viewer experience for any
kind of content: ranging from sports to movies in 8K high-definition
resolution. However, older content developed for CRT or early Plasma screen TVs
has become outdated quickly and no longer meets current aspect ratio and
resolution standards. In this paper, we explore whether we can solve this
problem with the use of diffusion models to adapt old content to meet
contemporary expectations. We explore the ability to combine multiple
independent computer vision tasks to attempt to solve the problem of expanding
aspect ratios of old animated content such that the new content would be
indistinguishable from the source material to a brand-new viewer. These
existing capabilities include Stable Diffusion, Content-Aware Scene Detection,
Object Detection, and Key Point Matching. We were able to successfully chain
these tasks together in a way that generated reasonable outputs, however,
future work needs to be done to improve and expand the application to
non-animated content as well.
\\ ( https://arxiv.org/abs/2306.06803 ,  3752kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06805
Date: Sun, 11 Jun 2023 23:33:59 GMT   (12637kb,D)

Title: Unlocking Feature Visualization for Deeper Networks with MAgnitude
 Constrained Optimization
Authors: Thomas Fel, Thibaut Boissin, Victor Boutin, Agustin Picard, Paul
 Novello, Julien Colin, Drew Linsley, Tom Rousseau, R\'emi Cad\`ene, Laurent
 Gardes, Thomas Serre
Categories: cs.CV cs.AI
\\
 Feature visualization has gained substantial popularity, particularly after
the influential work by Olah et al. in 2017, which established it as a crucial
tool for explainability. However, its widespread adoption has been limited due
to a reliance on tricks to generate interpretable images, and corresponding
challenges in scaling it to deeper neural networks. Here, we describe MACO, a
simple approach to address these shortcomings. The main idea is to generate
images by optimizing the phase spectrum while keeping the magnitude constant to
ensure that generated explanations lie in the space of natural images. Our
approach yields significantly better results (both qualitatively and
quantitatively) and unlocks efficient and interpretable feature visualizations
for large state-of-the-art neural networks. We also show that our approach
exhibits an attribution mechanism allowing us to augment feature visualizations
with spatial importance. We validate our method on a novel benchmark for
comparing feature visualization methods, and release its visualizations for all
classes of the ImageNet dataset on https://serre-lab.github.io/Lens/.
 Overall, our approach unlocks, for the first time, feature visualizations for
large, state-of-the-art deep neural networks without resorting to any
parametric prior image model.
\\ ( https://arxiv.org/abs/2306.06805 ,  12637kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06823
Date: Mon, 12 Jun 2023 02:22:30 GMT   (1751kb,D)

Title: Weakly supervised information extraction from inscrutable handwritten
 document images
Authors: Sujoy Paul and Gagan Madan and Akankshya Mishra and Narayan Hegde and
 Pradeep Kumar and Gaurav Aggarwal
Categories: cs.CV cs.CL
Comments: Accepted at ICDAR 2023
\\
 State-of-the-art information extraction methods are limited by OCR errors.
They work well for printed text in form-like documents, but unstructured,
handwritten documents still remain a challenge. Adapting existing models to
domain-specific training data is quite expensive, because of two factors, 1)
limited availability of the domain-specific documents (such as handwritten
prescriptions, lab notes, etc.), and 2) annotations become even more
challenging as one needs domain-specific knowledge to decode inscrutable
handwritten document images. In this work, we focus on the complex problem of
extracting medicine names from handwritten prescriptions using only weakly
labeled data. The data consists of images along with the list of medicine names
in it, but not their location in the image. We solve the problem by first
identifying the regions of interest, i.e., medicine lines from just weak labels
and then injecting a domain-specific medicine language model learned using only
synthetically generated data. Compared to off-the-shelf state-of-the-art
methods, our approach performs >2.5x better in medicine names extraction from
prescriptions.
\\ ( https://arxiv.org/abs/2306.06823 ,  1751kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06842
Date: Mon, 12 Jun 2023 03:28:18 GMT   (47729kb,D)

Title: AerialFormer: Multi-resolution Transformer for Aerial Image Segmentation
Authors: Kashu Yamazaki, Taisei Hanyu, Minh Tran, Adrian Garcia, Anh Tran, Roy
 McCann, Haitao Liao, Chase Rainwater, Meredith Adkins, Andrew Molthan,
 Jackson Cothren, Ngan Le
Categories: cs.CV
\\
 Aerial Image Segmentation is a top-down perspective semantic segmentation and
has several challenging characteristics such as strong imbalance in the
foreground-background distribution, complex background, intra-class
heterogeneity, inter-class homogeneity, and tiny objects. To handle these
problems, we inherit the advantages of Transformers and propose AerialFormer,
which unifies Transformers at the contracting path with lightweight
Multi-Dilated Convolutional Neural Networks (MD-CNNs) at the expanding path.
Our AerialFormer is designed as a hierarchical structure, in which Transformer
encoder outputs multi-scale features and MD-CNNs decoder aggregates information
from the multi-scales. Thus, it takes both local and global contexts into
consideration to render powerful representations and high-resolution
segmentation. We have benchmarked AerialFormer on three common datasets
including iSAID, LoveDA, and Potsdam. Comprehensive experiments and extensive
ablation studies show that our proposed AerialFormer outperforms previous
state-of-the-art methods with remarkable performance. Our source code will be
publicly available upon acceptance.
\\ ( https://arxiv.org/abs/2306.06842 ,  47729kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06870
Date: Mon, 12 Jun 2023 05:06:53 GMT   (3284kb,D)

Title: Sticker820K: Empowering Interactive Retrieval with Stickers
Authors: Sijie Zhao, Yixiao Ge, Zhongang Qi, Lin Song, Xiaohan Ding, Zehua Xie,
 Ying Shan
Categories: cs.CV cs.AI
\\
 Stickers have become a ubiquitous part of modern-day communication, conveying
complex emotions through visual imagery. To facilitate the development of more
powerful algorithms for analyzing stickers, we propose a large-scale Chinese
sticker dataset, namely Sticker820K, which consists of 820k image-text pairs.
Each sticker has rich and high-quality textual annotations, including
descriptions, optical characters, emotional labels, and style classifications.
Although vision-language tasks in the domain of natural images have been well
studied, directly applying the those models, such as CLIP, to sticker data is
not an optimal solution due to the discrepant nature between natural and
emotive image data. Therefore, we propose StickerCLIP as a benchmark model on
the Sticker820K dataset. For the text-to-image retrieval task, our StickerCLIP
demonstrates strong superiority over the CLIP, which achieves an absolute gain
of 66.0\% in mean recall on the Sticker820K test set. Additionally, we endeavor
to extend the recently popularized LLM by means of prompt tuning, integrating
its ability for sticker retrieval and allowing users to retrieve stickers
through instructions. We validate the feasibility of this method, demonstrating
the immense potential of prompt tuning in expanding LLM abilities while not
affecting the quality of upstream tasks.
\\ ( https://arxiv.org/abs/2306.06870 ,  3284kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06877
Date: Mon, 12 Jun 2023 05:30:09 GMT   (2603kb,D)

Title: Boosting Breast Ultrasound Video Classification by the Guidance of
 Keyframe Feature Centers
Authors: AnLan Sun, Zhao Zhang, Meng Lei, Yuting Dai, Dong Wang, Liwei Wang
Categories: cs.CV
Comments: Medical Image Computing and Computer-Assisted Intervention 2023
\\
 Breast ultrasound videos contain richer information than ultrasound images,
therefore it is more meaningful to develop video models for this diagnosis
task. However, the collection of ultrasound video datasets is much harder. In
this paper, we explore the feasibility of enhancing the performance of
ultrasound video classification using the static image dataset. To this end, we
propose KGA-Net and coherence loss. The KGA-Net adopts both video clips and
static images to train the network. The coherence loss uses the feature centers
generated by the static images to guide the frame attention in the video model.
Our KGA-Net boosts the performance on the public BUSV dataset by a large
margin. The visualization results of frame attention prove the explainability
of our method. The codes and model weights of our method will be made publicly
available.
\\ ( https://arxiv.org/abs/2306.06877 ,  2603kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06881
Date: Mon, 12 Jun 2023 05:49:23 GMT   (4490kb,D)

Title: Unmasking Deepfakes: Masked Autoencoding Spatiotemporal Transformers for
 Enhanced Video Forgery Detection
Authors: Sayantan Das, Mojtaba Kolahdouzi, Levent \"Ozparlak, Will Hickie, Ali
 Etemad
Categories: cs.CV
\\
 We present a novel approach for the detection of deepfake videos using a pair
of vision transformers pre-trained by a self-supervised masked autoencoding
setup. Our method consists of two distinct components, one of which focuses on
learning spatial information from individual RGB frames of the video, while the
other learns temporal consistency information from optical flow fields
generated from consecutive frames. Unlike most approaches where pre-training is
performed on a generic large corpus of images, we show that by pre-training on
smaller face-related datasets, namely Celeb-A (for the spatial learning
component) and YouTube Faces (for the temporal learning component), strong
results can be obtained. We perform various experiments to evaluate the
performance of our method on commonly used datasets namely FaceForensics++ (Low
Quality and High Quality, along with a new highly compressed version named Very
Low Quality) and Celeb-DFv2 datasets. Our experiments show that our method sets
a new state-of-the-art on FaceForensics++ (LQ, HQ, and VLQ), and obtains
competitive results on Celeb-DFv2. Moreover, our method outperforms other
methods in the area in a cross-dataset setup where we fine-tune our model on
FaceForensics++ and test on CelebDFv2, pointing to its strong cross-dataset
generalization ability.
\\ ( https://arxiv.org/abs/2306.06881 ,  4490kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06885
Date: Mon, 12 Jun 2023 06:06:05 GMT   (8441kb,D)

Title: NPVForensics: Jointing Non-critical Phonemes and Visemes for Deepfake
 Detection
Authors: Yu Chen, Yang Yu, Rongrong Ni, Yao Zhao, Haoliang Li
Categories: cs.CV
\\
 Deepfake technologies empowered by deep learning are rapidly evolving,
creating new security concerns for society. Existing multimodal detection
methods usually capture audio-visual inconsistencies to expose Deepfake videos.
More seriously, the advanced Deepfake technology realizes the audio-visual
calibration of the critical phoneme-viseme regions, achieving a more realistic
tampering effect, which brings new challenges. To address this problem, we
propose a novel Deepfake detection method to mine the correlation between
Non-critical Phonemes and Visemes, termed NPVForensics. Firstly, we propose the
Local Feature Aggregation block with Swin Transformer (LFA-ST) to construct
non-critical phoneme-viseme and corresponding facial feature streams
effectively. Secondly, we design a loss function for the fine-grained motion of
the talking face to measure the evolutionary consistency of non-critical
phoneme-viseme. Next, we design a phoneme-viseme awareness module for
cross-modal feature fusion and representation alignment, so that the modality
gap can be reduced and the intrinsic complementarity of the two modalities can
be better explored. Finally, a self-supervised pre-training strategy is
leveraged to thoroughly learn the audio-visual correspondences in natural
videos. In this manner, our model can be easily adapted to the downstream
Deepfake datasets with fine-tuning. Extensive experiments on existing
benchmarks demonstrate that the proposed approach outperforms state-of-the-art
methods.
\\ ( https://arxiv.org/abs/2306.06885 ,  8441kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06893
Date: Mon, 12 Jun 2023 06:46:42 GMT   (2578kb,D)

Title: In-context Cross-Density Adaptation on Noisy Mammogram Abnormalities
 Detection
Authors: Huy T. Nguyen, Thinh B. Lam, Quan D.D. Tran, Minh T. Nguyen, Dat T.
 Chung, and Vinh Q. Dinh
Categories: cs.CV cs.AI
\\
 This paper investigates the impact of breast density distribution on the
generalization performance of deep-learning models on mammography images using
the VinDr-Mammo dataset. We explore the use of domain adaptation techniques,
specifically Domain Adaptive Object Detection (DAOD) with the Noise Latent
Transferability Exploration (NLTE) framework, to improve model performance
across breast densities under noisy labeling circumstances. We propose a robust
augmentation framework to bridge the domain gap between the source and target
inside a dataset. Our results show that DAOD-based methods, along with the
proposed augmentation framework, can improve the generalization performance of
deep-learning models (+5% overall mAP improvement approximately in our
experimental results compared to commonly used detection models). This paper
highlights the importance of domain adaptation techniques in medical imaging,
particularly in the context of breast density distribution, which is critical
in mammography.
\\ ( https://arxiv.org/abs/2306.06893 ,  2578kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06899
Date: Mon, 12 Jun 2023 07:06:01 GMT   (6124kb,D)

Title: Augmenting Zero-Shot Detection Training with Image Labels
Authors: Katharina Kornmeier, Ulla Scheler, Pascal Herrmann
Categories: cs.CV cs.AI
\\
 Zero-shot detection (ZSD), i.e., detection on classes not seen during
training, is essential for real world detection use-cases, but remains a
difficult task. Recent research attempts ZSD with detection models that output
embeddings instead of direct class labels. To this aim, the output of the
detection model must be aligned to a learned embedding space such as CLIP.
However, this alignment is hindered by detection data sets which are expensive
to produce compared to image classification annotations, and the resulting lack
of category diversity in the training data. We address this challenge by
leveraging the CLIP embedding space in combination with image labels from
ImageNet. Our results show that image labels are able to better align the
detector output to the embedding space and thus have a high potential for ZSD.
Compared to only training on detection data, we see a significant gain by
adding image label data of 3.3 mAP for the 65/15 split on COCO on the unseen
classes, i.e., we more than double the gain of related work.
\\ ( https://arxiv.org/abs/2306.06899 ,  6124kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06908
Date: Mon, 12 Jun 2023 07:26:21 GMT   (223kb,D)

Title: Active Learning Guided Fine-Tuning for enhancing Self-Supervised Based
 Multi-Label Classification of Remote Sensing Images
Authors: Lars M\"ollenbrok and Beg\"um Demir
Categories: cs.CV
\\
 In recent years, deep neural networks (DNNs) have been found very successful
for multi-label classification (MLC) of remote sensing (RS) images.
Self-supervised pre-training combined with fine-tuning on a randomly selected
small training set has become a popular approach to minimize annotation efforts
of data-demanding DNNs. However, fine-tuning on a small and biased training set
may limit model performance. To address this issue, we investigate the
effectiveness of the joint use of self-supervised pre-training with active
learning (AL). The considered AL strategy aims at guiding the MLC fine-tuning
of a self-supervised model by selecting informative training samples to
annotate in an iterative manner. Experimental results show the effectiveness of
applying AL-guided fine-tuning (particularly for the case where strong
class-imbalance is present in MLC problems) compared to the application of
fine-tuning using a randomly constructed small training set.
\\ ( https://arxiv.org/abs/2306.06908 ,  223kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06928
Date: Mon, 12 Jun 2023 08:07:23 GMT   (547kb,D)

Title: Sparse-Inductive Generative Adversarial Hashing for Nearest Neighbor
 Search
Authors: Hong Liu
Categories: cs.CV cs.LG
Comments: 18 pages, 8 figures, 7 tables
\\
 Unsupervised hashing has received extensive research focus on the past
decade, which typically aims at preserving a predefined metric (i.e. Euclidean
metric) in the Hamming space. To this end, the encoding functions of the
existing hashing are typically quasi-isometric, which devote to reducing the
quantization loss from the target metric space to the discrete Hamming space.
However, it is indeed problematic to directly minimize such error, since such
mentioned two metric spaces are heterogeneous, and the quasi-isometric mapping
is non-linear. The former leads to inconsistent feature distributions, while
the latter leads to problematic optimization issues. In this paper, we propose
a novel unsupervised hashing method, termed Sparsity-Induced Generative
Adversarial Hashing (SiGAH), to encode large-scale high-dimensional features
into binary codes, which well solves the two problems through a generative
adversarial training framework. Instead of minimizing the quantization loss,
our key innovation lies in enforcing the learned Hamming space to have similar
data distribution to the target metric space via a generative model. In
particular, we formulate a ReLU-based neural network as a generator to output
binary codes and an MSE-loss based auto-encoder network as a discriminator,
upon which a generative adversarial learning is carried out to train hash
functions. Furthermore, to generate the synthetic features from the hash codes,
a compressed sensing procedure is introduced into the generative model, which
enforces the reconstruction boundary of binary codes to be consistent with that
of original features. Finally, such generative adversarial framework can be
trained via the Adam optimizer. Experimental results on four benchmarks, i.e.,
Tiny100K, GIST1M, Deep1M, and MNIST, have shown that the proposed SiGAH has
superior performance over the state-of-the-art approaches.
\\ ( https://arxiv.org/abs/2306.06928 ,  547kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06934
Date: Mon, 12 Jun 2023 08:14:12 GMT   (1451kb)

Title: Scale-Rotation-Equivariant Lie Group Convolution Neural Networks (Lie
 Group-CNNs)
Authors: Wei-Dong Qiao, Yang Xu, and Hui Li
Categories: cs.CV
\\
 The weight-sharing mechanism of convolutional kernels ensures
translation-equivariance of convolution neural networks (CNNs). Recently,
rotation-equivariance has been investigated. However, research on
scale-equivariance or simultaneous scale-rotation-equivariance is insufficient.
This study proposes a Lie group-CNN, which can keep scale-rotation-equivariance
for image classification tasks. The Lie group-CNN includes a lifting module, a
series of group convolution modules, a global pooling layer, and a
classification layer. The lifting module transfers the input image from
Euclidean space to Lie group space, and the group convolution is parameterized
through a fully connected network using Lie-algebra of Lie-group elements as
inputs to achieve scale-rotation-equivariance. The Lie group SIM(2) is utilized
to establish the Lie group-CNN with scale-rotation-equivariance.
Scale-rotation-equivariance of Lie group-CNN is verified and achieves the best
recognition accuracy on the blood cell dataset (97.50%) and the HAM10000
dataset (77.90%) superior to Lie algebra convolution network, dilation
convolution, spatial transformer network, and scale-equivariant steerable
network. In addition, the generalization ability of the Lie group-CNN on SIM(2)
on rotation-equivariance is verified on rotated-MNIST and rotated-CIFAR10, and
the robustness of the network is verified on SO(2) and SE(2). Therefore, the
Lie group-CNN can successfully extract geometric features and performs
equivariant recognition on images with rotation and scale transformations.
\\ ( https://arxiv.org/abs/2306.06934 ,  1451kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06960
Date: Mon, 12 Jun 2023 08:46:02 GMT   (27812kb,D)

Title: Semantic Parsing of Colonoscopy Videos with Multi-Label Temporal
 Networks
Authors: Ori Kelner, Or Weinstein, Ehud Rivlin, and Roman Goldenberg
Categories: cs.CV
\\
 Following the successful debut of polyp detection and characterization, more
advanced automation tools are being developed for colonoscopy. The new
automation tasks, such as quality metrics or report generation, require
understanding of the procedure flow that includes activities, events,
anatomical landmarks, etc. In this work we present a method for automatic
semantic parsing of colonoscopy videos. The method uses a novel DL multi-label
temporal segmentation model trained in supervised and unsupervised regimes. We
evaluate the accuracy of the method on a test set of over 300 annotated
colonoscopy videos, and use ablation to explore the relative importance of
various method's components.
\\ ( https://arxiv.org/abs/2306.06960 ,  27812kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06963
Date: Mon, 12 Jun 2023 08:50:46 GMT   (5631kb,D)

Title: Feature Fusion from Head to Tail: an Extreme Augmenting Strategy for
 Long-Tailed Visual Recognition
Authors: Mengke Li, Zhikai Hu, Yang Lu, Weichao Lan, Yiu-ming Cheung, Hui Huang
Categories: cs.CV
\\
 The imbalanced distribution of long-tailed data poses a challenge for deep
neural networks, as models tend to prioritize correctly classifying head
classes over others so that perform poorly on tail classes. The lack of
semantics for tail classes is one of the key factors contributing to their low
recognition accuracy. To rectify this issue, we propose to augment tail classes
by borrowing the diverse semantic information from head classes, referred to as
head-to-tail fusion (H2T). We randomly replace a portion of the feature maps of
the tail class with those of the head class. The fused feature map can
effectively enhance the diversity of tail classes by incorporating features
from head classes that are relevant to them. The proposed method is easy to
implement due to its additive fusion module, making it highly compatible with
existing long-tail recognition methods for further performance boosting.
Extensive experiments on various long-tailed benchmarks demonstrate the
effectiveness of the proposed H2T. The source code is temporarily available at
https://github.com/Keke921/H2T.
\\ ( https://arxiv.org/abs/2306.06963 ,  5631kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06991
Date: Mon, 12 Jun 2023 09:38:04 GMT   (4194kb,D)

Title: Fast Diffusion Model
Authors: Zike Wu, Pan Zhou, Kenji Kawaguchi, Hanwang Zhang
Categories: cs.CV cs.AI cs.LG
\\
 Despite their success in real data synthesis, diffusion models (DMs) often
suffer from slow and costly training and sampling issues, limiting their
broader applications. To mitigate this, we propose a Fast Diffusion Model (FDM)
which improves the diffusion process of DMs from a stochastic optimization
perspective to speed up both training and sampling. Specifically, we first find
that the diffusion process of DMs accords with the stochastic optimization
process of stochastic gradient descent (SGD) on a stochastic time-variant
problem. Note that momentum SGD uses both the current gradient and an extra
momentum, achieving more stable and faster convergence. We are inspired to
introduce momentum into the diffusion process to accelerate both training and
sampling. However, this comes with the challenge of deriving the noise
perturbation kernel from the momentum-based diffusion process. To this end, we
frame the momentum-based process as a Damped Oscillation system whose
critically damped state -- the kernel solution -- avoids oscillation and thus
has a faster convergence speed of the diffusion process. Empirical results show
that our FDM can be applied to several popular DM frameworks, e.g. VP, VE, and
EDM, and reduces their training cost by about 50% with comparable image
synthesis performance on CIFAR-10, FFHQ, and AFHQv2 datasets. Moreover, FDM
decreases their sampling steps by about $3\times$ to achieve similar
performance under the same deterministic samplers. The code is available at
https://github.com/sail-sg/FDM.
\\ ( https://arxiv.org/abs/2306.06991 ,  4194kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06997
Date: Mon, 12 Jun 2023 09:50:36 GMT   (10107kb,D)

Title: Slot-VAE: Object-Centric Scene Generation with Slot Attention
Authors: Yanbo Wang, Letao Liu, Justin Dauwels
Categories: cs.CV
\\
 Slot attention has shown remarkable object-centric representation learning
performance in computer vision tasks without requiring any supervision. Despite
its object-centric binding ability brought by compositional modelling, as a
deterministic module, slot attention lacks the ability to generate novel
scenes. In this paper, we propose the Slot-VAE, a generative model that
integrates slot attention with the hierarchical VAE framework for
object-centric structured scene generation. For each image, the model
simultaneously infers a global scene representation to capture high-level scene
structure and object-centric slot representations to embed individual object
components. During generation, slot representations are generated from the
global scene representation to ensure coherent scene structures. Our extensive
evaluation of the scene generation ability indicates that Slot-VAE outperforms
slot representation-based generative baselines in terms of sample quality and
scene structure accuracy.
\\ ( https://arxiv.org/abs/2306.06997 ,  10107kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07005
Date: Mon, 12 Jun 2023 10:19:13 GMT   (26367kb,D)

Title: AI-Generated Image Detection using a Cross-Attention Enhanced
 Dual-Stream Network
Authors: Ziyi Xi, Wenmin Huang, Kangkang Wei, Weiqi Luo and Peijia Zheng
Categories: cs.CV cs.CR
Comments: 8 pages, 41 figures
\\
 With the rapid evolution of AI Generated Content (AIGC), forged images
produced through this technology are inherently more deceptive and require less
human intervention compared to traditional Computer-generated Graphics (CG).
However, owing to the disparities between CG and AIGC, conventional CG
detection methods tend to be inadequate in identifying AIGC-produced images. To
address this issue, our research concentrates on the text-to-image generation
process in AIGC. Initially, we first assemble two text-to-image databases
utilizing two distinct AI systems, DALLE2 and DreamStudio. Aiming to
holistically capture the inherent anomalies produced by AIGC, we develope a
robust dual-stream network comprised of a residual stream and a content stream.
The former employs the Spatial Rich Model (SRM) to meticulously extract various
texture information from images, while the latter seeks to capture additional
forged traces in low frequency, thereby extracting complementary information
that the residual stream may overlook. To enhance the information exchange
between these two streams, we incorporate a cross multi-head attention
mechanism. Numerous comparative experiments are performed on both databases,
and the results show that our detection method consistently outperforms
traditional CG detection techniques across a range of image resolutions.
Moreover, our method exhibits superior performance through a series of
robustness tests and cross-database experiments. When applied to widely
recognized traditional CG benchmarks such as SPL2018 and DsTok, our approach
significantly exceeds the capabilities of other existing methods in the field
of CG detection.
\\ ( https://arxiv.org/abs/2306.07005 ,  26367kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07027
Date: Mon, 12 Jun 2023 11:04:11 GMT   (873kb)

Title: Rotational augmentation techniques: a new perspective on ensemble
 learning for image classification
Authors: Unai Mu\~noz-Aseguinolaza, Basilio Sierra and Naiara Aginako
Categories: cs.CV cs.AI cs.LG
Comments: 15 pages, 5 figures and 5 tables
\\
 The popularity of data augmentation techniques in machine learning has
increased in recent years, as they enable the creation of new samples from
existing datasets. Rotational augmentation, in particular, has shown great
promise by revolving images and utilising them as additional data points for
training. This research study introduces a new approach to enhance the
performance of classification methods where the testing sets were generated
employing transformations on every image from the original dataset.
Subsequently, ensemble-based systems were implemented to determine the most
reliable outcome in each subset acquired from the augmentation phase to get a
final prediction for every original image. The findings of this study suggest
that rotational augmentation techniques can significantly improve the accuracy
of standard classification models; and the selection of a voting scheme can
considerably impact the model's performance. Overall, the study found that
using an ensemble-based voting system produced more accurate results than
simple voting.
\\ ( https://arxiv.org/abs/2306.07027 ,  873kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07030
Date: Mon, 12 Jun 2023 11:09:16 GMT   (92kb,D)

Title: Resource Efficient Neural Networks Using Hessian Based Pruning
Authors: Jack Chong, Manas Gupta, Lihui Chen
Categories: cs.CV cs.AI
Comments: 9 pages, 1 figure
\\
 Neural network pruning is a practical way for reducing the size of trained
models and the number of floating-point operations. One way of pruning is to
use the relative Hessian trace to calculate sensitivity of each channel, as
compared to the more common magnitude pruning approach. However, the stochastic
approach used to estimate the Hessian trace needs to iterate over many times
before it can converge. This can be time-consuming when used for larger models
with many millions of parameters. To address this problem, we modify the
existing approach by estimating the Hessian trace using FP16 precision instead
of FP32. We test the modified approach (EHAP) on
ResNet-32/ResNet-56/WideResNet-28-8 trained on CIFAR10/CIFAR100 image
classification tasks and achieve faster computation of the Hessian trace.
Specifically, our modified approach can achieve speed ups ranging from 17% to
as much as 44% during our experiments on different combinations of model
architectures and GPU devices. Our modified approach also takes up around 40%
less GPU memory when pruning ResNet-32 and ResNet-56 models, which allows for a
larger Hessian batch size to be used for estimating the Hessian trace.
Meanwhile, we also present the results of pruning using both FP16 and FP32
Hessian trace calculation and show that there are no noticeable accuracy
differences between the two. Overall, it is a simple and effective way to
compute the relative Hessian trace faster without sacrificing on pruned model
performance. We also present a full pipeline using EHAP and quantization aware
training (QAT), using INT8 QAT to compress the network further after pruning.
In particular, we use symmetric quantization for the weights and asymmetric
quantization for the activations.
\\ ( https://arxiv.org/abs/2306.07030 ,  92kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07045
Date: Mon, 12 Jun 2023 11:45:59 GMT   (3383kb,D)

Title: Data-Driven Bilateral Generalized Two-Dimensional Quaternion Principal
 Component Analysis with Application to Color Face Recognition
Authors: Mei-Xiang Zhao, Zhi-Gang Jia, Dun-Wei Gong and Yong Zhang
Categories: cs.CV
\\
 A new data-driven bilateral generalized two-dimensional quaternion principal
component analysis (BiG2DQPCA) is presented to extract the features of matrix
samples from both row and column directions. This general framework directly
works on the 2D color images without vectorizing and well preserves the spatial
and color information, which makes it flexible to fit various real-world
applications. A generalized ridge regression model of BiG2DQPCA is firstly
proposed with orthogonality constrains on aimed features. Applying the
deflation technique and the framework of minorization-maximization, a new
quaternion optimization algorithm is proposed to compute the optimal features
of BiG2DQPCA and a closed-form solution is obtained at each iteration. A new
approach based on BiG2DQPCA is presented for color face recognition and image
reconstruction with a new data-driven weighting technique. Sufficient numerical
experiments are implemented on practical color face databases and indicate the
superiority of BiG2DQPCA over the state-of-the-art methods in terms of
recognition accuracies and rates of image reconstruction.
\\ ( https://arxiv.org/abs/2306.07045 ,  3383kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07050
Date: Mon, 12 Jun 2023 11:55:33 GMT   (12457kb,D)

Title: Revisiting Token Pruning for Object Detection and Instance Segmentation
Authors: Yifei Liu, Mathias Gehrig, Nico Messikommer, Marco Cannici, Davide
 Scaramuzza
Categories: cs.CV
\\
 Vision Transformers (ViTs) have shown impressive performance in computer
vision, but their high computational cost, quadratic in the number of tokens,
limits their adoption in computation-constrained applications. However, this
large number of tokens may not be necessary, as not all tokens are equally
important. In this paper, we investigate token pruning to accelerate inference
for object detection and instance segmentation, extending prior works from
image classification. Through extensive experiments, we offer four insights for
dense tasks: (i) tokens should not be completely pruned and discarded, but
rather preserved in the feature maps for later use. (ii) reactivating
previously pruned tokens can further enhance model performance. (iii) a dynamic
pruning rate based on images is better than a fixed pruning rate. (iv) a
lightweight, 2-layer MLP can effectively prune tokens, achieving accuracy
comparable with complex gating networks with a simpler design. We evaluate the
impact of these design choices on COCO dataset and present a method integrating
these insights that outperforms prior art token pruning models, significantly
reducing performance drop from ~1.5 mAP to ~0.3 mAP for both boxes and masks.
Compared to the dense counterpart that uses all tokens, our method achieves up
to 34% faster inference speed for the whole network and 46% for the backbone.
\\ ( https://arxiv.org/abs/2306.07050 ,  12457kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07083
Date: Mon, 12 Jun 2023 12:53:06 GMT   (13437kb,D)

Title: LUT-GCE: Lookup Table Global Curve Estimation for Fast Low-light Image
 Enhancement
Authors: Changguang Wu, Jiangxin Dong, Jinhui Tang
Categories: cs.CV
\\
 We present an effective and efficient approach for low-light image
enhancement, named Lookup Table Global Curve Estimation (LUT-GCE). In contrast
to existing curve-based methods with pixel-wise adjustment, we propose to
estimate a global curve for the entire image that allows corrections for both
under- and over-exposure. Specifically, we develop a novel cubic curve
formulation for light enhancement, which enables an image-adaptive and
pixel-independent curve for the range adjustment of an image. We then propose a
global curve estimation network (GCENet), a very light network with only 25.4k
parameters. To further speed up the inference speed, a lookup table method is
employed for fast retrieval. In addition, a novel histogram smoothness loss is
designed to enable zero-shot learning, which is able to improve the contrast of
the image and recover clearer details. Quantitative and qualitative results
demonstrate the effectiveness of the proposed approach. Furthermore, our
approach outperforms the state of the art in terms of inference speed,
especially on high-definition images (e.g., 1080p and 4k).
\\ ( https://arxiv.org/abs/2306.07083 ,  13437kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07087
Date: Mon, 12 Jun 2023 13:01:33 GMT   (6690kb,D)

Title: MaskedFusion360: Reconstruct LiDAR Data by Querying Camera Features
Authors: Royden Wagner, Marvin Klemp, Carlos Fernandez Lopez
Categories: cs.CV cs.RO
Comments: Technical report, 6 pages, 4 figures, accepted at ICLR 2023 Tiny
 Papers
\\
 In self-driving applications, LiDAR data provides accurate information about
distances in 3D but lacks the semantic richness of camera data. Therefore,
state-of-the-art methods for perception in urban scenes fuse data from both
sensor types. In this work, we introduce a novel self-supervised method to fuse
LiDAR and camera data for self-driving applications. We build upon masked
autoencoders (MAEs) and train deep learning models to reconstruct masked LiDAR
data from fused LiDAR and camera features. In contrast to related methods that
use birds-eye-view representations, we fuse features from dense spherical LiDAR
projections and features from fish-eye camera crops with a similar field of
view. Therefore, we reduce the learned spatial transformations to moderate
perspective transformations and do not require additional modules to generate
dense LiDAR representations. Code is available at:
https://github.com/KIT-MRT/masked-fusion-360
\\ ( https://arxiv.org/abs/2306.07087 ,  6690kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07096
Date: Mon, 12 Jun 2023 13:20:29 GMT   (10655kb,D)

Title: Global and Local Semantic Completion Learning for Vision-Language
 Pre-training
Authors: Rong-Cheng Tu, Yatai Ji, Jie Jiang, Weijie Kong, Chengfei Cai, Wenzhe
 Zhao, Hongfa Wang, Yujiu Yang, and Wei Liu
Categories: cs.CV
Comments: arXiv admin note: substantial text overlap with arXiv:2211.13437
\\
 Cross-modal alignment plays a crucial role in vision-language pre-training
(VLP) models, enabling them to capture meaningful associations across different
modalities. For this purpose, inspired by the success of masked language
modeling (MLM) tasks in the NLP pre-training area, numerous masked modeling
tasks have been proposed for VLP to further promote cross-modal interactions.
The core idea of previous masked modeling tasks is to focus on reconstructing
the masked tokens based on visible context for learning local-local alignment,
i.e., associations between image patches and text tokens. However, most of them
pay little attention to the global semantic features generated for the masked
data, resulting in a limited cross-modal alignment ability of global
representations to local features of the other modality. Therefore, in this
paper, we propose a novel Global and Local Semantic Completion Learning (GLSCL)
task to facilitate global-local alignment and local-local alignment
simultaneously. Specifically, the GLSCL task complements the missing semantics
of masked data and recovers global and local features by cross-modal
interactions. Our GLSCL consists of masked global semantic completion (MGSC)
and masked local token completion (MLTC). MGSC promotes learning more
representative global features which have a great impact on the performance of
downstream tasks, and MLTC can further enhance accurate comprehension on
multimodal data. Moreover, we present a flexible vision encoder, enabling our
model to simultaneously perform image-text and video-text multimodal tasks.
Experimental results show that our proposed method obtains state-of-the-art
performance on various vision-language benchmarks, such as visual question
answering, image-text retrieval, and video-text retrieval.
\\ ( https://arxiv.org/abs/2306.07096 ,  10655kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07154
Date: Mon, 12 Jun 2023 14:42:23 GMT   (7211kb,D)

Title: InstructP2P: Learning to Edit 3D Point Clouds with Text Instructions
Authors: Jiale Xu, Xintao Wang, Yan-Pei Cao, Weihao Cheng, Ying Shan, Shenghua
 Gao
Categories: cs.CV
\\
 Enhancing AI systems to perform tasks following human instructions can
significantly boost productivity. In this paper, we present InstructP2P, an
end-to-end framework for 3D shape editing on point clouds, guided by high-level
textual instructions. InstructP2P extends the capabilities of existing methods
by synergizing the strengths of a text-conditioned point cloud diffusion model,
Point-E, and powerful language models, enabling color and geometry editing
using language instructions. To train InstructP2P, we introduce a new shape
editing dataset, constructed by integrating a shape segmentation dataset,
off-the-shelf shape programs, and diverse edit instructions generated by a
large language model, ChatGPT. Our proposed method allows for editing both
color and geometry of specific regions in a single forward pass, while leaving
other regions unaffected. In our experiments, InstructP2P shows generalization
capabilities, adapting to novel shape categories and instructions, despite
being trained on a limited amount of data.
\\ ( https://arxiv.org/abs/2306.07154 ,  7211kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07178
Date: Mon, 12 Jun 2023 15:19:13 GMT   (4594kb,D)

Title: Frequency-Based Vulnerability Analysis of Deep Learning Models against
 Image Corruptions
Authors: Harshitha Machiraju, Michael H. Herzog, Pascal Frossard
Categories: cs.CV cs.AI cs.CR cs.LG
Comments: Code: https://github.com/code-Assasin/MUFIACode
\\
 Deep learning models often face challenges when handling real-world image
corruptions. In response, researchers have developed image corruption datasets
to evaluate the performance of deep neural networks in handling such
corruptions. However, these datasets have a significant limitation: they do not
account for all corruptions encountered in real-life scenarios. To address this
gap, we present MUFIA (Multiplicative Filter Attack), an algorithm designed to
identify the specific types of corruptions that can cause models to fail. Our
algorithm identifies the combination of image frequency components that render
a model susceptible to misclassification while preserving the semantic
similarity to the original image. We find that even state-of-the-art models
trained to be robust against known common corruptions struggle against the low
visibility-based corruptions crafted by MUFIA. This highlights the need for
more comprehensive approaches to enhance model robustness against a wider range
of real-world image corruptions.
\\ ( https://arxiv.org/abs/2306.07178 ,  4594kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07186
Date: Mon, 12 Jun 2023 15:37:18 GMT   (2384kb)

Title: CD-CTFM: A Lightweight CNN-Transformer Network for Remote Sensing Cloud
 Detection Fusing Multiscale Features
Authors: Wenxuan Ge, Xubing Yang, Li Zhang
Categories: cs.CV cs.LG eess.IV
\\
 Clouds in remote sensing images inevitably affect information extraction,
which hinder the following analysis of satellite images. Hence, cloud detection
is a necessary preprocessing procedure. However, the existing methods have
numerous calculations and parameters. In this letter, a lightweight
CNN-Transformer network, CD-CTFM, is proposed to solve the problem. CD-CTFM is
based on encoder-decoder architecture and incorporates the attention mechanism.
In the decoder part, we utilize a lightweight network combing CNN and
Transformer as backbone, which is conducive to extract local and global
features simultaneously. Moreover, a lightweight feature pyramid module is
designed to fuse multiscale features with contextual information. In the
decoder part, we integrate a lightweight channel-spatial attention module into
each skip connection between encoder and decoder, extracting low-level features
while suppressing irrelevant information without introducing many parameters.
Finally, the proposed model is evaluated on two cloud datasets, 38-Cloud and
MODIS. The results demonstrate that CD-CTFM achieves comparable accuracy as the
state-of-art methods. At the same time, CD-CTFM outperforms state-of-art
methods in terms of efficiency.
\\ ( https://arxiv.org/abs/2306.07186 ,  2384kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07196
Date: Mon, 12 Jun 2023 15:52:02 GMT   (9535kb,D)

Title: Retrieval-Enhanced Contrastive Vision-Text Models
Authors: Ahmet Iscen, Mathilde Caron, Alireza Fathi, Cordelia Schmid
Categories: cs.CV
\\
 Contrastive image-text models such as CLIP form the building blocks of many
state-of-the-art systems. While they excel at recognizing common generic
concepts, they still struggle on fine-grained entities which are rare, or even
absent from the pre-training dataset. Hence, a key ingredient to their success
has been the use of large-scale curated pre-training data aiming at expanding
the set of concepts that they can memorize during the pre-training stage. In
this work, we explore an alternative to encoding fine-grained knowledge
directly into the model's parameters: we instead train the model to retrieve
this knowledge from an external memory. Specifically, we propose to equip
existing vision-text models with the ability to refine their embedding with
cross-modal retrieved information from a memory at inference time, which
greatly improves their zero-shot predictions. Remarkably, we show that this can
be done with a light-weight, single-layer, fusion transformer on top of a
frozen CLIP. Our experiments validate that our retrieval-enhanced contrastive
(RECO) training improves CLIP performance substantially on several challenging
fine-grained tasks: for example +10.9 on Stanford Cars, +10.2 on CUB-2011 and
+7.3 on the recent OVEN benchmark.
\\ ( https://arxiv.org/abs/2306.07196 ,  9535kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07197
Date: Mon, 12 Jun 2023 15:54:52 GMT   (815kb,D)

Title: AROID: Improving Adversarial Robustness through Online Instance-wise
 Data Augmentation
Authors: Lin Li, Jianing Qiu, Michael Spratling
Categories: cs.CV cs.AI cs.LG
Comments: in submission
\\
 Deep neural networks are vulnerable to adversarial examples. Adversarial
training (AT) is an effective defense against adversarial examples. However, AT
is prone to overfitting which degrades robustness substantially. Recently, data
augmentation (DA) was shown to be effective in mitigating robust overfitting if
appropriately designed and optimized for AT. This work proposes a new method to
automatically learn online, instance-wise, DA policies to improve robust
generalization for AT. A novel policy learning objective, consisting of
Vulnerability, Affinity and Diversity, is proposed and shown to be sufficiently
effective and efficient to be practical for automatic DA generation during AT.
This allows our method to efficiently explore a large search space for a more
effective DA policy and evolve the policy as training progresses. Empirically,
our method is shown to outperform or match all competitive DA methods across
various model architectures (CNNs and ViTs) and datasets (CIFAR10, SVHN and
Imagenette). Our DA policy reinforced vanilla AT to surpass several
state-of-the-art AT methods (with baseline DA) in terms of both accuracy and
robustness. It can also be combined with those advanced AT methods to produce a
further boost in robustness.
\\ ( https://arxiv.org/abs/2306.07197 ,  815kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07200
Date: Mon, 12 Jun 2023 16:01:20 GMT   (33734kb,D)

Title: Fill-Up: Balancing Long-Tailed Data with Generative Models
Authors: Joonghyuk Shin, Minguk Kang, Jaesik Park
Categories: cs.CV cs.LG
Comments: 32 pages, 19 Figures, and 10 Tables. Project webpage at
 https://alex4727.github.io/Fill-Up/
\\
 Modern text-to-image synthesis models have achieved an exceptional level of
photorealism, generating high-quality images from arbitrary text descriptions.
In light of the impressive synthesis ability, several studies have exhibited
promising results in exploiting generated data for image recognition. However,
directly supplementing data-hungry situations in the real-world (e.g. few-shot
or long-tailed scenarios) with existing approaches result in marginal
performance gains, as they suffer to thoroughly reflect the distribution of the
real data. Through extensive experiments, this paper proposes a new image
synthesis pipeline for long-tailed situations using Textual Inversion. The
study demonstrates that generated images from textual-inverted text tokens
effectively aligns with the real domain, significantly enhancing the
recognition ability of a standard ResNet50 backbone. We also show that
real-world data imbalance scenarios can be successfully mitigated by filling up
the imbalanced data with synthetic images. In conjunction with techniques in
the area of long-tailed recognition, our method achieves state-of-the-art
results on standard long-tailed benchmarks when trained from scratch.
\\ ( https://arxiv.org/abs/2306.07200 ,  33734kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07207
Date: Mon, 12 Jun 2023 16:11:10 GMT   (6885kb,D)

Title: Valley: Video Assistant with Large Language model Enhanced abilitY
Authors: Ruipu Luo, Ziwang Zhao, Min Yang, Junwei Dong, Minghui Qiu, Pengcheng
 Lu, Tao Wang, Zhongyu Wei
Categories: cs.CV cs.AI cs.CL
\\
 Recently, several multi-modal models have been developed for joint image and
language understanding, which have demonstrated impressive chat abilities by
utilizing advanced large language models (LLMs). The process of developing such
models is straightforward yet effective. It involves pre-training an adaptation
module to align the semantics of the vision encoder and language model,
followed by fine-tuning on the instruction-following data. However, despite the
success of this pipeline in image and language understanding, its effectiveness
in joint video and language understanding has not been widely explored. In this
paper, we aim to develop a novel multi-modal foundation model capable of
perceiving video, image, and language within a general framework. To achieve
this goal, we introduce Valley: Video Assistant with Large Language model
Enhanced ability. Specifically, our proposed Valley model is designed with a
simple projection module that bridges video, image, and language modalities,
and is further unified with a multi-lingual LLM. We also collect multi-source
vision-text pairs and adopt a spatio-temporal pooling strategy to obtain a
unified vision encoding of video and image input for pre-training. Furthermore,
we generate multi-task instruction-following video data, including multi-shot
captions, long video descriptions, action recognition, causal relationship
inference, etc. To obtain the instruction-following data, we design diverse
rounds of task-oriented conversations between humans and videos, facilitated by
ChatGPT. Qualitative examples demonstrate that our proposed model has the
potential to function as a highly effective multilingual video assistant that
can make complex video understanding scenarios easy. Code, data, and models
will be available at https://github.com/RupertLuo/Valley.
\\ ( https://arxiv.org/abs/2306.07207 ,  6885kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07233
Date: Mon, 12 Jun 2023 16:49:08 GMT   (6200kb,D)

Title: Generative Plug and Play: Posterior Sampling for Inverse Problems
Authors: Charles A. Bouman and Gregery T. Buzzard
Categories: cs.CV
Comments: 8 pages, submitted to 2023 IEEE Allerton Conference
MSC-class: 94A08, 68U10, 60J22
\\
 Over the past decade, Plug-and-Play (PnP) has become a popular method for
reconstructing images using a modular framework consisting of a forward and
prior model. The great strength of PnP is that an image denoiser can be used as
a prior model while the forward model can be implemented using more traditional
physics-based approaches. However, a limitation of PnP is that it reconstructs
only a single deterministic image.
 In this paper, we introduce Generative Plug-and-Play (GPnP), a generalization
of PnP to sample from the posterior distribution. As with PnP, GPnP has a
modular framework using a physics-based forward model and an image denoising
prior model. However, in GPnP these models are extended to become proximal
generators, which sample from associated distributions. GPnP applies these
proximal generators in alternation to produce samples from the posterior. We
present experimental simulations using the well-known BM3D denoiser. Our
results demonstrate that the GPnP method is robust, easy to implement, and
produces intuitively reasonable samples from the posterior for sparse
interpolation and tomographic reconstruction. Code to accompany this paper is
available at https://github.com/gbuzzard/generative-pnp-allerton .
\\ ( https://arxiv.org/abs/2306.07233 ,  6200kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07244
Date: Mon, 12 Jun 2023 17:09:24 GMT   (42786kb,D)

Title: RB-Dust -- A Reference-based Dataset for Vision-based Dust Removal
Authors: Peter Buckel, Timo Oksanen, Thomas Dietmueller
Categories: cs.CV
Comments: Accepted by CVPR Workshop NTIRE 2023. Errata: Caption Figure 6
 changed
\\
 Dust in the agricultural landscape is a significant challenge and influences,
for example, the environmental perception of autonomous agricultural machines.
Image enhancement algorithms can be used to reduce dust. However, these require
dusty and dust-free images of the same environment for validation. In fact, to
date, there is no dataset that we are aware of that addresses this issue.
Therefore, we present the agriscapes RB-Dust dataset, which is named after its
purpose of reference-based dust removal. It is not possible to take pictures
from the cabin during tillage, as this would cause shifts in the images.
Because of this, we built a setup from which it is possible to take images from
a stationary position close to the passing tractor. The test setup was based on
a half-sided gate through which the tractor could drive. The field tests were
carried out on a farm in Bavaria, Germany, during tillage. During the field
tests, other parameters such as soil moisture and wind speed were controlled,
as these significantly affect dust development. We validated our dataset with
contrast enhancement and image dehazing algorithms and analyzed the
generalizability from recordings from the moving tractor. Finally, we
demonstrate the application of dust removal based on a high-level vision task,
such as person classification. Our empirical study confirms the validity of
RB-Dust for vision-based dust removal in agriculture.
\\ ( https://arxiv.org/abs/2306.07244 ,  42786kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07257
Date: Mon, 12 Jun 2023 17:31:23 GMT   (1967kb,D)

Title: MovieFactory: Automatic Movie Creation from Text using Large Generative
 Models for Language and Images
Authors: Junchen Zhu, Huan Yang, Huiguo He, Wenjing Wang, Zixi Tuo, Wen-Huang
 Cheng, Lianli Gao, Jingkuan Song, Jianlong Fu
Categories: cs.CV
\\
 In this paper, we present MovieFactory, a powerful framework to generate
cinematic-picture (3072$\times$1280), film-style (multi-scene), and
multi-modality (sounding) movies on the demand of natural languages. As the
first fully automated movie generation model to the best of our knowledge, our
approach empowers users to create captivating movies with smooth transitions
using simple text inputs, surpassing existing methods that produce soundless
videos limited to a single scene of modest quality. To facilitate this
distinctive functionality, we leverage ChatGPT to expand user-provided text
into detailed sequential scripts for movie generation. Then we bring scripts to
life visually and acoustically through vision generation and audio retrieval.
To generate videos, we extend the capabilities of a pretrained text-to-image
diffusion model through a two-stage process. Firstly, we employ spatial
finetuning to bridge the gap between the pretrained image model and the new
video dataset. Subsequently, we introduce temporal learning to capture object
motion. In terms of audio, we leverage sophisticated retrieval models to select
and align audio elements that correspond to the plot and visual content of the
movie. Extensive experiments demonstrate that our MovieFactory produces movies
with realistic visuals, diverse scenes, and seamlessly fitting audio, offering
users a novel and immersive experience. Generated samples can be found in
YouTube or Bilibili (1080P).
\\ ( https://arxiv.org/abs/2306.07257 ,  1967kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07265
Date: Mon, 12 Jun 2023 17:52:11 GMT   (165kb,D)

Title: detrex: Benchmarking Detection Transformers
Authors: Tianhe Ren, Shilong Liu, Feng Li, Hao Zhang, Ailing Zeng, Jie Yang,
 Xingyu Liao, Ding Jia, Hongyang Li, He Cao, Jianan Wang, Zhaoyang Zeng,
 Xianbiao Qi, Yuhui Yuan, Jianwei Yang, Lei Zhang
Categories: cs.CV
Comments: project link: https://github.com/IDEA-Research/detrex
\\
 The DEtection TRansformer (DETR) algorithm has received considerable
attention in the research community and is gradually emerging as a mainstream
approach for object detection and other perception tasks. However, the current
field lacks a unified and comprehensive benchmark specifically tailored for
DETR-based models. To address this issue, we develop a unified, highly modular,
and lightweight codebase called detrex, which supports a majority of the
mainstream DETR-based instance recognition algorithms, covering various
fundamental tasks, including object detection, segmentation, and pose
estimation. We conduct extensive experiments under detrex and perform a
comprehensive benchmark for DETR-based models. Moreover, we enhance the
performance of detection transformers through the refinement of training
hyper-parameters, providing strong baselines for supported algorithms.We hope
that detrex could offer research communities a standardized and unified
platform to evaluate and compare different DETR-based models while fostering a
deeper understanding and driving advancements in DETR-based instance
recognition. Our code is available at https://github.com/IDEA-Research/detrex.
The project is currently being actively developed. We encourage the community
to use detrex codebase for further development and contributions.
\\ ( https://arxiv.org/abs/2306.07265 ,  165kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07272
Date: Mon, 12 Jun 2023 17:56:01 GMT   (37453kb,D)

Title: Zero-shot Composed Text-Image Retrieval
Authors: Yikun Liu and Jiangchao Yao and Ya Zhang and Yanfeng Wang and Weidi
 Xie
Categories: cs.CV
\\
 In this paper, we consider the problem of composed image retrieval (CIR), it
aims to train a model that can fuse multi-modal information, e.g., text and
images, to accurately retrieve images that match the query, extending the
user's expression ability. We make the following contributions: (i) we initiate
a scalable pipeline to automatically construct datasets for training CIR model,
by simply exploiting a large-scale dataset of image-text pairs, e.g., a subset
of LAION-5B; (ii) we introduce a transformer-based adaptive aggregation model,
TransAgg, which employs a simple yet efficient fusion mechanism, to adaptively
combine information from diverse modalities; (iii) we conduct extensive
ablation studies to investigate the usefulness of our proposed data
construction procedure, and the effectiveness of core components in TransAgg;
(iv) when evaluating on the publicly available benckmarks under the zero-shot
scenario, i.e., training on the automatically constructed datasets, then
directly conduct inference on target downstream datasets, e.g., CIRR and
FashionIQ, our proposed approach either performs on par with or significantly
outperforms the existing state-of-the-art (SOTA) models. Project page:
https://code-kunkun.github.io/ZS-CIR/
\\ ( https://arxiv.org/abs/2306.07272 ,  37453kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07274
Date: Mon, 12 Jun 2023 17:57:12 GMT   (23130kb,D)

Title: Reconstructing Heterogeneous Cryo-EM Molecular Structures by Decomposing
 Them into Polymer Chains
Authors: Bongjin Koo, Julien Martel, Ariana Peck, Axel Levy, Fr\'ed\'eric
 Poitevin, Nina Miolane
Categories: cs.CV q-bio.BM
\\
 Cryogenic electron microscopy (cryo-EM) has transformed structural biology by
allowing to reconstruct 3D biomolecular structures up to near-atomic
resolution. However, the 3D reconstruction process remains challenging, as the
3D structures may exhibit substantial shape variations, while the 2D image
acquisition suffers from a low signal-to-noise ratio, requiring to acquire very
large datasets that are time-consuming to process. Current reconstruction
methods are precise but computationally expensive, or faster but lack a
physically-plausible model of large molecular shape variations. To fill this
gap, we propose CryoChains that encodes large deformations of biomolecules via
rigid body transformation of their polymer instances (chains), while
representing their finer shape variations with the normal mode analysis
framework of biophysics. Our synthetic data experiments on the human
$\text{GABA}_{\text{B}}$ and heat shock protein show that CryoChains gives a
biophysically-grounded quantification of the heterogeneous conformations of
biomolecules, while reconstructing their 3D molecular structures at an improved
resolution compared to the current fastest, interpretable deep learning method.
\\ ( https://arxiv.org/abs/2306.07274 ,  23130kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07276
Date: Mon, 12 Jun 2023 17:58:31 GMT   (5607kb,D)

Title: Transcendental Idealism of Planner: Evaluating Perception from Planning
 Perspective for Autonomous Driving
Authors: Wei-Xin Li, Xiaodong Yang
Categories: cs.CV cs.RO
Comments: ICML 2023
\\
 Evaluating the performance of perception modules in autonomous driving is one
of the most critical tasks in developing the complex intelligent system. While
module-level unit test metrics adopted from traditional computer vision tasks
are feasible to some extent, it remains far less explored to measure the impact
of perceptual noise on the driving quality of autonomous vehicles in a
consistent and holistic manner. In this work, we propose a principled framework
that provides a coherent and systematic understanding of the impact an error in
the perception module imposes on an autonomous agent's planning that actually
controls the vehicle. Specifically, the planning process is formulated as
expected utility maximisation, where all input signals from upstream modules
jointly provide a world state description, and the planner strives for the
optimal action by maximising the expected utility determined by both world
states and actions. We show that, under practical conditions, the objective
function can be represented as an inner product between the world state
description and the utility function in a Hilbert space. This geometric
interpretation enables a novel way to analyse the impact of noise in world
state estimation on planning and leads to a universal metric for evaluating
perception. The whole framework resembles the idea of transcendental idealism
in the classical philosophical literature, which gives the name to our
approach.
\\ ( https://arxiv.org/abs/2306.07276 ,  5607kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07279
Date: Mon, 12 Jun 2023 17:59:03 GMT   (6977kb,D)

Title: Scalable 3D Captioning with Pretrained Models
Authors: Tiange Luo, Chris Rockwell, Honglak Lee, Justin Johnson
Categories: cs.CV
Comments: Dataset link: https://huggingface.co/datasets/tiange/Cap3D
\\
 We introduce Cap3D, an automatic approach for generating descriptive text for
3D objects. This approach utilizes pretrained models from image captioning,
image-text alignment, and LLM to consolidate captions from multiple views of a
3D asset, completely side-stepping the time-consuming and costly process of
manual annotation. We apply Cap3D to the recently introduced large-scale 3D
dataset, Objaverse, resulting in 660k 3D-text pairs. Our evaluation, conducted
using 41k human annotations from the same dataset, demonstrates that Cap3D
surpasses human-authored descriptions in terms of quality, cost, and speed.
Through effective prompt engineering, Cap3D rivals human performance in
generating geometric descriptions on 17k collected annotations from the ABO
dataset. Finally, we finetune Text-to-3D models on Cap3D and human captions,
and show Cap3D outperforms; and benchmark the SOTA including Point-E, Shape-E,
and DreamFusion.
\\ ( https://arxiv.org/abs/2306.07279 ,  6977kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07280
Date: Mon, 12 Jun 2023 17:59:23 GMT   (46700kb,D)

Title: Controlling Text-to-Image Diffusion by Orthogonal Finetuning
Authors: Zeju Qiu, Weiyang Liu, Haiwen Feng, Yuxuan Xue, Yao Feng, Zhen Liu,
 Dan Zhang, Adrian Weller, Bernhard Sch\"olkopf
Categories: cs.CV cs.AI cs.GR cs.LG
Comments: Technical Report (40 pages, 32 figures, project page:
 https://oft.wyliu.com/)
\\
 Large text-to-image diffusion models have impressive capabilities in
generating photorealistic images from text prompts. How to effectively guide or
control these powerful models to perform different downstream tasks becomes an
important open problem. To tackle this challenge, we introduce a principled
finetuning method -- Orthogonal Finetuning (OFT), for adapting text-to-image
diffusion models to downstream tasks. Unlike existing methods, OFT can provably
preserve hyperspherical energy which characterizes the pairwise neuron
relationship on the unit hypersphere. We find that this property is crucial for
preserving the semantic generation ability of text-to-image diffusion models.
To improve finetuning stability, we further propose Constrained Orthogonal
Finetuning (COFT) which imposes an additional radius constraint to the
hypersphere. Specifically, we consider two important finetuning text-to-image
tasks: subject-driven generation where the goal is to generate subject-specific
images given a few images of a subject and a text prompt, and controllable
generation where the goal is to enable the model to take in additional control
signals. We empirically show that our OFT framework outperforms existing
methods in generation quality and convergence speed.
\\ ( https://arxiv.org/abs/2306.07280 ,  46700kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07282
Date: Mon, 12 Jun 2023 17:59:48 GMT   (8349kb,D)

Title: Waffling around for Performance: Visual Classification with Random Words
 and Broad Concepts
Authors: Karsten Roth, Jae Myung Kim, A. Sophia Koepke, Oriol Vinyals, Cordelia
 Schmid, Zeynep Akata
Categories: cs.CV cs.LG
\\
 The visual classification performance of vision-language models such as CLIP
can benefit from additional semantic knowledge, e.g. via large language models
(LLMs) such as GPT-3. Further extending classnames with LLM-generated class
descriptors, e.g. ``waffle, \textit{which has a round shape}'', or averaging
retrieval scores over multiple such descriptors, has been shown to improve
generalization performance. In this work, we study this behavior in detail and
propose \texttt{Waffle}CLIP, a framework for zero-shot visual classification
which achieves similar performance gains on a large number of visual
classification tasks by simply replacing LLM-generated descriptors with random
character and word descriptors \textbf{without} querying external models. We
extend these results with an extensive experimental study on the impact and
shortcomings of additional semantics introduced via LLM-generated descriptors,
and showcase how semantic context is better leveraged by automatically querying
LLMs for high-level concepts, while jointly resolving potential class name
ambiguities. Link to the codebase: https://github.com/ExplainableML/WaffleCLIP.
\\ ( https://arxiv.org/abs/2306.07282 ,  8349kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06502
Date: Sat, 10 Jun 2023 18:39:49 GMT   (5669kb,D)

Title: Quantifying the Benefits of Carbon-Aware Temporal and Spatial Workload
 Shifting in the Cloud
Authors: Thanathorn Sukprasert, Abel Souza, Noman Bashir, David Irwin, Prashant
 Shenoy
Categories: cs.DC cs.CY cs.SY eess.SY
\\
 To mitigate climate change, there has been a recent focus on reducing
computing's carbon emissions by shifting its time and location to when and
where lower-carbon energy is available. However, despite the prominence of
carbon-aware spatiotemporal workload shifting, prior work has only quantified
its benefits in narrow settings, i.e., for specific workloads in select
regions. As a result, the potential benefits of spatiotemporal workload
scheduling, which are a function of both workload and energy characteristics,
are unclear. To address the problem, this paper quantifies the upper bound on
the benefits of carbon-aware spatiotemporal workload shifting for a wide range
of workloads with different characteristics, e.g., job duration, deadlines,
SLOs, memory footprint, etc., based on hourly variations in energy's
carbon-intensity across 123 distinct regions, including cloud regions, over a
year. Notably, while we find that some workloads can benefit from carbon-aware
spatiotemporal workload shifting in some regions, the approach yields limited
benefits for many workloads and cloud regions. In addition, we also show that
simple scheduling policies often yield most of the benefits. Thus, contrary to
conventional wisdom, i) carbon-aware spatiotemporal workload shifting is likely
not a panacea for significantly reducing cloud platforms' carbon emissions, and
ii) pursuing further research on sophisticated policies is likely to yield
little marginal benefits.
\\ ( https://arxiv.org/abs/2306.06502 ,  5669kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06946
Date: Mon, 12 Jun 2023 08:28:01 GMT   (2365kb,D)

Title: An efficient implicit constraint resolution scheme for interactive FE
 simulations
Authors: Ziqiu Zeng (MIMESIS, ICube, UNISTRA), Hadrien Courtecuisse (MIMESIS,
 ICube, UNISTRA)
Categories: cs.DC
\\
 This paper presents a novel implicit scheme for the constraint resolution in
real-time finite element simulations in the presence of contact and friction.
Instead of using the standard motion correction scheme, we propose an iterative
method where the constraint forces are corrected in Newton iterations. In this
scheme, we are able to update the constraint directions recursively, providing
more accurate contact and friction response. However, updating the constraint
matrices leads to massive computation costs. To address the issue, we propose
separating the constraint direction and geometrical mapping in the contact
Jacobian matrix and reformulating the schur-complement of the system matrix.
When combined with GPU-based parallelization, the reformulation provides a very
efficient updating process for the constraint matrices in the recursive
corrective motion scheme. Our method enables the possibility to handle the
inconsistency of constraint directions at the beginning and the end of time
steps. At the same time, the resolution process is kept as efficient as
possible. We evaluate the performance of our fast-updating scheme in a contact
simulation and compare it with the standard updating scheme.
\\ ( https://arxiv.org/abs/2306.06946 ,  2365kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06250
Date: Fri, 9 Jun 2023 20:46:31 GMT   (2776kb,D)

Title: Strategic Apple Tasting
Authors: Keegan Harris, Chara Podimata, Zhiwei Steven Wu
Categories: cs.GT cs.LG
\\
 Algorithmic decision-making in high-stakes domains often involves assigning
decisions to agents with incentives to strategically modify their input to the
algorithm. In addition to dealing with incentives, in many domains of interest
(e.g. lending and hiring) the decision-maker only observes feedback regarding
their policy for rounds in which they assign a positive decision to the agent;
this type of feedback is often referred to as apple tasting (or one-sided)
feedback. We formalize this setting as an online learning problem with
apple-tasting feedback where a principal makes decisions about a sequence of
$T$ agents, each of which is represented by a context that may be strategically
modified. Our goal is to achieve sublinear strategic regret, which compares the
performance of the principal to that of the best fixed policy in hindsight, if
the agents were truthful when revealing their contexts. Our main result is a
learning algorithm which incurs $\tilde{\mathcal{O}}(\sqrt{T})$ strategic
regret when the sequence of agents is chosen stochastically. We also give an
algorithm capable of handling adversarially-chosen agents, albeit at the cost
of $\tilde{\mathcal{O}}(T^{(d+1)/(d+2)})$ strategic regret (where $d$ is the
dimension of the context). Our algorithms can be easily adapted to the setting
where the principal receives bandit feedback -- this setting generalizes both
the linear contextual bandit problem (by considering agents with incentives)
and the strategic classification problem (by allowing for partial feedback).
\\ ( https://arxiv.org/abs/2306.06250 ,  2776kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06351
Date: Sat, 10 Jun 2023 05:50:26 GMT   (416kb,D)

Title: Mechanism Design for Collaborative Normal Mean Estimation
Authors: Yiding Chen, Xiaojin Zhu, Kirthevasan Kandasamy
Categories: cs.GT
\\
 We study collaborative normal mean estimation, where $m$ strategic agents
collect i.i.d samples from a normal distribution $\mathcal{N}(\mu, \sigma^2)$
at a cost. They all wish to estimate the mean $\mu$. By sharing data with each
other, agents can obtain better estimates while keeping the cost of data
collection small. To facilitate this collaboration, we wish to design
mechanisms that encourage agents to collect a sufficient amount of data and
share it truthfully, so that they are all better off than working alone. In
naive mechanisms, such as simply pooling and sharing all the data, an
individual agent might find it beneficial to under-collect and/or fabricate
data, which can lead to poor social outcomes. We design a novel mechanism that
overcomes these challenges via two key techniques: first, when sharing the
others' data with an agent, the mechanism corrupts this dataset proportional to
how much the data reported by the agent differs from the others; second, we
design minimax optimal estimators for the corrupted dataset. Our mechanism,
which is incentive compatible and individually rational, achieves a social
penalty (sum of all agents' estimation errors and data collection costs) that
is at most a factor 2 of the global minimum. When applied to high dimensional
(non-Gaussian) distributions with bounded variance, this mechanism retains
these three properties, but with slightly weaker results. Finally, in two
special cases where we restrict the strategy space of the agents, we design
mechanisms that essentially achieve the global minimum.
\\ ( https://arxiv.org/abs/2306.06351 ,  416kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06485
Date: Sat, 10 Jun 2023 16:45:56 GMT   (3111kb,D)

Title: The Defense of Networked Targets in General Lotto games
Authors: Adel Aghajan, Keith Paarporn, Jason R. Marden
Categories: cs.GT
\\
 Ensuring the security of networked systems is a significant problem,
considering the susceptibility of modern infrastructures and technologies to
adversarial interference. A central component of this problem is how defensive
resources should be allocated to mitigate the severity of potential attacks on
the system. In this paper, we consider this in the context of a General Lotto
game, where a defender and attacker deploys resources on the nodes of a
network, and the objective is to secure as many links as possible. The defender
secures a link only if it out-competes the attacker on both of its associated
nodes. For bipartite networks, we completely characterize equilibrium payoffs
and strategies for both the defender and attacker. Surprisingly, the resulting
payoffs are the same for any bipartite graph. On arbitrary network structures,
we provide lower and upper bounds on the defender's max-min value. Notably, the
equilibrium payoff from bipartite networks serves as the lower bound. These
results suggest that more connected networks are easier to defend against
attacks. We confirm these findings with simulations that compute deterministic
allocation strategies on large random networks. This also highlights the
importance of randomization in the equilibrium strategies.
\\ ( https://arxiv.org/abs/2306.06485 ,  3111kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06554
Date: Sun, 11 Jun 2023 01:18:24 GMT   (1202kb,D)

Title: Bayesian Calibrated Click-Through Auction
Authors: Junjie Chen, Minming Li, Haifeng Xu and Song Zuo
Categories: cs.GT
\\
 We study information design in click-through auctions, in which the
bidders/advertisers bid for winning an opportunity to show their ads but only
pay for realized clicks. The payment may or may not happen, and its probability
is called the click-through rate(CTR). This auction format is widely used in
the industry of online advertising. Bidders have private values, whereas the
seller has private information about each bidder's CTRs. We are interested in
the seller's problem of partially revealing CTR information to maximize
revenue. Information design in click-through auctions turns out to be
intriguingly different from almost all previous studies in this space since any
revealed information about CTRs will never affect bidders' bidding behaviors --
they will always bid their true value for a click -- but only affect the
auction's allocation and payment rule. This makes information design
effectively a (constrained) mechanism design problem.
 We primarily focus on the two-bidder situation, which is already notoriously
challenging as demonstrated in recent works, and adopt the algorithmic lens of
developing approximate algorithms. Our first result is an FPTAS to compute an
approximately optimal mechanism. The design of this algorithm leverages
Bayesian bidder values which help to ``smooth'' the seller's revenue function
and lead to better tractability. Our second result seeks to design ``simple''
and more practical signaling schemes. When bidders' CTR distribution is
symmetric, we develop a simple prior-free signaling scheme, whose construction
relies on a single parameter called optimal signal ratio. The constructed
scheme provably obtains a good approximation as long as the maximum and minimum
of bidders' value density functions do not differ much.
\\ ( https://arxiv.org/abs/2306.06554 ,  1202kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06791
Date: Sun, 11 Jun 2023 22:07:18 GMT   (2602kb,D)

Title: To Save Crowdsourcing from Cheap-Talk: Strategic Learning from Biased
 Users
Authors: Shugang Hao and Lingjie Duan
Categories: cs.GT
\\
 Today many users are invited by a crowdsourcing platform (e.g., TripAdvisor,
and Waze) to provide their anonymous reviews about service experiences (e.g.,
in hotels, restaurants, and trips), yet many reviews are found biased to be
extremely positive or negative. It is difficult to learn from biased users'
reviews to infer actual service state, as the service state can also be extreme
and the platform cannot verify immediately. Further, due to the anonymity,
reviewers can hide their bias types (positive or negative) from the platform
and adaptively adjust their reviews against the platform's inference. To our
best knowledge, we are the first to study how to save crowdsourcing from
cheap-talk and strategically learn the actual service state from biased users'
reviews. We formulate the problem as a dynamic Bayesian game, including the
unknown users' messaging and the platform's follow-up inference. Through
involved analysis, we provide closed-form expressions for the Perfect Bayesian
Equilibrium (PBE). Our PBE shows that the platform's strategic learning can
successfully prevent biased users from cheap-talk in most cases, where a user
even with extreme bias still honestly messages to convince the platform of
listening to his review. We prove that the price of anarchy (PoA) is 2, telling
that the social cost can at most be doubled in the worst-case. As the user
number becomes large, our platform always learns the actual service state.
Perhaps surprisingly, the platform's expected cost may be worse off after
adding one more user.
\\ ( https://arxiv.org/abs/2306.06791 ,  2602kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07211
Date: Mon, 12 Jun 2023 16:15:20 GMT   (159kb,D)

Title: Differential Game Analysis for Cooperation Models in Automotive Supply
 Chain under Low-Carbon Emission Reduction Policies
Authors: Yukun Cheng, Zhanghao Yao, Xinxin Wang
Categories: cs.GT
\\
 In the context of reducing carbon emissions in the automotive supply chain,
collaboration between vehicle manufacturers and retailers has proven to be an
effective measure for enhancing carbon emission reduction within the
enterprise. This study aims to evaluate the effectiveness of such collaboration
by constructing a differential game model that incorporates carbon trading and
consumer preferences for low-carbon products. The model examines the
decision-making process of an automotive supply chain comprising a vehicle
manufacturer and multiple retailers. By utilizing the Hamilton-Jacobi-Bellman
equation, we analyze the equilibrium strategies of the participants under both
a decentralized model and a Stackelberg leader-follower game model. In the
decentralized model, the vehicle manufacturer optimizes its carbon emission
reduction efforts, while each retailer independently determines its low-carbon
promotion efforts and vehicle retail price. In the Stackelberg leader-follower
game model, the vehicle manufacturer cooperates with the retailers by offering
them a subsidy. Consequently, the manufacturer plays as the leader, making
decisions on carbon emission reduction efforts and the subsidy rate, while the
retailers, as followers, compute their promotion efforts and retail prices
accordingly. Through theoretical analysis and numerical experiments considering
the manufacturer's and retailers' efforts, the low-carbon reputation of
vehicles, and the overall system profits under both models, we conclude that
compared to the decentralized model, where each party pursues individual
profits, the collaboration in the Stackelberg game yields greater benefits for
both parties. Furthermore, this collaborative approach promotes the long-term
development of the automotive supply chain.
\\ ( https://arxiv.org/abs/2306.07211 ,  159kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06110
Date: Fri, 26 May 2023 09:33:12 GMT   (3348kb,D)

Title: Surrogate Modeling of Car Drag Coefficient with Depth and Normal
 Renderings
Authors: Binyang Song, Chenyang Yuan, Frank Permenter, Nikos Arechiga, Faez
 Ahmed
Categories: cs.LG cs.CE cs.CV
\\
 Generative AI models have made significant progress in automating the
creation of 3D shapes, which has the potential to transform car design. In
engineering design and optimization, evaluating engineering metrics is crucial.
To make generative models performance-aware and enable them to create
high-performing designs, surrogate modeling of these metrics is necessary.
However, the currently used representations of three-dimensional (3D) shapes
either require extensive computational resources to learn or suffer from
significant information loss, which impairs their effectiveness in surrogate
modeling. To address this issue, we propose a new two-dimensional (2D)
representation of 3D shapes. We develop a surrogate drag model based on this
representation to verify its effectiveness in predicting 3D car drag. We
construct a diverse dataset of 9,070 high-quality 3D car meshes labeled by drag
coefficients computed from computational fluid dynamics (CFD) simulations to
train our model. Our experiments demonstrate that our model can accurately and
efficiently evaluate drag coefficients with an $R^2$ value above 0.84 for
various car categories. Moreover, the proposed representation method can be
generalized to many other product categories beyond cars. Our model is
implemented using deep neural networks, making it compatible with recent AI
image generation tools (such as Stable Diffusion) and a significant step
towards the automatic generation of drag-optimized car designs. We have made
the dataset and code publicly available at
https://decode.mit.edu/projects/dragprediction/.
\\ ( https://arxiv.org/abs/2306.06110 ,  3348kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06118
Date: Mon, 5 Jun 2023 08:20:46 GMT   (2411kb)

Title: Estimation of River Water Surface Elevation Using UAV Photogrammetry and
 Machine Learning
Authors: Rados{\l}aw Szostak, Marcin Pietro\'n, Przemys{\l}aw Wachniew,
 Miros{\l}aw Zimnoch, Pawe{\l} \'Cwi\k{a}ka{\l}a
Categories: cs.LG cs.CV eess.IV
Comments: Manuscript submitted to Measurement journal (ISSN 0263-2241)
\\
 Unmanned aerial vehicle (UAV) photogrammetry allows for the creation of
orthophotos and digital surface models (DSMs) of a terrain. However, DSMs of
water bodies mapped with this technique reveal water surface distortions,
preventing the use of photogrammetric data for accurate determination of water
surface elevation (WSE). Firstly, we propose a new solution in which a
convolutional neural network (CNN) is used as a WSE estimator from
photogrammetric DSMs and orthophotos. Second, we improved the previously known
"water-edge" method by filtering the outliers using a forward-backwards
exponential weighted moving average. Further improvement in these two methods
was achieved by performing a linear regression of the WSE values against
chainage. The solutions estimate the uncertainty of the predictions. This is
the first approach in which DL was used for this task. A brand new machine
learning data set has been created. It was collected on a small lowland river
in winter and summer conditions. It consists of 322 samples, each corresponding
to a 10 by 10 meter area of the river channel and adjacent land. Each data set
sample contains orthophoto and DSM arrays as input, along with a single
ground-truth WSE value as output. The data set was supplemented with data
collected by other researchers that compared the state-of-the-art methods for
determining WSE using an UAV. The results of the DL solution were verified
using k-fold cross-validation method. This provided an in-depth examination of
the model's ability to perform on previously unseen data. The WSE RMSEs differ
for each k-fold cross-validation subset and range from 1.7 cm up to 17.2 cm.
The RMSE results of the improved "water-edge" method are at least six times
lower than the RMSE results achieved by the conventional "water-edge" method.
The results obtained by new methods are predominantly outperforming existing
ones.
\\ ( https://arxiv.org/abs/2306.06118 ,  2411kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06134
Date: Thu, 8 Jun 2023 19:58:30 GMT   (142kb,D)

Title: Sound Explanation for Trustworthy Machine Learning
Authors: Kai Jia, Pasapol Saowakon, Limor Appelbaum, Martin Rinard
Categories: cs.LG cs.AI
\\
 We take a formal approach to the explainability problem of machine learning
systems. We argue against the practice of interpreting black-box models via
attributing scores to input components due to inherently conflicting goals of
attribution-based interpretation. We prove that no attribution algorithm
satisfies specificity, additivity, completeness, and baseline invariance. We
then formalize the concept, sound explanation, that has been informally adopted
in prior work. A sound explanation entails providing sufficient information to
causally explain the predictions made by a system. Finally, we present the
application of feature selection as a sound explanation for cancer prediction
models to cultivate trust among clinicians.
\\ ( https://arxiv.org/abs/2306.06134 ,  142kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06135
Date: Fri, 9 Jun 2023 01:37:32 GMT   (80kb,D)

Title: Safety and Fairness for Content Moderation in Generative Models
Authors: Susan Hao, Piyush Kumar, Sarah Laszlo, Shivani Poddar, Bhaktipriya
 Radharapu, Renee Shelby
Categories: cs.LG cs.AI
Comments: CVPR Workshop Paper
\\
 With significant advances in generative AI, new technologies are rapidly
being deployed with generative components. Generative models are typically
trained on large datasets, resulting in model behaviors that can mimic the
worst of the content in the training data. Responsible deployment of generative
technologies requires content moderation strategies, such as safety input and
output filters. Here, we provide a theoretical framework for conceptualizing
responsible content moderation of text-to-image generative technologies,
including a demonstration of how to empirically measure the constructs we
enumerate. We define and distinguish the concepts of safety, fairness, and
metric equity, and enumerate example harms that can come in each domain. We
then provide a demonstration of how the defined harms can be quantified. We
conclude with a summary of how the style of harms quantification we demonstrate
enables data-driven content moderation decisions.
\\ ( https://arxiv.org/abs/2306.06135 ,  80kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06136
Date: Fri, 9 Jun 2023 02:26:28 GMT   (576kb,D)

Title: Robustness Testing for Multi-Agent Reinforcement Learning: State
 Perturbations on Critical Agents
Authors: Ziyuan Zhou and Guanjun Liu
Categories: cs.LG cs.AI cs.CR cs.MA
\\
 Multi-Agent Reinforcement Learning (MARL) has been widely applied in many
fields such as smart traffic and unmanned aerial vehicles. However, most MARL
algorithms are vulnerable to adversarial perturbations on agent states.
Robustness testing for a trained model is an essential step for confirming the
trustworthiness of the model against unexpected perturbations. This work
proposes a novel Robustness Testing framework for MARL that attacks states of
Critical Agents (RTCA). The RTCA has two innovations: 1) a Differential
Evolution (DE) based method to select critical agents as victims and to advise
the worst-case joint actions on them; and 2) a team cooperation policy
evaluation method employed as the objective function for the optimization of
DE. Then, adversarial state perturbations of the critical agents are generated
based on the worst-case joint actions. This is the first robustness testing
framework with varying victim agents. RTCA demonstrates outstanding performance
in terms of the number of victim agents and destroying cooperation policies.
\\ ( https://arxiv.org/abs/2306.06136 ,  576kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06139
Date: Fri, 9 Jun 2023 07:00:00 GMT   (485kb)

Title: WePaMaDM-Outlier Detection: Weighted Outlier Detection using Pattern
 Approaches for Mass Data Mining
Authors: Ravindrakumar Purohit, Jai Prakash Verma, Rachna Jain, Madhuri Bhavsar
Categories: cs.LG cs.AI cs.CV
\\
 Weighted Outlier Detection is a method for identifying unusual or anomalous
data points in a dataset, which can be caused by various factors like human
error, fraud, or equipment malfunctions. Detecting outliers can reveal vital
information about system faults, fraudulent activities, and patterns in the
data, assisting experts in addressing the root causes of these anomalies.
However,creating a model of normal data patterns to identify outliers can be
challenging due to the nature of input data, labeled data availability, and
specific requirements of the problem. This article proposed the
WePaMaDM-Outlier Detection with distinct mass data mining domain, demonstrating
that such techniques are domain-dependent and usually developed for specific
problem formulations. Nevertheless, similar domains can adapt solutions with
modifications. This work also investigates the significance of data modeling in
outlier detection techniques in surveillance, fault detection, and trend
analysis, also referred to as novelty detection, a semisupervised task where
the algorithm learns to recognize abnormality while being taught the normal
class.
\\ ( https://arxiv.org/abs/2306.06139 ,  485kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06146
Date: Fri, 9 Jun 2023 10:52:49 GMT   (183kb,D)

Title: Hidden Classification Layers: a study on Data Hidden Representations
 with a Higher Degree of Linear Separability between the Classes
Authors: Andrea Apicella, Francesco Isgr\`o, Roberto Prevete
Categories: cs.LG cs.AI
Comments: Paper submitted for peer-review
\\
 In the context of classification problems, Deep Learning (DL) approaches
represent state of art. Many DL approaches are based on variations of standard
multi-layer feed-forward neural networks. These are also referred to as deep
networks. The basic idea is that each hidden neural layer accomplishes a data
transformation which is expected to make the data representation "somewhat more
linearly separable" than the previous one to obtain a final data representation
which is as linearly separable as possible. However, determining the
appropriate neural network parameters that can perform these transformations is
a critical problem. In this paper, we investigate the impact on deep network
classifier performances of a training approach favouring solutions where data
representations at the hidden layers have a higher degree of linear
separability between the classes with respect to standard methods. To this aim,
we propose a neural network architecture which induces an error function
involving the outputs of all the network layers. Although similar approaches
have already been partially discussed in the past literature, here we propose a
new architecture with a novel error function and an extensive experimental
analysis. This experimental analysis was made in the context of image
classification tasks considering four widely used datasets. The results show
that our approach improves the accuracy on the test set in all the considered
cases.
\\ ( https://arxiv.org/abs/2306.06146 ,  183kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06148
Date: Fri, 9 Jun 2023 12:08:34 GMT   (581kb)

Title: Artificial intelligence and radiation protection. A game changer or an
 update?
Authors: Sylvain Andresz (CEPN), A Z\'ephir, Jeremy Bez (IRSN/PSN-RES/SNC/LN),
 Maxime Karst, J. Danieli (SPRA)
Categories: cs.LG cs.AI
Journal-ref: Radioprotection, 2022, 57 (2), pp.157-164
DOI: 10.1051/radiopro/2022004
\\
 Artificial intelligence (AI) is regarded as one of the most disruptive
technology of the century and with countless applications. What does it mean
for radiation protection? This article describes the fundamentals of machine
learning (ML) based methods and presents the inaugural applications in
different fields of radiation protection. It is foreseen that the usage of AI
will increase in radiation protection. Consequently, this article explores some
of the benefits and also the potential barriers and questions, including
ethical ones, that can come out. The article proposes that collaboration
between radiation protection professionals and data scientist experts can
accelerate and guide the development of the algorithms for effective scientific
and technological outcomes.
\\ ( https://arxiv.org/abs/2306.06148 ,  581kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06152
Date: Fri, 9 Jun 2023 13:51:33 GMT   (18733kb,D)

Title: EfficientBioAI: Making Bioimaging AI Models Efficient in Energy, Latency
 and Representation
Authors: Yu Zhou, Justin Sonneck, Sweta Banerjee, Stefanie D\"orr, Anika
 Gr\"uneboom, Kristina Lorenz, Jianxu Chen
Categories: cs.LG cs.AI
Comments: 17 pages, 6 figures
\\
 Artificial intelligence (AI) has been widely used in bioimage image analysis
nowadays, but the efficiency of AI models, like the energy consumption and
latency is not ignorable due to the growing model size and complexity, as well
as the fast-growing analysis needs in modern biomedical studies. Like we can
compress large images for efficient storage and sharing, we can also compress
the AI models for efficient applications and deployment. In this work, we
present EfficientBioAI, a plug-and-play toolbox that can compress given
bioimaging AI models for them to run with significantly reduced energy cost and
inference time on both CPU and GPU, without compromise on accuracy. In some
cases, the prediction accuracy could even increase after compression, since the
compression procedure could remove redundant information in the model
representation and therefore reduce over-fitting. From four different bioimage
analysis applications, we observed around 2-5 times speed-up during inference
and 30-80$\%$ saving in energy. Cutting the runtime of large scale bioimage
analysis from days to hours or getting a two-minutes bioimaging AI model
inference done in near real-time will open new doors for method development and
biomedical discoveries. We hope our toolbox will facilitate
resource-constrained bioimaging AI and accelerate large-scale AI-based
quantitative biological studies in an eco-friendly way, as well as stimulate
further research on the efficiency of bioimaging AI.
\\ ( https://arxiv.org/abs/2306.06152 ,  18733kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06154
Date: Fri, 9 Jun 2023 14:49:20 GMT   (1991kb,D)

Title: HypLL: The Hyperbolic Learning Library
Authors: Max van Spengler, Philipp Wirth, Pascal Mettes
Categories: cs.LG cs.AI
\\
 Deep learning in hyperbolic space is quickly gaining traction in the fields
of machine learning, multimedia, and computer vision. Deep networks commonly
operate in Euclidean space, implicitly assuming that data lies on regular
grids. Recent advances have shown that hyperbolic geometry provides a viable
alternative foundation for deep learning, especially when data is hierarchical
in nature and when working with few embedding dimensions. Currently however, no
accessible open-source library exists to build hyperbolic network modules akin
to well-known deep learning libraries. We present HypLL, the Hyperbolic
Learning Library to bring the progress on hyperbolic deep learning together.
HypLL is built on top of PyTorch, with an emphasis in its design for
easy-of-use, in order to attract a broad audience towards this new and
open-ended research direction. The code is available at:
https://github.com/maxvanspengler/hyperbolic_learning_library. The compressed
archive is available at: https://doi.org/10.21942/uva.23385506.v4
\\ ( https://arxiv.org/abs/2306.06154 ,  1991kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06155
Date: Fri, 9 Jun 2023 15:38:25 GMT   (526kb,D)

Title: Intensity Profile Projection: A Framework for Continuous-Time
 Representation Learning for Dynamic Networks
Authors: Alexander Modell, Ian Gallagher, Emma Ceccherini, Nick Whiteley and
 Patrick Rubin-Delanchy
Categories: cs.LG stat.ME stat.ML
Comments: 36 pages, 8 figures
MSC-class: 62H12 (primary), 62H30 (secondary)
\\
 We present a new algorithmic framework, Intensity Profile Projection, for
learning continuous-time representations of the nodes of a dynamic network,
characterised by a node set and a collection of instantaneous interaction
events which occur in continuous time. Our framework consists of three stages:
estimating the intensity functions underlying the interactions between pairs of
nodes, e.g. via kernel smoothing; learning a projection which minimises a
notion of intensity reconstruction error; and inductively constructing evolving
node representations via the learned projection. We show that our
representations preserve the underlying structure of the network, and are
temporally coherent, meaning that node representations can be meaningfully
compared at different points in time. We develop estimation theory which
elucidates the role of smoothing as a bias-variance trade-off, and shows how we
can reduce smoothing as the signal-to-noise ratio increases on account of the
algorithm `borrowing strength' across the network.
\\ ( https://arxiv.org/abs/2306.06155 ,  526kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06174
Date: Fri, 9 Jun 2023 18:01:14 GMT   (14217kb,D)

Title: Active-Learning-Driven Surrogate Modeling for Efficient Simulation of
 Parametric Nonlinear Systems
Authors: Harshit Kapadia, Lihong Feng, Peter Benner
Categories: cs.LG cs.CE cs.NA math.DS math.NA physics.flu-dyn
Comments: 31 pages, 24 figures, 1 table; Under review
\\
 When repeated evaluations for varying parameter configurations of a
high-fidelity physical model are required, surrogate modeling techniques based
on model order reduction are desired. In absence of the governing equations
describing the dynamics, we need to construct the parametric reduced-order
surrogate model in a non-intrusive fashion. In this setting, the usual
residual-based error estimate for optimal parameter sampling associated with
the reduced basis method is not directly available. Our work provides a
non-intrusive optimality criterion to efficiently populate the parameter
snapshots, thereby, enabling us to effectively construct a parametric surrogate
model. We consider separate parameter-specific proper orthogonal decomposition
(POD) subspaces and propose an active-learning-driven surrogate model using
kernel-based shallow neural networks, abbreviated as ActLearn-POD-KSNN
surrogate model. To demonstrate the validity of our proposed ideas, we present
numerical experiments using two physical models, namely Burgers' equation and
shallow water equations. Both the models have mixed -- convective and diffusive
-- effects within their respective parameter domains, with each of them
dominating in certain regions. The proposed ActLearn-POD-KSNN surrogate model
efficiently predicts the solution at new parameter locations, even for a
setting with multiple interacting shock profiles.
\\ ( https://arxiv.org/abs/2306.06174 ,  14217kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06179
Date: Fri, 9 Jun 2023 18:07:06 GMT   (3182kb,D)

Title: Hidden symmetries of ReLU networks
Authors: J. Elisenda Grigsby and Kathryn Lindsey and David Rolnick
Categories: cs.LG math.CO math.GT
Comments: 27 pages, 11 figures, ICML 2023
MSC-class: 57R70, 57Q99, 52B70, 52C35
ACM-class: I.2.6
\\
 The parameter space for any fixed architecture of feedforward ReLU neural
networks serves as a proxy during training for the associated class of
functions - but how faithful is this representation? It is known that many
different parameter settings can determine the same function. Moreover, the
degree of this redundancy is inhomogeneous: for some networks, the only
symmetries are permutation of neurons in a layer and positive scaling of
parameters at a neuron, while other networks admit additional hidden
symmetries. In this work, we prove that, for any network architecture where no
layer is narrower than the input, there exist parameter settings with no hidden
symmetries. We also describe a number of mechanisms through which hidden
symmetries can arise, and empirically approximate the functional dimension of
different network architectures at initialization. These experiments indicate
that the probability that a network has no hidden symmetries decreases towards
0 as depth increases, while increasing towards 1 as width and input dimension
increase.
\\ ( https://arxiv.org/abs/2306.06179 ,  3182kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06184
Date: Fri, 9 Jun 2023 18:21:04 GMT   (83kb,D)

Title: A Unified Model and Dimension for Interactive Estimation
Authors: Nataly Brukhim, Miroslav Dudik, Aldo Pacchiano, Robert Schapire
Categories: cs.LG stat.ML
\\
 We study an abstract framework for interactive learning called interactive
estimation in which the goal is to estimate a target from its "similarity'' to
points queried by the learner. We introduce a combinatorial measure called
dissimilarity dimension which largely captures learnability in our model. We
present a simple, general, and broadly-applicable algorithm, for which we
obtain both regret and PAC generalization bounds that are polynomial in the new
dimension. We show that our framework subsumes and thereby unifies two classic
learning models: statistical-query learning and structured bandits. We also
delineate how the dissimilarity dimension is related to well-known parameters
for both frameworks, in some cases yielding significantly improved analyses.
\\ ( https://arxiv.org/abs/2306.06184 ,  83kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06191
Date: Fri, 9 Jun 2023 18:43:26 GMT   (61kb,D)

Title: Open Data on GitHub: Unlocking the Potential of AI
Authors: Anthony Cintron Roman, Kevin Xu, Arfon Smith, Jehu Torres Vega, Caleb
 Robinson, Juan M Lavista Ferres
Categories: cs.LG cs.IR
Comments: In submission to NeurIPS 2023 Track Datasets and Benchmarks
\\
 GitHub is the world's largest platform for collaborative software
development, with over 100 million users. GitHub is also used extensively for
open data collaboration, hosting more than 800 million open data files,
totaling 142 terabytes of data. This study highlights the potential of open
data on GitHub and demonstrates how it can accelerate AI research. We analyze
the existing landscape of open data on GitHub and the patterns of how users
share datasets. Our findings show that GitHub is one of the largest hosts of
open data in the world and has experienced an accelerated growth of open data
assets over the past four years. By examining the open data landscape on
GitHub, we aim to empower users and organizations to leverage existing open
datasets and improve their discoverability -- ultimately contributing to the
ongoing AI revolution to help address complex societal issues. We release the
three datasets that we have collected to support this analysis as open datasets
at https://github.com/github/open-data-on-github.
\\ ( https://arxiv.org/abs/2306.06191 ,  61kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06193
Date: Fri, 9 Jun 2023 18:45:43 GMT   (8526kb,D)

Title: Consistent Explanations in the Face of Model Indeterminacy via
 Ensembling
Authors: Dan Ley, Leonard Tang, Matthew Nazari, Hongjin Lin, Suraj Srinivas,
 Himabindu Lakkaraju
Categories: cs.LG cs.AI cs.CY
\\
 This work addresses the challenge of providing consistent explanations for
predictive models in the presence of model indeterminacy, which arises due to
the existence of multiple (nearly) equally well-performing models for a given
dataset and task. Despite their similar performance, such models often exhibit
inconsistent or even contradictory explanations for their predictions, posing
challenges to end users who rely on these models to make critical decisions.
Recognizing this issue, we introduce ensemble methods as an approach to enhance
the consistency of the explanations provided in these scenarios. Leveraging
insights from recent work on neural network loss landscapes and mode
connectivity, we devise ensemble strategies to efficiently explore the
$\textit{underspecification set}$ -- the set of models with performance
variations resulting solely from changes in the random seed during training.
Experiments on five benchmark financial datasets reveal that ensembling can
yield significant improvements when it comes to explanation similarity, and
demonstrate the potential of existing ensemble methods to explore the
underspecification set efficiently. Our findings highlight the importance of
considering model indeterminacy when interpreting explanations and showcase the
effectiveness of ensembles in enhancing the reliability of explanations in
machine learning.
\\ ( https://arxiv.org/abs/2306.06193 ,  8526kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06194
Date: Fri, 9 Jun 2023 18:48:39 GMT   (4185kb,D)

Title: Public Transit Demand Prediction During Highly Dynamic Conditions: A
 Meta-Analysis of State-of-the-Art Models and Open-Source Benchmarking
 Infrastructure
Authors: Juan D. Caicedo, Marta C. Gonz\'alez, Joan L. Walker
Categories: cs.LG
Comments: 17 pages, 8 figures
\\
 Real-time demand prediction is a critical input for dynamic bus routing.
While many researchers have developed numerous complex methods to predict
short-term transit demand, the applications have been limited to short, stable
time frames and a few stations. How these methods perform in highly dynamic
environments has not been studied, nor has their performance been
systematically compared. We built an open-source infrastructure with five
common methodologies, including econometric and deep learning approaches, and
assessed their performance under stable and highly dynamic conditions. We used
a time series from smartcard data to predict demand for the following day for
the BRT system in Bogota, Colombia. The dynamic conditions in the time series
include a month-long protest and the COVID-19 pandemic. Both conditions
triggered drastic shifts in demand. The results reveal that most tested models
perform similarly in stable conditions, with MAAPE varying from 0.08 to 0.12.
The benchmark demonstrated that all models performed significantly worse in
both dynamic conditions compared to the stable conditions. In the month-long
protest, the increased MAAPE ranged from 0.14 to 0.24. Similarly, during the
COVID-19 pandemic, the increased MAAPE ranged from 0.12 to 0.82. Notably, in
the COVID-19 pandemic condition, an LSTM model with adaptive training and a
multi-output design outperformed other models, adapting faster to disruptions.
The prediction error stabilized within approximately 1.5 months, whereas other
models continued to exhibit higher error rates even a year after the start of
the pandemic. The aim of this open-source codebase infrastructure is to lower
the barrier for other researchers to replicate and reproduce models, facilitate
a collective effort within the research community to improve the benchmarking
process and accelerate the advancement of short-term ridership prediction
models.
\\ ( https://arxiv.org/abs/2306.06194 ,  4185kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06196
Date: Fri, 9 Jun 2023 18:53:25 GMT   (340kb,D)

Title: ElectroCardioGuard: Preventing Patient Misidentification in
 Electrocardiogram Databases through Neural Networks
Authors: Michal Sej\'ak, Jakub Sido, David \v{Z}ahour
Categories: cs.LG cs.AI eess.SP
Comments: 22 pages, 4 figures, 6 tables
\\
 Electrocardiograms (ECGs) are commonly used by cardiologists to detect
heart-related pathological conditions. Reliable collections of ECGs are crucial
for precise diagnosis. However, in clinical practice, the assignment of
captured ECG recordings to incorrect patients can occur inadvertently. In
collaboration with a clinical and research facility which recognized this
challenge and reached out to us, we present a study that addresses this issue.
In this work, we propose a small and efficient neural-network based model for
determining whether two ECGs originate from the same patient. Our model
demonstrates great generalization capabilities and achieves state-of-the-art
performance in gallery-probe patient identification on PTB-XL while utilizing
760x fewer parameters. Furthermore, we present a technique leveraging our model
for detection of recording-assignment mistakes, showcasing its applicability in
a realistic scenario. Finally, we evaluate our model on a newly collected ECG
dataset specifically curated for this study, and make it public for the
research community.
\\ ( https://arxiv.org/abs/2306.06196 ,  340kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06202
Date: Fri, 9 Jun 2023 19:10:16 GMT   (395kb,D)

Title: NeuroGraph: Benchmarks for Graph Machine Learning in Brain Connectomics
Authors: Anwar Said, Roza G. Bayrak, Tyler Derr, Mudassir Shabbir, Daniel
 Moyer, Catie Chang, Xenofon Koutsoukos
Categories: cs.LG cs.AI q-bio.NC
\\
 Machine learning provides a valuable tool for analyzing high-dimensional
functional neuroimaging data, and is proving effective in predicting various
neurological conditions, psychiatric disorders, and cognitive patterns. In
functional Magnetic Resonance Imaging (MRI) research, interactions between
brain regions are commonly modeled using graph-based representations. The
potency of graph machine learning methods has been established across myriad
domains, marking a transformative step in data interpretation and predictive
modeling. Yet, despite their promise, the transposition of these techniques to
the neuroimaging domain remains surprisingly under-explored due to the
expansive preprocessing pipeline and large parameter search space for
graph-based datasets construction. In this paper, we introduce NeuroGraph, a
collection of graph-based neuroimaging datasets that span multiple categories
of behavioral and cognitive traits. We delve deeply into the dataset generation
search space by crafting 35 datasets within both static and dynamic contexts,
running in excess of 15 baseline methods for benchmarking. Additionally, we
provide generic frameworks for learning on dynamic as well as static graphs.
Our extensive experiments lead to several key observations. Notably, using
correlation vectors as node features, incorporating larger number of regions of
interest, and employing sparser graphs lead to improved performance. To foster
further advancements in graph-based data driven Neuroimaging, we offer a
comprehensive open source Python package that includes the datasets, baseline
implementations, model training, and standard evaluation. The package is
publicly accessible at https://anwar-said.github.io/anwarsaid/neurograph.html .
\\ ( https://arxiv.org/abs/2306.06202 ,  395kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06203
Date: Fri, 9 Jun 2023 19:10:51 GMT   (39817kb,D)

Title: FLSL: Feature-level Self-supervised Learning
Authors: Qing Su, Anton Netchaev, Hai Li, and Shihao Ji
Categories: cs.LG cs.CV
\\
 Current self-supervised learning (SSL) methods (e.g., SimCLR, DINO, VICReg,
MOCOv3) target primarily on representations at instance level and do not
generalize well to dense prediction tasks, such as object detection and
segmentation. Towards aligning SSL with dense predictions, this paper
demonstrates for the first time the underlying mean-shift clustering process of
Vision Transformers (ViT), which aligns well with natural image semantics
(e.g., a world of objects and stuffs). By employing transformer for joint
embedding and clustering, we propose a two-level feature clustering SSL method,
coined Feature-Level Self-supervised Learning (FLSL). We present the formal
definition of the FLSL problem and construct the objectives from the mean-shift
and k-means perspectives. We show that FLSL promotes remarkable semantic
cluster representations and learns an embedding scheme amenable to intra-view
and inter-view feature clustering. Experiments show that FLSL yields
significant improvements in dense prediction tasks, achieving 44.9 (+2.8)% AP
and 46.5% AP in object detection, as well as 40.8 (+2.3)% AP and 42.1% AP in
instance segmentation on MS-COCO, using Mask R-CNN with ViT-S/16 and ViT-S/8 as
backbone, respectively. FLSL consistently outperforms existing SSL methods
across additional benchmarks, including UAV object detection on UAVDT, and
video instance segmentation on DAVIS 2017. We conclude by presenting
visualization and various ablation studies to better 20 understand the success
of FLSL.
\\ ( https://arxiv.org/abs/2306.06203 ,  39817kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06213
Date: Fri, 9 Jun 2023 19:27:24 GMT   (536kb)

Title: Robust Twin Parametric Margin Support Vector Machine for Multiclass
 Classification
Authors: Renato De Leone, Francesca Maggioni and Andrea Spinelli
Categories: cs.LG math.OC
\\
 In this paper we present a Twin Parametric-Margin Support Vector Machine
(TPMSVM) model to tackle the problem of multiclass classification. In the
spirit of one-versus-all paradigm, for each class we construct a classifier by
solving a TPMSVM-type model. Once all classifiers have been determined, they
are combined into an aggregate decision function. We consider the cases of both
linear and nonlinear kernel-induced classifiers. In addition, we robustify the
proposed approach through robust optimization techniques. Indeed, in real-world
applications observations are subject to measurement errors and noise,
affecting the quality of the solutions. Consequently, data uncertainties need
to be included within the model in order to prevent low accuracies in the
classification process. Preliminary computational experiments on real-world
datasets show the good performance of the proposed approach.
\\ ( https://arxiv.org/abs/2306.06213 ,  536kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06238
Date: Fri, 9 Jun 2023 20:18:05 GMT   (1444kb,D)

Title: Understanding the Effect of the Long Tail on Neural Network Compression
Authors: Harvey Dam, Vinu Joseph, Aditya Bhaskara, Ganesh Gopalakrishna, Saurav
 Muralidharan, Michael Garland
Categories: cs.LG cs.AI cs.CV
\\
 Network compression is now a mature sub-field of neural network research:
over the last decade, significant progress has been made towards reducing the
size of models and speeding up inference, while maintaining the classification
accuracy. However, many works have observed that focusing on just the overall
accuracy can be misguided. E.g., it has been shown that mismatches between the
full and compressed models can be biased towards under-represented classes.
This raises the important research question, \emph{can we achieve network
compression while maintaining ``semantic equivalence'' with the original
network?} In this work, we study this question in the context of the ``long
tail'' phenomenon in computer vision datasets observed by Feldman, et al. They
argue that \emph{memorization} of certain inputs (appropriately defined) is
essential to achieving good generalization. As compression limits the capacity
of a network (and hence also its ability to memorize), we study the question:
are mismatches between the full and compressed models correlated with the
memorized training data? We present positive evidence in this direction for
image classification tasks, by considering different base architectures and
compression schemes.
\\ ( https://arxiv.org/abs/2306.06238 ,  1444kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06247
Date: Fri, 9 Jun 2023 20:43:19 GMT   (30kb)

Title: Online Learning with Set-Valued Feedback
Authors: Vinod Raman, Unique Subedi, Ambuj Tewari
Categories: cs.LG stat.ML
Comments: 19 pages
\\
 We study a variant of online multiclass classification where the learner
predicts a single label but receives a \textit{set of labels} as feedback. In
this model, the learner is penalized for not outputting a label contained in
the revealed set. We show that unlike online multiclass learning with
single-label feedback, deterministic and randomized online learnability are
\textit{not equivalent} even in the realizable setting with set-valued
feedback. Accordingly, we give two new combinatorial dimensions, named the Set
Littlestone and Measure Shattering dimension, that tightly characterize
deterministic and randomized online learnability respectively in the realizable
setting. In addition, we show that the Measure Shattering dimension tightly
characterizes online learnability in the agnostic setting. Finally, we show
that practical learning settings like online multilabel ranking and online
multilabel classification are specific instances of our general online learning
framework.
\\ ( https://arxiv.org/abs/2306.06247 ,  30kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06251
Date: Fri, 9 Jun 2023 20:46:31 GMT   (949kb,D)

Title: Design Principles for Generalization and Scalability of AI in
 Communication Systems
Authors: Pablo Soldati, Euhanna Ghadimi, Burak Demirel, Yu Wang, Raimundas
 Gaigalas and Mathias Sintorn
Categories: cs.LG cs.AI cs.NI
\\
 Artificial intelligence (AI) has emerged as a powerful tool for addressing
complex and dynamic tasks in communication systems, where traditional
rule-based algorithms often struggle. However, most AI applications to
networking tasks are designed and trained for specific, limited conditions,
hindering the algorithms from learning and adapting to generic situations, such
as those met across radio access networks (RAN). This paper proposes design
principles for sustainable and scalable AI integration in communication
systems, focusing on creating AI algorithms that can generalize across network
environments, intents, and control tasks. This approach enables a limited
number of AI-driven RAN functions to tackle larger problems, improve system
performance, and simplify lifecycle management. To achieve sustainability and
automation, we introduce a scalable learning architecture that supports all
deployed AI applications in the system. This architecture separates centralized
learning functionalities from distributed actuation and inference functions,
enabling efficient data collection and management, computational and storage
resources optimization, and cost reduction. We illustrate these concepts by
designing a generalized link adaptation algorithm, demonstrating the benefits
of our proposed approach.
\\ ( https://arxiv.org/abs/2306.06251 ,  949kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06252
Date: Fri, 9 Jun 2023 20:46:55 GMT   (232kb,D)

Title: Feature Programming for Multivariate Time Series Prediction
Authors: Alex Reneau, Jerry Yao-Chieh Hu, Chenwei Xu, Weijian Li, Ammar Gilani,
 Han Liu
Categories: cs.LG stat.ML
Comments: 21 pages, accepted to ICML2023. Code is available at
 https://github.com/SirAlex900/FeatureProgramming
\\
 We introduce the concept of programmable feature engineering for time series
modeling and propose a feature programming framework. This framework generates
large amounts of predictive features for noisy multivariate time series while
allowing users to incorporate their inductive bias with minimal effort. The key
motivation of our framework is to view any multivariate time series as a
cumulative sum of fine-grained trajectory increments, with each increment
governed by a novel spin-gas dynamical Ising model. This fine-grained
perspective motivates the development of a parsimonious set of operators that
summarize multivariate time series in an abstract fashion, serving as the
foundation for large-scale automated feature engineering. Numerically, we
validate the efficacy of our method on several synthetic and real-world noisy
time series datasets.
\\ ( https://arxiv.org/abs/2306.06252 ,  232kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06253
Date: Fri, 9 Jun 2023 20:52:16 GMT   (1849kb,D)

Title: Decision Stacks: Flexible Reinforcement Learning via Modular Generative
 Models
Authors: Siyan Zhao and Aditya Grover
Categories: cs.LG cs.AI
\\
 Reinforcement learning presents an attractive paradigm to reason about
several distinct aspects of sequential decision making, such as specifying
complex goals, planning future observations and actions, and critiquing their
utilities. However, the combined integration of these capabilities poses
competing algorithmic challenges in retaining maximal expressivity while
allowing for flexibility in modeling choices for efficient learning and
inference. We present Decision Stacks, a generative framework that decomposes
goal-conditioned policy agents into 3 generative modules. These modules
simulate the temporal evolution of observations, rewards, and actions via
independent generative models that can be learned in parallel via teacher
forcing. Our framework guarantees both expressivity and flexibility in
designing individual modules to account for key factors such as architectural
bias, optimization objective and dynamics, transferrability across domains, and
inference speed. Our empirical results demonstrate the effectiveness of
Decision Stacks for offline policy optimization for several MDP and POMDP
environments, outperforming existing methods and enabling flexible generative
decision making.
\\ ( https://arxiv.org/abs/2306.06253 ,  1849kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06265
Date: Fri, 9 Jun 2023 21:26:57 GMT   (5694kb,D)

Title: Near-optimal Conservative Exploration in Reinforcement Learning under
 Episode-wise Constraints
Authors: Donghao Li, Ruiquan Huang, Cong Shen, Jing Yang
Categories: cs.LG stat.ML
Comments: Accepted by ICML2023
\\
 This paper investigates conservative exploration in reinforcement learning
where the performance of the learning agent is guaranteed to be above a certain
threshold throughout the learning process. It focuses on the tabular episodic
Markov Decision Process (MDP) setting that has finite states and actions. With
the knowledge of an existing safe baseline policy, an algorithm termed as
StepMix is proposed to balance the exploitation and exploration while ensuring
that the conservative constraint is never violated in each episode with high
probability. StepMix features a unique design of a mixture policy that
adaptively and smoothly interpolates between the baseline policy and the
optimistic policy. Theoretical analysis shows that StepMix achieves
near-optimal regret order as in the constraint-free setting, indicating that
obeying the stringent episode-wise conservative constraint does not compromise
the learning performance. Besides, a randomization-based EpsMix algorithm is
also proposed and shown to achieve the same performance as StepMix. The
algorithm design and theoretical analysis are further extended to the setting
where the baseline policy is not given a priori but must be learned from an
offline dataset, and it is proved that similar conservative guarantee and
regret can be achieved if the offline dataset is sufficiently large. Experiment
results corroborate the theoretical analysis and demonstrate the effectiveness
of the proposed conservative exploration strategies.
\\ ( https://arxiv.org/abs/2306.06265 ,  5694kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06268
Date: Fri, 9 Jun 2023 21:35:34 GMT   (978kb)

Title: Attention-stacked Generative Adversarial Network (AS-GAN)-empowered
 Sensor Data Augmentation for Online Monitoring of Manufacturing System
Authors: Yuxuan Li, Chenang Liu
Categories: cs.LG
\\
 Machine learning (ML) has been extensively adopted for the online
sensing-based monitoring in advanced manufacturing systems. However, the sensor
data collected under abnormal states are usually insufficient, leading to
significant data imbalanced issue for supervised machine learning. A common
solution for this issue is to incorporate data augmentation technique, i.e.,
augmenting the available abnormal states data (i.e., minority samples) via
synthetic generation. To generate the high-quality minority samples
effectively, it is vital to learn the underlying distribution of the abnormal
states data. In recent years, the generative adversarial network (GAN)-based
approaches become popular to learn data distribution as well as perform data
augmentation. However, in practice, the quality of generated samples from
GAN-based data augmentation may vary drastically. In addition, the sensor
signals are collected sequentially by time from the manufacturing systems,
which means the consideration of sequential information is also very important
in data augmentation. To address these limitations, inspired by the multi-head
attention mechanism, this paper proposed an attention-stacked GAN (AS-GAN)
architecture for the sensor data augmentation of online monitoring in advanced
manufacturing. In this proposed AS-GAN, a new attention-stacked framework is
incorporated to strengthen the generator in GAN with the learning capability of
considering sequential information. Furthermore, the developed
attention-stacked framework also greatly helps to improve the quality of
generated sensor signals. The case studies conducted in additive manufacturing
also successfully validate the effectiveness of AS-GAN to augment high-quality
artificial multi-channel sensor signals for online monitoring of manufacturing
systems.
\\ ( https://arxiv.org/abs/2306.06268 ,  978kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06276
Date: Fri, 9 Jun 2023 22:03:18 GMT   (1633kb,D)

Title: Contrastive Learning for Predicting Cancer Prognosis Using Gene
 Expression Values
Authors: Anchen Sun, Zhibin Chen, Xiaodong Cai
Categories: cs.LG
\\
 Several artificial neural networks (ANNs) have recently been developed as the
Cox proportional hazard model for predicting cancer prognosis based on tumor
transcriptome. However, they have not demonstrated significantly better
performance than the traditional Cox regression with regularization. Training
an ANN with high prediction power is challenging in the presence of a limited
number of data samples and a high-dimensional feature space. Recent
advancements in image classification have shown that contrastive learning can
facilitate further learning tasks by learning good feature representation from
a limited number of data samples. In this paper, we applied supervised
contrastive learning to tumor gene expression and clinical data to learn
feature representations in a low-dimensional space. We then used these learned
features to train the Cox model for predicting cancer prognosis. Using data
from The Cancer Genome Atlas (TCGA), we demonstrated that our contrastive
learning-based Cox model (CLCox) significantly outperformed existing methods in
predicting the prognosis of 18 types of cancer under consideration. We also
developed contrastive learning-based classifiers to classify tumors into
different risk groups and showed that contrastive learning can significantly
improve classification accuracy.
\\ ( https://arxiv.org/abs/2306.06276 ,  1633kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06325
Date: Sat, 10 Jun 2023 00:49:21 GMT   (11101kb,D)

Title: Explaining a machine learning decision to physicians via counterfactuals
Authors: Supriya Nagesh, Nina Mishra, Yonatan Naamad, James M. Rehg, Mehul A.
 Shah, Alexei Wagner
Categories: cs.LG
\\
 Machine learning models perform well on several healthcare tasks and can help
reduce the burden on the healthcare system. However, the lack of explainability
is a major roadblock to their adoption in hospitals. \textit{How can the
decision of an ML model be explained to a physician?} The explanations
considered in this paper are counterfactuals (CFs), hypothetical scenarios that
would have resulted in the opposite outcome. Specifically, time-series CFs are
investigated, inspired by the way physicians converse and reason out decisions
`I would have given the patient a vasopressor if their blood pressure was lower
and falling'. Key properties of CFs that are particularly meaningful in
clinical settings are outlined: physiological plausibility, relevance to the
task and sparse perturbations. Past work on CF generation does not satisfy
these properties, specifically plausibility in that realistic time-series CFs
are not generated. A variational autoencoder (VAE)-based approach is proposed
that captures these desired properties. The method produces CFs that improve on
prior approaches quantitatively (more plausible CFs as evaluated by their
likelihood w.r.t original data distribution, and 100$\times$ faster at
generating CFs) and qualitatively (2$\times$ more plausible and relevant) as
evaluated by three physicians.
\\ ( https://arxiv.org/abs/2306.06325 ,  11101kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06327
Date: Sat, 10 Jun 2023 00:55:38 GMT   (1283kb,D)

Title: Any-dimensional equivariant neural networks
Authors: Eitan Levin and Mateo D\'iaz
Categories: cs.LG math.RT stat.ML
Comments: 18 pages, 2 figures
\\
 Traditional supervised learning aims to learn an unknown mapping by fitting a
function to a set of input-output pairs with a fixed dimension. The fitted
function is then defined on inputs of the same dimension. However, in many
settings, the unknown mapping takes inputs in any dimension; examples include
graph parameters defined on graphs of any size and physics quantities defined
on an arbitrary number of particles. We leverage a newly-discovered phenomenon
in algebraic topology, called representation stability, to define equivariant
neural networks that can be trained with data in a fixed dimension and then
extended to accept inputs in any dimension. Our approach is user-friendly,
requiring only the network architecture and the groups for equivariance, and
can be combined with any training procedure. We provide a simple open-source
implementation of our methods and offer preliminary numerical experiments.
\\ ( https://arxiv.org/abs/2306.06327 ,  1283kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06329
Date: Sat, 10 Jun 2023 01:49:01 GMT   (2151kb,D)

Title: HIPODE: Enhancing Offline Reinforcement Learning with High-Quality
 Synthetic Data from a Policy-Decoupled Approach
Authors: Shixi Lian, Yi Ma, Jinyi Liu, Yan Zheng, Zhaopeng Meng
Categories: cs.LG
\\
 Offline reinforcement learning (ORL) has gained attention as a means of
training reinforcement learning models using pre-collected static data. To
address the issue of limited data and improve downstream ORL performance,
recent work has attempted to expand the dataset's coverage through data
augmentation. However, most of these methods are tied to a specific policy
(policy-dependent), where the generated data can only guarantee to support the
current downstream ORL policy, limiting its usage scope on other downstream
policies. Moreover, the quality of synthetic data is often not well-controlled,
which limits the potential for further improving the downstream policy. To
tackle these issues, we propose \textbf{HI}gh-quality
\textbf{PO}licy-\textbf{DE}coupled~(HIPODE), a novel data augmentation method
for ORL. On the one hand, HIPODE generates high-quality synthetic data by
selecting states near the dataset distribution with potentially high value
among candidate states using the negative sampling technique. On the other
hand, HIPODE is policy-decoupled, thus can be used as a common plug-in method
for any downstream ORL process. We conduct experiments on the widely studied
TD3BC and CQL algorithms, and the results show that HIPODE outperforms the
state-of-the-art policy-decoupled data augmentation method and most prevalent
model-based ORL methods on D4RL benchmarks.
\\ ( https://arxiv.org/abs/2306.06329 ,  2151kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06335
Date: Sat, 10 Jun 2023 02:33:34 GMT   (3268kb,D)

Title: How to Learn and Generalize From Three Minutes of Data:
 Physics-Constrained and Uncertainty-Aware Neural Stochastic Differential
 Equations
Authors: Franck Djeumou and Cyrus Neary and Ufuk Topcu
Categories: cs.LG cs.RO cs.SY eess.SY
Comments: Initial submission to CoRL 2023
\\
 We present a framework and algorithms to learn controlled dynamics models
using neural stochastic differential equations (SDEs) -- SDEs whose drift and
diffusion terms are both parametrized by neural networks. We construct the
drift term to leverage a priori physics knowledge as inductive bias, and we
design the diffusion term to represent a distance-aware estimate of the
uncertainty in the learned model's predictions -- it matches the system's
underlying stochasticity when evaluated on states near those from the training
dataset, and it predicts highly stochastic dynamics when evaluated on states
beyond the training regime. The proposed neural SDEs can be evaluated quickly
enough for use in model predictive control algorithms, or they can be used as
simulators for model-based reinforcement learning. Furthermore, they make
accurate predictions over long time horizons, even when trained on small
datasets that cover limited regions of the state space. We demonstrate these
capabilities through experiments on simulated robotic systems, as well as by
using them to model and control a hexacopter's flight dynamics: A neural SDE
trained using only three minutes of manually collected flight data results in a
model-based control policy that accurately tracks aggressive trajectories that
push the hexacopter's velocity and Euler angles to nearly double the maximum
values observed in the training dataset.
\\ ( https://arxiv.org/abs/2306.06335 ,  3268kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06338
Date: Sat, 10 Jun 2023 03:29:48 GMT   (1044kb)

Title: Machine Learning Based Missing Values Imputation in Categorical Datasets
Authors: Muhammad Ishaq, Laila iftikhar, Majid Khan, Asfandyar Khan, Arshad
 Khan
Categories: cs.LG
Comments: 29 pages
\\
 This study explored the use of machine learning algorithms for predicting and
imputing missing values in categorical datasets. We focused on ensemble models
that use the error correction output codes (ECOC) framework, including
SVM-based and KNN-based ensemble models, as well as an ensemble classifier that
combines SVM, KNN, and MLP models. We applied these algorithms to three
datasets: the CPU dataset, the hypothyroid dataset, and the Breast Cancer
dataset. Our experiments showed that the machine learning algorithms were able
to achieve good performance in predicting and imputing the missing values, with
some variations depending on the specific dataset and missing value pattern.
The ensemble models using the error correction output codes (ECOC) framework
were particularly effective in improving the accuracy and robustness of the
predictions, compared to individual models. However, there are also challenges
and limitations to using deep learning for missing value imputation, including
the need for large amounts of labeled data and the potential for overfitting.
Further research is needed to evaluate the effectiveness and efficiency of deep
learning algorithms for missing value imputation and to develop strategies for
addressing the challenges and limitations that may arise.
\\ ( https://arxiv.org/abs/2306.06338 ,  1044kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06375
Date: Sat, 10 Jun 2023 07:54:20 GMT   (1227kb)

Title: Optimized Gradient Tracking for Decentralized Online Learning
Authors: Shivangi Dubey Sharma (1) and Ketan Rajawat (1), ((1) Indian Institute
 of Technology Kanpur)
Categories: cs.LG eess.SP math.OC
Comments: 30 pages, 6 Figures
\\
 This work considers the problem of decentralized online learning, where the
goal is to track the optimum of the sum of time-varying functions, distributed
across several nodes in a network. The local availability of the functions and
their gradients necessitates coordination and consensus among the nodes. We put
forth the Generalized Gradient Tracking (GGT) framework that unifies a number
of existing approaches, including the state-of-the-art ones. The performance of
the proposed GGT algorithm is theoretically analyzed using a novel semidefinite
programming-based analysis that yields the desired regret bounds under very
general conditions and without requiring the gradient boundedness assumption.
The results are applicable to the special cases of GGT, which include various
state-of-the-art algorithms as well as new dynamic versions of various
classical decentralized algorithms. To further minimize the regret, we consider
a condensed version of GGT with only four free parameters. A procedure for
offline tuning of these parameters using only the problem parameters is also
detailed. The resulting optimized GGT (oGGT) algorithm not only achieves
improved dynamic regret bounds, but also outperforms all state-of-the-art
algorithms on both synthetic and real-world datasets.
\\ ( https://arxiv.org/abs/2306.06375 ,  1227kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06380
Date: Sat, 10 Jun 2023 08:35:00 GMT   (500kb,D)

Title: D2Match: Leveraging Deep Learning and Degeneracy for Subgraph Matching
Authors: Xuanzhou Liu, Lin Zhang, Jiaqi Sun, Yujiu Yang, Haiqin Yang
Categories: cs.LG cs.AI
Comments: Accepted by icml2023
\\
 Subgraph matching is a fundamental building block for graph-based
applications and is challenging due to its high-order combinatorial nature.
Existing studies usually tackle it by combinatorial optimization or
learning-based methods. However, they suffer from exponential computational
costs or searching the matching without theoretical guarantees. In this paper,
we develop D2Match by leveraging the efficiency of Deep learning and Degeneracy
for subgraph matching. More specifically, we first prove that subgraph matching
can degenerate to subtree matching, and subsequently is equivalent to finding a
perfect matching on a bipartite graph. We can then yield an implementation of
linear time complexity by the built-in tree-structured aggregation mechanism on
graph neural networks. Moreover, circle structures and node attributes can be
easily incorporated in D2Match to boost the matching performance. Finally, we
conduct extensive experiments to show the superior performance of our D2Match
and confirm that our D2Match indeed exploits the subtrees and differs from
existing GNNs-based subgraph matching methods that depend on memorizing the
data distribution divergence
\\ ( https://arxiv.org/abs/2306.06380 ,  500kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06385
Date: Sat, 10 Jun 2023 09:12:10 GMT   (9252kb,D)

Title: Continually learning out-of-distribution spatiotemporal data for robust
 energy forecasting
Authors: Arian Prabowo, Kaixuan Chen, Hao Xue, Subbu Sethuvenkatraman, Flora D.
 Salim
Categories: cs.LG
Comments: 15 pages, 3 figures, ECML PKDD ADS 2023
\\
 Forecasting building energy usage is essential for promoting sustainability
and reducing waste, as it enables building managers to optimize energy
consumption and reduce costs. This importance is magnified during anomalous
periods, such as the COVID-19 pandemic, which have disrupted occupancy patterns
and made accurate forecasting more challenging. Forecasting energy usage during
anomalous periods is difficult due to changes in occupancy patterns and energy
usage behavior. One of the primary reasons for this is the shift in
distribution of occupancy patterns, with many people working or learning from
home. This has created a need for new forecasting methods that can adapt to
changing occupancy patterns. Online learning has emerged as a promising
solution to this challenge, as it enables building managers to adapt to changes
in occupancy patterns and adjust energy usage accordingly. With online
learning, models can be updated incrementally with each new data point,
allowing them to learn and adapt in real-time. Another solution is to use human
mobility data as a proxy for occupancy, leveraging the prevalence of mobile
devices to track movement patterns and infer occupancy levels. Human mobility
data can be useful in this context as it provides a way to monitor occupancy
patterns without relying on traditional sensors or manual data collection
methods. We have conducted extensive experiments using data from six buildings
to test the efficacy of these approaches. However, deploying these methods in
the real world presents several challenges.
\\ ( https://arxiv.org/abs/2306.06385 ,  9252kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06394
Date: Sat, 10 Jun 2023 09:41:30 GMT   (13923kb,D)

Title: PEAR: Primitive enabled Adaptive Relabeling for boosting Hierarchical
 Reinforcement Learning
Authors: Utsav Singh, Vinay P Namboodiri
Categories: cs.LG
\\
 Hierarchical reinforcement learning (HRL) has the potential to solve complex
long horizon tasks using temporal abstraction and increased exploration.
However, hierarchical agents are difficult to train as they suffer from
inherent non-stationarity due to continuously changing low level primitive. We
present primitive enabled adaptive relabeling (PEAR), a two-phase approach
where firstly we perform adaptive relabeling on a few expert demonstrations to
generate subgoal supervision dataset, and then employ imitation learning for
regularizing HRL agents. We bound the sub-optimality of our method using
theoretical bounds and devise a practical HRL algorithm for solving complex
robotic tasks. We perform experiments on challenging robotic tasks: maze
navigation, pick and place, rope manipulation and kitchen environments, and
demonstrate that the proposed approach is able to solve complex tasks that
require long term decision making. Since our method uses a handful of expert
demonstrations and makes minimal limiting assumptions on task structure, it can
be easily integrated with typical model free reinforcement learning algorithms
to solve most robotic tasks. We empirically show that our approach outperforms
previous hierarchical and non-hierarchical baselines, and exhibits better
sample efficiency. We also perform real world robotic experiments by deploying
the learned policy on a real robotic rope manipulation task and demonstrate
that PEAR consistently outperforms the baselines. Here is the link for
supplementary video: \url{https://tinyurl.com/pearOverview}
\\ ( https://arxiv.org/abs/2306.06394 ,  13923kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06399
Date: Sat, 10 Jun 2023 09:52:01 GMT   (565kb)

Title: Personalized Graph Federated Learning with Differential Privacy
Authors: Francois Gauthier, Vinay Chakravarthi Gogineni, Stefan Werner,
 Yih-Fang Huang, Anthony Kuh
Categories: cs.LG stat.ML
\\
 This paper presents a personalized graph federated learning (PGFL) framework
in which distributedly connected servers and their respective edge devices
collaboratively learn device or cluster-specific models while maintaining the
privacy of every individual device. The proposed approach exploits similarities
among different models to provide a more relevant experience for each device,
even in situations with diverse data distributions and disproportionate
datasets. Furthermore, to ensure a secure and efficient approach to
collaborative personalized learning, we study a variant of the PGFL
implementation that utilizes differential privacy, specifically
zero-concentrated differential privacy, where a noise sequence perturbs model
exchanges. Our mathematical analysis shows that the proposed privacy-preserving
PGFL algorithm converges to the optimal cluster-specific solution for each
cluster in linear time. It also shows that exploiting similarities among
clusters leads to an alternative output whose distance to the original solution
is bounded, and that this bound can be adjusted by modifying the algorithm's
hyperparameters. Further, our analysis shows that the algorithm ensures local
differential privacy for all clients in terms of zero-concentrated differential
privacy. Finally, the performance of the proposed PGFL algorithm is examined by
performing numerical experiments in the context of regression and
classification using synthetic data and the MNIST dataset.
\\ ( https://arxiv.org/abs/2306.06399 ,  565kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06402
Date: Sat, 10 Jun 2023 10:04:54 GMT   (266kb,D)

Title: A Single-Loop Deep Actor-Critic Algorithm for Constrained Reinforcement
 Learning with Provable Convergence
Authors: Kexuan Wang, An Liu, and Baishuo Liu
Categories: cs.LG
\\
 Abstract -- Deep Actor-Critic algorithms, which combine Actor-Critic with
deep neural network (DNN), have been among the most prevalent reinforcement
learning algorithms for decision-making problems in simulated environments.
However, the existing deep Actor-Critic algorithms are still not mature to
solve realistic problems with non-convex stochastic constraints and high cost
to interact with the environment. In this paper, we propose a single-loop deep
Actor-Critic (SLDAC) algorithmic framework for general constrained
reinforcement learning (CRL) problems. In the actor step, the constrained
stochastic successive convex approximation (CSSCA) method is applied to handle
the non-convex stochastic objective and constraints. In the critic step, the
critic DNNs are only updated once or a few finite times for each iteration,
which simplifies the algorithm to a single-loop framework (the existing works
require a sufficient number of updates for the critic step to ensure a good
enough convergence of the inner loop for each iteration). Moreover, the
variance of the policy gradient estimation is reduced by reusing observations
from the old policy. The single-loop design and the observation reuse
effectively reduce the agent-environment interaction cost and computational
complexity. In spite of the biased policy gradient estimation incurred by the
single-loop design and observation reuse, we prove that the SLDAC with a
feasible initial point can converge to a Karush-Kuhn-Tuker (KKT) point of the
original problem almost surely. Simulations show that the SLDAC algorithm can
achieve superior performance with much lower interaction cost.
\\ ( https://arxiv.org/abs/2306.06402 ,  266kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06446
Date: Sat, 10 Jun 2023 13:53:41 GMT   (7640kb,D)

Title: ShiftAddViT: Mixture of Multiplication Primitives Towards Efficient
 Vision Transformer
Authors: Haoran You, Huihong Shi, Yipin Guo, Yingyan (Celine) Lin
Categories: cs.LG cs.AI
Comments: Preprint
\\
 Vision Transformers (ViTs) have shown impressive performance and have become
a unified backbone for multiple vision tasks. But both attention and
multi-layer perceptions (MLPs) in ViTs are not efficient enough due to dense
multiplications, resulting in costly training and inference. To this end, we
propose to reparameterize the pre-trained ViT with a mixture of multiplication
primitives, e.g., bitwise shifts and additions, towards a new type of
multiplication-reduced model, dubbed $\textbf{ShiftAddViT}$, which aims for
end-to-end inference speedups on GPUs without the need of training from
scratch. Specifically, all $\texttt{MatMuls}$ among queries, keys, and values
are reparameterized by additive kernels, after mapping queries and keys to
binary codes in Hamming space. The remaining MLPs or linear layers are then
reparameterized by shift kernels. We utilize TVM to implement and optimize
those customized kernels for practical hardware deployment on GPUs. We find
that such a reparameterization on (quadratic or linear) attention maintains
model accuracy, while inevitably leading to accuracy drops when being applied
to MLPs. To marry the best of both worlds, we further propose a new mixture of
experts (MoE) framework to reparameterize MLPs by taking multiplication or its
primitives as experts, e.g., multiplication and shift, and designing a new
latency-aware load-balancing loss. Such a loss helps to train a generic router
for assigning a dynamic amount of input tokens to different experts according
to their latency. In principle, the faster experts run, the larger amount of
input tokens are assigned. Extensive experiments consistently validate the
effectiveness of our proposed ShiftAddViT, achieving up to
$\textbf{5.18$\times$}$ latency reductions on GPUs and $\textbf{42.9%}$ energy
savings, while maintaining comparable accuracy as original or efficient ViTs.
\\ ( https://arxiv.org/abs/2306.06446 ,  7640kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06462
Date: Sat, 10 Jun 2023 15:11:24 GMT   (1789kb,D)

Title: Boosting Adversarial Robustness using Feature Level Stochastic Smoothing
Authors: Sravanti Addepalli, Samyak Jain, Gaurang Sriramanan, R. Venkatesh Babu
Categories: cs.LG
Comments: CVPR Workshops 2021. First three authors contributed equally
\\
 Advances in adversarial defenses have led to a significant improvement in the
robustness of Deep Neural Networks. However, the robust accuracy of present
state-ofthe-art defenses is far from the requirements in critical applications
such as robotics and autonomous navigation systems. Further, in practical use
cases, network prediction alone might not suffice, and assignment of a
confidence value for the prediction can prove crucial. In this work, we propose
a generic method for introducing stochasticity in the network predictions, and
utilize this for smoothing decision boundaries and rejecting low confidence
predictions, thereby boosting the robustness on accepted samples. The proposed
Feature Level Stochastic Smoothing based classification also results in a boost
in robustness without rejection over existing adversarial training methods.
Finally, we combine the proposed method with adversarial detection methods, to
achieve the benefits of both approaches.
\\ ( https://arxiv.org/abs/2306.06462 ,  1789kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06473
Date: Sat, 10 Jun 2023 16:15:55 GMT   (818kb,D)

Title: Interpretable Differencing of Machine Learning Models
Authors: Swagatam Haldar, Diptikalyan Saha, Dennis Wei, Rahul Nair, Elizabeth
 M. Daly
Categories: cs.LG
Comments: UAI 2023
\\
 Understanding the differences between machine learning (ML) models is of
interest in scenarios ranging from choosing amongst a set of competing models,
to updating a deployed model with new training data. In these cases, we wish to
go beyond differences in overall metrics such as accuracy to identify
\emph{where} in the feature space do the differences occur. We formalize this
problem of model \emph{differencing} as one of predicting a dissimilarity
function of two ML models' outputs, subject to the representation of the
differences being human-interpretable. Our solution is to learn a \emph{Joint
Surrogate Tree} (JST), which is composed of two conjoined decision tree
surrogates for the two models. A JST provides an intuitive representation of
differences and places the changes in the context of the models' decision
logic. Context is important as it helps users to map differences to an
underlying mental model of an AI system. We also propose a refinement procedure
to increase the precision of a JST. We demonstrate, through an empirical
evaluation, that such contextual differencing is concise and can be achieved
with no loss in fidelity over naive approaches.
\\ ( https://arxiv.org/abs/2306.06473 ,  818kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06479
Date: Sat, 10 Jun 2023 16:36:22 GMT   (806kb,D)

Title: Learning a Neuron by a Shallow ReLU Network: Dynamics and Implicit Bias
 for Correlated Inputs
Authors: Dmitry Chistikov, Matthias Englert, Ranko Lazic
Categories: cs.LG
MSC-class: 68Q32, 68T07
ACM-class: I.2.6
\\
 We prove that, for the fundamental regression task of learning a single
neuron, training a one-hidden layer ReLU network of any width by gradient flow
from a small initialisation converges to zero loss and is implicitly biased to
minimise the rank of network parameters. By assuming that the training points
are correlated with the teacher neuron, we complement previous work that
considered orthogonal datasets. Our results are based on a detailed
non-asymptotic analysis of the dynamics of each hidden neuron throughout the
training. We also show and characterise a surprising distinction in this
setting between interpolator networks of minimal rank and those of minimal
Euclidean norm. Finally we perform a range of numerical experiments, which
corroborate our theoretical findings.
\\ ( https://arxiv.org/abs/2306.06479 ,  806kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06482
Date: Sat, 10 Jun 2023 16:41:18 GMT   (168kb,D)

Title: TensorNet: Cartesian Tensor Representations for Efficient Learning of
 Molecular Potentials
Authors: Guillem Simeon, Gianni de Fabritiis
Categories: cs.LG physics.chem-ph physics.comp-ph
\\
 The development of efficient machine learning models for molecular systems
representation is becoming crucial in scientific research. We introduce
TensorNet, an innovative $\mathrm{O}(3)$-equivariant message-passing neural
network architecture that leverages Cartesian tensor representations. By using
Cartesian tensor atomic embeddings, feature mixing is simplified through matrix
product operations. Furthermore, the cost-effective decomposition of these
tensors into rotation group irreducible representations allows for the separate
processing of scalars, vectors, and tensors when necessary. Compared to
higher-rank spherical tensor models, TensorNet demonstrates state-of-the-art
performance with significantly fewer parameters. For small molecule potential
energies, this can be achieved even with a single interaction layer. As a
result of all these properties, the model's computational cost is substantially
decreased. Moreover, the accurate prediction of vector and tensor molecular
quantities on top of potential energies and forces is possible. In summary,
TensorNet's framework opens up a new space for the design of state-of-the-art
equivariant models.
\\ ( https://arxiv.org/abs/2306.06482 ,  168kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06503
Date: Sat, 10 Jun 2023 18:41:50 GMT   (3265kb)

Title: Preserving privacy in domain transfer of medical AI models comes at no
 performance costs: The integral role of differential privacy
Authors: Soroosh Tayebi Arasteh, Mahshad Lotfinia, Teresa Nolte, Marwin Saehn,
 Peter Isfort, Christiane Kuhl, Sven Nebelung, Georgios Kaissis, Daniel Truhn
Categories: cs.LG cs.AI cs.CR eess.IV
\\
 Developing robust and effective artificial intelligence (AI) models in
medicine requires access to large amounts of patient data. The use of AI models
solely trained on large multi-institutional datasets can help with this, yet
the imperative to ensure data privacy remains, particularly as membership
inference risks breaching patient confidentiality. As a proposed remedy, we
advocate for the integration of differential privacy (DP). We specifically
investigate the performance of models trained with DP as compared to models
trained without DP on data from institutions that the model had not seen during
its training (i.e., external validation) - the situation that is reflective of
the clinical use of AI models. By leveraging more than 590,000 chest
radiographs from five institutions, we evaluated the efficacy of DP-enhanced
domain transfer (DP-DT) in diagnosing cardiomegaly, pleural effusion,
pneumonia, atelectasis, and in identifying healthy subjects. We juxtaposed
DP-DT with non-DP-DT and examined diagnostic accuracy and demographic fairness
using the area under the receiver operating characteristic curve (AUC) as the
main metric, as well as accuracy, sensitivity, and specificity. Our results
show that DP-DT, even with exceptionally high privacy levels (epsilon around
1), performs comparably to non-DP-DT (P>0.119 across all domains). Furthermore,
DP-DT led to marginal AUC differences - less than 1% - for nearly all
subgroups, relative to non-DP-DT. Despite consistent evidence suggesting that
DP models induce significant performance degradation for on-domain
applications, we show that off-domain performance is almost not affected.
Therefore, we ardently advocate for the adoption of DP in training diagnostic
medical AI models, given its minimal impact on performance.
\\ ( https://arxiv.org/abs/2306.06503 ,  3265kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06506
Date: Sat, 10 Jun 2023 18:54:15 GMT   (19447kb,D)

Title: Calculating and Visualizing Counterfactual Feature Importance Values
Authors: Bjorge Meulemeester, Raphael Mazzine Barbosa De Oliveira, David
 Martens
Categories: cs.LG cs.AI cs.HC
\\
 Despite the success of complex machine learning algorithms, mostly justified
by an outstanding performance in prediction tasks, their inherent opaque nature
still represents a challenge to their responsible application. Counterfactual
explanations surged as one potential solution to explain individual decision
results. However, two major drawbacks directly impact their usability: (1) the
isonomic view of feature changes, in which it is not possible to observe
\textit{how much} each modified feature influences the prediction, and (2) the
lack of graphical resources to visualize the counterfactual explanation. We
introduce Counterfactual Feature (change) Importance (CFI) values as a
solution: a way of assigning an importance value to each feature change in a
given counterfactual explanation. To calculate these values, we propose two
potential CFI methods. One is simple, fast, and has a greedy nature. The other,
coined CounterShapley, provides a way to calculate Shapley values between the
factual-counterfactual pair. Using these importance values, we additionally
introduce three chart types to visualize the counterfactual explanations: (a)
the Greedy chart, which shows a greedy sequential path for prediction score
increase up to predicted class change, (b) the CounterShapley chart, depicting
its respective score in a simple and one-dimensional chart, and finally (c) the
Constellation chart, which shows all possible combinations of feature changes,
and their impact on the model's prediction score. For each of our proposed CFI
methods and visualization schemes, we show how they can provide more
information on counterfactual explanations. Finally, an open-source
implementation is offered, compatible with any counterfactual explanation
generator algorithm. Code repository at:
https://github.com/ADMAntwerp/CounterPlots
\\ ( https://arxiv.org/abs/2306.06506 ,  19447kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06508
Date: Sat, 10 Jun 2023 18:59:50 GMT   (396kb,D)

Title: Optimizing the Collaboration Structure in Cross-Silo Federated Learning
Authors: Wenxuan Bao, Haohan Wang, Jun Wu, Jingrui He
Categories: cs.LG
Comments: Accepted by ICML 2023
\\
 In federated learning (FL), multiple clients collaborate to train machine
learning models together while keeping their data decentralized. Through
utilizing more training data, FL suffers from the potential negative transfer
problem: the global FL model may even perform worse than the models trained
with local data only. In this paper, we propose FedCollab, a novel FL framework
that alleviates negative transfer by clustering clients into non-overlapping
coalitions based on their distribution distances and data quantities. As a
result, each client only collaborates with the clients having similar data
distributions, and tends to collaborate with more clients when it has less
data. We evaluate our framework with a variety of datasets, models, and types
of non-IIDness. Our results demonstrate that FedCollab effectively mitigates
negative transfer across a wide range of FL algorithms and consistently
outperforms other clustered FL algorithms.
\\ ( https://arxiv.org/abs/2306.06508 ,  396kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06510
Date: Sat, 10 Jun 2023 19:04:03 GMT   (1429kb,D)

Title: Partial Identifiability for Domain Adaptation
Authors: Lingjing Kong, Shaoan Xie, Weiran Yao, Yujia Zheng, Guangyi Chen,
 Petar Stojanov, Victor Akinwande, Kun Zhang
Categories: cs.LG stat.ML
Comments: ICML 2022
\\
 Unsupervised domain adaptation is critical to many real-world applications
where label information is unavailable in the target domain. In general,
without further assumptions, the joint distribution of the features and the
label is not identifiable in the target domain. To address this issue, we rely
on the property of minimal changes of causal mechanisms across domains to
minimize unnecessary influences of distribution shifts. To encode this
property, we first formulate the data-generating process using a latent
variable model with two partitioned latent subspaces: invariant components
whose distributions stay the same across domains and sparse changing components
that vary across domains. We further constrain the domain shift to have a
restrictive influence on the changing components. Under mild conditions, we
show that the latent variables are partially identifiable, from which it
follows that the joint distribution of data and labels in the target domain is
also identifiable. Given the theoretical insights, we propose a practical
domain adaptation framework called iMSDA. Extensive experimental results reveal
that iMSDA outperforms state-of-the-art domain adaptation algorithms on
benchmark datasets, demonstrating the effectiveness of our framework.
\\ ( https://arxiv.org/abs/2306.06510 ,  1429kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06517
Date: Sat, 10 Jun 2023 20:07:06 GMT   (829kb,D)

Title: Probabilistic Multi-Dimensional Classification
Authors: Vu-Linh Nguyen, Yang Yang and Cassio de Campos
Categories: cs.LG
Comments: Accepted for the 39th Conference on Uncertainty in Artificial
 Intelligence (UAI 2023)
\\
 Multi-dimensional classification (MDC) can be employed in a range of
applications where one needs to predict multiple class variables for each given
instance. Many existing MDC methods suffer from at least one of inaccuracy,
scalability, limited use to certain types of data, hardness of interpretation
or lack of probabilistic (uncertainty) estimations. This paper is an attempt to
address all these disadvantages simultaneously. We propose a formal framework
for probabilistic MDC in which learning an optimal multi-dimensional classifier
can be decomposed, without loss of generality, into learning a set of (smaller)
single-variable multi-class probabilistic classifiers and a directed acyclic
graph. Current and future developments of both probabilistic classification and
graphical model learning can directly enhance our framework, which is flexible
and provably optimal. A collection of experiments is conducted to highlight the
usefulness of this MDC framework.
\\ ( https://arxiv.org/abs/2306.06517 ,  829kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06522
Date: Sat, 10 Jun 2023 21:17:42 GMT   (462kb,D)

Title: TS-MoCo: Time-Series Momentum Contrast for Self-Supervised Physiological
 Representation Learning
Authors: Philipp Hallgarten, David Bethge, Ozan \"Ozdenizci, Tobias
 Grosse-Puppendahl, Enkelejda Kasneci
Categories: cs.LG cs.HC eess.SP
Comments: 31ST EUROPEAN SIGNAL PROCESSING CONFERENCE (EUSIPCO)
\\
 Limited availability of labeled physiological data often prohibits the use of
powerful supervised deep learning models in the biomedical machine intelligence
domain. We approach this problem and propose a novel encoding framework that
relies on self-supervised learning with momentum contrast to learn
representations from multivariate time-series of various physiological domains
without needing labels. Our model uses a transformer architecture that can be
easily adapted to classification problems by optimizing a linear output
classification layer. We experimentally evaluate our framework using two
publicly available physiological datasets from different domains, i.e., human
activity recognition from embedded inertial sensory and emotion recognition
from electroencephalography. We show that our self-supervised learning approach
can indeed learn discriminative features which can be exploited in downstream
classification tasks. Our work enables the development of domain-agnostic
intelligent systems that can effectively analyze multivariate time-series data
from physiological domains.
\\ ( https://arxiv.org/abs/2306.06522 ,  462kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06523
Date: Sat, 10 Jun 2023 21:18:31 GMT   (43kb,D)

Title: Finding Hamiltonian cycles with graph neural networks
Authors: Filip Bosni\'c, Mile \v{S}iki\'c
Categories: cs.LG cs.SI
Comments: 6 pages, 5 figures
ACM-class: I.2.8
\\
 We train a small message-passing graph neural network to predict Hamiltonian
cycles on Erd\H{o}s-R\'enyi random graphs in a critical regime. It outperforms
existing hand-crafted heuristics after about 2.5 hours of training on a single
GPU. Our findings encourage an alternative approach to solving computationally
demanding (NP-hard) problems arising in practice. Instead of devising a
heuristic by hand, one can train it end-to-end using a neural network. This has
several advantages. Firstly, it is relatively quick and requires little
problem-specific knowledge. Secondly, the network can adjust to the
distribution of training samples, improving the performance on the most
relevant problem instances. The model is trained using supervised learning on
artificially created problem instances; this training procedure does not use an
existing solver to produce the supervised signal. Finally, the model
generalizes well to larger graph sizes and retains reasonable performance even
on graphs eight times the original size.
\\ ( https://arxiv.org/abs/2306.06523 ,  43kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06528
Date: Sat, 10 Jun 2023 21:53:39 GMT   (306kb,D)

Title: Pus$\mathbb{H}$: Concurrent Probabilistic Programming with Function
 Spaces
Authors: Daniel Huang, Christian Cama\~no, Jonathan Tsegaye
Categories: cs.LG cs.AI cs.PL
Comments: preprint
\\
 We introduce a prototype probabilistic programming language (PPL) called
Pus$\mathbb{H}$ for performing Bayesian inference on function spaces with a
focus on Bayesian deep learning (BDL). We describe the core abstraction of
Pus$\mathbb{H}$ based on particles that links models, specified as neural
networks (NNs), with inference, specified as procedures on particles using a
programming model inspired by message passing. Finally, we test Pus$\mathbb{H}$
on a variety of models and datasets used in scientific machine learning
(SciML), a domain with natural function space inference problems, and we
evaluate scaling of Pus$\mathbb{H}$ on single-node multi-GPU devices. Thus we
explore the combination of probabilistic programming, NNs, and concurrency in
the context of Bayesian inference on function spaces. The code can be found at
https://github.com/lbai-lab/PusH.
\\ ( https://arxiv.org/abs/2306.06528 ,  306kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06529
Date: Sat, 10 Jun 2023 21:55:28 GMT   (401kb,D)

Title: Neural Injective Functions for Multisets, Measures and Graphs via a
 Finite Witness Theorem
Authors: Tal Amir, Steven J. Gortler, Ilai Avni, Ravina Ravina, Nadav Dym
Categories: cs.LG
Comments: 33 pages
\\
 Injective multiset functions have a key role in the theoretical study of
machine learning on multisets and graphs. Yet, there remains a gap between the
provably injective multiset functions considered in theory, which typically
rely on polynomial moments, and the multiset functions used in practice which
typically rely on $\textit{neural moments}$, whose injectivity on multisets has
not been studied to date.
 In this paper we bridge this gap by showing that moments of neural network do
define an injective multiset function, provided that an analytic non-polynomial
activation is used. The number of moments required by our theory is optimal up
to a multiplicative factor of two. To prove this result, we state and prove a
$\textit{finite witness theorem}$, which is of independent interest.
 As a corollary to our main theorem, we derive new approximation results for
functions on multisets and measures, and new separation results for graph
neural networks. We also provide two negative results: We show that (1) moments
of piecewise-linear neural networks do not lead to injective multiset
functions, and (2) even when moment-based multiset functions are injective,
they will never be bi-Lipschitz.
\\ ( https://arxiv.org/abs/2306.06529 ,  401kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06534
Date: Sat, 10 Jun 2023 22:24:42 GMT   (134kb,D)

Title: K-Tensors: Clustering Positive Semi-Definite Matrices
Authors: Hanchao Zhang, Thaddeus Tarpey
Categories: cs.LG stat.ME
Comments: 10 pages, 2 figures
\\
 This paper introduces a novel self-consistency clustering algorithm
(K-Tensors) designed for positive-semidefinite matrices based on their
eigenstructures. As positive semi-definite matrices can be represented as
ellipses or ellipsoids in $\Re^p$, $p \ge 2$, it is critical to maintain their
structural information to perform effective clustering. However, traditional
clustering algorithms often vectorize the matrices, resulting in a loss of
essential structural information. To address this issue, we propose a distance
metric that is specifically based on the structural information of positive
semi-definite matrices. This distance metric enables the clustering algorithm
to consider the differences between positive semi-definite matrices and their
projection onto the common space spanned by a set of positive semi-definite
matrices. This innovative approach to clustering positive semi-definite
matrices has broad applications in several domains, including financial and
biomedical research, such as analyzing functional connectivity data. By
maintaining the structural information of positive semi-definite matrices, our
proposed algorithm promises to cluster the positive semi-definite matrices in a
more meaningful way, thereby facilitating deeper insights into the underlying
data in various applications.
\\ ( https://arxiv.org/abs/2306.06534 ,  134kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06545
Date: Sun, 11 Jun 2023 00:06:57 GMT   (476kb,D)

Title: A Probabilistic Framework for Modular Continual Learning
Authors: Lazar Valkov, Akash Srivastava, Swarat Chaudhuri, Charles Sutton
Categories: cs.LG stat.ML
\\
 Modular approaches, which use a different composition of modules for each
problem and avoid forgetting by design, have been shown to be a promising
direction in continual learning (CL). However, searching through the large,
discrete space of possible module compositions is a challenge because
evaluating a composition's performance requires a round of neural network
training. To address this challenge, we develop a modular CL framework, called
PICLE, that accelerates search by using a probabilistic model to cheaply
compute the fitness of each composition. The model combines prior knowledge
about good module compositions with dataset-specific information. Its use is
complemented by splitting up the search space into subsets, such as perceptual
and latent subsets. We show that PICLE is the first modular CL algorithm to
achieve different types of transfer while scaling to large search spaces. We
evaluate it on two benchmark suites designed to capture different desiderata of
CL techniques. On these benchmarks, PICLE offers significantly better
performance than state-of-the-art CL baselines.
\\ ( https://arxiv.org/abs/2306.06545 ,  476kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06547
Date: Sun, 11 Jun 2023 00:22:44 GMT   (6231kb,D)

Title: Local-to-global Perspectives on Graph Neural Networks
Authors: Chen Cai
Categories: cs.LG stat.ML
Comments: arXiv admin note: substantial text overlap with arXiv:2201.10129,
 arXiv:2301.11956, arXiv:2102.01350
\\
 We present a local-to-global perspective on graph neural networks (GNN),
which are categorized as local Message Passing Neural Networks (MPNN) and
global Graph Transformer. We present three pieces of work: 1) study the
convergence property of a type of global GNN, Invariant Graph Networks, 2)
connect the local MPNN and global Graph Transformer, and 3) use local MPNN for
graph coarsening, a common subroutine used in global modeling.
\\ ( https://arxiv.org/abs/2306.06547 ,  6231kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06559
Date: Sun, 11 Jun 2023 02:08:59 GMT   (1581kb,D)

Title: Straggler-Resilient Decentralized Learning via Adaptive Asynchronous
 Updates
Authors: Guojun Xiong, Gang Yan, Shiqiang Wang, Jian Li
Categories: cs.LG cs.DC
Comments: 32 pages
\\
 With the increasing demand for large-scale training of machine learning
models, fully decentralized optimization methods have recently been advocated
as alternatives to the popular parameter server framework. In this paradigm,
each worker maintains a local estimate of the optimal parameter vector, and
iteratively updates it by waiting and averaging all estimates obtained from its
neighbors, and then corrects it on the basis of its local dataset. However, the
synchronization phase is sensitive to stragglers. An efficient way to mitigate
this effect is to consider asynchronous updates, where each worker computes
stochastic gradients and communicates with other workers at its own pace.
Unfortunately, fully asynchronous updates suffer from staleness of the
stragglers' parameters. To address these limitations, we propose a fully
decentralized algorithm DSGD-AAU with adaptive asynchronous updates via
adaptively determining the number of neighbor workers for each worker to
communicate with. We show that DSGD-AAU achieves a linear speedup for
convergence (i.e., convergence performance increases linearly with respect to
the number of workers). Experimental results on a suite of datasets and deep
neural network models are provided to verify our theoretical results.
\\ ( https://arxiv.org/abs/2306.06559 ,  1581kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06561
Date: Sun, 11 Jun 2023 02:25:15 GMT   (12490kb,D)

Title: Learning World Models with Identifiable Factorization
Authors: Yu-Ren Liu, Biwei Huang, Zhengmao Zhu, Honglong Tian, Mingming Gong,
 Yang Yu, Kun Zhang
Categories: cs.LG
\\
 Extracting a stable and compact representation of the environment is crucial
for efficient reinforcement learning in high-dimensional, noisy, and
non-stationary environments. Different categories of information coexist in
such environments -- how to effectively extract and disentangle these
information remains a challenging problem. In this paper, we propose IFactor, a
general framework to model four distinct categories of latent state variables
that capture various aspects of information within the RL system, based on
their interactions with actions and rewards. Our analysis establishes
block-wise identifiability of these latent variables, which not only provides a
stable and compact representation but also discloses that all reward-relevant
factors are significant for policy learning. We further present a practical
approach to learning the world model with identifiable blocks, ensuring the
removal of redundants but retaining minimal and sufficient information for
policy optimization. Experiments in synthetic worlds demonstrate that our
method accurately identifies the ground-truth latent variables, substantiating
our theoretical findings. Moreover, experiments in variants of the DeepMind
Control Suite and RoboDesk showcase the superior performance of our approach
over baselines.
\\ ( https://arxiv.org/abs/2306.06561 ,  12490kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06563
Date: Sun, 11 Jun 2023 02:46:41 GMT   (620kb,D)

Title: Provably Efficient Adversarial Imitation Learning with Unknown
 Transitions
Authors: Tian Xu, Ziniu Li, Yang Yu, Zhi-Quan Luo
Categories: cs.LG
\\
 Imitation learning (IL) has proven to be an effective method for learning
good policies from expert demonstrations. Adversarial imitation learning (AIL),
a subset of IL methods, is particularly promising, but its theoretical
foundation in the presence of unknown transitions has yet to be fully
developed. This paper explores the theoretical underpinnings of AIL in this
context, where the stochastic and uncertain nature of environment transitions
presents a challenge. We examine the expert sample complexity and interaction
complexity required to recover good policies. To this end, we establish a
framework connecting reward-free exploration and AIL, and propose an algorithm,
MB-TAIL, that achieves the minimax optimal expert sample complexity of
$\widetilde{O} (H^{3/2} |S|/\varepsilon)$ and interaction complexity of
$\widetilde{O} (H^{3} |S|^2 |A|/\varepsilon^2)$. Here, $H$ represents the
planning horizon, $|S|$ is the state space size, $|A|$ is the action space
size, and $\varepsilon$ is the desired imitation gap. MB-TAIL is the first
algorithm to achieve this level of expert sample complexity in the unknown
transition setting and improves upon the interaction complexity of the
best-known algorithm, OAL, by $O(H)$. Additionally, we demonstrate the
generalization ability of MB-TAIL by extending it to the function approximation
setting and proving that it can achieve expert sample and interaction
complexity independent of $|S|$
\\ ( https://arxiv.org/abs/2306.06563 ,  620kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06569
Date: Sun, 11 Jun 2023 03:02:10 GMT   (1058kb,D)

Title: Policy Regularization with Dataset Constraint for Offline Reinforcement
 Learning
Authors: Yuhang Ran, Yi-Chen Li, Fuxiang Zhang, Zongzhang Zhang, Yang Yu
Categories: cs.LG cs.AI
Comments: Accepted to ICML 2023
\\
 We consider the problem of learning the best possible policy from a fixed
dataset, known as offline Reinforcement Learning (RL). A common taxonomy of
existing offline RL works is policy regularization, which typically constrains
the learned policy by distribution or support of the behavior policy. However,
distribution and support constraints are overly conservative since they both
force the policy to choose similar actions as the behavior policy when
considering particular states. It will limit the learned policy's performance,
especially when the behavior policy is sub-optimal. In this paper, we find that
regularizing the policy towards the nearest state-action pair can be more
effective and thus propose Policy Regularization with Dataset Constraint
(PRDC). When updating the policy in a given state, PRDC searches the entire
dataset for the nearest state-action sample and then restricts the policy with
the action of this sample. Unlike previous works, PRDC can guide the policy
with proper behaviors from the dataset, allowing it to choose actions that do
not appear in the dataset along with the given state. It is a softer constraint
but still keeps enough conservatism from out-of-distribution actions. Empirical
evidence and theoretical analysis show that PRDC can alleviate offline RL's
fundamentally challenging value overestimation issue with a bounded performance
gap. Moreover, on a set of locomotion and navigation tasks, PRDC achieves
state-of-the-art performance compared with existing methods. Code is available
at https://github.com/LAMDA-RL/PRDC
\\ ( https://arxiv.org/abs/2306.06569 ,  1058kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06579
Date: Sun, 11 Jun 2023 04:00:11 GMT   (16818kb,D)

Title: Learning Robust and Consistent Time Series Representations: A Dilated
 Inception-Based Approach
Authors: Anh Duy Nguyen, Trang H. Tran, Hieu H. Pham, Phi Le Nguyen, Lam M.
 Nguyen
Categories: cs.LG
\\
 Representation learning for time series has been an important research area
for decades. Since the emergence of the foundation models, this topic has
attracted a lot of attention in contrastive self-supervised learning, to solve
a wide range of downstream tasks. However, there have been several challenges
for contrastive time series processing. First, there is no work considering
noise, which is one of the critical factors affecting the efficacy of time
series tasks. Second, there is a lack of efficient yet lightweight encoder
architectures that can learn informative representations robust to various
downstream tasks. To fill in these gaps, we initiate a novel sampling strategy
that promotes consistent representation learning with the presence of noise in
natural time series. In addition, we propose an encoder architecture that
utilizes dilated convolution within the Inception block to create a scalable
and robust network architecture with a wide receptive field. Experiments
demonstrate that our method consistently outperforms state-of-the-art methods
in forecasting, classification, and abnormality detection tasks, e.g. ranks
first over two-thirds of the classification UCR datasets, with only $40\%$ of
the parameters compared to the second-best approach. Our source code for
CoInception framework is accessible at
https://github.com/anhduy0911/CoInception.
\\ ( https://arxiv.org/abs/2306.06579 ,  16818kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06591
Date: Sun, 11 Jun 2023 04:58:47 GMT   (513kb,D)

Title: Blocked Cross-Validation: A Precise and Efficient Method for
 Hyperparameter Tuning
Authors: Giovanni Maria Merola
Categories: cs.LG stat.ME
Comments: 28 pages, 7 figures
MSC-class: 62-00
ACM-class: G.3
\\
 Hyperparameter tuning plays a crucial role in optimizing the performance of
predictive learners. Cross--validation (CV) is a widely adopted technique for
estimating the error of different hyperparameter settings. Repeated
cross-validation (RCV) has been commonly employed to reduce the variability of
CV errors. In this paper, we introduce a novel approach called blocked
cross-validation (BCV), where the repetitions are blocked with respect to both
CV partition and the random behavior of the learner. Theoretical analysis and
empirical experiments demonstrate that BCV provides more precise error
estimates compared to RCV, even with a significantly reduced number of runs. We
present extensive examples using real--world data sets to showcase the
effectiveness and efficiency of BCV in hyperparameter tuning. Our results
indicate that BCV outperforms RCV in hyperparameter tuning, achieving greater
precision with fewer computations.
\\ ( https://arxiv.org/abs/2306.06591 ,  513kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06599
Date: Sun, 11 Jun 2023 06:27:06 GMT   (145kb,D)

Title: Variational Imbalanced Regression
Authors: Ziyan Wang, Hao Wang
Categories: cs.LG stat.ML
\\
 Existing regression models tend to fall short in both accuracy and
uncertainty estimation when the label distribution is imbalanced. In this
paper, we propose a probabilistic deep learning model, dubbed variational
imbalanced regression (VIR), which not only performs well in imbalanced
regression but naturally produces reasonable uncertainty estimation as a
byproduct. Different from typical variational autoencoders assuming I.I.D.
representations (a data point's representation is not directly affected by
other data points), our VIR borrows data with similar regression labels to
compute the latent representation's variational distribution; furthermore,
different from deterministic regression models producing point estimates, VIR
predicts the entire normal-inverse-gamma distributions and modulates the
associated conjugate distributions to impose probabilistic reweighting on the
imbalanced data, thereby providing better uncertainty estimation. Experiments
in several real-world datasets show that our VIR can outperform
state-of-the-art imbalanced regression models in terms of both accuracy and
uncertainty estimation.
\\ ( https://arxiv.org/abs/2306.06599 ,  145kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06611
Date: Sun, 11 Jun 2023 07:28:35 GMT   (181kb,D)

Title: Learning the Positions in CountSketch
Authors: Yi Li, Honghao Lin, Simin Liu, Ali Vakilian, David P. Woodruff
Categories: cs.LG cs.DS
Comments: Merging of arXiv:2007.09890 and arXiv:2102.12317 with additional
 results. Published as a conference paper at ICLR 2023
\\
 We consider sketching algorithms which first compress data by multiplication
with a random sketch matrix, and then apply the sketch to quickly solve an
optimization problem, e.g., low-rank approximation and regression. In the
learning-based sketching paradigm proposed by~\cite{indyk2019learning}, the
sketch matrix is found by choosing a random sparse matrix, e.g., CountSketch,
and then the values of its non-zero entries are updated by running gradient
descent on a training data set. Despite the growing body of work on this
paradigm, a noticeable omission is that the locations of the non-zero entries
of previous algorithms were fixed, and only their values were learned. In this
work, we propose the first learning-based algorithms that also optimize the
locations of the non-zero entries. Our first proposed algorithm is based on a
greedy algorithm. However, one drawback of the greedy algorithm is its slower
training time. We fix this issue and propose approaches for learning a
sketching matrix for both low-rank approximation and Hessian approximation for
second order optimization. The latter is helpful for a range of constrained
optimization problems, such as LASSO and matrix estimation with a nuclear norm
constraint. Both approaches achieve good accuracy with a fast running time.
Moreover, our experiments suggest that our algorithm can still reduce the error
significantly even if we only have a very limited number of training matrices.
\\ ( https://arxiv.org/abs/2306.06611 ,  181kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06613
Date: Sun, 11 Jun 2023 07:46:22 GMT   (12kb)

Title: Parameter-free version of Adaptive Gradient Methods for Strongly-Convex
 Functions
Authors: Deepak Gouda, Hassan Naveed, Salil Kamath
Categories: cs.LG math.OC
\\
 The optimal learning rate for adaptive gradient methods applied to
{\lambda}-strongly convex functions relies on the parameters {\lambda} and
learning rate {\eta}. In this paper, we adapt a universal algorithm along the
lines of Metagrad, to get rid of this dependence on {\lambda} and {\eta}. The
main idea is to concurrently run multiple experts and combine their predictions
to a master algorithm. This master enjoys O(d log T) regret bounds.
\\ ( https://arxiv.org/abs/2306.06613 ,  12kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06626
Date: Sun, 11 Jun 2023 08:54:12 GMT   (6649kb,D)

Title: On Kinetic Optimal Probability Paths for Generative Models
Authors: Neta Shaul, Ricky T. Q. Chen, Maximilian Nickel, Matt Le, Yaron Lipman
Categories: cs.LG stat.ML
\\
 Recent successful generative models are trained by fitting a neural network
to an a-priori defined tractable probability density path taking noise to
training examples. In this paper we investigate the space of Gaussian
probability paths, which includes diffusion paths as an instance, and look for
an optimal member in some useful sense. In particular, minimizing the Kinetic
Energy (KE) of a path is known to make particles' trajectories simple, hence
easier to sample, and empirically improve performance in terms of likelihood of
unseen data and sample generation quality. We investigate Kinetic Optimal (KO)
Gaussian paths and offer the following observations: (i) We show the KE takes a
simplified form on the space of Gaussian paths, where the data is incorporated
only through a single, one dimensional scalar function, called the \emph{data
separation function}. (ii) We characterize the KO solutions with a one
dimensional ODE. (iii) We approximate data-dependent KO paths by approximating
the data separation function and minimizing the KE. (iv) We prove that the data
separation function converges to $1$ in the general case of arbitrary
normalized dataset consisting of $n$ samples in $d$ dimension as
$n/\sqrt{d}\rightarrow 0$. A consequence of this result is that the Conditional
Optimal Transport (Cond-OT) path becomes \emph{kinetic optimal} as
$n/\sqrt{d}\rightarrow 0$. We further support this theory with empirical
experiments on ImageNet.
\\ ( https://arxiv.org/abs/2306.06626 ,  6649kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06637
Date: Sun, 11 Jun 2023 09:45:31 GMT   (1034kb,D)

Title: PACER: A Fully Push-forward-based Distributional Reinforcement Learning
 Algorithm
Authors: Wensong Bai, Chao Zhang, Yichao Fu, Lingwei Peng, Hui Qian, Bin Dai
Categories: cs.LG
\\
 In this paper, we propose the first fully push-forward-based Distributional
Reinforcement Learning algorithm, called Push-forward-based Actor-Critic
EncourageR (PACER). Specifically, PACER establishes a stochastic utility value
policy gradient theorem and simultaneously leverages the push-forward operator
in the construction of both the actor and the critic. Moreover, based on
maximum mean discrepancies (MMD), a novel sample-based encourager is designed
to incentivize exploration. Experimental evaluations on various continuous
control benchmarks demonstrate the superiority of our algorithm over the
state-of-the-art.
\\ ( https://arxiv.org/abs/2306.06637 ,  1034kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06642
Date: Sun, 11 Jun 2023 10:32:44 GMT   (866kb,D)

Title: Well-Calibrated Probabilistic Predictive Maintenance using Venn-Abers
Authors: Ulf Johansson, Tuwe L\"ofstr\"om, and Cecilia S\"onstr\"od
Categories: cs.LG cs.AI
\\
 When using machine learning for fault detection, a common problem is the fact
that most data sets are very unbalanced, with the minority class (a fault)
being the interesting one. In this paper, we investigate the usage of
Venn-Abers predictors, looking specifically at the effect on the minority class
predictions. A key property of Venn-Abers predictors is that they output
well-calibrated probability intervals. In the experiments, we apply Venn-Abers
calibration to decision trees, random forests and XGBoost models, showing how
both overconfident and underconfident models are corrected. In addition, the
benefit of using the valid probability intervals produced by Venn-Abers for
decision support is demonstrated. When using techniques producing opaque
underlying models, e.g., random forest and XGBoost, each prediction will
consist of not only the label, but also a valid probability interval, where the
width is an indication of the confidence in the estimate. Adding Venn-Abers on
top of a decision tree allows inspection and analysis of the model, to
understand both the underlying relationship, and finding out in which parts of
feature space that the model is accurate and/or confident.
\\ ( https://arxiv.org/abs/2306.06642 ,  866kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06712
Date: Sun, 11 Jun 2023 16:02:14 GMT   (1751kb,D)

Title: Neural Architecture Design and Robustness: A Dataset
Authors: Steffen Jung, Jovita Lukasik, Margret Keuper
Categories: cs.LG cs.CV
Comments: ICLR 2023; project page: http://robustness.vision/
\\
 Deep learning models have proven to be successful in a wide range of machine
learning tasks. Yet, they are often highly sensitive to perturbations on the
input data which can lead to incorrect decisions with high confidence,
hampering their deployment for practical use-cases. Thus, finding architectures
that are (more) robust against perturbations has received much attention in
recent years. Just like the search for well-performing architectures in terms
of clean accuracy, this usually involves a tedious trial-and-error process with
one additional challenge: the evaluation of a network's robustness is
significantly more expensive than its evaluation for clean accuracy. Thus, the
aim of this paper is to facilitate better streamlined research on architectural
design choices with respect to their impact on robustness as well as, for
example, the evaluation of surrogate measures for robustness. We therefore
borrow one of the most commonly considered search spaces for neural
architecture search for image classification, NAS-Bench-201, which contains a
manageable size of 6466 non-isomorphic network designs. We evaluate all these
networks on a range of common adversarial attacks and corruption types and
introduce a database on neural architecture design and robustness evaluations.
We further present three exemplary use cases of this dataset, in which we (i)
benchmark robustness measurements based on Jacobian and Hessian matrices for
their robustness predictability, (ii) perform neural architecture search on
robust accuracies, and (iii) provide an initial analysis of how architectural
design choices affect robustness. We find that carefully crafting the topology
of a network can have substantial impact on its robustness, where networks with
the same parameter count range in mean adversarial robust accuracy from
20%-41%. Code and data is available at http://robustness.vision/.
\\ ( https://arxiv.org/abs/2306.06712 ,  1751kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06715
Date: Sun, 11 Jun 2023 16:30:57 GMT   (251kb,D)

Title: FedDec: Peer-to-peer Aided Federated Learning
Authors: Marina Costantini, Giovanni Neglia, and Thrasyvoulos Spyropoulos
Categories: cs.LG math.OC
Comments: 14 pages, 6 figures in png or pdf format
\\
 Federated learning (FL) has enabled training machine learning models
exploiting the data of multiple agents without compromising privacy. However,
FL is known to be vulnerable to data heterogeneity, partial device
participation, and infrequent communication with the server, which are
nonetheless three distinctive characteristics of this framework. While much of
the recent literature has tackled these weaknesses using different tools, only
a few works have explored the possibility of exploiting inter-agent
communication to improve FL's performance. In this work, we present FedDec, an
algorithm that interleaves peer-to-peer communication and parameter averaging
(similar to decentralized learning in networks) between the local gradient
updates of FL. We analyze the convergence of FedDec under the assumptions of
non-iid data distribution, partial device participation, and smooth and
strongly convex costs, and show that inter-agent communication alleviates the
negative impact of infrequent communication rounds with the server by reducing
the dependence on the number of local updates $H$ from $O(H^2)$ to $O(H)$.
Furthermore, our analysis reveals that the term improved in the bound is
multiplied by a constant that depends on the spectrum of the inter-agent
communication graph, and that vanishes quickly the more connected the network
is. We confirm the predictions of our theory in numerical simulations, where we
show that FedDec converges faster than FedAvg, and that the gains are greater
as either $H$ or the connectivity of the network increase.
\\ ( https://arxiv.org/abs/2306.06715 ,  251kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06716
Date: Sun, 11 Jun 2023 16:34:19 GMT   (6226kb,D)

Title: On Minimizing the Impact of Dataset Shifts on Actionable Explanations
Authors: Anna P. Meyer, Dan Ley, Suraj Srinivas, Himabindu Lakkaraju
Categories: cs.LG
Comments: 30 pages, 19 figures. To be published at UAI 2023
\\
 The Right to Explanation is an important regulatory principle that allows
individuals to request actionable explanations for algorithmic decisions.
However, several technical challenges arise when providing such actionable
explanations in practice. For instance, models are periodically retrained to
handle dataset shifts. This process may invalidate some of the previously
prescribed explanations, thus rendering them unactionable. But, it is unclear
if and when such invalidations occur, and what factors determine explanation
stability i.e., if an explanation remains unchanged amidst model retraining due
to dataset shifts. In this paper, we address the aforementioned gaps and
provide one of the first theoretical and empirical characterizations of the
factors influencing explanation stability. To this end, we conduct rigorous
theoretical analysis to demonstrate that model curvature, weight decay
parameters while training, and the magnitude of the dataset shift are key
factors that determine the extent of explanation (in)stability. Extensive
experimentation with real-world datasets not only validates our theoretical
results, but also demonstrates that the aforementioned factors dramatically
impact the stability of explanations produced by various state-of-the-art
methods.
\\ ( https://arxiv.org/abs/2306.06716 ,  6226kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06731
Date: Sun, 11 Jun 2023 17:45:46 GMT   (600kb,D)

Title: An information-Theoretic Approach to Semi-supervised Transfer Learning
Authors: Daniel Jakubovitz, David Uliel, Miguel Rodrigues, Raja Giryes
Categories: cs.LG
Comments: arXiv admin note: substantial text overlap with arXiv:1904.01670
\\
 Transfer learning is a valuable tool in deep learning as it allows
propagating information from one "source dataset" to another "target dataset",
especially in the case of a small number of training examples in the latter.
Yet, discrepancies between the underlying distributions of the source and
target data are commonplace and are known to have a substantial impact on
algorithm performance. In this work we suggest novel information-theoretic
approaches for the analysis of the performance of deep neural networks in the
context of transfer learning. We focus on the task of semi-supervised transfer
learning, in which unlabeled samples from the target dataset are available
during network training on the source dataset. Our theory suggests that one may
improve the transferability of a deep neural network by incorporating
regularization terms on the target data based on information-theoretic
quantities, namely the Mutual Information and the Lautum Information. We
demonstrate the effectiveness of the proposed approaches in various
semi-supervised transfer learning experiments.
\\ ( https://arxiv.org/abs/2306.06731 ,  600kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06772
Date: Sun, 11 Jun 2023 20:56:21 GMT   (61kb,D)

Title: Between-Sample Relationship in Learning Tabular Data Using Graph and
 Attention Networks
Authors: Shourav B. Rabbani and Manar D. Samad
Categories: cs.LG cs.AI
Comments: Accepted to the 19th Int. Conf. on Data Science, Las Vegas, NV
\\
 Traditional machine learning assumes samples in tabular data to be
independent and identically distributed (i.i.d). This assumption may miss
useful information within and between sample relationships in representation
learning. This paper relaxes the i.i.d assumption to learn tabular data
representations by incorporating between-sample relationships for the first
time using graph neural networks (GNN). We investigate our hypothesis using
several GNNs and state-of-the-art (SOTA) deep attention models to learn the
between-sample relationship on ten tabular data sets by comparing them to
traditional machine learning methods. GNN methods show the best performance on
tabular data with large feature-to-sample ratios. Our results reveal that
attention-based GNN methods outperform traditional machine learning on five
data sets and SOTA deep tabular learning methods on three data sets.
Between-sample learning via GNN and deep attention methods yield the best
classification accuracy on seven of the ten data sets. This suggests that the
i.i.d assumption may not always hold for most tabular data sets.
\\ ( https://arxiv.org/abs/2306.06772 ,  61kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06777
Date: Sun, 11 Jun 2023 21:14:29 GMT   (619kb,D)

Title: Improving the Validitity of Decision Trees as Explanations
Authors: Jiri Nemecek and Tomas Pevny and Jakub Marecek
Categories: cs.LG cs.AI math.OC
\\
 In classification and forecasting with tabular data, one often utilizes
tree-based models. This can be competitive with deep neural networks on tabular
data [cf. Grinsztajn et al., NeurIPS 2022, arXiv:2207.08815] and, under some
conditions, explainable. The explainability depends on the depth of the tree
and the accuracy in each leaf of the tree. Here, we train a low-depth tree with
the objective of minimising the maximum misclassification error across each
leaf node, and then ``suspend'' further tree-based models (e.g., trees of
unlimited depth) from each leaf of the low-depth tree. The low-depth tree is
easily explainable, while the overall statistical performance of the combined
low-depth and suspended tree-based models improves upon decision trees of
unlimited depth trained using classical methods (e.g., CART) and is comparable
to state-of-the-art methods (e.g., well-tuned XGBoost).
\\ ( https://arxiv.org/abs/2306.06777 ,  619kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06778
Date: Sun, 11 Jun 2023 21:18:40 GMT   (250kb,D)

Title: Approximation Algorithms for Fair Range Clustering
Authors: S\`edjro S. Hotegni and Sepideh Mahabadi and Ali Vakilian
Categories: cs.LG cs.AI cs.DS
Comments: ICML 2023
\\
 This paper studies the fair range clustering problem in which the data points
are from different demographic groups and the goal is to pick $k$ centers with
the minimum clustering cost such that each group is at least minimally
represented in the centers set and no group dominates the centers set. More
precisely, given a set of $n$ points in a metric space $(P,d)$ where each point
belongs to one of the $\ell$ different demographics (i.e., $P = P_1 \uplus P_2
\uplus \cdots \uplus P_\ell$) and a set of $\ell$ intervals $[\alpha_1,
\beta_1], \cdots, [\alpha_\ell, \beta_\ell]$ on desired number of centers from
each group, the goal is to pick a set of $k$ centers $C$ with minimum
$\ell_p$-clustering cost (i.e., $(\sum_{v\in P} d(v,C)^p)^{1/p}$) such that for
each group $i\in \ell$, $|C\cap P_i| \in [\alpha_i, \beta_i]$. In particular,
the fair range $\ell_p$-clustering captures fair range $k$-center, $k$-median
and $k$-means as its special cases. In this work, we provide an
$O(1)$-approximation algorithm for the fair range $\ell_p$-clustering that
picks at most $k+2\ell$ centers and may only violate the upper bound of each
demographic group by at most an additive term of $2$.
\\ ( https://arxiv.org/abs/2306.06778 ,  250kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06788
Date: Sun, 11 Jun 2023 22:04:28 GMT   (1372kb,D)

Title: Graph Mixup with Soft Alignments
Authors: Hongyi Ling, Zhimeng Jiang, Meng Liu, Shuiwang Ji, Na Zou
Categories: cs.LG cs.AI
\\
 We study graph data augmentation by mixup, which has been used successfully
on images. A key operation of mixup is to compute a convex combination of a
pair of inputs. This operation is straightforward for grid-like data, such as
images, but challenging for graph data. The key difficulty lies in the fact
that different graphs typically have different numbers of nodes, and thus there
lacks a node-level correspondence between graphs. In this work, we propose
S-Mixup, a simple yet effective mixup method for graph classification by soft
alignments. Specifically, given a pair of graphs, we explicitly obtain
node-level correspondence via computing a soft assignment matrix to match the
nodes between two graphs. Based on the soft assignments, we transform the
adjacency and node feature matrices of one graph, so that the transformed graph
is aligned with the other graph. In this way, any pair of graphs can be mixed
directly to generate an augmented graph. We conduct systematic experiments to
show that S-Mixup can improve the performance and generalization of graph
neural networks (GNNs) on various graph classification tasks. In addition, we
show that S-Mixup can increase the robustness of GNNs against noisy labels.
\\ ( https://arxiv.org/abs/2306.06788 ,  1372kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06801
Date: Sun, 11 Jun 2023 22:56:59 GMT   (10890kb,D)

Title: CARNA: Characterizing Advanced heart failure Risk and hemodyNAmic
 phenotypes using learned multi-valued decision diagrams
Authors: Josephine Lamp, Yuxin Wu, Steven Lamp, Prince Afriyie, Kenneth
 Bilchick, Lu Feng, Sula Mazimba
Categories: cs.LG
\\
 Early identification of high risk heart failure (HF) patients is key to
timely allocation of life-saving therapies. Hemodynamic assessments can
facilitate risk stratification and enhance understanding of HF trajectories.
However, risk assessment for HF is a complex, multi-faceted decision-making
process that can be challenging. Previous risk models for HF do not integrate
invasive hemodynamics or support missing data, and use statistical methods
prone to bias or machine learning methods that are not interpretable. To
address these limitations, this paper presents CARNA, a hemodynamic risk
stratification and phenotyping framework for advanced HF that takes advantage
of the explainability and expressivity of machine learned Multi-Valued Decision
Diagrams (MVDDs). This interpretable framework learns risk scores that predict
the probability of patient outcomes, and outputs descriptive patient phenotypes
(sets of features and thresholds) that characterize each predicted risk score.
CARNA incorporates invasive hemodynamics and can make predictions on missing
data. The CARNA models were trained and validated using a total of five
advanced HF patient cohorts collected from previous trials, and compared with
six established HF risk scores and three traditional ML risk models. CARNA
provides robust risk stratification, outperforming all previous benchmarks.
Although focused on advanced HF, the CARNA framework is general purpose and can
be used to learn risk stratifications for other diseases and medical
applications.
\\ ( https://arxiv.org/abs/2306.06801 ,  10890kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06836
Date: Mon, 12 Jun 2023 02:56:09 GMT   (73kb)

Title: Tackling Heavy-Tailed Rewards in Reinforcement Learning with Function
 Approximation: Minimax Optimal and Instance-Dependent Regret Bounds
Authors: Jiayi Huang, Han Zhong, Liwei Wang, Lin F. Yang
Categories: cs.LG cs.AI stat.ML
\\
 While numerous works have focused on devising efficient algorithms for
reinforcement learning (RL) with uniformly bounded rewards, it remains an open
question whether sample or time-efficient algorithms for RL with large
state-action space exist when the rewards are \emph{heavy-tailed}, i.e., with
only finite $(1+\epsilon)$-th moments for some $\epsilon\in(0,1]$. In this
work, we address the challenge of such rewards in RL with linear function
approximation. We first design an algorithm, \textsc{Heavy-OFUL}, for
heavy-tailed linear bandits, achieving an \emph{instance-dependent} $T$-round
regret of $\tilde{O}\big(d T^{\frac{1-\epsilon}{2(1+\epsilon)}}
\sqrt{\sum_{t=1}^T \nu_t^2} + d T^{\frac{1-\epsilon}{2(1+\epsilon)}}\big)$, the
\emph{first} of this kind. Here, $d$ is the feature dimension, and
$\nu_t^{1+\epsilon}$ is the $(1+\epsilon)$-th central moment of the reward at
the $t$-th round. We further show the above bound is minimax optimal when
applied to the worst-case instances in stochastic and deterministic linear
bandits. We then extend this algorithm to the RL settings with linear function
approximation. Our algorithm, termed as \textsc{Heavy-LSVI-UCB}, achieves the
\emph{first} computationally efficient \emph{instance-dependent} $K$-episode
regret of $\tilde{O}(d \sqrt{H \mathcal{U}^*} K^\frac{1}{1+\epsilon} + d
\sqrt{H \mathcal{V}^* K})$. Here, $H$ is length of the episode, and
$\mathcal{U}^*, \mathcal{V}^*$ are instance-dependent quantities scaling with
the central moment of reward and value functions, respectively. We also provide
a matching minimax lower bound $\Omega(d H K^{\frac{1}{1+\epsilon}} + d
\sqrt{H^3 K})$ to demonstrate the optimality of our algorithm in the worst
case. Our result is achieved via a novel robust self-normalized concentration
inequality that may be of independent interest in handling heavy-tailed noise
in general online regression problems.
\\ ( https://arxiv.org/abs/2306.06836 ,  73kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06849
Date: Mon, 12 Jun 2023 03:47:43 GMT   (863kb,D)

Title: Mitigating Transformer Overconfidence via Lipschitz Regularization
Authors: Wenqian Ye, Yunsheng Ma, Xu Cao, Kun Tang
Categories: cs.LG cs.CV
\\
 Though Transformers have achieved promising results in many computer vision
tasks, they tend to be over-confident in predictions, as the standard Dot
Product Self-Attention (DPSA) can barely preserve distance for the unbounded
input domain. In this work, we fill this gap by proposing a novel Lipschitz
Regularized Transformer (LRFormer). Specifically, we present a new similarity
function with the distance within Banach Space to ensure the Lipschitzness and
also regularize the term by a contractive Lipschitz Bound. The proposed method
is analyzed with a theoretical guarantee, providing a rigorous basis for its
effectiveness and reliability. Extensive experiments conducted on standard
vision benchmarks demonstrate that our method outperforms the state-of-the-art
single forward pass approaches in prediction, calibration, and uncertainty
estimation.
\\ ( https://arxiv.org/abs/2306.06849 ,  863kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06852
Date: Mon, 12 Jun 2023 03:56:09 GMT   (2147kb,D)

Title: Rethink DARTS Search Space and Renovate a New Benchmark
Authors: Jiuling Zhang, Zhiming Ding
Categories: cs.LG
Comments: Accepted by ICML 2023
\\
 DARTS search space (DSS) has become a canonical benchmark for NAS whereas
some emerging works pointed out the issue of narrow accuracy range and claimed
it would hurt the method ranking. We observe some recent studies already suffer
from this issue that overshadows the meaning of scores. In this work, we first
propose and orchestrate a suite of improvements to frame a larger and harder
DSS, termed LHD, while retaining high efficiency in search. We step forward to
renovate a LHD-based new benchmark, taking care of both discernibility and
accessibility. Specifically, we re-implement twelve baselines and evaluate them
across twelve conditions by combining two underexpolored influential factors:
transductive robustness and discretization policy, to reasonably construct a
benchmark upon multi-condition evaluation. Considering that the tabular
benchmarks are always insufficient to adequately evaluate the methods of neural
architecture search (NAS), our work can serve as a crucial basis for the future
progress of NAS. https://github.com/chaoji90/LHD
\\ ( https://arxiv.org/abs/2306.06852 ,  2147kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06855
Date: Mon, 12 Jun 2023 04:01:57 GMT   (510kb,D)

Title: Small Temperature is All You Need for Differentiable Architecture Search
Authors: Jiuling Zhang, Zhiming Ding
Categories: cs.LG
Comments: Accepted for PAKDD 2023
\\
 Differentiable architecture search (DARTS) yields highly efficient
gradient-based neural architecture search (NAS) by relaxing the discrete
operation selection to optimize continuous architecture parameters that maps
NAS from the discrete optimization to a continuous problem. DARTS then remaps
the relaxed supernet back to the discrete space by one-off post-search pruning
to obtain the final architecture (finalnet). Some emerging works argue that
this remap is inherently prone to mismatch the network between training and
evaluation which leads to performance discrepancy and even model collapse in
extreme cases. We propose to close the gap between the relaxed supernet in
training and the pruned finalnet in evaluation through utilizing small
temperature to sparsify the continuous distribution in the training phase. To
this end, we first formulate sparse-noisy softmax to get around gradient
saturation. We then propose an exponential temperature schedule to better
control the outbound distribution and elaborate an entropy-based adaptive
scheme to finally achieve the enhancement. We conduct extensive experiments to
verify the efficiency and efficacy of our method.
\\ ( https://arxiv.org/abs/2306.06855 ,  510kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06858
Date: Mon, 12 Jun 2023 04:11:37 GMT   (857kb,D)

Title: Robustifying DARTS by Eliminating Information Bypass Leakage via
 Explicit Sparse Regularization
Authors: Jiuling Zhang, Zhiming Ding
Categories: cs.LG
Comments: Published as full paper on ICDM 2021
DOI: 10.1109/ICDM51629.2021.00099
\\
 Differentiable architecture search (DARTS) is a promising end to end NAS
method which directly optimizes the architecture parameters through general
gradient descent. However, DARTS is brittle to the catastrophic failure
incurred by the skip connection in the search space. Recent studies also cast
doubt on the basic underlying hypotheses of DARTS which are argued to be
inherently prone to the performance discrepancy between the continuous-relaxed
supernet in the training phase and the discretized finalnet in the evaluation
phase. We figure out that the robustness problem and the skepticism can both be
explained by the information bypass leakage during the training of the
supernet. This naturally highlights the vital role of the sparsity of
architecture parameters in the training phase which has not been well developed
in the past. We thus propose a novel sparse-regularized approximation and an
efficient mixed-sparsity training scheme to robustify DARTS by eliminating the
information bypass leakage. We subsequently conduct extensive experiments on
multiple search spaces to demonstrate the effectiveness of our method.
\\ ( https://arxiv.org/abs/2306.06858 ,  857kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06865
Date: Mon, 12 Jun 2023 04:46:01 GMT   (1686kb,D)

Title: Deep denoising autoencoder-based non-invasive blood flow detection for
 arteriovenous fistula
Authors: Li-Chin Chen, Yi-Heng Lin, Li-Ning Peng, Feng-Ming Wang, Yu-Hsin Chen,
 Po-Hsun Huang, Shang-Feng Yang, Yu Tsao
Categories: cs.LG cs.AI eess.SP
\\
 Clinical guidelines underscore the importance of regularly monitoring and
surveilling arteriovenous fistula (AVF) access in hemodialysis patients to
promptly detect any dysfunction. Although phono-angiography/sound analysis
overcomes the limitations of standardized AVF stenosis diagnosis tool, prior
studies have depended on conventional feature extraction methods, restricting
their applicability in diverse contexts. In contrast, representation learning
captures fundamental underlying factors that can be readily transferred across
different contexts. We propose an approach based on deep denoising autoencoders
(DAEs) that perform dimensionality reduction and reconstruction tasks using the
waveform obtained through one-level discrete wavelet transform, utilizing
representation learning. Our results demonstrate that the latent representation
generated by the DAE surpasses expectations with an accuracy of 0.93. The
incorporation of noise-mixing and the utilization of a noise-to-clean scheme
effectively enhance the discriminative capabilities of the latent
representation. Moreover, when employed to identify patient-specific
characteristics, the latent representation exhibited performance by surpassing
an accuracy of 0.92. Appropriate light-weighted methods can restore the
detection performance of the excessively reduced dimensionality version and
enable operation on less computational devices. Our findings suggest that
representation learning is a more feasible approach for extracting auscultation
features in AVF, leading to improved generalization and applicability across
multiple tasks. The manipulation of latent representations holds immense
potential for future advancements. Further investigations in this area are
promising and warrant continued exploration.
\\ ( https://arxiv.org/abs/2306.06865 ,  1686kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06866
Date: Mon, 12 Jun 2023 04:46:44 GMT   (7002kb,D)

Title: Generating Synthetic Datasets by Interpolating along Generalized
 Geodesics
Authors: Jiaojiao Fan and David Alvarez-Melis
Categories: cs.LG cs.AI
Journal-ref: Conference on Uncertainty in Artificial Intelligence (UAI) 2023
\\
 Data for pretraining machine learning models often consists of collections of
heterogeneous datasets. Although training on their union is reasonable in
agnostic settings, it might be suboptimal when the target domain -- where the
model will ultimately be used -- is known in advance. In that case, one would
ideally pretrain only on the dataset(s) most similar to the target one. Instead
of limiting this choice to those datasets already present in the pretraining
collection, here we explore extending this search to all datasets that can be
synthesized as `combinations' of them. We define such combinations as
multi-dataset interpolations, formalized through the notion of generalized
geodesics from optimal transport (OT) theory. We compute these geodesics using
a recent notion of distance between labeled datasets, and derive alternative
interpolation schemes based on it: using either barycentric projections or
optimal transport maps, the latter computed using recent neural OT methods.
These methods are scalable, efficient, and -- notably -- can be used to
interpolate even between datasets with distinct and unrelated label sets.
Through various experiments in transfer learning in computer vision, we
demonstrate this is a promising new approach for targeted on-demand dataset
synthesis.
\\ ( https://arxiv.org/abs/2306.06866 ,  7002kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06871
Date: Mon, 12 Jun 2023 05:10:10 GMT   (3895kb,D)

Title: Ensemble-based Offline-to-Online Reinforcement Learning: From
 Pessimistic Learning to Optimistic Exploration
Authors: Kai Zhao, Yi Ma, Jinyi Liu, Yan Zheng, Zhaopeng Meng
Categories: cs.LG cs.AI cs.RO
\\
 Offline reinforcement learning (RL) is a learning paradigm where an agent
learns from a fixed dataset of experience. However, learning solely from a
static dataset can limit the performance due to the lack of exploration. To
overcome it, offline-to-online RL combines offline pre-training with online
fine-tuning, which enables the agent to further refine its policy by
interacting with the environment in real-time. Despite its benefits, existing
offline-to-online RL methods suffer from performance degradation and slow
improvement during the online phase. To tackle these challenges, we propose a
novel framework called Ensemble-based Offline-to-Online (E2O) RL. By increasing
the number of Q-networks, we seamlessly bridge offline pre-training and online
fine-tuning without degrading performance. Moreover, to expedite online
performance enhancement, we appropriately loosen the pessimism of Q-value
estimation and incorporate ensemble-based exploration mechanisms into our
framework. Experimental results demonstrate that E2O can substantially improve
the training stability, learning efficiency, and final performance of existing
offline RL methods during online fine-tuning on a range of locomotion and
navigation tasks, significantly outperforming existing offline-to-online RL
methods.
\\ ( https://arxiv.org/abs/2306.06871 ,  3895kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06894
Date: Mon, 12 Jun 2023 06:52:04 GMT   (14472kb,D)

Title: A Generalized Unbiased Risk Estimator for Learning with Augmented
 Classes
Authors: Senlin Shu, Shuo He, Haobo Wang, Hongxin Wei, Tao Xiang, Lei Feng
Categories: cs.LG cs.CV
Comments: Accepted by AAAI 2023, 17 pages, 4 tables, 4 figures
\\
 In contrast to the standard learning paradigm where all classes can be
observed in training data, learning with augmented classes (LAC) tackles the
problem where augmented classes unobserved in the training data may emerge in
the test phase. Previous research showed that given unlabeled data, an unbiased
risk estimator (URE) can be derived, which can be minimized for LAC with
theoretical guarantees. However, this URE is only restricted to the specific
type of one-versus-rest loss functions for multi-class classification, making
it not flexible enough when the loss needs to be changed with the dataset in
practice. In this paper, we propose a generalized URE that can be equipped with
arbitrary loss functions while maintaining the theoretical guarantees, given
unlabeled data for LAC. To alleviate the issue of negative empirical risk
commonly encountered by previous studies, we further propose a novel
risk-penalty regularization term. Experiments demonstrate the effectiveness of
our proposed method.
\\ ( https://arxiv.org/abs/2306.06894 ,  14472kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06895
Date: Mon, 12 Jun 2023 07:00:37 GMT   (816kb,D)

Title: MPPN: Multi-Resolution Periodic Pattern Network For Long-Term Time
 Series Forecasting
Authors: Xing Wang, Zhendong Wang, Kexin Yang, Junlan Feng, Zhiyan Song, Chao
 Deng, Lin zhu
Categories: cs.LG stat.ML
Comments: 21 pages
\\
 Long-term time series forecasting plays an important role in various
real-world scenarios. Recent deep learning methods for long-term series
forecasting tend to capture the intricate patterns of time series by
decomposition-based or sampling-based methods. However, most of the extracted
patterns may include unpredictable noise and lack good interpretability.
Moreover, the multivariate series forecasting methods usually ignore the
individual characteristics of each variate, which may affecting the prediction
accuracy. To capture the intrinsic patterns of time series, we propose a novel
deep learning network architecture, named Multi-resolution Periodic Pattern
Network (MPPN), for long-term series forecasting. We first construct
context-aware multi-resolution semantic units of time series and employ
multi-periodic pattern mining to capture the key patterns of time series. Then,
we propose a channel adaptive module to capture the perceptions of multivariate
towards different patterns. In addition, we present an entropy-based method for
evaluating the predictability of time series and providing an upper bound on
the prediction accuracy before forecasting. Our experimental evaluation on nine
real-world benchmarks demonstrated that MPPN significantly outperforms the
state-of-the-art Transformer-based, decomposition-based and sampling-based
methods for long-term series forecasting.
\\ ( https://arxiv.org/abs/2306.06895 ,  816kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06904
Date: Mon, 12 Jun 2023 07:18:13 GMT   (28607kb,D)

Title: Differentiable Multi-Fidelity Fusion: Efficient Learning of Physics
 Simulations with Neural Architecture Search and Transfer Learning
Authors: Yuwen Deng, Wang Kang, Wei W. Xing
Categories: cs.LG cs.AI
\\
 With rapid progress in deep learning, neural networks have been widely used
in scientific research and engineering applications as surrogate models.
Despite the great success of neural networks in fitting complex systems, two
major challenges still remain: i) the lack of generalization on different
problems/datasets, and ii) the demand for large amounts of simulation data that
are computationally expensive. To resolve these challenges, we propose the
differentiable \mf (DMF) model, which leverages neural architecture search
(NAS) to automatically search the suitable model architecture for different
problems, and transfer learning to transfer the learned knowledge from
low-fidelity (fast but inaccurate) data to high-fidelity (slow but accurate)
model. Novel and latest machine learning techniques such as hyperparameters
search and alternate learning are used to improve the efficiency and robustness
of DMF. As a result, DMF can efficiently learn the physics simulations with
only a few high-fidelity training samples, and outperform the state-of-the-art
methods with a significant margin (with up to 58$\%$ improvement in RMSE) based
on a variety of synthetic and practical benchmark problems.
\\ ( https://arxiv.org/abs/2306.06904 ,  28607kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06909
Date: Mon, 12 Jun 2023 07:27:31 GMT   (42524kb,D)

Title: Graph Agent Network: Empowering Nodes with Decentralized Communications
 Capabilities for Adversarial Resilience
Authors: Ao Liu, Wenshan Li, Tao Li, Beibei Li, Hanyuan Huang, Guangquan Xu,
 Pan Zhou
Categories: cs.LG cs.AI cs.CR cs.NE
\\
 End-to-end training with global optimization have popularized graph neural
networks (GNNs) for node classification, yet inadvertently introduced
vulnerabilities to adversarial edge-perturbing attacks. Adversaries can exploit
the inherent opened interfaces of GNNs' input and output, perturbing critical
edges and thus manipulating the classification results. Current defenses, due
to their persistent utilization of global-optimization-based end-to-end
training schemes, inherently encapsulate the vulnerabilities of GNNs. This is
specifically evidenced in their inability to defend against targeted secondary
attacks. In this paper, we propose the Graph Agent Network (GAgN) to address
the aforementioned vulnerabilities of GNNs. GAgN is a graph-structured agent
network in which each node is designed as an 1-hop-view agent. Through the
decentralized interactions between agents, they can learn to infer global
perceptions to perform tasks including inferring embeddings, degrees and
neighbor relationships for given nodes. This empowers nodes to filtering
adversarial edges while carrying out classification tasks. Furthermore, agents'
limited view prevents malicious messages from propagating globally in GAgN,
thereby resisting global-optimization-based secondary attacks. We prove that
single-hidden-layer multilayer perceptrons (MLPs) are theoretically sufficient
to achieve these functionalities. Experimental results show that GAgN
effectively implements all its intended capabilities and, compared to
state-of-the-art defenses, achieves optimal classification accuracy on the
perturbed datasets.
\\ ( https://arxiv.org/abs/2306.06909 ,  42524kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06913
Date: Mon, 12 Jun 2023 07:34:21 GMT   (24224kb,D)

Title: Network Robustness Learning via Graph Transformer
Authors: Yu Zhang, Jia Li, Jie Ding, Xiang Li
Categories: cs.LG cs.AI cs.CR
Comments: 14 pages, 7 figures
\\
 Learning and analysis of network robustness, including controllability
robustness and connectivity robustness, is critical for various networked
systems against attacks. Traditionally, network robustness is determined by
attack simulations, which is very time-consuming and even incapable for
large-scale networks. Network Robustness Learning, which is dedicated to
learning network robustness with high precision and high speed, provides a
powerful tool to analyze network robustness by replacing simulations. In this
paper, a novel versatile and unified robustness learning approach via graph
transformer (NRL-GT) is proposed, which accomplishes the task of
controllability robustness learning and connectivity robustness learning from
multiple aspects including robustness curve learning, overall robustness
learning, and synthetic network classification. Numerous experiments show that:
1) NRL-GT is a unified learning framework for controllability robustness and
connectivity robustness, demonstrating a strong generalization ability to
ensure high precision when training and test sets are distributed differently;
2) Compared to the cutting-edge methods, NRL-GT can simultaneously perform
network robustness learning from multiple aspects and obtains superior results
in less time. NRL-GT is also able to deal with complex networks of different
size with low learning error and high efficiency; 3) It is worth mentioning
that the backbone of NRL-GT can serve as a transferable feature learning module
for complex networks of different size and different downstream tasks.
\\ ( https://arxiv.org/abs/2306.06913 ,  24224kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06923
Date: Mon, 12 Jun 2023 07:50:53 GMT   (119kb,D)

Title: On the Viability of using LLMs for SW/HW Co-Design: An Example in
 Designing CiM DNN Accelerators
Authors: Zheyu Yan, Yifan Qin, Xiaobo Sharon Hu, Yiyu Shi
Categories: cs.LG cs.AR
\\
 Deep Neural Networks (DNNs) have demonstrated impressive performance across a
wide range of tasks. However, deploying DNNs on edge devices poses significant
challenges due to stringent power and computational budgets. An effective
solution to this issue is software-hardware (SW-HW) co-design, which allows for
the tailored creation of DNN models and hardware architectures that optimally
utilize available resources. However, SW-HW co-design traditionally suffers
from slow optimization speeds because their optimizers do not make use of
heuristic knowledge, also known as the ``cold start'' problem. In this study,
we present a novel approach that leverages Large Language Models (LLMs) to
address this issue. By utilizing the abundant knowledge of pre-trained LLMs in
the co-design optimization process, we effectively bypass the cold start
problem, substantially accelerating the design process. The proposed method
achieves a significant speedup of 25x. This advancement paves the way for the
rapid and efficient deployment of DNNs on edge devices.
\\ ( https://arxiv.org/abs/2306.06923 ,  119kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06930
Date: Mon, 12 Jun 2023 08:08:53 GMT   (4440kb,D)

Title: Localised Adaptive Spatial-Temporal Graph Neural Network
Authors: Wenying Duan, Xiaoxi He, Zimu Zhou, Lothar Thiele, Hong Rao
Categories: cs.LG
Comments: 11 pages,6 figures and this paper is accepted by KDD'23
\\
 Spatial-temporal graph models are prevailing for abstracting and modelling
spatial and temporal dependencies. In this work, we ask the following question:
\textit{whether and to what extent can we localise spatial-temporal graph
models?} We limit our scope to adaptive spatial-temporal graph neural networks
(ASTGNNs), the state-of-the-art model architecture. Our approach to
localisation involves sparsifying the spatial graph adjacency matrices. To this
end, we propose Adaptive Graph Sparsification (AGS), a graph sparsification
algorithm which successfully enables the localisation of ASTGNNs to an extreme
extent (fully localisation). We apply AGS to two distinct ASTGNN architectures
and nine spatial-temporal datasets. Intriguingly, we observe that spatial
graphs in ASTGNNs can be sparsified by over 99.5\% without any decline in test
accuracy. Furthermore, even when ASTGNNs are fully localised, becoming
graph-less and purely temporal, we record no drop in accuracy for the majority
of tested datasets, with only minor accuracy deterioration observed in the
remaining datasets. However, when the partially or fully localised ASTGNNs are
reinitialised and retrained on the same data, there is a considerable and
consistent drop in accuracy. Based on these observations, we reckon that
\textit{(i)} in the tested data, the information provided by the spatial
dependencies is primarily included in the information provided by the temporal
dependencies and, thus, can be essentially ignored for inference; and
\textit{(ii)} although the spatial dependencies provide redundant information,
it is vital for the effective training of ASTGNNs and thus cannot be ignored
during training. Furthermore, the localisation of ASTGNNs holds the potential
to reduce the heavy computation overhead required on large-scale
spatial-temporal data and further enable the distributed deployment of ASTGNNs.
\\ ( https://arxiv.org/abs/2306.06930 ,  4440kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06931
Date: Mon, 12 Jun 2023 08:11:06 GMT   (4762kb,D)

Title: Evolving Semantic Prototype Improves Generative Zero-Shot Learning
Authors: Shiming Chen, Wenjin Hou, Ziming Hong, Xiaohan Ding, Yibing Song,
 Xinge You, Tongliang Liu, Kun Zhang
Categories: cs.LG cs.CV
Comments: Accepted to ICML'23
\\
 In zero-shot learning (ZSL), generative methods synthesize class-related
sample features based on predefined semantic prototypes. They advance the ZSL
performance by synthesizing unseen class sample features for better training
the classifier. We observe that each class's predefined semantic prototype
(also referred to as semantic embedding or condition) does not accurately match
its real semantic prototype. So the synthesized visual sample features do not
faithfully represent the real sample features, limiting the classifier training
and existing ZSL performance. In this paper, we formulate this mismatch
phenomenon as the visual-semantic domain shift problem. We propose a dynamic
semantic prototype evolving (DSP) method to align the empirically predefined
semantic prototypes and the real prototypes for class-related feature
synthesis. The alignment is learned by refining sample features and semantic
prototypes in a unified framework and making the synthesized visual sample
features approach real sample features. After alignment, synthesized sample
features from unseen classes are closer to the real sample features and benefit
DSP to improve existing generative ZSL methods by 8.5\%, 8.0\%, and 9.7\% on
the standard CUB, SUN AWA2 datasets, the significant performance improvement
indicates that evolving semantic prototype explores a virgin field in ZSL.
\\ ( https://arxiv.org/abs/2306.06931 ,  4762kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06936
Date: Mon, 12 Jun 2023 08:14:42 GMT   (1851kb,D)

Title: CARL-G: Clustering-Accelerated Representation Learning on Graphs
Authors: William Shiao, Uday Singh Saini, Yozen Liu, Tong Zhao, Neil Shah,
 Evangelos E. Papalexakis
Categories: cs.LG
Comments: 14 pages. Accepted at KDD 2023
DOI: 10.1145/3580305.3599268
\\
 Self-supervised learning on graphs has made large strides in achieving great
performance in various downstream tasks. However, many state-of-the-art methods
suffer from a number of impediments, which prevent them from realizing their
full potential. For instance, contrastive methods typically require negative
sampling, which is often computationally costly. While non-contrastive methods
avoid this expensive step, most existing methods either rely on overly complex
architectures or dataset-specific augmentations. In this paper, we ask: Can we
borrow from classical unsupervised machine learning literature in order to
overcome those obstacles? Guided by our key insight that the goal of
distance-based clustering closely resembles that of contrastive learning: both
attempt to pull representations of similar items together and dissimilar items
apart. As a result, we propose CARL-G - a novel clustering-based framework for
graph representation learning that uses a loss inspired by Cluster Validation
Indices (CVIs), i.e., internal measures of cluster quality (no ground truth
required). CARL-G is adaptable to different clustering methods and CVIs, and we
show that with the right choice of clustering method and CVI, CARL-G
outperforms node classification baselines on 4/5 datasets with up to a 79x
training speedup compared to the best-performing baseline. CARL-G also performs
at par or better than baselines in node clustering and similarity search tasks,
training up to 1,500x faster than the best-performing baseline. Finally, we
also provide theoretical foundations for the use of CVI-inspired losses in
graph representation learning.
\\ ( https://arxiv.org/abs/2306.06936 ,  1851kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06955
Date: Mon, 12 Jun 2023 08:37:38 GMT   (144kb,D)

Title: A Brief Review of Hypernetworks in Deep Learning
Authors: Vinod Kumar Chauhan, Jiandong Zhou, Ping Lu, Soheila Molaei and David
 A. Clifton
Categories: cs.LG
Comments: 2 figures and 2 tables (under review)
\\
 Hypernetworks, or hypernets in short, are neural networks that generate
weights for another neural network, known as the target network. They have
emerged as a powerful deep learning technique that allows for greater
flexibility, adaptability, faster training, information sharing, and model
compression etc. Hypernets have shown promising results in a variety of deep
learning problems, including continual learning, causal inference, transfer
learning, weight pruning, uncertainty quantification, zero-shot learning,
natural language processing, and reinforcement learning etc. Despite their
success across different problem settings, currently, there is no review
available to inform the researchers about the developments and help in
utilizing hypernets. To fill this gap, we review the progress in hypernets. We
present an illustrative example to train deep neural networks using hypernets
and propose to categorize hypernets on five criteria that affect the design of
hypernets as inputs, outputs, variability of inputs and outputs, and
architecture of hypernets. We also review applications of hypernets across
different deep learning problem settings. Finally, we discuss the challenges
and future directions that remain under-explored in the field of hypernets. We
believe that hypernetworks have the potential to revolutionize the field of
deep learning. They offer a new way to design and train neural networks, and
they have the potential to improve the performance of deep learning models on a
variety of tasks. Through this review, we aim to inspire further advancements
in deep learning through hypernetworks.
\\ ( https://arxiv.org/abs/2306.06955 ,  144kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06965
Date: Mon, 12 Jun 2023 08:52:14 GMT   (1765kb,D)

Title: NF4 Isn't Information Theoretically Optimal (and that's Good)
Authors: Davis Yoshida
Categories: cs.LG
\\
 This note shares some simple calculations and experiments related to
absmax-based blockwise quantization, as used in Dettmers et al., 2023. Their
proposed NF4 data type is said to be information theoretically optimal for
representing normally distributed weights. I show that this is can't quite be
the case, as the distribution of the values to be quantized depends on the
block-size. I attempt to apply these insights to derive an improved code based
on minimizing the expected L1 reconstruction error, rather than the quantile
based method. This leads to improved performance for larger quantization block
sizes, while both codes perform similarly at smaller block sizes.
\\ ( https://arxiv.org/abs/2306.06965 ,  1765kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06968
Date: Mon, 12 Jun 2023 08:53:41 GMT   (395kb,D)

Title: Can Forward Gradient Match Backpropagation?
Authors: Louis Fournier (MLIA), St\'ephane Rivaud (MLIA), Eugene Belilovsky
 (MILA), Michael Eickenberg, Edouard Oyallon (MLIA)
Categories: cs.LG cs.CV cs.NE stat.ML
Journal-ref: Fortieth International Conference on Machine Learning, Jul 2023,
 Honolulu (Hawaii), USA, United States
\\
 Forward Gradients - the idea of using directional derivatives in forward
differentiation mode - have recently been shown to be utilizable for neural
network training while avoiding problems generally associated with
backpropagation gradient computation, such as locking and memorization
requirements. The cost is the requirement to guess the step direction, which is
hard in high dimensions. While current solutions rely on weighted averages over
isotropic guess vector distributions, we propose to strongly bias our gradient
guesses in directions that are much more promising, such as feedback obtained
from small, local auxiliary networks. For a standard computer vision neural
network, we conduct a rigorous study systematically covering a variety of
combinations of gradient targets and gradient guesses, including those
previously presented in the literature. We find that using gradients obtained
from a local loss as a candidate direction drastically improves on random noise
in Forward Gradient methods.
\\ ( https://arxiv.org/abs/2306.06968 ,  395kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06974
Date: Mon, 12 Jun 2023 09:15:58 GMT   (1752kb,D)

Title: A Computational Theory and Semi-Supervised Algorithm for Clustering
Authors: Nassir Mohammad
Categories: cs.LG
\\
 A computational theory for clustering and a semi-supervised clustering
algorithm is presented. Clustering is defined to be the obtainment of groupings
of data such that each group contains no anomalies with respect to a chosen
grouping principle and measure; all other examples are considered to be fringe
points, isolated anomalies, anomalous clusters or unknown clusters. More
precisely, after appropriate modelling under the assumption of uniform random
distribution, any example whose expectation of occurrence is <1 with respect to
a group is considered an anomaly; otherwise it is assigned a membership of that
group. Thus, clustering is conceived as the dual of anomaly detection. The
representation of data is taken to be the Euclidean distance of a point to a
cluster median. This is due to the robustness properties of the median to
outliers, its approximate location of centrality and so that decision
boundaries are general purpose. The kernel of the clustering method is
Mohammad's anomaly detection algorithm, resulting in a parameter-free, fast,
and efficient clustering algorithm. Acknowledging that clustering is an
interactive and iterative process, the algorithm relies on a small fraction of
known relationships between examples. These relationships serve as seeds to
define the user's objectives and guide the clustering process. The algorithm
then expands the clusters accordingly, leaving the remaining examples for
exploration and subsequent iterations. Results are presented on synthetic and
realworld data sets, demonstrating the advantages over the most widely used
clustering methods.
\\ ( https://arxiv.org/abs/2306.06974 ,  1752kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06994
Date: Mon, 12 Jun 2023 09:42:16 GMT   (1039kb,D)

Title: Correlated Time Series Self-Supervised Representation Learning via
 Spatiotemporal Bootstrapping
Authors: Luxuan Wang, Lei Bai, Ziyue Li, Rui Zhao, Fugee Tsung
Categories: cs.LG cs.AI
Comments: Accepted to IEEE CASE 2023
\\
 Correlated time series analysis plays an important role in many real-world
industries. Learning an efficient representation of this large-scale data for
further downstream tasks is necessary but challenging. In this paper, we
propose a time-step-level representation learning framework for individual
instances via bootstrapped spatiotemporal representation prediction. We
evaluated the effectiveness and flexibility of our representation learning
framework on correlated time series forecasting and cold-start transferring the
forecasting model to new instances with limited data. A linear regression model
trained on top of the learned representations demonstrates our model performs
best in most cases. Especially compared to representation learning models, we
reduce the RMSE, MAE, and MAPE by 37%, 49%, and 48% on the PeMS-BAY dataset,
respectively. Furthermore, in real-world metro passenger flow data, our
framework demonstrates the ability to transfer to infer future information of
new cold-start instances, with gains of 15%, 19%, and 18%. The source code will
be released under the GitHub
https://github.com/bonaldli/Spatiotemporal-TS-Representation-Learning
\\ ( https://arxiv.org/abs/2306.06994 ,  1039kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06995
Date: Mon, 12 Jun 2023 09:45:21 GMT   (10422kb,D)

Title: How robust accuracy suffers from certified training with convex
 relaxations
Authors: Piersilvio De Bartolomeis, Jacob Clarysse, Amartya Sanyal, Fanny Yang
Categories: cs.LG
\\
 Adversarial attacks pose significant threats to deploying state-of-the-art
classifiers in safety-critical applications. Two classes of methods have
emerged to address this issue: empirical defences and certified defences.
Although certified defences come with robustness guarantees, empirical defences
such as adversarial training enjoy much higher popularity among practitioners.
In this paper, we systematically compare the standard and robust error of these
two robust training paradigms across multiple computer vision tasks. We show
that in most tasks and for both $\mathscr{l}_\infty$-ball and
$\mathscr{l}_2$-ball threat models, certified training with convex relaxations
suffers from worse standard and robust error than adversarial training. We
further explore how the error gap between certified and adversarial training
depends on the threat model and the data distribution. In particular, besides
the perturbation budget, we identify as important factors the shape of the
perturbation set and the implicit margin of the data distribution. We support
our arguments with extensive ablations on both synthetic and image datasets.
\\ ( https://arxiv.org/abs/2306.06995 ,  10422kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07001
Date: Mon, 12 Jun 2023 10:10:57 GMT   (43kb)

Title: Cancellation-Free Regret Bounds for Lagrangian Approaches in Constrained
 Markov Decision Processes
Authors: Adrian M\"uller, Pragnya Alatur, Giorgia Ramponi, Niao He
Categories: cs.LG stat.ML
\\
 Constrained Markov Decision Processes (CMDPs) are one of the common ways to
model safe reinforcement learning problems, where the safety objectives are
modeled by constraint functions. Lagrangian-based dual or primal-dual
algorithms provide efficient methods for learning in CMDPs. For these
algorithms, the currently known regret bounds in the finite-horizon setting
allow for a \textit{cancellation of errors}; that is, one can compensate for a
constraint violation in one episode with a strict constraint satisfaction in
another episode. However, in practical applications, we do not consider such a
behavior safe.
 In this paper, we overcome this weakness by proposing a novel model-based
dual algorithm \textsc{OptAug-CMDP} for tabular finite-horizon CMDPs. Our
algorithm is motivated by the augmented Lagrangian method and can be performed
efficiently. We show that during $K$ episodes of exploring the CMDP, our
algorithm obtains a regret of $\tilde{O}(\sqrt{K})$ for both the objective and
the constraint violation. Unlike existing Lagrangian approaches, our algorithm
achieves this regret without the need for the cancellation of errors.
\\ ( https://arxiv.org/abs/2306.07001 ,  43kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07015
Date: Mon, 12 Jun 2023 10:39:57 GMT   (29kb)

Title: Combining Primal and Dual Representations in Deep Restricted Kernel
 Machines Classifiers
Authors: Francesco Tonin, Panagiotis Patrinos, Johan A. K. Suykens
Categories: cs.LG
\\
 In contrast to deep networks, kernel methods cannot directly take advantage
of depth. In this regard, the deep Restricted Kernel Machine (DRKM) framework
allows multiple levels of kernel PCA (KPCA) and Least-Squares Support Vector
Machines (LSSVM) to be combined into a deep architecture using visible and
hidden units. We propose a new method for DRKM classification coupling the
objectives of KPCA and classification levels, with the hidden feature matrix
lying on the Stiefel manifold. The classification level can be formulated as an
LSSVM or as an MLP feature map, combining depth in terms of levels and layers.
The classification level is expressed in its primal formulation, as the deep
KPCA levels can embed the most informative components of the data in a much
lower dimensional space. In the experiments on benchmark datasets with few
available training points, we show that our deep method improves over the
LSSVM/MLP and that models with multiple KPCA levels can outperform models with
a single level.
\\ ( https://arxiv.org/abs/2306.07015 ,  29kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07019
Date: Mon, 12 Jun 2023 10:46:31 GMT   (522kb,D)

Title: Dynamic Causal Graph Convolutional Network for Traffic Prediction
Authors: Junpeng Lin, Ziyue Li, Zhishuai Li, Lei Bai, Rui Zhao, Chen Zhang
Categories: cs.LG eess.SP
Comments: Accepted to IEEE CASE 2023
\\
 Modeling complex spatiotemporal dependencies in correlated traffic series is
essential for traffic prediction. While recent works have shown improved
prediction performance by using neural networks to extract spatiotemporal
correlations, their effectiveness depends on the quality of the graph
structures used to represent the spatial topology of the traffic network. In
this work, we propose a novel approach for traffic prediction that embeds
time-varying dynamic Bayesian network to capture the fine spatiotemporal
topology of traffic data. We then use graph convolutional networks to generate
traffic forecasts. To enable our method to efficiently model nonlinear traffic
propagation patterns, we develop a deep learning-based module as a
hyper-network to generate stepwise dynamic causal graphs. Our experimental
results on a real traffic dataset demonstrate the superior prediction
performance of the proposed method.
\\ ( https://arxiv.org/abs/2306.07019 ,  522kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07024
Date: Mon, 12 Jun 2023 10:53:50 GMT   (3451kb,D)

Title: DRCFS: Doubly Robust Causal Feature Selection
Authors: Francesco Quinzan, Ashkan Soleymani, Patrik Jaillet, Cristian R.
 Rojas, Stefan Bauer
Categories: cs.LG stat.ME
\\
 Knowing the features of a complex system that are highly relevant to a
particular target variable is of fundamental interest in many areas of science.
Existing approaches are often limited to linear settings, sometimes lack
guarantees, and in most cases, do not scale to the problem at hand, in
particular to images. We propose DRCFS, a doubly robust feature selection
method for identifying the causal features even in nonlinear and high
dimensional settings. We provide theoretical guarantees, illustrate necessary
conditions for our assumptions, and perform extensive experiments across a wide
range of simulated and semi-synthetic datasets. DRCFS significantly outperforms
existing state-of-the-art methods, selecting robust features even in
challenging highly non-linear and high-dimensional problems.
\\ ( https://arxiv.org/abs/2306.07024 ,  3451kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07032
Date: Mon, 12 Jun 2023 11:24:48 GMT   (523kb,D)

Title: Mitigating Prior Errors in Causal Structure Learning: Towards LLM driven
 Prior Knowledge
Authors: Lyuzhou Chen, Taiyu Ban, Xiangyu Wang, Derui Lyu, Huanhuan Chen
Categories: cs.LG cs.AI
Comments: 14 pages, 4 figures
\\
 Causal structure learning, a prominent technique for encoding cause and
effect relationships among variables, through Bayesian Networks (BNs). Merely
recovering causal structures from real-world observed data lacks precision,
while the development of Large Language Models (LLM) is opening a new frontier
of causality. LLM presents strong capability in discovering causal
relationships between variables with the "text" inputs defining the
investigated variables, leading to a potential new hierarchy and new ladder of
causality. We aim an critical issue in the emerging topic of LLM based causal
structure learning, to tackle erroneous prior causal statements from LLM, which
is seldom considered in the current context of expert dominating prior
resources. As a pioneer attempt, we propose a BN learning strategy resilient to
prior errors without need of human intervention. Focusing on the edge-level
prior, we classify the possible prior errors into three types:
order-consistent, order-reversed, and irrelevant, and provide their theoretical
impact on the Structural Hamming Distance (SHD) under the presumption of
sufficient data. Intriguingly, we discover and prove that only the
order-reversed error contributes to an increase in a unique acyclic closed
structure, defined as a "quasi-circle". Leveraging this insight, a post-hoc
strategy is employed to identify the order-reversed prior error by its impact
on the increment of "quasi-circles". Through empirical evaluation on both real
and synthetic datasets, we demonstrate our strategy's robustness against prior
errors. Specifically, we highlight its substantial ability to resist
order-reversed errors while maintaining the majority of correct prior
knowledge.
\\ ( https://arxiv.org/abs/2306.07032 ,  523kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07036
Date: Mon, 12 Jun 2023 11:33:46 GMT   (1664kb,D)

Title: Making Binary Classification from Multiple Unlabeled Datasets Almost
 Free of Supervision
Authors: Yuhao Wu, Xiaobo Xia, Jun Yu, Bo Han, Gang Niu, Masashi Sugiyama,
 Tongliang Liu
Categories: cs.LG
Comments: 38 pages, 5 figures, 10 tables
\\
 Training a classifier exploiting a huge amount of supervised data is
expensive or even prohibited in a situation, where the labeling cost is high.
The remarkable progress in working with weaker forms of supervision is binary
classification from multiple unlabeled datasets which requires the knowledge of
exact class priors for all unlabeled datasets. However, the availability of
class priors is restrictive in many real-world scenarios. To address this
issue, we propose to solve a new problem setting, i.e., binary classification
from multiple unlabeled datasets with only one pairwise numerical relationship
of class priors (MU-OPPO), which knows the relative order (which unlabeled
dataset has a higher proportion of positive examples) of two class-prior
probabilities for two datasets among multiple unlabeled datasets. In MU-OPPO,
we do not need the class priors for all unlabeled datasets, but we only require
that there exists a pair of unlabeled datasets for which we know which
unlabeled dataset has a larger class prior. Clearly, this form of supervision
is easier to be obtained, which can make labeling costs almost free. We propose
a novel framework to handle the MU-OPPO problem, which consists of four
sequential modules: (i) pseudo label assignment; (ii) confident example
collection; (iii) class prior estimation; (iv) classifier training with
estimated class priors. Theoretically, we analyze the gap between estimated
class priors and true class priors under the proposed framework. Empirically,
we confirm the superiority of our framework with comprehensive experiments.
Experimental results demonstrate that our framework brings smaller estimation
errors of class priors and better performance of binary classification.
\\ ( https://arxiv.org/abs/2306.07036 ,  1664kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07040
Date: Mon, 12 Jun 2023 11:39:34 GMT   (357kb,D)

Title: Nonlinear SVD with Asymmetric Kernels: feature learning and asymmetric
 Nystr\"om method
Authors: Qinghua Tao, Francesco Tonin, Panagiotis Patrinos, Johan A. K. Suykens
Categories: cs.LG
\\
 Asymmetric data naturally exist in real life, such as directed graphs.
Different from the common kernel methods requiring Mercer kernels, this paper
tackles the asymmetric kernel-based learning problem. We describe a nonlinear
extension of the matrix Singular Value Decomposition through asymmetric
kernels, namely KSVD. First, we construct two nonlinear feature mappings w.r.t.
rows and columns of the given data matrix. The proposed optimization problem
maximizes the variance of each mapping projected onto the subspace spanned by
the other, subject to a mutual orthogonality constraint. Through Lagrangian
duality, we show that it can be solved by the left and right singular vectors
in the feature space induced by the asymmetric kernel. Moreover, we start from
the integral equations with a pair of adjoint eigenfunctions corresponding to
the singular vectors on an asymmetrical kernel, and extend the Nystr\"om method
to asymmetric cases through the finite sample approximation, which can be
applied to speedup the training in KSVD. Experiments show that asymmetric KSVD
learns features outperforming Mercer-kernel based methods that resort to
symmetrization, and also verify the effectiveness of the asymmetric Nystr\"om
method.
\\ ( https://arxiv.org/abs/2306.07040 ,  357kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07042
Date: Mon, 12 Jun 2023 11:41:42 GMT   (1833kb,D)

Title: Transformers learn through gradual rank increase
Authors: Enric Boix-Adsera, Etai Littwin, Emmanuel Abbe, Samy Bengio, Joshua
 Susskind
Categories: cs.LG
\\
 We identify incremental learning dynamics in transformers, where the
difference between trained and initial weights progressively increases in rank.
We rigorously prove this occurs under the simplifying assumptions of diagonal
weight matrices and small initialization. Our experiments support the theory
and also show that phenomenon can occur in practice without the simplifying
assumptions.
\\ ( https://arxiv.org/abs/2306.07042 ,  1833kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07059
Date: Mon, 12 Jun 2023 12:13:06 GMT   (799kb,D)

Title: A Distribution Optimization Framework for Confidence Bounds of Risk
 Measures
Authors: Hao Liang, Zhi-quan Luo
Categories: cs.LG cs.AI stat.ML
\\
 We present a distribution optimization framework that significantly improves
confidence bounds for various risk measures compared to previous methods. Our
framework encompasses popular risk measures such as the entropic risk measure,
conditional value at risk (CVaR), spectral risk measure, distortion risk
measure, equivalent certainty, and rank-dependent expected utility, which are
well established in risk-sensitive decision-making literature. To achieve this,
we introduce two estimation schemes based on concentration bounds derived from
the empirical distribution, specifically using either the Wasserstein distance
or the supremum distance. Unlike traditional approaches that add or subtract a
confidence radius from the empirical risk measures, our proposed schemes
evaluate a specific transformation of the empirical distribution based on the
distance. Consequently, our confidence bounds consistently yield tighter
results compared to previous methods. We further verify the efficacy of the
proposed framework by providing tighter problem-dependent regret bound for the
CVaR bandit.
\\ ( https://arxiv.org/abs/2306.07059 ,  799kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07060
Date: Mon, 12 Jun 2023 12:14:57 GMT   (680kb,D)

Title: Prediction Algorithms Achieving Bayesian Decision Theoretical Optimality
 Based on Decision Trees as Data Observation Processes
Authors: Yuta Nakahara, Shota Saito, Naoki Ichijo, Koki Kazama, Toshiyasu
 Matsushima
Categories: cs.LG stat.ML
\\
 In the field of decision trees, most previous studies have difficulty
ensuring the statistical optimality of a prediction of new data and suffer from
overfitting because trees are usually used only to represent prediction
functions to be constructed from given data. In contrast, some studies,
including this paper, used the trees to represent stochastic data observation
processes behind given data. Moreover, they derived the statistically optimal
prediction, which is robust against overfitting, based on the Bayesian decision
theory by assuming a prior distribution for the trees. However, these studies
still have a problem in computing this Bayes optimal prediction because it
involves an infeasible summation for all division patterns of a feature space,
which is represented by the trees and some parameters. In particular, an open
problem is a summation with respect to combinations of division axes, i.e., the
assignment of features to inner nodes of the tree. We solve this by a Markov
chain Monte Carlo method, whose step size is adaptively tuned according to a
posterior distribution for the trees.
\\ ( https://arxiv.org/abs/2306.07060 ,  680kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07071
Date: Mon, 12 Jun 2023 12:35:16 GMT   (5433kb,D)

Title: Budgeted Multi-Armed Bandits with Asymmetric Confidence Intervals
Authors: Marco Heyden, Vadim Arzamasov, Edouard Fouch\'e, Klemens B\"ohm
Categories: cs.LG stat.ML
MSC-class: 68T37, 68T05 (Primary) 68W27, 68Q32 (Secondary)
ACM-class: I.2.6; H.4.2; G.3
\\
 We study the stochastic Budgeted Multi-Armed Bandit (MAB) problem, where a
player chooses from $K$ arms with unknown expected rewards and costs. The goal
is to maximize the total reward under a budget constraint. A player thus seeks
to choose the arm with the highest reward-cost ratio as often as possible.
Current state-of-the-art policies for this problem have several issues, which
we illustrate. To overcome them, we propose a new upper confidence bound (UCB)
sampling policy, $\omega$-UCB, that uses asymmetric confidence intervals. These
intervals scale with the distance between the sample mean and the bounds of a
random variable, yielding a more accurate and tight estimation of the
reward-cost ratio compared to our competitors. We show that our approach has
logarithmic regret and consistently outperforms existing policies in synthetic
and real settings.
\\ ( https://arxiv.org/abs/2306.07071 ,  5433kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07077
Date: Mon, 12 Jun 2023 12:43:27 GMT   (3009kb,D)

Title: Latent Dynamical Implicit Diffusion Processes
Authors: Mohammad R. Rezaei
Categories: cs.LG stat.ML
\\
 Latent dynamical models are commonly used to learn the distribution of a
latent dynamical process that represents a sequence of noisy data samples.
However, producing samples from such models with high fidelity is challenging
due to the complexity and variability of latent and observation dynamics.
Recent advances in diffusion-based generative models, such as DDPM and NCSN,
have shown promising alternatives to state-of-the-art latent generative models,
such as Neural ODEs, RNNs, and Normalizing flow networks, for generating
high-quality sequential samples from a prior distribution. However, their
application in modeling sequential data with latent dynamical models is yet to
be explored. Here, we propose a novel latent variable model named latent
dynamical implicit diffusion processes (LDIDPs), which utilizes implicit
diffusion processes to sample from dynamical latent processes and generate
sequential observation samples accordingly. We tested LDIDPs on synthetic and
simulated neural decoding problems. We demonstrate that LDIDPs can accurately
learn the dynamics over latent dimensions. Furthermore, the implicit sampling
method allows for the computationally efficient generation of high-quality
sequential data samples from the latent and observation spaces.
\\ ( https://arxiv.org/abs/2306.07077 ,  3009kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07098
Date: Mon, 12 Jun 2023 13:22:06 GMT   (1387kb,D)

Title: Efficiently Learning the Graph for Semi-supervised Learning
Authors: Dravyansh Sharma, Maxwell Jones
Categories: cs.LG cs.AI
Comments: 29 pages, 9 figures
\\
 Computational efficiency is a major bottleneck in using classic graph-based
approaches for semi-supervised learning on datasets with a large number of
unlabeled examples. Known techniques to improve efficiency typically involve an
approximation of the graph regularization objective, but suffer two major
drawbacks - first the graph is assumed to be known or constructed with
heuristic hyperparameter values, second they do not provide a principled
approximation guarantee for learning over the full unlabeled dataset. Building
on recent work on learning graphs for semi-supervised learning from multiple
datasets for problems from the same domain, and leveraging techniques for fast
approximations for solving linear systems in the graph Laplacian matrix, we
propose algorithms that overcome both the above limitations.
 We show a formal separation in the learning-theoretic complexity of sparse
and dense graph families. We further show how to approximately learn the best
graphs from the sparse families efficiently using the conjugate gradient
method.
 Our approach can also be used to learn the graph efficiently online with
sub-linear regret, under mild smoothness assumptions. Our online learning
results are stated generally, and may be useful for approximate and efficient
parameter tuning in other problems. We implement our approach and demonstrate
significant ($\sim$10-100x) speedups over prior work on semi-supervised
learning with learned graphs on benchmark datasets.
\\ ( https://arxiv.org/abs/2306.07098 ,  1387kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07104
Date: Mon, 12 Jun 2023 13:27:55 GMT   (31816kb,D)

Title: Unveiling the Hessian's Connection to the Decision Boundary
Authors: Mahalakshmi Sabanayagam, Freya Behrens, Urte Adomaityte, Anna Dawid
Categories: cs.LG cond-mat.dis-nn stat.ML
Comments: 14 pages, 6 figures + 18-page appendices with 19 figures. Any
 feedback is very welcome! Code is available at
 https://github.com/Shmoo137/Hessian-and-Decision-Boundary
\\
 Understanding the properties of well-generalizing minima is at the heart of
deep learning research. On the one hand, the generalization of neural networks
has been connected to the decision boundary complexity, which is hard to study
in the high-dimensional input space. Conversely, the flatness of a minimum has
become a controversial proxy for generalization. In this work, we provide the
missing link between the two approaches and show that the Hessian top
eigenvectors characterize the decision boundary learned by the neural network.
Notably, the number of outliers in the Hessian spectrum is proportional to the
complexity of the decision boundary. Based on this finding, we provide a new
and straightforward approach to studying the complexity of a high-dimensional
decision boundary; show that this connection naturally inspires a new
generalization measure; and finally, we develop a novel margin estimation
technique which, in combination with the generalization measure, precisely
identifies minima with simple wide-margin boundaries. Overall, this analysis
establishes the connection between the Hessian and the decision boundary and
provides a new method to identify minima with simple wide-margin decision
boundaries.
\\ ( https://arxiv.org/abs/2306.07104 ,  31816kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07106
Date: Mon, 12 Jun 2023 13:31:58 GMT   (368kb,D)

Title: Adversarial Constrained Bidding via Minimax Regret Optimization with
 Causality-Aware Reinforcement Learning
Authors: Haozhe Wang, Chao Du, Panyan Fang, Li He, Liang Wang, Bo Zheng
Categories: cs.LG cs.AI cs.GT cs.IR
Comments: Accepted by SIGKDD2023
DOI: 10.1145/3580305.3599254
\\
 The proliferation of the Internet has led to the emergence of online
advertising, driven by the mechanics of online auctions. In these repeated
auctions, software agents participate on behalf of aggregated advertisers to
optimize for their long-term utility. To fulfill the diverse demands, bidding
strategies are employed to optimize advertising objectives subject to different
spending constraints. Existing approaches on constrained bidding typically rely
on i.i.d. train and test conditions, which contradicts the adversarial nature
of online ad markets where different parties possess potentially conflicting
objectives. In this regard, we explore the problem of constrained bidding in
adversarial bidding environments, which assumes no knowledge about the
adversarial factors. Instead of relying on the i.i.d. assumption, our insight
is to align the train distribution of environments with the potential test
distribution meanwhile minimizing policy regret. Based on this insight, we
propose a practical Minimax Regret Optimization (MiRO) approach that
interleaves between a teacher finding adversarial environments for tutoring and
a learner meta-learning its policy over the given distribution of environments.
In addition, we pioneer to incorporate expert demonstrations for learning
bidding strategies. Through a causality-aware policy design, we improve upon
MiRO by distilling knowledge from the experts. Extensive experiments on both
industrial data and synthetic data show that our method, MiRO with
Causality-aware reinforcement Learning (MiROCL), outperforms prior methods by
over 30%.
\\ ( https://arxiv.org/abs/2306.07106 ,  368kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07114
Date: Mon, 12 Jun 2023 13:42:56 GMT   (13463kb)

Title: Coupled Attention Networks for Multivariate Time Series Anomaly
 Detection
Authors: Feng Xia, Xin Chen, Shuo Yu, Mingliang Hou, Mujie Liu, Linlin You
Categories: cs.LG
\\
 Multivariate time series anomaly detection (MTAD) plays a vital role in a
wide variety of real-world application domains. Over the past few years, MTAD
has attracted rapidly increasing attention from both academia and industry.
Many deep learning and graph learning models have been developed for effective
anomaly detection in multivariate time series data, which enable advanced
applications such as smart surveillance and risk management with unprecedented
capabilities. Nevertheless, MTAD is facing critical challenges deriving from
the dependencies among sensors and variables, which often change over time. To
address this issue, we propose a coupled attention-based neural network
framework (CAN) for anomaly detection in multivariate time series data
featuring dynamic variable relationships. We combine adaptive graph learning
methods with graph attention to generate a global-local graph that can
represent both global correlations and dynamic local correlations among
sensors. To capture inter-sensor relationships and temporal dependencies, a
convolutional neural network based on the global-local graph is integrated with
a temporal self-attention module to construct a coupled attention module. In
addition, we develop a multilevel encoder-decoder architecture that
accommodates reconstruction and prediction tasks to better characterize
multivariate time series data. Extensive experiments on real-world datasets
have been conducted to evaluate the performance of the proposed CAN approach,
and the results show that CAN significantly outperforms state-of-the-art
baselines.
\\ ( https://arxiv.org/abs/2306.07114 ,  13463kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07124
Date: Mon, 12 Jun 2023 13:59:48 GMT   (25457kb,D)

Title: Diverse Projection Ensembles for Distributional Reinforcement Learning
Authors: Moritz A. Zanger, Wendelin B\"ohmer, Matthijs T. J. Spaan
Categories: cs.LG cs.AI stat.ML
Comments: 21 pages, 7 figures, submitted to NeurIPS 2023
\\
 In contrast to classical reinforcement learning, distributional reinforcement
learning algorithms aim to learn the distribution of returns rather than their
expected value. Since the nature of the return distribution is generally
unknown a priori or arbitrarily complex, a common approach finds approximations
within a set of representable, parametric distributions. Typically, this
involves a projection of the unconstrained distribution onto the set of
simplified distributions. We argue that this projection step entails a strong
inductive bias when coupled with neural networks and gradient descent, thereby
profoundly impacting the generalization behavior of learned models. In order to
facilitate reliable uncertainty estimation through diversity, this work studies
the combination of several different projections and representations in a
distributional ensemble. We establish theoretical properties of such projection
ensembles and derive an algorithm that uses ensemble disagreement, measured by
the average $1$-Wasserstein distance, as a bonus for deep exploration. We
evaluate our algorithm on the behavior suite benchmark and find that diverse
projection ensembles lead to significant performance improvements over existing
methods on a wide variety of tasks with the most pronounced gains in directed
exploration problems.
\\ ( https://arxiv.org/abs/2306.07124 ,  25457kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07125
Date: Mon, 12 Jun 2023 14:01:30 GMT   (2085kb,D)

Title: On the Dynamics of Learning Time-Aware Behavior with Recurrent Neural
 Networks
Authors: Peter DelMastro, Rushiv Arora, Edward Rietman, Hava T. Siegelmann
Categories: cs.LG cs.NE
Comments: Main paper: 11 pages, 8 figures. Supplemental Material: 6 pages, 5
 figures, 1 table
\\
 Recurrent Neural Networks (RNNs) have shown great success in modeling
time-dependent patterns, but there is limited research on their learned
representations of latent temporal features and the emergence of these
representations during training. To address this gap, we use timed automata
(TA) to introduce a family of supervised learning tasks modeling behavior
dependent on hidden temporal variables whose complexity is directly
controllable. Building upon past studies from the perspective of dynamical
systems, we train RNNs to emulate temporal flipflops, a new collection of TA
that emphasizes the need for time-awareness over long-term memory. We find that
these RNNs learn in phases: they quickly perfect any time-independent behavior,
but they initially struggle to discover the hidden time-dependent features. In
the case of periodic "time-of-day" aware automata, we show that the RNNs learn
to switch between periodic orbits that encode time modulo the period of the
transition rules. We subsequently apply fixed point stability analysis to
monitor changes in the RNN dynamics during training, and we observe that the
learning phases are separated by a bifurcation from which the periodic behavior
emerges. In this way, we demonstrate how dynamical systems theory can provide
insights into not only the learned representations of these models, but also
the dynamics of the learning process itself. We argue that this style of
analysis may provide insights into the training pathologies of recurrent
architectures in contexts outside of time-awareness.
\\ ( https://arxiv.org/abs/2306.07125 ,  2085kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07163
Date: Mon, 12 Jun 2023 14:50:21 GMT   (36kb)

Title: General Transformation for Consistent Online Approximation Algorithms
Authors: Jing Dong, Yuichi Yoshida
Categories: cs.LG stat.ML
\\
 We introduce a transformation framework that can be utilized to develop
online algorithms with low $\epsilon$-approximate regret in the random-order
model from offline approximation algorithms. We first give a general reduction
theorem that transforms an offline approximation algorithm with low average
sensitivity to an online algorithm with low $\epsilon$-approximate regret. We
then demonstrate that offline approximation algorithms can be transformed into
a low-sensitivity version using a coreset construction method. To showcase the
versatility of our approach, we apply it to various problems, including online
$(k,z)$-clustering, online matrix approximation, and online regression, and
successfully achieve polylogarithmic $\epsilon$-approximate regret for each
problem. Moreover, we show that in all three cases, our algorithm also enjoys
low inconsistency, which may be desired in some online applications.
\\ ( https://arxiv.org/abs/2306.07163 ,  36kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07171
Date: Mon, 12 Jun 2023 15:09:13 GMT   (134kb)

Title: Shapley Value on Probabilistic Classifiers
Authors: Xiang Li and Haocheng Xia and Jinfei Liu
Categories: cs.LG cs.DB
\\
 Data valuation has become an increasingly significant discipline in data
science due to the economic value of data. In the context of machine learning
(ML), data valuation methods aim to equitably measure the contribution of each
data point to the utility of an ML model. One prevalent method is Shapley
value, which helps identify data points that are beneficial or detrimental to
an ML model. However, traditional Shapley-based data valuation methods may not
effectively distinguish between beneficial and detrimental training data points
for probabilistic classifiers. In this paper, we propose Probabilistic Shapley
(P-Shapley) value by constructing a probability-wise utility function that
leverages the predicted class probabilities of probabilistic classifiers rather
than binarized prediction results in the traditional Shapley value. We also
offer several activation functions for confidence calibration to effectively
quantify the marginal contribution of each data point to the probabilistic
classifiers. Extensive experiments on four real-world datasets demonstrate the
effectiveness of our proposed P-Shapley value in evaluating the importance of
data for building a high-usability and trustworthy ML model.
\\ ( https://arxiv.org/abs/2306.07171 ,  134kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07176
Date: Mon, 12 Jun 2023 15:15:00 GMT   (5376kb,D)

Title: Unbalanced Optimal Transport meets Sliced-Wasserstein
Authors: Thibault S\'ejourn\'e, Cl\'ement Bonet, Kilian Fatras, Kimia Nadjahi,
 Nicolas Courty
Categories: cs.LG math.OC
\\
 Optimal transport (OT) has emerged as a powerful framework to compare
probability measures, a fundamental task in many statistical and machine
learning problems. Substantial advances have been made over the last decade in
designing OT variants which are either computationally and statistically more
efficient, or more robust to the measures and datasets to compare. Among them,
sliced OT distances have been extensively used to mitigate optimal transport's
cubic algorithmic complexity and curse of dimensionality. In parallel,
unbalanced OT was designed to allow comparisons of more general positive
measures, while being more robust to outliers. In this paper, we propose to
combine these two concepts, namely slicing and unbalanced OT, to develop a
general framework for efficiently comparing positive measures. We propose two
new loss functions based on the idea of slicing unbalanced OT, and study their
induced topology and statistical properties. We then develop a fast
Frank-Wolfe-type algorithm to compute these loss functions, and show that the
resulting methodology is modular as it encompasses and extends prior related
work. We finally conduct an empirical analysis of our loss functions and
methodology on both synthetic and real datasets, to illustrate their relevance
and applicability.
\\ ( https://arxiv.org/abs/2306.07176 ,  5376kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07179
Date: Mon, 12 Jun 2023 15:21:02 GMT   (1288kb,D)

Title: Benchmarking Neural Network Training Algorithms
Authors: George E. Dahl, Frank Schneider, Zachary Nado, Naman Agarwal,
 Chandramouli Shama Sastry, Philipp Hennig, Sourabh Medapati, Runa
 Eschenhagen, Priya Kasimbeg, Daniel Suo, Juhan Bae, Justin Gilmer, Abel L.
 Peirson, Bilal Khan, Rohan Anil, Mike Rabbat, Shankar Krishnan, Daniel
 Snider, Ehsan Amid, Kongtao Chen, Chris J. Maddison, Rakshith Vasudev, Michal
 Badura, Ankush Garg, Peter Mattson
Categories: cs.LG stat.ML
Comments: 102 pages, 8 figures, 41 tables
\\
 Training algorithms, broadly construed, are an essential part of every deep
learning pipeline. Training algorithm improvements that speed up training
across a wide variety of workloads (e.g., better update rules, tuning
protocols, learning rate schedules, or data selection schemes) could save time,
save computational resources, and lead to better, more accurate, models.
Unfortunately, as a community, we are currently unable to reliably identify
training algorithm improvements, or even determine the state-of-the-art
training algorithm. In this work, using concrete experiments, we argue that
real progress in speeding up training requires new benchmarks that resolve
three basic challenges faced by empirical comparisons of training algorithms:
(1) how to decide when training is complete and precisely measure training
time, (2) how to handle the sensitivity of measurements to exact workload
details, and (3) how to fairly compare algorithms that require hyperparameter
tuning. In order to address these challenges, we introduce a new, competitive,
time-to-result benchmark using multiple workloads running on fixed hardware,
the AlgoPerf: Training Algorithms benchmark. Our benchmark includes a set of
workload variants that make it possible to detect benchmark submissions that
are more robust to workload changes than current widely-used methods. Finally,
we evaluate baseline submissions constructed using various optimizers that
represent current practice, as well as other optimizers that have recently
received attention in the literature. These baseline results collectively
demonstrate the feasibility of our benchmark, show that non-trivial gaps
between methods exist, and set a provisional state-of-the-art for future
benchmark submissions to try and surpass.
\\ ( https://arxiv.org/abs/2306.07179 ,  1288kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07180
Date: Mon, 12 Jun 2023 15:26:44 GMT   (2366kb,D)

Title: Diffusion Models for Black-Box Optimization
Authors: Siddarth Krishnamoorthy, Satvik Mehul Mashkaria, Aditya Grover
Categories: cs.LG
Comments: International Conference on Machine Learning 2023
\\
 The goal of offline black-box optimization (BBO) is to optimize an expensive
black-box function using a fixed dataset of function evaluations. Prior works
consider forward approaches that learn surrogates to the black-box function and
inverse approaches that directly map function values to corresponding points in
the input domain of the black-box function. These approaches are limited by the
quality of the offline dataset and the difficulty in learning one-to-many
mappings in high dimensions, respectively. We propose Denoising Diffusion
Optimization Models (DDOM), a new inverse approach for offline black-box
optimization based on diffusion models. Given an offline dataset, DDOM learns a
conditional generative model over the domain of the black-box function
conditioned on the function values. We investigate several design choices in
DDOM, such as re-weighting the dataset to focus on high function values and the
use of classifier-free guidance at test-time to enable generalization to
function values that can even exceed the dataset maxima. Empirically, we
conduct experiments on the Design-Bench benchmark and show that DDOM achieves
results competitive with state-of-the-art baselines.
\\ ( https://arxiv.org/abs/2306.07180 ,  2366kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07188
Date: Mon, 12 Jun 2023 15:44:58 GMT   (2636kb,D)

Title: Fair Learning to Rank with Distribution-free Risk Control
Authors: Ruocheng Guo, Jean-Fran\c{c}ois Ton, Yang Liu
Categories: cs.LG cs.CY cs.IR
Comments: 12 pages, 4 figures
\\
 Learning to Rank (LTR) methods are vital in online economies, affecting users
and item providers. Fairness in LTR models is crucial to allocate exposure
proportionally to item relevance. The deterministic ranking model can lead to
unfair exposure distribution when items with the same relevance receive
slightly different scores. Stochastic LTR models, incorporating the
Plackett-Luce (PL) model, address fairness issues but have limitations in
computational cost and performance guarantees. To overcome these limitations,
we propose FairLTR-RC, a novel post-hoc model-agnostic method. FairLTR-RC
leverages a pretrained scoring function to create a stochastic LTR model,
eliminating the need for expensive training. Furthermore, FairLTR-RC provides
finite-sample guarantees on a user-specified utility using distribution-free
risk control framework. By additionally incorporating the Thresholded PL (TPL)
model, we are able to achieve an effective trade-off between utility and
fairness. Experimental results on several benchmark datasets demonstrate that
FairLTR-RC significantly improves fairness in widely-used deterministic LTR
models while guaranteeing a specified level of utility.
\\ ( https://arxiv.org/abs/2306.07188 ,  2636kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07212
Date: Mon, 12 Jun 2023 16:17:04 GMT   (5655kb,D)

Title: Polyhedral Complex Extraction from ReLU Networks using Edge Subdivision
Authors: Arturs Berzins
Categories: cs.LG
\\
 A neural network consisting of piecewise affine building blocks, such as
fully-connected layers and ReLU activations, is itself a piecewise affine
function supported on a polyhedral complex. This complex has been previously
studied to characterize theoretical properties of neural networks, but, in
practice, extracting it remains a challenge due to its high combinatorial
complexity. A natural idea described in previous works is to subdivide the
regions via intersections with hyperplanes induced by each neuron. However, we
argue that this view leads to computational redundancy. Instead of regions, we
propose to subdivide edges, leading to a novel method for polyhedral complex
extraction. A key to this are sign-vectors, which encode the combinatorial
structure of the complex. Our approach allows to use standard tensor operations
on a GPU, taking seconds for millions of cells on a consumer grade machine.
Motivated by the growing interest in neural shape representation, we use the
speed and differentiability of our method to optimize geometric properties of
the complex. The code is available at
https://github.com/arturs-berzins/relu_edge_subdivision .
\\ ( https://arxiv.org/abs/2306.07212 ,  5655kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07215
Date: Mon, 12 Jun 2023 16:20:36 GMT   (580kb,D)

Title: Efficient Quantization-aware Training with Adaptive Coreset Selection
Authors: Xijie Huang, Zechun Liu, Shih-Yang Liu, Kwang-Ting Cheng
Categories: cs.LG cs.AI cs.CV
Comments: Code: https://github.com/HuangOwen/QAT-ACS
\\
 The expanding model size and computation of deep neural networks (DNNs) have
increased the demand for efficient model deployment methods. Quantization-aware
training (QAT) is a representative model compression method to leverage
redundancy in weights and activations. However, most existing QAT methods
require end-to-end training on the entire dataset, which suffers from long
training time and high energy costs. Coreset selection, aiming to improve data
efficiency utilizing the redundancy of training data, has also been widely used
for efficient training. In this work, we propose a new angle through the
coreset selection to improve the training efficiency of quantization-aware
training. Based on the characteristics of QAT, we propose two metrics: error
vector score and disagreement score, to quantify the importance of each sample
during training. Guided by these two metrics of importance, we proposed a
quantization-aware adaptive coreset selection (ACS) method to select the data
for the current training epoch. We evaluate our method on various networks
(ResNet-18, MobileNetV2), datasets(CIFAR-100, ImageNet-1K), and under different
quantization settings. Compared with previous coreset selection methods, our
method significantly improves QAT performance with different dataset fractions.
Our method can achieve an accuracy of 68.39% of 4-bit quantized ResNet-18 on
the ImageNet-1K dataset with only a 10% subset, which has an absolute gain of
4.24% compared to the baseline.
\\ ( https://arxiv.org/abs/2306.07215 ,  580kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07218
Date: Mon, 12 Jun 2023 16:24:01 GMT   (2732kb,D)

Title: A Protocol for Continual Explanation of SHAP
Authors: Andrea Cossu, Francesco Spinnato, Riccardo Guidotti, Davide Bacciu
Categories: cs.LG cs.AI
Comments: ESANN 2023, 6 pages
\\
 Continual Learning trains models on a stream of data, with the aim of
learning new information without forgetting previous knowledge. Given the
dynamic nature of such environments, explaining the predictions of these models
can be challenging. We study the behavior of SHAP values explanations in
Continual Learning and propose an evaluation protocol to robustly assess the
change of explanations in Class-Incremental scenarios. We observed that, while
Replay strategies enforce the stability of SHAP values in
feedforward/convolutional models, they are not able to do the same with
fully-trained recurrent models. We show that alternative recurrent approaches,
like randomized recurrent models, are more effective in keeping the
explanations stable over time.
\\ ( https://arxiv.org/abs/2306.07218 ,  2732kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07221
Date: Mon, 12 Jun 2023 16:28:11 GMT   (100kb)

Title: Convergence of mean-field Langevin dynamics: Time and space
 discretization, stochastic gradient, and variance reduction
Authors: Taiji Suzuki and Denny Wu and Atsushi Nitanda
Categories: cs.LG stat.ML
Comments: 37 pages
\\
 The mean-field Langevin dynamics (MFLD) is a nonlinear generalization of the
Langevin dynamics that incorporates a distribution-dependent drift, and it
naturally arises from the optimization of two-layer neural networks via (noisy)
gradient descent. Recent works have shown that MFLD globally minimizes an
entropy-regularized convex functional in the space of measures. However, all
prior analyses assumed the infinite-particle or continuous-time limit, and
cannot handle stochastic gradient updates. We provide an general framework to
prove a uniform-in-time propagation of chaos for MFLD that takes into account
the errors due to finite-particle approximation, time-discretization, and
stochastic gradient approximation. To demonstrate the wide applicability of
this framework, we establish quantitative convergence rate guarantees to the
regularized global optimal solution under (i) a wide range of learning problems
such as neural network in the mean-field regime and MMD minimization, and (ii)
different gradient estimators including SGD and SVRG. Despite the generality of
our results, we achieve an improved convergence rate in both the SGD and SVRG
settings when specialized to the standard Langevin dynamics.
\\ ( https://arxiv.org/abs/2306.07221 ,  100kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07255
Date: Mon, 12 Jun 2023 17:25:12 GMT   (1737kb,D)

Title: Conditional Matrix Flows for Gaussian Graphical Models
Authors: Marcello Massimo Negri, F. Arend Torres and Volker Roth
Categories: cs.LG stat.ML
\\
 Studying conditional independence structure among many variables with few
observations is a challenging task. Gaussian Graphical Models (GGMs) tackle
this problem by encouraging sparsity in the precision matrix through an $l_p$
regularization with $p\leq1$. However, since the objective is highly non-convex
for sub-$l_1$ pseudo-norms, most approaches rely on the $l_1$ norm. In this
case frequentist approaches allow to elegantly compute the solution path as a
function of the shrinkage parameter $\lambda$. Instead of optimizing the
penalized likelihood, the Bayesian formulation introduces a Laplace prior on
the precision matrix. However, posterior inference for different $\lambda$
values requires repeated runs of expensive Gibbs samplers. We propose a very
general framework for variational inference in GGMs that unifies the benefits
of frequentist and Bayesian frameworks. Specifically, we propose to approximate
the posterior with a matrix-variate Normalizing Flow defined on the space of
symmetric positive definite matrices. As a key improvement on previous work, we
train a continuum of sparse regression models jointly for all regularization
parameters $\lambda$ and all $l_p$ norms, including non-convex sub-$l_1$
pseudo-norms. This is achieved by conditioning the flow on $p>0$ and on the
shrinkage parameter $\lambda$. We have then access with one model to (i) the
evolution of the posterior for any $\lambda$ and for any $l_p$ (pseudo-) norms,
(ii) the marginal log-likelihood for model selection, and (iii) we can recover
the frequentist solution paths as the MAP, which is obtained through simulated
annealing.
\\ ( https://arxiv.org/abs/2306.07255 ,  1737kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07261
Date: Mon, 12 Jun 2023 17:44:15 GMT   (10754kb,D)

Title: Unprocessing Seven Years of Algorithmic Fairness
Authors: Andr\'e F. Cruz, Moritz Hardt
Categories: cs.LG cs.CY
\\
 Seven years ago, researchers proposed a postprocessing method to equalize the
error rates of a model across different demographic groups. The work launched
hundreds of papers purporting to improve over the postprocessing baseline. We
empirically evaluate these claims through thousands of model evaluations on
several tabular datasets. We find that the fairness-accuracy Pareto frontier
achieved by postprocessing contains all other methods we were feasibly able to
evaluate. In doing so, we address two common methodological errors that have
confounded previous observations. One relates to the comparison of methods with
different unconstrained base models. The other concerns methods achieving
different levels of constraint relaxation. At the heart of our study is a
simple idea we call unprocessing that roughly corresponds to the inverse of
postprocessing. Unprocessing allows for a direct comparison of methods using
different underlying models and levels of relaxation. Interpreting our
findings, we recall a widely overlooked theoretical argument, present seven
years ago, that accurately predicted what we observe.
\\ ( https://arxiv.org/abs/2306.07261 ,  10754kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07266
Date: Mon, 12 Jun 2023 17:52:39 GMT   (44881kb,D)

Title: Operator Learning with Neural Fields: Tackling PDEs on General
 Geometries
Authors: Louis Serrano, Lise Le Boudec, Armand Kassa\"i Koupa\"i, Thomas X
 Wang, Yuan Yin, Jean-No\"el Vittaut, Patrick Gallinari
Categories: cs.LG cs.AI
\\
 Machine learning approaches for solving partial differential equations
require learning mappings between function spaces. While convolutional or graph
neural networks are constrained to discretized functions, neural operators
present a promising milestone toward mapping functions directly. Despite
impressive results they still face challenges with respect to the domain
geometry and typically rely on some form of discretization. In order to
alleviate such limitations, we present CORAL, a new method that leverages
coordinate-based networks for solving PDEs on general geometries. CORAL is
designed to remove constraints on the input mesh, making it applicable to any
spatial sampling and geometry. Its ability extends to diverse problem domains,
including PDE solving, spatio-temporal forecasting, and inverse problems like
geometric design. CORAL demonstrates robust performance across multiple
resolutions and performs well in both convex and non-convex domains, surpassing
or performing on par with state-of-the-art models.
\\ ( https://arxiv.org/abs/2306.07266 ,  44881kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07273
Date: Mon, 12 Jun 2023 17:57:05 GMT   (314kb,D)

Title: Gaussian Membership Inference Privacy
Authors: Tobias Leemann, Martin Pawelczyk, Gjergji Kasneci
Categories: cs.LG cs.CR stat.ML
Comments: The first two authors contributed equally
\\
 We propose a new privacy notion called $f$-Membership Inference Privacy
($f$-MIP), which explicitly considers the capabilities of realistic adversaries
under the membership inference attack threat model. By doing so $f$-MIP offers
interpretable privacy guarantees and improved utility (e.g., better
classification accuracy). Our novel theoretical analysis of likelihood
ratio-based membership inference attacks on noisy stochastic gradient descent
(SGD) results in a parametric family of $f$-MIP guarantees that we refer to as
$\mu$-Gaussian Membership Inference Privacy ($\mu$-GMIP). Our analysis
additionally yields an analytical membership inference attack that offers
distinct advantages over previous approaches. First, unlike existing methods,
our attack does not require training hundreds of shadow models to approximate
the likelihood ratio. Second, our analytical attack enables straightforward
auditing of our privacy notion $f$-MIP. Finally, our analysis emphasizes the
importance of various factors, such as hyperparameters (e.g., batch size,
number of model parameters) and data specific characteristics in controlling an
attacker's success in reliably inferring a given point's membership to the
training set. We demonstrate the effectiveness of our method on models trained
across vision and tabular datasets.
\\ ( https://arxiv.org/abs/2306.07273 ,  314kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07277
Date: Mon, 12 Jun 2023 17:58:38 GMT   (401kb,D)

Title: Mathematical conjecture generation using machine intelligence
Authors: Challenger Mishra, Subhayan Roy Moulik, Rahul Sarkar
Categories: cs.LG
\\
 Conjectures have historically played an important role in the development of
pure mathematics. We propose a systematic approach to finding abstract patterns
in mathematical data, in order to generate conjectures about mathematical
inequalities, using machine intelligence. We focus on strict inequalities of
type f < g and associate them with a vector space. By geometerising this space,
which we refer to as a conjecture space, we prove that this space is isomorphic
to a Banach manifold. We develop a structural understanding of this conjecture
space by studying linear automorphisms of this manifold and show that this
space admits several free group actions. Based on these insights, we propose an
algorithmic pipeline to generate novel conjectures using geometric gradient
descent, where the metric is informed by the invariances of the conjecture
space. As proof of concept, we give a toy algorithm to generate novel
conjectures about the prime counting function and diameters of Cayley graphs of
non-abelian simple groups. We also report private communications with
colleagues in which some conjectures were proved, and highlight that some
conjectures generated using this procedure are still unproven. Finally, we
propose a pipeline of mathematical discovery in this space and highlight the
importance of domain expertise in this pipeline.
\\ ( https://arxiv.org/abs/2306.07277 ,  401kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07284
Date: Mon, 12 Jun 2023 17:59:50 GMT   (1374kb,D)

Title: No Free Lunch: The Hazards of Over-Expressive Representations in Anomaly
 Detection
Authors: Tal Reiss, Niv Cohen, Yedid Hoshen
Categories: cs.LG cs.CV
\\
 Anomaly detection methods, powered by deep learning, have recently been
making significant progress, mostly due to improved representations. It is
tempting to hypothesize that anomaly detection can improve indefinitely by
increasing the scale of our networks, making their representations more
expressive. In this paper, we provide theoretical and empirical evidence to the
contrary. In fact, we empirically show cases where very expressive
representations fail to detect even simple anomalies when evaluated beyond the
well-studied object-centric datasets. To investigate this phenomenon, we begin
by introducing a novel theoretical toy model for anomaly detection performance.
The model uncovers a fundamental trade-off between representation sufficiency
and over-expressivity. It provides evidence for a no-free-lunch theorem in
anomaly detection stating that increasing representation expressivity will
eventually result in performance degradation. Instead, guidance must be
provided to focus the representation on the attributes relevant to the
anomalies of interest. We conduct an extensive empirical investigation
demonstrating that state-of-the-art representations often suffer from
over-expressivity, failing to detect many types of anomalies. Our investigation
demonstrates how this over-expressivity impairs image anomaly detection in
practical settings. We conclude with future directions for mitigating this
issue.
\\ ( https://arxiv.org/abs/2306.07284 ,  1374kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06236
Date: Fri, 9 Jun 2023 20:12:02 GMT   (9407kb,D)

Title: iPLAN: Intent-Aware Planning in Heterogeneous Traffic via Distributed
 Multi-Agent Reinforcement Learning
Authors: Xiyang Wu, Rohan Chandra, Tianrui Guan, Amrit Singh Bedi, Dinesh
 Manocha
Categories: cs.MA cs.LG cs.RO
\\
 Navigating safely and efficiently in dense and heterogeneous traffic
scenarios is challenging for autonomous vehicles (AVs) due to their inability
to infer the behaviors or intentions of nearby drivers. In this work, we
propose a distributed multi-agent reinforcement learning (MARL) algorithm with
trajectory and intent prediction in dense and heterogeneous traffic scenarios.
Our approach for intent-aware planning, iPLAN, allows agents to infer nearby
drivers' intents solely from their local observations. We model two distinct
incentives for agents' strategies: Behavioral incentives for agents' long-term
planning based on their driving behavior or personality; Instant incentives for
agents' short-term planning for collision avoidance based on the current
traffic state. We design a two-stream inference module that allows agents to
infer their opponents' incentives and incorporate their inferred information
into decision-making. We perform experiments on two simulation environments,
Non-Cooperative Navigation and Heterogeneous Highway. In Heterogeneous Highway,
results show that, compared with centralized MARL baselines such as QMIX and
MAPPO, our method yields a 4.0% and 35.7% higher episodic reward in mild and
chaotic traffic, with 48.1% higher success rate and 80.6% longer survival time
in chaotic traffic. We also compare with a decentralized baseline IPPO and
demonstrate a higher episodic reward of 9.2% and 10.3% in mild traffic and
chaotic traffic, 25.3% higher success rate, and 13.7% longer survival time.
\\ ( https://arxiv.org/abs/2306.06236 ,  9407kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06382
Date: Sat, 10 Jun 2023 08:41:57 GMT   (2416kb,D)

Title: Multi-agent Exploration with Sub-state Entropy Estimation
Authors: Jian Tao and Yang Zhang and Yangkun Chen and Xiu Li
Categories: cs.MA
\\
 Researchers have integrated exploration techniques into multi-agent
reinforcement learning (MARL) algorithms, drawing on their remarkable success
in deep reinforcement learning. Nonetheless, exploration in MARL presents a
more substantial challenge, as agents need to coordinate their efforts in order
to achieve comprehensive state coverage. Reaching a unanimous agreement on
which kinds of states warrant exploring can be a struggle for agents in this
context. We introduce \textbf{M}ulti-agent \textbf{E}xploration based on
\textbf{S}ub-state \textbf{E}ntropy (MESE) to address this limitation. This
novel approach incentivizes agents to explore states cooperatively by directing
them to achieve consensus via an extra team reward. Calculating the additional
reward is based on the novelty of the current sub-state that merits cooperative
exploration. MESE employs a conditioned entropy approach to select the
sub-state, using particle-based entropy estimation to calculate the entropy.
MESE is a plug-and-play module that can be seamlessly integrated into most
existing MARL algorithms, which makes it a highly effective tool for
reinforcement learning. Our experiments demonstrate that MESE can substantially
improve the MAPPO's performance on various tasks in the StarCraft multi-agent
challenge (SMAC).
\\ ( https://arxiv.org/abs/2306.06382 ,  2416kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06544
Date: Sun, 11 Jun 2023 00:02:18 GMT   (4395kb,D)

Title: Herd's Eye View: Improving Game AI Agent Learning with Collaborative
 Perception
Authors: Andrew Nash, Andrew Vardy, David Churchill
Categories: cs.MA
\\
 We present a novel paradigm named Herd's Eye View (HEV) that adopts a global
perspective derived from multiple agents to boost decision-making capabilities
of reinforcement learning (RL) agents in multi-agent environments, specifically
in the context of game AI. The HEV approach utilizes cooperative perception to
empower RL agents with a global reasoning ability, enhancing their
decision-making. We demonstrate the effectiveness of the HEV within simulated
game environments and highlight its superior performance compared to
traditional ego-centric perception models. This work contributes to cooperative
perception and multi-agent reinforcement learning by offering a more realistic
and efficient perspective for global coordination and decision-making within
game environments. Moreover, our approach promotes broader AI applications
beyond gaming by addressing constraints faced by AI outside of this field. The
code is available on GitHub.
\\ ( https://arxiv.org/abs/2306.06544 ,  4395kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06120
Date: Mon, 5 Jun 2023 16:12:55 GMT   (19216kb,D)

Title: Using R-functions to Control the Shape of Soft Robots
Authors: Declan Mulroy, Esteban Lopez, Matthew Spenko, and Ankit Srivastava
Categories: cs.RO
\\
 In this paper, we introduce a new approach for soft robot shape formation and
morphing using approximate distance fields. The method uses concepts from
constructive solid geometry, R-functions, to construct an approximate distance
function to the boundary of a domain in $\Re^d$. The gradients of the
R-functions can then be used to generate control algorithms for shape formation
tasks for soft robots. By construction, R-functions are smooth and convex
everywhere, possess precise differential properties, and easily extend from
$\Re^2$ to $\Re^3$ if needed. Furthermore, R-function theory provides a
straightforward method to creating composite distance functions for any desired
shape by combining subsets of distance functions. The process is highly
efficient since the shape description is an analytical expression, and in this
sense, it is better than competing control algorithms such as those based on
potential fields. Although the method could also apply to swarm robots, in this
paper it is applied to soft robots to demonstrate shape formation and morphing
in 2-D (simulation and experimentation) and 3-D (simulation).
\\ ( https://arxiv.org/abs/2306.06120 ,  19216kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06192
Date: Fri, 9 Jun 2023 18:45:15 GMT   (40320kb,D)

Title: Ada-NAV: Adaptive Trajectory-Based Sample Efficient Policy Learning for
 Robotic Navigation
Authors: Bhrij Patel, Kasun Weerakoon, Wesley A. Suttle, Alec Koppel, Brian M.
 Sadler, Amrit Singh Bedi and Dinesh Manocha
Categories: cs.RO cs.AI cs.LG
Comments: 14 pages, 7 figures, 2 tables
\\
 Reinforcement learning methods, while effective for learning robotic
navigation strategies, are known to be highly sample inefficient. This sample
inefficiency comes in part from not suitably balancing the explore-exploit
dilemma, especially in the presence of non-stationarity, during policy
optimization. To incorporate a balance of exploration-exploitation for sample
efficiency, we propose Ada-NAV, an adaptive trajectory length scheme where the
length grows as a policy's randomness, represented by its Shannon or
differential entropy, decreases. Our adaptive trajectory length scheme
emphasizes exploration at the beginning of training due to more frequent
gradient updates and emphasizes exploitation later on with longer trajectories.
In gridworld, simulated robotic environments, and real-world robotic
experiments, we demonstrate the merits of the approach over constant and
randomly sampled trajectory lengths in terms of performance and sample
efficiency. For a fixed sample budget, Ada-NAV results in an 18% increase in
navigation success rate, a 20-38% decrease in the navigation path length, and
9.32% decrease in the elevation cost compared to the policies obtained by the
other methods. We also demonstrate that Ada-NAV can be transferred and
integrated into a Clearpath Husky robot without significant performance
degradation.
\\ ( https://arxiv.org/abs/2306.06192 ,  40320kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06344
Date: Sat, 10 Jun 2023 05:20:30 GMT   (3752kb,D)

Title: Language-Guided Traffic Simulation via Scene-Level Diffusion
Authors: Ziyuan Zhong, Davis Rempe, Yuxiao Chen, Boris Ivanovic, Yulong Cao,
 Danfei Xu, Marco Pavone, Baishakhi Ray
Categories: cs.RO cs.AI cs.LG
\\
 Realistic and controllable traffic simulation is a core capability that is
necessary to accelerate autonomous vehicle (AV) development. However, current
approaches for controlling learning-based traffic models require significant
domain expertise and are difficult for practitioners to use. To remedy this, we
present CTG++, a scene-level conditional diffusion model that can be guided by
language instructions. Developing this requires tackling two challenges: the
need for a realistic and controllable traffic model backbone, and an effective
method to interface with a traffic model using language. To address these
challenges, we first propose a scene-level diffusion model equipped with a
spatio-temporal transformer backbone, which generates realistic and
controllable traffic. We then harness a large language model (LLM) to convert a
user's query into a loss function, guiding the diffusion model towards
query-compliant generation. Through comprehensive evaluation, we demonstrate
the effectiveness of our proposed method in generating realistic,
query-compliant traffic simulations.
\\ ( https://arxiv.org/abs/2306.06344 ,  3752kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06363
Date: Sat, 10 Jun 2023 06:50:39 GMT   (1366kb,D)

Title: Probabilistic Visibility-Aware Trajectory Planning for Target Tracking
 in Cluttered Environments
Authors: Han Gao, Pengying Wu, Yao Su, Kangjie Zhou, Ji Ma, Hangxin Liu, Chang
 Liu
Categories: cs.RO
\\
 Target tracking with a mobile robot has numerous significant applications in
both civilian and military. Practical challenges such as limited field-of-view,
obstacle occlusion, and system uncertainty may all adversely affect tracking
performance, yet few existing works can simultaneously tackle these
limitations. To bridge the gap, we introduce the concept of belief-space
probability of detection (BPOD) to measure the predictive visibility of the
target under stochastic robot and target states. An Extended Kalman Filter
variant incorporating BPOD is developed to predict target belief state under
uncertain visibility within the planning horizon. Furthermore, we propose a
computationally efficient algorithm to uniformly calculate both BPOD and the
chance-constrained collision risk by utilizing linearized signed distance
function (SDF), and then design a two-stage strategy for lightweight
calculation of SDF in sequential convex programming. Building upon these
treatments, we develop a real-time, non-myopic trajectory planner for
visibility-aware and safe target tracking in the presence of system
uncertainty. The effectiveness of the proposed approach is verified by both
simulations and real-world experiments.
\\ ( https://arxiv.org/abs/2306.06363 ,  1366kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06401
Date: Sat, 10 Jun 2023 10:03:39 GMT   (1788kb,D)

Title: Long-term Microscopic Traffic Simulation with History-Masked Multi-agent
 Imitation Learning
Authors: Ke Guo, Wei Jing, Lingping Gao, Weiwei Liu, and Weizi Li, Jia Pan
Categories: cs.RO
\\
 A realistic long-term microscopic traffic simulator is necessary for
understanding how microscopic changes affect traffic patterns at a larger
scale. Traditional simulators that model human driving behavior with heuristic
rules often fail to achieve accurate simulations due to real-world traffic
complexity. To overcome this challenge, researchers have turned to neural
networks, which are trained through imitation learning from human driver
demonstrations. However, existing learning-based microscopic simulators often
fail to generate stable long-term simulations due to the \textit{covariate
shift} issue. To address this, we propose a history-masked multi-agent
imitation learning method that removes all vehicles' historical trajectory
information and applies perturbation to their current positions during
learning. We apply our approach specifically to the urban traffic simulation
problem and evaluate it on the real-world large-scale pNEUMA dataset, achieving
better short-term microscopic and long-term macroscopic similarity to
real-world data than state-of-the-art baselines.
\\ ( https://arxiv.org/abs/2306.06401 ,  1788kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06423
Date: Sat, 10 Jun 2023 12:29:23 GMT   (34899kb,D)

Title: Bayesian and Neural Inference on LSTM-based Object Recognition from
 Tactile and Kinesthetic Information
Authors: Francisco Pastor (1), Jorge Garc\'ia-Gonz\'alez (2), Juan M. Gandarias
 (1), Daniel Medina (3), Pau Closas (4), Alfonso J. Garc\'ia-Cerezo (1),
 Jes\'us M. G\'omez-de-Gabriel (1) ((1) Robotics and Mechatronics Group,
 University of Malaga, Spain, (2) Department of Computer Languages and
 Computer Science, University of Malaga, Spain, (3) Institute of
 Communications and Navigation, German Aerospace Center (DLR), Germany, (4)
 Department of Electrical and Computer Engineering, Northeastern University,
 Boston, USA)
Categories: cs.RO cs.AI
DOI: 10.1109/LRA.2020.3038377
\\
 Recent advances in the field of intelligent robotic manipulation pursue
providing robotic hands with touch sensitivity. Haptic perception encompasses
the sensing modalities encountered in the sense of touch (e.g., tactile and
kinesthetic sensations). This letter focuses on multimodal object recognition
and proposes analytical and data-driven methodologies to fuse tactile- and
kinesthetic-based classification results. The procedure is as follows: a
three-finger actuated gripper with an integrated high-resolution tactile sensor
performs squeeze-and-release Exploratory Procedures (EPs). The tactile images
and kinesthetic information acquired using angular sensors on the finger joints
constitute the time-series datasets of interest. Each temporal dataset is fed
to a Long Short-term Memory (LSTM) Neural Network, which is trained to classify
in-hand objects. The LSTMs provide an estimation of the posterior probability
of each object given the corresponding measurements, which after fusion allows
to estimate the object through Bayesian and Neural inference approaches. An
experiment with 36-classes is carried out to evaluate and compare the
performance of the fused, tactile, and kinesthetic perception systems.The
results show that the Bayesian-based classifiers improves capabilities for
object recognition and outperforms the Neural-based approach.
\\ ( https://arxiv.org/abs/2306.06423 ,  34899kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06455
Date: Sat, 10 Jun 2023 14:41:05 GMT   (4434kb,D)

Title: Scalable Rail Planning and Replanning with Soft Deadlines
Authors: Zhe Chen, Jiaoyang Li, Daniel Harabor, Peter J. Stuckey
Categories: cs.RO cs.MA
\\
 The Flatland Challenge, which was first held in 2019 and reported in NeurIPS
2020, is designed to answer the question: How to efficiently manage dense
traffic on complex rail networks? Considering the significance of punctuality
in real-world railway network operation and the fact that fast passenger trains
share the network with slow freight trains, Flatland version 3 introduces
trains with different speeds and scheduling time windows. This paper introduces
the Flatland 3 problem definitions and extends an award-winning MAPF-based
software, which won the NeurIPS 2020 competition, to efficiently solve Flatland
3 problems. The resulting system won the Flatland 3 competition. We designed a
new priority ordering for initial planning, a new neighbourhood selection
strategy for efficient solution quality improvement with Multi-Agent Path
Finding via Large Neighborhood Search(MAPF-LNS), and use MAPF-LNS for partially
replanning the trains influenced by malfunction.
\\ ( https://arxiv.org/abs/2306.06455 ,  4434kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06465
Date: Sat, 10 Jun 2023 15:29:14 GMT   (14531kb,D)

Title: Simultaneous Trajectory Optimization and Contact Selection for
 Multi-Modal Manipulation Planning
Authors: Mengchao Zhang, Devesh K. Jha, Arvind U. Raghunathan, Kris Hauser
Categories: cs.RO
Comments: 10 pages, 9 figures, to be published in RSS 2023
\\
 Complex dexterous manipulations require switching between prehensile and
non-prehensile grasps, and sliding and pivoting the object against the
environment. This paper presents a manipulation planner that is able to reason
about diverse changes of contacts to discover such plans. It implements a
hybrid approach that performs contact-implicit trajectory optimization for
pivoting and sliding manipulation primitives and sampling-based planning to
change between manipulation primitives and target object poses. The
optimization method, simultaneous trajectory optimization and contact selection
(STOCS), introduces an infinite programming framework to dynamically select
from contact points and support forces between the object and environment
during a manipulation primitive. To sequence manipulation primitives, a
sampling-based tree-growing planner uses STOCS to construct a manipulation
tree. We show that by using a powerful trajectory optimizer, the proposed
planner can discover multi-modal manipulation trajectories involving grasping,
sliding, and pivoting within a few dozen samples. The resulting trajectories
are verified to enable a 6 DoF manipulator to manipulate physical objects
successfully.
\\ ( https://arxiv.org/abs/2306.06465 ,  14531kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06489
Date: Sat, 10 Jun 2023 17:08:48 GMT   (24543kb,D)

Title: On Robot Grasp Learning Using Equivariant Models
Authors: Xupeng Zhu, Dian Wang, Guanang Su, Ondrej Biza, Robin Walters and
 Robert Platt
Categories: cs.RO cs.AI
Comments: Accepted in Autonomous Robot. arXiv admin note: substantial text
 overlap with arXiv:2202.09468
\\
 Real-world grasp detection is challenging due to the stochasticity in grasp
dynamics and the noise in hardware. Ideally, the system would adapt to the real
world by training directly on physical systems. However, this is generally
difficult due to the large amount of training data required by most grasp
learning models. In this paper, we note that the planar grasp function is
$\SE(2)$-equivariant and demonstrate that this structure can be used to
constrain the neural network used during learning. This creates an inductive
bias that can significantly improve the sample efficiency of grasp learning and
enable end-to-end training from scratch on a physical robot with as few as
$600$ grasp attempts. We call this method Symmetric Grasp learning (SymGrasp)
and show that it can learn to grasp ``from scratch'' in less that 1.5 hours of
physical robot time.
\\ ( https://arxiv.org/abs/2306.06489 ,  24543kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06520
Date: Sat, 10 Jun 2023 21:01:18 GMT   (174kb,D)

Title: Learning optimal controllers: a dynamical motion primitive approach
Authors: Hugo T. M. Kussaba, Abdalla Swikir, Fan Wu, Anastasija Demerdjieva,
 Gitta Kutyniok, Sami Haddadin
Categories: cs.RO math.OC
Comments: This work has been accepted to the 22nd IFAC World Congress
\\
 Real-time computation of optimal control is a challenging problem and, to
solve this difficulty, many frameworks proposed to use learning techniques to
learn (possibly sub-optimal) controllers and enable their usage in an online
fashion. Among these techniques, the optimal motion framework is a simple, yet
powerful technique, that obtained success in many complex real-world
applications. The main idea of this approach is to take advantage of dynamic
motion primitives, a widely used tool in robotics to learn trajectories from
demonstrations. While usually these demonstrations come from humans, the
optimal motion framework is based on demonstrations coming from optimal
solutions, such as the ones obtained by numeric solvers. As usual in many
learning techniques, a drawback of this approach is that it is hard to estimate
the suboptimality of learned solutions, since finding easily computable and
non-trivial upper bounds to the error between an optimal solution and a learned
solution is, in general, unfeasible. However, we show in this paper that it is
possible to estimate this error for a broad class of problems. Furthermore, we
apply this estimation technique to achieve a novel and more efficient sampling
scheme to be used within the optimal motion framework, enabling the usage of
this framework in some scenarios where the computational resources are limited.
\\ ( https://arxiv.org/abs/2306.06520 ,  174kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06525
Date: Sat, 10 Jun 2023 21:31:19 GMT   (1277kb,D)

Title: Fast yet predictable braking manoeuvers for real-time robot control
Authors: Mazin Hamad, Jesus Gutierrez-Moreno, Hugo T. M. Kussaba, Nico
 Mansfeld, Saeed Abdolshah, Abdalla Swikir, Wolfram Burgard, Sami Haddadin
Categories: cs.RO math.OC
Comments: This work has been accepted to the 22nd IFAC World Congress
\\
 This paper proposes a framework for generating fast, smooth and predictable
braking manoeuvers for a controlled robot. The proposed framework integrates
two approaches to obtain feasible modal limits for designing braking
trajectories. The first approach is real-time capable but conservative
considering the usage of the available feasible actuator control region,
resulting in longer braking times. In contrast, the second approach maximizes
the used braking control inputs at the cost of requiring more time to evaluate
larger, feasible modal limits via optimization. Both approaches allow for
predicting the robot's stopping trajectory online. In addition, we also
formulated and solved a constrained, nonlinear final-time minimization problem
to find optimal torque inputs. The optimal solutions were used as a benchmark
to evaluate the performance of the proposed predictable braking framework. A
comparative study was compiled in simulation versus a classical optimal
controller on a 7-DoF robot arm with only three moving joints. The results
verified the effectiveness of our proposed framework and its integrated
approaches in achieving fast robot braking manoeuvers with accurate online
predictions of the stopping trajectories and distances under various braking
settings.
\\ ( https://arxiv.org/abs/2306.06525 ,  1277kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06527
Date: Sat, 10 Jun 2023 21:49:08 GMT   (13865kb,D)

Title: Contribution \`a l'Optimisation d'un Comportement Collectif pour un
 Groupe de Robots Autonomes
Authors: Amine Bendahmane
Categories: cs.RO cs.AI cs.MA
Comments: PhD Thesis (French version)
DOI: 10.13140/RG.2.2.34066.63684
\\
 This thesis studies the domain of collective robotics, and more particularly
the optimization problems of multirobot systems in the context of exploration,
path planning and coordination. It includes two contributions. The first one is
the use of the Butterfly Optimization Algorithm (BOA) to solve the Unknown Area
Exploration problem with energy constraints in dynamic environments. This
algorithm was never used for solving robotics problems before, as far as we
know. We proposed a new version of this algorithm called xBOA based on the
crossover operator to improve the diversity of the candidate solutions and
speed up the convergence of the algorithm. The second contribution is the
development of a new simulation framework for benchmarking dynamic incremental
problems in robotics such as exploration tasks. The framework is made in such a
manner to be generic to quickly compare different metaheuristics with minimum
modifications, and to adapt easily to single and multi-robot scenarios. Also,
it provides researchers with tools to automate their experiments and generate
visuals, which will allow them to focus on more important tasks such as
modeling new algorithms. We conducted a series of experiments that showed
promising results and allowed us to validate our approach and model.
\\ ( https://arxiv.org/abs/2306.06527 ,  13865kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06531
Date: Sat, 10 Jun 2023 21:58:29 GMT   (9815kb,D)

Title: AutoTAMP: Autoregressive Task and Motion Planning with LLMs as
 Translators and Checkers
Authors: Yongchao Chen, Jacob Arkin, Yang Zhang, Nicholas Roy, Chuchu Fan
Categories: cs.RO cs.CL cs.HC
Comments: 18 pages, 8 figures
\\
 For effective human-robot interaction, robots need to understand, plan, and
execute complex, long-horizon tasks described by natural language. The recent
and remarkable advances in large language models (LLMs) have shown promise for
translating natural language into robot action sequences for complex tasks.
However, many existing approaches either translate the natural language
directly into robot trajectories, or factor the inference process by
decomposing language into task sub-goals, then relying on a motion planner to
execute each sub-goal. When complex environmental and temporal constraints are
involved, inference over planning tasks must be performed jointly with motion
plans using traditional task-and-motion planning (TAMP) algorithms, making such
factorization untenable. Rather than using LLMs to directly plan task
sub-goals, we instead perform few-shot translation from natural language task
descriptions to an intermediary task representation that can then be consumed
by a TAMP algorithm to jointly solve the task and motion plan. To improve
translation, we automatically detect and correct both syntactic and semantic
errors via autoregressive re-prompting, resulting in significant improvements
in task completion. We show that our approach outperforms several methods using
LLMs as planners in complex task domains.
\\ ( https://arxiv.org/abs/2306.06531 ,  9815kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06543
Date: Sat, 10 Jun 2023 23:53:28 GMT   (10937kb,D)

Title: MANER: Multi-Agent Neural Rearrangement Planning of Objects in Cluttered
 Environments
Authors: Vivek Gupta, Praphpreet Dhir, Jeegn Dani, Ahmed H. Qureshi
Categories: cs.RO cs.AI cs.LG
Comments: The videos and supplementary material are available at
 https://sites.google.com/view/maner-supplementary
\\
 Object rearrangement is a fundamental problem in robotics with various
practical applications ranging from managing warehouses to cleaning and
organizing home kitchens. While existing research has primarily focused on
single-agent solutions, real-world scenarios often require multiple robots to
work together on rearrangement tasks. This paper proposes a comprehensive
learning-based framework for multi-agent object rearrangement planning,
addressing the challenges of task sequencing and path planning in complex
environments. The proposed method iteratively selects objects, determines their
relocation regions, and pairs them with available robots under kinematic
feasibility and task reachability for execution to achieve the target
arrangement. Our experiments on a diverse range of environments demonstrate the
effectiveness and robustness of the proposed framework. Furthermore, results
indicate improved performance in terms of traversal time and success rate
compared to baseline approaches.
\\ ( https://arxiv.org/abs/2306.06543 ,  10937kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06578
Date: Sun, 11 Jun 2023 03:59:26 GMT   (8330kb,D)

Title: Long-Term Autonomous Ocean Monitoring with Streaming Samples
Authors: Weizhe Chen and Lantao Liu
Categories: cs.RO
Comments: Proceedings of OCEANS 2019, SEATTLE
\\
 In the autonomous ocean monitoring task, the sampling robot moves in the
environment and accumulates data continuously. The widely adopted spatial
modeling method - standard Gaussian process (GP) regression - becomes
inadequate in processing the growing sensing data of a large size. To overcome
the computational challenge, this paper presents an environmental modeling
framework using a sparse variant of GP called streaming sparse GP (SSGP). The
SSGP is able to handle streaming data in an online and incremental manner, and
is therefore suitable for long-term autonomous environmental monitoring. The
SSGP summarizes the collected data using a small set of pseudo data points that
best represent the whole dataset, and updates the hyperparameters and pseudo
point locations in a streaming fashion, leading to high-quality approximation
of the underlying environmental model with significantly reduced computational
cost and memory demand.
\\ ( https://arxiv.org/abs/2306.06578 ,  8330kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06675
Date: Sun, 11 Jun 2023 13:22:25 GMT   (12175kb,D)

Title: Contact Reduction with Bounded Stiffness for Robust Sim-to-Real Transfer
 of Robot Assembly
Authors: Nghia Vuong and Quang-Cuong Pham
Categories: cs.RO
\\
 In sim-to-real Reinforcement Learning (RL), a policy is trained in a
simulated environment and then deployed on the physical system. The main
challenge of sim-to-real RL is to overcome the reality gap - the discrepancies
between the real world and its simulated counterpart. Using general geometric
representations, such as convex decomposition, triangular mesh, signed distance
field can improve simulation fidelity, and thus potentially narrow the reality
gap. Common to these approaches is that many contact points are generated for
geometrically-complex objects, which slows down simulation and may cause
numerical instability. Contact reduction methods address these issues by
limiting the number of contact points, but the validity of these methods for
sim-to-real RL has not been confirmed. In this paper, we present a contact
reduction method with bounded stiffness to improve the simulation accuracy. Our
experiments show that the proposed method critically enables training RL policy
for a tight-clearance double pin insertion task and successfully deploying the
policy on a rigid, position-controlled physical robot.
\\ ( https://arxiv.org/abs/2306.06675 ,  12175kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06679
Date: Sun, 11 Jun 2023 13:38:26 GMT   (2919kb,D)

Title: Reinforcement Learning with Parameterized Manipulation Primitives for
 Robotic Assembly
Authors: Nghia Vuong and Quang-Cuong Pham
Categories: cs.RO
\\
 A common theme in robot assembly is the adoption of Manipulation Primitives
as the atomic motion to compose assembly strategy, typically in the form of a
state machine or a graph. While this approach has shown great performance and
robustness in increasingly complex assembly tasks, the state machine has to be
engineered manually in most cases. Such hard-coded strategies will fail to
handle unexpected situations that are not considered in the design. To address
this issue, we propose to find dynamics sequence of manipulation primitives
through Reinforcement Learning. Leveraging parameterized manipulation
primitives, the proposed method greatly improves both assembly performance and
sample efficiency of Reinforcement Learning compared to a previous work using
non-parameterized manipulation primitives. In practice, our method achieves
good zero-shot sim-to-real performance on high-precision peg insertion tasks
with different geometry, clearance, and material.
\\ ( https://arxiv.org/abs/2306.06679 ,  2919kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06754
Date: Sun, 11 Jun 2023 19:47:46 GMT   (13952kb,D)

Title: Reinforcement Learning in Robotic Motion Planning by Combined
 Experience-based Planning and Self-Imitation Learning
Authors: Sha Luo, Lambert Schomaker
Categories: cs.RO cs.AI
\\
 High-quality and representative data is essential for both Imitation Learning
(IL)- and Reinforcement Learning (RL)-based motion planning tasks. For real
robots, it is challenging to collect enough qualified data either as
demonstrations for IL or experiences for RL due to safety considerations in
environments with obstacles. We target this challenge by proposing the
self-imitation learning by planning plus (SILP+) algorithm, which efficiently
embeds experience-based planning into the learning architecture to mitigate the
data-collection problem. The planner generates demonstrations based on
successfully visited states from the current RL policy, and the policy improves
by learning from these demonstrations. In this way, we relieve the demand for
human expert operators to collect demonstrations required by IL and improve the
RL performance as well. Various experimental results show that SILP+ achieves
better training efficiency higher and more stable success rate in complex
motion planning tasks compared to several other methods. Extensive tests on
physical robots illustrate the effectiveness of SILP+ in a physical setting.
\\ ( https://arxiv.org/abs/2306.06754 ,  13952kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06766
Date: Sun, 11 Jun 2023 20:33:22 GMT   (8055kb,D)

Title: Generalizable Wireless Navigation through Physics-Informed Reinforcement
 Learning in Wireless Digital Twin
Authors: Mingsheng Yin, Tao Li, Haozhe Lei, Yaqi Hu, Sundeep Rangan, and
 Quanyan Zhu
Categories: cs.RO cs.LG
Comments: 19 pages, 12 figures
\\
 The growing focus on indoor robot navigation utilizing wireless signals has
stemmed from the capability of these signals to capture high-resolution angular
and temporal measurements. However, employing end-to-end generic reinforcement
learning (RL) for wireless indoor navigation (WIN) in initially unknown
environments remains a significant challenge, due to its limited generalization
ability and poor sample efficiency. At the same time, purely model-based
solutions, based on radio frequency propagation, are simple and generalizable,
but unable to find optimal decisions in complex environments. This work
proposes a novel physics-informed RL (PIRL) were a standard
distance-to-target-based cost along with physics-informed terms on the optimal
trajectory. The proposed PIRL is evaluated using a wireless digital twin (WDT)
built upon simulations of a large class of indoor environments from the AI
Habitat dataset augmented with electromagnetic radiation (EM) simulation for
wireless signals. It is shown that the PIRL significantly outperforms both
standard RL and purely physics-based solutions in terms of generalizability and
performance. Furthermore, the resulting PIRL policy is explainable in that it
is empirically consistent with the physics heuristic.
\\ ( https://arxiv.org/abs/2306.06766 ,  8055kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06799
Date: Sun, 11 Jun 2023 22:52:08 GMT   (3918kb,D)

Title: On the Efficacy of 3D Point Cloud Reinforcement Learning
Authors: Zhan Ling, Yunchao Yao, Xuanlin Li, Hao Su
Categories: cs.RO cs.AI cs.LG
\\
 Recent studies on visual reinforcement learning (visual RL) have explored the
use of 3D visual representations. However, none of these work has
systematically compared the efficacy of 3D representations with 2D
representations across different tasks, nor have they analyzed 3D
representations from the perspective of agent-object / object-object
relationship reasoning. In this work, we seek answers to the question of when
and how do 3D neural networks that learn features in the 3D-native space
provide a beneficial inductive bias for visual RL. We specifically focus on 3D
point clouds, one of the most common forms of 3D representations. We
systematically investigate design choices for 3D point cloud RL, leading to the
development of a robust algorithm for various robotic manipulation and control
tasks. Furthermore, through comparisons between 2D image vs 3D point cloud RL
methods on both minimalist synthetic tasks and complex robotic manipulation
tasks, we find that 3D point cloud RL can significantly outperform the 2D
counterpart when agent-object / object-object relationship encoding is a key
factor.
\\ ( https://arxiv.org/abs/2306.06799 ,  3918kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06822
Date: Mon, 12 Jun 2023 02:12:23 GMT   (3754kb)

Title: Toward Terrain-based Navigation Using Side-scan Sonar
Authors: Ellen Davenport, Junsu Jang and Florian Meyer
Categories: cs.RO cs.SY eess.SY
Comments: 8 pages
\\
 This paper introduces a statistical model and corresponding sequential
Bayesian estimation method for terrain-based navigation using side-scan sonar
(SSS) data. The presented approach relies on slant range measurements extracted
from the received ping of a SSS. In particular, incorporating slant range
measurements to landmarks for navigation constrains the location and altitude
error of an autonomous platform in GPS-denied environments. The proposed
navigation filter consists of a prediction step based on the unscented
transform and an update step that relies on particle filtering. The SSS
measurement model aims to capture the highly nonlinear nature of SSS data while
maintaining reasonable computational requirements in the particle-based update
step. For our numerical results, we assume a scenario with a surface vehicle
that performs SSS and compass measurements. The simulated scenario is
consistent with our current hardware platform. We also discuss how the proposed
method can be extended to autonomous underwater vehicles (AUVs) in a
straightforward way and why the combination of SSS sensor and compass is
particularly suitable for small autonomous platforms.
\\ ( https://arxiv.org/abs/2306.06822 ,  3754kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06850
Date: Mon, 12 Jun 2023 03:50:50 GMT   (1065kb,D)

Title: Volume-DROID: A Real-Time Implementation of Volumetric Mapping with
 DROID-SLAM
Authors: Peter Stratton, Sandilya Sai Garimella, Ashwin Saxena, Nibarkavi
 Amutha, Emaad Gerami
Categories: cs.RO cs.CV
\\
 This paper presents Volume-DROID, a novel approach for Simultaneous
Localization and Mapping (SLAM) that integrates Volumetric Mapping and
Differentiable Recurrent Optimization-Inspired Design (DROID). Volume-DROID
takes camera images (monocular or stereo) or frames from a video as input and
combines DROID-SLAM, point cloud registration, an off-the-shelf semantic
segmentation network, and Convolutional Bayesian Kernel Inference (ConvBKI) to
generate a 3D semantic map of the environment and provide accurate localization
for the robot. The key innovation of our method is the real-time fusion of
DROID-SLAM and Convolutional Bayesian Kernel Inference (ConvBKI), achieved
through the introduction of point cloud generation from RGB-Depth frames and
optimized camera poses. This integration, engineered to enable efficient and
timely processing, minimizes lag and ensures effective performance of the
system. Our approach facilitates functional real-time online semantic mapping
with just camera images or stereo video input. Our paper offers an open-source
Python implementation of the algorithm, available at
https://github.com/peterstratton/Volume-DROID.
\\ ( https://arxiv.org/abs/2306.06850 ,  1065kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06862
Date: Mon, 12 Jun 2023 04:35:33 GMT   (5746kb,D)

Title: Saltation Matrices: The Essential Tool for Linearizing Hybrid Dynamical
 Systems
Authors: Nathan J. Kong, J. Joe Payne, James Zhu, and Aaron M. Johnson
Categories: cs.RO
\\
 Hybrid dynamical systems, i.e. systems that have both continuous and discrete
states, are ubiquitous in engineering, but are difficult to work with due to
their discontinuous transitions. For example, a robot leg is able to exert very
little control effort while it is in the air compared to when it is on the
ground. When the leg hits the ground, the penetrating velocity instantaneously
collapses to zero. These instantaneous changes in dynamics and discontinuities
(or jumps) in state make standard smooth tools for planning, estimation,
control, and learning difficult for hybrid systems. One of the key tools for
accounting for these jumps is called the saltation matrix. The saltation matrix
is the sensitivity update when a hybrid jump occurs and has been used in a
variety of fields including robotics, power circuits, and computational
neuroscience. This paper presents an intuitive derivation of the saltation
matrix and discusses what it captures, where it has been used in the past, how
it is used for linear and quadratic forms, how it is computed for rigid body
systems with unilateral constraints, and some of the structural properties of
the saltation matrix in these cases.
\\ ( https://arxiv.org/abs/2306.06862 ,  5746kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06900
Date: Mon, 12 Jun 2023 07:07:33 GMT   (1508kb,D)

Title: FocalGatedNet: A Novel Deep Learning Model for Accurate Knee Joint Angle
 Prediction
Authors: Humaid Ibrahim, Lyes Saad Saoud, Ahmad Aljarah, Irfan Hussain
Categories: cs.RO
Comments: 8 pages, 5 figures, 3 tables, submitted to IEEE Robotics and
 Automation Letters (RA-L)
\\
 Predicting knee joint angles accurately is critical for biomechanical
analysis and rehabilitation. This paper introduces a new deep learning model
called FocalGatedNet that incorporates Dynamic Contextual Focus (DCF) Attention
and Gated Linear Units (GLU) to enhance feature dependencies and interactions.
Our proposed model is evaluated on a large-scale dataset and compared to
existing models such as Transformer, Autoformer, Informer, NLinear, DLinear,
and LSTM in multi-step gait trajectory prediction. Our results demonstrate that
FocalGatedNet outperforms other state-of-the-art models for long-term
prediction lengths (60 ms, 80 ms, and 100 ms), achieving an average improvement
of 13.66% in MAE and 8.13% in RMSE compared to the second-best performing model
(Transformer). Furthermore, our model has a lower computational load than most
equivalent deep learning models. These results highlight the effectiveness of
our proposed model for knee joint angle prediction and the importance of our
modifications for this specific application.
\\ ( https://arxiv.org/abs/2306.06900 ,  1508kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06969
Date: Mon, 12 Jun 2023 08:57:15 GMT   (38884kb,D)

Title: Viewpoint Generation using Feature-Based Constrained Spaces for Robot
 Vision Systems
Authors: Alejandro Maga\~na, Jonas Dirr, Philipp Bauer, Gunther Reinhart
Categories: cs.RO cs.AI cs.CV
\\
 The efficient computation of viewpoints under consideration of various system
and process constraints is a common challenge that any robot vision system is
confronted with when trying to execute a vision task. Although fundamental
research has provided solid and sound solutions for tackling this problem, a
holistic framework that poses its formal description, considers the
heterogeneity of robot vision systems, and offers an integrated solution
remains unaddressed. Hence, this publication outlines the generation of
viewpoints as a geometrical problem and introduces a generalized theoretical
framework based on Feature-Based Constrained Spaces ($\mathcal{C}$-spaces) as
the backbone for solving it. A $\mathcal{C}$-space can be understood as the
topological space that a viewpoint constraint spans, where the sensor can be
positioned for acquiring a feature while fulfilling the regarded constraint.
The present study demonstrates that many viewpoint constraints can be
efficiently formulated as $\mathcal{C}$-spaces providing geometric,
deterministic, and closed solutions. The introduced $\mathcal{C}$-spaces are
characterized based on generic domain and viewpoint constraints models to ease
the transferability of the present framework to different applications and
robot vision systems. The effectiveness and efficiency of the concepts
introduced are verified on a simulation-based scenario and validated on a real
robot vision system comprising two different sensors.
\\ ( https://arxiv.org/abs/2306.06969 ,  38884kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06981
Date: Mon, 12 Jun 2023 09:25:58 GMT   (2749kb)

Title: Time-to-Collision-Aware Lane-Change Strategy Based on Potential Field
 and Cubic Polynomial for Autonomous Vehicles
Authors: Pengfei Lin, Ehsan Javanmardi, Ye Tao, Vishal Chauhan, Jin Nakazato,
 and Manabu Tsukada
Categories: cs.RO
Comments: Accepted in IEEE Intelligent Vehicles Symposium (IV) 2023
\\
 Making safe and successful lane changes (LCs) is one of the many vitally
important functions of autonomous vehicles (AVs) that are needed to ensure safe
driving on expressways. Recently, the simplicity and real-time performance of
the potential field (PF) method have been leveraged to design decision and
planning modules for AVs. However, the LC trajectory planned by the PF method
is usually lengthy and takes the ego vehicle laterally parallel and close to
the obstacle vehicle, which creates a dangerous situation if the obstacle
vehicle suddenly steers. To mitigate this risk, we propose a
time-to-collision-aware LC (TTCA-LC) strategy based on the PF and cubic
polynomial in which the TTC constraint is imposed in the optimized curve
fitting. The proposed approach is evaluated using MATLAB/Simulink under
high-speed conditions in a comparative driving scenario. The simulation results
indicate that the TTCA-LC method performs better than the conventional PF-based
LC (CPF-LC) method in generating shorter, safer, and smoother trajectories. The
length of the LC trajectory is shortened by over 27.1\%, and the curvature is
reduced by approximately 56.1\% compared with the CPF-LC method.
\\ ( https://arxiv.org/abs/2306.06981 ,  2749kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06987
Date: Mon, 12 Jun 2023 09:33:03 GMT   (1937kb)

Title: Potential Field-based Path Planning with Interactive Speed Optimization
 for Autonomous Vehicles
Authors: Pengfei Lin, Ehsan Javanmardi, Jin Nakazato, and Manabu Tsukada
Categories: cs.RO
Comments: Submitted to IEEE IECON 2023
\\
 Path planning is critical for autonomous vehicles (AVs) to determine the
optimal route while considering constraints and objectives. The potential field
(PF) approach has become prevalent in path planning due to its simple structure
and computational efficiency. However, current PF methods used in AVs focus
solely on the path generation of the ego vehicle while assuming that the
surrounding obstacle vehicles drive at a preset behavior without the PF-based
path planner, which ignores the fact that the ego vehicle's PF could also
impact the path generation of the obstacle vehicles. To tackle this problem, we
propose a PF-based path planning approach where local paths are shared among
ego and obstacle vehicles via vehicle-to-vehicle (V2V) communication. Then by
integrating this shared local path into an objective function, a new
optimization function called interactive speed optimization (ISO) is designed
to allow driving safety and comfort for both ego and obstacle vehicles. The
proposed method is evaluated using MATLAB/Simulink in the urgent merging
scenarios by comparing it with conventional methods. The simulation results
indicate that the proposed method can mitigate the impact of other AVs' PFs by
slowing down in advance, effectively reducing the oscillations for both ego and
obstacle AVs.
\\ ( https://arxiv.org/abs/2306.06987 ,  1937kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06993
Date: Mon, 12 Jun 2023 09:40:04 GMT   (5712kb)

Title: Occlusion-Aware Path Planning for Collision Avoidance: Leveraging
 Potential Field Method with Responsibility-Sensitive Safety
Authors: Pengfei Lin, Ehsan Javanmardi, Jin Nakazato, and Manabu Tsukada
Categories: cs.RO
Comments: Submitted to IEEE ITSC 2023
\\
 Collision avoidance (CA) has always been the foremost task for autonomous
vehicles (AVs) under safety criteria. And path planning is directly responsible
for generating a safe path to accomplish CA while satisfying other commands.
Due to the real-time computation and simple structure, the potential field (PF)
has emerged as one of the mainstream path-planning algorithms. However, the
current PF is primarily simulated in ideal CA scenarios, assuming complete
obstacle information while disregarding occlusion issues where obstacles can be
partially or entirely hidden from the AV's sensors. During the occlusion
period, the occluded obstacles do not possess a PF. Once the occlusion is over,
these obstacles can generate an instantaneous virtual force that impacts the
ego vehicle. Therefore, we propose an occlusion-aware path planning (OAPP) with
the responsibility-sensitive safety (RSS)-based PF to tackle the occlusion
problem for non-connected AVs. We first categorize the detected and occluded
obstacles, and then we proceed to the RSS violation check. Finally, we can
generate different virtual forces from the PF for occluded and non-occluded
obstacles. We compare the proposed OAPP method with other PF-based path
planning methods via MATLAB/Simulink. The simulation results indicate that the
proposed method can eliminate instantaneous lateral oscillation or sway and
produce a smoother path than conventional PF methods.
\\ ( https://arxiv.org/abs/2306.06993 ,  5712kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07003
Date: Mon, 12 Jun 2023 10:16:54 GMT   (1911kb,D)

Title: High-speed Autonomous Racing using Trajectory-aided Deep Reinforcement
 Learning
Authors: Benjamin David Evans, Herman Arnold Engelbrecht and Hendrik Willem
 Jordaan
Categories: cs.RO
Comments: 7 pages, 16 figures. Submitted for review
\\
 The classical method of autonomous racing uses real-time localisation to
follow a precalculated optimal trajectory. In contrast, end-to-end deep
reinforcement learning (DRL) can train agents to race using only raw LiDAR
scans. While classical methods prioritise optimization for high-performance
racing, DRL approaches have focused on low-performance contexts with little
consideration of the speed profile. This work addresses the problem of using
end-to-end DRL agents for high-speed autonomous racing. We present
trajectory-aided learning (TAL) that trains DRL agents for high-performance
racing by incorporating the optimal trajectory (racing line) into the learning
formulation. Our method is evaluated using the TD3 algorithm on four maps in
the open-source F1Tenth simulator. The results demonstrate that our method
achieves a significantly higher lap completion rate at high speeds compared to
the baseline. This is due to TAL training the agent to select a feasible speed
profile of slowing down in the corners and roughly tracking the optimal
trajectory.
\\ ( https://arxiv.org/abs/2306.07003 ,  1911kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07004
Date: Mon, 12 Jun 2023 10:18:46 GMT   (6693kb,D)

Title: Occlusion-aware Risk Assessment and Driving Strategy for Autonomous
 Vehicles Using Simplified Reachability Quantification
Authors: Hyunwoo Park, Jongseo Choi, Hyuntai Chin, and Sang-Hyun Lee
Categories: cs.RO
Comments: 9 pages, 9 figures
\\
 There are several unresolved challenges for autonomous vehicles. One of them
is safely navigating among occluded pedestrians and vehicles. Much of the
previous work tried to solve this problem by generating phantom cars and
assessing their risk. In this paper, motivated by the previous works, we
propose an algorithm that efficiently assesses risks of phantom
pedestrians/vehicles using Simplified Reachability Quantification. We utilized
this occlusion risk to set a speed limit at the risky position when planning
the velocity profile of an autonomous vehicle. This allows an autonomous
vehicle to safely and efficiently drive in occluded areas. The proposed
algorithm was evaluated in various scenarios in the CARLA simulator and it
reduced the average collision rate by 6.14X, the discomfort score by 5.03X,
while traversal time was increased by 1.48X compared to baseline 1, and
computation time was reduced by 20.15X compared to baseline 2.
\\ ( https://arxiv.org/abs/2306.07004 ,  6693kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07035
Date: Mon, 12 Jun 2023 11:33:20 GMT   (5027kb)

Title: Stochastic Approach for Modeling a Soft Robotic Finger with Creep
 Behavior
Authors: Sumitaka Honji, Hikaru Arita, Kenji Tahara
Categories: cs.RO
Comments: 17 pages, 8 figures. This is a preprint of an article submitted for
 consideration in Advanced Robotics, copyright Taylor & Francis and Robotics
 Society of Japan; Advanced Robotics is available online at
 http://www.tandfonline.com/
\\
 Soft robots have high adaptability and safeness which are derived from their
softness, and therefore it is paid attention to use them in human society.
However, the controllability of soft robots is not enough to perform dexterous
behaviors when considering soft robots as alternative laborers for humans. The
model-based control is effective to achieve dexterous behaviors. When
considering building a model which is suitable for control, there are problems
based on their special properties such as the creep behavior or the variability
of motion. In this paper, the lumped parameterized model with viscoelastic
joints for a soft finger is established for the creep behavior. Parameters are
expressed as distributions, which makes it possible to take into account the
variability of motion. Furthermore, stochastic analyses are performed based on
the parameters' distribution. They show high adaptivity compared with
experimental results and also enable the investigation of the effects of
parameters for robots' variability.
\\ ( https://arxiv.org/abs/2306.07035 ,  5027kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07092
Date: Mon, 12 Jun 2023 13:10:14 GMT   (8255kb,D)

Title: Tuning Legged Locomotion Controllers via Safe Bayesian Optimization
Authors: Daniel Widmer, Dongho Kang, Bhavya Sukhija, Jonas H\"ubotter, Andreas
 Krause, Stelian Coros
Categories: cs.RO cs.AI
\\
 In this paper, we present a data-driven strategy to simplify the deployment
of model-based controllers in legged robotic hardware platforms. Our approach
leverages a model-free safe learning algorithm to automate the tuning of
control gains, addressing the mismatch between the simplified model used in the
control formulation and the real system. This method substantially mitigates
the risk of hazardous interactions with the robot by sample-efficiently
optimizing parameters within a probably safe region. Additionally, we extend
the applicability of our approach to incorporate the different gait parameters
as contexts, leading to a safe, sample-efficient exploration algorithm capable
of tuning a motion controller for diverse gait patterns. We validate our method
through simulation and hardware experiments, where we demonstrate that the
algorithm obtains superior performance on tuning a model-based motion
controller for multiple gaits safely.
\\ ( https://arxiv.org/abs/2306.07092 ,  8255kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07129
Date: Mon, 12 Jun 2023 14:07:53 GMT   (4495kb,D)

Title: Collaborative Robotic Biopsy with Trajectory Guidance and Needle Tip
 Force Feedback
Authors: Robin Mieling, Maximilian Neidhardt, Sarah Latus, Carolin Stapper,
 Stefan Gerlach, Inga Kniep, Axel Heinemann, Benjamin Ondruschka and Alexander
 Schlaefer
Categories: cs.RO cs.LG cs.SY eess.SY
Comments: Presented at ICRA 2023
\\
 The diagnostic value of biopsies is highly dependent on the placement of
needles. Robotic trajectory guidance has been shown to improve needle
positioning, but feedback for real-time navigation is limited. Haptic display
of needle tip forces can provide rich feedback for needle navigation by
enabling localization of tissue structures along the insertion path. We present
a collaborative robotic biopsy system that combines trajectory guidance with
kinesthetic feedback to assist the physician in needle placement. The robot
aligns the needle while the insertion is performed in collaboration with a
medical expert who controls the needle position on site. We present a needle
design that senses forces at the needle tip based on optical coherence
tomography and machine learning for real-time data processing. Our robotic
setup allows operators to sense deep tissue interfaces independent of
frictional forces to improve needle placement relative to a desired target
structure. We first evaluate needle tip force sensing in ex-vivo tissue in a
phantom study. We characterize the tip forces during insertions with constant
velocity and demonstrate the ability to detect tissue interfaces in a
collaborative user study. Participants are able to detect 91% of ex-vivo tissue
interfaces based on needle tip force feedback alone. Finally, we demonstrate
that even smaller, deep target structures can be accurately sampled by
performing post-mortem in situ biopsies of the pancreas.
\\ ( https://arxiv.org/abs/2306.07129 ,  4495kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07160
Date: Mon, 12 Jun 2023 14:48:32 GMT   (1566kb,D)

Title: Looking Around Corners: Generative Methods in Terrain Extension
Authors: Alec Reed, Christoffer Heckman
Categories: cs.RO
\\
 In this paper, we provide an early look at our model for generating terrain
that is occluded in the initial lidar scan or out of range of the sensor. As a
proof of concept, we show that a transformer based framework is able to be
overfit to predict the geometries of unobserved roads around intersections or
corners. We discuss our method for generating training data, as well as a
unique loss function for training our terrain extension network. The framework
is tested on data from the SemanticKitti [1] dataset. Unlabeled point clouds
measured from an onboard lidar are used as input data to generate predicted
road points that are out of range or occluded in the original point-cloud scan.
Then the input pointcloud and predicted terrain are concatenated to the
terrain-extended pointcloud. We show promising qualitative results from these
methods, as well as discussion for potential quantitative metrics to evaluate
the overall success of our framework. Finally, we discuss improvements that can
be made to the framework for successful generalization to test sets.
\\ ( https://arxiv.org/abs/2306.07160 ,  1566kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07205
Date: Mon, 12 Jun 2023 16:09:17 GMT   (664kb,D)

Title: Maximising Coefficiency of Human-Robot Handovers through Reinforcement
 Learning
Authors: Marta Lagomarsino, Marta Lorenzini, Merryn Dale Constable, Elena De
 Momi, Cristina Becchio, Arash Ajoudani
Categories: cs.RO
Comments: 8 pages, 6 figures, IEEE Robotics and Automation Letters
DOI: 10.1109/LRA.2023.3280752
\\
 Handing objects to humans is an essential capability for collaborative
robots. Previous research works on human-robot handovers focus on facilitating
the performance of the human partner and possibly minimising the physical
effort needed to grasp the object. However, altruistic robot behaviours may
result in protracted and awkward robot motions, contributing to unpleasant
sensations by the human partner and affecting perceived safety and social
acceptance. This paper investigates whether transferring the cognitive science
principle that "humans act coefficiently as a group" (i.e. simultaneously
maximising the benefits of all agents involved) to human-robot cooperative
tasks promotes a more seamless and natural interaction. Human-robot
coefficiency is first modelled by identifying implicit indicators of human
comfort and discomfort as well as calculating the robot energy consumption in
performing the desired trajectory. We then present a reinforcement learning
approach that uses the human-robot coefficiency score as reward to adapt and
learn online the combination of robot interaction parameters that maximises
such coefficiency. Results proved that by acting coefficiently the robot could
meet the individual preferences of most subjects involved in the experiments,
improve the human perceived comfort, and foster trust in the robotic partner.
\\ ( https://arxiv.org/abs/2306.07205 ,  664kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07225
Date: Mon, 12 Jun 2023 16:33:53 GMT   (9581kb,D)

Title: Kalman Filter Auto-tuning through Enforcing Chi-Squared Normalized Error
 Distributions with Bayesian Optimization
Authors: Zhaozhong Chen and Harel Biggie and Nisar Ahmed and Simon Julier and
 Christoffer Heckman
Categories: cs.RO cs.SY eess.SY
Comments: 34 pages, 9 figures, submitted to IEEE Transactions on Aerospace and
 Electronic Systems
\\
 The nonlinear and stochastic relationship between noise covariance parameter
values and state estimator performance makes optimal filter tuning a very
challenging problem. Popular optimization-based tuning approaches can easily
get trapped in local minima, leading to poor noise parameter identification and
suboptimal state estimation. Recently, black box techniques based on Bayesian
optimization with Gaussian processes (GPBO) have been shown to overcome many of
these issues, using normalized estimation error squared (NEES) and normalized
innovation error (NIS) statistics to derive cost functions for Kalman filter
auto-tuning. While reliable noise parameter estimates are obtained in many
cases, GPBO solutions obtained with these conventional cost functions do not
always converge to optimal filter noise parameters and lack robustness to
parameter ambiguities in time-discretized system models. This paper addresses
these issues by making two main contributions. First, we show that NIS and NEES
errors are only chi-squared distributed for tuned estimators. As a result,
chi-square tests are not sufficient to ensure that an estimator has been
correctly tuned. We use this to extend the familiar consistency tests for NIS
and NEES to penalize if the distribution is not chi-squared distributed.
Second, this cost measure is applied within a Student-t processes Bayesian
Optimization (TPBO) to achieve robust estimator performance for time
discretized state space models. The robustness, accuracy, and reliability of
our approach are illustrated on classical state estimation problems.
\\ ( https://arxiv.org/abs/2306.07225 ,  9581kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07229
Date: Mon, 12 Jun 2023 16:41:59 GMT   (13221kb,D)

Title: MRS Drone: A Modular Platform for Real-World Deployment of Aerial
 Multi-Robot Systems
Authors: Daniel Hert and Tomas Baca and Pavel Petracek and Vit Kratky and
 Robert Penicka and Vojtech Spurny and Matej Petrlik and Matous Vrba and David
 Zaitlik and Pavel Stoudek and Viktor Walter and Petr Stepan and Jiri Horyna
 and Vaclav Pritzl and Martin Sramek and Afzal Ahmad and Giuseppe Silano and
 Daniel Bonilla Licea and Petr Stibinger and Tiago Nascimento and Martin Saska
Categories: cs.RO
Comments: 49 pages, 39 figures, accepted for publication to the Journal of
 Intelligent & Robotic Systems
\\
 This paper presents a modular autonomous Unmanned Aerial Vehicle (UAV)
platform called the Multi-robot Systems (MRS) Drone that can be used in a large
range of indoor and outdoor applications. The MRS Drone features unique
modularity with respect to changes in actuators, frames, and sensory
configuration. As the name suggests, the platform is specially tailored for
deployment within a MRS group. The MRS Drone contributes to the
state-of-the-art of UAV platforms by allowing smooth real-world deployment of
multiple aerial robots, as well as by outperforming other platforms with its
modularity. For real-world multi-robot deployment in various applications, the
platform is easy to both assemble and modify. Moreover, it is accompanied by a
realistic simulator to enable safe pre-flight testing and a smooth transition
to complex real-world experiments. In this manuscript, we present mechanical
and electrical designs, software architecture, and technical specifications to
build a fully autonomous multi UAV system. Finally, we demonstrate the full
capabilities and the unique modularity of the MRS Drone in various real-world
applications that required a diverse range of platform configurations.
\\ ( https://arxiv.org/abs/2306.07229 ,  13221kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07258
Date: Mon, 12 Jun 2023 17:39:26 GMT   (33771kb,D)

Title: On the Collocated Form with Input Decoupling of Lagrangian Systems
Authors: Pietro Pustina, Cosimo Della Santina, Fr\'ed\'eric Boyer, Alessandro
 De Luca, Federico Renda
Categories: cs.RO cs.SY eess.SY physics.class-ph
\\
 Suitable representations of dynamical systems can simplify their analysis and
control. On this line of thought, this paper considers the input decoupling
problem for input-affine Lagrangian dynamics, namely the problem of finding a
transformation of the generalized coordinates that decouples the input
channels. We identify a class of systems for which this problem is solvable.
Such systems are called collocated because the decoupling variables correspond
to the coordinates on which the actuators directly perform work. Under mild
conditions on the input matrix, a simple test is presented to verify whether a
system is collocated or not. By exploiting power invariance, it is proven that
a change of coordinates decouples the input channels if and only if the
dynamics is collocated. We illustrate the theoretical results by considering
several Lagrangian systems, focusing on underactuated mechanical systems, for
which novel controllers that exploit input decoupling are designed.
\\ ( https://arxiv.org/abs/2306.07258 ,  33771kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06330
Date: Sat, 10 Jun 2023 01:59:38 GMT   (5444kb,D)

Title: Autonomous Drifting with 3 Minutes of Data via Learned Tire Models
Authors: Franck Djeumou and Jonathan Y.M. Goh and Ufuk Topcu and Avinash
 Balachandran
Categories: eess.SY cs.LG cs.SY
Comments: Final Submission at ICRA 2023
\\
 Near the limits of adhesion, the forces generated by a tire are nonlinear and
intricately coupled. Efficient and accurate modelling in this region could
improve safety, especially in emergency situations where high forces are
required. To this end, we propose a novel family of tire force models based on
neural ordinary differential equations and a neural-ExpTanh parameterization.
These models are designed to satisfy physically insightful assumptions while
also having sufficient fidelity to capture higher-order effects directly from
vehicle state measurements. They are used as drop-in replacements for an
analytical brush tire model in an existing nonlinear model predictive control
framework. Experiments with a customized Toyota Supra show that scarce amounts
of driving data -- less than three minutes -- is sufficient to achieve
high-performance autonomous drifting on various trajectories with speeds up to
45mph. Comparisons with the benchmark model show a $4 \times$ improvement in
tracking performance, smoother control inputs, and faster and more consistent
computation time.
\\ ( https://arxiv.org/abs/2306.06330 ,  5444kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06467
Date: Sat, 10 Jun 2023 15:38:25 GMT   (510kb,D)

Title: A Chance-Constrained Optimal Design of Volt/VAR Control Rules for
 Distributed Energy Resources
Authors: Jinlei Wei, Sarthak Gupta, Dionysios C. Aliprantis, Vassilis Kekatos
Categories: eess.SY cs.SY
\\
 Deciding setpoints for distributed energy resources (DERs) via local control
rules rather than centralized optimization offers significant autonomy. The
IEEE Standard 1547 recommends deciding DER setpoints using Volt/VAR rules.
Although such rules are specified as non-increasing piecewise-affine functions,
their exact shape is left for the utility operators to decide and possibly
customize per bus and grid conditions. To address this need, this work
optimally designs Volt/VAR rules to minimize ohmic losses on lines while
maintaining voltages within allowable limits. This is practically relevant as
excessive reactive injections could reduce equipment$^{\prime}$s lifetime due
to overloading. Optimal rule design (ORD) is technically challenging as
Volt/VAR rules entail mixed-integer models, stability implications, and
uncertainties in grid conditions. Uncertainty is handled by minimizing average
losses under voltage chance constraints, both replaced by smooth sample
approximations. To cope with the piecewise-affine shape of the rules, we build
upon our previous reformulation of ORD as a deep learning task. A recursive
neural network (RNN) surrogates Volt/VAR dynamics and thanks to
back-propagation, we can expedite ORD. The RNN weights coincide with rule
parameters, and are trained using primal-dual decomposition. Numerical tests
corroborate the efficacy of the proposed ORD formulation and solution
methodology.
\\ ( https://arxiv.org/abs/2306.06467 ,  510kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06530
Date: Sat, 10 Jun 2023 21:56:03 GMT   (1505kb)

Title: Use of Robust DOB/CDOB Compensation to Improve Autonomous Vehicle Path
 Following Performance in the Presence of Model Uncertainty, CAN Bus Delays
 and External Disturbances
Authors: Haoan Wang, Levent Guvenc
Categories: eess.SY cs.SY
Comments: arXiv admin note: text overlap with arXiv:2306.01899
\\
 A path tracking control system is chosen as the proof-of-concept
demonstration application in this paper. A disturbance observer (DOB) is
embedded within the steering to path error automated driving loop to handle
uncertain parameters such as vehicle mass, vehicle velocities and road friction
coefficient and to reject yaw moment disturbances. The compensation of vehicle
model with the embedded disturbance observer forces it to behave like its
nominal model within the bandwidth of the disturbance observer. A parameter
space approach based steering controller is then used to optimize performance.
The proposed method demonstrates good disturbance rejection and achieves
stability robustness. The variable time delay from the steer-by-wire system in
an actual vehicle can also lead to stability issues since it adds large
negative phase angle to the plant frequency response and tends to destabilize
it. A communication disturbance observer (CDOB) based time delay compensation
approach that does not require exact knowledge of this time delay is embedded
into the steering actuation loop to handle this problem. Stability analysis of
both DOB and CDOB compensation system are presented in this paper. Extensive
model-in-the-loop simulations were performed to test the designed disturbance
observer and CDOB systems and show reduced path following errors in the
presence of uncertainty, disturbances and time delay. A validated model of our
2017 Ford Fusion Hybrid research autonomous vehicle is used in the simulation
analyses. Simulation results verify the performance enhancement of the vehicle
path following control with proposed DOB and CDOB structure. A HiL simulator
that uses a validated CarSim model with sensors and traffic will be used later
to verify the real time capability of our approach.
\\ ( https://arxiv.org/abs/2306.06530 ,  1505kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06646
Date: Sun, 11 Jun 2023 10:43:12 GMT   (63kb)

Title: Fractional Barrier Lyapunov Functions with Application to Learning
 Control
Authors: Mingxuan Sun
Categories: eess.SY cs.SY
\\
 Barrier Lyapunov functions are suitable for learning control designs, due to
their feature of finite duration tracking. This paper presents fractional
barrier Lyapunov functions, provided and compared with the conventional ones in
the error-constraint learning control designs. Two error models are adopted and
the desired compensation control approach is applied for a non-parametric
design, allowing two kinds of uncertainties involved in the error dynamics.
Theoretical results about existence of the solution and convergence of the
learning control schemes are presented. It is shown that fully-saturated
learning algorithms play important role in assuring boundedness of the
estimates, by which the error constraint objective can be achieved. Moreover,
the robust technique is developed through modifying the discontinuous action
involved in the learning control scheme that yields the expected tracking
performance in the presence of residual.
\\ ( https://arxiv.org/abs/2306.06646 ,  63kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06839
Date: Mon, 12 Jun 2023 03:17:49 GMT   (161kb,D)

Title: Single-Integrator Consensus Dynamics over Minimally Reactive Networks
Authors: Amirhossein Nazerian, David Phillips, Hernan A. Makse, Francesco
 Sorrentino
Categories: eess.SY cs.SY
\\
 The problem of achieving consensus in a network of connected systems arises
in many science and engineering applications. In contrast to previous works, we
focus on the system reactivity, i.e., the initial amplification of the norm of
the system states. We identify a class of networks that we call minimally
reactive, which are such that the indegree and the outdegree of each node of
the network are the same. We propose several optimization procedures in which
minimum perturbations (links or link weights) are imposed on a given network
topology to make it minimally reactive. A new concept of structural reactivity
is introduced which measures how much a given network is far from becoming
minimally reactive by link perturbations. The structural reactivity of directed
random graphs is studied.
\\ ( https://arxiv.org/abs/2306.06839 ,  161kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06898
Date: Mon, 12 Jun 2023 07:04:03 GMT   (1287kb,D)

Title: Transient Stability Analysis of Grid-Connected Converters Based on
 Reverse-Time Trajectory
Authors: Mohammad Kazem Bakhshizadeh, Sujay Ghosh, Guangya Yang and {\L}ukasz
 Kocewiak
Categories: eess.SY cs.SY
\\
 As the proportion of converter-interfaced renewable energy resources in the
power system is increasing, the strength of the power grid at the connection
point of wind turbine generators (WTGs) is gradually weakening. Existing
research has shown that when connected with the weak grid, the dynamic
characteristics of the traditional grid-following controlled converters will
deteriorate, and unstable phenomena such as oscillation are prone to arise. Due
to the limitations of linear analysis that can not sufficiently capture the
stability phenomena, transient stability must also be investigated. So far,
standalone time-domain simulations or analytical Lyapunov stability criteria
have been used to investigate transient stability. However, time-domain
simulations have proven to be computationally too heavy, while analytical
methods are more complex to formulate, require many assumptions, and are
conservative. This paper demonstrates an innovative approach to estimating the
system boundaries via hybrid - linearised Lyapunov function-based approach and
the time-reversal technique. The proposed methodology enables compensation for
both time-consuming simulations and the conservative nature of Lyapunov
functions. This work brings out the clear distinction between the system
boundaries with different post-fault active current ramp rate controls. At the
same time providing a new perspective on critical clearing times for wind
turbine systems. Finally, the stability boundary is verified using time domain
simulation studies.
\\ ( https://arxiv.org/abs/2306.06898 ,  1287kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07082
Date: Mon, 12 Jun 2023 12:48:44 GMT   (3664kb,D)

Title: Residual-Based Detection of Attacks in Cyber-Physical Inverter-Based
 Microgrids
Authors: Andres Intriago, Francesco Liberati, Nikos D. Hatziargyriou,
 Charalambos Konstantinou
Categories: eess.SY cs.CR cs.SY
Comments: Accepted at IEEE Transactions on Power Systems
\\
 This paper discusses the challenges faced by cyber-physical microgrids (MGs)
due to the inclusion of information and communication technologies in their
already complex, multi-layered systems. The work identifies a research gap in
modeling and analyzing stealthy intermittent integrity attacks in MGs, which
are designed to maximize damage and cancel secondary control objectives. To
address this, the paper proposes a nonlinear residual-based observer approach
to detect and mitigate such attacks. In order to ensure a stable operation of
the MG, the formulation then incorporates stability constraints along with the
detection observer. The proposed design is validated through case studies on a
MG benchmark with four distributed generators, demonstrating its effectiveness
in detecting attacks while satisfying network and stability constraints.
\\ ( https://arxiv.org/abs/2306.07082 ,  3664kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07113
Date: Mon, 12 Jun 2023 13:42:28 GMT   (384kb,D)

Title: Koopman-inspired Implicit Backward Reachable Sets for Unknown Nonlinear
 Systems
Authors: Haldun Balim, Antoine Aspeel, Zexiang Liu, Necmiye Ozay
Categories: eess.SY cs.SY
\\
 Koopman liftings have been successfully used to learn high dimensional linear
approximations for autonomous systems for prediction purposes, or for control
systems for leveraging linear control techniques to control nonlinear dynamics.
In this paper, we show how learned Koopman approximations can be used for
state-feedback correct-by-construction control. To this end, we introduce the
Koopman over-approximation, a (possibly hybrid) lifted representation that has
a simulation-like relation with the underlying dynamics. Then, we prove how
successive application of controlled predecessor operation in the lifted space
leads to an implicit backward reachable set for the actual dynamics. Finally,
we demonstrate the approach on two nonlinear control examples with unknown
dynamics.
\\ ( https://arxiv.org/abs/2306.07113 ,  384kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07142
Date: Mon, 12 Jun 2023 14:26:12 GMT   (1630kb)

Title: Evolving Testing Scenario Generation Method and Intelligence Evaluation
 Framework for Automated Vehicles
Authors: Yining Ma, Wei Jiang, Lingtong Zhang, Junyi Chen, Hong Wang, Chen Lv,
 Xuesong Wang, Lu Xiong
Categories: eess.SY cs.AI cs.MA cs.RO cs.SY
Comments: 18 pages,17 figures
\\
 Interaction between the background vehicles (BVs) and automated vehicles
(AVs) in scenario-based testing plays a critical role in evaluating the
intelligence of the AVs. Current testing scenarios typically employ predefined
or scripted BVs, which inadequately reflect the complexity of human-like social
behaviors in real-world driving scenarios, and also lack a systematic metric
for evaluating the comprehensive intelligence of AVs. Therefore, this paper
proposes an evolving scenario generation method that utilizes deep
reinforcement learning (DRL) to create human-like BVs for testing and
intelligence evaluation of AVs. Firstly, a class of driver models with
human-like competitive, cooperative, and mutual driving motivations is
designed. Then, utilizing an improved "level-k" training procedure, the three
distinct driver models acquire game-based interactive driving policies. And
these models are assigned to BVs for generating evolving scenarios in which all
BVs can interact continuously and evolve diverse contents. Next, a framework
including safety, driving efficiency, and interaction utility are presented to
evaluate and quantify the intelligence performance of 3 systems under test
(SUTs), indicating the effectiveness of the evolving scenario for intelligence
testing. Finally, the complexity and fidelity of the proposed evolving testing
scenario are validated. The results demonstrate that the proposed evolving
scenario exhibits the highest level of complexity compared to other baseline
scenarios and has more than 85% similarity to naturalistic driving data. This
highlights the potential of the proposed method to facilitate the development
and evaluation of high-level AVs in a realistic and challenging environment.
\\ ( https://arxiv.org/abs/2306.07142 ,  1630kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07263
Date: Mon, 12 Jun 2023 17:49:46 GMT   (10702kb,D)

Title: Backpressure control with predicted imminent saturation flow rate for
 urban networks
Authors: Dianchao Lin and Li Li
Categories: eess.SY cs.SY
\\
 The network's admissible demand region (ADR), which is a key index to
characterize a network's ability to handle incoming demands, is shaped by each
movement's saturation flow rate (SFR). Existing backpressure (BP) traffic
control policies commonly assumed a fixed and/or completely known SFR when
calculating the pressure for decision-making. On one hand, since real-time
traffic conditions can significantly influence the traffic supply, the fixed
mean SFR (M-SFR) assumption could result in a mismatch between dynamic demand
and supply. On the other hand, accurately predicting the imminent SFR (I-SFR)
is challenging because of the complicated interactions between traffic
participants. Hence, the completely known SFR assumption is impractical in
real-world settings. Our paper demonstrates that, compared with only using the
constant M-SFR information, using more knowledge of I-SFR can enlarge the upper
bound of ADR. In addition, we theoretically prove that the BP with predicted
I-SFR can guarantee network stability as long as the demand is interior to the
ADR.
 The proposed theory is validated by a calibrated simulation model in the
experiments. Three I-SFR prediction methods with different accuracies are
adopted: the M-SFR method, the heuristic estimation method, and the deep neural
network method. They are tested in three BP-based control policies to
investigate whether our findings are robust. The simulation results show that:
a higher prediction accuracy of I-SFR can effectively help all three BP-based
policies enlarge the network ADR, and more accurate I-SFR can productively
reduce the average vehicle delay.
\\ ( https://arxiv.org/abs/2306.07263 ,  10702kb)
%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-
------------------------------------------------------------------------------
\\
arXiv:2306.06109 (*cross-listing*)
Date: Fri, 26 May 2023 04:13:31 GMT   (3435kb,D)

Title: Learning to Quantize Vulnerability Patterns and Match to Locate
 Statement-Level Vulnerabilities
Authors: Michael Fu, Trung Le, Van Nguyen, Chakkrit Tantithamthavorn, Dinh
 Phung
Categories: cs.CR cs.AI cs.LG
\\
 Deep learning (DL) models have become increasingly popular in identifying
software vulnerabilities. Prior studies found that vulnerabilities across
different vulnerable programs may exhibit similar vulnerable scopes, implicitly
forming discernible vulnerability patterns that can be learned by DL models
through supervised training. However, vulnerable scopes still manifest in
various spatial locations and formats within a program, posing challenges for
models to accurately identify vulnerable statements. Despite this challenge,
state-of-the-art vulnerability detection approaches fail to exploit the
vulnerability patterns that arise in vulnerable programs. To take full
advantage of vulnerability patterns and unleash the ability of DL models, we
propose a novel vulnerability-matching approach in this paper, drawing
inspiration from program analysis tools that locate vulnerabilities based on
pre-defined patterns. Specifically, a vulnerability codebook is learned, which
consists of quantized vectors representing various vulnerability patterns.
During inference, the codebook is iterated to match all learned patterns and
predict the presence of potential vulnerabilities within a given program. Our
approach was extensively evaluated on a real-world dataset comprising more than
188,000 C/C++ functions. The evaluation results show that our approach achieves
an F1-score of 94% (6% higher than the previous best) and 82% (19% higher than
the previous best) for function and statement-level vulnerability
identification, respectively. These substantial enhancements highlight the
effectiveness of our approach to identifying vulnerabilities. The training code
and pre-trained models are available at https://github.com/optimatch/optimatch.
\\ ( https://arxiv.org/abs/2306.06109 ,  3435kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06117 (*cross-listing*)
Date: Thu, 1 Jun 2023 20:35:06 GMT   (1278kb,D)

Title: Strengths and Weaknesses of 3D Pose Estimation and Inertial Motion
 Capture System for Movement Therapy
Authors: Shawan Mohammed, Hannah Siebers, Ted Preu{\ss}
Categories: eess.IV cs.AI cs.CV cs.LG eess.SP
\\
 3D pose estimation offers the opportunity for fast, non-invasive, and
accurate motion analysis. This is of special interest also for clinical use.
Currently, motion capture systems are used, as they offer robust and precise
data acquisition, which is essential in the case of clinical applications. In
this study, we investigate the accuracy of the state-of-the-art 3D position
estimation approach MeTrabs, compared to the established inertial sensor system
MTw Awinda for specific motion exercises. The study uses and provides an
evaluation dataset of parallel recordings from 10 subjects during various
movement therapy exercises. The information from the Awinda system and the
frames for monocular pose estimation are synchronized. For the comparison,
clinically relevant parameters for joint angles of ankle, knee, back, and elbow
flexion-extension were estimated and evaluated using mean, median, and maximum
deviation between the calculated joint angles for the different exercises,
camera positions, and clothing items. The results of the analysis indicate that
the mean and median deviations can be kept below 5{\deg} for some of the
studied angles. These joints could be considered for medical applications even
considering the maximum deviations of 15{\deg}. However, caution should be
applied to certain particularly problematic joints. In particular, elbow
flexions, which showed high maximum deviations of up to 50{\deg} in our
analysis. Furthermore, the type of exercise plays a crucial role in the
reliable and safe application of the 3D position estimation method. For
example, all joint angles showed a significant deterioration in performance
during exercises near the ground.
\\ ( https://arxiv.org/abs/2306.06117 ,  1278kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06123 (*cross-listing*)
Date: Tue, 6 Jun 2023 09:53:39 GMT   (739kb,D)

Title: Adversarial Attacks and Defenses in Explainable Artificial Intelligence:
 A Survey
Authors: Hubert Baniecki and Przemyslaw Biecek
Categories: cs.CR cs.AI cs.CV cs.LG
Comments: To be presented at the IJCAI 2023 Workshop on XAI
\\
 Explainable artificial intelligence (XAI) methods are portrayed as a remedy
for debugging and trusting statistical and deep learning models, as well as
interpreting their predictions. However, recent advances in adversarial machine
learning highlight the limitations and vulnerabilities of state-of-the-art
explanations, putting their security and trustworthiness into question. The
possibility of manipulating, fooling or fairwashing evidence of the model's
reasoning has detrimental consequences when applied in high-stakes
decision-making and knowledge discovery. This concise survey of over 50 papers
summarizes research concerning adversarial attacks on explanations of machine
learning models, as well as fairness metrics. We discuss how to defend against
attacks and design robust interpretation methods. We contribute a list of
existing insecurities in XAI and outline the emerging research directions in
adversarial XAI (AdvXAI).
\\ ( https://arxiv.org/abs/2306.06123 ,  739kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06124 (*cross-listing*)
Date: Thu, 8 Jun 2023 04:41:34 GMT   (2367kb,D)

Title: Unsupervised clustering of disturbances in power systems via deep
 convolutional autoencoders
Authors: Md Maidul Islam, Md Omar Faruque, Joshua Butterfield, Gaurav Singh,
 Thomas A. Cooke
Categories: eess.SP cs.AI cs.LG cs.SY
\\
 Power quality (PQ) events are recorded by PQ meters whenever anomalous events
are detected on the power grid. Using neural networks with machine learning can
aid in accurately classifying the recorded waveforms and help power system
engineers diagnose and rectify the root causes of problems. However, many of
the waveforms captured during a disturbance in the power system need to be
labeled for supervised learning, leaving a large number of data recordings for
engineers to process manually or go unseen. This paper presents an autoencoder
and K-means clustering-based unsupervised technique that can be used to cluster
PQ events into categories like sag, interruption, transients, normal, and
harmonic distortion to enable filtering of anomalous waveforms from recurring
or normal waveforms. The method is demonstrated using three-phase,
field-obtained voltage waveforms recorded in a distribution grid. First, a
convolutional autoencoder compresses the input signals into a set of lower
feature dimensions which, after further processing, is passed to the K-means
algorithm to identify data clusters. Using a small, labeled dataset, numerical
labels are then assigned to events based on a cosine similarity analysis.
Finally, the study analyzes the clusters using the t-distributed stochastic
neighbor embedding (t-SNE) visualization tool, demonstrating that the technique
can help investigate a large number of captured events in a quick manner.
\\ ( https://arxiv.org/abs/2306.06124 ,  2367kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06147 (*cross-listing*)
Date: Fri, 9 Jun 2023 12:07:10 GMT   (1948kb)

Title: SentiGOLD: A Large Bangla Gold Standard Multi-Domain Sentiment Analysis
 Dataset and its Evaluation
Authors: Md. Ekramul Islam, Labib Chowdhury, Faisal Ahamed Khan, Shazzad
 Hossain, Sourave Hossain, Mohammad Mamun Or Rashid, Nabeel Mohammed and
 Mohammad Ruhul Amin
Categories: cs.CL cs.AI
Comments: Accepted in KDD 2023 Applied Data Science Track; 12 pages, 14 figures
DOI: 10.1145/3580305.3599904
\\
 This study introduces SentiGOLD, a Bangla multi-domain sentiment analysis
dataset. Comprising 70,000 samples, it was created from diverse sources and
annotated by a gender-balanced team of linguists. SentiGOLD adheres to
established linguistic conventions agreed upon by the Government of Bangladesh
and a Bangla linguistics committee. Unlike English and other languages, Bangla
lacks standard sentiment analysis datasets due to the absence of a national
linguistics framework. The dataset incorporates data from online video
comments, social media posts, blogs, news, and other sources while maintaining
domain and class distribution rigorously. It spans 30 domains (e.g., politics,
entertainment, sports) and includes 5 sentiment classes (strongly negative,
weakly negative, neutral, and strongly positive). The annotation scheme,
approved by the national linguistics committee, ensures a robust Inter
Annotator Agreement (IAA) with a Fleiss' kappa score of 0.88. Intra- and
cross-dataset evaluation protocols are applied to establish a standard
classification system. Cross-dataset evaluation on the noisy SentNoB dataset
presents a challenging test scenario. Additionally, zero-shot experiments
demonstrate the generalizability of SentiGOLD. The top model achieves a macro
f1 score of 0.62 (intra-dataset) across 5 classes, setting a benchmark, and
0.61 (cross-dataset from SentNoB) across 3 classes, comparable to the
state-of-the-art. Fine-tuned sentiment analysis model can be accessed at
https://sentiment.bangla.gov.bd.
\\ ( https://arxiv.org/abs/2306.06147 ,  1948kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06233 (*cross-listing*)
Date: Fri, 9 Jun 2023 20:08:46 GMT   (11510kb,D)

Title: Boosting GUI Prototyping with Diffusion Models
Authors: Jialiang Wei, Anne-Lise Courbis, Thomas Lambolais, Binbin Xu, Pierre
 Louis Bernard, G\'erard Dray
Categories: cs.SE cs.AI cs.CV
Comments: Accepted for The 31st IEEE International Requirements Engineering
 Conference 2023, RE@Next! track
\\
 GUI (graphical user interface) prototyping is a widely-used technique in
requirements engineering for gathering and refining requirements, reducing
development risks and increasing stakeholder engagement. However, GUI
prototyping can be a time-consuming and costly process. In recent years, deep
learning models such as Stable Diffusion have emerged as a powerful
text-to-image tool capable of generating detailed images based on text prompts.
In this paper, we propose UI-Diffuser, an approach that leverages Stable
Diffusion to generate mobile UIs through simple textual descriptions and UI
components. Preliminary results show that UI-Diffuser provides an efficient and
cost-effective way to generate mobile GUI designs while reducing the need for
extensive prototyping efforts. This approach has the potential to significantly
improve the speed and efficiency of GUI prototyping in requirements
engineering.
\\ ( https://arxiv.org/abs/2306.06233 ,  11510kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06234 (*cross-listing*)
Date: Fri, 9 Jun 2023 20:08:48 GMT   (80kb,D)

Title: Using Foundation Models to Detect Policy Violations with Minimal
 Supervision
Authors: Sid Mittal, Vineet Gupta, Frederick Liu, Mukund Sundararajan
Categories: cs.CL cs.AI
Comments: 16 pages
\\
 Foundation models, i.e. large neural networks pre-trained on large text
corpora, have revolutionized NLP. They can be instructed directly (e.g.
(arXiv:2005.14165)) - this is called hard prompting - and they can be tuned
using very little data (e.g. (arXiv:2104.08691)) - this technique is called
soft prompting. We seek to leverage their capabilities to detect policy
violations. Our contributions are: We identify a hard prompt that adapts
chain-of-thought prompting to policy violation tasks. This prompt produces
policy violation classifications, along with extractive explanations that
justify the classification. We compose the hard-prompts with soft prompt tuning
to produce a classifier that attains high accuracy with very little
supervision; the same classifier also produces explanations. Though the
supervision only acts on the classifications, we find that the modified
explanations remain consistent with the (tuned) model's response. Along the
way, we identify several unintuitive aspects of foundation models. For
instance, adding an example from a specific class can actually reduce
predictions of that class, and separately, the effects of tokenization on
scoring etc. Based on our technical results, we identify a simple workflow for
product teams to quickly develop effective policy violation detectors.
\\ ( https://arxiv.org/abs/2306.06234 ,  80kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06284 (*cross-listing*)
Date: Fri, 9 Jun 2023 22:24:05 GMT   (945kb,D)

Title: Everybody Compose: Deep Beats To Music
Authors: Conghao Shen, Violet Z. Yao, Yixin Liu
Categories: cs.SD cs.AI cs.MM eess.AS
Comments: Accepted MMSys '23
Journal-ref: Proceedings of the 14th Conference on ACM Multimedia Systems
 (2023)
DOI: 10.1145/3587819.3592542
\\
 This project presents a deep learning approach to generate monophonic
melodies based on input beats, allowing even amateurs to create their own music
compositions. Three effective methods - LSTM with Full Attention, LSTM with
Local Attention, and Transformer with Relative Position Representation - are
proposed for this novel task, providing great variation, harmony, and structure
in the generated music. This project allows anyone to compose their own music
by tapping their keyboards or ``recoloring'' beat sequences from existing
works.
\\ ( https://arxiv.org/abs/2306.06284 ,  945kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06297 (*cross-listing*)
Date: Fri, 9 Jun 2023 23:23:26 GMT   (123kb,D)

Title: Protect Your Prompts: Protocols for IP Protection in LLM Applications
Authors: M.A. van Wyk, M. Bekker, X.L. Richards, K.J. Nixon
Categories: cs.CL cs.AI
Comments: 5 pages, 2 figures
MSC-class: 91D10, 68T10, 03D40
ACM-class: I.2.6; K.6.5; F.3.2
\\
 With the rapid adoption of AI in the form of large language models (LLMs),
the potential value of carefully engineered prompts has become significant.
However, to realize this potential, prompts should be tradable on an open
market. Since prompts are, at present, generally economically non-excludable,
by virtue of their nature as text, no general competitive market has yet been
established. This note discusses two protocols intended to provide protection
of prompts, elevating their status as intellectual property, thus confirming
the intellectual property rights of prompt engineers, and potentially
supporting the flourishing of an open market for LLM prompts.
\\ ( https://arxiv.org/abs/2306.06297 ,  123kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06376 (*cross-listing*)
Date: Sat, 10 Jun 2023 07:57:24 GMT   (272kb,D)

Title: Enjoy the Silence: Analysis of Stochastic Petri Nets with Silent
 Transitions
Authors: Sander J. J. Leemans, Fabrizio M. Maggi, Marco Montali
Categories: cs.LO cs.AI
\\
 Capturing stochastic behaviors in business and work processes is essential to
quantitatively understand how nondeterminism is resolved when taking decisions
within the process. This is of special interest in process mining, where event
data tracking the actual execution of the process are related to process
models, and can then provide insights on frequencies and probabilities.
Variants of stochastic Petri nets provide a natural formal basis for this.
However, when capturing processes, such nets need to be labelled with (possibly
duplicated) activities, and equipped with silent transitions that model
internal, non-logged steps related to the orchestration of the process. At the
same time, they have to be analyzed in a finite-trace semantics, matching the
fact that each process execution consists of finitely many steps. These two
aspects impede the direct application of existing techniques for stochastic
Petri nets, calling for a novel characterization that incorporates labels and
silent transitions in a finite-trace semantics. In this article, we provide
such a characterization starting from generalized stochastic Petri nets and
obtaining the framework of labelled stochastic processes (LSPs). On top of this
framework, we introduce different key analysis tasks on the traces of LSPs and
their probabilities. We show that all such analysis tasks can be solved
analytically, in particular reducing them to a single method that combines
automata-based techniques to single out the behaviors of interest within a LSP,
with techniques based on absorbing Markov chains to reason on their
probabilities. Finally, we demonstrate the significance of how our approach in
the context of stochastic conformance checking, illustrating practical
feasibility through a proof-of-concept implementation and its application to
different datasets.
\\ ( https://arxiv.org/abs/2306.06376 ,  272kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06386 (*cross-listing*)
Date: Sat, 10 Jun 2023 09:17:45 GMT   (4082kb,D)

Title: Learnersourcing in the Age of AI: Student, Educator and Machine
 Partnerships for Content Creation
Authors: Hassan Khosravi and Paul Denny and Steven Moore and John Stamper
Categories: cs.HC cs.AI
\\
 Engaging students in creating novel content, also referred to as
learnersourcing, is increasingly recognised as an effective approach to
promoting higher-order learning, deeply engaging students with course material
and developing large repositories of content suitable for personalized
learning. Despite these benefits, some common concerns and criticisms are
associated with learnersourcing (e.g., the quality of resources created by
students, challenges in incentivising engagement and lack of availability of
reliable learnersourcing systems), which have limited its adoption. This paper
presents a framework that considers the existing learnersourcing literature,
the latest insights from the learning sciences and advances in AI to offer
promising future directions for developing learnersourcing systems. The
framework is designed around important questions and human-AI partnerships
relating to four key aspects: (1) creating novel content, (2) evaluating the
quality of the created content, (3) utilising learnersourced contributions of
students and (4) enabling instructors to support students in the
learnersourcing process. We then present two comprehensive case studies that
illustrate the application of the proposed framework in relation to two
existing popular learnersourcing systems.
\\ ( https://arxiv.org/abs/2306.06386 ,  4082kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06452 (*cross-listing*)
Date: Sat, 10 Jun 2023 14:18:44 GMT   (2554kb,D)

Title: BlockTheFall: Wearable Device-based Fall Detection Framework Powered by
 Machine Learning and Blockchain for Elderly Care
Authors: Bilash Saha, Md Saiful Islam, Abm Kamrul Riad, Sharaban Tahora,
 Hossain Shahriar, Sweta Sneha
Categories: cs.CY cs.AI
Comments: Accepted to publish in The 1st IEEE International Workshop on Digital
 and Public Health
\\
 Falls among the elderly are a major health concern, frequently resulting in
serious injuries and a reduced quality of life. In this paper, we propose
"BlockTheFall," a wearable device-based fall detection framework which detects
falls in real time by using sensor data from wearable devices. To accurately
identify patterns and detect falls, the collected sensor data is analyzed using
machine learning algorithms. To ensure data integrity and security, the
framework stores and verifies fall event data using blockchain technology. The
proposed framework aims to provide an efficient and dependable solution for
fall detection with improved emergency response, and elderly individuals'
overall well-being. Further experiments and evaluations are being carried out
to validate the effectiveness and feasibility of the proposed framework, which
has shown promising results in distinguishing genuine falls from simulated
falls. By providing timely and accurate fall detection and response, this
framework has the potential to substantially boost the quality of elderly care.
\\ ( https://arxiv.org/abs/2306.06452 ,  2554kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06476 (*cross-listing*)
Date: Sat, 10 Jun 2023 16:28:52 GMT   (1702kb,D)

Title: Modality Influence in Multimodal Machine Learning
Authors: Abdelhamid Haouhat, Slimane Bellaouar, Attia Nehar, Hadda Cherroun
Categories: cs.CL cs.AI
Comments: 10 pages
\\
 Multimodal Machine Learning has emerged as a prominent research direction
across various applications such as Sentiment Analysis, Emotion Recognition,
Machine Translation, Hate Speech Recognition, and Movie Genre Classification.
This approach has shown promising results by utilizing modern deep learning
architectures. Despite the achievements made, challenges remain in data
representation, alignment techniques, reasoning, generation, and quantification
within multimodal learning. Additionally, assumptions about the dominant role
of textual modality in decision-making have been made. However, limited
investigations have been conducted on the influence of different modalities in
Multimodal Machine Learning systems. This paper aims to address this gap by
studying the impact of each modality on multimodal learning tasks. The research
focuses on verifying presumptions and gaining insights into the usage of
different modalities. The main contribution of this work is the proposal of a
methodology to determine the effect of each modality on several Multimodal
Machine Learning models and datasets from various tasks. Specifically, the
study examines Multimodal Sentiment Analysis, Multimodal Emotion Recognition,
Multimodal Hate Speech Recognition, and Multimodal Disease Detection. The study
objectives include training SOTA MultiModal Machine Learning models with masked
modalities to evaluate their impact on performance. Furthermore, the research
aims to identify the most influential modality or set of modalities for each
task and draw conclusions for diverse multimodal classification tasks. By
undertaking these investigations, this research contributes to a better
understanding of the role of individual modalities in multi-modal learning and
provides valuable insights for future advancements in this field.
\\ ( https://arxiv.org/abs/2306.06476 ,  1702kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06521 (*cross-listing*)
Date: Sat, 10 Jun 2023 21:09:16 GMT   (1178kb)

Title: Universal Language Modelling agent
Authors: Anees Aslam
Categories: cs.CL cs.AI cs.LG
\\
 Large Language Models are designed to understand complex Human Language. Yet,
Understanding of animal language has long intrigued researchers striving to
bridge the communication gap between humans and other species. This research
paper introduces a novel approach that draws inspiration from the linguistic
concepts found in the Quran, a revealed Holy Arabic scripture dating back 1400
years. By exploring the linguistic structure of the Quran, specifically the
components of ism, fil, and harf, we aim to unlock the underlying intentions
and meanings embedded within animal conversations using audio data. To unravel
the intricate complexities of animal language, we employ word embedding
techniques to analyze each distinct frequency component. This methodology
enables the identification of potential correlations and the extraction of
meaningful insights from the data. Furthermore, we leverage a bioacoustics
model to generate audio, which serves as a valuable resource for training
natural language processing (NLP) techniques. This Paper aims to find the
intention* behind animal language rather than having each word translation.
\\ ( https://arxiv.org/abs/2306.06521 ,  1178kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06548 (*cross-listing*)
Date: Sun, 11 Jun 2023 00:23:25 GMT   (5855kb,D)

Title: Inductive reasoning in humans and large language models
Authors: Simon J. Han, Keith Ransom, Andrew Perfors, Charles Kemp
Categories: cs.CL cs.AI
Comments: 57 pages, 5 figures
\\
 The impressive recent performance of large language models has led many to
wonder to what extent they can serve as models of general intelligence or are
similar to human cognition. We address this issue by applying GPT-3 and GPT-4
to a classic problem in human inductive reasoning known as property induction.
Over two experiments, we elicit human judgments on a range of property
induction tasks spanning multiple domains. Although GPT-3 struggles to capture
many aspects of human behaviour, GPT-4 is much more successful: for the most
part, its performance qualitatively matches that of humans, and the only
notable exception is its failure to capture the phenomenon of premise
non-monotonicity. Overall, this work not only demonstrates that property
induction is an interesting skill on which to compare human and machine
intelligence, but also provides two large datasets that can serve as suitable
benchmarks for future work in this vein.
\\ ( https://arxiv.org/abs/2306.06548 ,  5855kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06615 (*cross-listing*)
Date: Sun, 11 Jun 2023 08:16:25 GMT   (7225kb,D)

Title: Empowering Molecule Discovery for Molecule-Caption Translation with
 Large Language Models: A ChatGPT Perspective
Authors: Jiatong Li, Yunqing Liu, Wenqi Fan, Xiao-Yong Wei, Hui Liu, Jiliang
 Tang, and Qing Li
Categories: cs.CL cs.AI
Comments: Our implementation is available at:
 https://github.com/phenixace/MolReGPT
\\
 Molecule discovery plays a crucial role in various scientific fields,
advancing the design of tailored materials and drugs. Traditional methods for
molecule discovery follow a trial-and-error process, which are both
time-consuming and costly, while computational approaches such as artificial
intelligence (AI) have emerged as revolutionary tools to expedite various
tasks, like molecule-caption translation. Despite the importance of
molecule-caption translation for molecule discovery, most of the existing
methods heavily rely on domain experts, require excessive computational cost,
and suffer from poor performance. On the other hand, Large Language Models
(LLMs), like ChatGPT, have shown remarkable performance in various cross-modal
tasks due to their great powerful capabilities in natural language
understanding, generalization, and reasoning, which provides unprecedented
opportunities to advance molecule discovery. To address the above limitations,
in this work, we propose a novel LLMs-based framework (\textbf{MolReGPT}) for
molecule-caption translation, where a retrieval-based prompt paradigm is
introduced to empower molecule discovery with LLMs like ChatGPT without
fine-tuning. More specifically, MolReGPT leverages the principle of molecular
similarity to retrieve similar molecules and their text descriptions from a
local database to ground the generation of LLMs through in-context few-shot
molecule learning. We evaluate the effectiveness of MolReGPT via
molecule-caption translation, which includes molecule understanding and
text-based molecule generation. Experimental results show that MolReGPT
outperforms fine-tuned models like MolT5-base without any additional training.
To the best of our knowledge, MolReGPT is the first work to leverage LLMs in
molecule-caption translation for advancing molecule discovery.
\\ ( https://arxiv.org/abs/2306.06615 ,  7225kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06620 (*cross-listing*)
Date: Sun, 11 Jun 2023 08:41:37 GMT   (6104kb,D)

Title: ARIST: An Effective API Argument Recommendation Approach
Authors: Son Nguyen, Cuong Tran Manh, Kien T. Tran, Tan M. Nguyen, Thu-Trang
 Nguyen, Kien-Tuan Ngo and Hieu Dinh Vo
Categories: cs.SE cs.AI
\\
 Learning and remembering to use APIs are difficult. Several techniques have
been proposed to assist developers in using APIs. Most existing techniques
focus on recommending the right API methods to call, but very few techniques
focus on recommending API arguments. In this paper, we propose ARIST, a novel
automated argument recommendation approach which suggests arguments by
predicting developers' expectations when they define and use API methods. To
implement this idea in the recommendation process, ARIST combines program
analysis (PA), language models (LMs), and several features specialized for the
recommendation task which consider the functionality of formal parameters and
the positional information of code elements (e.g., variables or method calls)
in the given context. In ARIST, the LMs and the recommending features are used
to suggest the promising candidates identified by PA. Meanwhile, PA navigates
the LMs and the features working on the set of the valid candidates which
satisfy syntax, accessibility, and type-compatibility constraints defined by
the programming language in use. Our evaluation on a large dataset of
real-world projects shows that ARIST improves the state-of-the-art approach by
19% and 18% in top-1 precision and recall for recommending arguments of
frequently-used libraries. For general argument recommendation task, i.e.,
recommending arguments for every method call, ARIST outperforms the baseline
approaches by up to 125% top-1 accuracy. Moreover, for newly-encountered
projects, ARIST achieves more than 60% top-3 accuracy when evaluating on a
larger dataset. For working/maintaining projects, with a personalized LM to
capture developers' coding practice, ARIST can productively rank the expected
arguments at the top-1 position in 7/10 requests.
\\ ( https://arxiv.org/abs/2306.06620 ,  6104kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06625 (*cross-listing*)
Date: Sun, 11 Jun 2023 08:53:27 GMT   (453kb,D)

Title: Are Intermediate Layers and Labels Really Necessary? A General Language
 Model Distillation Method
Authors: Shicheng Tan, Weng Lam Tam, Yuanchun Wang, Wenwen Gong, Shu Zhao, Peng
 Zhang, Jie Tang
Categories: cs.CL cs.AI
Comments: Accepted to Findings of ACL2023
\\
 The large scale of pre-trained language models poses a challenge for their
deployment on various devices, with a growing emphasis on methods to compress
these models, particularly knowledge distillation. However, current knowledge
distillation methods rely on the model's intermediate layer features and the
golden labels (also called hard labels), which usually require aligned model
architecture and enough labeled data respectively. Moreover, the parameters of
vocabulary are usually neglected in existing methods. To address these
problems, we propose a general language model distillation (GLMD) method that
performs two-stage word prediction distillation and vocabulary compression,
which is simple and surprisingly shows extremely strong performance.
Specifically, GLMD supports more general application scenarios by eliminating
the constraints of dimension and structure between models and the need for
labeled datasets through the absence of intermediate layers and golden labels.
Meanwhile, based on the long-tailed distribution of word frequencies in the
data, GLMD designs a strategy of vocabulary compression through decreasing
vocabulary size instead of dimensionality. Experimental results show that our
method outperforms 25 state-of-the-art methods on the SuperGLUE benchmark,
achieving an average score that surpasses the best method by 3%.
\\ ( https://arxiv.org/abs/2306.06625 ,  453kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06629 (*cross-listing*)
Date: Sun, 11 Jun 2023 09:17:21 GMT   (333kb,D)

Title: GKD: A General Knowledge Distillation Framework for Large-scale
 Pre-trained Language Model
Authors: Shicheng Tan, Weng Lam Tam, Yuanchun Wang, Wenwen Gong, Yang Yang,
 Hongyin Tang, Keqing He, Jiahao Liu, Jingang Wang, Shu Zhao, Peng Zhang, Jie
 Tang
Categories: cs.CL cs.AI
Comments: accepted for ACL 2023 industry track
\\
 Currently, the reduction in the parameter scale of large-scale pre-trained
language models (PLMs) through knowledge distillation has greatly facilitated
their widespread deployment on various devices. However, the deployment of
knowledge distillation systems faces great challenges in real-world
industrial-strength applications, which require the use of complex distillation
methods on even larger-scale PLMs (over 10B), limited by memory on GPUs and the
switching of methods. To overcome these challenges, we propose GKD, a general
knowledge distillation framework that supports distillation on larger-scale
PLMs using various distillation methods. With GKD, developers can build larger
distillation models on memory-limited GPUs and easily switch and combine
different distillation methods within a single framework. Experimental results
show that GKD can support the distillation of at least 100B-scale PLMs and 25
mainstream methods on 8 NVIDIA A100 (40GB) GPUs.
\\ ( https://arxiv.org/abs/2306.06629 ,  333kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06651 (*cross-listing*)
Date: Sun, 11 Jun 2023 11:16:27 GMT   (16284kb,D)

Title: Predicting Software Performance with Divide-and-Learn
Authors: Jingzhi Gong, Tao Chen
Categories: cs.SE cs.AI cs.PF
Comments: This paper has been accepted by The ACM Joint European Software
 Engineering Conference and Symposium on the Foundations of Software
 Engineering (ESEC/FSE), 2023
\\
 Predicting the performance of highly configurable software systems is the
foundation for performance testing and quality assurance. To that end, recent
work has been relying on machine/deep learning to model software performance.
However, a crucial yet unaddressed challenge is how to cater for the sparsity
inherited from the configuration landscape: the influence of configuration
options (features) and the distribution of data samples are highly sparse.
 In this paper, we propose an approach based on the concept of
'divide-and-learn', dubbed $DaL$. The basic idea is that, to handle sample
sparsity, we divide the samples from the configuration landscape into distant
divisions, for each of which we build a regularized Deep Neural Network as the
local model to deal with the feature sparsity. A newly given configuration
would then be assigned to the right model of division for the final prediction.
 Experiment results from eight real-world systems and five sets of training
data reveal that, compared with the state-of-the-art approaches, $DaL$ performs
no worse than the best counterpart on 33 out of 40 cases (within which 26 cases
are significantly better) with up to $1.94\times$ improvement on accuracy;
requires fewer samples to reach the same/better accuracy; and producing
acceptable training overhead. Practically, $DaL$ also considerably improves
different global models when using them as the underlying local models, which
further strengthens its flexibility. To promote open science, all the data,
code, and supplementary figures of this work can be accessed at our repository:
https://github.com/ideas-labo/DaL.
\\ ( https://arxiv.org/abs/2306.06651 ,  16284kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06662 (*cross-listing*)
Date: Sun, 11 Jun 2023 12:25:02 GMT   (198kb,D)

Title: EaSyGuide : ESG Issue Identification Framework leveraging Abilities of
 Generative Large Language Models
Authors: Hanwool Lee, Jonghyun Choi, Sohyeon Kwon, Sungbum Jung
Categories: cs.CL cs.AI
Comments: Accepted at The IJCAI-2023 Workshop On Financial Technology and
 Natural Language Processing (FinNLP)
\\
 This paper presents our participation in the FinNLP-2023 shared task on
multi-lingual environmental, social, and corporate governance issue
identification (ML-ESG). The task's objective is to classify news articles
based on the 35 ESG key issues defined by the MSCI ESG rating guidelines. Our
approach focuses on the English and French subtasks, employing the CerebrasGPT,
OPT, and Pythia models, along with the zero-shot and GPT3Mix Augmentation
techniques. We utilize various encoder models, such as RoBERTa, DeBERTa, and
FinBERT, subjecting them to knowledge distillation and additional training.
 Our approach yielded exceptional results, securing the first position in the
English text subtask with F1-score 0.69 and the second position in the French
text subtask with F1-score 0.78. These outcomes underscore the effectiveness of
our methodology in identifying ESG issues in news articles across different
languages. Our findings contribute to the exploration of ESG topics and
highlight the potential of leveraging advanced language models for ESG issue
identification.
\\ ( https://arxiv.org/abs/2306.06662 ,  198kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06672 (*cross-listing*)
Date: Sun, 11 Jun 2023 12:53:46 GMT   (458kb,D)

Title: Reducing Barriers to Self-Supervised Learning: HuBERT Pre-training with
 Academic Compute
Authors: William Chen, Xuankai Chang, Yifan Peng, Zhaoheng Ni, Soumi Maiti,
 Shinji Watanabe
Categories: cs.CL cs.AI eess.AS
Comments: Accepted at INTERSPEECH 2023
\\
 Self-supervised learning (SSL) has led to great strides in speech processing.
However, the resources needed to train these models has become prohibitively
large as they continue to scale. Currently, only a few groups with substantial
resources are capable of creating SSL models, which harms reproducibility. In
this work, we optimize HuBERT SSL to fit in academic constraints. We reproduce
HuBERT independently from the original implementation, with no performance
loss. Our code and training optimizations make SSL feasible with only 8 GPUs,
instead of the 32 used in the original work. We also explore a semi-supervised
route, using an ASR model to skip the first pre-training iteration. Within one
iteration of pre-training, our models improve over HuBERT on several tasks.
Furthermore, our HuBERT Large variant requires only 8 GPUs, achieving similar
performance to the original trained on 128. As our contribution to the
community, all models, configurations, and code are made open-source in ESPnet.
\\ ( https://arxiv.org/abs/2306.06672 ,  458kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06686 (*cross-listing*)
Date: Sun, 11 Jun 2023 14:01:15 GMT   (11280kb,D)

Title: UAV Trajectory and Multi-User Beamforming Optimization for Clustered
 Users Against Passive Eavesdropping Attacks With Unknown CSI
Authors: Aly Sabri Abdalla, Ali Behfarnia, and Vuk Marojevic
Categories: cs.IT cs.AI cs.CR eess.SP math.IT
Comments: This paper has been accepted for publication in the IEEE Transactions
 on Vehicular Technology
\\
 This paper tackles the fundamental passive eavesdropping problem in modern
wireless communications in which the location and the channel state information
(CSI) of the attackers are unknown. In this regard, we propose deploying an
unmanned aerial vehicle (UAV) that serves as a mobile aerial relay (AR) to help
ground base station (GBS) support a subset of vulnerable users. More precisely,
our solution (1) clusters the single-antenna users in two groups to be either
served by the GBS directly or via the AR, (2) employs optimal multi-user
beamforming to the directly served users, and (3) optimizes the AR's 3D
position, its multi-user beamforming matrix and transmit powers by combining
closed-form solutions with machine learning techniques. Specifically, we design
a plain beamforming and power optimization combined with a deep reinforcement
learning (DRL) algorithm for an AR to optimize its trajectory for the security
maximization of the served users. Numerical results show that the multi-user
multiple input, single output (MU-MISO) system split between a GBS and an AR
with optimized transmission parameters without knowledge of the eavesdropping
channels achieves high secrecy capacities that scale well with increasing the
number of users.
\\ ( https://arxiv.org/abs/2306.06686 ,  11280kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06688 (*cross-listing*)
Date: Sun, 11 Jun 2023 14:03:09 GMT   (690kb,D)

Title: Language Versatilists vs. Specialists: An Empirical Revisiting on
 Multilingual Transfer Ability
Authors: Jiacheng Ye, Xijia Tao, Lingpeng Kong
Categories: cs.CL cs.AI
\\
 Multilingual transfer ability, which reflects how well the models fine-tuned
on one source language can be applied to other languages, has been well studied
in multilingual pre-trained models (e.g., BLOOM). However, such ability has not
been investigated for English-centric models (e.g., LLaMA). To fill this gap,
we study the following research questions. First, does multilingual transfer
ability exist in English-centric models and how does it compare with
multilingual pretrained models? Second, does it only appears when English is
the source language for the English-centric model? Third, how does it vary in
different tasks? We take multilingual reasoning ability as our focus and
conduct extensive experiments across four types of reasoning tasks. We find
that the multilingual pretrained model does not always outperform an
English-centric model. Furthermore, English appears to be a less suitable
source language, and the choice of source language becomes less important when
the English-centric model scales up. In addition, different types of tasks
exhibit different multilingual transfer abilities. These findings demonstrate
that English-centric models not only possess multilingual transfer ability but
may even surpass the transferability of multilingual pretrained models if
well-trained. By showing the strength and weaknesses, the experiments also
provide valuable insights into enhancing multilingual reasoning abilities for
the English-centric models.
\\ ( https://arxiv.org/abs/2306.06688 ,  690kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06748 (*cross-listing*)
Date: Sun, 11 Jun 2023 19:12:30 GMT   (13532kb,D)

Title: Moving beyond simulation: data-driven quantitative photoacoustic imaging
 using tissue-mimicking phantoms
Authors: Janek Gr\"ohl, Thomas R. Else, Lina Hacker, Ellie V. Bunce, Paul W.
 Sweeney, Sarah E. Bohndiek
Categories: eess.IV cs.AI cs.LG physics.med-ph
Comments: 20 pages, 14 figures
\\
 Accurate measurement of optical absorption coefficients from photoacoustic
imaging (PAI) data would enable direct mapping of molecular concentrations,
providing vital clinical insight. The ill-posed nature of the problem of
absorption coefficient recovery has prohibited PAI from achieving this goal in
living systems due to the domain gap between simulation and experiment. To
bridge this gap, we introduce a collection of experimentally well-characterised
imaging phantoms and their digital twins. This first-of-a-kind phantom data set
enables supervised training of a U-Net on experimental data for pixel-wise
estimation of absorption coefficients. We show that training on simulated data
results in artefacts and biases in the estimates, reinforcing the existence of
a domain gap between simulation and experiment. Training on experimentally
acquired data, however, yielded more accurate and robust estimates of optical
absorption coefficients. We compare the results to fluence correction with a
Monte Carlo model from reference optical properties of the materials, which
yields a quantification error of approximately 20%. Application of the trained
U-Nets to a blood flow phantom demonstrated spectral biases when training on
simulated data, while application to a mouse model highlighted the ability of
both learning-based approaches to recover the depth-dependent loss of signal
intensity. We demonstrate that training on experimental phantoms can restore
the correlation of signal amplitudes measured in depth. While the absolute
quantification error remains high and further improvements are needed, our
results highlight the promise of deep learning to advance quantitative PAI.
\\ ( https://arxiv.org/abs/2306.06748 ,  13532kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06755 (*cross-listing*)
Date: Sun, 11 Jun 2023 19:47:52 GMT   (998kb,D)

Title: Attention, Compilation, and Solver-based Symbolic Analysis are All You
 Need
Authors: Prithwish Jana, Piyush Jha, Haoyang Ju, Gautham Kishore, Aryan Mahajan
 and Vijay Ganesh
Categories: cs.PL cs.AI cs.SE
ACM-class: I.2.7; I.2.5; D.2
\\
 In this paper we present a Java-to-Python (J2P) and Python-to-Java (P2J)
back-to-back code translation method, and associated tool called CoTran, based
on large language models (LLMs). Our method leverages the attention mechanism
of LLMs, compilation, and symbolic execution-based test generation for
equivalence testing between the input and output programs. More precisely, we
modify the typical LLM training loop to incorporate compiler and symbolic
execution loss. Via extensive experiments comparing CoTran with 10 other
transpilers and LLM-based translation tools over a benchmark of more than
57,000 Java-Python equivalent pairs, we show that CoTran outperforms them on
relevant metrics such as compilation and runtime equivalence accuracy. For
example, our tool gets 97.43% compilation accuracy and 49.66% runtime
equivalence accuracy for J2P translation, whereas the nearest competing tool
only gets 96.44% and 6.8% respectively.
\\ ( https://arxiv.org/abs/2306.06755 ,  998kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06782 (*cross-listing*)
Date: Sun, 11 Jun 2023 21:44:47 GMT   (7504kb,D)

Title: Augmenting Greybox Fuzzing with Generative AI
Authors: Jie Hu (University of California Riverside), Qian Zhang (University of
 California Riverside), Heng Yin (University of California Riverside)
Categories: cs.CR cs.AI
Comments: 20 pages, 11 figures
\\
 Real-world programs expecting structured inputs often has a format-parsing
stage gating the deeper program space. Neither a mutation-based approach nor a
generative approach can provide a solution that is effective and scalable.
Large language models (LLM) pre-trained with an enormous amount of natural
language corpus have proved to be effective for understanding the implicit
format syntax and generating format-conforming inputs. In this paper, propose
ChatFuzz, a greybox fuzzer augmented by generative AI. More specifically, we
pick a seed in the fuzzer's seed pool and prompt ChatGPT generative models to
variations, which are more likely to be format-conforming and thus of high
quality. We conduct extensive experiments to explore the best practice for
harvesting the power of generative LLM models. The experiment results show that
our approach improves the edge coverage by 12.77\% over the SOTA greybox fuzzer
(AFL++) on 12 target programs from three well-tested benchmarks. As for
vulnerability detection, \sys is able to perform similar to or better than
AFL++ for programs with explicit syntax rules but not for programs with
non-trivial syntax.
\\ ( https://arxiv.org/abs/2306.06782 ,  7504kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06794 (*cross-listing*)
Date: Sun, 11 Jun 2023 22:15:01 GMT   (25518kb,D)

Title: A blind spot for large language models: Supradiegetic linguistic
 information
Authors: Julia Witte Zimmerman, Denis Hudon, Kathryn Cramer, Jonathan St. Onge,
 Mikaela Fudolig, Milo Z. Trujillo, Christopher M. Danforth, Peter Sheridan
 Dodds
Categories: cs.CL cs.AI
Comments: 21 pages, 6 figures, 3 tables
\\
 Large Language Models (LLMs) like ChatGPT reflect profound changes in the
field of Artificial Intelligence, achieving a linguistic fluency that is
impressively, even shockingly, human-like. The extent of their current and
potential capabilities is an active area of investigation by no means limited
to scientific researchers. It is common for people to frame the training data
for LLMs as "text" or even "language". We examine the details of this framing
using ideas from several areas, including linguistics, embodied cognition,
cognitive science, mathematics, and history. We propose that considering what
it is like to be an LLM like ChatGPT, as Nagel might have put it, can help us
gain insight into its capabilities in general, and in particular, that its
exposure to linguistic training data can be productively reframed as exposure
to the diegetic information encoded in language, and its deficits can be
reframed as ignorance of extradiegetic information, including supradiegetic
linguistic information. Supradiegetic linguistic information consists of those
arbitrary aspects of the physical form of language that are not derivable from
the one-dimensional relations of context -- frequency, adjacency, proximity,
co-occurrence -- that LLMs like ChatGPT have access to. Roughly speaking, the
diegetic portion of a word can be thought of as its function, its meaning, as
the information in a theoretical vector in a word embedding, while the
supradiegetic portion of the word can be thought of as its form, like the
shapes of its letters or the sounds of its syllables. We use these concepts to
investigate why LLMs like ChatGPT have trouble handling palindromes, the visual
characteristics of symbols, translating Sumerian cuneiform, and continuing
integer sequences.
\\ ( https://arxiv.org/abs/2306.06794 ,  25518kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06812 (*cross-listing*)
Date: Mon, 12 Jun 2023 01:06:22 GMT   (651kb,D)

Title: Particularity
Authors: Lee Spector, Li Ding, Ryan Boldi
Categories: cs.NE cs.AI cs.LG
Comments: Genetic Programming Theory and Practice XX
ACM-class: I.2.2; I.2.6
\\
 We describe a design principle for adaptive systems under which adaptation is
driven by particular challenges that the environment poses, as opposed to
average or otherwise aggregated measures of performance over many challenges.
We trace the development of this "particularity" approach from the use of
lexicase selection in genetic programming to "particularist" approaches to
other forms of machine learning and to the design of adaptive systems more
generally.
\\ ( https://arxiv.org/abs/2306.06812 ,  651kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06814 (*cross-listing*)
Date: Mon, 12 Jun 2023 01:21:41 GMT   (1364kb,D)

Title: HiddenSinger: High-Quality Singing Voice Synthesis via Neural Audio
 Codec and Latent Diffusion Models
Authors: Ji-Sang Hwang, Sang-Hoon Lee, and Seong-Whan Lee
Categories: eess.AS cs.AI cs.SD eess.SP
Comments: 11 pages, 5 figures, 5 tables, under review
\\
 Recently, denoising diffusion models have demonstrated remarkable performance
among generative models in various domains. However, in the speech domain, the
application of diffusion models for synthesizing time-varying audio faces
limitations in terms of complexity and controllability, as speech synthesis
requires very high-dimensional samples with long-term acoustic features. To
alleviate the challenges posed by model complexity in singing voice synthesis,
we propose HiddenSinger, a high-quality singing voice synthesis system using a
neural audio codec and latent diffusion models. To ensure high-fidelity audio,
we introduce an audio autoencoder that can encode audio into an audio codec as
a compressed representation and reconstruct the high-fidelity audio from the
low-dimensional compressed latent vector. Subsequently, we use the latent
diffusion models to sample a latent representation from a musical score. In
addition, our proposed model is extended to an unsupervised singing voice
learning framework, HiddenSinger-U, to train the model using an unlabeled
singing voice dataset. Experimental results demonstrate that our model
outperforms previous models in terms of audio quality. Furthermore, the
HiddenSinger-U can synthesize high-quality singing voices of speakers trained
solely on unlabeled data.
\\ ( https://arxiv.org/abs/2306.06814 ,  1364kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06826 (*cross-listing*)
Date: Mon, 12 Jun 2023 02:26:00 GMT   (1208kb,D)

Title: When Do Annotator Demographics Matter? Measuring the Influence of
 Annotator Demographics with the POPQUORN Dataset
Authors: Jiaxin Pei and David Jurgens
Categories: cs.CL cs.AI cs.CY cs.HC cs.LG
\\
 Annotators are not fungible. Their demographics, life experiences, and
backgrounds all contribute to how they label data. However, NLP has only
recently considered how annotator identity might influence their decisions.
Here, we present POPQUORN (the POtato-Prolific dataset for QUestion-Answering,
Offensiveness, text Rewriting, and politeness rating with demographic Nuance).
POPQUORN contains 45,000 annotations from 1,484 annotators, drawn from a
representative sample regarding sex, age, and race as the US population.
Through a series of analyses, we show that annotators' background plays a
significant role in their judgments. Further, our work shows that backgrounds
not previously considered in NLP (e.g., education), are meaningful and should
be considered. Our study suggests that understanding the background of
annotators and collecting labels from a demographically balanced pool of crowd
workers is important to reduce the bias of datasets. The dataset, annotator
background, and annotation interface are available at
https://github.com/Jiaxin-Pei/potato-prolific-dataset .
\\ ( https://arxiv.org/abs/2306.06826 ,  1208kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06891 (*cross-listing*)
Date: Mon, 12 Jun 2023 06:34:16 GMT   (7273kb,D)

Title: Recursion of Thought: A Divide-and-Conquer Approach to Multi-Context
 Reasoning with Language Models
Authors: Soochan Lee and Gunhee Kim
Categories: cs.CL cs.AI
Comments: ACL 2023 (short, findings)
\\
 Generating intermediate steps, or Chain of Thought (CoT), is an effective way
to significantly improve language models' (LM) multi-step reasoning capability.
However, the CoT lengths can grow rapidly with the problem complexity, easily
exceeding the maximum context size. Instead of increasing the context limit,
which has already been heavily investigated, we explore an orthogonal
direction: making LMs divide a problem into multiple contexts. We propose a new
inference framework, called Recursion of Thought (RoT), which introduces
several special tokens that the models can output to trigger context-related
operations. Extensive experiments with multiple architectures including GPT-3
show that RoT dramatically improves LMs' inference capability to solve
problems, whose solution consists of hundreds of thousands of tokens.
\\ ( https://arxiv.org/abs/2306.06891 ,  7273kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06918 (*cross-listing*)
Date: Mon, 12 Jun 2023 07:38:31 GMT   (776kb,D)

Title: The Devil is in the Details: On the Pitfalls of Event Extraction
 Evaluation
Authors: Peng Hao, Wang Xiaozhi, Yao Feng, Zeng Kaisheng, Hou Lei, Li Juanzi,
 Liu Zhiyuan, Shen Weixing
Categories: cs.CL cs.AI
Comments: Accepted at ACL 2023
\\
 Event extraction (EE) is a crucial task aiming at extracting events from
texts, which includes two subtasks: event detection (ED) and event argument
extraction (EAE). In this paper, we check the reliability of EE evaluations and
identify three major pitfalls: (1) The data preprocessing discrepancy makes the
evaluation results on the same dataset not directly comparable, but the data
preprocessing details are not widely noted and specified in papers. (2) The
output space discrepancy of different model paradigms makes different-paradigm
EE models lack grounds for comparison and also leads to unclear mapping issues
between predictions and annotations. (3) The absence of pipeline evaluation of
many EAE-only works makes them hard to be directly compared with EE works and
may not well reflect the model performance in real-world pipeline scenarios. We
demonstrate the significant influence of these pitfalls through comprehensive
meta-analyses of recent papers and empirical experiments. To avoid these
pitfalls, we suggest a series of remedies, including specifying data
preprocessing, standardizing outputs, and providing pipeline evaluation
results. To help implement these remedies, we develop a consistent evaluation
framework OMNIEVENT, which can be obtained from
https://github.com/THU-KEG/OmniEvent.
\\ ( https://arxiv.org/abs/2306.06918 ,  776kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06919 (*cross-listing*)
Date: Mon, 12 Jun 2023 07:39:06 GMT   (9576kb,D)

Title: Learning Multilingual Sentence Representations with Cross-lingual
 Consistency Regularization
Authors: Pengzhi Gao, Liwen Zhang, Zhongjun He, Hua Wu, Haifeng Wang
Categories: cs.CL cs.AI
\\
 Multilingual sentence representations are the foundation for similarity-based
bitext mining, which is crucial for scaling multilingual neural machine
translation (NMT) system to more languages. In this paper, we introduce MuSR: a
one-for-all Multilingual Sentence Representation model that supports more than
220 languages. Leveraging billions of English-centric parallel corpora, we
train a multilingual Transformer encoder, coupled with an auxiliary Transformer
decoder, by adopting a multilingual NMT framework with CrossConST, a
cross-lingual consistency regularization technique proposed in Gao et al.
(2023). Experimental results on multilingual similarity search and bitext
mining tasks show the effectiveness of our approach. Specifically, MuSR
achieves superior performance over LASER3 (Heffernan et al., 2022) which
consists of 148 independent multilingual sentence encoders.
\\ ( https://arxiv.org/abs/2306.06919 ,  9576kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06935 (*cross-listing*)
Date: Mon, 12 Jun 2023 08:14:16 GMT   (3821kb,D)

Title: LIVABLE: Exploring Long-Tailed Classification of Software Vulnerability
 Types
Authors: Xin-Cheng Wen, Cuiyun Gao, Feng Luo, Haoyu Wang, Ge Li, and Qing Liao
Categories: cs.SE cs.AI
\\
 Prior studies generally focus on software vulnerability detection and have
demonstrated the effectiveness of Graph Neural Network (GNN)-based approaches
for the task. Considering the various types of software vulnerabilities and the
associated different degrees of severity, it is also beneficial to determine
the type of each vulnerable code for developers. In this paper, we observe that
the distribution of vulnerability type is long-tailed in practice, where a
small portion of classes have massive samples (i.e., head classes) but the
others contain only a few samples (i.e., tail classes). Directly adopting
previous vulnerability detection approaches tends to result in poor detection
performance, mainly due to two reasons. First, it is difficult to effectively
learn the vulnerability representation due to the over-smoothing issue of GNNs.
Second, vulnerability types in tails are hard to be predicted due to the
extremely few associated samples.To alleviate these issues, we propose a
Long-taIled software VulnerABiLity typE classification approach, called
LIVABLE. LIVABLE mainly consists of two modules, including (1) vulnerability
representation learning module, which improves the propagation steps in GNN to
distinguish node representations by a differentiated propagation method. A
sequence-to-sequence model is also involved to enhance the vulnerability
representations. (2) adaptive re-weighting module, which adjusts the learning
weights for different types according to the training epochs and numbers of
associated samples by a novel training loss.
\\ ( https://arxiv.org/abs/2306.06935 ,  3821kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06948 (*cross-listing*)
Date: Mon, 12 Jun 2023 08:32:04 GMT   (1992kb,D)

Title: Rethinking Translation Memory Augmented Neural Machine Translation
Authors: Hongkun Hao, Guoping Huang, Lemao Liu, Zhirui Zhang, Shuming Shi, Rui
 Wang
Categories: cs.CL cs.AI
Comments: 15 pages, 2 figures, accepted by ACL2023 findings
\\
 This paper rethinks translation memory augmented neural machine translation
(TM-augmented NMT) from two perspectives, i.e., a probabilistic view of
retrieval and the variance-bias decomposition principle. The finding
demonstrates that TM-augmented NMT is good at the ability of fitting data
(i.e., lower bias) but is more sensitive to the fluctuations in the training
data (i.e., higher variance), which provides an explanation to a recently
reported contradictory phenomenon on the same translation task: TM-augmented
NMT substantially advances vanilla NMT under the high-resource scenario whereas
it fails under the low-resource scenario. Then we propose a simple yet
effective TM-augmented NMT model to promote the variance and address the
contradictory phenomenon. Extensive experiments show that the proposed
TM-augmented NMT achieves consistent gains over both conventional NMT and
existing TM-augmented NMT under two variance-preferable (low-resource and
plug-and-play) scenarios as well as the high-resource scenario.
\\ ( https://arxiv.org/abs/2306.06948 ,  1992kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07052 (*cross-listing*)
Date: Mon, 12 Jun 2023 11:59:33 GMT   (7151kb,D)

Title: Gradient Ascent Post-training Enhances Language Model Generalization
Authors: Dongkeun Yoon, Joel Jang, Sungdong Kim, Minjoon Seo
Categories: cs.CL cs.AI
Comments: ACL 2023 Main Conference (Short Paper)
\\
 In this work, we empirically show that updating pretrained LMs (350M, 1.3B,
2.7B) with just a few steps of Gradient Ascent Post-training (GAP) on random,
unlabeled text corpora enhances its zero-shot generalization capabilities
across diverse NLP tasks. Specifically, we show that GAP can allow LMs to
become comparable to 2-3x times larger LMs across 12 different NLP tasks. We
also show that applying GAP on out-of-distribution corpora leads to the most
reliable performance improvements. Our findings indicate that GAP can be a
promising method for improving the generalization capability of LMs without any
task-specific fine-tuning.
\\ ( https://arxiv.org/abs/2306.07052 ,  7151kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07061 (*cross-listing*)
Date: Mon, 12 Jun 2023 12:24:47 GMT   (8026kb,D)

Title: Deep Model Compression Also Helps Models Capture Ambiguity
Authors: Hancheol Park, Jong C. Park
Categories: cs.CL cs.AI cs.LG
Comments: ACL 2023
\\
 Natural language understanding (NLU) tasks face a non-trivial amount of
ambiguous samples where veracity of their labels is debatable among annotators.
NLU models should thus account for such ambiguity, but they approximate the
human opinion distributions quite poorly and tend to produce over-confident
predictions. To address this problem, we must consider how to exactly capture
the degree of relationship between each sample and its candidate classes. In
this work, we propose a novel method with deep model compression and show how
such relationship can be accounted for. We see that more reasonably represented
relationships can be discovered in the lower layers and that validation
accuracies are converging at these layers, which naturally leads to layer
pruning. We also see that distilling the relationship knowledge from a lower
layer helps models produce better distribution. Experimental results
demonstrate that our method makes substantial improvement on quantifying
ambiguity without gold distribution labels. As positive side-effects, our
method is found to reduce the model size significantly and improve latency,
both attractive aspects of NLU products.
\\ ( https://arxiv.org/abs/2306.07061 ,  8026kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07075 (*cross-listing*)
Date: Mon, 12 Jun 2023 12:40:48 GMT   (492kb)

Title: Large Language Models as Tax Attorneys: A Case Study in Legal
 Capabilities Emergence
Authors: John J. Nay, David Karamardian, Sarah B. Lawsky, Wenting Tao, Meghana
 Bhat, Raghav Jain, Aaron Travis Lee, Jonathan H. Choi, Jungo Kasai
Categories: cs.CL cs.AI cs.CY
\\
 Better understanding of Large Language Models' (LLMs) legal analysis
abilities can contribute to improving the efficiency of legal services,
governing artificial intelligence, and leveraging LLMs to identify
inconsistencies in law. This paper explores LLM capabilities in applying tax
law. We choose this area of law because it has a structure that allows us to
set up automated validation pipelines across thousands of examples, requires
logical reasoning and maths skills, and enables us to test LLM capabilities in
a manner relevant to real-world economic lives of citizens and companies. Our
experiments demonstrate emerging legal understanding capabilities, with
improved performance in each subsequent OpenAI model release. We experiment
with retrieving and utilising the relevant legal authority to assess the impact
of providing additional legal context to LLMs. Few-shot prompting, presenting
examples of question-answer pairs, is also found to significantly enhance the
performance of the most advanced model, GPT-4. The findings indicate that LLMs,
particularly when combined with prompting enhancements and the correct legal
texts, can perform at high levels of accuracy but not yet at expert tax lawyer
levels. As LLMs continue to advance, their ability to reason about law
autonomously could have significant implications for the legal profession and
AI governance.
\\ ( https://arxiv.org/abs/2306.07075 ,  492kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07089 (*cross-listing*)
Date: Mon, 12 Jun 2023 13:01:50 GMT   (2414kb,D)

Title: Topology Repairing of Disconnected Pulmonary Airways and Vessels:
 Baselines and a Dataset
Authors: Ziqiao Weng, Jiancheng Yang, Dongnan Liu, Weidong Cai
Categories: eess.IV cs.AI cs.CV
Comments: MICCAI 2023 Early Accepted
\\
 Accurate segmentation of pulmonary airways and vessels is crucial for the
diagnosis and treatment of pulmonary diseases. However, current deep learning
approaches suffer from disconnectivity issues that hinder their clinical
usefulness. To address this challenge, we propose a post-processing approach
that leverages a data-driven method to repair the topology of disconnected
pulmonary tubular structures. Our approach formulates the problem as a keypoint
detection task, where a neural network is trained to predict keypoints that can
bridge disconnected components. We use a training data synthesis pipeline that
generates disconnected data from complete pulmonary structures. Moreover, the
new Pulmonary Tree Repairing (PTR) dataset is publicly available, which
comprises 800 complete 3D models of pulmonary airways, arteries, and veins, as
well as the synthetic disconnected data. Our code and data are available at
https://github.com/M3DV/pulmonary-tree-repairing.
\\ ( https://arxiv.org/abs/2306.07089 ,  2414kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07111 (*cross-listing*)
Date: Mon, 12 Jun 2023 13:39:54 GMT   (20kb,D)

Title: Linear Classifier: An Often-Forgotten Baseline for Text Classification
Authors: Yu-Chen Lin, Si-An Chen, Jie-Jyun Liu, and Chih-Jen Lin
Categories: cs.CL cs.AI cs.LG
Comments: Accepted by ACL 2023
\\
 Large-scale pre-trained language models such as BERT are popular solutions
for text classification. Due to the superior performance of these advanced
methods, nowadays, people often directly train them for a few epochs and deploy
the obtained model. In this opinion paper, we point out that this way may only
sometimes get satisfactory results. We argue the importance of running a simple
baseline like linear classifiers on bag-of-words features along with advanced
methods. First, for many text data, linear methods show competitive
performance, high efficiency, and robustness. Second, advanced models such as
BERT may only achieve the best results if properly applied. Simple baselines
help to confirm whether the results of advanced models are acceptable. Our
experimental results fully support these points.
\\ ( https://arxiv.org/abs/2306.07111 ,  20kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07117 (*cross-listing*)
Date: Mon, 12 Jun 2023 13:52:01 GMT   (1859kb,D)

Title: Language of Bargaining
Authors: Mourad Heddaya, Solomon Dworkin, Chenhao Tan, Rob Voigt, Alexander
 Zentefis
Categories: cs.CL cs.AI cs.CY
Comments: ACL 2023 Main Conference
\\
 Leveraging an established exercise in negotiation education, we build a novel
dataset for studying how the use of language shapes bilateral bargaining. Our
dataset extends existing work in two ways: 1) we recruit participants via
behavioral labs instead of crowdsourcing platforms and allow participants to
negotiate through audio, enabling more naturalistic interactions; 2) we add a
control setting where participants negotiate only through alternating, written
numeric offers.Despite the two contrasting forms of communication, we find that
the average agreed prices of the two treatments are identical. But when
subjects can talk, fewer offers are exchanged, negotiations finish faster, the
likelihood of reaching agreement rises, and the variance of prices at which
subjects agree drops substantially. We further propose a taxonomy of speech
acts in negotiation and enrich the dataset with annotated speech acts. We set
up prediction tasks to predict negotiation success and find that being reactive
to the arguments of the other party is advantageous over driving the
negotiation.
\\ ( https://arxiv.org/abs/2306.07117 ,  1859kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07135 (*cross-listing*)
Date: Mon, 12 Jun 2023 14:17:05 GMT   (875kb,D)

Title: On the Amplification of Linguistic Bias through Unintentional
 Self-reinforcement Learning by Generative Language Models -- A Perspective
Authors: Minhyeok Lee
Categories: cs.CL cs.AI
\\
 Generative Language Models (GLMs) have the potential to significantly shape
our linguistic landscape due to their expansive use in various digital
applications. However, this widespread adoption might inadvertently trigger a
self-reinforcement learning cycle that can amplify existing linguistic biases.
This paper explores the possibility of such a phenomenon, where the initial
biases in GLMs, reflected in their generated text, can feed into the learning
material of subsequent models, thereby reinforcing and amplifying these biases.
Moreover, the paper highlights how the pervasive nature of GLMs might influence
the linguistic and cognitive development of future generations, as they may
unconsciously learn and reproduce these biases. The implications of this
potential self-reinforcement cycle extend beyond the models themselves,
impacting human language and discourse. The advantages and disadvantages of
this bias amplification are weighed, considering educational benefits and ease
of future GLM learning against threats to linguistic diversity and dependence
on initial GLMs. This paper underscores the need for rigorous research to
understand and address these issues. It advocates for improved model
transparency, bias-aware training techniques, development of methods to
distinguish between human and GLM-generated text, and robust measures for
fairness and bias evaluation in GLMs. The aim is to ensure the effective, safe,
and equitable use of these powerful technologies, while preserving the richness
and diversity of human language.
\\ ( https://arxiv.org/abs/2306.07135 ,  875kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07195 (*cross-listing*)
Date: Mon, 12 Jun 2023 15:50:38 GMT   (271kb)

Title: Large language models and (non-)linguistic recursion
Authors: Maksymilian D\k{a}bkowski and Ga\v{s}per Begu\v{s}
Categories: cs.CL cs.AI
\\
 Recursion is one of the hallmarks of human language. While many design
features of language have been shown to exist in animal communication systems,
recursion has not. Previous research shows that GPT-4 is the first large
language model (LLM) to exhibit metalinguistic abilities (Begu\v{s},
D\k{a}bkowski, and Rhodes 2023). Here, we propose several prompt designs aimed
at eliciting and analyzing recursive behavior in LLMs, both linguistic and
non-linguistic. We demonstrate that when explicitly prompted, GPT-4 can both
produce and analyze recursive structures. Thus, we present one of the first
studies investigating whether meta-linguistic awareness of recursion -- a
uniquely human cognitive property -- can emerge in transformers with a high
number of parameters such as GPT-4.
\\ ( https://arxiv.org/abs/2306.07195 ,  271kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07206 (*cross-listing*)
Date: Mon, 12 Jun 2023 16:10:21 GMT   (6959kb,D)

Title: RECAP: Retrieval-Enhanced Context-Aware Prefix Encoder for Personalized
 Dialogue Response Generation
Authors: Shuai Liu, Hyundong J. Cho, Marjorie Freedman, Xuezhe Ma, Jonathan May
Categories: cs.CL cs.AI
\\
 Endowing chatbots with a consistent persona is essential to an engaging
conversation, yet it remains an unresolved challenge. In this work, we propose
a new retrieval-enhanced approach for personalized response generation.
Specifically, we design a hierarchical transformer retriever trained on
dialogue domain data to perform personalized retrieval and a context-aware
prefix encoder that fuses the retrieved information to the decoder more
effectively. Extensive experiments on a real-world dataset demonstrate the
effectiveness of our model at generating more fluent and personalized
responses. We quantitatively evaluate our model's performance under a suite of
human and automatic metrics and find it to be superior compared to
state-of-the-art baselines on English Reddit conversations.
\\ ( https://arxiv.org/abs/2306.07206 ,  6959kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07209 (*cross-listing*)
Date: Mon, 12 Jun 2023 16:12:56 GMT   (6220kb,D)

Title: Data-Copilot: Bridging Billions of Data and Humans with Autonomous
 Workflow
Authors: Wenqi Zhang, Yongliang Shen, Weiming Lu, Yueting Zhuang
Categories: cs.CL cs.AI cs.CE
\\
 Various industries such as finance, meteorology, and energy generate vast
amounts of heterogeneous data every day. There is a natural demand for humans
to manage, process, and display data efficiently. However, it necessitates
labor-intensive efforts and a high level of expertise for these data-related
tasks. Considering that large language models (LLMs) have showcased promising
capabilities in semantic understanding and reasoning, we advocate that the
deployment of LLMs could autonomously manage and process massive amounts of
data while displaying and interacting in a human-friendly manner. Based on this
belief, we propose Data-Copilot, an LLM-based system that connects numerous
data sources on one end and caters to diverse human demands on the other end.
Acting like an experienced expert, Data-Copilot autonomously transforms raw
data into visualization results that best match the user's intent.
Specifically, Data-Copilot autonomously designs versatile interfaces (tools)
for data management, processing, prediction, and visualization. In real-time
response, it automatically deploys a concise workflow by invoking corresponding
interfaces step by step for the user's request. The interface design and
deployment processes are fully controlled by Data-Copilot itself, without human
assistance. Besides, we create a Data-Copilot demo that links abundant data
from different domains (stock, fund, company, economics, and live news) and
accurately respond to diverse requests, serving as a reliable AI assistant.
\\ ( https://arxiv.org/abs/2306.07209 ,  6220kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07220 (*cross-listing*)
Date: Mon, 12 Jun 2023 16:26:38 GMT   (25242kb,D)

Title: Strokes2Surface: Recovering Curve Networks From 4D Architectural Design
 Sketches
Authors: S. Rasoulzadeh, M. Wimmer, and I. Kovacic
Categories: cs.GR cs.AI cs.LG
Comments: 14 pages, 16 figures
ACM-class: I.2; I.3
\\
 We present Strokes2Surface, an offline geometry-reconstruction pipeline built
upon a 4D Sketching Interface, MR.Sketch, targeted at architectural design. The
pipeline recovers a curve network from designer-drawn strokes, thus bridging
between concept design and digital modeling stages in architectural design. The
input to our pipeline consists of 3D strokes' polyline vertices and their
corresponding timestamps (as of the fourth dimension), along with additional
geometric and stylus-related recorded properties. Inspired by sketch
consolidation and sketch-based modeling methods, our pipeline leverages such
data and combines three Machine Learning (ML) models; a classifier and two
clustering models. In particular, based on observations of practices designers
typically employ in architectural design sketches, we solve a binary
classification problem to recognize whether a stroke depicts a boundary and
edge or is used to fill in the enclosing areas and faces of the intended
architectural object. Followed by the two clustering models, strokes of each
type are further parsed into groups, each representing either a single edge or
a single face. Next, groups representing edges are approximated with B-spline
curves, followed by a topology-recovering process identifying and fixing
desired connectivities between the curves forming a well-connected curve
network. Next, groups representing the faces are employed to detect the cycles
bounding patches in the curve network, resulting in the final surface mesh
geometry of the architectural object. We confirm the usability of
Strokes2Surface via a user study and further validate and compare our results
against a range of reconstructions computed using alternative methods. We also
introduce our manually labeled dataset of 4D architectural design sketches for
further use in the community.
\\ ( https://arxiv.org/abs/2306.07220 ,  25242kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06116 (*cross-listing*)
Date: Thu, 1 Jun 2023 17:05:18 GMT   (7401kb,D)

Title: Overview of Deep Learning Methods for Retinal Vessel Segmentation
Authors: Gorana Goji\'c, Ognjen Kunda\v{c}ina, Dragi\v{s}a Mi\v{s}kovi\'c, Dinu
 Dragan
Categories: eess.IV cs.CV cs.LG
\\
 Methods for automated retinal vessel segmentation play an important role in
the treatment and diagnosis of many eye and systemic diseases. With the fast
development of deep learning methods, more and more retinal vessel segmentation
methods are implemented as deep neural networks. In this paper, we provide a
brief review of recent deep learning methods from highly influential journals
and conferences. The review objectives are: (1) to assess the design
characteristics of the latest methods, (2) to report and analyze quantitative
values of performance evaluation metrics, and (3) to analyze the advantages and
disadvantages of the recent solutions.
\\ ( https://arxiv.org/abs/2306.06116 ,  7401kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06145 (*cross-listing*)
Date: Fri, 9 Jun 2023 10:34:18 GMT   (5721kb,D)

Title: LDMRes-Net: Enabling Real-Time Disease Monitoring through Efficient
 Image Segmentation
Authors: Shahzaib Iqbal, Tariq M. Khan, Musaed Alhussein, Syed S. Naqvi,
 Muhammad Usman, and Khursheed Aurangzeb
Categories: eess.IV cs.CV cs.LG
\\
 Retinal eye diseases can lead to irreversible vision loss in both eyes if not
diagnosed and treated earlier. Owing to the complexities of retinal diseases,
the likelihood that retinal images would contain two or more abnormalities is
very high. The current deep learning algorithms used for segmenting retinal
images with multiple labels and features suffer from inadequate detection
accuracy and a lack of generalizability. In this paper, we propose a
lightweight and efficient network, featuring dual multi-residual connections to
enhance segmentation performance while minimizing computational cost. The
proposed network is evaluated on eight publicly available retinal image
datasets and achieved promising segmentation results, which demonstrate the
effectiveness of the proposed network for retinal image analysis tasks. The
proposed network's lightweight and efficient design makes it a promising
candidate for real-time retinal image analysis applications.
\\ ( https://arxiv.org/abs/2306.06145 ,  5721kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06195 (*cross-listing*)
Date: Mon, 15 May 2023 20:59:44 GMT   (1316kb,D)

Title: Risk stratification of malignant melanoma using neural networks
Authors: Julian Burghoff, Leonhard Ackermann, Younes Salahdine, Veronika Bram,
 Katharina Wunderlich, Julius Balkenhol, Thomas Dirschka and Hanno Gottschalk
Categories: eess.IV cs.CV
Comments: 7 pages, two figures
\\
 In order to improve the detection and classification of malignant melanoma,
this paper describes an image-based method that can achieve AUROC values of up
to 0.78 without additional clinical information. Furthermore, the importance of
the domain gap between two different image sources is considered, as it is
important to create usability independent of hardware components such as the
high-resolution scanner used. Since for the application of machine learning
methods, alterations of scanner-specific properties such as brightness,
contrast or sharpness can have strong (negative) effects on the quality of the
prediction methods, two ways to overcome this domain gap are discussed in this
paper.
\\ ( https://arxiv.org/abs/2306.06195 ,  1316kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06207 (*cross-listing*)
Date: Tue, 23 May 2023 11:23:38 GMT   (380kb,D)

Title: Towards clinical translation of deep-learning based classification of
 DSA image sequences for stroke treatment
Authors: Timo Baumg\"artner, Benjamin J. Mittmann, Till Malzacher, Johannes
 Ro{\ss}kopf, Michael Braun, Bernd Schmitz, Alfred M. Franz
Categories: physics.med-ph cs.CV
Comments: This is the preprint version of the BVM paper accepted for
 publication in the conference proceedings of "Bildverarbeitung in der Medizin
 2023"
\\
 In the event of stroke, a catheter-guided procedure (thrombectomy) is used to
remove blood clots. Feasibility of machine learning based automatic
classifications for thrombus detection on digital substraction angiography
(DSA) sequences has been demonstrated. It was however not used live in the
clinic, yet. We present an open-source tool for automatic thrombus
classification and test it on three selected clinical cases regarding
functionality and classification runtime. With our trained model all large
vessel occlusions in the M1 segment were correctly classified. One small
remaining M3 thrombus was not detected. Runtime was in the range from 1 to 10
seconds depending on the used hardware. We conclude that our open-source
software tool enables clinical staff to classify DSA sequences in (close to)
realtime and can be used for further studies in clinics.
\\ ( https://arxiv.org/abs/2306.06207 ,  380kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06217 (*cross-listing*)
Date: Fri, 9 Jun 2023 19:30:49 GMT   (1130kb)

Title: BioGAN: An unpaired GAN-based image to image translation model for
 microbiological images
Authors: Saber Mirzaee Bafti, Chee Siang Ang, Gianluca Marcelli, Md. Moinul
 Hossain, Sadiya Maxamhud, Anastasios D. Tsaousis
Categories: eess.IV cs.CV
\\
 A diversified dataset is crucial for training a well-generalized supervised
computer vision algorithm. However, in the field of microbiology, generation
and annotation of a diverse dataset including field-taken images are time
consuming, costly, and in some cases impossible. Image to image translation
frameworks allow us to diversify the dataset by transferring images from one
domain to another. However, most existing image translation techniques require
a paired dataset (original image and its corresponding image in the target
domain), which poses a significant challenge in collecting such datasets. In
addition, the application of these image translation frameworks in microbiology
is rarely discussed. In this study, we aim to develop an unpaired GAN-based
(Generative Adversarial Network) image to image translation model for
microbiological images, and study how it can improve generalization ability of
object detection models. In this paper, we present an unpaired and unsupervised
image translation model to translate laboratory-taken microbiological images to
field images, building upon the recent advances in GAN networks and Perceptual
loss function. We propose a novel design for a GAN model, BioGAN, by utilizing
Adversarial and Perceptual loss in order to transform high level features of
laboratory-taken images into field images, while keeping their spatial
features. The contribution of Adversarial and Perceptual loss in the generation
of realistic field images were studied. We used the synthetic field images,
generated by BioGAN, to train an object-detection framework, and compared the
results with those of an object-detection framework trained with laboratory
images; this resulted in up to 68.1% and 75.3% improvement on F1-score and mAP,
respectively. Codes is publicly available at
https://github.com/Kahroba2000/BioGAN.
\\ ( https://arxiv.org/abs/2306.06217 ,  1130kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06408 (*cross-listing*)
Date: Sat, 10 Jun 2023 10:42:49 GMT   (34922kb,D)

Title: Fast light-field 3D microscopy with out-of-distribution detection and
 adaptation through Conditional Normalizing Flows
Authors: Josu\'e Page Vizca\'ino, Panagiotis Symvoulidis, Zeguan Wang, Jonas
 Jelten, Paolo Favaro, Edward S. Boyden, Tobias Lasser
Categories: eess.IV cs.CV cs.LG q-bio.NC
\\
 Real-time 3D fluorescence microscopy is crucial for the spatiotemporal
analysis of live organisms, such as neural activity monitoring. The eXtended
field-of-view light field microscope (XLFM), also known as Fourier light field
microscope, is a straightforward, single snapshot solution to achieve this. The
XLFM acquires spatial-angular information in a single camera exposure. In a
subsequent step, a 3D volume can be algorithmically reconstructed, making it
exceptionally well-suited for real-time 3D acquisition and potential analysis.
Unfortunately, traditional reconstruction methods (like deconvolution) require
lengthy processing times (0.0220 Hz), hampering the speed advantages of the
XLFM. Neural network architectures can overcome the speed constraints at the
expense of lacking certainty metrics, which renders them untrustworthy for the
biomedical realm. This work proposes a novel architecture to perform fast 3D
reconstructions of live immobilized zebrafish neural activity based on a
conditional normalizing flow. It reconstructs volumes at 8 Hz spanning
512x512x96 voxels, and it can be trained in under two hours due to the small
dataset requirements (10 image-volume pairs). Furthermore, normalizing flows
allow for exact Likelihood computation, enabling distribution monitoring,
followed by out-of-distribution detection and retraining of the system when a
novel sample is detected. We evaluate the proposed method on a cross-validation
approach involving multiple in-distribution samples (genetically identical
zebrafish) and various out-of-distribution ones.
\\ ( https://arxiv.org/abs/2306.06408 ,  34922kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06410 (*cross-listing*)
Date: Sat, 10 Jun 2023 11:04:10 GMT   (11280kb,D)

Title: OpenSR: Open-Modality Speech Recognition via Maintaining Multi-Modality
 Alignment
Authors: Xize Cheng, Tao Jin, Linjun Li, Wang Lin, Xinyu Duan and Zhou Zhao
Categories: cs.CL cs.CV
Comments: Accepted to ACL2023 (Oral)
\\
 Speech Recognition builds a bridge between the multimedia streaming
(audio-only, visual-only or audio-visual) and the corresponding text
transcription. However, when training the specific model of new domain, it
often gets stuck in the lack of new-domain utterances, especially the labeled
visual utterances. To break through this restriction, we attempt to achieve
zero-shot modality transfer by maintaining the multi-modality alignment in
phoneme space learned with unlabeled multimedia utterances in the high resource
domain during the pre-training \cite{shi2022learning}, and propose a training
system Open-modality Speech Recognition (\textbf{OpenSR}) that enables the
models trained on a single modality (e.g., audio-only) applicable to more
modalities (e.g., visual-only and audio-visual). Furthermore, we employ a
cluster-based prompt tuning strategy to handle the domain shift for the
scenarios with only common words in the new domain utterances. We demonstrate
that OpenSR enables modality transfer from one to any in three different
settings (zero-, few- and full-shot), and achieves highly competitive zero-shot
performance compared to the existing few-shot and full-shot lip-reading
methods. To the best of our knowledge, OpenSR achieves the state-of-the-art
performance of word error rate in LRS2 on audio-visual speech recognition and
lip-reading with 2.7\% and 25.0\%, respectively. The code and demo are
available at https://github.com/Exgc/OpenSR.
\\ ( https://arxiv.org/abs/2306.06410 ,  11280kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06491 (*cross-listing*)
Date: Sat, 10 Jun 2023 17:14:41 GMT   (7312kb,D)

Title: Online learning for X-ray, CT or MRI
Authors: Mosabbir Bhuiyan, MD Abdullah Al Nasim, Sarwar Saif, Dr. Kishor Datta
 Gupta, Md Jahangir Alam, Sajedul Talukder
Categories: eess.IV cs.CV cs.LG physics.med-ph
Comments: 14 pages, 17 figures, 1 table; Acceptance of the chapter for the
 Springer book "Data-driven approaches to medical imaging"
\\
 Medical imaging plays an important role in the medical sector in identifying
diseases. X-ray, computed tomography (CT) scans, and magnetic resonance imaging
(MRI) are a few examples of medical imaging. Most of the time, these imaging
techniques are utilized to examine and diagnose diseases. Medical professionals
identify the problem after analyzing the images. However, manual identification
can be challenging because the human eye is not always able to recognize
complex patterns in an image. Because of this, it is difficult for any
professional to recognize a disease with rapidity and accuracy. In recent
years, medical professionals have started adopting Computer-Aided Diagnosis
(CAD) systems to evaluate medical images. This system can analyze the image and
detect the disease very precisely and quickly. However, this system has certain
drawbacks in that it needs to be processed before analysis. Medical research is
already entered a new era of research which is called Artificial Intelligence
(AI). AI can automatically find complex patterns from an image and identify
diseases. Methods for medical imaging that uses AI techniques will be covered
in this chapter.
\\ ( https://arxiv.org/abs/2306.06491 ,  7312kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06669 (*cross-listing*)
Date: Sun, 11 Jun 2023 12:41:23 GMT   (5752kb,D)

Title: TransMRSR: Transformer-based Self-Distilled Generative Prior for Brain
 MRI Super-Resolution
Authors: Shan Huang, Xiaohong Liu, Tao Tan, Menghan Hu, Xiaoer Wei, Tingli
 Chen, Bin Sheng
Categories: eess.IV cs.CV cs.LG
Comments: 2023 CGI
\\
 Magnetic resonance images (MRI) acquired with low through-plane resolution
compromise time and cost. The poor resolution in one orientation is
insufficient to meet the requirement of high resolution for early diagnosis of
brain disease and morphometric study. The common Single image super-resolution
(SISR) solutions face two main challenges: (1) local detailed and global
anatomical structural information combination; and (2) large-scale restoration
when applied for reconstructing thick-slice MRI into high-resolution (HR)
iso-tropic data. To address these problems, we propose a novel two-stage
network for brain MRI SR named TransMRSR based on the convolutional blocks to
extract local information and transformer blocks to capture long-range
dependencies. TransMRSR consists of three modules: the shallow local feature
extraction, the deep non-local feature capture, and the HR image
reconstruction. We perform a generative task to encapsulate diverse priors into
a generative network (GAN), which is the decoder sub-module of the deep
non-local feature capture part, in the first stage. The pre-trained GAN is used
for the second stage of SR task. We further eliminate the potential latent
space shift caused by the two-stage training strategy through the
self-distilled truncation trick. The extensive experiments show that our method
achieves superior performance to other SSIR methods on both public and private
datasets. Code is released at https://github.com/goddesshs/TransMRSR.git .
\\ ( https://arxiv.org/abs/2306.06669 ,  5752kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06747 (*cross-listing*)
Date: Sun, 11 Jun 2023 19:00:41 GMT   (2616kb,D)

Title: Precise and Generalized Robustness Certification for Neural Networks
Authors: Yuanyuan Yuan, Shuai Wang, and Zhendong Su
Categories: cs.CR cs.CV cs.LG
Comments: The extended version of a paper to appear in the Proceedings of the
 32nd USENIX Security Symposium, 2023, (USENIX Security '23), 19 pages
\\
 The objective of neural network (NN) robustness certification is to determine
if a NN changes its predictions when mutations are made to its inputs. While
most certification research studies pixel-level or a few geometrical-level and
blurring operations over images, this paper proposes a novel framework, GCERT,
which certifies NN robustness under a precise and unified form of diverse
semantic-level image mutations. We formulate a comprehensive set of
semantic-level image mutations uniformly as certain directions in the latent
space of generative models. We identify two key properties, independence and
continuity, that convert the latent space into a precise and analysis-friendly
input space representation for certification. GCERT can be smoothly integrated
with de facto complete, incomplete, or quantitative certification frameworks.
With its precise input space representation, GCERT enables for the first time
complete NN robustness certification with moderate cost under diverse
semantic-level input mutations, such as weather-filter, style transfer, and
perceptual changes (e.g., opening/closing eyes). We show that GCERT enables
certifying NN robustness under various common and security-sensitive scenarios
like autonomous driving.
\\ ( https://arxiv.org/abs/2306.06747 ,  2616kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06780 (*cross-listing*)
Date: Sun, 11 Jun 2023 21:30:20 GMT   (13827kb,D)

Title: Multimodal Pathology Image Search Between H&E Slides and Multiplexed
 Immunofluorescent Images
Authors: Amir Hajighasemi, MD Jillur Rahman Saurav, Mohammad S Nasr, Jai
 Prakash Veerla, Aarti Darji, Parisa Boodaghi Malidarreh, Michael Robben,
 Helen H Shang, Jacob M Luber
Categories: eess.IV cs.CV q-bio.QM
\\
 We present an approach for multimodal pathology image search, using dynamic
time warping (DTW) on Variational Autoencoder (VAE) latent space that is fed
into a ranked choice voting scheme to retrieve multiplexed immunofluorescent
imaging (mIF) that is most similar to a query H&E slide. Through training the
VAE and applying DTW, we align and compare mIF and H&E slides. Our method
improves differential diagnosis and therapeutic decisions by integrating
morphological H&E data with immunophenotyping from mIF, providing clinicians a
rich perspective of disease states. This facilitates an understanding of the
spatial relationships in tissue samples and could revolutionize the diagnostic
process, enhancing precision and enabling personalized therapy selection. Our
technique demonstrates feasibility using colorectal cancer and healthy tonsil
samples. An exhaustive ablation study was conducted on a search engine designed
to explore the correlation between multiplexed Immunofluorescence (mIF) and
Hematoxylin and Eosin (H&E) staining, in order to validate its ability to map
these distinct modalities into a unified vector space. Despite extreme class
imbalance, the system demonstrated robustness and utility by returning similar
results across various data features, which suggests potential for future use
in multimodal histopathology data analysis.
\\ ( https://arxiv.org/abs/2306.06780 ,  13827kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06874 (*cross-listing*)
Date: Mon, 12 Jun 2023 05:14:13 GMT   (7853kb,D)

Title: VillanDiffusion: A Unified Backdoor Attack Framework for Diffusion
 Models
Authors: Sheng-Yen Chou, Pin-Yu Chen, Tsung-Yi Ho
Categories: cs.CR cs.CV cs.LG
\\
 Diffusion Models (DMs) are state-of-the-art generative models that learn a
reversible corruption process from iterative noise addition and denoising. They
are the backbone of many generative AI applications, such as text-to-image
conditional generation. However, recent studies have shown that basic
unconditional DMs (e.g., DDPM and DDIM) are vulnerable to backdoor injection, a
type of output manipulation attack triggered by a maliciously embedded pattern
at model input. This paper presents a unified backdoor attack framework
(VillanDiffusion) to expand the current scope of backdoor analysis for DMs. Our
framework covers mainstream unconditional and conditional DMs (denoising-based
and score-based) and various training-free samplers for holistic evaluations.
Experiments show that our unified framework facilitates the backdoor analysis
of different DM configurations and provides new insights into caption-based
backdoor attacks on DMs.
\\ ( https://arxiv.org/abs/2306.06874 ,  7853kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06914 (*cross-listing*)
Date: Mon, 12 Jun 2023 07:34:28 GMT   (553kb)

Title: Enhancing COVID-19 Diagnosis through Vision Transformer-Based Analysis
 of Chest X-ray Images
Authors: Sultan Zavrak
Categories: eess.IV cs.CV cs.LG
ACM-class: I.2; I.2.10
\\
 The advent of 2019 Coronavirus (COVID-19) has engendered a momentous global
health crisis, necessitating the identification of the ailment in individuals
through diverse diagnostic modalities. Radiological imaging, particularly the
deployment of X-ray imaging, has been recognized as a pivotal instrument in the
detection and characterization of COVID-19. Recent investigations have unveiled
invaluable insights pertaining to the virus within X-ray images, instigating
the exploration of methodologies aimed at augmenting diagnostic accuracy
through the utilization of artificial intelligence (AI) techniques. The current
research endeavor posits an innovative framework for the automated diagnosis of
COVID-19, harnessing raw chest X-ray images, specifically by means of
fine-tuning pre-trained Vision Transformer (ViT) models. The developed models
were appraised in terms of their binary classification performance, discerning
COVID-19 from Normal cases, as well as their ternary classification
performance, discriminating COVID-19 from Pneumonia and Normal instances, and
lastly, their quaternary classification performance, discriminating COVID-19
from Bacterial Pneumonia, Viral Pneumonia, and Normal conditions, employing
distinct datasets. The proposed model evinced extraordinary precision,
registering results of 99.92% and 99.84% for binary classification, 0.9795 and
86.48% for ternary classification, and 86.81% for quaternary classification,
respectively, on the respective datasets.
\\ ( https://arxiv.org/abs/2306.06914 ,  553kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06982 (*cross-listing*)
Date: Mon, 12 Jun 2023 09:26:54 GMT   (1183kb)

Title: Weakly Supervised Lesion Detection and Diagnosis for Breast Cancers with
 Partially Annotated Ultrasound Images
Authors: Jian Wang, Liang Qiao, Shichong Zhou, Jin Zhou, Jun Wang, Juncheng Li,
 Shihui Ying, Cai Chang, and Jun Shi
Categories: eess.IV cs.CV cs.LG
\\
 Deep learning (DL) has proven highly effective for ultrasound-based
computer-aided diagnosis (CAD) of breast cancers. In an automaticCAD system,
lesion detection is critical for the following diagnosis. However, existing
DL-based methods generally require voluminous manually-annotated region of
interest (ROI) labels and class labels to train both the lesion detection and
diagnosis models. In clinical practice, the ROI labels, i.e. ground truths, may
not always be optimal for the classification task due to individual experience
of sonologists, resulting in the issue of coarse annotation that limits the
diagnosis performance of a CAD model. To address this issue, a novel Two-Stage
Detection and Diagnosis Network (TSDDNet) is proposed based on weakly
supervised learning to enhance diagnostic accuracy of the ultrasound-based CAD
for breast cancers. In particular, all the ROI-level labels are considered as
coarse labels in the first training stage, and then a candidate selection
mechanism is designed to identify optimallesion areas for both the fully and
partially annotated samples. It refines the current ROI-level labels in the
fully annotated images and the detected ROIs in the partially annotated samples
with a weakly supervised manner under the guidance of class labels. In the
second training stage, a self-distillation strategy further is further proposed
to integrate the detection network and classification network into a unified
framework as the final CAD model for joint optimization, which then further
improves the diagnosis performance. The proposed TSDDNet is evaluated on a
B-mode ultrasound dataset, and the experimental results show that it achieves
the best performance on both lesion detection and diagnosis tasks, suggesting
promising application potential.
\\ ( https://arxiv.org/abs/2306.06982 ,  1183kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06742 (*cross-listing*)
Date: Sun, 11 Jun 2023 18:33:45 GMT   (601kb,D)

Title: Time-limited Bloom Filter
Authors: Ana Rodrigues, Ariel Shtul, Carlos Baquero, Paulo S\'ergio Almeida
Categories: cs.DS cs.DC
Comments: This version extends the 4-page version published in ACM SAC 2023 and
 adds a section on Experimental Evaluation
\\
 A Bloom Filter is a probabilistic data structure designed to check, rapidly
and memory-efficiently, whether an element is present in a set. It has been
vastly used in various computing areas and several variants, allowing
deletions, dynamic sets and working with sliding windows, have surfaced over
the years. When summarizing data streams, it becomes relevant to identify the
more recent elements in the stream. However, most of the sliding window schemes
consider the most recent items of a data stream without considering time as a
factor. While this allows, e.g., storing the most recent 10000 elements, it
does not easily translate into storing elements received in the last 60
seconds, unless the insertion rate is stable and known in advance. In this
paper, we present the Time-limited Bloom Filter, a new BF-based approach that
can save information of a given time period and correctly identify it as
present when queried, while also being able to retire data when it becomes
stale. The approach supports variable insertion rates while striving to keep a
target false positive rate. We also make available a reference implementation
of the data structure as a Redis module.
\\ ( https://arxiv.org/abs/2306.06742 ,  601kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07159 (*cross-listing*)
Date: Mon, 12 Jun 2023 14:46:21 GMT   (125kb)

Title: On the Computation-Communication Trade-Off with A Flexible Gradient
 Tracking Approach
Authors: Yan Huang and Jinming Xu
Categories: math.OC cs.DC cs.LG
Comments: This manuscript was submitted to the 62nd IEEE Conference on Decision
 and Control in March 2023
\\
 We propose a flexible gradient tracking approach with adjustable computation
and communication steps for solving distributed stochastic optimization problem
over networks. The proposed method allows each node to perform multiple local
gradient updates and multiple inter-node communications in each round, aiming
to strike a balance between computation and communication costs according to
the properties of objective functions and network topology in non-i.i.d.
settings. Leveraging a properly designed Lyapunov function, we derive both the
computation and communication complexities for achieving arbitrary accuracy on
smooth and strongly convex objective functions. Our analysis demonstrates sharp
dependence of the convergence performance on graph topology and properties of
objective functions, highlighting the trade-off between computation and
communication. Numerical experiments are conducted to validate our theoretical
findings.
\\ ( https://arxiv.org/abs/2306.07159 ,  125kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07192 (*cross-listing*)
Date: Mon, 12 Jun 2023 15:47:53 GMT   (26kb)

Title: Cybersecurity Training for Users of Remote Computing
Authors: Marcelo Ponce, Ramses van Zon
Categories: cs.CR cs.CY cs.DC
Comments: To be presented at SEHET23@PEARC23 and published in the Journal of
 Computational Science Education. Associated repository with best practices
 and recommendations:
 https://github.com/cybersec-BestPractices/cybersec-RemoteComputing
\\
 End users of remote computing systems are frequently not aware of basic ways
in which they could enhance protection against cyber-threats and attacks. In
this paper, we discuss specific techniques to help and train users to improve
cybersecurity when using such systems. To explain the rationale behind these
techniques, we go into some depth explaining possible threats in the context of
using remote, shared computing resources. Although some of the details of these
prescriptions and recommendations apply to specific use cases when connecting
to remote servers, such as a supercomputer, cluster, or Linux workstation, the
main concepts and ideas can be applied to a wider spectrum of cases.
\\ ( https://arxiv.org/abs/2306.07192 ,  26kb)
------------------------------------------------------------------------------
\\
arXiv:1810.04510 (*cross-listing*)
Date: Wed, 10 Oct 2018 13:23:36 GMT   (5791kb,D)

Title: Machine learning plasma-surface interface for coupling sputtering and
 gas-phase transport simulations
Authors: Florian Kr\"uger, Tobias Gergs, Jan Trieschmann
Categories: physics.plasm-ph cs.LG physics.comp-ph
DOI: 10.1088/1361-6595/ab0246
\\
 Thin film processing by means of sputter deposition inherently depends on the
interaction of energetic particles with a target surface and the subsequent
particle transport. The length and time scales of the underlying physical
phenomena span orders of magnitudes. A theoretical description which bridges
all time and length scales is not practically possible. Advantage can be taken
particularly from the well-separated time scales of the fundamental surface and
plasma processes. Initially, surface properties may be calculated from a
surface model and stored for a number of representative cases. Subsequently,
the surface data may be provided to gas-phase transport simulations via
appropriate model interfaces (e.g., analytic expressions or look-up tables) and
utilized to define insertion boundary conditions. During run-time evaluation,
however, the maintained surface data may prove to be not sufficient. In this
case, missing data may be obtained by interpolation (common), extrapolation
(inaccurate), or be supplied on-demand by the surface model (computationally
inefficient). In this work, a potential alternative is established based on
machine learning techniques using artificial neural networks. As a proof of
concept, a multilayer perceptron network is trained and verified with sputtered
particle distributions obtained from transport of ions in matter based
simulations for Ar projectiles bombarding a Ti-Al composite. It is demonstrated
that the trained network is able to predict the sputtered particle
distributions for unknown, arbitrarily shaped incident ion energy
distributions. It is consequently argued that the trained network may be
readily used as a machine learning based model interface (e.g., by
quasi-continuously sampling the desired sputtered particle distributions from
the network), which is sufficiently accurate also in scenarios which have not
been previously trained.
\\ ( https://arxiv.org/abs/1810.04510 ,  5791kb)
------------------------------------------------------------------------------
\\
arXiv:2109.01406 (*cross-listing*)
Date: Fri, 3 Sep 2021 09:51:32 GMT   (1397kb,D)
Date (revised v2): Mon, 6 Sep 2021 08:50:35 GMT   (1397kb,D)

Title: An efficient plasma-surface interaction surrogate model for sputtering
 processes based on autoencoder neural networks
Authors: Tobias Gergs, Borislav Borislavov, and Jan Trieschmann
Categories: physics.comp-ph cs.LG physics.plasm-ph
DOI: 10.1116/6.0001485
\\
 Simulations of thin film sputter deposition require the separation of the
plasma and material transport in the gas-phase from the growth/sputtering
processes at the bounding surfaces. Interface models based on analytic
expressions or look-up tables inherently restrict this complex interaction to a
bare minimum. A machine learning model has recently been shown to overcome this
remedy for Ar ions bombarding a Ti-Al composite target. However, the chosen
network structure (i.e., a multilayer perceptron) provides approximately 4
million degrees of freedom, which bears the risk of overfitting the relevant
dynamics and complicating the model to an unreliable extend. This work proposes
a conceptually more sophisticated but parameterwise simplified regression
artificial neural network for an extended scenario, considering a variable
instead of a single fixed Ti-Al stoichiometry. A convolutional
$\beta$-variational autoencoder is trained to reduce the high-dimensional
energy-angular distribution of sputtered particles to a latent space
representation of only two components. In addition to a primary decoder which
is trained to reconstruct the input energy-angular distribution, a secondary
decoder is employed to reconstruct the mean energy of incident Ar ions as well
as the present Ti-Al composition. The mutual latent space is hence conditioned
on these quantities. The trained primary decoder of the variational autoencoder
network is subsequently transferred to a regression network, for which only the
mapping to the particular latent space has to be learned. While obtaining a
competitive performance, the number of degrees of freedom is drastically
reduced to 15,111 and 486 parameters for the primary decoder and the remaining
regression network, respectively. The underlying methodology is general and can
easily be extended to more complex physical descriptions with a minimal amount
of data required.
\\ ( https://arxiv.org/abs/2109.01406 ,  1397kb)
------------------------------------------------------------------------------
\\
arXiv:2211.04796 (*cross-listing*)
Date: Wed, 9 Nov 2022 10:44:03 GMT   (3989kb,D)

Title: Physics-separating artificial neural networks for predicting initial
 stages of Al sputtering and thin film deposition in Ar plasma discharges
Authors: Tobias Gergs, Thomas Mussenbrock, Jan Trieschmann
Categories: cond-mat.mtrl-sci cs.LG physics.plasm-ph
DOI: 10.1088/1361-6463/acb6a4
\\
 Simulations of Al thin film sputter depositions rely on accurate plasma and
surface interaction models. Establishing the latter commonly requires a higher
level of abstraction and means to dismiss the fundamental atomic fidelity.
Previous works on sputtering processes addressed this issue by establishing
machine learning surrogate models, which include a basic surface state (i.e.,
stoichiometry) as static input. In this work, an evolving surface state and
defect structure are introduced to jointly describe sputtering and growth with
physics-separating artificial neural networks. The data describing the
plasma-surface interactions stem from hybrid reactive molecular
dynamics/time-stamped force bias Monte Carlo simulations of Al neutrals and
Ar$^+$ ions impinging onto Al(001) surfaces. It is demonstrated that the
fundamental processes are comprehensively described by taking the surface state
as well as defect structure into account. Hence, a machine learning
plasma-surface interaction surrogate model is established that resolves the
inherent kinetics with high physical fidelity. The resulting model is not
restricted to input from modeling and simulation, but may similarly be applied
to experimental input data.
\\ ( https://arxiv.org/abs/2211.04796 ,  3989kb)
------------------------------------------------------------------------------
\\
arXiv:2301.03524 (*cross-listing*)
Date: Mon, 9 Jan 2023 17:20:32 GMT   (7125kb,D)

Title: Physics-separating artificial neural networks for predicting sputtering
 and thin film deposition of AlN in Ar/N$_2$ discharges on experimental
 timescales
Authors: Tobias Gergs, Thomas Mussenbrock, Jan Trieschmann
Categories: cond-mat.mtrl-sci cs.LG physics.plasm-ph
DOI: 10.1088/1361-6463/acc07e
\\
 Understanding and modeling plasma-surface interactions frame a multi-scale as
well as multi-physics problem. Scale-bridging machine learning surface
surrogate models have been demonstrated to perceive the fundamental atomic
fidelity for the physical vapor deposition of pure metals. However, the immense
computational cost of the data-generating simulations render a practical
application with predictions on relevant timescales impracticable. This issue
is resolved in this work for the sputter deposition of AlN in Ar/N$_2$
discharges by developing a scheme that populates the parameter spaces
effectively. Hybrid reactive molecular dynamics / time-stamped force-bias Monte
Carlo simulations of randomized plasma-surface interactions / diffusion
processes are used to setup a physics-separating artificial neural network. The
application of this generic machine learning model to a specific experimental
reference case study enables the systematic analysis of the particle flux
emission as well as underlying system state (e.g., composition, mass density,
stress, point defect structure) evolution within process times of up to 45
minutes.
\\ ( https://arxiv.org/abs/2301.03524 ,  7125kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06107 (*cross-listing*)
Date: Thu, 25 May 2023 12:05:18 GMT   (168kb,D)

Title: Adversarial Attacks on Leakage Detectors in Water Distribution Networks
Authors: Paul Stahlhofen, Andr\'e Artelt, Luca Hermes, Barbara Hammer
Categories: cs.CR cs.LG
Comments: This paper was accepted for the 17th International Work-Conference on
 Artificial Neural Networks (IWANN 2023). A link to the version of record will
 be provided upon publication of the conference proceedings
\\
 Many Machine Learning models are vulnerable to adversarial attacks: There
exist methodologies that add a small (imperceptible) perturbation to an input
such that the model comes up with a wrong prediction. Better understanding of
such attacks is crucial in particular for models used in security-critical
domains, such as monitoring of water distribution networks, in order to devise
counter-measures enhancing model robustness and trustworthiness.
 We propose a taxonomy for adversarial attacks against machine learning based
leakage detectors in water distribution networks. Following up on this, we
focus on a particular type of attack: an adversary searching the least
sensitive point, that is, the location in the water network where the largest
possible undetected leak could occur. Based on a mathematical formalization of
the least sensitive point problem, we use three different algorithmic
approaches to find a solution. Results are evaluated on two benchmark water
distribution networks.
\\ ( https://arxiv.org/abs/2306.06107 ,  168kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06108 (*cross-listing*)
Date: Thu, 25 May 2023 18:36:54 GMT   (18034kb,D)

Title: Demystifying Fraudulent Transactions and Illicit Nodes in the Bitcoin
 Network for Financial Forensics
Authors: Youssef Elmougy and Ling Liu
Categories: cs.CR cs.LG
DOI: 10.1145/3580305.3599803
\\
 Blockchain provides the unique and accountable channel for financial
forensics by mining its open and immutable transaction data. A recent surge has
been witnessed by training machine learning models with cryptocurrency
transaction data for anomaly detection, such as money laundering and other
fraudulent activities. This paper presents a holistic applied data science
approach to fraud detection in the Bitcoin network with two original
contributions. First, we contribute the Elliptic++ dataset, which extends the
Elliptic transaction dataset to include over 822k Bitcoin wallet addresses
(nodes), each with 56 features, and 1.27M temporal interactions. This enables
both the detection of fraudulent transactions and the detection of illicit
addresses (actors) in the Bitcoin network by leveraging four types of graph
data: (i) the transaction-to-transaction graph, representing the money flow in
the Bitcoin network, (ii) the address-to-address interaction graph, capturing
the types of transaction flows between Bitcoin addresses, (iii) the
address-transaction graph, representing the bi-directional money flow between
addresses and transactions (BTC flow from input address to one or more
transactions and BTC flow from a transaction to one or more output addresses),
and (iv) the user entity graph, capturing clusters of Bitcoin addresses
representing unique Bitcoin users. Second, we perform fraud detection tasks on
all four graphs by using diverse machine learning algorithms. We show that
adding enhanced features from the address-to-address and the
address-transaction graphs not only assists in effectively detecting both
illicit transactions and illicit addresses, but also assists in gaining
in-depth understanding of the root cause of money laundering vulnerabilities in
cryptocurrency transactions and the strategies for fraud detection and
prevention. Released at github.com/git-disl/EllipticPlusPlus.
\\ ( https://arxiv.org/abs/2306.06108 ,  18034kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06119 (*cross-listing*)
Date: Mon, 5 Jun 2023 14:15:39 GMT   (139kb,D)

Title: Doubly Stochastic Graph-based Non-autoregressive Reaction Prediction
Authors: Ziqiao Meng, Peilin Zhao, Yang Yu, Irwin King
Categories: physics.chem-ph cs.LG
Comments: Accepted by IJCAI 2023
\\
 Organic reaction prediction is a critical task in drug discovery. Recently,
researchers have achieved non-autoregressive reaction prediction by modeling
the redistribution of electrons, resulting in state-of-the-art top-1 accuracy,
and enabling parallel sampling. However, the current non-autoregressive decoder
does not satisfy two essential rules of electron redistribution modeling
simultaneously: the electron-counting rule and the symmetry rule. This
violation of the physical constraints of chemical reactions impairs model
performance. In this work, we propose a new framework called that combines two
doubly stochastic self-attention mappings to obtain electron redistribution
predictions that follow both constraints. We further extend our solution to a
general multi-head attention mechanism with augmented constraints. To achieve
this, we apply Sinkhorn's algorithm to iteratively update self-attention
mappings, which imposes doubly conservative constraints as additional
informative priors on electron redistribution modeling. We theoretically
demonstrate that our can simultaneously satisfy both rules, which the current
decoder mechanism cannot do. Empirical results show that our approach
consistently improves the predictive performance of non-autoregressive models
and does not bring an unbearable additional computational cost.
\\ ( https://arxiv.org/abs/2306.06119 ,  139kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06125 (*cross-listing*)
Date: Thu, 8 Jun 2023 06:15:17 GMT   (664kb,D)

Title: Joint Channel Estimation and Feedback with Masked Token Transformers in
 Massive MIMO Systems
Authors: Mingming Zhao, Lin Liu, Lifu Liu, Qi Tian
Categories: cs.IT cs.LG math.IT
Comments: 9 pages, 8 figures
\\
 When the base station has downlink channel status information (CSI), the huge
potential of large-scale multiple input multiple output (MIMO) in frequency
division duplex (FDD) mode can be fully exploited. In this paper, we propose a
deep-learning-based joint channel estimation and feedback framework to realize
channel estimation and feedback in massive MIMO systems. Specifically, we use
traditional channel design rather than end-to-end methods. Our model contains
two networks. The first network is a channel estimation network, which adopts a
double loss design, and can accurately estimate the full channel information
while removing channel noises. The second network is a compression and feedback
network. Inspired by the masked token transformer, we propose a learnable mask
token method to obtain excellent estimation and compression performance. The
extensive simulation results and ablation studies show that our method
outperforms state-of-the-art channel estimation and feedback methods in both
separate and joint tasks.
\\ ( https://arxiv.org/abs/2306.06125 ,  664kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06129 (*cross-listing*)
Date: Thu, 8 Jun 2023 10:12:50 GMT   (1166kb,D)

Title: Energy-efficient Wearable-to-Mobile Offload of ML Inference for
 PPG-based Heart-Rate Estimation
Authors: Alessio Burrello, Matteo Risso, Noemi Tomasello, Yukai Chen, Luca
 Benini, Enrico Macii, Massimo Poncino, Daniele Jahier Pagliari
Categories: eess.SP cs.LG
Comments: Published at 2023 Design, Automation \& Test in Europe Conference \&
 Exhibition (DATE)
Journal-ref: 2023 Design, Automation & Test in Europe Conference & Exhibition
 (DATE)
DOI: 10.23919/DATE56975.2023.10137129
\\
 Modern smartwatches often include photoplethysmographic (PPG) sensors to
measure heartbeats or blood pressure through complex algorithms that fuse PPG
data with other signals. In this work, we propose a collaborative inference
approach that uses both a smartwatch and a connected smartphone to maximize the
performance of heart rate (HR) tracking while also maximizing the smartwatch's
battery life. In particular, we first analyze the trade-offs between running
on-device HR tracking or offloading the work to the mobile. Then, thanks to an
additional step to evaluate the difficulty of the upcoming HR prediction, we
demonstrate that we can smartly manage the workload between smartwatch and
smartphone, maintaining a low mean absolute error (MAE) while reducing energy
consumption. We benchmark our approach on a custom smartwatch prototype,
including the STM32WB55 MCU and Bluetooth Low-Energy (BLE) communication, and a
Raspberry Pi3 as a proxy for the smartphone. With our Collaborative Heart Rate
Inference System (CHRIS), we obtain a set of Pareto-optimal configurations
demonstrating the same MAE as State-of-Art (SoA) algorithms while consuming
less energy. For instance, we can achieve approximately the same MAE of
TimePPG-Small (5.54 BPM MAE vs. 5.60 BPM MAE) while reducing the energy by
2.03x, with a configuration that offloads 80\% of the predictions to the phone.
Furthermore, accepting a performance degradation to 7.16 BPM of MAE, we can
achieve an energy consumption of 179 uJ per prediction, 3.03x less than running
TimePPG-Small on the smartwatch, and 1.82x less than streaming all the input
data to the phone.
\\ ( https://arxiv.org/abs/2306.06129 ,  1166kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06138 (*cross-listing*)
Date: Fri, 9 Jun 2023 05:53:11 GMT   (7735kb)

Title: Extraction and Recovery of Spatio-Temporal Structure in Latent Dynamics
 Alignment with Diffusion Model
Authors: Yule Wang, Zijing Wu, Chengrui Li, Anqi Wu
Categories: q-bio.NC cs.LG
\\
 In the field of behavior-related brain computation, it is necessary to
meaningfully align raw neural population activities against the drastic shift
between them. However, the alignment is non-trivial since most neural
population activities are in a multivariate time-series manner. An instrumental
framework within neuroscience research posits that trial-based neural
population activities rely on low-dimensional latent dynamics. Focusing on such
latent dynamics greatly facilitates the alignment procedure. Despite the
considerable progress we have reached, existing methods usually ignore the
intrinsic spatio-temporal structures within latent dynamics. Thus, those
solutions lead to poor quality in dynamics structures and overall performance
after alignment. To tackle this problem, we propose a method leveraging the
expressiveness of diffusion model to relieve such issues. Specifically, the
latent dynamics structures of the source domain are first extracted by the
diffusion model. Then, such structures are well-recovered through a maximum
likelihood alignment procedure on the target domain. We first demonstrate the
effectiveness of our proposed method on a synthetic dataset. Then, when applied
to neural recordings from primate motor cortex, under both cross-day and
inter-subject settings, our method consistently manifests its capability of
preserving the spatio-temporal structure of latent dynamics and outperforms
existing approaches in alignment quality.
\\ ( https://arxiv.org/abs/2306.06138 ,  7735kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06140 (*cross-listing*)
Date: Fri, 9 Jun 2023 07:01:17 GMT   (6kb)

Title: Null/No Information Rate (NIR): a statistical test to assess if a
 classification accuracy is significant for a given problem
Authors: Manuele Bicego and Antonella Mensi
Categories: stat.ME cs.LG
\\
 In many research contexts, especially in the biomedical field, after studying
and developing a classification system a natural question arises: "Is this
accuracy enough high?", or better, "Can we say, with a statistically
significant confidence, that our classification system is able to solve the
problem"? To answer to this question, we can use the statistical test described
in this paper, which is referred in some cases as NIR (No Information Rate or
Null Information Rate).
\\ ( https://arxiv.org/abs/2306.06140 ,  6kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06144 (*cross-listing*)
Date: Fri, 9 Jun 2023 09:10:28 GMT   (4103kb,D)

Title: Bayesian Calibration of MEMS Accelerometers
Authors: Oliver D\"urr, Po-Yu Fan, and Zong-Xian Yin
Categories: eess.SP cs.LG stat.AP
Comments: Accepted in IEEE Sensors
DOI: 10.1109/JSEN.2023.3272907
\\
 This study aims to investigate the utilization of Bayesian techniques for the
calibration of micro-electro-mechanical systems (MEMS) accelerometers. These
devices have garnered substantial interest in various practical applications
and typically require calibration through error-correcting functions. The
parameters of these error-correcting functions are determined during a
calibration process. However, due to various sources of noise, these parameters
cannot be determined with precision, making it desirable to incorporate
uncertainty in the calibration models. Bayesian modeling offers a natural and
complete way of reflecting uncertainty by treating the model parameters as
variables rather than fixed values. Additionally, Bayesian modeling enables the
incorporation of prior knowledge, making it an ideal choice for calibration.
Nevertheless, it is infrequently used in sensor calibration. This study
introduces Bayesian methods for the calibration of MEMS accelerometer data in a
straightforward manner using recent advances in probabilistic programming.
\\ ( https://arxiv.org/abs/2306.06144 ,  4103kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06156 (*cross-listing*)
Date: Fri, 9 Jun 2023 16:06:36 GMT   (9138kb,D)

Title: PoET: A generative model of protein families as sequences-of-sequences
Authors: Timothy F. Truong Jr, Tristan Bepler
Categories: q-bio.QM cs.LG
\\
 Generative protein language models are a natural way to design new proteins
with desired functions. However, current models are either difficult to direct
to produce a protein from a specific family of interest, or must be trained on
a large multiple sequence alignment (MSA) from the specific family of interest,
making them unable to benefit from transfer learning across families. To
address this, we propose $\textbf{P}$r$\textbf{o}$tein $\textbf{E}$volutionary
$\textbf{T}$ransformer (PoET), an autoregressive generative model of whole
protein families that learns to generate sets of related proteins as
sequences-of-sequences across tens of millions of natural protein sequence
clusters. PoET can be used as a retrieval-augmented language model to generate
and score arbitrary modifications conditioned on any protein family of
interest, and can extrapolate from short context lengths to generalize well
even for small families. This is enabled by a unique Transformer layer; we
model tokens sequentially within sequences while attending between sequences
order invariantly, allowing PoET to scale to context lengths beyond those used
during training. PoET outperforms existing protein language models and
evolutionary sequence models for variant function prediction in extensive
experiments on deep mutational scanning datasets, improving variant effect
prediction across proteins of all MSA depths.
\\ ( https://arxiv.org/abs/2306.06156 ,  9138kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06190 (*cross-listing*)
Date: Fri, 9 Jun 2023 18:42:19 GMT   (2092kb,D)

Title: $FPDM$: Domain-Specific Fast Pre-training Technique using Document-Level
 Metadata
Authors: Abhilash Nandy, Manav Nitin Kapadnis, Sohan Patnaik, Yash Parag
 Butala, Pawan Goyal, Niloy Ganguly
Categories: cs.CL cs.LG
Comments: 23 pages, 7 figures
MSC-class: 68T50
ACM-class: I.2.7
\\
 Pre-training Transformers has shown promising results on open-domain and
domain-specific downstream tasks. However, state-of-the-art Transformers
require an unreasonably large amount of pre-training data and compute. In this
paper, we propose $FPDM$ (Fast Pre-training Technique using Document Level
Metadata), a novel, compute-efficient framework that utilizes Document metadata
and Domain-Specific Taxonomy as supervision signals to pre-train transformer
encoder on a domain-specific corpus. The main innovation is that during
domain-specific pretraining, an open-domain encoder is continually pre-trained
using sentence-level embeddings as inputs (to accommodate long documents),
however, fine-tuning is done with token-level embeddings as inputs to this
encoder. We show that $FPDM$ outperforms several transformer-based baselines in
terms of character-level F1 scores and other automated metrics in the Customer
Support, Scientific, and Legal Domains, and shows a negligible drop in
performance on open-domain benchmarks. Importantly, the novel use of
document-level supervision along with sentence-level embedding input for
pre-training reduces pre-training compute by around $1,000$, $4,500$, and $500$
times compared to MLM and/or NSP in Customer Support, Scientific, and Legal
Domains, respectively. Code and datasets are available at
https://bit.ly/FPDMCode.
\\ ( https://arxiv.org/abs/2306.06190 ,  2092kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06199 (*cross-listing*)
Date: Fri, 9 Jun 2023 19:07:31 GMT   (7105kb,D)

Title: Reliability Check: An Analysis of GPT-3's Response to Sensitive Topics
 and Prompt Wording
Authors: Aisha Khatun and Daniel G. Brown
Categories: cs.CL cs.LG
Comments: Accepted in TrustNLP: Third Workshop on Trustworthy Natural Language
 Processing, co-located with ACL 2023
\\
 Large language models (LLMs) have become mainstream technology with their
versatile use cases and impressive performance. Despite the countless
out-of-the-box applications, LLMs are still not reliable. A lot of work is
being done to improve the factual accuracy, consistency, and ethical standards
of these models through fine-tuning, prompting, and Reinforcement Learning with
Human Feedback (RLHF), but no systematic analysis of the responses of these
models to different categories of statements, or on their potential
vulnerabilities to simple prompting changes is available. In this work, we
analyze what confuses GPT-3: how the model responds to certain sensitive topics
and what effects the prompt wording has on the model response. We find that
GPT-3 correctly disagrees with obvious Conspiracies and Stereotypes but makes
mistakes with common Misconceptions and Controversies. The model responses are
inconsistent across prompts and settings, highlighting GPT-3's unreliability.
Dataset and code of our analysis is available in
https://github.com/tanny411/GPT3-Reliability-Check.
\\ ( https://arxiv.org/abs/2306.06199 ,  7105kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06228 (*cross-listing*)
Date: Fri, 9 Jun 2023 19:53:40 GMT   (601kb,D)

Title: AVScan2Vec: Feature Learning on Antivirus Scan Data for Production-Scale
 Malware Corpora
Authors: Robert J. Joyce, Tirth Patel, Charles Nicholas, Edward Raff
Categories: cs.CR cs.LG
\\
 When investigating a malicious file, searching for related files is a common
task that malware analysts must perform. Given that production malware corpora
may contain over a billion files and consume petabytes of storage, many feature
extraction and similarity search approaches are computationally infeasible. Our
work explores the potential of antivirus (AV) scan data as a scalable source of
features for malware. This is possible because AV scan reports are widely
available through services such as VirusTotal and are ~100x smaller than the
average malware sample. The information within an AV scan report is abundant
with information and can indicate a malicious file's family, behavior, target
operating system, and many other characteristics. We introduce AVScan2Vec, a
language model trained to comprehend the semantics of AV scan data. AVScan2Vec
ingests AV scan data for a malicious file and outputs a meaningful vector
representation. AVScan2Vec vectors are ~3 to 85x smaller than popular
alternatives in use today, enabling faster vector comparisons and lower memory
usage. By incorporating Dynamic Continuous Indexing, we show that
nearest-neighbor queries on AVScan2Vec vectors can scale to even the largest
malware production datasets. We also demonstrate that AVScan2Vec vectors are
superior to other leading malware feature vector representations across nearly
all classification, clustering, and nearest-neighbor lookup algorithms that we
evaluated.
\\ ( https://arxiv.org/abs/2306.06228 ,  601kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06262 (*cross-listing*)
Date: Fri, 9 Jun 2023 21:18:44 GMT   (723kb,D)

Title: Spectral gap-based deterministic tensor completion
Authors: Kameron Decker Harris and Oscar L\'opez and Angus Read and Yizhe Zhu
Categories: stat.ML cs.LG
Comments: In proceedings of SampTA 2023
\\
 Tensor completion is a core machine learning algorithm used in recommender
systems and other domains with missing data. While the matrix case is
well-understood, theoretical results for tensor problems are limited,
particularly when the sampling patterns are deterministic. Here we bound the
generalization error of the solutions of two tensor completion methods, Poisson
loss and atomic norm minimization, providing tighter bounds in terms of the
target tensor rank. If the ground-truth tensor is order $t$ with CP-rank $r$,
the dependence on $r$ is improved from $r^{2(t-1)(t^2-t-1)}$ in
arXiv:1910.10692 to $r^{2(t-1)(3t-5)}$. The error in our bounds is
deterministically controlled by the spectral gap of the sampling sparsity
pattern. We also prove several new properties for the atomic tensor norm,
reducing the rank dependence from $r^{3t-3}$ in arXiv:1711.04965 to $r^{3t-5}$
under random sampling schemes. A limitation is that atomic norm minimization,
while theoretically interesting, leads to inefficient algorithms. However,
numerical experiments illustrate the dependence of the reconstruction error on
the spectral gap for the practical max-quasinorm, ridge penalty, and Poisson
loss minimization algorithms. This view through the spectral gap is a promising
window for further study of tensor algorithms.
\\ ( https://arxiv.org/abs/2306.06262 ,  723kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06264 (*cross-listing*)
Date: Fri, 9 Jun 2023 21:25:48 GMT   (725kb,D)

Title: Measuring and Modifying Factual Knowledge in Large Language Models
Authors: Pouya Pezeshkpour
Categories: cs.CL cs.LG
\\
 Large Language Models (LLMs) store an extensive amount of factual knowledge
obtained from vast collections of text. To effectively utilize these models for
downstream tasks, it is crucial to have reliable methods for measuring their
knowledge. However, existing approaches for knowledge measurement have certain
limitations, and despite recent efforts, they fail to provide accurate
measurements and the necessary insights for modifying the knowledge within
LLMs. In this work, we employ information theory-based measurements to provide
a framework estimating the factual knowledge contained within large language
models. More specifically, we measure knowledge by analyzing the LLM's
prediction probability distribution before and after instilling the target
knowledge, employing metrics such as entropy and KL-divergence. Introducing our
metrics, we first assess their accuracy in comparison to previous ranking-based
methods, surpassing them by over $35\%$ in a synthetic experiment. Then, we
explore two prominent methods of knowledge instillation, discovering that LLMs
exhibit limitations in capturing new knowledge under specific circumstances for
one of these methods. Lastly, we demonstrate the applicability of our methods
in extracting unlearned and mislearned facts in LLMs through their application
to in-context learning. We make code and data for all methods and experiments
in this paper publicly available.
\\ ( https://arxiv.org/abs/2306.06264 ,  725kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06281 (*cross-listing*)
Date: Fri, 9 Jun 2023 22:11:16 GMT   (4036kb,D)

Title: Energy-Dissipative Evolutionary Deep Operator Neural Networks
Authors: Jiahao Zhang, Shiheng Zhang, Jie Shen, Guang Lin
Categories: stat.ML cs.LG
Comments: 18 pages
\\
 Energy-Dissipative Evolutionary Deep Operator Neural Network is an operator
learning neural network. It is designed to seed numerical solutions for a class
of partial differential equations instead of a single partial differential
equation, such as partial differential equations with different parameters or
different initial conditions. The network consists of two sub-networks, the
Branch net and the Trunk net. For an objective operator G, the Branch net
encodes different input functions u at the same number of sensors, and the
Trunk net evaluates the output function at any location. By minimizing the
error between the evaluated output q and the expected output G(u)(y), DeepONet
generates a good approximation of the operator G. In order to preserve
essential physical properties of PDEs, such as the Energy Dissipation Law, we
adopt a scalar auxiliary variable approach to generate the minimization
problem. It introduces a modified energy and enables unconditional energy
dissipation law at the discrete level. By taking the parameter as a function of
time t, this network can predict the accurate solution at any further time with
feeding data only at the initial state. The data needed can be generated by the
initial conditions, which are readily available. In order to validate the
accuracy and efficiency of our neural networks, we provide numerical
simulations of several partial differential equations, including heat
equations, parametric heat equations and Allen-Cahn equations.
\\ ( https://arxiv.org/abs/2306.06281 ,  4036kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06283 (*cross-listing*)
Date: Fri, 9 Jun 2023 22:22:02 GMT   (12598kb,D)

Title: 14 Examples of How LLMs Can Transform Materials Science and Chemistry: A
 Reflection on a Large Language Model Hackathon
Authors: Kevin Maik Jablonka, Qianxiang Ai, Alexander Al-Feghali, Shruti
 Badhwar, Joshua D. Bocarsly Andres M Bran, Stefan Bringuier, L. Catherine
 Brinson, Kamal Choudhary, Defne Circi, Sam Cox, Wibe A. de Jong, Matthew L.
 Evans, Nicolas Gastellu, Jerome Genzling, Mar\'ia Victoria Gil, Ankur K.
 Gupta, Zhi Hong, Alishba Imran, Sabine Kruschwitz, Anne Labarre, Jakub
 L\'ala, Tao Liu, Steven Ma, Sauradeep Majumdar, Garrett W. Merz, Nicolas
 Moitessier, Elias Moubarak, Beatriz Mouri\~no, Brenden Pelkie, Michael
 Pieler, Mayk Caldas Ramos, Bojana Rankovi\'c, Samuel G. Rodriques, Jacob N.
 Sanders, Philippe Schwaller, Marcus Schwarting, Jiale Shi, Berend Smit, Ben
 E. Smith, Joren Van Heck, Christoph V\"olker, Logan Ward, Sean Warren,
 Benjamin Weiser, Sylvester Zhang, Xiaoqi Zhang, Ghezal Ahmad Zia, Aristana
 Scourtas, KJ Schmidt, Ian Foster, Andrew D. White, Ben Blaiszik
Categories: cond-mat.mtrl-sci cs.LG physics.chem-ph
\\
 Chemistry and materials science are complex. Recently, there have been great
successes in addressing this complexity using data-driven or computational
techniques. Yet, the necessity of input structured in very specific forms and
the fact that there is an ever-growing number of tools creates usability and
accessibility challenges. Coupled with the reality that much data in these
disciplines is unstructured, the effectiveness of these tools is limited.
 Motivated by recent works that indicated that large language models (LLMs)
might help address some of these issues, we organized a hackathon event on the
applications of LLMs in chemistry, materials science, and beyond. This article
chronicles the projects built as part of this hackathon. Participants employed
LLMs for various applications, including predicting properties of molecules and
materials, designing novel interfaces for tools, extracting knowledge from
unstructured data, and developing new educational applications.
 The diverse topics and the fact that working prototypes could be generated in
less than two days highlight that LLMs will profoundly impact the future of our
fields. The rich collection of ideas and projects also indicates that the
applications of LLMs are not limited to materials science and chemistry but
offer potential benefits to a wide range of scientific disciplines.
\\ ( https://arxiv.org/abs/2306.06283 ,  12598kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06291 (*cross-listing*)
Date: Fri, 9 Jun 2023 22:48:13 GMT   (1937kb,D)

Title: Optimal Heterogeneous Collaborative Linear Regression and Contextual
 Bandits
Authors: Xinmeng Huang, Kan Xu, Donghwan Lee, Hamed Hassani, Hamsa Bastani,
 Edgar Dobriban
Categories: stat.ML cs.LG stat.ME
\\
 Large and complex datasets are often collected from several, possibly
heterogeneous sources. Collaborative learning methods improve efficiency by
leveraging commonalities across datasets while accounting for possible
differences among them. Here we study collaborative linear regression and
contextual bandits, where each instance's associated parameters are equal to a
global parameter plus a sparse instance-specific term. We propose a novel
two-stage estimator called MOLAR that leverages this structure by first
constructing an entry-wise median of the instances' linear regression
estimates, and then shrinking the instance-specific estimates towards the
median. MOLAR improves the dependence of the estimation error on the data
dimension, compared to independent least squares estimates. We then apply MOLAR
to develop methods for sparsely heterogeneous collaborative contextual bandits,
which lead to improved regret guarantees compared to independent bandit
methods. We further show that our methods are minimax optimal by providing a
number of lower bounds. Finally, we support the efficiency of our methods by
performing experiments on both synthetic data and the PISA dataset on student
educational outcomes from heterogeneous countries.
\\ ( https://arxiv.org/abs/2306.06291 ,  1937kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06292 (*cross-listing*)
Date: Fri, 9 Jun 2023 22:48:14 GMT   (2076kb,D)

Title: PLPCA: Persistent Laplacian Enhanced-PCA for Microarray Data Analysis
Authors: Sean Cottrell, Rui Wang, Guowei Wei
Categories: math.AT cs.LG
Comments: 24 pages, 15 figures
\\
 Over the years, Principal Component Analysis (PCA) has served as the baseline
approach for dimensionality reduction in gene expression data analysis. It
primary objective is to identify a subset of disease-causing genes from a vast
pool of thousands of genes. However, PCA possesses inherent limitations that
hinder its interpretability, introduce classification ambiguity, and fail to
capture complex geometric structures in the data. Although these limitations
have been partially addressed in the literature by incorporating various
regularizers such as graph Laplacian regularization, existing improved PCA
methods still face challenges related to multiscale analysis and capturing
higher-order interactions in the data. To address these challenges, we propose
a novel approach called Persistent Laplacian-enhanced Principal Component
Analysis (PLPCA). PLPCA amalgamates the advantages of earlier regularized PCA
methods with persistent spectral graph theory, specifically persistent
Laplacians derived from algebraic topology. In contrast to graph Laplacians,
persistent Laplacians enable multiscale analysis through filtration and
incorporate higher-order simplicial complexes to capture higher-order
interactions in the data. We evaluate and validate the performance of PLPCA
using benchmark microarray datasets that involve normal tissue samples and four
different cancer tissues. Our extensive studies demonstrate that PLPCA
outperforms all other state-of-the-art models for classification tasks after
dimensionality reduction.
\\ ( https://arxiv.org/abs/2306.06292 ,  2076kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06296 (*cross-listing*)
Date: Fri, 9 Jun 2023 23:22:49 GMT   (8144kb,D)

Title: Response Time Improves Choice Prediction and Function Estimation for
 Gaussian Process Models of Perception and Preferences
Authors: Michael Shvartsman, Benjamin Letham, Stephen Keeley
Categories: q-bio.NC cs.LG
Comments: 18 pages incl. references and supplement; 11 figures
\\
 Models for human choice prediction in preference learning and psychophysics
often consider only binary response data, requiring many samples to accurately
learn preferences or perceptual detection thresholds. The response time (RT) to
make each choice captures additional information about the decision process,
however existing models incorporating RTs for choice prediction do so in fully
parametric settings or over discrete stimulus sets. This is in part because the
de-facto standard model for choice RTs, the diffusion decision model (DDM),
does not admit tractable, differentiable inference. The DDM thus cannot be
easily integrated with flexible models for continuous, multivariate function
approximation, particularly Gaussian process (GP) models. We propose a novel
differentiable approximation to the DDM likelihood using a family of known,
skewed three-parameter distributions. We then use this new likelihood to
incorporate RTs into GP models for binary choices. Our RT-choice GPs enable
both better latent value estimation and held-out choice prediction relative to
baselines, which we demonstrate on three real-world multivariate datasets
covering both human psychophysics and preference learning applications.
\\ ( https://arxiv.org/abs/2306.06296 ,  8144kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06302 (*cross-listing*)
Date: Fri, 9 Jun 2023 23:40:03 GMT   (1289kb,D)

Title: Multi-Task Knowledge Enhancement for Zero-Shot and Multi-Domain
 Recommendation in an AI Assistant Application
Authors: Elan Markowitz, Ziyan Jiang, Fan Yang, Xing Fan, Tony Chen, Greg Ver
 Steeg, Aram Galstyan
Categories: cs.IR cs.LG
\\
 Recommender systems have found significant commercial success but still
struggle with integrating new users. Since users often interact with content in
different domains, it is possible to leverage a user's interactions in previous
domains to improve that user's recommendations in a new one (multi-domain
recommendation). A separate research thread on knowledge graph enhancement uses
external knowledge graphs to improve single domain recommendations (knowledge
graph enhancement). Both research threads incorporate related information to
improve predictions in a new domain. We propose in this work to unify these
approaches: Using information from interactions in other domains as well as
external knowledge graphs to make predictions in a new domain that would be
impossible with either information source alone. We apply these ideas to a
dataset derived from millions of users' requests for content across three
domains (videos, music, and books) in a live virtual assistant application. We
demonstrate the advantage of combining knowledge graph enhancement with
previous multi-domain recommendation techniques to provide better overall
recommendations as well as for better recommendations on new users of a domain.
\\ ( https://arxiv.org/abs/2306.06302 ,  1289kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06322 (*cross-listing*)
Date: Sat, 10 Jun 2023 00:13:09 GMT   (2798kb,D)

Title: Towards Arabic Multimodal Dataset for Sentiment Analysis
Authors: Abdelhamid Haouhat, Slimane Bellaouar, Attia Nehar, Hadda Cherroun
Categories: cs.CL cs.LG
Comments: 8 pages
\\
 Multimodal Sentiment Analysis (MSA) has recently become a centric research
direction for many real-world applications. This proliferation is due to the
fact that opinions are central to almost all human activities and are key
influencers of our behaviors. In addition, the recent deployment of Deep
Learning-based (DL) models has proven their high efficiency for a wide range of
Western languages. In contrast, Arabic DL-based multimodal sentiment analysis
(MSA) is still in its infantile stage due, mainly, to the lack of standard
datasets. In this paper, our investigation is twofold. First, we design a
pipeline that helps building our Arabic Multimodal dataset leveraging both
state-of-the-art transformers and feature extraction tools within word
alignment techniques. Thereafter, we validate our dataset using
state-of-the-art transformer-based model dealing with multimodality. Despite
the small size of the outcome dataset, experiments show that Arabic
multimodality is very promising
\\ ( https://arxiv.org/abs/2306.06322 ,  2798kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06331 (*cross-listing*)
Date: Sat, 10 Jun 2023 02:01:02 GMT   (131kb,D)

Title: Investigating the Effectiveness of ChatGPT in Mathematical Reasoning and
 Problem Solving: Evidence from the Vietnamese National High School Graduation
 Examination
Authors: Xuan-Quy Dao and Ngoc-Bich Le
Categories: cs.CL cs.LG
Comments: 17 pages, 13 images
\\
 This study offers a complete analysis of ChatGPT's mathematics abilities in
responding to multiple-choice questions for the Vietnamese National High School
Graduation Examination (VNHSGE) on a range of subjects and difficulty levels.
The dataset included 250 questions divided into four levels: knowledge (K),
comprehension (C), application (A), and high application (H), and it included
ten themes that covered diverse mathematical concepts. The outcomes demonstrate
that ChatGPT's performance varies depending on the difficulty level and
subject. It performed best on questions at Level (K), with an accuracy rate of
$83\%$; but, as the difficulty level rose, it scored poorly, with an accuracy
rate of $10\%$. The study has also shown that ChatGPT significantly succeeds in
providing responses to questions on subjects including exponential and
logarithmic functions, geometric progression, and arithmetic progression. The
study found that ChatGPT had difficulty correctly answering questions on topics
including derivatives and applications, spatial geometry, and Oxyz spatial
calculus. Additionally, this study contrasted ChatGPT outcomes with Vietnamese
students in VNHSGE and in other math competitions. ChatGPT dominated in the SAT
Math competition with a success rate of $70\%$, followed by VNHSGE mathematics
($58.8\%)$. However, its success rates were lower on other exams, such as AP
Statistics, the GRE Quantitative, AMC 10, AMC 12, and AP Calculus BC. These
results suggest that ChatGPT has the potential to be an effective teaching tool
for mathematics, but more work is needed to enhance its handling of graphical
data and address the challenges presented by questions that are getting more
challenging.
\\ ( https://arxiv.org/abs/2306.06331 ,  131kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06340 (*cross-listing*)
Date: Sat, 10 Jun 2023 04:23:08 GMT   (5202kb,D)

Title: ECGBERT: Understanding Hidden Language of ECGs with Self-Supervised
 Representation Learning
Authors: Seokmin Choi, Sajad Mousavi, Phillip Si, Haben G. Yhdego, Fatemeh
 Khadem, Fatemeh Afghah
Categories: eess.SP cs.LG q-bio.QM
\\
 In the medical field, current ECG signal analysis approaches rely on
supervised deep neural networks trained for specific tasks that require
substantial amounts of labeled data. However, our paper introduces ECGBERT, a
self-supervised representation learning approach that unlocks the underlying
language of ECGs. By unsupervised pre-training of the model, we mitigate
challenges posed by the lack of well-labeled and curated medical data. ECGBERT,
inspired by advances in the area of natural language processing and large
language models, can be fine-tuned with minimal additional layers for various
ECG-based problems. Through four tasks, including Atrial Fibrillation
arrhythmia detection, heartbeat classification, sleep apnea detection, and user
authentication, we demonstrate ECGBERT's potential to achieve state-of-the-art
results on a wide variety of tasks.
\\ ( https://arxiv.org/abs/2306.06340 ,  5202kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06403 (*cross-listing*)
Date: Sat, 10 Jun 2023 10:10:55 GMT   (866kb,D)

Title: Bayesian Inverse Contextual Reasoning for Heterogeneous Semantics-Native
 Communication
Authors: Hyowoon Seo, Yoonseong Kang, Mehdi Bennis, Wan Choi
Categories: cs.IT cs.LG math.IT
Comments: 14 pages, 7 figures, submitted for possible publication
\\
 This work deals with the heterogeneous semantic-native communication (SNC)
problem. When agents do not share the same communication context, the
effectiveness of contextual reasoning (CR) is compromised calling for agents to
infer other agents' context. This article proposes a novel framework for
solving the inverse problem of CR in SNC using two Bayesian inference methods,
namely: Bayesian inverse CR (iCR) and Bayesian inverse linearized CR (iLCR).
The first proposed Bayesian iCR method utilizes Markov Chain Monte Carlo (MCMC)
sampling to infer the agent's context while being computationally expensive. To
address this issue, a Bayesian iLCR method is leveraged which obtains a
linearized CR (LCR) model by training a linear neural network. Experimental
results show that the Bayesian iLCR method requires less computation and
achieves higher inference accuracy compared to Bayesian iCR. Additionally,
heterogeneous SNC based on the context obtained through the Bayesian iLCR
method shows better communication effectiveness than that of Bayesian iCR.
Overall, this work provides valuable insights and methods to improve the
effectiveness of SNC in situations where agents have different contexts.
\\ ( https://arxiv.org/abs/2306.06403 ,  866kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06409 (*cross-listing*)
Date: Sat, 10 Jun 2023 11:02:53 GMT   (1534kb,D)

Title: Functional Causal Bayesian Optimization
Authors: Limor Gultchin and Virginia Aglietti and Alexis Bellot and Silvia
 Chiappa
Categories: stat.ML cs.LG
\\
 We propose functional causal Bayesian optimization (fCBO), a method for
finding interventions that optimize a target variable in a known causal graph.
fCBO extends the CBO family of methods to enable functional interventions,
which set a variable to be a deterministic function of other variables in the
graph. fCBO models the unknown objectives with Gaussian processes whose inputs
are defined in a reproducing kernel Hilbert space, thus allowing to compute
distances among vector-valued functions. In turn, this enables to sequentially
select functions to explore by maximizing an expected improvement acquisition
functional while keeping the typical computational tractability of standard BO
settings. We introduce graphical criteria that establish when considering
functional interventions allows attaining better target effects, and conditions
under which selected interventions are also optimal for conditional target
effects. We demonstrate the benefits of the method in a synthetic and in a
real-world causal graph.
\\ ( https://arxiv.org/abs/2306.06409 ,  1534kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06477 (*cross-listing*)
Date: Sat, 10 Jun 2023 16:31:04 GMT   (823kb,D)

Title: Enhancing Low Resource NER Using Assisting Language And Transfer
 Learning
Authors: Maithili Sabane, Aparna Ranade, Onkar Litake, Parth Patil, Raviraj
 Joshi, Dipali Kadam
Categories: cs.CL cs.LG
Comments: Accepted at International Conference on Applied Artificial
 Intelligence and Computing (ICAAIC) 2023
DOI: 10.1109/ICAAIC56838.2023.10141204
\\
 Named Entity Recognition (NER) is a fundamental task in NLP that is used to
locate the key information in text and is primarily applied in conversational
and search systems. In commercial applications, NER or comparable slot-filling
methods have been widely deployed for popular languages. NER is used in
applications such as human resources, customer service, search engines, content
classification, and academia. In this paper, we draw focus on identifying name
entities for low-resource Indian languages that are closely related, like Hindi
and Marathi. We use various adaptations of BERT such as baseBERT, AlBERT, and
RoBERTa to train a supervised NER model. We also compare multilingual models
with monolingual models and establish a baseline. In this work, we show the
assisting capabilities of the Hindi and Marathi languages for the NER task. We
show that models trained using multiple languages perform better than a single
language. However, we also observe that blind mixing of all datasets doesn't
necessarily provide improvements and data selection methods may be required.
\\ ( https://arxiv.org/abs/2306.06477 ,  823kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06542 (*cross-listing*)
Date: Sat, 10 Jun 2023 23:42:26 GMT   (126kb)

Title: Investigating Practices and Opportunities for Cross-functional
 Collaboration around AI Fairness in Industry Practice
Authors: Wesley Hanwen Deng, Nur Yildirim, Monica Chang, Motahhare Eslami, Ken
 Holstein, Michael Madaio
Categories: cs.HC cs.CY cs.LG
Comments: In Proceedings of the 2023 ACM Conference on Fairness,
 Accountability, and Transparency (FAccT '23)
\\
 An emerging body of research indicates that ineffective cross-functional
collaboration -- the interdisciplinary work done by industry practitioners
across roles -- represents a major barrier to addressing issues of fairness in
AI design and development. In this research, we sought to better understand
practitioners' current practices and tactics to enact cross-functional
collaboration for AI fairness, in order to identify opportunities to support
more effective collaboration. We conducted a series of interviews and design
workshops with 23 industry practitioners spanning various roles from 17
companies. We found that practitioners engaged in bridging work to overcome
frictions in understanding, contextualization, and evaluation around AI
fairness across roles. In addition, in organizational contexts with a lack of
resources and incentives for fairness work, practitioners often piggybacked on
existing requirements (e.g., for privacy assessments) and AI development norms
(e.g., the use of quantitative evaluation metrics), although they worry that
these tactics may be fundamentally compromised. Finally, we draw attention to
the invisible labor that practitioners take on as part of this bridging and
piggybacking work to enact interdisciplinary collaboration for fairness. We
close by discussing opportunities for both FAccT researchers and AI
practitioners to better support cross-functional collaboration for fairness in
the design and development of AI systems.
\\ ( https://arxiv.org/abs/2306.06542 ,  126kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06546 (*cross-listing*)
Date: Sun, 11 Jun 2023 00:13:00 GMT   (83kb,D)

Title: High-Fidelity Audio Compression with Improved RVQGAN
Authors: Rithesh Kumar, Prem Seetharaman, Alejandro Luebs, Ishaan Kumar, Kundan
 Kumar
Categories: cs.SD cs.LG eess.AS
\\
 Language models have been successfully used to model natural signals, such as
images, speech, and music. A key component of these models is a high quality
neural compression model that can compress high-dimensional natural signals
into lower dimensional discrete tokens. To that end, we introduce a
high-fidelity universal neural audio compression algorithm that achieves ~90x
compression of 44.1 KHz audio into tokens at just 8kbps bandwidth. We achieve
this by combining advances in high-fidelity audio generation with better vector
quantization techniques from the image domain, along with improved adversarial
and reconstruction losses. We compress all domains (speech, environment, music,
etc.) with a single universal model, making it widely applicable to generative
modeling of all audio. We compare with competing audio compression algorithms,
and find our method outperforms them significantly. We provide thorough
ablations for every design choice, as well as open-source code and trained
model weights. We hope our work can lay the foundation for the next generation
of high-fidelity audio modeling.
\\ ( https://arxiv.org/abs/2306.06546 ,  83kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06574 (*cross-listing*)
Date: Sun, 11 Jun 2023 03:43:39 GMT   (4399kb,D)

Title: Learnable Digital Twin for Efficient Wireless Network Evaluation
Authors: Boning Li, Timofey Efimov, Abhishek Kumar, Jose Cortes, Gunjan Verma,
 Ananthram Swami, Santiago Segarra
Categories: cs.NI cs.LG cs.SY eess.SY
\\
 Network digital twins (NDTs) facilitate the estimation of key performance
indicators (KPIs) before physically implementing a network, thereby enabling
efficient optimization of the network configuration. In this paper, we propose
a learning-based NDT for network simulators. The proposed method offers a
holistic representation of information flow in a wireless network by
integrating node, edge, and path embeddings. Through this approach, the model
is trained to map the network configuration to KPIs in a single forward pass.
Hence, it offers a more efficient alternative to traditional simulation-based
methods, thus allowing for rapid experimentation and optimization. Our proposed
method has been extensively tested through comprehensive experimentation in
various scenarios, including wired and wireless networks. Results show that it
outperforms baseline learning models in terms of accuracy and robustness.
Moreover, our approach achieves comparable performance to simulators but with
significantly higher computational efficiency.
\\ ( https://arxiv.org/abs/2306.06574 ,  4399kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06581 (*cross-listing*)
Date: Sun, 11 Jun 2023 04:03:22 GMT   (4884kb,D)

Title: Importance Sparsification for Sinkhorn Algorithm
Authors: Mengyu Li, Jun Yu, Tao Li, Cheng Meng
Categories: stat.ML cs.DS cs.LG math.OC
Comments: Accepted by Journal of Machine Learning Research
\\
 Sinkhorn algorithm has been used pervasively to approximate the solution to
optimal transport (OT) and unbalanced optimal transport (UOT) problems.
However, its practical application is limited due to the high computational
complexity. To alleviate the computational burden, we propose a novel
importance sparsification method, called Spar-Sink, to efficiently approximate
entropy-regularized OT and UOT solutions. Specifically, our method employs
natural upper bounds for unknown optimal transport plans to establish effective
sampling probabilities, and constructs a sparse kernel matrix to accelerate
Sinkhorn iterations, reducing the computational cost of each iteration from
$O(n^2)$ to $\widetilde{O}(n)$ for a sample of size $n$. Theoretically, we show
the proposed estimators for the regularized OT and UOT problems are consistent
under mild regularity conditions. Experiments on various synthetic data
demonstrate Spar-Sink outperforms mainstream competitors in terms of both
estimation error and speed. A real-world echocardiogram data analysis shows
Spar-Sink can effectively estimate and visualize cardiac cycles, from which one
can identify heart failure and arrhythmia. To evaluate the numerical accuracy
of cardiac cycle prediction, we consider the task of predicting the end-systole
time point using the end-diastole one. Results show Spar-Sink performs as well
as the classical Sinkhorn algorithm, requiring significantly less computational
time.
\\ ( https://arxiv.org/abs/2306.06581 ,  4884kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06582 (*cross-listing*)
Date: Sun, 11 Jun 2023 04:03:58 GMT   (534kb,D)

Title: Fast, Distribution-free Predictive Inference for Neural Networks with
 Coverage Guarantees
Authors: Yue Gao, Garvesh Raskutti, Rebecca Willet
Categories: stat.ML cs.LG
\\
 This paper introduces a novel, computationally-efficient algorithm for
predictive inference (PI) that requires no distributional assumptions on the
data and can be computed faster than existing bootstrap-type methods for neural
networks. Specifically, if there are $n$ training samples, bootstrap methods
require training a model on each of the $n$ subsamples of size $n-1$; for large
models like neural networks, this process can be computationally prohibitive.
In contrast, our proposed method trains one neural network on the full dataset
with $(\epsilon, \delta)$-differential privacy (DP) and then approximates each
leave-one-out model efficiently using a linear approximation around the
differentially-private neural network estimate. With exchangeable data, we
prove that our approach has a rigorous coverage guarantee that depends on the
preset privacy parameters and the stability of the neural network, regardless
of the data distribution. Simulations and experiments on real data demonstrate
that our method satisfies the coverage guarantees with substantially reduced
computation compared to bootstrap methods.
\\ ( https://arxiv.org/abs/2306.06582 ,  534kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06603 (*cross-listing*)
Date: Sun, 11 Jun 2023 06:40:51 GMT   (13864kb)

Title: Task-Oriented Integrated Sensing, Computation and Communication for
 Wireless Edge AI
Authors: Hong Xing, Guangxu Zhu, Dongzhu Liu, Haifeng Wen, Kaibin Huang, and
 Kaishun Wu
Categories: cs.IT cs.LG eess.SP math.IT
Comments: 18 pages, 6 figures, submitted for possible journal publication
\\
 With the advent of emerging IoT applications such as autonomous driving,
digital-twin and metaverse etc. featuring massive data sensing, analyzing and
inference as well critical latency in beyond 5G (B5G) networks, edge artificial
intelligence (AI) has been proposed to provide high-performance computation of
a conventional cloud down to the network edge. Recently, convergence of
wireless sensing, computation and communication (SC${}^2$) for specific edge AI
tasks, has aroused paradigm shift by enabling (partial) sharing of the
radio-frequency (RF) transceivers and information processing pipelines among
these three fundamental functionalities of IoT. However, most existing design
frameworks separate these designs incurring unnecessary signaling overhead and
waste of energy, and it is therefore of paramount importance to advance fully
integrated sensing, computation and communication (ISCC) to achieve
ultra-reliable and low-latency edge intelligence acquisition. In this article,
we provide an overview of principles of enabling ISCC technologies followed by
two concrete use cases of edge AI tasks demonstrating the advantage of
task-oriented ISCC, and pointed out some practical challenges in edge AI design
with advanced ISCC solutions.
\\ ( https://arxiv.org/abs/2306.06603 ,  13864kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06649 (*cross-listing*)
Date: Sun, 11 Jun 2023 11:08:20 GMT   (37kb)

Title: Efficient Learning of Minimax Risk Classifiers in High Dimensions
Authors: Kartheek Bondugula and Santiago Mazuelas and Aritz P\'erez
Categories: stat.ML cs.LG
Comments: Accepted for the 39th Conference on Uncertainty in Artificial
 Intelligence (UAI 2023)
\\
 High-dimensional data is common in multiple areas, such as health care and
genomics, where the number of features can be tens of thousands. In such
scenarios, the large number of features often leads to inefficient learning.
Constraint generation methods have recently enabled efficient learning of
L1-regularized support vector machines (SVMs). In this paper, we leverage such
methods to obtain an efficient learning algorithm for the recently proposed
minimax risk classifiers (MRCs). The proposed iterative algorithm also provides
a sequence of worst-case error probabilities and performs feature selection.
Experiments on multiple high-dimensional datasets show that the proposed
algorithm is efficient in high-dimensional scenarios. In addition, the
worst-case error probability provides useful information about the classifier
performance, and the features selected by the algorithm are competitive with
the state-of-the-art.
\\ ( https://arxiv.org/abs/2306.06649 ,  37kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06674 (*cross-listing*)
Date: Sun, 11 Jun 2023 13:19:37 GMT   (1306kb,D)

Title: Self-supervised Equality Embedded Deep Lagrange Dual for Approximate
 Constrained Optimization
Authors: Minsoo kim, Hongseok Kim
Categories: math.OC cs.LG
Comments: 11 pages, 5 figures
\\
 Conventional solvers are often computationally expensive for constrained
optimization, particularly in large-scale and time-critical problems. While
this leads to a growing interest in using neural networks (NNs) as fast optimal
solution approximators, incorporating the constraints with NNs is challenging.
In this regard, we propose deep Lagrange dual with equality embedding
(DeepLDE), a framework that learns to find an optimal solution without using
labels. To ensure feasible solutions, we embed equality constraints into the
NNs and train the NNs using the primal-dual method to impose inequality
constraints. Furthermore, we prove the convergence of DeepLDE and show that the
primal-dual learning method alone cannot ensure equality constraints without
the help of equality embedding. Simulation results on convex, non-convex, and
AC optimal power flow (AC-OPF) problems show that the proposed DeepLDE achieves
the smallest optimality gap among all the NN-based approaches while always
ensuring feasible solutions. Furthermore, the computation time of the proposed
method is about 5 to 250 times faster than DC3 and the conventional solvers in
solving constrained convex, non-convex optimization, and/or AC-OPF.
\\ ( https://arxiv.org/abs/2306.06674 ,  1306kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06698 (*cross-listing*)
Date: Sun, 11 Jun 2023 15:04:12 GMT   (18kb)

Title: On the Confidence Intervals in Bioequivalence Studies
Authors: Kexuan Li, Susie Sinks, Peng Sun, Lingli Yang
Categories: stat.ME cs.LG stat.ML stat.OT
\\
 A bioequivalence study is a type of clinical trial designed to compare the
biological equivalence of two different formulations of a drug. Such studies
are typically conducted in controlled clinical settings with human subjects,
who are randomly assigned to receive two formulations. The two formulations are
then compared with respect to their pharmacokinetic profiles, which encompass
the absorption, distribution, metabolism, and elimination of the drug. Under
the guidance from Food and Drug Administration (FDA), for a size-$\alpha$
bioequivalence test, the standard approach is to construct a $100(1-2\alpha)\%$
confidence interval and verify if the confidence interval falls with the
critical region. In this work, we clarify that $100(1-2\alpha)\%$ confidence
interval approach for bioequivalence testing yields a size-$\alpha$ test only
when the two one-sided tests in TOST are ``equal-tailed''. Furthermore, a
$100(1-\alpha)\%$ confidence interval approach is also discussed in the
bioequivalence study.
\\ ( https://arxiv.org/abs/2306.06698 ,  18kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06721 (*cross-listing*)
Date: Sun, 11 Jun 2023 16:46:00 GMT   (144kb,D)

Title: Differentially Private Conditional Independence Testing
Authors: Iden Kalemaj, Shiva Prasad Kasiviswanathan, Aaditya Ramdas
Categories: stat.ML cs.CR cs.LG
\\
 Conditional independence (CI) tests are widely used in statistical data
analysis, e.g., they are the building block of many algorithms for causal graph
discovery. The goal of a CI test is to accept or reject the null hypothesis
that $X \perp \!\!\! \perp Y \mid Z$, where $X \in \mathbb{R}, Y \in
\mathbb{R}, Z \in \mathbb{R}^d$. In this work, we investigate conditional
independence testing under the constraint of differential privacy. We design
two private CI testing procedures: one based on the generalized covariance
measure of Shah and Peters (2020) and another based on the conditional
randomization test of Cand\`es et al. (2016) (under the model-X assumption). We
provide theoretical guarantees on the performance of our tests and validate
them empirically. These are the first private CI tests that work for the
general case when $Z$ is continuous.
\\ ( https://arxiv.org/abs/2306.06721 ,  144kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06727 (*cross-listing*)
Date: Sun, 11 Jun 2023 17:17:48 GMT   (2022kb,D)

Title: A Normalized Bottleneck Distance on Persistence Diagrams and Homology
 Preservation under Dimension Reduction
Authors: Bala Krishnamoorthy and Nathan H. May
Categories: cs.CG cs.LG math.AT
Comments: 19 pages, 2 figures
\\
 Persistence diagrams are used as signatures of point cloud data assumed to be
sampled from manifolds, and represent their topology in a compact fashion.
Further, two given clouds of points can be compared by directly comparing their
persistence diagrams using the bottleneck distance, d_B. But one potential
drawback of this pipeline is that point clouds sampled from topologically
similar manifolds can have arbitrarily large d_B values when there is a large
degree of scaling between them. This situation is typical in dimension
reduction frameworks that are also aiming to preserve topology.
 We define a new scale-invariant distance between persistence diagrams termed
normalized bottleneck distance, d_N, and study its properties. In defining d_N,
we also develop a broader framework called metric decomposition for comparing
finite metric spaces of equal cardinality with a bijection. We utilize metric
decomposition to prove a stability result for d_N by deriving an explicit bound
on the distortion of the associated bijective map. We then study two popular
dimension reduction techniques, Johnson-Lindenstrauss (JL) projections and
metric multidimensional scaling (mMDS), and a third class of general
biLipschitz mappings. We provide new bounds on how well these dimension
reduction techniques preserve homology with respect to d_N. For a JL map f that
transforms input X to f(X), we show that d_N(dgm(X),dgm(f(X)) < e, where dgm(X)
is the Vietoris-Rips persistence diagram of X, and 0 < e < 1 is the tolerance
up to which pairwise distances are preserved by f. For mMDS, we present new
bounds for both d_B and d_N between persistence diagrams of X and its
projection in terms of the eigenvalues of the covariance matrix. And for
k-biLipschitz maps, we show that d_N is bounded by the product of (k^2-1)/k and
the ratio of diameters of X and f(X).
\\ ( https://arxiv.org/abs/2306.06727 ,  2022kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06736 (*cross-listing*)
Date: Sun, 11 Jun 2023 18:06:06 GMT   (696kb,D)

Title: Efficient Skip Connections Realization for Secure Inference on Encrypted
 Data
Authors: Nir Drucker and Itamar Zimerman
Categories: cs.CR cs.LG
\\
 Homomorphic Encryption (HE) is a cryptographic tool that allows performing
computation under encryption, which is used by many privacy-preserving machine
learning solutions, for example, to perform secure classification. Modern deep
learning applications yield good performance for example in image processing
tasks benchmarks by including many skip connections. The latter appears to be
very costly when attempting to execute model inference under HE. In this paper,
we show that by replacing (mid-term) skip connections with (short-term) Dirac
parameterization and (long-term) shared-source skip connection we were able to
reduce the skip connections burden for HE-based solutions, achieving x1.3
computing power improvement for the same accuracy.
\\ ( https://arxiv.org/abs/2306.06736 ,  696kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06743 (*cross-listing*)
Date: Sun, 11 Jun 2023 18:41:23 GMT   (1942kb,D)

Title: Comparing machine learning models for tau triggers
Authors: Maayan Yaary (1 and 2), Uriel Barron (1), Luis Pascual Dom\'inguez
 (1), Boping Chen (1), Liron Barak (1), Erez Etzion (1), Raja Giryes (2) ((1)
 Raymond and Beverly Sackler School of Physics and Astronomy, Tel Aviv
 University, Tel Aviv, Israel (2) School of Electrical Engineering, Tel Aviv
 University, Tel Aviv, Israel)
Categories: hep-ex cs.LG physics.ins-det
Comments: Submitted to JHEP
\\
 This paper introduces novel supervised learning techniques for real-time
selection (triggering) of hadronically decaying tau leptons in proton-proton
colliders. By implementing classic machine learning decision trees and advanced
deep learning models, such as Multi-Layer Perceptron or residual NN, visible
improvements in performance compared to standard tau triggers are observed. We
show how such an implementation may lower the current energy thresholds, thus
contributing to increasing the sensitivity of searches for new phenomena in
proton-proton collisions classified by low-energy tau leptons.
\\ ( https://arxiv.org/abs/2306.06743 ,  1942kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06792 (*cross-listing*)
Date: Sun, 11 Jun 2023 22:14:21 GMT   (593kb,D)

Title: A Neural Network Implementation for Free Energy Principle
Authors: Jingwei Liu
Categories: cs.NE cs.LG q-bio.NC
Comments: 12 pages, 3 figures, submitted to the 4th international workshop on
 active inference
MSC-class: I.2.3, F.4.1
\\
 The free energy principle (FEP), as an encompassing framework and a unified
brain theory, has been widely applied to account for various problems in fields
such as cognitive science, neuroscience, social interaction, and hermeneutics.
As a computational model deeply rooted in math and statistics, FEP posits an
optimization problem based on variational Bayes, which is solved either by
dynamic programming or expectation maximization in practice. However, there
seems to be a bottleneck in extending the FEP to machine learning and
implementing such models with neural networks. This paper gives a preliminary
attempt at bridging FEP and machine learning, via a classical neural network
model, the Helmholtz machine. As a variational machine learning model, the
Helmholtz machine is optimized by minimizing its free energy, the same
objective as FEP. Although the Helmholtz machine is not temporal, it gives an
ideal parallel to the vanilla FEP and the hierarchical model of the brain,
under which the active inference and predictive coding could be formulated
coherently. Besides a detailed theoretical discussion, the paper also presents
a preliminary experiment to validate the hypothesis. By fine-tuning the trained
neural network through active inference, the model performance is promoted to
accuracy above 99\%. In the meantime, the data distribution is continuously
deformed to a salience that conforms to the model representation, as a result
of active sampling.
\\ ( https://arxiv.org/abs/2306.06792 ,  593kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06798 (*cross-listing*)
Date: Sun, 11 Jun 2023 22:39:28 GMT   (2878kb,D)

Title: Kepler: Robust Learning for Faster Parametric Query Optimization
Authors: Lyric Doshi, Vincent Zhuang, Gaurav Jain, Ryan Marcus, Haoyu Huang,
 Deniz Altinb\"uken, Eugene Brevdo, Campbell Fraser
Categories: cs.DB cs.LG
Comments: SIGMOD 2023
DOI: 10.1145/3588963
\\
 Most existing parametric query optimization (PQO) techniques rely on
traditional query optimizer cost models, which are often inaccurate and result
in suboptimal query performance. We propose Kepler, an end-to-end
learning-based approach to PQO that demonstrates significant speedups in query
latency over a traditional query optimizer. Central to our method is Row Count
Evolution (RCE), a novel plan generation algorithm based on perturbations in
the sub-plan cardinality space. While previous approaches require accurate cost
models, we bypass this requirement by evaluating candidate plans via actual
execution data and training an ML model to predict the fastest plan given
parameter binding values. Our models leverage recent advances in neural network
uncertainty in order to robustly predict faster plans while avoiding
regressions in query performance. Experimentally, we show that Kepler achieves
significant improvements in query runtime on multiple datasets on PostgreSQL.
\\ ( https://arxiv.org/abs/2306.06798 ,  2878kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06819 (*cross-listing*)
Date: Mon, 12 Jun 2023 01:55:53 GMT   (232kb,D)

Title: Multimodal Audio-textual Architecture for Robust Spoken Language
 Understanding
Authors: Anderson R. Avila, Mehdi Rezagholizadeh, Chao Xing
Categories: cs.CL cs.LG eess.AS
\\
 Recent voice assistants are usually based on the cascade spoken language
understanding (SLU) solution, which consists of an automatic speech recognition
(ASR) engine and a natural language understanding (NLU) system. Because such
approach relies on the ASR output, it often suffers from the so-called ASR
error propagation. In this work, we investigate impacts of this ASR error
propagation on state-of-the-art NLU systems based on pre-trained language
models (PLM), such as BERT and RoBERTa. Moreover, a multimodal language
understanding (MLU) module is proposed to mitigate SLU performance degradation
caused by errors present in the ASR transcript. The MLU benefits from
self-supervised features learned from both audio and text modalities,
specifically Wav2Vec for speech and Bert/RoBERTa for language. Our MLU combines
an encoder network to embed the audio signal and a text encoder to process text
transcripts followed by a late fusion layer to fuse audio and text logits. We
found that the proposed MLU showed to be robust towards poor quality ASR
transcripts, while the performance of BERT and RoBERTa are severely
compromised. Our model is evaluated on five tasks from three SLU datasets and
robustness is tested using ASR transcripts from three ASR engines. Results show
that the proposed approach effectively mitigates the ASR error propagation
problem, surpassing the PLM models' performance across all datasets for the
academic ASR engine.
\\ ( https://arxiv.org/abs/2306.06819 ,  232kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06825 (*cross-listing*)
Date: Mon, 12 Jun 2023 02:25:44 GMT   (259kb,D)

Title: AnoFel: Supporting Anonymity for Privacy-Preserving Federated Learning
Authors: Ghada Almashaqbeh, Zahra Ghodsi
Categories: cs.CR cs.LG
\\
 Federated learning enables users to collaboratively train a machine learning
model over their private datasets. Secure aggregation protocols are employed to
mitigate information leakage about the local datasets. This setup, however,
still leaks the participation of a user in a training iteration, which can also
be sensitive. Protecting user anonymity is even more challenging in dynamic
environments where users may (re)join or leave the training process at any
point of time. In this paper, we introduce AnoFel, the first framework to
support private and anonymous dynamic participation in federated learning.
AnoFel leverages several cryptographic primitives, the concept of anonymity
sets, differential privacy, and a public bulletin board to support anonymous
user registration, as well as unlinkable and confidential model updates
submission. Additionally, our system allows dynamic participation, where users
can join or leave at any time, without needing any recovery protocol or
interaction. To assess security, we formalize a notion for privacy and
anonymity in federated learning, and formally prove that AnoFel satisfies this
notion. To the best of our knowledge, our system is the first solution with
provable anonymity guarantees. To assess efficiency, we provide a concrete
implementation of AnoFel, and conduct experiments showing its ability to
support learning applications scaling to a large number of clients. For an
MNIST classification task with 512 clients, the client setup takes less than 3
sec, and a training iteration can be finished in 3.2 sec. We also compare our
system with prior work and demonstrate its practicality for contemporary
learning tasks.
\\ ( https://arxiv.org/abs/2306.06825 ,  259kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06844 (*cross-listing*)
Date: Mon, 12 Jun 2023 03:35:45 GMT   (896kb,D)

Title: Provably Efficient Bayesian Optimization with Unbiased Gaussian Process
 Hyperparameter Estimation
Authors: Huong Ha, Vu Nguyen, Hongyu Zhang, Anton van den Hengel
Categories: stat.ML cs.LG
Comments: 23 pages, 5 figures
\\
 Gaussian process (GP) based Bayesian optimization (BO) is a powerful method
for optimizing black-box functions efficiently. The practical performance and
theoretical guarantees associated with this approach depend on having the
correct GP hyperparameter values, which are usually unknown in advance and need
to be estimated from the observed data. However, in practice, these estimations
could be incorrect due to biased data sampling strategies commonly used in BO.
This can lead to degraded performance and break the sub-linear global
convergence guarantee of BO. To address this issue, we propose a new BO method
that can sub-linearly converge to the global optimum of the objective function
even when the true GP hyperparameters are unknown in advance and need to be
estimated from the observed data. Our method uses a multi-armed bandit
technique (EXP3) to add random data points to the BO process, and employs a
novel training loss function for the GP hyperparameter estimation process that
ensures unbiased estimation from the observed data. We further provide
theoretical analysis of our proposed method. Finally, we demonstrate
empirically that our method outperforms existing approaches on various
synthetic and real-world problems.
\\ ( https://arxiv.org/abs/2306.06844 ,  896kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06945 (*cross-listing*)
Date: Mon, 12 Jun 2023 08:26:47 GMT   (14460kb,D)

Title: Underwater Acoustic Target Recognition based on Smoothness-inducing
 Regularization and Spectrogram-based Data Augmentation
Authors: Ji Xu, Yuan Xie, Wenchao Wang
Categories: cs.SD cs.LG
Journal-ref: Ocean Engineering, 2023, 281: 114926
DOI: 10.1016/j.oceaneng.2023.114926
\\
 Underwater acoustic target recognition is a challenging task owing to the
intricate underwater environments and limited data availability. Insufficient
data can hinder the ability of recognition systems to support complex modeling,
thus impeding their advancement. To improve the generalization capacity of
recognition models, techniques such as data augmentation have been employed to
simulate underwater signals and diversify data distribution. However, the
complexity of underwater environments can cause the simulated signals to
deviate from real scenarios, resulting in biased models that are misguided by
non-true data. In this study, we propose two strategies to enhance the
generalization ability of models in the case of limited data while avoiding the
risk of performance degradation. First, as an alternative to traditional data
augmentation, we utilize smoothness-inducing regularization, which only
incorporates simulated signals in the regularization term. Additionally, we
propose a specialized spectrogram-based data augmentation strategy, namely
local masking and replicating (LMR), to capture inter-class relationships. Our
experiments and visualization analysis demonstrate the superiority of our
proposed strategies.
\\ ( https://arxiv.org/abs/2306.06945 ,  14460kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06954 (*cross-listing*)
Date: Mon, 12 Jun 2023 08:37:36 GMT   (1706kb,D)

Title: Multi-View Frequency-Attention Alternative to CNN Frontends for
 Automatic Speech Recognition
Authors: Belen Alastruey, Lukas Drude, Jahn Heymann, Simon Wiesler
Categories: eess.AS cs.CL cs.LG cs.SD
\\
 Convolutional frontends are a typical choice for Transformer-based automatic
speech recognition to preprocess the spectrogram, reduce its sequence length,
and combine local information in time and frequency similarly. However, the
width and height of an audio spectrogram denote different information, e.g.,
due to reverberation as well as the articulatory system, the time axis has a
clear left-to-right dependency. On the contrary, vowels and consonants
demonstrate very different patterns and occupy almost disjoint frequency
ranges. Therefore, we hypothesize, global attention over frequencies is
beneficial over local convolution. We obtain 2.4 % relative word error rate
reduction (rWERR) on a production scale Conformer transducer replacing its
convolutional neural network frontend by the proposed F-Attention module on
Alexa traffic. To demonstrate generalizability, we validate this on public
LibriSpeech data with a long short term memory-based listen attend and spell
architecture obtaining 4.6 % rWERR and demonstrate robustness to (simulated)
noisy conditions.
\\ ( https://arxiv.org/abs/2306.06954 ,  1706kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06979 (*cross-listing*)
Date: Mon, 12 Jun 2023 09:21:34 GMT   (680kb,D)

Title: A Weakly Supervised Approach to Emotion-change Prediction and Improved
 Mood Inference
Authors: Soujanya Narayana, Ibrahim Radwan, Ravikiran Parameshwara, Iman
 Abbasnejad, Akshay Asthana, Ramanathan Subramanian, Roland Goecke
Categories: cs.HC cs.LG cs.MM
Comments: 9 pages, 3 figures, 6 tables
\\
 Whilst a majority of affective computing research focuses on inferring
emotions, examining mood or understanding the \textit{mood-emotion interplay}
has received significantly less attention. Building on prior work, we (a)
deduce and incorporate emotion-change ($\Delta$) information for inferring
mood, without resorting to annotated labels, and (b) attempt mood prediction
for long duration video clips, in alignment with the characterisation of mood.
We generate the emotion-change ($\Delta$) labels via metric learning from a
pre-trained Siamese Network, and use these in addition to mood labels for mood
classification. Experiments evaluating \textit{unimodal} (training only using
mood labels) vs \textit{multimodal} (training using mood plus $\Delta$ labels)
models show that mood prediction benefits from the incorporation of
emotion-change information, emphasising the importance of modelling the
mood-emotion interplay for effective mood inference.
\\ ( https://arxiv.org/abs/2306.06979 ,  680kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07033 (*cross-listing*)
Date: Mon, 12 Jun 2023 11:26:08 GMT   (866kb,D)

Title: When Vision Fails: Text Attacks Against ViT and OCR
Authors: Nicholas Boucher, Jenny Blessing, Ilia Shumailov, Ross Anderson,
 Nicolas Papernot
Categories: cs.CR cs.LG
\\
 While text-based machine learning models that operate on visual inputs of
rendered text have become robust against a wide range of existing attacks, we
show that they are still vulnerable to visual adversarial examples encoded as
text. We use the Unicode functionality of combining diacritical marks to
manipulate encoded text so that small visual perturbations appear when the text
is rendered. We show how a genetic algorithm can be used to generate visual
adversarial examples in a black-box setting, and conduct a user study to
establish that the model-fooling adversarial examples do not affect human
comprehension. We demonstrate the effectiveness of these attacks in the real
world by creating adversarial examples against production models published by
Facebook, Microsoft, IBM, and Google.
\\ ( https://arxiv.org/abs/2306.07033 ,  866kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07046 (*cross-listing*)
Date: Mon, 12 Jun 2023 11:51:50 GMT   (169kb)

Title: Imbalanced Multi-label Classification for Business-related Text with
 Moderately Large Label Spaces
Authors: Muhammad Arslan and Christophe Cruz
Categories: cs.IR cs.LG
Journal-ref: https://easychair.org/smart-program/FRCCS2023/2023-06-01.html
\\
 In this study, we compared the performance of four different methods for
multi label text classification using a specific imbalanced business dataset.
The four methods we evaluated were fine tuned BERT, Binary Relevance,
Classifier Chains, and Label Powerset. The results show that fine tuned BERT
outperforms the other three methods by a significant margin, achieving high
values of accuracy, F1 Score, Precision, and Recall. Binary Relevance also
performs well on this dataset, while Classifier Chains and Label Powerset
demonstrate relatively poor performance. These findings highlight the
effectiveness of fine tuned BERT for multi label text classification tasks, and
suggest that it may be a useful tool for businesses seeking to analyze complex
and multifaceted texts.
\\ ( https://arxiv.org/abs/2306.07046 ,  169kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07056 (*cross-listing*)
Date: Mon, 12 Jun 2023 12:05:54 GMT   (2055kb,D)

Title: Kernel Random Projection Depth for Outlier Detection
Authors: Akira Tamamori
Categories: stat.ML cs.LG stat.AP stat.ME
Comments: submitted to APSIPA ASC 2023
\\
 This paper proposes an extension of Random Projection Depth (RPD) to cope
with multiple modalities and non-convexity on data clouds. In the framework of
the proposed method, the RPD is computed in a reproducing kernel Hilbert space.
With the help of kernel principal component analysis, we expect that the
proposed method can cope with the above multiple modalities and non-convexity.
The experimental results demonstrate that the proposed method outperforms RPD
and is comparable to other existing detection models on benchmark datasets
regarding Area Under the Curves (AUCs) of Receiver Operating Characteristic
(ROC).
\\ ( https://arxiv.org/abs/2306.07056 ,  2055kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07074 (*cross-listing*)
Date: Mon, 12 Jun 2023 12:39:21 GMT   (15525kb,D)

Title: Using a neural network approach to accelerate disequilibrium chemistry
 calculations in exoplanet atmospheres
Authors: Julius L. A. M. Hendrix, Amy J. Louca, Yamila Miguel
Categories: astro-ph.EP cs.LG
Comments: 13 pages, 9 figures, accepted for publication at MNRAS
\\
 In this era of exoplanet characterisation with JWST, the need for a fast
implementation of classical forward models to understand the chemical and
physical processes in exoplanet atmospheres is more important than ever.
Notably, the time-dependent ordinary differential equations to be solved by
chemical kinetics codes are very time-consuming to compute. In this study, we
focus on the implementation of neural networks to replace mathematical
frameworks in one-dimensional chemical kinetics codes. Using the gravity
profile, temperature-pressure profiles, initial mixing ratios, and stellar flux
of a sample of hot-Jupiters atmospheres as free parameters, the neural network
is built to predict the mixing ratio outputs in steady state. The architecture
of the network is composed of individual autoencoders for each input variable
to reduce the input dimensionality, which is then used as the input training
data for an LSTM-like neural network. Results show that the autoencoders for
the mixing ratios, stellar spectra, and pressure profiles are exceedingly
successful in encoding and decoding the data. Our results show that in 90% of
the cases, the fully trained model is able to predict the evolved mixing ratios
of the species in the hot-Jupiter atmosphere simulations. The fully trained
model is ~1000 times faster than the simulations done with the forward,
chemical kinetics model while making accurate predictions.
\\ ( https://arxiv.org/abs/2306.07074 ,  15525kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07118 (*cross-listing*)
Date: Mon, 12 Jun 2023 13:52:28 GMT   (1903kb)

Title: On building machine learning pipelines for Android malware detection: a
 procedural survey of practices, challenges and opportunities
Authors: Masoud Mehrabi Koushki, Ibrahim AbuAlhaol, Anandharaju Durai Raju,
 Yang Zhou, Ronnie Salvador Giagone and Huang Shengqiang
Categories: cs.CR cs.LG
Comments: file:///C:/Users/ibrahim_abualhaol/Downloads/s42400-022-00119-8.pdf
Journal-ref: SpringerOpen Cybersecurity 2022
\\
 As the smartphone market leader, Android has been a prominent target for
malware attacks. The number of malicious applications (apps) identified for it
has increased continually over the past decade, creating an immense challenge
for all parties involved. For market holders and researchers, in particular,
the large number of samples has made manual malware detection unfeasible,
leading to an influx of research that investigate Machine Learning (ML)
approaches to automate this process. However, while some of the proposed
approaches achieve high performance, rapidly evolving Android malware has made
them unable to maintain their accuracy over time. This has created a need in
the community to conduct further research, and build more flexible ML
pipelines. Doing so, however, is currently hindered by a lack of systematic
overview of the existing literature, to learn from and improve upon the
existing solutions. Existing survey papers often focus only on parts of the ML
process (e.g., data collection or model deployment), while omitting other
important stages, such as model evaluation and explanation. In this paper, we
address this problem with a review of 42 highly-cited papers, spanning a decade
of research (from 2011 to 2021). We introduce a novel procedural taxonomy of
the published literature, covering how they have used ML algorithms, what
features they have engineered, which dimensionality reduction techniques they
have employed, what datasets they have employed for training, and what their
evaluation and explanation strategies are. Drawing from this taxonomy, we also
identify gaps in knowledge and provide ideas for improvement and future work.
\\ ( https://arxiv.org/abs/2306.07118 ,  1903kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07158 (*cross-listing*)
Date: Mon, 12 Jun 2023 14:44:22 GMT   (18712kb,D)

Title: Riemannian Laplace approximations for Bayesian neural networks
Authors: Federico Bergamin, Pablo Moreno-Mu\~noz, S{\o}ren Hauberg, Georgios
 Arvanitidis
Categories: stat.ML cs.LG stat.ME
Comments: 28 pages, 12 figures. Under submission
\\
 Bayesian neural networks often approximate the weight-posterior with a
Gaussian distribution. However, practical posteriors are often, even locally,
highly non-Gaussian, and empirical performance deteriorates. We propose a
simple parametric approximate posterior that adapts to the shape of the true
posterior through a Riemannian metric that is determined by the log-posterior
gradient. We develop a Riemannian Laplace approximation where samples naturally
fall into weight-regions with low negative log-posterior. We show that these
samples can be drawn by solving a system of ordinary differential equations,
which can be done efficiently by leveraging the structure of the Riemannian
metric and automatic differentiation. Empirically, we demonstrate that our
approach consistently improves over the conventional Laplace approximation
across tasks. We further show that, unlike the conventional Laplace
approximation, our method is not overly sensitive to the choice of prior, which
alleviates a practical pitfall of current approaches.
\\ ( https://arxiv.org/abs/2306.07158 ,  18712kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07165 (*cross-listing*)
Date: Mon, 12 Jun 2023 14:53:00 GMT   (4521kb)

Title: Explainable AI and Machine Learning Towards Human Gait Deterioration
 Analysis
Authors: Abdullah Alharthi
Categories: eess.SP cs.LG
Comments: Book Chapter
\\
 Gait analysis, an expanding research area, employs non invasive sensors and
machine learning techniques for a range of applicatio ns. In this study, we
concentrate on gait analysis for detecting cognitive decline in Parkinson's
disease (PD) and under dual task conditions. Using convolutional neural
networks (CNNs) and explainable machine learning, we objectively analyze gait
data and associate findings with clinically relevant biomarkers. This is
accomplished by connecting machine learning outputs to decisions based on human
visual observations or derived quantitative gait parameters, which are tested
and routinely implemented in curr ent healthcare practice. Our analysis of gait
deterioration due to cognitive decline in PD enables robust results using the
proposed methods for assessing PD severity from ground reaction force (GRF)
data. We achieved classification accuracies of 98% F1 sc ores for each
PhysioNet.org dataset and 95.5% F1 scores for the combined PhysioNet dataset.
By linking clinically observable features to the model outputs, we demonstrate
the impact of PD severity on gait. Furthermore, we explore the significance of
cognit ive load in healthy gait analysis, resulting in robust classification
accuracies of 100% F1 scores for subject identity verification. We also
identify weaker features crucial for model predictions using Layer Wise
Relevance Propagation. A notable finding o f this study reveals that cognitive
deterioration's effect on gait influences body balance and foot landing/lifting
dynamics in both classification cases: cognitive load in healthy gait and
cognitive decline in PD gait.
\\ ( https://arxiv.org/abs/2306.07165 ,  4521kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07187 (*cross-listing*)
Date: Mon, 12 Jun 2023 15:40:31 GMT   (5929kb,D)

Title: Video-to-Music Recommendation using Temporal Alignment of Segments
Authors: Laure Pr\'etet, Ga\"el Richard, Cl\'ement Souchier, Geoffroy Peeters
Categories: cs.MM cs.IR cs.LG cs.SD eess.AS
Journal-ref: IEEE Transactions on Multimedia, 18 February 2022
DOI: 10.1109/TMM.2022.3152598
\\
 We study cross-modal recommendation of music tracks to be used as soundtracks
for videos. This problem is known as the music supervision task. We build on a
self-supervised system that learns a content association between music and
video. In addition to the adequacy of content, adequacy of structure is crucial
in music supervision to obtain relevant recommendations. We propose a novel
approach to significantly improve the system's performance using
structure-aware recommendation. The core idea is to consider not only the full
audio-video clips, but rather shorter segments for training and inference. We
find that using semantic segments and ranking the tracks according to sequence
alignment costs significantly improves the results. We investigate the impact
of different ranking metrics and segmentation methods.
\\ ( https://arxiv.org/abs/2306.07187 ,  5929kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07235 (*cross-listing*)
Date: Mon, 12 Jun 2023 16:53:38 GMT   (6956kb)

Title: Deep Gaussian Mixture Ensembles
Authors: Yousef El-Laham, Niccol\`o Dalmasso, Elizabeth Fons, Svitlana
 Vyetrenko
Categories: stat.ML cs.LG stat.ME
Comments: Accepted at Uncertainty in Artificial Intelligence (UAI) 2023
 Conference, 7 figures, 11 tables
\\
 This work introduces a novel probabilistic deep learning technique called
deep Gaussian mixture ensembles (DGMEs), which enables accurate quantification
of both epistemic and aleatoric uncertainty. By assuming the data generating
process follows that of a Gaussian mixture, DGMEs are capable of approximating
complex probability distributions, such as heavy-tailed or multimodal
distributions. Our contributions include the derivation of an
expectation-maximization (EM) algorithm used for learning the model parameters,
which results in an upper-bound on the log-likelihood of training data over
that of standard deep ensembles. Additionally, the proposed EM training
procedure allows for learning of mixture weights, which is not commonly done in
ensembles. Our experimental results demonstrate that DGMEs outperform
state-of-the-art uncertainty quantifying deep learning models in handling
complex predictive densities.
\\ ( https://arxiv.org/abs/2306.07235 ,  6956kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07246 (*cross-listing*)
Date: Mon, 12 Jun 2023 17:12:08 GMT   (1676kb)

Title: Reliable machine learning potentials based on artificial neural network
 for graphene
Authors: Akash Singh, Yumeng Li
Categories: physics.comp-ph cond-mat.mes-hall cond-mat.mtrl-sci cond-mat.stat-mech cs.LG
Comments: 10 pages
Journal-ref: Computational Materials Science Volume 227, August 2023, 112272
DOI: 10.1016/j.commatsci.2023.112272
\\
 Graphene is one of the most researched two dimensional (2D) material due to
its unique combination of mechanical, thermal and electrical properties.
Special 2D structure of graphene enables it to exhibit a wide range of peculiar
material properties like high Young's modulus, high specific strength etc.
which are critical for myriad of applications including light weight structural
materials, multi-functional coating and flexible electronics. It is quite
challenging and costly to experimentally investigate graphene/graphene based
nanocomposites, computational simulations such as molecular dynamics (MD)
simulations are widely adopted for understanding the microscopic origins of
their unique properties. However, disparate results were reported from
computational studies, especially MD simulations using various empirical
inter-atomic potentials. In this work, an artificial neural network based
interatomic potential has been developed for graphene to represent the
potential energy surface based on first principle calculations. The developed
machine learning potential (MLP) facilitates high fidelity MD simulations to
approach the accuracy of ab initio methods but with a fraction of computational
cost, which allows larger simulation size/length, and thereby enables
accelerated discovery/design of graphene-based novel materials. Lattice
parameter, coefficient of thermal expansion (CTE), Young's modulus and yield
strength are estimated using machine learning accelerated MD simulations
(MLMD), which are compared to experimental/first principle calculations from
previous literatures. It is demonstrated that MLMD can capture the dominating
mechanism governing CTE of graphene, including effects from lattice parameter
and out of plane rippling.
\\ ( https://arxiv.org/abs/2306.07246 ,  1676kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07254 (*cross-listing*)
Date: Mon, 12 Jun 2023 17:22:57 GMT   (86kb,D)

Title: On the Expected Size of Conformal Prediction Sets
Authors: Guneet S. Dhillon and George Deligiannidis and Tom Rainforth
Categories: stat.ML cs.LG
\\
 While conformal predictors reap the benefits of rigorous statistical
guarantees for their error frequency, the size of their corresponding
prediction sets is critical to their practical utility. Unfortunately, there is
currently a lack of finite-sample analysis and guarantees for their prediction
set sizes. To address this shortfall, we theoretically quantify the expected
size of the prediction set under the split conformal prediction framework. As
this precise formulation cannot usually be calculated directly, we further
derive point estimates and high probability intervals that can be easily
computed, providing a practical method for characterizing the expected
prediction set size across different possible realizations of the test and
calibration data. Additionally, we corroborate the efficacy of our results with
experiments on real-world datasets, for both regression and classification
problems.
\\ ( https://arxiv.org/abs/2306.07254 ,  86kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06137 (*cross-listing*)
Date: Fri, 9 Jun 2023 05:52:26 GMT   (1055kb,D)

Title: Sensing-Aided Scalable Peer-to-Peer Millimeter-Wave Communication
Authors: Sidong Guo, Shez Malik, Xiangyu Li
Categories: eess.SP cs.SY eess.SY
\\
 One of the bottlenecks of modern communication is to enable sensing and
communication simultaneously with causing scheduling conflicts, and how sensing
may be leveraged to help directional communication accuracy. To this end, we
propose and implement a novel peer-to-peer mmWave communication system to
achieve joint beamforming and sensing. A radar and IMU assisted tracking and
beamforming algorithm is designed and tested and the results show robust
tracking capacity with an overall higher throughtput obtained. The results
demonstrated promising future extensions where with refinements the design and
implementation can be deployed in a more scalable manner.
\\ ( https://arxiv.org/abs/2306.06137 ,  1055kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06201 (*cross-listing*)
Date: Fri, 9 Jun 2023 19:10:04 GMT   (613kb,D)

Title: Approximate Dynamic Programming with Feasibility Guarantees
Authors: Alexander Engelmann, Maisa B. Bandeira, Timm Faulwasser
Categories: math.OC cs.SY eess.SY
\\
 The safe and economical operation of large-scale networked systems is
challenging. Optimization-based schemes are frequently employed, since they
achieve near-optimality while ensuring safety via the explicit consideration of
constraints. Hence, these schemes require solving large-scale optimization
problems. Iterative techniques from distributed optimization have been proposed
for complexity reduction. Yet, they achieve feasibility asymptotically, which
induces a substantial computational burden. This work presents a approximate
dynamic programming scheme, which is guaranteed to deliver a feasible solution
in ``one shot'', i.e., in one backward-forward iteration over all subproblems.
The proposed scheme generalizes and unifies successful methods from seemingly
disconnected domains such as power systems and optimal control. We demonstrate
its applicability to problems with non-convex constraints via numerical
examples from power systems and control.
\\ ( https://arxiv.org/abs/2306.06201 ,  613kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06255 (*cross-listing*)
Date: Fri, 9 Jun 2023 20:57:27 GMT   (1121kb,D)

Title: Early Malware Detection and Next-Action Prediction
Authors: Zahra Jamadi and Amir G. Aghdam
Categories: cs.CR cs.SY eess.SY
\\
 In this paper, we propose a framework for early-stage malware detection and
mitigation by leveraging natural language processing (NLP) techniques and
machine learning algorithms. Our primary contribution is presenting an approach
for predicting the upcoming actions of malware by treating application
programming interface (API) call sequences as natural language inputs and
employing text classification methods, specifically a Bi-LSTM neural network,
to predict the next API call. This enables proactive threat identification and
mitigation, demonstrating the effectiveness of applying NLP principles to API
call sequences. The Bi-LSTM model is evaluated using two datasets. %The model
achieved an accuracy of 93.6\% and 88.8\% for the %first and second dataset
respectively. Additionally, by modeling consecutive API calls as 2-gram and
3-gram strings, we extract new features to be further processed using a
Bagging-XGBoost algorithm, effectively predicting malware presence at its early
stages. The accuracy of the proposed framework is evaluated by simulations.
\\ ( https://arxiv.org/abs/2306.06255 ,  1121kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06373 (*cross-listing*)
Date: Sat, 10 Jun 2023 07:40:45 GMT   (2818kb,D)

Title: Quantum feedback control of a two-atom network closed by a semi-infinite
 waveguide
Authors: Haijin Ding, Guofeng Zhang, Mu-Tian Cheng, Guoqing Cai
Categories: quant-ph cs.SY eess.SY physics.atom-ph
\\
 The purpose of this paper is to study the dynamics of a coherent feedback
network where two two-level atoms are coupled with a semi-infinite waveguide.
In this set-up, the two-level atoms can work as the photon source, and the
photons can be emitted into the waveguide via the nonchiral or chiral couplings
between the atom and the waveguide, according to whether the coupling strengths
between the atoms and different directional propagating modes in the waveguide
are identical or not. For the photon emitted by one of the two atoms, it can be
reflected by the terminal mirror, or interact with the other atom, and then the
photon can re-interact with the former atom. When the two atoms are both
initially excited, finally there can be two-photon, one-photon or zero-photon
states in the waveguide via the spontaneous emission and feedback interactions,
and this is influenced by the locations of the atoms and the chirality of the
coupling between the atom and the waveguide. Similarly, if only one of the two
atoms is initially excited, there can be zero or one photon in the waveguide.
Thus we can control the number of the photons in the waveguide and the atomic
states by tuning the feedback loop length and the chiral couplings between the
atom and waveguide. The photonic state in the waveguide is analyzed in the
frequency domain and the spatial domain, and the transient process of photon
emissions can be better understood based on the comprehensive analysis in these
two domains.
\\ ( https://arxiv.org/abs/2306.06373 ,  2818kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06379 (*cross-listing*)
Date: Sat, 10 Jun 2023 08:33:51 GMT   (3646kb)

Title: Implementation of Multiple-Step Quantized STDP based on Linear Weight
 Update Memristive Synapses
Authors: Y. Liu, D. Wang, Z. Dong, H. Xie, and W. Zhao
Categories: cs.ET cs.SY eess.SY
Comments: 10 pages, 25 figures
\\
 Memristors have been widely studied as artificial synapses in neuromorphic
circuits, due to their functional similarity with biological synapse, low
operating power, and high integration density. In this work, a memristor bridge
synapse for SNN with excellent linearity and soft-bound synaptic plasticity is
designed and utilized for a neuron circuit implementing the robust spike-timing
dependent plasticity (STDP) learning. This is the first of its kind
demonstrating successful pulse width encoded multiple-step quantized STDP, with
mixed-signal neuron possessing linear weight update. Physical models are
employed to study the performance of proposed synapse and circuit, and
simulations are carried out based on the MATLAB Simulink and Simscape. An
improved memristor model which exhibits balanced flexibility, efficiency,
convergence, and emulation performance, is developed though including the
nonlinear Joule effect and weak signal effect. By using the improved memristor
model in pattern learning, the influence of weak signal induced weight
variation on circuit performance can be rigorously assessed. Moreover, the
robustness and compatibility of the neuron circuit are greatly enhanced by
employing the clock-based square-wave pulsed to process and program the
synaptic weight. This proposed circuit could give an inspiration for combining
the analog memristive synapse and leaky integrate-and-fire neuron with digital
control units, prompting their development as edge computing devices.
\\ ( https://arxiv.org/abs/2306.06379 ,  3646kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06440 (*cross-listing*)
Date: Sat, 10 Jun 2023 13:39:30 GMT   (306kb)

Title: Epidemic spreading in wireless sensor networks with node sleep
 scheduling
Authors: Yanqing Wu, Cunlai Pu, Gongxuan Zhang, Lunbo Li, Yongxiang Xia, and
 Chengyi Xia
Categories: cs.NI cs.CR cs.SY eess.SY
Comments: This work has been submitted to the IEEE for possible publication.
 Copyright may be transferred without notice, after which this version may no
 longer be accessible
\\
 Wireless Sensor Networks (WSNs) have become widely used in various fields
like environmental monitoring, smart agriculture, and health care. However,
their extensive usage also introduces significant vulnerabilities to cyber
viruses. Addressing this security issue in WSNs is very challenging due to
their inherent limitations in energy and bandwidth to implement real-time
security measures. To tackle the virus issue, it is crucial to first understand
how it spreads in WSNs. In this brief, we propose a novel epidemic spreading
model for WSNs, integrating the susceptible-infected-susceptible (SIS) epidemic
spreading model and node probabilistic sleep scheduling--a critical mechanism
for optimizing energy efficiency. Using the microscopic Markov chain (MMC)
method, we derive the spreading equations and epidemic threshold of our model.
We conduct numerical simulations to validate the theoretical results and
investigate the impact of key factors on epidemic spreading in WSNs. Notably,
we discover that the epidemic threshold is directly proportional to the ratio
of node sleeping and node activation probabilities.
\\ ( https://arxiv.org/abs/2306.06440 ,  306kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06511 (*cross-listing*)
Date: Sat, 10 Jun 2023 19:15:18 GMT   (384kb,D)

Title: Analysis of Cascading Failures Due to Dynamic Load-Altering Attacks
Authors: Maldon Patrice Goodridge, Alessandro Zocca, and Subhash
 Lakshminarayana
Categories: cs.CR cs.SY eess.SY
\\
 Large-scale load-altering attacks (LAAs) are known to severely disrupt power
grid operations by manipulating several internet-of-things (IoT)-enabled load
devices. In this work, we analyze power grid cascading failures induced by such
attacks. The inherent security features in power grids such as the $N-1$ design
philosophy dictate LAAs that can trigger cascading failures are \emph{rare}
events. We overcome the challenge of efficiently sampling critical LAAs
scenarios for a wide range of attack parameters by using the so-called
``skipping sampler'' algorithm. We conduct extensive simulations using a
three-area IEEE-39 bus system and provide several novel insights into the
composition of cascades due to LAAs. Our results highlight the particular risks
to modern power systems posed by strategically designed coordinated LAAs that
exploit their structural and real-time operating characteristics.
\\ ( https://arxiv.org/abs/2306.06511 ,  384kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07084 (*cross-listing*)
Date: Mon, 12 Jun 2023 12:55:09 GMT   (3746kb,D)

Title: Performance of Graph Database Management Systems as route planning
 solutions for different data and usage characteristics
Authors: Karin Festl, Patrick Promitzer, Daniel Watzenig, Huilin Yin
Categories: cs.DB cs.SY eess.SY
Comments: Submitted to IEEE IAVVC 2023
\\
 Graph databases have grown in popularity in recent years as they are able to
efficiently store and query complex relationships between data. Incidentally,
navigation data and road networks can be processed, sampled or modified
efficiently when stored as a graph. As a result, graph databases are a solution
for solving route planning tasks that comes more and more to the attention of
developers of autonomous vehicles. To achieve a computational performance that
enables the realization of route planning on large road networks or for a great
number of agents concurrently, several aspects need to be considered in the
design of the solution. Based on a concrete use case for centralized route
planning, we discuss the characteristics and properties of a use case that can
significantly influence the computational effort or efficiency of the database
management system. Subsequently we evaluate the performance of both Neo4j and
ArangoDB depending on these properties. With these results, it is not only
possible to choose the most suitable database system but also to improve the
resulting performance by addressing relevant aspects in the design of the
application.
\\ ( https://arxiv.org/abs/2306.07084 ,  3746kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07107 (*cross-listing*)
Date: Mon, 12 Jun 2023 13:34:42 GMT   (1759kb,D)

Title: Towards continuous-time MPC: a novel trajectory optimization algorithm
Authors: Souvik Das, Siddhartha Ganguly, Muthyala Anjali, Debasish Chatterjee
Categories: math.OC cs.SY eess.SY
\\
 This article introduces a numerical algorithm that serves as a preliminary
step toward solving continuous-time model predictive control (MPC) problems
directly without explicit time-discretization. The chief ingredients of the
underlying optimal control problem (OCP) are a linear time-invariant system,
quadratic instantaneous and terminal cost functions, and convex path
constraints. The thrust of the method involves finitely parameterizing the
admissible space of control trajectories and solving the OCP satisfying the
given constraints at every time instant in a tractable manner without explicit
time-discretization. The ensuing OCP turns out to be a convex semi-infinite
program (SIP), and some recently developed results are employed to obtain an
optimal solution to this convex SIP. Numerical illustrations on some benchmark
models are included to show the efficacy of the algorithm.
\\ ( https://arxiv.org/abs/2306.07107 ,  1759kb)
------------------------------------------------------------------------------
\\
arXiv:2306.07139 (*cross-listing*)
Date: Mon, 12 Jun 2023 14:23:15 GMT   (4350kb,D)

Title: An agent-based decentralized threshold policy finding the constrained
 shortest paths
Authors: Francesca Rosset, Raffaele Pesenti, Franco Blanchini
Categories: math.OC cs.SY eess.SY math.DS
Comments: This work has been submitted to the IEEE for possible publication.
 Copyright may be transferred without notice, after which this version may no
 longer be accessible
\\
 We consider a problem where autonomous agents enter a dynamic and unknown
environment described by a network of weighted arcs. These agents move within
the network from node to node according to a decentralized policy using only
local information, with the goal of finding a path to an unknown sink node to
leave the network. This policy makes each agent move to some adjacent node or
stop at the current node. The transition along an arc is allowed or denied
based on a threshold mechanism that takes into account the number of agents
already accumulated in the arc's end nodes and the arc's weight. We show that
this policy ensures path-length optimality in the sense that, in a finite time,
all new agents entering the network reach the closer sinks by the shortest
paths. Our approach is later extended to support constraints on the paths that
agents can follow.
\\ ( https://arxiv.org/abs/2306.07139 ,  4350kb)
%%--%%--%%--%%--%%--%%--%%--%%--%%--%%--%%--%%--%%--%%--%%--%%--%%--%%--%%--%%
------------------------------------------------------------------------------
\\
arXiv:1910.01539
replaced with revised version Mon, 12 Jun 2023 17:02:57 GMT   (510kb,D)

Title: Method for the semantic indexing of concept hierarchies, uniform
 representation, use of relational database systems and generic and case-based
 reasoning
Authors: Uwe Petersohn, Sandra Zimmer, Jens Lehmann
Categories: cs.AI
\\ ( https://arxiv.org/abs/1910.01539 ,  510kb)
------------------------------------------------------------------------------
\\
arXiv:2112.06028
replaced with revised version Sat, 10 Jun 2023 03:13:46 GMT   (606kb,D)

Title: Retrosynthetic Planning with Experience-Guided Monte Carlo Tree Search
Authors: Siqi Hong, Hankz Hankui Zhuo, Kebing Jin, Guang Shao, Zhanwen Zhou
Categories: cs.AI
\\ ( https://arxiv.org/abs/2112.06028 ,  606kb)
------------------------------------------------------------------------------
\\
arXiv:2303.11366
replaced with revised version Sat, 10 Jun 2023 04:32:30 GMT   (396kb,D)

Title: Reflexion: Language Agents with Verbal Reinforcement Learning
Authors: Noah Shinn, Federico Cassano, Beck Labash, Ashwin Gopinath, Karthik
 Narasimhan, Shunyu Yao
Categories: cs.AI cs.CL cs.LG
Comments: v3 contains additional citations
\\ ( https://arxiv.org/abs/2303.11366 ,  396kb)
------------------------------------------------------------------------------
\\
arXiv:2304.07297
replaced with revised version Sat, 10 Jun 2023 20:00:45 GMT   (3692kb,D)

Title: Language Instructed Reinforcement Learning for Human-AI Coordination
Authors: Hengyuan Hu, Dorsa Sadigh
Categories: cs.AI cs.CL cs.LG cs.MA
\\ ( https://arxiv.org/abs/2304.07297 ,  3692kb)
------------------------------------------------------------------------------
\\
arXiv:2304.09349
replaced with revised version Mon, 12 Jun 2023 14:07:42 GMT   (0kb,I)

Title: LLM as A Robotic Brain: Unifying Egocentric Memory and Control
Authors: Jinjie Mai, Jun Chen, Bing Li, Guocheng Qian, Mohamed Elhoseiny,
 Bernard Ghanem
Categories: cs.AI cs.CL cs.RO
Comments: This early project is now integrated to: Mindstorms in Natural
 Language-Based Societies of Mind, arXiv:2305.17066
\\ ( https://arxiv.org/abs/2304.09349 ,  0kb)
------------------------------------------------------------------------------
\\
arXiv:2305.03433
replaced with revised version Mon, 12 Jun 2023 11:53:37 GMT   (1446kb,D)

Title: Towards Applying Powerful Large AI Models in Classroom Teaching:
 Opportunities, Challenges and Prospects
Authors: Kehui Tan, Tianqi Pang, Chenyou Fan and Song Yu
Categories: cs.AI cs.CY
Comments: 16 pages, 2 figures
\\ ( https://arxiv.org/abs/2305.03433 ,  1446kb)
------------------------------------------------------------------------------
\\
arXiv:2305.07722
replaced with revised version Mon, 12 Jun 2023 05:04:28 GMT   (1625kb,D)

Title: In Search of Verifiability: Explanations Rarely Enable Complementary
 Performance in AI-Advised Decision Making
Authors: Raymond Fok, Daniel S. Weld
Categories: cs.AI cs.HC
Comments: 11 pages, 6 figures, 1 table, working paper
\\ ( https://arxiv.org/abs/2305.07722 ,  1625kb)
------------------------------------------------------------------------------
\\
arXiv:2305.10201
replaced with revised version Mon, 12 Jun 2023 15:12:53 GMT   (5150kb)

Title: Echoes of Biases: How Stigmatizing Language Affects AI Performance
Authors: Yizhi Liu, Weiguang Wang, Guodong Gordon Gao, Ritu Agarwal
Categories: cs.AI cs.CY
Comments: 54 pages, 9 figures
\\ ( https://arxiv.org/abs/2305.10201 ,  5150kb)
------------------------------------------------------------------------------
\\
arXiv:2306.00380
replaced with revised version Mon, 12 Jun 2023 06:04:32 GMT   (1837kb)

Title: Survey of Trustworthy AI: A Meta Decision of AI
Authors: Caesar Wu, Yuan-Fang Lib, and Pascal Bouvry
Categories: cs.AI cs.CY
\\ ( https://arxiv.org/abs/2306.00380 ,  1837kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03604
replaced with revised version Sun, 11 Jun 2023 01:04:34 GMT   (905kb,D)

Title: Enabling Intelligent Interactions between an Agent and an LLM: A
 Reinforcement Learning Approach
Authors: Bin Hu, Chenyang Zhao, Pu Zhang, Zihao Zhou, Yuanhang Yang, Zenglin
 Xu, Bin Liu
Categories: cs.AI
Comments: 11 pages
\\ ( https://arxiv.org/abs/2306.03604 ,  905kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04090
replaced with revised version Sat, 10 Jun 2023 03:04:30 GMT   (14932kb,D)

Title: Professional Basketball Player Behavior Synthesis via Planning with
 Diffusion
Authors: Xiusi Chen, Wei-Yao Wang, Ziniu Hu, Curtis Chou, Lam Hoang, Kun Jin,
 Mingyan Liu, P. Jeffrey Brantingham, Wei Wang
Categories: cs.AI cs.MA
\\ ( https://arxiv.org/abs/2306.04090 ,  14932kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04422
replaced with revised version Mon, 12 Jun 2023 14:04:28 GMT   (3322kb,D)

Title: A Gamified Interaction with a Humanoid Robot to explain Therapeutic
 Procedures in Pediatric Asthma
Authors: Laura Montalbano, Agnese Augello, Giovanni Pilato, Stefania La Grutta
Categories: cs.AI cs.HC cs.RO
\\ ( https://arxiv.org/abs/2306.04422 ,  3322kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04440
replaced with revised version Sun, 11 Jun 2023 12:20:49 GMT   (2117kb,D)

Title: Dual policy as self-model for planning
Authors: Jaesung Yoo, Fernanda de la Torre, Guangyu Robert Yang
Categories: cs.AI cs.LG
\\ ( https://arxiv.org/abs/2306.04440 ,  2117kb)
------------------------------------------------------------------------------
\\
arXiv:2007.00112
replaced with revised version Sat, 10 Jun 2023 00:02:28 GMT   (3777kb,D)

Title: Robustness to Transformations Across Categories: Is Robustness To
 Transformations Driven by Invariant Neural Representations?
Authors: Hojin Jang, Syed Suleman Abbas Zaidi, Xavier Boix, Neeraj Prasad,
 Sharon Gilad-Gutnick, Shlomit Ben-Ami, Pawan Sinha
Categories: cs.CV cs.LG
\\ ( https://arxiv.org/abs/2007.00112 ,  3777kb)
------------------------------------------------------------------------------
\\
arXiv:2007.02622
replaced with revised version Mon, 12 Jun 2023 08:40:02 GMT   (2439kb,D)

Title: Integrating Distributed Architectures in Highly Modular RL Libraries
Authors: Albert Bou, Sebastian Dittert and Gianni De Fabritiis
Categories: cs.CV cs.AI cs.LG
Comments: 9 pages, 9 figures
\\ ( https://arxiv.org/abs/2007.02622 ,  2439kb)
------------------------------------------------------------------------------
\\
arXiv:2010.01477
replaced with revised version Mon, 12 Jun 2023 03:28:15 GMT   (2358kb,D)

Title: Generalized Two-Dimensional Quaternion Principal Component Analysis with
 Weighting for Color Image Recognition
Authors: Zhi-Gang Jia, Zi-Jin Qiu, Qian-Yu Wang, Mei-Xiang Zhao, and Dan-Dan
 Zhu
Categories: cs.CV
Comments: 17 pages, 13 figures
\\ ( https://arxiv.org/abs/2010.01477 ,  2358kb)
------------------------------------------------------------------------------
\\
arXiv:2010.12427
replaced with revised version Sat, 10 Jun 2023 05:24:15 GMT   (1608kb,D)

Title: Casting a BAIT for Offline and Online Source-free Domain Adaptation
Authors: Shiqi Yang, Yaxing Wang, Joost van de Weijer, Luis Herranz and
 Shangling Jui
Categories: cs.CV
Comments: Accepted by Computer Vision and Image Understanding
\\ ( https://arxiv.org/abs/2010.12427 ,  1608kb)
------------------------------------------------------------------------------
\\
arXiv:2012.13188
replaced with revised version Fri, 9 Jun 2023 21:49:33 GMT   (1617kb,D)

Title: Control of Computer Pointer Using Hand Gesture Recognition in Motion
 Pictures
Authors: Yalda Foroutan, Ahmad Kalhor, Saeid Mohammadi Nejati, Samad Sheikhaei
Categories: cs.CV cs.HC
Comments: 9 pages, 6 figures, 2 tables
\\ ( https://arxiv.org/abs/2012.13188 ,  1617kb)
------------------------------------------------------------------------------
\\
arXiv:2203.01391
replaced with revised version Mon, 12 Jun 2023 12:05:42 GMT   (32606kb,D)

Title: DDL-MVS: Depth Discontinuity Learning for MVS Networks
Authors: Nail Ibrahimli, Hugo Ledoux, Julian Kooij, Liangliang Nan
Categories: cs.CV cs.LG
\\ ( https://arxiv.org/abs/2203.01391 ,  32606kb)
------------------------------------------------------------------------------
\\
arXiv:2203.01923
replaced with revised version Sat, 10 Jun 2023 10:10:36 GMT   (1807kb,D)

Title: Recovering 3D Human Mesh from Monocular Images: A Survey
Authors: Yating Tian, Hongwen Zhang, Yebin Liu, Limin Wang
Categories: cs.CV cs.GR
Comments: Survey paper on monocular 3D human mesh recovery, Project page:
 https://github.com/tinatiansjz/hmr-survey
\\ ( https://arxiv.org/abs/2203.01923 ,  1807kb)
------------------------------------------------------------------------------
\\
arXiv:2204.03444
replaced with revised version Fri, 9 Jun 2023 10:18:20 GMT   (7870kb,D)

Title: Deep Visual Geo-localization Benchmark
Authors: Gabriele Berton, Riccardo Mereu, Gabriele Trivigno, Carlo Masone,
 Gabriela Csurka, Torsten Sattler, Barbara Caputo
Categories: cs.CV
Comments: CVPR 2022 (Oral)
\\ ( https://arxiv.org/abs/2204.03444 ,  7870kb)
------------------------------------------------------------------------------
\\
arXiv:2206.03591
replaced with revised version Fri, 9 Jun 2023 20:18:14 GMT   (21561kb,D)

Title: ObPose: Leveraging Pose for Object-Centric Scene Inference and
 Generation in 3D
Authors: Yizhe Wu, Oiwi Parker Jones, Ingmar Posner
Categories: cs.CV cs.AI
Comments: 14 pages, 4 figures
MSC-class: 68T07
\\ ( https://arxiv.org/abs/2206.03591 ,  21561kb)
------------------------------------------------------------------------------
\\
arXiv:2206.15462
replaced with revised version Mon, 12 Jun 2023 17:59:37 GMT   (5233kb,D)

Title: Improving Visual Grounding by Encouraging Consistent Gradient-based
 Explanations
Authors: Ziyan Yang, Kushal Kafle, Franck Dernoncourt, Vicente Ordonez
Categories: cs.CV cs.CL cs.LG
Comments: CVPR 2023. Code: https://github.com/uvavision/AMC-grounding Project
 Webpage: https://vislang.ai/amc
\\ ( https://arxiv.org/abs/2206.15462 ,  5233kb)
------------------------------------------------------------------------------
\\
arXiv:2207.02621
replaced with revised version Sun, 11 Jun 2023 18:40:36 GMT   (6473kb,D)

Title: VMRF: View Matching Neural Radiance Fields
Authors: Jiahui Zhang and Fangneng Zhan and Rongliang Wu and Yingchen Yu and
 Wenqing Zhang and Bai Song and Xiaoqin Zhang and Shijian Lu
Categories: cs.CV
Comments: This paper has been accepted to ACM MM 2022
\\ ( https://arxiv.org/abs/2207.02621 ,  6473kb)
------------------------------------------------------------------------------
\\
arXiv:2209.11359
replaced with revised version Fri, 9 Jun 2023 19:07:50 GMT   (21942kb,D)

Title: CUTS: A Fully Unsupervised Framework for Medical Image Segmentation
Authors: Chen Liu, Matthew Amodio, Liangbo L. Shen, Feng Gao, Arman Avesta,
 Sanjay Aneja, Jay Wang, Lucian V. Del Priore, Smita Krishnaswamy
Categories: cs.CV
Comments: Updated Table 1. Rerun supervised and STEGO after unified codebase.
 Correct bug in multi-class dice and hausdorff
\\ ( https://arxiv.org/abs/2209.11359 ,  21942kb)
------------------------------------------------------------------------------
\\
arXiv:2210.04671
replaced with revised version Sat, 10 Jun 2023 06:11:31 GMT   (2584kb,D)

Title: TCDM: Transformational Complexity Based Distortion Metric for Perceptual
 Point Cloud Quality Assessment
Authors: Yujie Zhang, Qi Yang, Yifei Zhou, Xiaozhong Xu, Le Yang, Yiling Xu
Categories: cs.CV cs.MM
\\ ( https://arxiv.org/abs/2210.04671 ,  2584kb)
------------------------------------------------------------------------------
\\
arXiv:2211.09146
replaced with revised version Mon, 12 Jun 2023 08:47:22 GMT   (5918kb,D)

Title: A Unified Multimodal De- and Re-coupling Framework for RGB-D Motion
 Recognition
Authors: Benjia Zhou, Pichao Wang, Jun Wan, Yanyan Liang and Fan Wang
Categories: cs.CV cs.MM
Comments: Accepted to TPAMI 2023
\\ ( https://arxiv.org/abs/2211.09146 ,  5918kb)
------------------------------------------------------------------------------
\\
arXiv:2211.10526
replaced with revised version Mon, 12 Jun 2023 16:11:55 GMT   (2274kb,D)

Title: Castling-ViT: Compressing Self-Attention via Switching Towards
 Linear-Angular Attention at Vision Transformer Inference
Authors: Haoran You, Yunyang Xiong, Xiaoliang Dai, Bichen Wu, Peizhao Zhang,
 Haoqi Fan, Peter Vajda, Yingyan (Celine) Lin
Categories: cs.CV
Comments: CVPR 2023 Camera Ready
\\ ( https://arxiv.org/abs/2211.10526 ,  2274kb)
------------------------------------------------------------------------------
\\
arXiv:2211.11679
replaced with revised version Mon, 12 Jun 2023 17:05:45 GMT   (6057kb,AD)

Title: Mean Shift Mask Transformer for Unseen Object Instance Segmentation
Authors: Yangxiao Lu, Yuqiao Chen, Nicholas Ruozzi, Yu Xiang
Categories: cs.CV cs.AI cs.LG cs.RO
Comments: add RGB cases
\\ ( https://arxiv.org/abs/2211.11679 ,  6057kb)
------------------------------------------------------------------------------
\\
arXiv:2212.03063
replaced with revised version Sat, 10 Jun 2023 12:01:04 GMT   (9010kb,D)

Title: Causal Inference via Style Transfer for Out-of-distribution
 Generalisation
Authors: Toan Nguyen, Kien Do, Duc Thanh Nguyen, Bao Duong, Thin Nguyen
Categories: cs.CV cs.AI
Comments: In Proceedings of the 29th ACM SIGKDD Conference on Knowledge
 Discovery and Data Mining (KDD 23), August 6-10, 2023, Long Beach, CA, USA.
 ACM, New York, NY, USA, 19 pages
DOI: 10.1145/3580305.3599270
\\ ( https://arxiv.org/abs/2212.03063 ,  9010kb)
------------------------------------------------------------------------------
\\
arXiv:2212.03145
replaced with revised version Sat, 10 Jun 2023 08:20:10 GMT   (259kb,D)

Title: FacT: Factor-Tuning for Lightweight Adaptation on Vision Transformer
Authors: Shibo Jie, Zhi-Hong Deng
Categories: cs.CV
Comments: AAAI 2023 Oral. Code: https://github.com/JieShibo/PETL-ViT
\\ ( https://arxiv.org/abs/2212.03145 ,  259kb)
------------------------------------------------------------------------------
\\
arXiv:2212.05332
replaced with revised version Sun, 11 Jun 2023 20:29:27 GMT   (20426kb,D)

Title: An approach to robust ICP initialization
Authors: Alexander Kolpakov, Michael Werman
Categories: cs.CV cs.CG math.OC
Comments: 9 pages, 18 figures; GitHub repository at
 (https://github.com/sashakolpakov/icp-init)
\\ ( https://arxiv.org/abs/2212.05332 ,  20426kb)
------------------------------------------------------------------------------
\\
arXiv:2212.11595
replaced with revised version Mon, 12 Jun 2023 09:21:03 GMT   (3725kb,D)

Title: Metadata-guided Consistency Learning for High Content Images
Authors: Johan Fredin Haslum and Christos Matsoukas and Karl-Johan Leuchowius
 and Erik M\"ullers and Kevin Smith
Categories: cs.CV
\\ ( https://arxiv.org/abs/2212.11595 ,  3725kb)
------------------------------------------------------------------------------
\\
arXiv:2301.01081
replaced with revised version Sat, 10 Jun 2023 14:37:49 GMT   (4401kb,D)

Title: StyleTalk: One-shot Talking Head Generation with Controllable Speaking
 Styles
Authors: Yifeng Ma, Suzhen Wang, Zhipeng Hu, Changjie Fan, Tangjie Lv, Yu Ding,
 Zhidong Deng and Xin Yu
Categories: cs.CV
Comments: Accepted at AAAI2023 as Oral. Demo: https://youtu.be/mO2Tjcwr4u8
\\ ( https://arxiv.org/abs/2301.01081 ,  4401kb)
------------------------------------------------------------------------------
\\
arXiv:2301.03426
replaced with revised version Mon, 12 Jun 2023 07:18:39 GMT   (9142kb,D)

Title: LTS-NET: End-to-end Unsupervised Learning of Long-Term 3D Stable objects
Authors: Ibrahim Hroob, Sergi Molina, Riccardo Polvara, Grzegorz Cielniak and
 Marc Hanheide
Categories: cs.CV cs.RO
\\ ( https://arxiv.org/abs/2301.03426 ,  9142kb)
------------------------------------------------------------------------------
\\
arXiv:2301.05211
replaced with revised version Sat, 10 Jun 2023 21:01:56 GMT   (16165kb,D)

Title: Accidental Light Probes
Authors: Hong-Xing Yu, Samir Agarwala, Charles Herrmann, Richard Szeliski, Noah
 Snavely, Jiajun Wu, Deqing Sun
Categories: cs.CV cs.GR
Comments: CVPR2023. Project website: https://kovenyu.com/ALP/
\\ ( https://arxiv.org/abs/2301.05211 ,  16165kb)
------------------------------------------------------------------------------
\\
arXiv:2301.08874
replaced with revised version Mon, 12 Jun 2023 08:33:45 GMT   (759kb,D)

Title: Improving Zero-Shot Action Recognition using Human Instruction with Text
 Description
Authors: Nan Wu, Hiroshi Kera, Kazuhiko Kawamoto
Categories: cs.CV
Comments: 18 pages, 9 figures
\\ ( https://arxiv.org/abs/2301.08874 ,  759kb)
------------------------------------------------------------------------------
\\
arXiv:2301.09060
replaced with revised version Fri, 9 Jun 2023 18:26:58 GMT   (1967kb)

Title: 3D Reconstruction of Non-cooperative Resident Space Objects using
 Instant NGP-accelerated NeRF and D-NeRF
Authors: Basilio Caruso and Trupti Mahendrakar and Van Minh Nguyen and Ryan T.
 White and Todd Steffen
Categories: cs.CV
Comments: Presented at AAS/AIAA Spaceflight Mechanics Conference 2023, 14
 pages, 10 figures, 2 tables
\\ ( https://arxiv.org/abs/2301.09060 ,  1967kb)
------------------------------------------------------------------------------
\\
arXiv:2301.10900
replaced with revised version Sat, 10 Jun 2023 10:32:06 GMT   (11721kb,D)

Title: Graph Contrastive Learning for Skeleton-based Action Recognition
Authors: Xiaohu Huang, Hao Zhou, Jian Wang, Haocheng Feng, Junyu Han, Errui
 Ding, Jingdong Wang, Xinggang Wang, Wenyu Liu, Bin Feng
Categories: cs.CV
Comments: Accepted by ICLR2023
\\ ( https://arxiv.org/abs/2301.10900 ,  11721kb)
------------------------------------------------------------------------------
\\
arXiv:2301.12972
replaced with revised version Mon, 12 Jun 2023 16:54:05 GMT   (1110kb,D)

Title: Human Vision Based 3D Point Cloud Semantic Segmentation of Large-Scale
 Outdoor Scene
Authors: Sunghwan Yoo, Yeongjeong Jeong, Maryam Jameela, Gunho Sohn
Categories: cs.CV
\\ ( https://arxiv.org/abs/2301.12972 ,  1110kb)
------------------------------------------------------------------------------
\\
arXiv:2302.00573
replaced with revised version Mon, 12 Jun 2023 12:21:34 GMT   (11044kb,D)

Title: An automated, geometry-based method for hippocampal shape and thickness
 analysis
Authors: Kersten Diers and Hannah Baumeister and Frank Jessen and Emrah D\"uzel
 and David Berron and Martin Reuter
Categories: cs.CV cs.CG
Comments: Updated to journal publication
Journal-ref: Neuroimage 276 (2023) 120182
DOI: 10.1016/j.neuroimage.2023.120182
\\ ( https://arxiv.org/abs/2302.00573 ,  11044kb)
------------------------------------------------------------------------------
\\
arXiv:2302.09119
replaced with revised version Fri, 9 Jun 2023 20:27:16 GMT   (7800kb,D)

Title: A Review on Generative Adversarial Networks for Data Augmentation in
 Person Re-Identification Systems
Authors: Victor Uc-Cetina, Laura Alvarez-Gonzalez, Anabel Martin-Gonzalez
Categories: cs.CV cs.AI
\\ ( https://arxiv.org/abs/2302.09119 ,  7800kb)
------------------------------------------------------------------------------
\\
arXiv:2303.05470
replaced with revised version Mon, 12 Jun 2023 14:04:53 GMT   (2810kb,D)

Title: Spawrious: A Benchmark for Fine Control of Spurious Correlation Biases
Authors: Aengus Lynch, Gb\`etondji J-S Dovonon, Jean Kaddour, Ricardo Silva
Categories: cs.CV cs.LG
\\ ( https://arxiv.org/abs/2303.05470 ,  2810kb)
------------------------------------------------------------------------------
\\
arXiv:2303.11831
replaced with revised version Mon, 12 Jun 2023 17:14:08 GMT   (7330kb,D)

Title: CLADE: Cycle Loss Augmented Degradation Enhancement for Unpaired
 Super-Resolution of Anisotropic Medical Images
Authors: Michele Pascale, Vivek Muthurangu, Javier Montalt Tordera, Heather E
 Fitzke, Gauraang Bhatnagar, Stuart Taylor, Jennifer Steeden
Categories: cs.CV cs.LG eess.IV physics.med-ph
\\ ( https://arxiv.org/abs/2303.11831 ,  7330kb)
------------------------------------------------------------------------------
\\
arXiv:2303.12865
replaced with revised version Mon, 12 Jun 2023 16:42:57 GMT   (14940kb,D)

Title: NeRF-GAN Distillation for Memory-Efficient 3D-Aware Generation with
 Convolutions
Authors: Mohamad Shahbazi, Evangelos Ntavelis, Alessio Tonioni, Edo Collins,
 Danda Pani Paudel, Martin Danelljan, Luc Van Gool
Categories: cs.CV cs.GR cs.LG
\\ ( https://arxiv.org/abs/2303.12865 ,  14940kb)
------------------------------------------------------------------------------
\\
arXiv:2303.14115
replaced with revised version Mon, 12 Jun 2023 11:54:25 GMT   (2060kb,D)

Title: Principles of Forgetting in Domain-Incremental Semantic Segmentation in
 Adverse Weather Conditions
Authors: Tobias Kalb, J\"urgen Beyerer
Categories: cs.CV
Comments: Accepted at IEEE/CVF Conference on Computer Vision and Pattern
 Recognition 2023
\\ ( https://arxiv.org/abs/2303.14115 ,  2060kb)
------------------------------------------------------------------------------
\\
arXiv:2304.05538
replaced with revised version Sat, 10 Jun 2023 11:12:57 GMT   (27280kb,D)

Title: ImageNet-Hard: The Hardest Images Remaining from a Study of the Power of
 Zoom and Spatial Biases in Image Classification
Authors: Mohammad Reza Taesiri, Giang Nguyen, Sarra Habchi, Cor-Paul Bezemer,
 Anh Nguyen
Categories: cs.CV
\\ ( https://arxiv.org/abs/2304.05538 ,  27280kb)
------------------------------------------------------------------------------
\\
arXiv:2304.06939
replaced with revised version Fri, 9 Jun 2023 21:49:58 GMT   (2494kb,D)

Title: Multimodal C4: An Open, Billion-scale Corpus of Images Interleaved with
 Text
Authors: Wanrong Zhu and Jack Hessel and Anas Awadalla and Samir Yitzhak Gadre
 and Jesse Dodge and Alex Fang and Youngjae Yu and Ludwig Schmidt and William
 Yang Wang and Yejin Choi
Categories: cs.CV cs.CL
Comments: Project homepage: https://github.com/allenai/mmc4
\\ ( https://arxiv.org/abs/2304.06939 ,  2494kb)
------------------------------------------------------------------------------
\\
arXiv:2304.10440
replaced with revised version Sat, 10 Jun 2023 17:22:09 GMT   (5983kb,D)

Title: OpenLane-V2: A Topology Reasoning Benchmark for Scene Understanding in
 Autonomous Driving
Authors: Huijie Wang, Tianyu Li, Yang Li, Li Chen, Chonghao Sima, Zhenbo Liu,
 Yuting Wang, Shengyin Jiang, Peijin Jia, Bangjun Wang, Feng Wen, Hang Xu,
 Ping Luo, Junchi Yan, Wei Zhang, Hongyang Li
Categories: cs.CV
Comments: OpenLane-V2 dataset: https://github.com/OpenDriveLab/OpenLane-V2
\\ ( https://arxiv.org/abs/2304.10440 ,  5983kb)
------------------------------------------------------------------------------
\\
arXiv:2304.13995
replaced with revised version Mon, 12 Jun 2023 13:33:16 GMT   (4218kb,D)

Title: Rotation and Translation Invariant Representation Learning with Implicit
 Neural Representations
Authors: Sehyun Kwon, Joo Young Choi, Ernest K. Ryu
Categories: cs.CV cs.AI
\\ ( https://arxiv.org/abs/2304.13995 ,  4218kb)
------------------------------------------------------------------------------
\\
arXiv:2304.14837
replaced with revised version Sun, 11 Jun 2023 16:31:39 GMT   (14047kb,D)

Title: IMP: Iterative Matching and Pose Estimation with Adaptive Pooling
Authors: Fei Xue and Ignas Budvytis and Roberto Cipolla
Categories: cs.CV
Comments: CVPR 2023. code available at https://github.com/feixue94/imp-release
\\ ( https://arxiv.org/abs/2304.14837 ,  14047kb)
------------------------------------------------------------------------------
\\
arXiv:2304.14845
replaced with revised version Sun, 11 Jun 2023 16:35:08 GMT   (26989kb,D)

Title: SFD2: Semantic-guided Feature Detection and Description
Authors: Fei Xue and Ignas Budvytis and Roberto Cipolla
Categories: cs.CV
Comments: CVPR 2023. code is available at https://github.com/feixue94/sfd2
\\ ( https://arxiv.org/abs/2304.14845 ,  26989kb)
------------------------------------------------------------------------------
\\
arXiv:2305.06710
replaced with revised version Sun, 11 Jun 2023 03:44:53 GMT   (21715kb,D)

Title: Null-text Guidance in Diffusion Models is Secretly a Cartoon-style
 Creator
Authors: Jing Zhao, Heliang Zheng, Chaoyue Wang, Long Lan, Wanrong Huang,
 Wenjing Yang
Categories: cs.CV cs.AI
Comments: Project homepage:https://nulltextforcartoon.github.io/
\\ ( https://arxiv.org/abs/2305.06710 ,  21715kb)
------------------------------------------------------------------------------
\\
arXiv:2305.08265
replaced with revised version Sat, 10 Jun 2023 14:19:00 GMT   (431kb,D)

Title: Vehicle Detection and Classification without Residual Calculation:
 Accelerating HEVC Image Decoding with Random Perturbation Injection
Authors: Muhammet Sebul Berato\u{g}lu and Beh\c{c}et U\u{g}ur T\"oreyin
Categories: cs.CV cs.LG
Comments: 10 pages 4 figures
MSC-class: 68T20
ACM-class: E.4; I.4.5; H.3.3; I.5.4
\\ ( https://arxiv.org/abs/2305.08265 ,  431kb)
------------------------------------------------------------------------------
\\
arXiv:2305.10874
replaced with revised version Mon, 12 Jun 2023 10:37:50 GMT   (787kb,D)

Title: VideoFactory: Swap Attention in Spatiotemporal Diffusions for
 Text-to-Video Generation
Authors: Wenjing Wang, Huan Yang, Zixi Tuo, Huiguo He, Junchen Zhu, Jianlong
 Fu, Jiaying Liu
Categories: cs.CV
\\ ( https://arxiv.org/abs/2305.10874 ,  787kb)
------------------------------------------------------------------------------
\\
arXiv:2305.16649
replaced with revised version Mon, 12 Jun 2023 02:27:54 GMT   (1763kb,D)

Title: FSD: Fully-Specialized Detector via Neural Architecture Search
Authors: Zhe Huang and Yudian Li
Categories: cs.CV
\\ ( https://arxiv.org/abs/2305.16649 ,  1763kb)
------------------------------------------------------------------------------
\\
arXiv:2305.17303
replaced with revised version Sat, 10 Jun 2023 06:34:11 GMT   (6457kb,D)

Title: Distilling BlackBox to Interpretable models for Efficient Transfer
 Learning
Authors: Shantanu Ghosh, Ke Yu, Kayhan Batmanghelich
Categories: cs.CV cs.LG
Comments: MICCAI, 2023, Early accept
\\ ( https://arxiv.org/abs/2305.17303 ,  6457kb)
------------------------------------------------------------------------------
\\
arXiv:2305.20055
replaced with revised version Sun, 11 Jun 2023 12:10:08 GMT   (19675kb,D)

Title: Cross-Domain Car Detection Model with Integrated Convolutional Block
 Attention Mechanism
Authors: Haoxuan Xu, Songning Lai, Xianyang Li, Yang Yang
Categories: cs.CV
\\ ( https://arxiv.org/abs/2305.20055 ,  19675kb)
------------------------------------------------------------------------------
\\
arXiv:2306.00986
replaced with revised version Sun, 11 Jun 2023 23:36:38 GMT   (27313kb,D)

Title: Diffusion Self-Guidance for Controllable Image Generation
Authors: Dave Epstein, Allan Jabri, Ben Poole, Alexei A. Efros, Aleksander
 Holynski
Categories: cs.CV cs.LG stat.ML
Comments: Project page at https://dave.ml/selfguidance/
\\ ( https://arxiv.org/abs/2306.00986 ,  27313kb)
------------------------------------------------------------------------------
\\
arXiv:2306.01272
replaced with revised version Sun, 11 Jun 2023 03:08:24 GMT   (35813kb,D)

Title: DeepfakeArt Challenge: A Benchmark Dataset for Generative AI Art Forgery
 and Data Poisoning Detection
Authors: Hossein Aboutalebi, Dayou Mao, Carol Xu, Alexander Wong
Categories: cs.CV cs.CR cs.LG
\\ ( https://arxiv.org/abs/2306.01272 ,  35813kb)
------------------------------------------------------------------------------
\\
arXiv:2306.01293
replaced with revised version Sat, 10 Jun 2023 07:31:29 GMT   (710kb,D)

Title: LoCoOp: Few-Shot Out-of-Distribution Detection via Prompt Learning
Authors: Atsuyuki Miyai, Qing Yu, Go Irie, Kiyoharu Aizawa
Categories: cs.CV
Comments: v2: minor modification (i.e., I removed tex commands from the arXiv
 abstract)
\\ ( https://arxiv.org/abs/2306.01293 ,  710kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02080
replaced with revised version Sun, 11 Jun 2023 13:00:15 GMT   (7961kb,D)

Title: Benchmarking Robustness of Adaptation Methods on Pre-trained
 Vision-Language Models
Authors: Shuo Chen, Jindong Gu, Zhen Han, Yunpu Ma, Philip Torr, Volker Tresp
Categories: cs.CV cs.CL cs.LG
Comments: 9 pages, 5 figures
\\ ( https://arxiv.org/abs/2306.02080 ,  7961kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02395
replaced with revised version Sat, 10 Jun 2023 06:13:54 GMT   (0kb,I)

Title: NICE-SLAM with Adaptive Feature Grids
Authors: Ganlin Zhang, Deheng Zhang, Feichi Lu, Anqi Li
Categories: cs.CV cs.GR
Comments: This is a course project, not suitable for a preprint platform
\\ ( https://arxiv.org/abs/2306.02395 ,  0kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02517
replaced with revised version Mon, 12 Jun 2023 08:38:29 GMT   (14506kb,D)

Title: Disaster Anomaly Detector via Deeper FCDDs for Explainable Initial
 Responses
Authors: Takato Yasuno, Masahiro Okano and Junichiro Fujii
Categories: cs.CV
Comments: 10 pages, 10 figures, 8 tables
ACM-class: I.2.10; I.4.9; I.5.4
\\ ( https://arxiv.org/abs/2306.02517 ,  14506kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02548
replaced with revised version Mon, 12 Jun 2023 09:28:07 GMT   (7608kb,D)

Title: Inflated 3D Convolution-Transformer for Weakly-supervised Carotid
 Stenosis Grading with Ultrasound Videos
Authors: Xinrui Zhou, Yuhao Huang, Wufeng Xue, Xin Yang, Yuxin Zou, Qilong
 Ying, Yuanji Zhang, Jia Liu, Jie Ren, Dong Ni
Categories: cs.CV
Comments: Accepted by MICCAI 2023
\\ ( https://arxiv.org/abs/2306.02548 ,  7608kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03374
replaced with revised version Mon, 12 Jun 2023 09:37:36 GMT   (17710kb,D)

Title: PGformer: Proxy-Bridged Game Transformer for Multi-Person Extremely
 Interactive Motion Prediction
Authors: Yanwen Fang, Chao Li, Jintai Chen, Peng-Tao Jiang, Yifeng Geng,
 Xuansong Xie, Eddy K. F. Lam, Guodong Li
Categories: cs.CV
\\ ( https://arxiv.org/abs/2306.03374 ,  17710kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03538
replaced with revised version Sat, 10 Jun 2023 15:31:04 GMT   (1647kb)

Title: SDR-GAIN: A High Real-Time Occluded Pedestrian Pose Completion Method
 for Autonomous Driving
Authors: Honghao Fu, Libo Sun
Categories: cs.CV cs.AI
\\ ( https://arxiv.org/abs/2306.03538 ,  1647kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04166
replaced with revised version Fri, 9 Jun 2023 18:10:26 GMT   (6558kb,D)

Title: BAA-NGP: Bundle-Adjusting Accelerated Neural Graphics Primitives
Authors: Sainan Liu, Shan Lin, Jingpei Lu, Shreya Saha, Alexey Supikov, Michael
 Yip
Categories: cs.CV
\\ ( https://arxiv.org/abs/2306.04166 ,  6558kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04717
replaced with revised version Mon, 12 Jun 2023 16:42:59 GMT   (13860kb,D)

Title: AGIQA-3K: An Open Database for AI-Generated Image Quality Assessment
Authors: Chunyi Li, Zicheng Zhang, Haoning Wu, Wei Sun, Xiongkuo Min, Xiaohong
 Liu, Guangtao Zhai, Weisi Lin
Categories: cs.CV cs.AI eess.IV
Comments: 12 pages, 11 figures
\\ ( https://arxiv.org/abs/2306.04717 ,  13860kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05382
replaced with revised version Sun, 11 Jun 2023 14:38:54 GMT   (7150kb,D)

Title: Automatic Image Blending Algorithm Based on SAM and DINO
Authors: Haochen Xue, Mingyu Jin, Chong Zhang, Yuxuan Huang, Qian Weng, Xiaobo
 Jin
Categories: cs.CV
Comments: 15 pages, 9 figure
\\ ( https://arxiv.org/abs/2306.05382 ,  7150kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05749
replaced with revised version Mon, 12 Jun 2023 04:03:23 GMT   (37251kb,D)

Title: DocAligner: Annotating Real-world Photographic Document Images by Simply
 Taking Pictures
Authors: Jiaxin Zhang, Bangdong Chen, Hiuyi Cheng, Fengjun Guo, Kai Ding,
 Lianwen Jin
Categories: cs.CV
\\ ( https://arxiv.org/abs/2306.05749 ,  37251kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05772
replaced with revised version Mon, 12 Jun 2023 05:18:34 GMT   (207kb,D)

Title: A Boosted Model Ensembling Approach to Ball Action Spotting in Videos:
 The Runner-Up Solution to CVPR'23 SoccerNet Challenge
Authors: Luping Wang, Hao Guo, Bin Liu
Categories: cs.CV
Comments: 4 pages
\\ ( https://arxiv.org/abs/2306.05772 ,  207kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05872
replaced with revised version Mon, 12 Jun 2023 10:31:38 GMT   (29538kb,D)

Title: Neural Haircut: Prior-Guided Strand-Based Hair Reconstruction
Authors: Vanessa Sklyarova, Jenya Chelishev, Andreea Dogaru, Igor Medvedev,
 Victor Lempitsky, Egor Zakharov
Categories: cs.CV cs.GR
\\ ( https://arxiv.org/abs/2306.05872 ,  29538kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06062
replaced with revised version Mon, 12 Jun 2023 00:37:58 GMT   (1816kb,D)

Title: Neural FIM for learning Fisher Information Metrics from point cloud data
Authors: Oluwadamilola Fasina, Guillaume Huguet, Alexander Tong, Yanlei Zhang,
 Guy Wolf, Maximilian Nickel, Ian Adelstein, Smita Krishnaswamy
Categories: cs.CV cs.LG
Comments: 13 pages, 11 figures, 1 table
\\ ( https://arxiv.org/abs/2306.06062 ,  1816kb)
------------------------------------------------------------------------------
\\
arXiv:2003.09895
replaced with revised version Mon, 12 Jun 2023 01:04:03 GMT   (59kb)

Title: The Local Information Cost of Distributed Graph Problems
Authors: Peter Robinson
Categories: cs.DC cs.DS
Comments: A preliminary version of this paper appeared in the proceedings of
 SODA 2021
\\ ( https://arxiv.org/abs/2003.09895 ,  59kb)
------------------------------------------------------------------------------
\\
arXiv:2205.10034
replaced with revised version Mon, 12 Jun 2023 12:07:22 GMT   (465kb,D)

Title: SE-MoE: A Scalable and Efficient Mixture-of-Experts Distributed Training
 and Inference System
Authors: Liang Shen, Zhihua Wu, WeiBao Gong, Hongxiang Hao, Yangfan Bai,
 HuaChao Wu, Xinxuan Wu, Jiang Bian, Haoyi Xiong, Dianhai Yu, Yanjun Ma
Categories: cs.DC cs.AI
\\ ( https://arxiv.org/abs/2205.10034 ,  465kb)
------------------------------------------------------------------------------
\\
arXiv:2210.02638
replaced with revised version Mon, 12 Jun 2023 00:19:07 GMT   (11kb)

Title: What Can We Compute in a Single Round of the Congested Clique?
Authors: Peter Robinson
Categories: cs.DC cs.DS
\\ ( https://arxiv.org/abs/2210.02638 ,  11kb)
------------------------------------------------------------------------------
\\
arXiv:2210.08376
replaced with revised version Sun, 11 Jun 2023 21:10:25 GMT   (5042kb,D)

Title: Variant Parallelism: Lightweight Deep Convolutional Models for
 Distributed Inference on IoT Devices
Authors: Navidreza Asadi, Maziar Goudarzi
Categories: cs.DC cs.CV
Comments: 8 pages, 6 figures, 7 tables
\\ ( https://arxiv.org/abs/2210.08376 ,  5042kb)
------------------------------------------------------------------------------
\\
arXiv:2301.08235
replaced with revised version Mon, 12 Jun 2023 01:20:53 GMT   (40kb)

Title: Improved Tradeoffs for Leader Election
Authors: Shay Kutten, Peter Robinson, Ming Ming Tan, Xianbin Zhu
Categories: cs.DC cs.DS
\\ ( https://arxiv.org/abs/2301.08235 ,  40kb)
------------------------------------------------------------------------------
\\
arXiv:2305.16588
replaced with revised version Mon, 12 Jun 2023 08:25:09 GMT   (7825kb,D)

Title: Legion: Automatically Pushing the Envelope of Multi-GPU System for
 Billion-Scale GNN Training
Authors: Jie Sun, Li Su, Zuocheng Shi, Wenting Shen, Zeke Wang, Lei Wang, Jie
 Zhang, Yong Li, Wenyuan Yu, Jingren Zhou, Fei Wu
Categories: cs.DC
\\ ( https://arxiv.org/abs/2305.16588 ,  7825kb)
------------------------------------------------------------------------------
\\
arXiv:2107.04685
replaced with revised version Sun, 11 Jun 2023 14:01:18 GMT   (69kb,D)

Title: Parameterized Complexity of Multi-winner Determination: More Effort
 Towards Fixed-Parameter Tractability
Authors: Yongjie Yang and Jianxin Wang
Categories: cs.GT cs.MA
Comments: 30 pages, 2 figures, extended abstract appeared in the Proceedings of
 AAMAS 2018
\\ ( https://arxiv.org/abs/2107.04685 ,  69kb)
------------------------------------------------------------------------------
\\
arXiv:2206.10660
replaced with revised version Mon, 12 Jun 2023 14:35:48 GMT   (7395kb,D)

Title: Welfare-Maximizing Pooled Testing
Authors: Simon Finster and Michelle Gonz\'alez Amador and Edwin Lock and
 Francisco Marmolejo-Coss\'io and Evi Micha and Ariel D. Procaccia
Categories: cs.GT
Comments: Accepted at EC'23. (Exemplary track paper award)
\\ ( https://arxiv.org/abs/2206.10660 ,  7395kb)
------------------------------------------------------------------------------
\\
arXiv:2302.02873
replaced with revised version Mon, 12 Jun 2023 16:35:26 GMT   (472kb)

Title: Online Mechanism Design for Information Acquisition
Authors: Federico Cacciamani, Matteo Castiglioni, Nicola Gatti
Categories: cs.GT
\\ ( https://arxiv.org/abs/2302.02873 ,  472kb)
------------------------------------------------------------------------------
\\
arXiv:2304.06842
replaced with revised version Fri, 9 Jun 2023 20:46:22 GMT   (3349kb,D)

Title: Multiagent Incentive Design for Dynamic Task Delegation with Off-Menu
 Actions
Authors: Tao Zhang, Quanyan Zhu
Categories: cs.GT cs.MA
\\ ( https://arxiv.org/abs/2304.06842 ,  3349kb)
------------------------------------------------------------------------------
\\
arXiv:2304.13417
replaced with revised version Mon, 12 Jun 2023 14:31:09 GMT   (184kb,D)

Title: With a little help from your friends: semi-cooperative games via Joker
 moves
Authors: Petra van den Bos and Marielle Stoelinga
Categories: cs.GT
Comments: Extended version with appendix
\\ ( https://arxiv.org/abs/2304.13417 ,  184kb)
------------------------------------------------------------------------------
\\
arXiv:1908.10705
replaced with revised version Sun, 11 Jun 2023 23:27:05 GMT   (266kb)

Title: Improving a State-of-the-Art Heuristic for the Minimum Latency Problem
 with Data Mining
Authors: \'Italo Santana, Alexandre Plastino, Isabel Rosseti
Categories: cs.LG cs.AI stat.ML
\\ ( https://arxiv.org/abs/1908.10705 ,  266kb)
------------------------------------------------------------------------------
\\
arXiv:2110.03301
replaced with revised version Sun, 11 Jun 2023 06:54:56 GMT   (2933kb,D)

Title: EvadeDroid: A Practical Evasion Attack on Machine Learning for Black-box
 Android Malware Detection
Authors: Hamid Bostani and Veelasha Moonsamy
Categories: cs.LG cs.CR
\\ ( https://arxiv.org/abs/2110.03301 ,  2933kb)
------------------------------------------------------------------------------
\\
arXiv:2110.06917
replaced with revised version Sat, 10 Jun 2023 18:36:51 GMT   (2534kb,D)

Title: Extracting Dynamical Models from Data
Authors: Michael F. Zimmer
Categories: cs.LG
Comments: 17 pages, 16 figures
\\ ( https://arxiv.org/abs/2110.06917 ,  2534kb)
------------------------------------------------------------------------------
\\
arXiv:2111.03892
replaced with revised version Mon, 12 Jun 2023 12:39:37 GMT   (344kb,D)

Title: Efficient Multi-objective Neural Architecture Search Framework via
 Policy Gradient Algorithm
Authors: Bo Lyu, Shiping Wen
Categories: cs.LG cs.AI
\\ ( https://arxiv.org/abs/2111.03892 ,  344kb)
------------------------------------------------------------------------------
\\
arXiv:2112.11217
replaced with revised version Mon, 12 Jun 2023 08:54:17 GMT   (14413kb,D)

Title: Model-Based Safe Reinforcement Learning with Time-Varying State and
 Control Constraints: An Application to Intelligent Vehicles
Authors: Xinglong Zhang, Yaoqian Peng, Biao Luo, Wei Pan, Xin Xu, and Haibin
 Xie
Categories: cs.LG cs.AI
Comments: 16 pages, 11 figures
\\ ( https://arxiv.org/abs/2112.11217 ,  14413kb)
------------------------------------------------------------------------------
\\
arXiv:2201.09562
replaced with revised version Mon, 12 Jun 2023 12:20:59 GMT   (6447kb,D)

Title: GoSafeOpt: Scalable Safe Exploration for Global Optimization of
 Dynamical Systems
Authors: Bhavya Sukhija, Matteo Turchetta, David Lindner, Andreas Krause,
 Sebastian Trimpe, Dominik Baumann
Categories: cs.LG cs.SY eess.SY
Journal-ref: Artificial Intelligence, Volume 320, Year 2023
DOI: 10.1016/j.artint.2023.103922
\\ ( https://arxiv.org/abs/2201.09562 ,  6447kb)
------------------------------------------------------------------------------
\\
arXiv:2202.11046
replaced with revised version Sun, 11 Jun 2023 12:08:43 GMT   (101kb,D)

Title: A policy gradient approach for optimization of smooth risk measures
Authors: Nithia Vijayan and Prashanth L.A
Categories: cs.LG
Comments: arXiv admin note: text overlap with arXiv:2107.04422
\\ ( https://arxiv.org/abs/2202.11046 ,  101kb)
------------------------------------------------------------------------------
\\
arXiv:2203.05067
replaced with revised version Sat, 10 Jun 2023 01:22:34 GMT   (71kb)

Title: Universal Regression with Adversarial Responses
Authors: Mo\"ise Blanchard, Patrick Jaillet
Categories: cs.LG stat.ML
\\ ( https://arxiv.org/abs/2203.05067 ,  71kb)
------------------------------------------------------------------------------
\\
arXiv:2205.13341
replaced with revised version Sun, 11 Jun 2023 08:22:34 GMT   (3574kb,D)

Title: QUIC-FL: Quick Unbiased Compression for Federated Learning
Authors: Ran Ben Basat, Shay Vargaftik, Amit Portnoy, Gil Einziger, Yaniv
 Ben-Itzhak, Michael Mitzenmacher
Categories: cs.LG cs.AI cs.DS cs.NI
\\ ( https://arxiv.org/abs/2205.13341 ,  3574kb)
------------------------------------------------------------------------------
\\
arXiv:2205.14846
replaced with revised version Mon, 12 Jun 2023 13:22:21 GMT   (234kb,D)

Title: Precise Learning Curves and Higher-Order Scaling Limits for Dot Product
 Kernel Regression
Authors: Lechao Xiao, Hong Hu, Theodor Misiakiewicz, Yue M. Lu, Jeffrey
 Pennington
Categories: cs.LG stat.ML
Comments: 42 pages; 5 + 6 figures
MSC-class: 68T07
\\ ( https://arxiv.org/abs/2205.14846 ,  234kb)
------------------------------------------------------------------------------
\\
arXiv:2205.15128
replaced with revised version Sun, 11 Jun 2023 06:37:55 GMT   (2574kb,D)

Title: Level Up with RealAEs: Leveraging Domain Constraints in Feature Space to
 Strengthen Robustness of Android Malware Detection
Authors: Hamid Bostani, Zhengyu Zhao, Zhuoran Liu, Veelasha Moonsamy
Categories: cs.LG cs.CR
\\ ( https://arxiv.org/abs/2205.15128 ,  2574kb)
------------------------------------------------------------------------------
\\
arXiv:2206.02326
replaced with revised version Mon, 12 Jun 2023 01:51:06 GMT   (50kb)

Title: Asymptotic Instance-Optimal Algorithms for Interactive Decision Making
Authors: Kefan Dong, Tengyu Ma
Categories: cs.LG
Comments: Accepted by ICLR 2023
\\ ( https://arxiv.org/abs/2206.02326 ,  50kb)
------------------------------------------------------------------------------
\\
arXiv:2206.06354
replaced with revised version Mon, 12 Jun 2023 10:22:27 GMT   (256kb,D)

Title: Differentiable and Transportable Structure Learning
Authors: Jeroen Berrevoets, Nabeel Seedat, Fergus Imrie, Mihaela van der Schaar
Categories: cs.LG stat.ML
Comments: Accepted at the International Conference on Machine Learning (ICML)
 2023
\\ ( https://arxiv.org/abs/2206.06354 ,  256kb)
------------------------------------------------------------------------------
\\
arXiv:2206.07553
replaced with revised version Sat, 10 Jun 2023 18:29:50 GMT   (1073kb,D)

Title: On the fast convergence of minibatch heavy ball momentum
Authors: Raghu Bollapragada, Tyler Chen, Rachel Ward
Categories: cs.LG cs.DS cs.NA math.NA math.OC stat.ML
MSC-class: 65K05, 90C06, 90C30, 65F10, 68W20
\\ ( https://arxiv.org/abs/2206.07553 ,  1073kb)
------------------------------------------------------------------------------
\\
arXiv:2206.10786
replaced with revised version Mon, 12 Jun 2023 15:32:13 GMT   (3872kb,D)

Title: Generative Pretraining for Black-Box Optimization
Authors: Siddarth Krishnamoorthy, Satvik Mehul Mashkaria, Aditya Grover
Categories: cs.LG cs.AI
Comments: International Conference for Machine Learning 2023 NeurIPS Workshop
 for Foundational Models for Decision Making (Oral) 2022
\\ ( https://arxiv.org/abs/2206.10786 ,  3872kb)
------------------------------------------------------------------------------
\\
arXiv:2207.07874
replaced with revised version Sun, 11 Jun 2023 14:24:51 GMT   (1089kb,D)

Title: Model-Aware Contrastive Learning: Towards Escaping the Dilemmas
Authors: Zizheng Huang, Haoxing Chen, Ziqi Wen, Chao Zhang, Huaxiong Li, Bo
 Wang, Chunlin Chen
Categories: cs.LG
Journal-ref: ICML2023
\\ ( https://arxiv.org/abs/2207.07874 ,  1089kb)
------------------------------------------------------------------------------
\\
arXiv:2207.11240
replaced with revised version Mon, 12 Jun 2023 15:30:22 GMT   (7524kb,D)

Title: Discrete Key-Value Bottleneck
Authors: Frederik Tr\"auble, Anirudh Goyal, Nasim Rahaman, Michael Mozer, Kenji
 Kawaguchi, Yoshua Bengio, Bernhard Sch\"olkopf
Categories: cs.LG cs.AI
Comments: 40th International Conference on Machine Learning (ICML 2023)
\\ ( https://arxiv.org/abs/2207.11240 ,  7524kb)
------------------------------------------------------------------------------
\\
arXiv:2208.06245
replaced with revised version Sat, 10 Jun 2023 13:06:06 GMT   (393kb)

Title: Understanding the stochastic dynamics of sequential decision-making
 processes: A path-integral analysis of multi-armed bandits
Authors: Bo Li and Chi Ho Yeung
Categories: cs.LG cond-mat.dis-nn physics.soc-ph stat.ML
Journal-ref: Chaos 33, 063107 (2023)
DOI: 10.1063/5.0120076
\\ ( https://arxiv.org/abs/2208.06245 ,  393kb)
------------------------------------------------------------------------------
\\
arXiv:2209.10579
replaced with revised version Sat, 10 Jun 2023 21:34:45 GMT   (3727kb,D)

Title: First-order Policy Optimization for Robust Markov Decision Process
Authors: Yan Li, Guanghui Lan, Tuo Zhao
Categories: cs.LG cs.AI math.OC
\\ ( https://arxiv.org/abs/2209.10579 ,  3727kb)
------------------------------------------------------------------------------
\\
arXiv:2209.15567
replaced with revised version Mon, 12 Jun 2023 03:54:09 GMT   (6563kb,D)

Title: Holographic-(V)AE: an end-to-end SO(3)-Equivariant (Variational)
 Autoencoder in Fourier Space
Authors: Gian Marco Visani, Michael N. Pun, Arman Angaji, Armita Nourmohammad
Categories: cs.LG physics.bio-ph
\\ ( https://arxiv.org/abs/2209.15567 ,  6563kb)
------------------------------------------------------------------------------
\\
arXiv:2210.00762
replaced with revised version Mon, 12 Jun 2023 14:05:33 GMT   (1572kb,D)

Title: Meta-Learning Priors for Safe Bayesian Optimization
Authors: Jonas Rothfuss, Christopher Koenig, Alisa Rupenyan, Andreas Krause
Categories: cs.LG cs.AI cs.RO stat.ML
Comments: Conference on Robot Learning (CoRL) 2022
\\ ( https://arxiv.org/abs/2210.00762 ,  1572kb)
------------------------------------------------------------------------------
\\
arXiv:2210.02694
replaced with revised version Sun, 11 Jun 2023 06:16:34 GMT   (3530kb,D)

Title: Probabilistic partition of unity networks for high-dimensional
 regression problems
Authors: Tiffany Fan, Nathaniel Trask, Marta D'Elia, Eric Darve
Categories: cs.LG cs.CE
DOI: 10.1002/nme.7207
\\ ( https://arxiv.org/abs/2210.02694 ,  3530kb)
------------------------------------------------------------------------------
\\
arXiv:2210.03123
replaced with revised version Sun, 11 Jun 2023 02:52:18 GMT   (1512kb,D)

Title: On the Effectiveness of Hybrid Pooling in Mixup-Based Graph Learning for
 Language Processing
Authors: Zeming Dong, Qiang Hu, Zhenya Zhang, Yuejun Guo, Maxime Cordy, Mike
 Papadakis, Yves Le Traon, and Jianjun Zhao
Categories: cs.LG cs.AI
Comments: 16 pages, ongoing work
\\ ( https://arxiv.org/abs/2210.03123 ,  1512kb)
------------------------------------------------------------------------------
\\
arXiv:2210.06313
replaced with revised version Fri, 9 Jun 2023 21:53:43 GMT   (2924kb,D)

Title: The Lazy Neuron Phenomenon: On Emergence of Activation Sparsity in
 Transformers
Authors: Zonglin Li, Chong You, Srinadh Bhojanapalli, Daliang Li, Ankit Singh
 Rawat, Sashank J. Reddi, Ke Ye, Felix Chern, Felix Yu, Ruiqi Guo, Sanjiv
 Kumar
Categories: cs.LG cs.CL cs.CV stat.ML
Comments: A short version was presented at ICLR 2023. Previous title: Large
 Models are Parsimonious Learners: Activation Sparsity in Trained Transformers
\\ ( https://arxiv.org/abs/2210.06313 ,  2924kb)
------------------------------------------------------------------------------
\\
arXiv:2210.10880
replaced with revised version Fri, 9 Jun 2023 23:18:21 GMT   (15503kb,D)

Title: Learning to Invert: Simple Adaptive Attacks for Gradient Inversion in
 Federated Learning
Authors: Ruihan Wu, Xiangyu Chen, Chuan Guo, Kilian Q. Weinberger
Categories: cs.LG cs.CR
\\ ( https://arxiv.org/abs/2210.10880 ,  15503kb)
------------------------------------------------------------------------------
\\
arXiv:2210.12453
replaced with revised version Sat, 10 Jun 2023 16:21:03 GMT   (2443kb,D)

Title: NeuroPrim: An Attention-based Model for Solving NP-hard Spanning Tree
 Problems
Authors: Yuchen Shi, Congying Han, Tiande Guo
Categories: cs.LG
MSC-class: 90C27
\\ ( https://arxiv.org/abs/2210.12453 ,  2443kb)
------------------------------------------------------------------------------
\\
arXiv:2210.13319
replaced with revised version Sat, 10 Jun 2023 10:11:33 GMT   (19241kb,D)

Title: MARS: Meta-Learning as Score Matching in the Function Space
Authors: Krunoslav Lehman Pavasovic, Jonas Rothfuss and Andreas Krause
Categories: cs.LG stat.ML
Comments: In International Conference on Learning Representations (ICLR), 2023
\\ ( https://arxiv.org/abs/2210.13319 ,  19241kb)
------------------------------------------------------------------------------
\\
arXiv:2211.01156
replaced with revised version Mon, 12 Jun 2023 12:45:43 GMT   (10627kb,D)

Title: Entropic Neural Optimal Transport via Diffusion Processes
Authors: Nikita Gushchin, Alexander Kolesov, Alexander Korotin, Dmitry Vetrov,
 Evgeny Burnaev
Categories: cs.LG
\\ ( https://arxiv.org/abs/2211.01156 ,  10627kb)
------------------------------------------------------------------------------
\\
arXiv:2211.07484
replaced with revised version Mon, 12 Jun 2023 01:43:30 GMT   (44kb)

Title: Contextual Bandits with Packing and Covering Constraints: A Modular
 Lagrangian Approach via Regression
Authors: Aleksandrs Slivkins and Karthik Abinav Sankararaman and Dylan J.
 Foster
Categories: cs.LG stat.ML
Comments: Accepted at COLT 2023
\\ ( https://arxiv.org/abs/2211.07484 ,  44kb)
------------------------------------------------------------------------------
\\
arXiv:2211.11074
replaced with revised version Mon, 12 Jun 2023 17:39:15 GMT   (40326kb,D)

Title: Frozen Overparameterization: A Double Descent Perspective on Transfer
 Learning of Deep Neural Networks
Authors: Yehuda Dar, Lorenzo Luzi, Richard G. Baraniuk
Categories: cs.LG
\\ ( https://arxiv.org/abs/2211.11074 ,  40326kb)
------------------------------------------------------------------------------
\\
arXiv:2211.15755
replaced with revised version Sun, 11 Jun 2023 00:04:06 GMT   (1882kb,D)

Title: Confidence-Aware Graph Neural Networks for Learning Reliability
 Assessment Commitments
Authors: Seonho Park, Wenbo Chen, Dahye Han, Mathieu Tanneau, and Pascal Van
 Hentenryck
Categories: cs.LG math.OC
Comments: Submitted to IEEE Transactions on Power Systems
\\ ( https://arxiv.org/abs/2211.15755 ,  1882kb)
------------------------------------------------------------------------------
\\
arXiv:2212.02269
replaced with revised version Sun, 11 Jun 2023 15:22:40 GMT   (1721kb,D)

Title: Federated Neural Topic Models
Authors: Lorena Calvo-Bartolom\'e and Jer\'onimo Arenas-Garc\'ia
Categories: cs.LG cs.CL
Comments: 14 pages, 4 figures
\\ ( https://arxiv.org/abs/2212.02269 ,  1721kb)
------------------------------------------------------------------------------
\\
arXiv:2212.03714
replaced with revised version Sat, 10 Jun 2023 14:14:10 GMT   (269kb,D)

Title: Reconstructing Training Data from Model Gradient, Provably
Authors: Zihan Wang, Jason D. Lee, Qi Lei
Categories: cs.LG cs.CR stat.ML
\\ ( https://arxiv.org/abs/2212.03714 ,  269kb)
------------------------------------------------------------------------------
\\
arXiv:2212.04055
replaced with revised version Sat, 10 Jun 2023 15:07:08 GMT   (481kb,D)

Title: Mitigating Memorization of Noisy Labels by Clipping the Model Prediction
Authors: Hongxin Wei, Huiping Zhuang, Renchunzi Xie, Lei Feng, Gang Niu, Bo An,
 Yixuan Li
Categories: cs.LG cs.AI
Comments: Accepted by ICML 2024
\\ ( https://arxiv.org/abs/2212.04055 ,  481kb)
------------------------------------------------------------------------------
\\
arXiv:2212.12731
replaced with revised version Mon, 12 Jun 2023 07:55:18 GMT   (6915kb,D)

Title: Forecasting through deep learning and modal decomposition in two-phase
 concentric jets
Authors: Le\'on Mata, Rodrigo Abad\'ia-Heredia, Manuel Lopez-Martin, Jos\'e M.
 P\'erez, Soledad Le Clainche
Categories: cs.LG physics.flu-dyn
Comments: 48 pages, 21 figures, 13 tables. Submitted to Expert Systems with
 Applications
\\ ( https://arxiv.org/abs/2212.12731 ,  6915kb)
------------------------------------------------------------------------------
\\
arXiv:2301.08918
replaced with revised version Sat, 10 Jun 2023 05:03:09 GMT   (756kb,D)

Title: Improving Signed Propagation for Graph Neural Networks
Authors: Yoonhyuk Choi, Jiho Choi, Taewook Ko, Chong-Kwon Kim
Categories: cs.LG cs.SI
\\ ( https://arxiv.org/abs/2301.08918 ,  756kb)
------------------------------------------------------------------------------
\\
arXiv:2301.10053
replaced with revised version Mon, 12 Jun 2023 10:42:05 GMT   (29918kb,D)

Title: A Linear Reconstruction Approach for Attribute Inference Attacks against
 Synthetic Data
Authors: Meenatchi Sundaram Muthu Selva Annamalai, Andrea Gadotti and Luc
 Rocher
Categories: cs.LG cs.CR
\\ ( https://arxiv.org/abs/2301.10053 ,  29918kb)
------------------------------------------------------------------------------
\\
arXiv:2301.10119
replaced with revised version Sun, 11 Jun 2023 19:53:54 GMT   (2464kb,D)

Title: Minimal Value-Equivalent Partial Models for Scalable and Robust Planning
 in Lifelong Reinforcement Learning
Authors: Safa Alver, Doina Precup
Categories: cs.LG cs.AI
Comments: Published as a conference paper at CoLLAs 2023
\\ ( https://arxiv.org/abs/2301.10119 ,  2464kb)
------------------------------------------------------------------------------
\\
arXiv:2301.13443
replaced with revised version Sat, 10 Jun 2023 03:13:29 GMT   (1694kb,D)

Title: Retiring $\Delta$DP: New Distribution-Level Metrics for Demographic
 Parity
Authors: Xiaotian Han, Zhimeng Jiang, Hongye Jin, Zirui Liu, Na Zou, Qifan
 Wang, Xia Hu
Categories: cs.LG cs.AI cs.CY
Comments: Accepted by TMLR. Code available at
 https://github.com/ahxt/new_metric_for_demographic_parity
\\ ( https://arxiv.org/abs/2301.13443 ,  1694kb)
------------------------------------------------------------------------------
\\
arXiv:2302.00487
replaced with revised version Sun, 11 Jun 2023 00:36:51 GMT   (4645kb,D)

Title: A Comprehensive Survey of Continual Learning: Theory, Method and
 Application
Authors: Liyuan Wang, Xingxing Zhang, Hang Su, Jun Zhu
Categories: cs.LG cs.AI cs.CV
\\ ( https://arxiv.org/abs/2302.00487 ,  4645kb)
------------------------------------------------------------------------------
\\
arXiv:2302.00942
replaced with revised version Sat, 10 Jun 2023 01:29:45 GMT   (10017kb,D)

Title: Efficient Graph Field Integrators Meet Point Clouds
Authors: Krzysztof Choromanski, Arijit Sehanobish, Han Lin, Yunfan Zhao, Eli
 Berger, Tetiana Parshakova, Alvin Pan, David Watkins, Tianyi Zhang, Valerii
 Likhosherstov, Somnath Basu Roy Chowdhury, Avinava Dubey, Deepali Jain, Tamas
 Sarlos, Snigdha Chaturvedi, Adrian Weller
Categories: cs.LG
\\ ( https://arxiv.org/abs/2302.00942 ,  10017kb)
------------------------------------------------------------------------------
\\
arXiv:2302.01511
replaced with revised version Mon, 12 Jun 2023 02:27:53 GMT   (2753kb,D)

Title: Randomized Gaussian Process Upper Confidence Bound with Tighter Bayesian
 Regret Bounds
Authors: Shion Takeno, Yu Inatsu, Masayuki Karasuyama
Categories: cs.LG
Comments: 33 pages, 3 figures, Accepted to ICML2023
\\ ( https://arxiv.org/abs/2302.01511 ,  2753kb)
------------------------------------------------------------------------------
\\
arXiv:2302.01513
replaced with revised version Mon, 12 Jun 2023 02:38:21 GMT   (2201kb,D)

Title: Towards Practical Preferential Bayesian Optimization with Skew Gaussian
 Processes
Authors: Shion Takeno, Masahiro Nomura, Masayuki Karasuyama
Categories: cs.LG
Comments: 25 pages, 9 figures, Accepted to ICML2023
\\ ( https://arxiv.org/abs/2302.01513 ,  2201kb)
------------------------------------------------------------------------------
\\
arXiv:2302.02561
replaced with revised version Sat, 10 Jun 2023 13:28:41 GMT   (4774kb,D)

Title: Domain-Indexing Variational Bayes: Interpretable Domain Index for Domain
 Adaptation
Authors: Zihao Xu, Guang-Yuan Hao, Hao He, Hao Wang
Categories: cs.LG cs.AI
Comments: ICLR 2023 Spotlight (notable-top-25%)
\\ ( https://arxiv.org/abs/2302.02561 ,  4774kb)
------------------------------------------------------------------------------
\\
arXiv:2302.03322
replaced with revised version Sun, 11 Jun 2023 06:16:30 GMT   (40206kb,D)

Title: Attacking Cooperative Multi-Agent Reinforcement Learning by Adversarial
 Minority Influence
Authors: Simin Li, Jun Guo, Jingqiao Xiu, Pu Feng, Xin Yu, Aishan Liu, Wenjun
 Wu, Xianglong Liu
Categories: cs.LG
\\ ( https://arxiv.org/abs/2302.03322 ,  40206kb)
------------------------------------------------------------------------------
\\
arXiv:2302.04182
replaced with revised version Mon, 12 Jun 2023 10:52:47 GMT   (2005kb,D)

Title: Online Resource Allocation: Bandits feedback and Advice on Time-varying
 Demands
Authors: Lixing Lyu and Wang Chi Cheung
Categories: cs.LG math.OC
Comments: 74 pages. A preliminary short version entitled "Non-Stationary
 Bandits with Knapsack Problems with Advice" is accepted to ICML 2023
\\ ( https://arxiv.org/abs/2302.04182 ,  2005kb)
------------------------------------------------------------------------------
\\
arXiv:2302.04379
replaced with revised version Fri, 9 Jun 2023 22:39:14 GMT   (1249kb,D)

Title: The Certification Paradox: Certifications Admit Better Attacks
Authors: Andrew C. Cullen, Shijie Liu, Paul Montague, Sarah M. Erfani, Benjamin
 I.P. Rubinstein
Categories: cs.LG cs.CR
Comments: 16 pages, 6 figures
ACM-class: I.2.6; I.4.9
\\ ( https://arxiv.org/abs/2302.04379 ,  1249kb)
------------------------------------------------------------------------------
\\
arXiv:2302.04419
replaced with revised version Mon, 12 Jun 2023 06:29:22 GMT   (10615kb,D)

Title: An Investigation into Pre-Training Object-Centric Representations for
 Reinforcement Learning
Authors: Jaesik Yoon, Yi-Fu Wu, Heechul Bae, and Sungjin Ahn
Categories: cs.LG cs.AI cs.CV
Comments: We study unsupervised object-centric representations in reinforcement
 learning through systematic investigation
Journal-ref: ICML 2023
\\ ( https://arxiv.org/abs/2302.04419 ,  10615kb)
------------------------------------------------------------------------------
\\
arXiv:2302.06544
replaced with revised version Mon, 12 Jun 2023 06:36:53 GMT   (697kb,D)

Title: Probabilistic Circuits That Know What They Don't Know
Authors: Fabrizio Ventola and Steven Braun and Zhongjie Yu and Martin Mundt and
 Kristian Kersting
Categories: cs.LG cs.AI
Comments: 24 pages, 8 figures, 1 table, 1 algorithm
\\ ( https://arxiv.org/abs/2302.06544 ,  697kb)
------------------------------------------------------------------------------
\\
arXiv:2302.07612
replaced with revised version Sun, 11 Jun 2023 10:01:07 GMT   (1707kb,D)

Title: Towards Optimal Compression: Joint Pruning and Quantization
Authors: Ben Zandonati, Glenn Bucagu, Adrian Alan Pol, Maurizio Pierini, Olya
 Sirkin, Tal Kopetz
Categories: cs.LG
\\ ( https://arxiv.org/abs/2302.07612 ,  1707kb)
------------------------------------------------------------------------------
\\
arXiv:2302.08237
replaced with revised version Fri, 9 Jun 2023 19:45:42 GMT   (27474kb,D)

Title: A Cloud-based Deep Learning Framework for Early Detection of Pushing at
 Crowded Event Entrances
Authors: Ahmed Alia, Mohammed Maree, Mohcine Chraibi, Anas Toma and Armin
 Seyfried
Categories: cs.LG cs.CV
Journal-ref: 2023, IEEE Access
DOI: 10.1109/ACCESS.2023.3273770
\\ ( https://arxiv.org/abs/2302.08237 ,  27474kb)
------------------------------------------------------------------------------
\\
arXiv:2302.08783
replaced with revised version Sun, 11 Jun 2023 15:59:35 GMT   (28kb)

Title: SGD with AdaGrad Stepsizes: Full Adaptivity with High Probability to
 Unknown Parameters, Unbounded Gradients and Affine Variance
Authors: Amit Attia and Tomer Koren
Categories: cs.LG math.OC stat.ML
Comments: 27 pages
\\ ( https://arxiv.org/abs/2302.08783 ,  28kb)
------------------------------------------------------------------------------
\\
arXiv:2302.10911
replaced with revised version Mon, 12 Jun 2023 14:19:53 GMT   (2838kb,D)

Title: Revisiting Weighted Aggregation in Federated Learning with Neural
 Networks
Authors: Zexi Li, Tao Lin, Xinyi Shang, Chao Wu
Categories: cs.LG
Comments: Accepted by ICML 2023
\\ ( https://arxiv.org/abs/2302.10911 ,  2838kb)
------------------------------------------------------------------------------
\\
arXiv:2302.13726
replaced with revised version Sat, 10 Jun 2023 09:27:51 GMT   (10941kb,D)

Title: (Re)$^2$H2O: Autonomous Driving Scenario Generation via Reversely
 Regularized Hybrid Offline-and-Online Reinforcement Learning
Authors: Haoyi Niu, Kun Ren, Yizhou Xu, Ziyuan Yang, Yichen Lin, Yi Zhang,
 Jianming Hu
Categories: cs.LG cs.AI
Comments: Accepted in IEEE Intelligent Vehicles Symposium 2023
\\ ( https://arxiv.org/abs/2302.13726 ,  10941kb)
------------------------------------------------------------------------------
\\
arXiv:2302.14685
replaced with revised version Sat, 10 Jun 2023 15:11:02 GMT   (4104kb,D)

Title: DART: Diversify-Aggregate-Repeat Training Improves Generalization of
 Neural Networks
Authors: Samyak Jain, Sravanti Addepalli, Pawan Sahu, Priyam Dey and R.
 Venkatesh Babu
Categories: cs.LG cs.AI cs.CV
Comments: CVPR 2023. First two authors contributed equally
\\ ( https://arxiv.org/abs/2302.14685 ,  4104kb)
------------------------------------------------------------------------------
\\
arXiv:2303.01621
replaced with revised version Sun, 11 Jun 2023 16:08:34 GMT   (26594kb,D)

Title: GlucoSynth: Generating Differentially-Private Synthetic Glucose Traces
Authors: Josephine Lamp, Mark Derdzinski, Christopher Hannemann, Joost van der
 Linden, Lu Feng, Tianhao Wang, David Evans
Categories: cs.LG cs.CR
\\ ( https://arxiv.org/abs/2303.01621 ,  26594kb)
------------------------------------------------------------------------------
\\
arXiv:2303.03284
replaced with revised version Fri, 9 Jun 2023 18:08:13 GMT   (1409kb,D)

Title: The Wasserstein Believer: Learning Belief Updates for Partially
 Observable Environments through Reliable Latent Space Models
Authors: Raphael Avalos, Florent Delgrange, Ann Now\'e, Guillermo A. P\'erez,
 Diederik M. Roijers
Categories: cs.LG cs.AI
\\ ( https://arxiv.org/abs/2303.03284 ,  1409kb)
------------------------------------------------------------------------------
\\
arXiv:2303.06171
replaced with revised version Sat, 10 Jun 2023 20:09:43 GMT   (1809kb,D)

Title: DP-Fast MH: Private, Fast, and Accurate Metropolis-Hastings for
 Large-Scale Bayesian Inference
Authors: Wanrong Zhang, Ruqi Zhang
Categories: cs.LG stat.ML
Journal-ref: published at ICML 2023
\\ ( https://arxiv.org/abs/2303.06171 ,  1809kb)
------------------------------------------------------------------------------
\\
arXiv:2303.06799
replaced with revised version Sun, 11 Jun 2023 21:27:45 GMT   (911kb,D)

Title: Gaussian Process on the Product of Directional Manifolds
Authors: Ziyu Cao and Kailai Li
Categories: cs.LG
Comments: 7 pages
\\ ( https://arxiv.org/abs/2303.06799 ,  911kb)
------------------------------------------------------------------------------
\\
arXiv:2303.06833
replaced with revised version Sun, 11 Jun 2023 23:06:16 GMT   (25455kb,D)

Title: Transformer-based Planning for Symbolic Regression
Authors: Parshin Shojaee, Kazem Meidani, Amir Barati Farimani, Chandan K. Reddy
Categories: cs.LG cs.AI
Comments: Parshin Shojaee and Kazem Meidani contributed equally to this work
\\ ( https://arxiv.org/abs/2303.06833 ,  25455kb)
------------------------------------------------------------------------------
\\
arXiv:2303.06865
replaced with revised version Mon, 12 Jun 2023 07:48:53 GMT   (351kb,D)

Title: FlexGen: High-Throughput Generative Inference of Large Language Models
 with a Single GPU
Authors: Ying Sheng, Lianmin Zheng, Binhang Yuan, Zhuohan Li, Max Ryabinin,
 Daniel Y. Fu, Zhiqiang Xie, Beidi Chen, Clark Barrett, Joseph E. Gonzalez,
 Percy Liang, Christopher R\'e, Ion Stoica, Ce Zhang
Categories: cs.LG cs.AI cs.PF
\\ ( https://arxiv.org/abs/2303.06865 ,  351kb)
------------------------------------------------------------------------------
\\
arXiv:2303.09989
replaced with revised version Sun, 11 Jun 2023 19:18:31 GMT   (27344kb,D)

Title: Finding Competence Regions in Domain Generalization
Authors: Jens M\"uller, Stefan T. Radev, Robert Schmier, Felix Draxler, Carsten
 Rother, Ullrich K\"othe
Categories: cs.LG stat.ML
Comments: The paper has been published at TMLR (see
 https://openreview.net/forum?id=TSy0vuwQFN)
Journal-ref: Transactions on Machine Learning Research (06/2023)
\\ ( https://arxiv.org/abs/2303.09989 ,  27344kb)
------------------------------------------------------------------------------
\\
arXiv:2303.10158
replaced with revised version Sun, 11 Jun 2023 07:25:40 GMT   (654kb,D)

Title: Data-centric Artificial Intelligence: A Survey
Authors: Daochen Zha, Zaid Pervaiz Bhat, Kwei-Herng Lai, Fan Yang, Zhimeng
 Jiang, Shaochen Zhong, Xia Hu
Categories: cs.LG cs.AI cs.DB
Comments: 38 pages, 6 figues, 5 tables. A companion list of data-centric AI
 resources is available at https://github.com/daochenzha/data-centric-AI
\\ ( https://arxiv.org/abs/2303.10158 ,  654kb)
------------------------------------------------------------------------------
\\
arXiv:2304.00613
replaced with revised version Sun, 11 Jun 2023 15:47:58 GMT   (2694kb,D)

Title: Improving Few-Shot Inductive Learning on Temporal Knowledge Graphs using
 Confidence-Augmented Reinforcement Learning
Authors: Zifeng Ding, Jingpei Wu, Zongyue Li, Yunpu Ma, Volker Tresp
Categories: cs.LG cs.AI
Comments: Accepted to ECML/PKDD 2023
\\ ( https://arxiv.org/abs/2304.00613 ,  2694kb)
------------------------------------------------------------------------------
\\
arXiv:2304.01874
replaced with revised version Mon, 12 Jun 2023 01:11:18 GMT   (4269kb,D)

Title: Incremental Verification of Neural Networks
Authors: Shubham Ugare, Debangshu Banerjee, Sasa Misailovic, Gagandeep Singh
Categories: cs.LG cs.PL cs.SE
Comments: PLDI 2023
DOI: 10.1145/3591299
\\ ( https://arxiv.org/abs/2304.01874 ,  4269kb)
------------------------------------------------------------------------------
\\
arXiv:2304.04934
replaced with revised version Fri, 9 Jun 2023 19:36:24 GMT   (4337kb,D)

Title: Model Sparsification Can Simplify Machine Unlearning
Authors: Jinghan Jia, Jiancheng Liu, Parikshit Ram, Yuguang Yao, Gaowen Liu,
 Yang Liu, Pranay Sharma, Sijia Liu
Categories: cs.LG
\\ ( https://arxiv.org/abs/2304.04934 ,  4337kb)
------------------------------------------------------------------------------
\\
arXiv:2304.06094
replaced with revised version Mon, 12 Jun 2023 10:33:36 GMT   (2149kb,D)

Title: Energy-guided Entropic Neural Optimal Transport
Authors: Petr Mokrov and Alexander Korotin and Alexander Kolesov and Nikita
 Gushchin and Evgeny Burnaev
Categories: cs.LG stat.ML
\\ ( https://arxiv.org/abs/2304.06094 ,  2149kb)
------------------------------------------------------------------------------
\\
arXiv:2304.14836
replaced with revised version Sun, 11 Jun 2023 10:07:52 GMT   (8288kb,D)

Title: Training Large Scale Polynomial CNNs for E2E Inference over Homomorphic
 Encryption
Authors: Moran Baruch, Nir Drucker, Gilad Ezov, Yoav Goldberg, Eyal Kushnir,
 Jenny Lerner, Omri Soceanu and Itamar Zimerman
Categories: cs.LG cs.AI cs.CR
\\ ( https://arxiv.org/abs/2304.14836 ,  8288kb)
------------------------------------------------------------------------------
\\
arXiv:2305.04837
replaced with revised version Sun, 11 Jun 2023 05:55:54 GMT   (558kb)

Title: Scalable Optimal Margin Distribution Machine
Authors: Yilin Wang, Nan Cao, Teng Zhang, Xuanhua Shi and Hai Jin
Categories: cs.LG
\\ ( https://arxiv.org/abs/2305.04837 ,  558kb)
------------------------------------------------------------------------------
\\
arXiv:2305.05832
replaced with revised version Sat, 10 Jun 2023 10:32:36 GMT   (50kb,D)

Title: Causal Information Splitting: Engineering Proxy Features for Robustness
 to Distribution Shifts
Authors: Bijan Mazaheri, Atalanti Mastakouri, Dominik Janzing, Michaela Hardt
Categories: cs.LG cs.AI cs.IT math.IT stat.ME
Comments: To appear in UAI 2023
\\ ( https://arxiv.org/abs/2305.05832 ,  50kb)
------------------------------------------------------------------------------
\\
arXiv:2305.09779
replaced with revised version Sat, 10 Jun 2023 09:10:14 GMT   (16908kb,D)

Title: A Scalable Walsh-Hadamard Regularizer to Overcome the Low-degree
 Spectral Bias of Neural Networks
Authors: Ali Gorji, Andisheh Amrollahi, Andreas Krause
Categories: cs.LG cs.AI
Comments: Accepted for the 39th Conference on Uncertainty in Artificial
 Intelligence (UAI 2023)
\\ ( https://arxiv.org/abs/2305.09779 ,  16908kb)
------------------------------------------------------------------------------
\\
arXiv:2305.13141
replaced with revised version Mon, 12 Jun 2023 16:04:52 GMT   (27kb)

Title: Tight conditions for when the NTK approximation is valid
Authors: Enric Boix-Adsera, Etai Littwin
Categories: cs.LG
\\ ( https://arxiv.org/abs/2305.13141 ,  27kb)
------------------------------------------------------------------------------
\\
arXiv:2305.13592
replaced with revised version Mon, 12 Jun 2023 00:56:21 GMT   (334kb,D)

Title: Understanding Programs by Exploiting (Fuzzing) Test Cases
Authors: Jianyu Zhao and Yuyang Rong and Yiwen Guo and Yifeng He and Hao Chen
Categories: cs.LG cs.AI cs.CL cs.CR cs.SE
Comments: Findings of the Association for Computational Linguistics: ACL 2023;
 fix typos and update results to keep the same settings in all experiments
\\ ( https://arxiv.org/abs/2305.13592 ,  334kb)
------------------------------------------------------------------------------
\\
arXiv:2305.15639
replaced with revised version Sun, 11 Jun 2023 08:02:06 GMT   (57kb,D)

Title: Revisiting Generalized p-Laplacian Regularized Framelet GCNs:
 Convergence, Energy Dynamic and Training with Non-Linear Diffusion
Authors: Dai Shi, Zhiqi Shao, Yi Guo, Qibin Zhao, Junbin Gao
Categories: cs.LG
\\ ( https://arxiv.org/abs/2305.15639 ,  57kb)
------------------------------------------------------------------------------
\\
arXiv:2305.17537
replaced with revised version Mon, 12 Jun 2023 17:25:06 GMT   (7934kb,D)

Title: Modeling Dynamic Environments with Scene Graph Memory
Authors: Andrey Kurenkov, Michael Lingelbach, Tanmay Agarwal, Emily Jin,
 Chengshu Li, Ruohan Zhang, Li Fei-Fei, Jiajun Wu, Silvio Savarese, Roberto
 Mart\'in-Mart\'in
Categories: cs.LG cs.AI
\\ ( https://arxiv.org/abs/2305.17537 ,  7934kb)
------------------------------------------------------------------------------
\\
arXiv:2305.18430
replaced with revised version Sat, 10 Jun 2023 04:39:42 GMT   (1971kb,D)

Title: Scalable and Weakly Supervised Bank Transaction Classification
Authors: Liam Toran, Cory Van Der Walt, Alan Sammarone, Alex Keller
 (Flowcast.ai)
Categories: cs.LG
\\ ( https://arxiv.org/abs/2305.18430 ,  1971kb)
------------------------------------------------------------------------------
\\
arXiv:2305.19442
replaced with revised version Mon, 12 Jun 2023 17:04:36 GMT   (1763kb,D)

Title: SimFBO: Towards Simple, Flexible and Communication-efficient Federated
 Bilevel Learning
Authors: Yifan Yang, Peiyao Xiao and Kaiyi Ji
Categories: cs.LG cs.DC math.OC
\\ ( https://arxiv.org/abs/2305.19442 ,  1763kb)
------------------------------------------------------------------------------
\\
arXiv:2305.19903
replaced with revised version Sun, 11 Jun 2023 16:19:56 GMT   (8041kb,D)

Title: Improving Expressivity of GNNs with Subgraph-specific Factor Embedded
 Normalization
Authors: Kaixuan Chen and Shunyu Liu and Tongtian Zhu and Tongya Zheng and
 Haofei Zhang and Zunlei Feng and Jingwen Ye and Mingli Song
Categories: cs.LG cs.AI
Comments: 13 pages, 7 figures
\\ ( https://arxiv.org/abs/2305.19903 ,  8041kb)
------------------------------------------------------------------------------
\\
arXiv:2306.00585
replaced with revised version Sun, 11 Jun 2023 21:04:21 GMT   (61kb,D)

Title: Causal Imitability Under Context-Specific Independence Relations
Authors: Fateme Jamshidi, Sina Akbari, Negar Kiyavash
Categories: cs.LG cs.AI
Comments: 19 pages, 4 figures, under review
\\ ( https://arxiv.org/abs/2306.00585 ,  61kb)
------------------------------------------------------------------------------
\\
arXiv:2306.00643
replaced with revised version Mon, 12 Jun 2023 11:44:15 GMT   (8718kb,D)

Title: TriSig: Assessing the statistical significance of triclusters
Authors: Leonardo Alexandre, Rafael S. Costa, Rui Henriques
Categories: cs.LG stat.ME
\\ ( https://arxiv.org/abs/2306.00643 ,  8718kb)
------------------------------------------------------------------------------
\\
arXiv:2306.01095
replaced with revised version Mon, 12 Jun 2023 10:05:41 GMT   (14356kb,D)

Title: Large-Batch, Neural Multi-Objective Bayesian Optimization
Authors: Navid Ansari, Hans-Peter Seidel, Vahid Babaei
Categories: cs.LG cs.AI cs.CE
\\ ( https://arxiv.org/abs/2306.01095 ,  14356kb)
------------------------------------------------------------------------------
\\
arXiv:2306.01811
replaced with revised version Mon, 12 Jun 2023 07:11:05 GMT   (3343kb,D)

Title: DVFO: Learning-Based DVFS for Energy-Efficient Edge-Cloud Collaborative
 Inference
Authors: Ziyang Zhang, Yang Zhao, Huan Li, Changyao Lin, and Jie Liu
Categories: cs.LG cs.DC cs.OS
\\ ( https://arxiv.org/abs/2306.01811 ,  3343kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02913
replaced with revised version Mon, 12 Jun 2023 14:25:31 GMT   (2068kb,D)

Title: Decentralized SGD and Average-direction SAM are Asymptotically
 Equivalent
Authors: Tongtian Zhu, Fengxiang He, Kaixuan Chen, Mingli Song, Dacheng Tao
Categories: cs.LG cs.CY cs.DC cs.SY eess.SY stat.ML
Comments: Accepted for publication in the 40th International Conference on
 Machine Learning (ICML 2023)
\\ ( https://arxiv.org/abs/2306.02913 ,  2068kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03828
replaced with revised version Sun, 11 Jun 2023 12:57:31 GMT   (23616kb,D)

Title: Quick-Tune: Quickly Learning Which Pretrained Model to Finetune and How
Authors: Sebastian Pineda Arango, Fabio Ferreira, Arlind Kadra, Frank Hutter,
 Josif Grabocka
Categories: cs.LG
\\ ( https://arxiv.org/abs/2306.03828 ,  23616kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04111
replaced with revised version Sun, 11 Jun 2023 14:06:40 GMT   (258kb,D)

Title: Quasi-Newton Updating for Large-Scale Distributed Learning
Authors: Shuyuan Wu, Danyang Huang, Hansheng Wang
Categories: cs.LG cs.DC stat.ME
Comments: 56 pages, 3 figures
\\ ( https://arxiv.org/abs/2306.04111 ,  258kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04581
replaced with revised version Fri, 9 Jun 2023 21:39:45 GMT   (1550kb,D)

Title: Divide and Repair: Using Options to Improve Performance of Imitation
 Learning Against Adversarial Demonstrations
Authors: Prithviraj Dasgupta
Categories: cs.LG cs.AI cs.CR
Comments: 33 pages, 4 figures, 3 tables
ACM-class: I.2.3
\\ ( https://arxiv.org/abs/2306.04581 ,  1550kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04660
replaced with revised version Mon, 12 Jun 2023 08:44:55 GMT   (885kb)

Title: Adaptive Frequency Green Light Optimal Speed Advisory based on Hybrid
 Actor-Critic Reinforcement Learning
Authors: Ming Xu, Dongyu Zuo
Categories: cs.LG cs.AI
\\ ( https://arxiv.org/abs/2306.04660 ,  885kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04828
replaced with revised version Fri, 9 Jun 2023 20:58:43 GMT   (677kb,D)

Title: Fast and Effective GNN Training with Linearized Random Spanning Trees
Authors: Francesco Bonchi, Claudio Gentile, Andr\'e Panisson, Fabio Vitale
Categories: cs.LG
\\ ( https://arxiv.org/abs/2306.04828 ,  677kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04919
replaced with revised version Fri, 9 Jun 2023 20:50:27 GMT   (9747kb,D)

Title: Unsupervised Cross-Domain Soft Sensor Modelling via Deep
 Physics-Inspired Particle Flow Bayes
Authors: Junn Yong Loo, Ze Yang Ding, Surya G. Nurzaman, Chee-Ming Ting, Vishnu
 Monn Baskaran and Chee Pin Tan
Categories: cs.LG
\\ ( https://arxiv.org/abs/2306.04919 ,  9747kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04979
replaced with revised version Sat, 10 Jun 2023 11:20:26 GMT   (1217kb,D)

Title: CoCo: A Coupled Contrastive Framework for Unsupervised Domain Adaptive
 Graph Classification
Authors: Nan Yin, Li Shen, Mengzhu Wang, Long Lan, Zeyu Ma, Chong Chen,
 Xian-Sheng Hua, Xiao Luo
Categories: cs.LG cs.AI
\\ ( https://arxiv.org/abs/2306.04979 ,  1217kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05775
replaced with revised version Mon, 12 Jun 2023 00:42:03 GMT   (4609kb,D)

Title: Weight Freezing: A Regularization Approach for Fully Connected Layers
 with an Application in EEG Classification
Authors: Zhengqing Miao and Meirong Zhao
Categories: cs.LG eess.SP
Comments: 16 pages, 5 figures
\\ ( https://arxiv.org/abs/2306.05775 ,  4609kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05880
replaced with revised version Mon, 12 Jun 2023 14:44:49 GMT   (738kb,D)

Title: Time Series Continuous Modeling for Imputation and Forecasting with
 Implicit Neural Representations
Authors: Etienne Le Naour, Louis Serrano, L\'eon Migus, Yuan Yin, Ghislain
 Agoua, Nicolas Baskiotis, Patrick Gallinari, Vincent Guigue
Categories: cs.LG cs.AI
\\ ( https://arxiv.org/abs/2306.05880 ,  738kb)
------------------------------------------------------------------------------
\\
arXiv:2301.01919
replaced with revised version Mon, 12 Jun 2023 07:13:41 GMT   (1521kb,D)

Title: Scalable Communication for Multi-Agent Reinforcement Learning via
 Transformer-Based Email Mechanism
Authors: Xudong Guo, Daming Shi, Wenhui Fan
Categories: cs.MA cs.AI cs.LG
Comments: Accepted by IJCAI 2023
\\ ( https://arxiv.org/abs/2301.01919 ,  1521kb)
------------------------------------------------------------------------------
\\
arXiv:2002.06320
replaced with revised version Mon, 12 Jun 2023 13:57:31 GMT   (19617kb,D)

Title: Dimension-variable Mapless Navigation with Deep Reinforcement Learning
Authors: Wei Zhang, Yunfeng Zhang, Ning Liu and Kai Ren
Categories: cs.RO
Comments: 9 pages, 15 figures. This work will be submitted to the IEEE for
 possible publication. Copyright may be transferred without notice, after
 which this version may no longer be accessible
MSC-class: 68T40
\\ ( https://arxiv.org/abs/2002.06320 ,  19617kb)
------------------------------------------------------------------------------
\\
arXiv:2204.01922
replaced with revised version Sat, 10 Jun 2023 17:56:22 GMT   (330kb,D)

Title: SHAIL: Safety-Aware Hierarchical Adversarial Imitation Learning for
 Autonomous Driving in Urban Environments
Authors: Arec Jamgochian, Etienne Buehrle, Johannes Fischer, Mykel J.
 Kochenderfer
Categories: cs.RO
Comments: Presented at the 2023 IEEE International Conference on Robotics and
 Automation (ICRA)
\\ ( https://arxiv.org/abs/2204.01922 ,  330kb)
------------------------------------------------------------------------------
\\
arXiv:2204.02635
replaced with revised version Sun, 11 Jun 2023 08:20:30 GMT   (6381kb,D)

Title: PVI-DSO: Leveraging Planar Regularities for Direct Sparse
 Visual-Inertial Odometry
Authors: Bo Xu, Xin Li, Jingrong Wang, Chau Yuen (Fellow, IEEE), Jiancheng Li
Categories: cs.RO
\\ ( https://arxiv.org/abs/2204.02635 ,  6381kb)
------------------------------------------------------------------------------
\\
arXiv:2206.09215
replaced with revised version Sat, 10 Jun 2023 11:54:52 GMT   (2733kb,D)

Title: Mind the Gap: Norm-Aware Adaptive Robust Loss for Multivariate
 Least-Squares Problems
Authors: Thomas Hitchcox and James Richard Forbes
Categories: cs.RO
Comments: 8 pages, 4 figures. This paper has been accepted for publication in
 IEEE Robotics and Automation Letters. V2: Update weighting in (13), (28) and
 re-run results. Hypothesis, methodology, and general findings remain
 unchanged. Update Sec. II-A to reference IRLS, and update citation [11]
 accordingly. Include acknowledgement to Mitchell Cohen. V3: Update Section
 II-A to least-squares
Journal-ref: IEEE Robotics and Automation Letters, vol. 7, no. 3, pp.
 7116-7123, 2022
DOI: 10.1109/LRA.2022.3179424
\\ ( https://arxiv.org/abs/2206.09215 ,  2733kb)
------------------------------------------------------------------------------
\\
arXiv:2208.09861
replaced with revised version Sun, 11 Jun 2023 10:03:08 GMT   (10021kb,D)

Title: The Single Robot Line Coverage Problem: Theory, Algorithms, and
 Experiments
Authors: Saurav Agarwal and Srinivas Akella
Categories: cs.RO
\\ ( https://arxiv.org/abs/2208.09861 ,  10021kb)
------------------------------------------------------------------------------
\\
arXiv:2209.12336
replaced with revised version Sat, 10 Jun 2023 22:53:47 GMT   (1164kb,D)

Title: Generating Formal Safety Assurances for High-Dimensional Reachability
Authors: Albert Lin and Somil Bansal
Categories: cs.RO cs.AI cs.LG cs.SY eess.SY
Comments: Accepted to ICRA 2023
ACM-class: I.2.9; I.2.8
\\ ( https://arxiv.org/abs/2209.12336 ,  1164kb)
------------------------------------------------------------------------------
\\
arXiv:2209.14976
replaced with revised version Sat, 10 Jun 2023 19:49:55 GMT   (3588kb,D)

Title: Parameter-Conditioned Reachable Sets for Updating Safety Assurances
 Online
Authors: Javier Borquez, Kensuke Nakamura, Somil Bansal
Categories: cs.RO cs.SY eess.SY
\\ ( https://arxiv.org/abs/2209.14976 ,  3588kb)
------------------------------------------------------------------------------
\\
arXiv:2211.10934
replaced with revised version Mon, 12 Jun 2023 06:10:13 GMT   (18856kb,D)

Title: Active Exploration based on Information Gain by Particle Filter for
 Efficient Spatial Concept Formation
Authors: Akira Taniguchi, Yoshiki Tabuchi, Tomochika Ishikawa, Lotfi El Hafi,
 Yoshinobu Hagiwara, Tadahiro Taniguchi
Categories: cs.RO cs.AI
Comments: Accepted to Advanced Robotics
DOI: 10.1080/01691864.2023.2225175
\\ ( https://arxiv.org/abs/2211.10934 ,  18856kb)
------------------------------------------------------------------------------
\\
arXiv:2212.09234
replaced with revised version Fri, 9 Jun 2023 22:25:48 GMT   (27200kb,D)

Title: Real-Time Deformable-Contact-Aware Model Predictive Control for
 Force-Modulated Manipulation
Authors: Lasitha Wijayarathne, Ziyi Zhou, Ye Zhao, and Frank L. Hammond III
Categories: cs.RO
Comments: arXiv admin note: text overlap with arXiv:2004.09734
\\ ( https://arxiv.org/abs/2212.09234 ,  27200kb)
------------------------------------------------------------------------------
\\
arXiv:2301.09033
replaced with revised version Fri, 9 Jun 2023 22:28:50 GMT   (1455kb,D)

Title: Continuous-Time Ultra-Wideband-Inertial Fusion
Authors: Kailai Li, Ziyu Cao, and Uwe D. Hanebeck
Categories: cs.RO
Comments: 8 pages, Accepted by IEEE Robotics and Automation Letters (RA-L).
 Open-source code at: https://github.com/KIT-ISAS/SFUISE
DOI: 10.1109/LRA.2023.3281932
\\ ( https://arxiv.org/abs/2301.09033 ,  1455kb)
------------------------------------------------------------------------------
\\
arXiv:2303.05203
replaced with revised version Sat, 10 Jun 2023 01:07:03 GMT   (4191kb,D)

Title: RMMDet: Road-Side Multitype and Multigroup Sensor Detection System for
 Autonomous Driving
Authors: Xiuyu Yang, Zhuangyan Zhang, Haikuo Du, Sui Yang, Fengping Sun, Yanbo
 Liu, Ling Pei, Wenchao Xu, Weiqi Sun, Zhengyu Li
Categories: cs.RO cs.AI cs.SY eess.SY
\\ ( https://arxiv.org/abs/2303.05203 ,  4191kb)
------------------------------------------------------------------------------
\\
arXiv:2303.13446
replaced with revised version Sat, 10 Jun 2023 21:29:21 GMT   (9630kb,D)

Title: On the Utility of Koopman Operator Theory in Learning Dexterous
 Manipulation Skills
Authors: Yunhai Han, Mandy Xie, Ye Zhao, and Harish Ravichandar
Categories: cs.RO
\\ ( https://arxiv.org/abs/2303.13446 ,  9630kb)
------------------------------------------------------------------------------
\\
arXiv:2303.18186
replaced with revised version Sat, 10 Jun 2023 07:02:44 GMT   (16625kb,D)

Title: Adaptive Model Prediction Control-Based Multi-Terrain Trajectory
 Tracking Framework for Mobile Spherical Robots
Authors: Yifan Liu, Tao Hu, Xiaoqing Guan, Yixu Wang, Bixuan Zhang, You Wang,
 Guang Li
Categories: cs.RO
Comments: 10 pages, 20 figures
\\ ( https://arxiv.org/abs/2303.18186 ,  16625kb)
------------------------------------------------------------------------------
\\
arXiv:2304.09439
replaced with revised version Sat, 10 Jun 2023 14:13:17 GMT   (41067kb,D)

Title: Local object crop collision network for efficient simulation of
 non-convex objects in GPU-based simulators
Authors: Dongwon Son and Beomjoon Kim
Categories: cs.RO cs.AI
Comments: RSS 2023 https://sites.google.com/view/locc-rss2023/home
\\ ( https://arxiv.org/abs/2304.09439 ,  41067kb)
------------------------------------------------------------------------------
\\
arXiv:2305.08528
replaced with revised version Mon, 12 Jun 2023 11:43:55 GMT   (4221kb,D)

Title: NICOL: A Neuro-inspired Collaborative Semi-humanoid Robot that Bridges
 Social Interaction and Reliable Manipulation
Authors: Matthias Kerzel, Philipp Allgeuer, Erik Strahl, Nicolas Frick,
 Jan-Gerrit Habekost, Manfred Eppe and Stefan Wermter
Categories: cs.RO
\\ ( https://arxiv.org/abs/2305.08528 ,  4221kb)
------------------------------------------------------------------------------
\\
arXiv:2305.15189
replaced with revised version Mon, 12 Jun 2023 08:17:05 GMT   (1237kb,D)

Title: Black-Box vs. Gray-Box: A Case Study on Learning Table Tennis Ball
 Trajectory Prediction with Spin and Impacts
Authors: Jan Achterhold, Philip Tobuschat, Hao Ma, Dieter Buechler, Michael
 Muehlebach, Joerg Stueckler
Categories: cs.RO cs.LG cs.SY eess.SY
Comments: Accepted for publication at the 5th Annual Conference on Learning for
 Dynamics and Control (L4DC) 2023 (camera-ready). With supplementary material
\\ ( https://arxiv.org/abs/2305.15189 ,  1237kb)
------------------------------------------------------------------------------
\\
arXiv:2305.18903
replaced with revised version Mon, 12 Jun 2023 14:24:53 GMT   (2840kb,D)

Title: Improving the performance of Learned Controllers in Behavior Trees using
 Value Function Estimates at Switching Boundaries
Authors: Mart Kartasev and Petter \"Ogren
Categories: cs.RO
\\ ( https://arxiv.org/abs/2305.18903 ,  2840kb)
------------------------------------------------------------------------------
\\
arXiv:2306.01704
replaced with revised version Mon, 12 Jun 2023 16:55:10 GMT   (40630kb,D)

Title: Temporal-controlled Frame Swap for Generating High-Fidelity Stereo
 Driving Data for Autonomy Analysis
Authors: Yedi Luo, Xiangyu Bai, Le Jiang, Aniket Gupta, Eric Mortin, Hanumant
 Singh Sarah Ostadabbas
Categories: cs.RO
\\ ( https://arxiv.org/abs/2306.01704 ,  40630kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03906
replaced with revised version Mon, 12 Jun 2023 15:22:02 GMT   (5732kb)

Title: Biological Organisms as End Effectors
Authors: Josephine Galipon, Shoya Shimizu, Kenjiro Tadakuma
Categories: cs.RO
Comments: 13 pages, 9 figures, 1 graphical abstract
\\ ( https://arxiv.org/abs/2306.03906 ,  5732kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04732
replaced with revised version Mon, 12 Jun 2023 09:41:05 GMT   (28169kb,D)

Title: Online Multi-Contact Receding Horizon Planning via Value Function
 Approximation
Authors: Jiayi Wang, Sanghyun Kim, Teguh Santoso Lembono, Wenqian Du, Jaehyun
 Shim, Saeid Samadi, Ke Wang, Vladimir Ivan, Sylvain Calinon, Sethu
 Vijayakumar, Steve Tonneau
Categories: cs.RO
Comments: Under review
\\ ( https://arxiv.org/abs/2306.04732 ,  28169kb)
------------------------------------------------------------------------------
\\
arXiv:1911.09910
replaced with revised version Sat, 10 Jun 2023 20:01:48 GMT   (165kb,D)

Title: Learning Robustness with Bounded Failure: An Iterative MPC Approach
Authors: Monimoy Bujarbaruah, Akhil Shetty, Kameshwar Poolla, Francesco
 Borrelli
Categories: eess.SY cs.SY math.ST stat.TH
Comments: Added a set of important references that were missing
\\ ( https://arxiv.org/abs/1911.09910 ,  165kb)
------------------------------------------------------------------------------
\\
arXiv:2006.05054
replaced with revised version Sat, 10 Jun 2023 19:39:31 GMT   (201kb,D)

Title: Learning to Satisfy Unknown Constraints in Iterative MPC
Authors: Monimoy Bujarbaruah, Charlott Vallon, Francesco Borrelli
Categories: eess.SY cs.SY stat.ML
Comments: Long version of the published paper for IEEE-CDC 2020. First two
 authors contributed equally. Added some very relevant citations that were
 missing
\\ ( https://arxiv.org/abs/2006.05054 ,  201kb)
------------------------------------------------------------------------------
\\
arXiv:2202.13122
replaced with revised version Sat, 10 Jun 2023 14:59:54 GMT   (836kb,D)

Title: What ODE-Approximation Schemes of Time-Delay Systems Reveal about
 Lyapunov-Krasovskii Functionals
Authors: Tessina H. Scholl, Veit Hagenmeyer, Lutz Gr\"oll
Categories: eess.SY cs.SY
Comments: 16 pages, 4 figures; This work has been submitted to the IEEE for
 possible publication
\\ ( https://arxiv.org/abs/2202.13122 ,  836kb)
------------------------------------------------------------------------------
\\
arXiv:2212.14665
replaced with revised version Mon, 12 Jun 2023 03:19:03 GMT   (451kb,D)

Title: Sizing Grid-Connected Wind Power Generation and Energy Storage with Wake
 Effect and Endogenous Uncertainty: A Distributionally Robust Method
Authors: Rui Xie, Wei Wei, Yue Chen
Categories: eess.SY cs.SY math.OC
Comments: 14 pages, 6 figures
\\ ( https://arxiv.org/abs/2212.14665 ,  451kb)
------------------------------------------------------------------------------
\\
arXiv:2301.03376
replaced with revised version Mon, 12 Jun 2023 13:18:23 GMT   (748kb,D)

Title: Occupant-Oriented Demand Response with Multi-Zone Thermal Building
 Control
Authors: Moritz Frahm, Thomas Dengiz, Philipp Zwickel, Heiko Maa{\ss}, J\"org
 Matthes, Veit Hagenmeyer
Categories: eess.SY cs.SY
Comments: Paper pre-print
\\ ( https://arxiv.org/abs/2301.03376 ,  748kb)
------------------------------------------------------------------------------
\\
arXiv:2301.10968
replaced with revised version Sat, 10 Jun 2023 03:59:27 GMT   (1348kb)

Title: Time-delay based output feedback control of fourth-order oscillatory
 systems
Authors: Michael Ruderman
Categories: eess.SY cs.SY
Comments: 7 pages, 9 figures
\\ ( https://arxiv.org/abs/2301.10968 ,  1348kb)
------------------------------------------------------------------------------
\\
arXiv:2302.10104
replaced with revised version Sat, 10 Jun 2023 22:02:05 GMT   (3851kb,D)

Title: Comprehensive Framework for Controlling Nonlinear Multi-Species Water
 Quality Dynamics
Authors: Salma M. Elsherif, Ahmad F. Taha, Ahmed A. Abokifa, and Lina Sela
Categories: eess.SY cs.SY math.OC
\\ ( https://arxiv.org/abs/2302.10104 ,  3851kb)
------------------------------------------------------------------------------
\\
arXiv:2303.11197
replaced with revised version Mon, 12 Jun 2023 12:10:08 GMT   (432kb,D)

Title: Data-driven feedforward control design for nonlinear systems: A
 control-oriented system identification approach
Authors: Max Bolderman, Mircea Lazar, Hans Butler
Categories: eess.SY cs.SY
\\ ( https://arxiv.org/abs/2303.11197 ,  432kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04476
replaced with revised version Mon, 12 Jun 2023 06:43:10 GMT   (2573kb,D)

Title: Energy-based Assessment and Driving Behavior of ACC Systems and Humans
 Inside Platoons
Authors: Theocharis Apostolakis, Michail A. Makridis, Anastasios Kouvelas and
 Konstantinos Ampountolas
Categories: eess.SY cs.SY
Comments: 10 pages, 7 figures, 2 Tables
Journal-ref: IEEE Transactions on Intelligent Transportation Systems (2023)
DOI: 10.1109/TITS.2023.3285296
\\ ( https://arxiv.org/abs/2306.04476 ,  2573kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05686
replaced with revised version Mon, 12 Jun 2023 07:25:02 GMT   (4721kb,D)

Title: Encrypted Simultaneous Control of Joint Angle and Stiffness of
 Antagonistic Pneumatic Artificial Muscle Actuator by Polynomial Approximation
Authors: Yuta Takeda, Takaya Shin, Kaoru Teranishi, and Kiminao Kogiso
Categories: eess.SY cs.SY
Comments: 10 pages
\\ ( https://arxiv.org/abs/2306.05686 ,  4721kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05700
replaced with revised version Mon, 12 Jun 2023 08:30:10 GMT   (23kb)

Title: Finite-Time Analysis of Minimax Q-Learning for Two-Player Zero-Sum
 Markov Games: Switching System Approach
Authors: Donghwan Lee
Categories: eess.SY cs.GT cs.LG cs.SY
Comments: arXiv admin note: text overlap with arXiv:2205.05455
\\ ( https://arxiv.org/abs/2306.05700 ,  23kb)
------------------------------------------------------------------------------
\\
arXiv:2112.07337
replaced with revised version Sun, 11 Jun 2023 18:46:16 GMT   (4706kb,D)

Title: Multi-Row, Multi-Span Distant Supervision For Table+Text Question
Authors: Vishwajeet Kumar, Yash Gupta, Saneem Chemmengath, Jaydeep Sen, Soumen
 Chakrabarti, Samarth Bharadwaj, FeiFei Pan
Categories: cs.CL cs.AI
Comments: ACL 2023
\\ ( https://arxiv.org/abs/2112.07337 ,  4706kb)
------------------------------------------------------------------------------
\\
arXiv:2201.04632
replaced with revised version Mon, 12 Jun 2023 07:21:06 GMT   (60kb,D)

Title: The Concept of Criticality in AI Safety
Authors: Yitzhak Spielberg, Amos Azaria
Categories: cs.HC cs.AI
\\ ( https://arxiv.org/abs/2201.04632 ,  60kb)
------------------------------------------------------------------------------
\\
arXiv:2202.06411 (*cross-listing*)
replaced with revised version Sat, 10 Jun 2023 00:53:24 GMT   (340kb,D)

Title: The Impact of a Coalition: Assessing the Likelihood of Voter Influence
 in Large Elections
Authors: Lirong Xia
Categories: econ.TH cs.AI cs.GT
\\ ( https://arxiv.org/abs/2202.06411 ,  340kb)
------------------------------------------------------------------------------
\\
arXiv:2203.03047
replaced with revised version Mon, 12 Jun 2023 09:48:11 GMT   (212kb,D)

Title: Recent Advances in Neural Text Generation: A Task-Agnostic Survey
Authors: Chen Tang, Frank Guerin and Chenghua Lin
Categories: cs.CL cs.AI
Comments: This has been updated with some recent advances in 2023
\\ ( https://arxiv.org/abs/2203.03047 ,  212kb)
------------------------------------------------------------------------------
\\
arXiv:2204.13366
replaced with revised version Mon, 12 Jun 2023 14:48:16 GMT   (187kb,D)

Title: Semantic Information Recovery in Wireless Networks
Authors: Edgar Beck, Carsten Bockelmann and Armin Dekorsy
Categories: cs.IT cs.AI cs.LG eess.SP math.IT stat.ML
Comments: Submitted for peer review
\\ ( https://arxiv.org/abs/2204.13366 ,  187kb)
------------------------------------------------------------------------------
\\
arXiv:2206.00621
replaced with revised version Mon, 12 Jun 2023 12:47:16 GMT   (9775kb,D)

Title: Cross-View Language Modeling: Towards Unified Cross-Lingual Cross-Modal
 Pre-training
Authors: Yan Zeng, Wangchunshu Zhou, Ao Luo, Ziming Cheng, Xinsong Zhang
Categories: cs.CL cs.AI cs.CV cs.LG
Comments: ACL 2023
\\ ( https://arxiv.org/abs/2206.00621 ,  9775kb)
------------------------------------------------------------------------------
\\
arXiv:2206.04615
replaced with revised version Mon, 12 Jun 2023 17:51:15 GMT   (1948kb,D)

Title: Beyond the Imitation Game: Quantifying and extrapolating the
 capabilities of language models
Authors: Aarohi Srivastava, Abhinav Rastogi, Abhishek Rao, Abu Awal Md Shoeb,
 Abubakar Abid, Adam Fisch, Adam R. Brown, Adam Santoro, Aditya Gupta, Adri\`a
 Garriga-Alonso, Agnieszka Kluska, Aitor Lewkowycz, Akshat Agarwal, Alethea
 Power, Alex Ray, Alex Warstadt, Alexander W. Kocurek, Ali Safaya, Ali Tazarv,
 Alice Xiang, Alicia Parrish, Allen Nie, Aman Hussain, Amanda Askell, Amanda
 Dsouza, Ambrose Slone, Ameet Rahane, Anantharaman S. Iyer, Anders Andreassen,
 Andrea Madotto, Andrea Santilli, Andreas Stuhlm\"uller, Andrew Dai, Andrew
 La, Andrew Lampinen, Andy Zou, Angela Jiang, Angelica Chen, Anh Vuong,
 Animesh Gupta, Anna Gottardi, Antonio Norelli, Anu Venkatesh, Arash
 Gholamidavoodi, Arfa Tabassum, Arul Menezes, Arun Kirubarajan, Asher
 Mullokandov, Ashish Sabharwal, Austin Herrick, Avia Efrat, Aykut Erdem, et
 al. (399 additional authors not shown)
Categories: cs.CL cs.AI cs.CY cs.LG stat.ML
Comments: 27 pages, 17 figures + references and appendices, repo:
 https://github.com/google/BIG-bench
Journal-ref: Transactions on Machine Learning Research, May/2022,
 https://openreview.net/forum?id=uyTL5Bvosj
\\ ( https://arxiv.org/abs/2206.04615 ,  1948kb)
------------------------------------------------------------------------------
\\
arXiv:2211.08202
replaced with revised version Mon, 12 Jun 2023 08:11:57 GMT   (123kb,D)

Title: A Mathematical Runtime Analysis of the Non-dominated Sorting Genetic
 Algorithm III (NSGA-III)
Authors: Simon Wietheger, Benjamin Doerr
Categories: cs.NE cs.AI
Comments: Long version of a paper appearing at IJCAI 2023
\\ ( https://arxiv.org/abs/2211.08202 ,  123kb)
------------------------------------------------------------------------------
\\
arXiv:2212.06951
replaced with revised version Sun, 11 Jun 2023 17:49:45 GMT   (5465kb,D)

Title: AI Ethics on Blockchain: Topic Analysis on Twitter Data for Blockchain
 Security
Authors: Yihang Fu, Zesen Zhuang, Luyao Zhang
Categories: cs.CR cs.AI cs.LG q-fin.CP
MSC-class: 97P80, 68M25
ACM-class: H.5; J.5; J.4; I.2
\\ ( https://arxiv.org/abs/2212.06951 ,  5465kb)
------------------------------------------------------------------------------
\\
arXiv:2301.00488
replaced with revised version Sun, 11 Jun 2023 02:59:39 GMT   (1547kb)

Title: Information Transfer Rate in BCIs: Towards Tightly Integrated Symbiosis
Authors: Suayb S. Arslan and Pawan Sinha
Categories: cs.HC cs.AI cs.IT cs.PF eess.SP math.IT
Comments: 27 pages, 10 figures, 2 tables. Accepted to Biomedical Signal
 Processing and Control, Elsevier, 2023
\\ ( https://arxiv.org/abs/2301.00488 ,  1547kb)
------------------------------------------------------------------------------
\\
arXiv:2302.10724
replaced with revised version Fri, 9 Jun 2023 19:52:34 GMT   (1561kb,D)

Title: ChatGPT: Jack of all trades, master of none
Authors: Jan Koco\'n, Igor Cichecki, Oliwier Kaszyca, Mateusz Kochanek,
 Dominika Szyd{\l}o, Joanna Baran, Julita Bielaniewicz, Marcin Gruza,
 Arkadiusz Janz, Kamil Kanclerz, Anna Koco\'n, Bart{\l}omiej Koptyra, Wiktoria
 Mieleszczenko-Kowszewicz, Piotr Mi{\l}kowski, Marcin Oleksy, Maciej Piasecki,
 {\L}ukasz Radli\'nski, Konrad Wojtasik, Stanis{\l}aw Wo\'zniak, Przemys{\l}aw
 Kazienko
Categories: cs.CL cs.AI cs.CY cs.LG
Comments: preprint
Journal-ref: Information Fusion 101861 (2023)
DOI: 10.1016/j.inffus.2023.101861
\\ ( https://arxiv.org/abs/2302.10724 ,  1561kb)
------------------------------------------------------------------------------
\\
arXiv:2302.14370
replaced with revised version Mon, 12 Jun 2023 04:14:45 GMT   (1467kb,D)

Title: CrossSpeech: Speaker-independent Acoustic Representation for
 Cross-lingual Speech Synthesis
Authors: Ji-Hoon Kim, Hong-Sun Yang, Yoon-Cheol Ju, Il-Hwan Kim, and
 Byeong-Yeol Kim
Categories: cs.SD cs.AI eess.AS eess.SP
Comments: Accepted to ICASSP 2023
\\ ( https://arxiv.org/abs/2302.14370 ,  1467kb)
------------------------------------------------------------------------------
\\
arXiv:2303.12942
replaced with revised version Sun, 11 Jun 2023 23:50:52 GMT   (3535kb,D)

Title: A Survey on Explainable Artificial Intelligence for Cybersecurity
Authors: Gaith Rjoub, Jamal Bentahar, Omar Abdel Wahab, Rabeb Mizouni, Alyssa
 Song, Robin Cohen, Hadi Otrok, and Azzam Mourad
Categories: cs.CR cs.AI cs.NI
DOI: 10.1109/TNSM.2023.3282740
\\ ( https://arxiv.org/abs/2303.12942 ,  3535kb)
------------------------------------------------------------------------------
\\
arXiv:2304.12014 (*cross-listing*)
replaced with revised version Sat, 10 Jun 2023 17:52:49 GMT   (236kb,D)

Title: Optimal Layout Synthesis for Quantum Circuits as Classical Planning
Authors: Irfansha Shaik and Jaco van de Pol
Categories: quant-ph cs.AI
Comments: 11 pages, 5 figures, 10 listings and 2 tables
\\ ( https://arxiv.org/abs/2304.12014 ,  236kb)
------------------------------------------------------------------------------
\\
arXiv:2304.12244
replaced with revised version Sat, 10 Jun 2023 13:18:25 GMT   (2577kb,D)

Title: WizardLM: Empowering Large Language Models to Follow Complex
 Instructions
Authors: Can Xu, Qingfeng Sun, Kai Zheng, Xiubo Geng, Pu Zhao, Jiazhan Feng,
 Chongyang Tao, Daxin Jiang
Categories: cs.CL cs.AI
Comments: large language model, instruction fine-tune
\\ ( https://arxiv.org/abs/2304.12244 ,  2577kb)
------------------------------------------------------------------------------
\\
arXiv:2305.01876
replaced with revised version Sat, 10 Jun 2023 07:34:27 GMT   (1086kb,D)

Title: Causality-aware Concept Extraction based on Knowledge-guided Prompting
Authors: Siyu Yuan, Deqing Yang, Jinxi Liu, Shuyu Tian, Jiaqing Liang, Yanghua
 Xiao, Rui Xie
Categories: cs.CL cs.AI
Comments: Accepted to ACL 2023
\\ ( https://arxiv.org/abs/2305.01876 ,  1086kb)
------------------------------------------------------------------------------
\\
arXiv:2305.02531 (*cross-listing*)
replaced with revised version Mon, 12 Jun 2023 06:03:20 GMT   (572kb,D)

Title: Language, Time Preferences, and Consumer Behavior: Evidence from Large
 Language Models
Authors: Ali Goli, Amandeep Singh
Categories: econ.GN cs.AI cs.CL q-fin.EC
\\ ( https://arxiv.org/abs/2305.02531 ,  572kb)
------------------------------------------------------------------------------
\\
arXiv:2305.10824
replaced with revised version Sat, 10 Jun 2023 13:09:52 GMT   (1652kb,D)

Title: Integrating Item Relevance in Training Loss for Sequential Recommender
 Systems
Authors: Andrea Bacciu, Federico Siciliano, Nicola Tonellotto, Fabrizio
 Silvestri
Categories: cs.IR cs.AI
\\ ( https://arxiv.org/abs/2305.10824 ,  1652kb)
------------------------------------------------------------------------------
\\
arXiv:2305.12900
replaced with revised version Sun, 11 Jun 2023 08:23:23 GMT   (387kb,D)

Title: Evaluating Prompt-based Question Answering for Object Prediction in the
 Open Research Knowledge Graph
Authors: Jennifer D'Souza, Moussab Hrou and S\"oren Auer
Categories: cs.CL cs.AI cs.DL cs.IT math.IT
Comments: 14 pages, 1 figure, accepted for publication as a short paper at DEXA
 2023 (https://www.dexa.org/dexa2023)
\\ ( https://arxiv.org/abs/2305.12900 ,  387kb)
------------------------------------------------------------------------------
\\
arXiv:2305.17506
replaced with revised version Mon, 12 Jun 2023 08:05:03 GMT   (712kb,D)

Title: Backdooring Neural Code Search
Authors: Weisong Sun, Yuchen Chen, Guanhong Tao, Chunrong Fang, Xiangyu Zhang,
 Quanjun Zhang, Bin Luo
Categories: cs.SE cs.AI cs.CL
Comments: Accepted to the 61st Annual Meeting of the Association for
 Computational Linguistics (ACL 2023)
MSC-class: 68T01
ACM-class: I.2.2; D.2.13
\\ ( https://arxiv.org/abs/2305.17506 ,  712kb)
------------------------------------------------------------------------------
\\
arXiv:2305.17682
replaced with revised version Mon, 12 Jun 2023 02:44:26 GMT   (509kb,D)

Title: One Network, Many Masks: Towards More Parameter-Efficient Transfer
 Learning
Authors: Guangtao Zeng, Peiyuan Zhang, Wei Lu
Categories: cs.CL cs.AI
Comments: Accepted by ACL 2023
\\ ( https://arxiv.org/abs/2305.17682 ,  509kb)
------------------------------------------------------------------------------
\\
arXiv:2305.19148
replaced with revised version Sat, 10 Jun 2023 07:31:42 GMT   (1379kb,D)

Title: Mitigating Label Biases for In-context Learning
Authors: Yu Fei, Yifan Hou, Zeming Chen, Antoine Bosselut
Categories: cs.CL cs.AI cs.LG
Comments: Accepted to ACL 2023
\\ ( https://arxiv.org/abs/2305.19148 ,  1379kb)
------------------------------------------------------------------------------
\\
arXiv:2305.19512
replaced with revised version Mon, 12 Jun 2023 02:13:16 GMT   (3378kb,D)

Title: Fine-grained Text Style Transfer with Diffusion-Based Language Models
Authors: Yiwei Lyu, Tiange Luo, Jiacheng Shi, Todd C. Hollon, Honglak Lee
Categories: cs.CL cs.AI cs.LG
Comments: Accepted at Repl4NLP workshop at ACL 2023
\\ ( https://arxiv.org/abs/2305.19512 ,  3378kb)
------------------------------------------------------------------------------
\\
arXiv:2305.19915
replaced with revised version Mon, 12 Jun 2023 17:55:17 GMT   (6798kb,D)

Title: Data Augmentation Approaches for Source Code Models: A Survey
Authors: Terry Yue Zhuo, Zhou Yang, Zhensu Sun, Yufei Wang, Li Li, Xiaoning Du,
 Zhenchang Xing, David Lo
Categories: cs.CL cs.AI cs.SE
Comments: Technical Report
\\ ( https://arxiv.org/abs/2305.19915 ,  6798kb)
------------------------------------------------------------------------------
\\
arXiv:2306.00477
replaced with revised version Sun, 11 Jun 2023 15:01:49 GMT   (529kb,D)

Title: Make Your Pre-trained Model Reversible: From Parameter to Memory
 Efficient Fine-Tuning
Authors: Baohao Liao, Shaomu Tan, Christof Monz
Categories: cs.CL cs.AI cs.LG
Comments: Correct some typos. Code at https://github.com/BaohaoLiao/mefts
\\ ( https://arxiv.org/abs/2306.00477 ,  529kb)
------------------------------------------------------------------------------
\\
arXiv:2306.00627
replaced with revised version Mon, 12 Jun 2023 09:10:11 GMT   (78kb)

Title: Factors Impacting the Quality of User Answers on Smartphones
Authors: Ivano Bison, Haonan Zhao
Categories: cs.HC cs.AI
Comments: 5 pages, 1 table
Journal-ref: Workshop on Diversity-Aware Hybrid Human-Artificial Intelligence,
 2023
\\ ( https://arxiv.org/abs/2306.00627 ,  78kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02561
replaced with revised version Sat, 10 Jun 2023 01:07:38 GMT   (5477kb,D)

Title: LLM-Blender: Ensembling Large Language Models with Pairwise Ranking and
 Generative Fusion
Authors: Dongfu Jiang, Xiang Ren, Bill Yuchen Lin
Categories: cs.CL cs.AI cs.LG
Comments: Project website: https://yuchenlin.xyz/LLM-Blender/ The experiments
 on summarization, translation, and constrained generation tasks in the prior
 version have been moved to the appendix. Instead, we mainly present our work
 in the context of instruction-following data and LLMs in this version. The
 prior version has been accepted to ACL 2023
\\ ( https://arxiv.org/abs/2306.02561 ,  5477kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03358
replaced with revised version Sat, 10 Jun 2023 03:55:58 GMT   (1100kb)

Title: Is AI Changing the Rules of Academic Misconduct? An In-depth Look at
 Students' Perceptions of 'AI-giarism'
Authors: Cecilia Ka Yuk Chan
Categories: cs.CY cs.AI
\\ ( https://arxiv.org/abs/2306.03358 ,  1100kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03503
replaced with revised version Sun, 11 Jun 2023 10:45:57 GMT   (666kb)

Title: Applying Standards to Advance Upstream & Downstream Ethics in Large
 Language Models
Authors: Jose Berengueres and Marybeth Sandell
Categories: cs.CY cs.AI cs.CL
Comments: 8 pages, 4 tables, 2 figures
ACM-class: K.4.1; I.2.0
\\ ( https://arxiv.org/abs/2306.03503 ,  666kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04357
replaced with revised version Sun, 11 Jun 2023 13:30:07 GMT   (181kb,D)

Title: ConTextual Masked Auto-Encoder for Retrieval-based Dialogue Systems
Authors: Zhenpeng Su and Xing Wu and Wei Zhou and Guangyuan Ma and Songlin Hu
Categories: cs.CL cs.AI
\\ ( https://arxiv.org/abs/2306.04357 ,  181kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04757
replaced with revised version Sun, 11 Jun 2023 01:47:26 GMT   (3646kb,D)

Title: INSTRUCTEVAL: Towards Holistic Evaluation of Instruction-Tuned Large
 Language Models
Authors: Yew Ken Chia, Pengfei Hong, Lidong Bing, Soujanya Poria
Categories: cs.CL cs.AI
Comments: Github: https://github.com/declare-lab/instruct-eval Leaderboard:
 https://declare-lab.github.io/instruct-eval/
\\ ( https://arxiv.org/abs/2306.04757 ,  3646kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05554 (*cross-listing*)
replaced with revised version Mon, 12 Jun 2023 05:22:36 GMT   (1795kb)

Title: Simulation and Prediction of Countercurrent Spontaneous Imbibition at
 Early and Late Times Using Physics-Informed Neural Networks
Authors: Jassem Abbasi, P{\aa}l {\O}steb{\o} Andersen
Categories: physics.comp-ph cs.AI cs.LG
\\ ( https://arxiv.org/abs/2306.05554 ,  1795kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05817
replaced with revised version Mon, 12 Jun 2023 04:11:14 GMT   (639kb,D)

Title: How Can Recommender Systems Benefit from Large Language Models: A Survey
Authors: Jianghao Lin, Xinyi Dai, Yunjia Xi, Weiwen Liu, Bo Chen, Xiangyang Li,
 Chenxu Zhu, Huifeng Guo, Yong Yu, Ruiming Tang, Weinan Zhang
Categories: cs.IR cs.AI
Comments: 15 pages; 3 figures; summarization table in appendix;
\\ ( https://arxiv.org/abs/2306.05817 ,  639kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05949
replaced with revised version Mon, 12 Jun 2023 14:20:35 GMT   (223kb,D)

Title: Evaluating the Social Impact of Generative AI Systems in Systems and
 Society
Authors: Irene Solaiman, Zeerak Talat, William Agnew, Lama Ahmad, Dylan Baker,
 Su Lin Blodgett, Hal Daum\'e III, Jesse Dodge, Ellie Evans, Sara Hooker,
 Yacine Jernite, Alexandra Sasha Luccioni, Alberto Lusoli, Margaret Mitchell,
 Jessica Newman, Marie-Therese Png, Andrew Strait, Apostol Vassilev
Categories: cs.CY cs.AI
\\ ( https://arxiv.org/abs/2306.05949 ,  223kb)
------------------------------------------------------------------------------
\\
arXiv:2203.04301 (*cross-listing*)
replaced with revised version Mon, 12 Jun 2023 12:51:28 GMT   (8098kb,AD)

Title: Live Laparoscopic Video Retrieval with Compressed Uncertainty
Authors: Tong Yu, Pietro Mascagni, Juan Verde, Jacques Marescaux, Didier
 Mutter, Nicolas Padoy
Categories: eess.IV cs.CV
Comments: 16 pages, 13 figures
Journal-ref: Medical Image Analysis 88 (2023) 102866
\\ ( https://arxiv.org/abs/2203.04301 ,  8098kb)
------------------------------------------------------------------------------
\\
arXiv:2205.10373 (*cross-listing*)
replaced with revised version Sun, 11 Jun 2023 22:34:06 GMT   (39199kb,D)

Title: A SSIM Guided cGAN Architecture For Clinically Driven Generative Image
 Synthesis of Multiplexed Spatial Proteomics Channels
Authors: Jillur Rahman Saurav, Mohammad Sadegh Nasr, Paul Koomey, Michael
 Robben, Manfred Huber, Jon Weidanz, Br\'id Ryan, Eytan Ruppin, Peng Jiang,
 and Jacob M. Luber
Categories: eess.IV cs.CV q-bio.QM q-bio.TO
\\ ( https://arxiv.org/abs/2205.10373 ,  39199kb)
------------------------------------------------------------------------------
\\
arXiv:2207.02985 (*cross-listing*)
replaced with revised version Sat, 10 Jun 2023 15:38:13 GMT   (5572kb,D)

Title: Orthogonal Matrix Retrieval with Spatial Consensus for 3D Unknown-View
 Tomography
Authors: Shuai Huang, Mona Zehni, Ivan Dokmani\'c, Zhizhen Zhao
Categories: math.OC cs.CV eess.IV q-bio.BM stat.AP
Comments: Keywords: unknown view tomography, single-particle cryo-electron
 microscopy, method of moments, autocorrelation, spherical harmonics
MSC-class: 92C55, 68U10, 33C55, 78M05
\\ ( https://arxiv.org/abs/2207.02985 ,  5572kb)
------------------------------------------------------------------------------
\\
arXiv:2210.12331 (*cross-listing*)
replaced with revised version Mon, 12 Jun 2023 13:05:02 GMT   (1279kb,D)

Title: Deep Multi-Branch CNN Architecture for Early Alzheimer's Detection from
 Brain MRIs
Authors: Paul K. Mandal, Rakesh Mahto
Categories: eess.IV cs.CV cs.LG
Comments: 10 pages, 7 figures
MSC-class: 68Txx
ACM-class: I.2; I.4; I.5; J.3
\\ ( https://arxiv.org/abs/2210.12331 ,  1279kb)
------------------------------------------------------------------------------
\\
arXiv:2303.14845 (*cross-listing*)
replaced with revised version Sat, 10 Jun 2023 22:42:08 GMT   (4910kb,D)

Title: Multi-task Learning of Histology and Molecular Markers for Classifying
 Diffuse Glioma
Authors: Xiaofei Wang and Stephen Price and Chao Li
Categories: eess.IV cs.CV
\\ ( https://arxiv.org/abs/2303.14845 ,  4910kb)
------------------------------------------------------------------------------
\\
arXiv:2304.06286 (*cross-listing*)
replaced with revised version Sat, 10 Jun 2023 03:54:54 GMT   (4915kb,D)

Title: Converting ECG Signals to Images for Efficient Image-text Retrieval via
 Encoding
Authors: Jielin Qiu, Jiacheng Zhu, Shiqi Liu, William Han, Jingqi Zhang,
 Chaojing Duan, Michael Rosenberg, Emerson Liu, Douglas Weber, Ding Zhao
Categories: eess.SP cs.CV
Comments: 26 pages
\\ ( https://arxiv.org/abs/2304.06286 ,  4915kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02858
replaced with revised version Mon, 12 Jun 2023 02:28:57 GMT   (2864kb,D)

Title: Video-LLaMA: An Instruction-tuned Audio-Visual Language Model for Video
 Understanding
Authors: Hang Zhang, Xin Li, Lidong Bing
Categories: cs.CL cs.CV cs.SD eess.AS
Comments: Technical Report; Code, Pretrained Model, and Dataset:
 https://github.com/DAMO-NLP-SG/Video-LLaMA
\\ ( https://arxiv.org/abs/2306.02858 ,  2864kb)
------------------------------------------------------------------------------
\\
arXiv:2112.06275 (*cross-listing*)
replaced with revised version Mon, 12 Jun 2023 06:09:06 GMT   (1781kb,D)

Title: A Restless Bandit Model for Energy-Efficient Job Assignments in Server
 Farms
Authors: Jing Fu, Xinyu Wang, Zengfu Wang, and Moshe Zukerman
Categories: math.OC cs.DC
Comments: 40 pages, 4 figures
MSC-class: 68M20 (primary), 90B22, 90B36 (secondary)
ACM-class: G.1.6; G.3
\\ ( https://arxiv.org/abs/2112.06275 ,  1781kb)
------------------------------------------------------------------------------
\\
arXiv:2211.10769
replaced with revised version Fri, 9 Jun 2023 18:13:53 GMT   (839kb,D)

Title: Assessing Opportunities of SYCL and Intel oneAPI for Biological Sequence
 Alignment
Authors: Manuel Costanzo and Enzo Rucci and Carlos Garc\'ia S\'anchez and
 Marcelo Naiouf and Manuel Prieto-Mat\'ias
Categories: cs.PL cs.DC
\\ ( https://arxiv.org/abs/2211.10769 ,  839kb)
------------------------------------------------------------------------------
\\
arXiv:2303.04430
replaced with revised version Mon, 12 Jun 2023 09:19:01 GMT   (824kb,D)

Title: Multi-block MEV
Authors: Johannes Rude Jensen, Victor von Wachter, Omri Ross
Categories: cs.CR cs.DC
\\ ( https://arxiv.org/abs/2303.04430 ,  824kb)
------------------------------------------------------------------------------
\\
arXiv:2112.14356 (*cross-listing*)
replaced with revised version Fri, 9 Jun 2023 22:02:36 GMT   (66kb)

Title: Private Private Information
Authors: Kevin He, Fedor Sandomirskiy, and Omer Tamuz
Categories: econ.TH cs.GT math.PR
\\ ( https://arxiv.org/abs/2112.14356 ,  66kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02817 (*cross-listing*)
replaced with revised version Mon, 12 Jun 2023 13:01:23 GMT   (171kb,D)

Title: Integer Programming Games: A Gentle Computational Overview
Authors: Margarida Carvalho, Gabriele Dragotto, Andrea Lodi, Sriram
 Sankaranarayanan
Categories: math.OC cs.GT
Comments: To appear in INFORMS TutORials in Operations Research 2023
\\ ( https://arxiv.org/abs/2306.02817 ,  171kb)
------------------------------------------------------------------------------
\\
arXiv:2012.13940 (*cross-listing*)
replaced with revised version Fri, 9 Jun 2023 18:15:24 GMT   (1521kb,D)

Title: A Doubly Stochastic Simulator with Applications in Arrivals Modeling and
 Simulation
Authors: Yufeng Zheng, Zeyu Zheng, Tingyu Zhu
Categories: stat.ML cs.LG
Comments: We appreciate a lot the comments and suggestions from anonymous
 reviewers and editors. This is updated version, and with title changed from
 "Doubly Stochastic Generative Arrivals Modeling" to "A Doubly Stochastic
 Simulator with Applications in Arrivals Modeling and Simulation"
\\ ( https://arxiv.org/abs/2012.13940 ,  1521kb)
------------------------------------------------------------------------------
\\
arXiv:2105.12342 (*cross-listing*)
replaced with revised version Sun, 11 Jun 2023 13:23:40 GMT   (289kb)

Title: A data-driven approach to beating SAA out-of-sample
Authors: Jun-ya Gotoh, Michael Jong Kim, Andrew E.B. Lim
Categories: math.OC cs.LG cs.SY econ.EM eess.SY stat.ML
Comments: 25 pages, 2 page bibliography, 2 Figures, 12 page Appendix
MSC-class: 90C17, 90C31, 93B35, 90C47, 90B50, 62G35, 62K25,
\\ ( https://arxiv.org/abs/2105.12342 ,  289kb)
------------------------------------------------------------------------------
\\
arXiv:2109.10399 (*cross-listing*)
replaced with revised version Sun, 11 Jun 2023 03:17:19 GMT   (10809kb,D)

Title: SubseasonalClimateUSA: A Dataset for Subseasonal Forecasting and
 Benchmarking
Authors: Soukayna Mouatadid, Paulo Orenstein, Genevieve Flaspohler, Miruna
 Oprescu, Judah Cohen, Franklyn Wang, Sean Knight, Maria Geogdzhayeva, Sam
 Levang, Ernest Fraenkel and Lester Mackey
Categories: physics.ao-ph cs.LG stat.ML
\\ ( https://arxiv.org/abs/2109.10399 ,  10809kb)
------------------------------------------------------------------------------
\\
arXiv:2112.09466 (*cross-listing*)
replaced with revised version Sat, 10 Jun 2023 17:39:12 GMT   (4680kb,D)

Title: Fair Active Learning: Solving the Labeling Problem in Insurance
Authors: Romuald Elie, Caroline Hillairet, Fran\c{c}ois Hu, Marc Juillard
Categories: stat.ML cs.LG
\\ ( https://arxiv.org/abs/2112.09466 ,  4680kb)
------------------------------------------------------------------------------
\\
arXiv:2202.10506 (*cross-listing*)
replaced with revised version Mon, 12 Jun 2023 16:56:40 GMT   (398kb,D)

Title: Accelerating Primal-dual Methods for Regularized Markov Decision
 Processes
Authors: Haoya Li, Hsiang-fu Yu, Lexing Ying, and Inderjit Dhillon
Categories: math.OC cs.LG stat.ML
\\ ( https://arxiv.org/abs/2202.10506 ,  398kb)
------------------------------------------------------------------------------
\\
arXiv:2203.00132 (*cross-listing*)
replaced with revised version Sat, 10 Jun 2023 14:17:25 GMT   (478kb,D)

Title: On Testability and Goodness of Fit Tests in Missing Data Models
Authors: Razieh Nabi, Rohit Bhattacharya
Categories: stat.ME cs.LG stat.ML
Journal-ref: Proceedings of the 39th Conference on Uncertainty in Artificial
 Intelligence (UAI), 2023
\\ ( https://arxiv.org/abs/2203.00132 ,  478kb)
------------------------------------------------------------------------------
\\
arXiv:2203.04769 (*cross-listing*)
replaced with revised version Sun, 11 Jun 2023 10:09:39 GMT   (379kb,D)

Title: Autoregressive based Drift Detection Method
Authors: Mansour Zoubeirou A Mayaki and Michel Riveill
Categories: stat.ML cs.LG
DOI: 10.1109/IJCNN55064.2022.9892066
\\ ( https://arxiv.org/abs/2203.04769 ,  379kb)
------------------------------------------------------------------------------
\\
arXiv:2204.14174 (*cross-listing*)
replaced with revised version Sun, 11 Jun 2023 13:11:01 GMT   (930kb,D)

Title: Explainable AI via Learning to Optimize
Authors: Howard Heaton and Samy Wu Fung
Categories: math.OC cs.LG
\\ ( https://arxiv.org/abs/2204.14174 ,  930kb)
------------------------------------------------------------------------------
\\
arXiv:2206.05581 (*cross-listing*)
replaced with revised version Sun, 11 Jun 2023 19:35:58 GMT   (1000kb,D)

Title: Federated Offline Reinforcement Learning
Authors: Doudou Zhou, Yufeng Zhang, Aaron Sonabend-W, Zhaoran Wang, Junwei Lu,
 Tianxi Cai
Categories: stat.ML cs.LG stat.ME
\\ ( https://arxiv.org/abs/2206.05581 ,  1000kb)
------------------------------------------------------------------------------
\\
arXiv:2207.04932 (*cross-listing*)
replaced with revised version Mon, 12 Jun 2023 14:49:09 GMT   (229kb,D)

Title: Stochastic Gradient Descent and Anomaly of Variance-flatness Relation in
 Artificial Neural Networks
Authors: Xia Xiong, Yong-Cong Chen, Chunxiao Shi and Ping Ao
Categories: nlin.AO cs.LG
\\ ( https://arxiv.org/abs/2207.04932 ,  229kb)
------------------------------------------------------------------------------
\\
arXiv:2209.12651 (*cross-listing*)
replaced with revised version Sat, 10 Jun 2023 13:25:35 GMT   (481kb,D)

Title: Learning Variational Models with Unrolling and Bilevel Optimization
Authors: Christoph Brauer, Niklas Breustedt, Timo de Wolff, Dirk A. Lorenz
Categories: stat.ML cs.LG math.ST stat.TH
MSC-class: 68T07, 68T05
\\ ( https://arxiv.org/abs/2209.12651 ,  481kb)
------------------------------------------------------------------------------
\\
arXiv:2211.00375
replaced with revised version Sun, 11 Jun 2023 21:33:09 GMT   (2204kb,D)

Title: Generating Multilingual Gender-Ambiguous Text-to-Speech Voices
Authors: Konstantinos Markopoulos, Georgia Maniati, Georgios Vamvoukakis,
 Nikolaos Ellinas, Georgios Vardaxoglou, Panos Kakoulidis, Junkwang Oh, Gunu
 Jho, Inchul Hwang, Aimilios Chalamandaris, Pirros Tsiakoulis and Spyros
 Raptis
Categories: cs.SD cs.CL cs.LG eess.AS
Comments: Accepted to INTERSPEECH 2023
\\ ( https://arxiv.org/abs/2211.00375 ,  2204kb)
------------------------------------------------------------------------------
\\
arXiv:2211.06617 (*cross-listing*)
replaced with revised version Mon, 12 Jun 2023 11:46:01 GMT   (409kb,D)

Title: Empirical Risk Minimization with Relative Entropy Regularization
Authors: Samir M. Perlaza, Gaetan Bisson, I\~naki Esnaola, Alain Jean-Marie,
 Stefano Rini
Categories: math.ST cs.IT cs.LG math.IT stat.TH
Comments: Submitted to the the Transactions on Information Theory on June 12,
 2023. Also available as: Research Report, INRIA, No. RR-9454, Centre Inria
 d'Universit\'e C\^ote d'Azur, Sophia Antipolis, France, Feb., 2022
Report-no: RR-9454
\\ ( https://arxiv.org/abs/2211.06617 ,  409kb)
------------------------------------------------------------------------------
\\
arXiv:2211.16467 (*cross-listing*)
replaced with revised version Sun, 11 Jun 2023 21:35:42 GMT   (833kb,D)

Title: Linear Causal Disentanglement via Interventions
Authors: Chandler Squires, Anna Seigal, Salil Bhate, Caroline Uhler
Categories: stat.ML cs.LG
\\ ( https://arxiv.org/abs/2211.16467 ,  833kb)
------------------------------------------------------------------------------
\\
arXiv:2212.05866 (*cross-listing*)
replaced with revised version Mon, 12 Jun 2023 07:03:09 GMT   (8565kb,D)

Title: Explainable Performance: Measuring the Driving Forces of Predictive
 Performance
Authors: Hu\'e Sullivan, Hurlin Christophe, P\'erignon Christophe and Saurin
 S\'ebastien
Categories: stat.ML cs.LG econ.EM stat.ME
\\ ( https://arxiv.org/abs/2212.05866 ,  8565kb)
------------------------------------------------------------------------------
\\
arXiv:2212.07347 (*cross-listing*)
replaced with revised version Sat, 10 Jun 2023 23:28:30 GMT   (1725kb,D)

Title: Lorentz group equivariant autoencoders
Authors: Zichun Hao, Raghav Kansal, Javier Duarte, Nadezda Chernyavskaya
Categories: hep-ex cs.LG
Comments: 11 pages, 7 figures, 4 tables, and a 3 page appendix
Journal-ref: Eur. Phys. J. C 83, 485 (2023)
DOI: 10.1140/epjc/s10052-023-11633-5
\\ ( https://arxiv.org/abs/2212.07347 ,  1725kb)
------------------------------------------------------------------------------
\\
arXiv:2212.09470 (*cross-listing*)
replaced with revised version Sun, 11 Jun 2023 20:18:52 GMT   (1219kb)

Title: Automated Search for Conjectures on Mathematical Constants using
 Analysis of Integer Sequences
Authors: Ofir Razon, Yoav Harris, Shahar Gottlieb, Dan Carmon, Ofir David and
 Ido Kaminer
Categories: math.NT cs.LG
Comments: 5 figures, 31 pages including supplementary information
\\ ( https://arxiv.org/abs/2212.09470 ,  1219kb)
------------------------------------------------------------------------------
\\
arXiv:2212.14597
replaced with revised version Sat, 10 Jun 2023 18:48:55 GMT   (75kb,D)

Title: Defense Against Adversarial Attacks on Audio DeepFake Detection
Authors: Piotr Kawa, Marcin Plata, Piotr Syga
Categories: cs.SD cs.CR cs.LG eess.AS
Comments: Accepted to INTERSPEECH 2023
\\ ( https://arxiv.org/abs/2212.14597 ,  75kb)
------------------------------------------------------------------------------
\\
arXiv:2302.06807 (*cross-listing*)
replaced with revised version Mon, 12 Jun 2023 03:24:29 GMT   (2223kb,D)

Title: Horospherical Decision Boundaries for Large Margin Classification in
 Hyperbolic Space
Authors: Xiran Fan, Chun-Hao Yang, Baba C. Vemuri
Categories: stat.ML cs.LG
\\ ( https://arxiv.org/abs/2302.06807 ,  2223kb)
------------------------------------------------------------------------------
\\
arXiv:2302.07186 (*cross-listing*)
replaced with revised version Mon, 12 Jun 2023 16:52:27 GMT   (91kb)

Title: Adversarial Rewards in Universal Learning for Contextual Bandits
Authors: Moise Blanchard, Steve Hanneke and Patrick Jaillet
Categories: stat.ML cs.LG math.ST stat.TH
\\ ( https://arxiv.org/abs/2302.07186 ,  91kb)
------------------------------------------------------------------------------
\\
arXiv:2302.07698 (*cross-listing*)
replaced with revised version Mon, 12 Jun 2023 11:43:45 GMT   (1531kb,D)

Title: Photonic reservoir computing enabled by stimulated Brillouin scattering
Authors: Sendy Phang
Categories: physics.optics cs.LG
Comments: 8 pages, 6 figures, research article, to be published, accepted
 version
Journal-ref: Optics Express, 2023
DOI: 10.1364/OE.489057
\\ ( https://arxiv.org/abs/2302.07698 ,  1531kb)
------------------------------------------------------------------------------
\\
arXiv:2302.11294 (*cross-listing*)
replaced with revised version Mon, 12 Jun 2023 11:39:18 GMT   (2494kb,D)

Title: Distributional Learning of Variational AutoEncoder: Application to
 Synthetic Data Generation
Authors: Seunghwan An, Jong-June Jeon
Categories: stat.ML cs.LG
Comments: 9 pages for main part and 15 pages for Appendix, 5 figures
\\ ( https://arxiv.org/abs/2302.11294 ,  2494kb)
------------------------------------------------------------------------------
\\
arXiv:2303.07203
replaced with revised version Mon, 12 Jun 2023 12:55:48 GMT   (923kb,D)

Title: On the Robustness of Text Vectorizers
Authors: R\'emi Catellier, Samuel Vaiter, Damien Garreau
Categories: cs.CL cs.LG stat.ML
Comments: Accepted to ICML 2023. 33 pages, 10 figures
\\ ( https://arxiv.org/abs/2303.07203 ,  923kb)
------------------------------------------------------------------------------
\\
arXiv:2304.06858
replaced with revised version Sun, 11 Jun 2023 22:11:10 GMT   (99kb)

Title: Vax-Culture: A Dataset for Studying Vaccine Discourse on Twitter
Authors: Mohammad Reza Zarei, Michael Christensen, Sarah Everts and Majid
 Komeili
Categories: cs.SI cs.CL cs.LG
\\ ( https://arxiv.org/abs/2304.06858 ,  99kb)
------------------------------------------------------------------------------
\\
arXiv:2304.11473
replaced with revised version Sun, 11 Jun 2023 17:35:02 GMT   (737kb,D)

Title: (Vector) Space is Not the Final Frontier: Product Search as Program
 Synthesis
Authors: Jacopo Tagliabue and Ciro Greco
Categories: cs.IR cs.CL cs.LG
Comments: Published at SIGIR eCom 2023
\\ ( https://arxiv.org/abs/2304.11473 ,  737kb)
------------------------------------------------------------------------------
\\
arXiv:2304.13620
replaced with revised version Sun, 11 Jun 2023 04:07:27 GMT   (6961kb,D)

Title: ChartSumm: A Comprehensive Benchmark for Automatic Chart Summarization
 of Long and Short Summaries
Authors: Raian Rahman, Rizvi Hasan, Abdullah Al Farhad, Md Tahmid Rahman
 Laskar, Md. Hamjajul Ashmafee, Abu Raihan Mostofa Kamal
Categories: cs.CL cs.LG
Comments: Accepted as a long paper at the Canadian AI 2023
DOI: 10.21428/594757db.0b1f96f6
\\ ( https://arxiv.org/abs/2304.13620 ,  6961kb)
------------------------------------------------------------------------------
\\
arXiv:2305.00621 (*cross-listing*)
replaced with revised version Mon, 12 Jun 2023 09:32:29 GMT   (460kb,D)

Title: Proper Scoring Rules for Survival Analysis
Authors: Hiroki Yanagisawa
Categories: stat.ME cs.LG
Comments: Accepted at ICML 2023
\\ ( https://arxiv.org/abs/2305.00621 ,  460kb)
------------------------------------------------------------------------------
\\
arXiv:2305.01210
replaced with revised version Mon, 12 Jun 2023 06:49:51 GMT   (478kb,D)

Title: Is Your Code Generated by ChatGPT Really Correct? Rigorous Evaluation of
 Large Language Models for Code Generation
Authors: Jiawei Liu and Chunqiu Steven Xia and Yuyao Wang and Lingming Zhang
Categories: cs.SE cs.CL cs.LG
\\ ( https://arxiv.org/abs/2305.01210 ,  478kb)
------------------------------------------------------------------------------
\\
arXiv:2305.12100 (*cross-listing*)
replaced with revised version Sun, 11 Jun 2023 09:01:41 GMT   (828kb,D)

Title: Stability, Generalization and Privacy: Precise Analysis for Random and
 NTK Features
Authors: Simone Bombari, Marco Mondelli
Categories: stat.ML cs.LG
Comments: arXiv admin note: text overlap with arXiv:2302.01629 Fixed Cauchy
 Schwartz typo, square roots added
\\ ( https://arxiv.org/abs/2305.12100 ,  828kb)
------------------------------------------------------------------------------
\\
arXiv:2305.18624
replaced with revised version Sat, 10 Jun 2023 01:06:19 GMT   (551kb,D)

Title: W-procer: Weighted Prototypical Contrastive Learning for Medical
 Few-Shot Named Entity Recognition
Authors: Mingchen Li, Yang Ye, Jeremy Yeung, Huixue Zhou, Huaiyuan Chu, Rui
 Zhang
Categories: cs.CL cs.LG
Comments: Under Review
\\ ( https://arxiv.org/abs/2305.18624 ,  551kb)
------------------------------------------------------------------------------
\\
arXiv:2306.02383
replaced with revised version Sun, 11 Jun 2023 06:38:03 GMT   (3057kb)

Title: Evolution of Efficient Symbolic Communication Codes
Authors: Anton Kolonin
Categories: cs.CL cs.IT cs.LG math.IT
Comments: 9 pages, 6 figures
\\ ( https://arxiv.org/abs/2306.02383 ,  3057kb)
------------------------------------------------------------------------------
\\
arXiv:2306.04174 (*cross-listing*)
replaced with revised version Sun, 11 Jun 2023 10:29:32 GMT   (1784kb,D)

Title: End-to-End Learning for Stochastic Optimization: A Bayesian Perspective
Authors: Yves Rychener, Daniel Kuhn, Tobias Sutter
Categories: math.OC cs.LG stat.ML
Comments: Accepted at ICML 2023
\\ ( https://arxiv.org/abs/2306.04174 ,  1784kb)
------------------------------------------------------------------------------
\\
arXiv:2306.05708
replaced with revised version Mon, 12 Jun 2023 06:12:41 GMT   (991kb,D)

Title: Boosting Fast and High-Quality Speech Synthesis with Linear Diffusion
Authors: Haogeng Liu, Tao Wang, Jie Cao, Ran He, Jianhua Tao
Categories: cs.SD cs.LG eess.AS
\\ ( https://arxiv.org/abs/2306.05708 ,  991kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06079 (*cross-listing*)
replaced with revised version Mon, 12 Jun 2023 10:48:25 GMT   (7414kb,D)

Title: Deep Learning for Day Forecasts from Sparse Observations
Authors: Marcin Andrychowicz, Lasse Espeholt, Di Li, Samier Merchant, Alex
 Merose, Fred Zyda, Shreya Agrawal, Nal Kalchbrenner
Categories: physics.ao-ph cs.LG
\\ ( https://arxiv.org/abs/2306.06079 ,  7414kb)
------------------------------------------------------------------------------
\\
arXiv:2303.17977
replaced with revised version Mon, 12 Jun 2023 12:03:06 GMT   (1714kb,D)

Title: MARTSIA: Enabling Data Confidentiality for Blockchain-based Process
 Execution
Authors: Edoardo Marangone, Claudio Di Ciccio, Daniele Friolo, Eugenio Nerio
 Nemmi, Daniele Venturi, Ingo Weber
Categories: cs.CR cs.MA
\\ ( https://arxiv.org/abs/2303.17977 ,  1714kb)
------------------------------------------------------------------------------
\\
arXiv:2012.12937 (*cross-listing*)
replaced with revised version Sun, 11 Jun 2023 13:10:36 GMT   (240kb,D)

Title: Minimal controllability time for systems with nonlinear drift under a
 compact convex state constraint
Authors: Viktor Bezborodov, Luca Di Persio, Riccardo Muradore
Categories: math.OC cs.SY eess.SY
Comments: Figure 2 is now displayed correctly
MSC-class: 93B05, 93C05, 93B27
Journal-ref: Automatica Volume 125, March 2021,
DOI: 10.1016/j.automatica.2020.109428
\\ ( https://arxiv.org/abs/2012.12937 ,  240kb)
------------------------------------------------------------------------------
\\
arXiv:2301.04999 (*cross-listing*)
replaced with revised version Mon, 12 Jun 2023 09:24:48 GMT   (5358kb,D)

Title: Stress Flow Guided Non-Planar Print Trajectory Optimization for Additive
 Manufacturing of Anisotropic Polymers
Authors: Xavier Guidetti, Efe C. Balta, Yannick Nagel, Hang Yin, Alisa
 Rupenyan, John Lygeros
Categories: math.OC cs.SY eess.SY
Comments: Accepted and published on Elsevier Additive Manufacturing
Journal-ref: Additive Manufacturing, Volume 72, 2023, 103628
DOI: 10.1016/j.addma.2023.103628
\\ ( https://arxiv.org/abs/2301.04999 ,  5358kb)
%%%---%%%---%%%---%%%---%%%---%%%---%%%---%%%---%%%---%%%---%%%---%%%---%%%---
